<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-05-01</h1>
<h3>Title: Research on CNN-BiLSTM Network Traffic Anomaly Detection Model Based on MindSpore</h3>
<ul>
<li><strong>Authors: </strong>Qiuyan Xiang, Shuang Wu, Dongze Wu, Yuxin Liu, Zhenkai Qin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21008">https://arxiv.org/abs/2504.21008</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21008">https://arxiv.org/pdf/2504.21008</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21008]] Research on CNN-BiLSTM Network Traffic Anomaly Detection Model Based on MindSpore(https://arxiv.org/abs/2504.21008)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>With the widespread adoption of the Internet of Things (IoT) and Industrial IoT (IIoT) technologies, network architectures have become increasingly complex, and the volume of traffic has grown substantially. This evolution poses significant challenges to traditional security mechanisms, particularly in detecting high-frequency, diverse, and highly covert network attacks. To address these challenges, this study proposes a novel network traffic anomaly detection model that integrates a Convolutional Neural Network (CNN) with a Bidirectional Long Short-Term Memory (BiLSTM) network, implemented on the MindSpore framework. Comprehensive experiments were conducted using the NF-BoT-IoT dataset. The results demonstrate that the proposed model achieves 99% across accuracy, precision, recall, and F1-score, indicating its strong performance and robustness in network intrusion detection tasks.</li>
</ul>

<h3>Title: Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Makoto Sato</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21012">https://arxiv.org/abs/2504.21012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21012">https://arxiv.org/pdf/2504.21012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21012]] Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models(https://arxiv.org/abs/2504.21012)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>What underlies intuitive human thinking? One approach to this question is to compare the cognitive dynamics of humans and large language models (LLMs). However, such a comparison requires a method to quantitatively analyze AI cognitive behavior under controlled conditions. While anecdotal observations suggest that certain prompts can dramatically change LLM behavior, these observations have remained largely qualitative. Here, we propose a two-part framework to investigate this phenomenon: a Transition-Inducing Prompt (TIP) that triggers a rapid shift in LLM responsiveness, and a Transition Quantifying Prompt (TQP) that evaluates this change using a separate LLM. Through controlled experiments, we examined how LLMs react to prompts embedding two semantically distant concepts (e.g., mathematical aperiodicity and traditional crafts)--either fused together or presented separately--by changing their linguistic quality and affective tone. Whereas humans tend to experience heightened engagement when such concepts are meaningfully blended producing a novel concept--a form of conceptual fusion--current LLMs showed no significant difference in responsiveness between semantically fused and non-fused prompts. This suggests that LLMs may not yet replicate the conceptual integration processes seen in human intuition. Our method enables fine-grained, reproducible measurement of cognitive responsiveness, and may help illuminate key differences in how intuition and conceptual leaps emerge in artificial versus human minds.</li>
</ul>

<h3>Title: ViQA-COVID: COVID-19 Machine Reading Comprehension Dataset for Vietnamese</h3>
<ul>
<li><strong>Authors: </strong>Hai-Chung Nguyen-Phung, Ngoc C. Lê, Van-Chien Nguyen, Hang Thi Nguyen, Thuy Phuong Thi Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21017">https://arxiv.org/abs/2504.21017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21017">https://arxiv.org/pdf/2504.21017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21017]] ViQA-COVID: COVID-19 Machine Reading Comprehension Dataset for Vietnamese(https://arxiv.org/abs/2504.21017)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>After two years of appearance, COVID-19 has negatively affected people and normal life around the world. As in May 2022, there are more than 522 million cases and six million deaths worldwide (including nearly ten million cases and over forty-three thousand deaths in Vietnam). Economy and society are both severely affected. The variant of COVID-19, Omicron, has broken disease prevention measures of countries and rapidly increased number of infections. Resources overloading in treatment and epidemics prevention is happening all over the world. It can be seen that, application of artificial intelligence (AI) to support people at this time is extremely necessary. There have been many studies applying AI to prevent COVID-19 which are extremely useful, and studies on machine reading comprehension (MRC) are also in it. Realizing that, we created the first MRC dataset about COVID-19 for Vietnamese: ViQA-COVID and can be used to build models and systems, contributing to disease prevention. Besides, ViQA-COVID is also the first multi-span extraction MRC dataset for Vietnamese, we hope that it can contribute to promoting MRC studies in Vietnamese and multilingual.</li>
</ul>

<h3>Title: Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations</h3>
<ul>
<li><strong>Authors: </strong>Yinghan Zhou, Juan Wen, Wanli Peng, Yiming Xue, Ziwei Zhang, Zhengxian Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21019">https://arxiv.org/abs/2504.21019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21019">https://arxiv.org/pdf/2504.21019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21019]] Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations(https://arxiv.org/abs/2504.21019)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The growing popularity of large language models has raised concerns regarding the potential to misuse AI-generated text (AIGT). It becomes increasingly critical to establish an excellent AIGT detection method with high generalization and robustness. However, existing methods either focus on model generalization or concentrate on robustness. The unified mechanism, to simultaneously address the challenges of generalization and robustness, is less explored. In this paper, we argue that robustness can be view as a specific form of domain shift, and empirically reveal an intrinsic mechanism for model generalization of AIGT detection task. Then, we proposed a novel AIGT detection method (DP-Net) via dynamic perturbations introduced by a reinforcement learning with elaborated reward and action. Experimentally, extensive results show that the proposed DP-Net significantly outperforms some state-of-the-art AIGT detection methods for generalization capacity in three cross-domain scenarios. Meanwhile, the DP-Net achieves best robustness under two text adversarial attacks. The code is publicly available at this https URL.</li>
</ul>

<h3>Title: Context-Enhanced Contrastive Search for Improved LLM Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Jaydip Sen, Rohit Pandey, Hetvi Waghela</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21020">https://arxiv.org/abs/2504.21020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21020">https://arxiv.org/pdf/2504.21020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21020]] Context-Enhanced Contrastive Search for Improved LLM Text Generation(https://arxiv.org/abs/2504.21020)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, Large Language Models (LLMs) have demonstrated remarkable advancements in Natural Language Processing (NLP). However, generating high-quality text that balances coherence, diversity, and relevance remains challenging. Traditional decoding methods, such as bean search and top-k sampling, often struggle with either repetitive or incoherent outputs, particularly in tasks that require long-form text generation. To address these limitations, the paper proposes a novel enhancement of the well-known Contrastive Search algorithm, Context-Enhanced Contrastive Search (CECS) with contextual calibration. The proposed scheme introduces several novelties including dynamic contextual importance weighting, multi-level Contrastive Search, and adaptive temperature control, to optimize the balance between fluency, creativity, and precision. The performance of CECS is evaluated using several standard metrics such as BLEU, ROUGE, and semantic similarity. Experimental results demonstrate significant improvements in both coherence and relevance of the generated texts by CECS outperforming the existing Contrastive Search techniques. The proposed algorithm has several potential applications in the real world including legal document drafting, customer service chatbots, and content marketing.</li>
</ul>

<h3>Title: Param$Δ$ for Direct Weight Mixing: Post-Train Large Language Model at Zero Cost</h3>
<ul>
<li><strong>Authors: </strong>Sheng Cao, Mingrui Wu, Karthik Prasad, Yuandong Tian, Zechun Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21023">https://arxiv.org/abs/2504.21023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21023">https://arxiv.org/pdf/2504.21023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21023]] Param$Δ$ for Direct Weight Mixing: Post-Train Large Language Model at Zero Cost(https://arxiv.org/abs/2504.21023)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The post-training phase of large language models is essential for enhancing capabilities such as instruction-following, reasoning, and alignment with human preferences. However, it demands extensive high-quality data and poses risks like overfitting, alongside significant computational costs due to repeated post-training and evaluation after each base model update. This paper introduces $Param\Delta$, a novel method that streamlines post-training by transferring knowledge from an existing post-trained model to a newly updated base model with ZERO additional training. By computing the difference between post-trained model weights ($\Theta_\text{post}$) and base model weights ($\Theta_\text{base}$), and adding this to the updated base model ($\Theta'_\text{base}$), we define $Param\Delta$ Model as: $\Theta_{\text{Param}\Delta} = \Theta_\text{post} - \Theta_\text{base} + \Theta'_\text{base}$. This approach surprisingly equips the new base model with post-trained capabilities, achieving performance comparable to direct post-training. We did analysis on LLama3, Llama3.1, Qwen, and DeepSeek-distilled models. Results indicate $Param\Delta$ Model effectively replicates traditional post-training. For example, the $Param\Delta$ Model obtained from 70B Llama3-inst, Llama3-base, Llama3.1-base models attains approximately 95\% of Llama3.1-inst model's performance on average. $Param\Delta$ brings a new perspective on how to fully leverage models in the open-weight community, where checkpoints for base and instruct models are readily available and frequently updated, by providing a cost-free framework to accelerate the iterative cycle of model development.</li>
</ul>

<h3>Title: WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World Model</h3>
<ul>
<li><strong>Authors: </strong>Tianqing Fang, Hongming Zhang, Zhisong Zhang, Kaixin Ma, Wenhao Yu, Haitao Mi, Dong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21024">https://arxiv.org/abs/2504.21024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21024">https://arxiv.org/pdf/2504.21024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21024]] WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World Model(https://arxiv.org/abs/2504.21024)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Agent self-improvement, where the backbone Large Language Model (LLM) of the agent are trained on trajectories sampled autonomously based on their own policies, has emerged as a promising approach for enhancing performance. Recent advancements, particularly in web environments, face a critical limitation: their performance will reach a stagnation point during autonomous learning cycles, hindering further improvement. We argue that this stems from limited exploration of the web environment and insufficient exploitation of pre-trained web knowledge in LLMs. To improve the performance of self-improvement, we propose a novel framework that introduces a co-evolving World Model LLM. This world model predicts the next observation based on the current observation and action within the web environment. Leveraging LLMs' pretrained knowledge of abundant web content, the World Model serves dual roles: (1) as a virtual web server generating self-instructed training data to continuously refine the agent's policy, and (2) as an imagination engine during inference, enabling look-ahead simulation to guide action selection for the agent LLM. Experiments in real-world web environments (Mind2Web-Live, WebVoyager, and GAIA-web) show a 10% performance gain over existing self-evolving agents, demonstrating the efficacy and generalizability of our approach, without using any distillation from more powerful close-sourced models. Our work establishes the necessity of integrating world models into autonomous agent frameworks to unlock sustained adaptability.</li>
</ul>

<h3>Title: Durghotona GPT: A Web Scraping and Large Language Model Based Framework to Generate Road Accident Dataset Automatically in Bangladesh</h3>
<ul>
<li><strong>Authors: </strong>MD Thamed Bin Zaman Chowdhury, Moazzem Hossain, Md. Ridwanul Islam</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21025">https://arxiv.org/abs/2504.21025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21025">https://arxiv.org/pdf/2504.21025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21025]] Durghotona GPT: A Web Scraping and Large Language Model Based Framework to Generate Road Accident Dataset Automatically in Bangladesh(https://arxiv.org/abs/2504.21025)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Road accidents pose significant concerns globally. They lead to large financial losses, injuries, disabilities, and societal challenges. Accurate and timely accident data is essential for predicting and mitigating these events. This paper presents a novel framework named 'Durghotona GPT' that integrates web scraping and Large Language Models (LLMs) to automate the generation of comprehensive accident datasets from prominent national dailies in Bangladesh. The authors collected accident reports from three major newspapers: Prothom Alo, Dhaka Tribune, and The Daily Star. The collected news was then processed using the newest available LLMs: GPT-4, GPT-3.5, and Llama-3. The framework efficiently extracts relevant information, categorizes reports, and compiles detailed datasets. Thus, this framework overcomes limitations of manual data collection methods such as delays, errors, and communication gaps. The authors' evaluation demonstrates that Llama-3, an open-source model, performs comparably to GPT-4. It achieved 89% accuracy in the authors' evaluation. Therefore, it can be considered a cost-effective alternative for similar tasks. The results suggest that the framework developed by the authors can drastically enhance the quality and availability of accident data. As a result, it can support critical applications in traffic safety analysis, urban planning, and public health. The authors also developed an interface for 'Durghotona GPT' for ease of use as part of this paper. Future work will focus on expanding data collection methods and refining LLMs to further increase dataset accuracy and applicability.</li>
</ul>

<h3>Title: Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets for Abusive Language Detection Using Traditional and Deep Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Manish Pandey, Nageshwar Prasad Yadav, Mokshada Adduru, Sawan Rai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21026">https://arxiv.org/abs/2504.21026</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21026">https://arxiv.org/pdf/2504.21026</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21026]] Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets for Abusive Language Detection Using Traditional and Deep Learning Models(https://arxiv.org/abs/2504.21026)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>With the growing presence of multilingual users on social media, detecting abusive language in code-mixed text has become increasingly challenging. Code-mixed communication, where users seamlessly switch between English and their native languages, poses difficulties for traditional abuse detection models, as offensive content may be context-dependent or obscured by linguistic blending. While abusive language detection has been extensively explored for high-resource languages like English and Hindi, low-resource languages such as Telugu and Nepali remain underrepresented, leaving gaps in effective moderation. In this study, we introduce a novel, manually annotated dataset of 2 thousand Telugu-English and 5 Nepali-English code-mixed comments, categorized as abusive and non-abusive, collected from various social media platforms. The dataset undergoes rigorous preprocessing before being evaluated across multiple Machine Learning (ML), Deep Learning (DL), and Large Language Models (LLMs). We experimented with models including Logistic Regression, Random Forest, Support Vector Machines (SVM), Neural Networks (NN), LSTM, CNN, and LLMs, optimizing their performance through hyperparameter tuning, and evaluate it using 10-fold cross-validation and statistical significance testing (t-test). Our findings provide key insights into the challenges of detecting abusive language in code-mixed settings and offer a comparative analysis of computational approaches. This study contributes to advancing NLP for low-resource languages by establishing benchmarks for abusive language detection in Telugu-English and Nepali-English code-mixed text. The dataset and insights can aid in the development of more robust moderation strategies for multilingual social media environments.</li>
</ul>

<h3>Title: UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yu Zheng, Longyi Liu, Yuming Lin, Jie Feng, Guozhen Zhang, Depeng Jin, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21027">https://arxiv.org/abs/2504.21027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21027">https://arxiv.org/pdf/2504.21027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21027]] UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models(https://arxiv.org/abs/2504.21027)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) holds promise for revolutionizing various fields traditionally dominated by human expertise. Urban planning, a professional discipline that fundamentally shapes our daily surroundings, is one such field heavily relying on multifaceted domain knowledge and experience of human experts. The extent to which LLMs can assist human practitioners in urban planning remains largely unexplored. In this paper, we introduce a comprehensive benchmark, UrbanPlanBench, tailored to evaluate the efficacy of LLMs in urban planning, which encompasses fundamental principles, professional knowledge, and management and regulations, aligning closely with the qualifications expected of human planners. Through extensive evaluation, we reveal a significant imbalance in the acquisition of planning knowledge among LLMs, with even the most proficient models falling short of meeting professional standards. For instance, we observe that 70% of LLMs achieve subpar performance in understanding planning regulations compared to other aspects. Besides the benchmark, we present the largest-ever supervised fine-tuning (SFT) dataset, UrbanPlanText, comprising over 30,000 instruction pairs sourced from urban planning exams and textbooks. Our findings demonstrate that fine-tuned models exhibit enhanced performance in memorization tests and comprehension of urban planning knowledge, while there exists significant room for improvement, particularly in tasks requiring domain-specific terminology and reasoning. By making our benchmark, dataset, and associated evaluation and fine-tuning toolsets publicly available at this https URL, we aim to catalyze the integration of LLMs into practical urban planning, fostering a symbiotic collaboration between human expertise and machine intelligence.</li>
</ul>

<h3>Title: Semantic-Aware Contrastive Fine-Tuning: Boosting Multimodal Malware Classification with Discriminative Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Ivan Montoya Sanchez, Shaswata Mitra, Aritran Piplai, Sudip Mittal</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21028">https://arxiv.org/abs/2504.21028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21028">https://arxiv.org/pdf/2504.21028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21028]] Semantic-Aware Contrastive Fine-Tuning: Boosting Multimodal Malware Classification with Discriminative Embeddings(https://arxiv.org/abs/2504.21028)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid evolution of malware variants requires robust classification methods to enhance cybersecurity. While Large Language Models (LLMs) offer potential for generating malware descriptions to aid family classification, their utility is limited by semantic embedding overlaps and misalignment with binary behavioral features. We propose a contrastive fine-tuning (CFT) method that refines LLM embeddings via targeted selection of hard negative samples based on cosine similarity, enabling LLMs to distinguish between closely related malware families. Our approach combines high-similarity negatives to enhance discriminative power and mid-tier negatives to increase embedding diversity, optimizing both precision and generalization. Evaluated on the CIC-AndMal-2020 and BODMAS datasets, our refined embeddings are integrated into a multimodal classifier within a Model-Agnostic Meta-Learning (MAML) framework on a few-shot setting. Experiments demonstrate significant improvements: our method achieves 63.15% classification accuracy with as few as 20 samples on CIC-AndMal-2020, outperforming baselines by 11--21 percentage points and surpassing prior negative sampling strategies. Ablation studies confirm the superiority of similarity-based selection over random sampling, with gains of 10-23%. Additionally, fine-tuned LLMs generate attribute-aware descriptions that generalize to unseen variants, bridging textual and binary feature gaps. This work advances malware classification by enabling nuanced semantic distinctions and provides a scalable framework for adapting LLMs to cybersecurity challenges.</li>
</ul>

<h3>Title: PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight</h3>
<ul>
<li><strong>Authors: </strong>Ben Goertzel, Paulos Yibelo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21029">https://arxiv.org/abs/2504.21029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21029">https://arxiv.org/pdf/2504.21029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21029]] PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight(https://arxiv.org/abs/2504.21029)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>We propose a robust transformer architecture designed to prevent prompt injection attacks and ensure secure, reliable response generation. Our PICO (Prompt Isolation and Cybersecurity Oversight) framework structurally separates trusted system instructions from untrusted user inputs through dual channels that are processed independently and merged only by a controlled, gated fusion mechanism. In addition, we integrate a specialized Security Expert Agent within a Mixture-of-Experts (MoE) framework and incorporate a Cybersecurity Knowledge Graph (CKG) to supply domain-specific reasoning. Our training design further ensures that the system prompt branch remains immutable while the rest of the network learns to handle adversarial inputs safely. This PICO framework is presented via a general mathematical formulation, then elaborated in terms of the specifics of transformer architecture, and fleshed out via hypothetical case studies including Policy Puppetry attacks. While the most effective implementation may involve training transformers in a PICO-based way from scratch, we also present a cost-effective fine-tuning approach.</li>
</ul>

<h3>Title: SAGA: A Security Architecture for Governing AI Agentic Systems</h3>
<ul>
<li><strong>Authors: </strong>Georgios Syros, Anshuman Suri, Cristina Nita-Rotaru, Alina Oprea</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21034">https://arxiv.org/abs/2504.21034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21034">https://arxiv.org/pdf/2504.21034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21034]] SAGA: A Security Architecture for Governing AI Agentic Systems(https://arxiv.org/abs/2504.21034)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM)-based agents increasingly interact, collaborate, and delegate tasks to one another autonomously with minimal human interaction. Industry guidelines for agentic system governance emphasize the need for users to maintain comprehensive control over their agents, mitigating potential damage from malicious agents. Several proposed agentic system designs address agent identity, authorization, and delegation, but remain purely theoretical, without concrete implementation and evaluation. Most importantly, they do not provide user-controlled agent management. To address this gap, we propose SAGA, a Security Architecture for Governing Agentic systems, that offers user oversight over their agents' lifecycle. In our design, users register their agents with a central entity, the Provider, that maintains agents contact information, user-defined access control policies, and helps agents enforce these policies on inter-agent communication. We introduce a cryptographic mechanism for deriving access control tokens, that offers fine-grained control over an agent's interaction with other agents, balancing security and performance consideration. We evaluate SAGA on several agentic tasks, using agents in different geolocations, and multiple on-device and cloud LLMs, demonstrating minimal performance overhead with no impact on underlying task utility in a wide range of conditions. Our architecture enables secure and trustworthy deployment of autonomous agents, accelerating the responsible adoption of this technology in sensitive environments.</li>
</ul>

<h3>Title: A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage</h3>
<ul>
<li><strong>Authors: </strong>Rui Xin, Niloofar Mireshghallah, Shuyue Stella Li, Michael Duan, Hyunwoo Kim, Yejin Choi, Yulia Tsvetkov, Sewoong Oh, Pang Wei Koh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21035">https://arxiv.org/abs/2504.21035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21035">https://arxiv.org/pdf/2504.21035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21035]] A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage(https://arxiv.org/abs/2504.21035)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>Sanitizing sensitive text data typically involves removing personally identifiable information (PII) or generating synthetic data under the assumption that these methods adequately protect privacy; however, their effectiveness is often only assessed by measuring the leakage of explicit identifiers but ignoring nuanced textual markers that can lead to re-identification. We challenge the above illusion of privacy by proposing a new framework that evaluates re-identification attacks to quantify individual privacy risks upon data release. Our approach shows that seemingly innocuous auxiliary information -- such as routine social activities -- can be used to infer sensitive attributes like age or substance use history from sanitized data. For instance, we demonstrate that Azure's commercial PII removal tool fails to protect 74\% of information in the MedQA dataset. Although differential privacy mitigates these risks to some extent, it significantly reduces the utility of the sanitized text for downstream tasks. Our findings indicate that current sanitization techniques offer a \textit{false sense of privacy}, highlighting the need for more robust methods that protect against semantic-level information leakage.</li>
</ul>

<h3>Title: Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?</h3>
<ul>
<li><strong>Authors: </strong>Hao Du, Shang Liu, Yang Cao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21036">https://arxiv.org/abs/2504.21036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21036">https://arxiv.org/pdf/2504.21036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21036]] Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?(https://arxiv.org/abs/2504.21036)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, extraction, membership infer, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) has become an essential strategy for adapting them to specialized tasks; however, this process introduces significant privacy challenges, as sensitive training data may be inadvertently memorized and exposed. Although differential privacy (DP) offers strong theoretical guarantees against such leakage, its empirical privacy effectiveness on LLMs remains unclear, especially under different fine-tuning methods. In this paper, we systematically investigate the impact of DP across fine-tuning methods and privacy budgets, using both data extraction and membership inference attacks to assess empirical privacy risks. Our main findings are as follows: (1) Differential privacy reduces model utility, but its impact varies significantly across different fine-tuning methods. (2) Without DP, the privacy risks of models fine-tuned with different approaches differ considerably. (3) When DP is applied, even a relatively high privacy budget can substantially lower privacy risk. (4) The privacy-utility trade-off under DP training differs greatly among fine-tuning methods, with some methods being unsuitable for DP due to severe utility degradation. Our results provide practical guidance for privacy-conscious deployment of LLMs and pave the way for future research on optimizing the privacy-utility trade-off in fine-tuning methodologies.</li>
</ul>

<h3>Title: Security Bug Report Prediction Within and Across Projects: A Comparative Study of BERT and Random Forest</h3>
<ul>
<li><strong>Authors: </strong>Farnaz Soltaniani, Mohammad Ghafari, Mohammed Sayagh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21037">https://arxiv.org/abs/2504.21037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21037">https://arxiv.org/pdf/2504.21037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21037]] Security Bug Report Prediction Within and Across Projects: A Comparative Study of BERT and Random Forest(https://arxiv.org/abs/2504.21037)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Early detection of security bug reports (SBRs) is crucial for preventing vulnerabilities and ensuring system reliability. While machine learning models have been developed for SBR prediction, their predictive performance still has room for improvement. In this study, we conduct a comprehensive comparison between BERT and Random Forest (RF), a competitive baseline for predicting SBRs. The results show that RF outperforms BERT with a 34% higher average G-measure for within-project predictions. Adding only SBRs from various projects improves both models' average performance. However, including both security and nonsecurity bug reports significantly reduces RF's average performance to 46%, while boosts BERT to its best average performance of 66%, surpassing RF. In cross-project SBR prediction, BERT achieves a remarkable 62% G-measure, which is substantially higher than RF.</li>
</ul>

<h3>Title: Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary</h3>
<ul>
<li><strong>Authors: </strong>Yakai Li, Jiekang Hu, Weiduan Sang, Luping Ma, Jing Xie, Weijuan Zhang, Aimin Yu, Shijie Zhao, Qingjia Huang, Qihang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21038">https://arxiv.org/abs/2504.21038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21038">https://arxiv.org/pdf/2504.21038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21038]] Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary(https://arxiv.org/abs/2504.21038)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are designed to generate helpful and safe content. However, adversarial attacks, commonly referred to as jailbreak, can bypass their safety protocols, prompting LLMs to generate harmful content or reveal sensitive data. Consequently, investigating jailbreak methodologies is crucial for exposing systemic vulnerabilities within LLMs, ultimately guiding the continuous implementation of security enhancements by developers. In this paper, we introduce a novel jailbreak attack method that leverages the prefilling feature of LLMs, a feature designed to enhance model output constraints. Unlike traditional jailbreak methods, the proposed attack circumvents LLMs' safety mechanisms by directly manipulating the probability distribution of subsequent tokens, thereby exerting control over the model's output. We propose two attack variants: Static Prefilling (SP), which employs a universal prefill text, and Optimized Prefilling (OP), which iteratively optimizes the prefill text to maximize the attack success rate. Experiments on six state-of-the-art LLMs using the AdvBench benchmark validate the effectiveness of our method and demonstrate its capability to substantially enhance attack success rates when combined with existing jailbreak approaches. The OP method achieved attack success rates of up to 99.82% on certain models, significantly outperforming baseline methods. This work introduces a new jailbreak attack method in LLMs, emphasizing the need for robust content validation mechanisms to mitigate the adversarial exploitation of prefilling features. All code and data used in this paper are publicly available.</li>
</ul>

<h3>Title: Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Paul Kassianik, Baturay Saglam, Alexander Chen, Blaine Nelson, Anu Vellore, Massimo Aufiero, Fraser Burch, Dhruv Kedia, Avi Zohary, Sajana Weerawardhena, Aman Priyanshu, Adam Swanda, Amy Chang, Hyrum Anderson, Kojin Oshiba, Omar Santos, Yaron Singer, Amin Karbasi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21039">https://arxiv.org/abs/2504.21039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21039">https://arxiv.org/pdf/2504.21039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21039]] Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report(https://arxiv.org/abs/2504.21039)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer, large language model</a></li>
<li><strong>Abstract: </strong>As transformer-based large language models (LLMs) increasingly permeate society, they have revolutionized domains such as software engineering, creative writing, and digital arts. However, their adoption in cybersecurity remains limited due to challenges like scarcity of specialized training data and complexity of representing cybersecurity-specific knowledge. To address these gaps, we present Foundation-Sec-8B, a cybersecurity-focused LLM built on the Llama 3.1 architecture and enhanced through continued pretraining on a carefully curated cybersecurity corpus. We evaluate Foundation-Sec-8B across both established and new cybersecurity benchmarks, showing that it matches Llama 3.1-70B and GPT-4o-mini in certain cybersecurity-specific tasks. By releasing our model to the public, we aim to accelerate progress and adoption of AI-driven tools in both public and private cybersecurity contexts.</li>
</ul>

<h3>Title: Can a Large Language Model Assess Urban Design Quality? Evaluating Walkability Metrics Across Expertise Levels</h3>
<ul>
<li><strong>Authors: </strong>Chenyi Cai, Kosuke Kuriyama, Youlong Gu, Filip Biljecki, Pieter Herthogs</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21040">https://arxiv.org/abs/2504.21040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21040">https://arxiv.org/pdf/2504.21040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21040]] Can a Large Language Model Assess Urban Design Quality? Evaluating Walkability Metrics Across Expertise Levels(https://arxiv.org/abs/2504.21040)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Urban street environments are vital to supporting human activity in public spaces. The emergence of big data, such as street view images (SVIs) combined with multimodal large language models (MLLMs), is transforming how researchers and practitioners investigate, measure, and evaluate semantic and visual elements of urban environments. Considering the low threshold for creating automated evaluative workflows using MLLMs, it is crucial to explore both the risks and opportunities associated with these probabilistic models. In particular, the extent to which the integration of expert knowledge can influence the performance of MLLMs in evaluating the quality of urban design has not been fully explored. This study sets out an initial exploration of how integrating more formal and structured representations of expert urban design knowledge into the input prompts of an MLLM (ChatGPT-4) can enhance the model's capability and reliability in evaluating the walkability of built environments using SVIs. We collect walkability metrics from the existing literature and categorize them using relevant ontologies. We then select a subset of these metrics, focusing on the subthemes of pedestrian safety and attractiveness, and develop prompts for the MLLM accordingly. We analyze the MLLM's ability to evaluate SVI walkability subthemes through prompts with varying levels of clarity and specificity regarding evaluation criteria. Our experiments demonstrate that MLLMs are capable of providing assessments and interpretations based on general knowledge and can support the automation of multimodal image-text evaluations. However, they generally provide more optimistic scores and can make mistakes when interpreting the provided metrics, resulting in incorrect evaluations. By integrating expert knowledge, the MLLM's evaluative performance exhibits higher consistency and concentration.</li>
</ul>

<h3>Title: Fast and Robust Speckle Pattern Authentication by Scale Invariant Feature Transform algorithm in Physical Unclonable Functions</h3>
<ul>
<li><strong>Authors: </strong>Giuseppe Emanuele Lio, Mauro Daniel Luigi Bruno, Francesco Riboli, Sara Nocentini, Antonio Ferraro</a></li>
<li><strong>Subjects: </strong>cs.CR, physics.app-ph, physics.optics</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21041">https://arxiv.org/abs/2504.21041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21041">https://arxiv.org/pdf/2504.21041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21041]] Fast and Robust Speckle Pattern Authentication by Scale Invariant Feature Transform algorithm in Physical Unclonable Functions(https://arxiv.org/abs/2504.21041)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction</a></li>
<li><strong>Abstract: </strong>Nowadays, due to the growing phenomenon of forgery in many fields, the interest in developing new anti-counterfeiting device and cryptography keys, based on the Physical Unclonable Functions (PUFs) paradigm, is widely increased. PUFs are physical hardware with an intrinsic, irreproducible disorder that allows for on-demand cryptographic key extraction. Among them, optical PUF are characterized by a large number of degrees of freedom resulting in higher security and higher sensitivity to environmental conditions. While these promising features led to the growth of advanced fabrication strategies and materials for new PUF devices, their combination with robust recognition algorithm remains largely unexplored. In this work, we present a metric-independent authentication approach that leverages the Scale Invariant Feature Transform (SIFT) algorithm to extract unique and invariant features from the speckle patterns generated by optical Physical Unclonable Functions (PUFs). The application of SIFT to the challenge response pairs (CRPs) protocol allows us to correctly authenticate a client while denying any other fraudulent access. In this way, the authentication process is highly reliable even in presence of response rotation, zooming, and cropping that may occur in consecutive PUF interrogations and to which other postprocessing algorithm are highly sensitive. This characteristics together with the speed of the method (tens of microseconds for each operation) broaden the applicability and reliability of PUF to practical high-security authentication or merchandise anti-counterfeiting.</li>
</ul>

<h3>Title: What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift</h3>
<ul>
<li><strong>Authors: </strong>Jiamin Chang, Haoyang Li, Hammond Pearce, Ruoxi Sun, Bo Li, Minhui Xue</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21042">https://arxiv.org/abs/2504.21042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21042">https://arxiv.org/pdf/2504.21042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21042]] What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift(https://arxiv.org/abs/2504.21042)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>The growing adoption of artificial intelligence (AI) has amplified concerns about trustworthiness, including integrity, privacy, robustness, and bias. To assess and attribute these threats, we propose ConceptLens, a generic framework that leverages pre-trained multimodal models to identify the root causes of integrity threats by analyzing Concept Shift in probing samples. ConceptLens demonstrates strong detection performance for vanilla data poisoning attacks and uncovers vulnerabilities to bias injection, such as the generation of covert advertisements through malicious concept shifts. It identifies privacy risks in unaltered but high-risk samples, filters them before training, and provides insights into model weaknesses arising from incomplete or imbalanced training data. Additionally, at the model level, it attributes concepts that the target model is overly dependent on, identifies misleading concepts, and explains how disrupting key concepts negatively impacts the model. Furthermore, it uncovers sociological biases in generative content, revealing disparities across sociological contexts. Strikingly, ConceptLens reveals how safe training and inference data can be unintentionally and easily exploited, potentially undermining safety alignment. Our study informs actionable insights to breed trust in AI systems, thereby speeding adoption and driving greater innovation.</li>
</ul>

<h3>Title: CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Lingxiang wang, Hainan Zhang, Qinnan Zhang, Ziwei Wang, Hongwei Zheng, Jin Dong, Zhiming Zheng</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21043">https://arxiv.org/abs/2504.21043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21043">https://arxiv.org/pdf/2504.21043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21043]] CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain(https://arxiv.org/abs/2504.21043)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel at generating code from natural language instructions, yet they often lack an understanding of security vulnerabilities. This limitation makes it difficult for LLMs to avoid security risks in generated code, particularly in high-security programming tasks such as smart contract development for blockchain. Researchers have attempted to enhance the vulnerability awareness of these models by training them to differentiate between vulnerable and fixed code snippets. However, this approach relies heavily on manually labeled vulnerability data, which is only available for popular languages like Python and C++. For low-resource languages like Solidity, used in smart contracts, large-scale annotated datasets are scarce and difficult to obtain. To address this challenge, we introduce CodeBC, a code generation model specifically designed for generating secure smart contracts in blockchain. CodeBC employs a three-stage fine-tuning approach based on CodeLlama, distinguishing itself from previous methods by not relying on pairwise vulnerability location annotations. Instead, it leverages vulnerability and security tags to teach the model the differences between vulnerable and secure code. During the inference phase, the model leverages security tags to generate secure and robust code. Experimental results demonstrate that CodeBC outperforms baseline models in terms of BLEU, CodeBLEU, and compilation pass rates, while significantly reducing vulnerability rates. These findings validate the effectiveness and cost-efficiency of our three-stage fine-tuning strategy, making CodeBC a promising solution for generating secure smart contract code.</li>
</ul>

<h3>Title: AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection</h3>
<ul>
<li><strong>Authors: </strong>Jianbo Gao, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21044">https://arxiv.org/abs/2504.21044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21044">https://arxiv.org/pdf/2504.21044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21044]] AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection(https://arxiv.org/abs/2504.21044)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, steal, watermark</a></li>
<li><strong>Abstract: </strong>Recent advancement in large-scale Artificial Intelligence (AI) models offering multimodal services have become foundational in AI systems, making them prime targets for model theft. Existing methods select Out-of-Distribution (OoD) data as backdoor watermarks and retrain the original model for copyright protection. However, existing methods are susceptible to malicious detection and forgery by adversaries, resulting in watermark evasion. In this work, we propose Model-\underline{ag}nostic Black-box Backdoor W\underline{ate}rmarking Framework (AGATE) to address stealthiness and robustness challenges in multimodal model copyright protection. Specifically, we propose an adversarial trigger generation method to generate stealthy adversarial triggers from ordinary dataset, providing visual fidelity while inducing semantic shifts. To alleviate the issue of anomaly detection among model outputs, we propose a post-transform module to correct the model output by narrowing the distance between adversarial trigger image embedding and text embedding. Subsequently, a two-phase watermark verification is proposed to judge whether the current model infringes by comparing the two results with and without the transform module. Consequently, we consistently outperform state-of-the-art methods across five datasets in the downstream tasks of multimodal image-text retrieval and image classification. Additionally, we validated the robustness of AGATE under two adversarial attack scenarios.</li>
</ul>

<h3>Title: Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection</h3>
<ul>
<li><strong>Authors: </strong>Dennis Miczek, Divyesh Gabbireddy, Suman Saha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21045">https://arxiv.org/abs/2504.21045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21045">https://arxiv.org/pdf/2504.21045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21045]] Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection(https://arxiv.org/abs/2504.21045)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, large language model</a></li>
<li><strong>Abstract: </strong>According to the Open Web Application Security Project (OWASP), Cross-Site Scripting (XSS) is a critical security vulnerability. Despite decades of research, XSS remains among the top 10 security vulnerabilities. Researchers have proposed various techniques to protect systems from XSS attacks, with machine learning (ML) being one of the most widely used methods. An ML model is trained on a dataset to identify potential XSS threats, making its effectiveness highly dependent on the size and diversity of the training data. A variation of XSS is obfuscated XSS, where attackers apply obfuscation techniques to alter the code's structure, making it challenging for security systems to detect its malicious intent. Our study's random forest model was trained on traditional (non-obfuscated) XSS data achieved 99.8% accuracy. However, when tested against obfuscated XSS samples, accuracy dropped to 81.9%, underscoring the importance of training ML models with obfuscated data to improve their effectiveness in detecting XSS attacks. A significant challenge is to generate highly complex obfuscated code despite the availability of several public tools. These tools can only produce obfuscation up to certain levels of complexity. In our proposed system, we fine-tune a Large Language Model (LLM) to generate complex obfuscated XSS payloads automatically. By transforming original XSS samples into diverse obfuscated variants, we create challenging training data for ML model evaluation. Our approach achieved a 99.5% accuracy rate with the obfuscated dataset. We also found that the obfuscated samples generated by the LLMs were 28.1% more complex than those created by other tools, significantly improving the model's ability to handle advanced XSS attacks and making it more effective for real-world application security.</li>
</ul>

<h3>Title: Phishing URL Detection using Bi-LSTM</h3>
<ul>
<li><strong>Authors: </strong>Sneha Baskota</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21049">https://arxiv.org/abs/2504.21049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21049">https://arxiv.org/pdf/2504.21049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21049]] Phishing URL Detection using Bi-LSTM(https://arxiv.org/abs/2504.21049)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Phishing attacks threaten online users, often leading to data breaches, financial losses, and identity theft. Traditional phishing detection systems struggle with high false positive rates and are usually limited by the types of attacks they can identify. This paper proposes a deep learning-based approach using a Bidirectional Long Short-Term Memory (Bi-LSTM) network to classify URLs into four categories: benign, phishing, defacement, and malware. The model leverages sequential URL data and captures contextual information, improving the accuracy of phishing detection. Experimental results on a dataset comprising over 650,000 URLs demonstrate the model's effectiveness, achieving 97% accuracy and significant improvements over traditional techniques.</li>
</ul>

<h3>Title: Multimodal Large Language Models for Medicine: A Comprehensive Survey</h3>
<ul>
<li><strong>Authors: </strong>Jiarui Ye, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21051">https://arxiv.org/abs/2504.21051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21051">https://arxiv.org/pdf/2504.21051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21051]] Multimodal Large Language Models for Medicine: A Comprehensive Survey(https://arxiv.org/abs/2504.21051)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>MLLMs have recently become a focal point in the field of artificial intelligence research. Building on the strong capabilities of LLMs, MLLMs are adept at addressing complex multi-modal tasks. With the release of GPT-4, MLLMs have gained substantial attention from different domains. Researchers have begun to explore the potential of MLLMs in the medical and healthcare domain. In this paper, we first introduce the background and fundamental concepts related to LLMs and MLLMs, while emphasizing the working principles of MLLMs. Subsequently, we summarize three main directions of application within healthcare: medical reporting, medical diagnosis, and medical treatment. Our findings are based on a comprehensive review of 330 recent papers in this area. We illustrate the remarkable capabilities of MLLMs in these domains by providing specific examples. For data, we present six mainstream modes of data along with their corresponding evaluation benchmarks. At the end of the survey, we discuss the challenges faced by MLLMs in the medical and healthcare domain and propose feasible methods to mitigate or overcome these issues.</li>
</ul>

<h3>Title: SFIBA: Spatial-based Full-target Invisible Backdoor Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yangxu Yin, Honglong Chen, Yudong Gao, Peng Sun, Zhishuai Li, Weifeng Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21052">https://arxiv.org/abs/2504.21052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21052">https://arxiv.org/pdf/2504.21052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21052]] SFIBA: Spatial-based Full-target Invisible Backdoor Attacks(https://arxiv.org/abs/2504.21052)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, steal</a></li>
<li><strong>Abstract: </strong>Multi-target backdoor attacks pose significant security threats to deep neural networks, as they can preset multiple target classes through a single backdoor injection. This allows attackers to control the model to misclassify poisoned samples with triggers into any desired target class during inference, exhibiting superior attack performance compared with conventional backdoor attacks. However, existing multi-target backdoor attacks fail to guarantee trigger specificity and stealthiness in black-box settings, resulting in two main issues. First, they are unable to simultaneously target all classes when only training data can be manipulated, limiting their effectiveness in realistic attack scenarios. Second, the triggers often lack visual imperceptibility, making poisoned samples easy to detect. To address these problems, we propose a Spatial-based Full-target Invisible Backdoor Attack, called SFIBA. It restricts triggers for different classes to specific local spatial regions and morphologies in the pixel space to ensure specificity, while employing a frequency-domain-based trigger injection method to guarantee stealthiness. Specifically, for injection of each trigger, we first apply fast fourier transform to obtain the amplitude spectrum of clean samples in local spatial regions. Then, we employ discrete wavelet transform to extract the features from the amplitude spectrum and use singular value decomposition to integrate the trigger. Subsequently, we selectively filter parts of the trigger in pixel space to implement trigger morphology constraints and adjust injection coefficients based on visual effects. We conduct experiments on multiple datasets and models. The results demonstrate that SFIBA can achieve excellent attack performance and stealthiness, while preserving the model's performance on benign samples, and can also bypass existing backdoor defenses.</li>
</ul>

<h3>Title: NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yi Zhou, Wenpeng Xing, Dezhang Kong, Changting Lin, Meng Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21053">https://arxiv.org/abs/2504.21053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21053">https://arxiv.org/pdf/2504.21053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21053]] NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models(https://arxiv.org/abs/2504.21053)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Safety alignment in large language models (LLMs) is achieved through fine-tuning mechanisms that regulate neuron activations to suppress harmful content. In this work, we propose a novel approach to induce disalignment by identifying and modifying the neurons responsible for safety constraints. Our method consists of three key steps: Neuron Activation Analysis, where we examine activation patterns in response to harmful and harmless prompts to detect neurons that are critical for distinguishing between harmful and harmless inputs; Similarity-Based Neuron Identification, which systematically locates the neurons responsible for safe alignment; and Neuron Relearning for Safety Removal, where we fine-tune these selected neurons to restore the model's ability to generate previously restricted responses. Experimental results demonstrate that our method effectively removes safety constraints with minimal fine-tuning, highlighting a critical vulnerability in current alignment techniques. Our findings underscore the need for robust defenses against adversarial fine-tuning attacks on LLMs.</li>
</ul>

<h3>Title: FFCBA: Feature-based Full-target Clean-label Backdoor Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yangxu Yin, Honglong Chen, Yudong Gao, Peng Sun, Liantao Wu, Zhe Li, Weifeng Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21054">https://arxiv.org/abs/2504.21054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21054">https://arxiv.org/pdf/2504.21054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21054]] FFCBA: Feature-based Full-target Clean-label Backdoor Attacks(https://arxiv.org/abs/2504.21054)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Backdoor attacks pose a significant threat to deep neural networks, as backdoored models would misclassify poisoned samples with specific triggers into target classes while maintaining normal performance on clean samples. Among these, multi-target backdoor attacks can simultaneously target multiple classes. However, existing multi-target backdoor attacks all follow the dirty-label paradigm, where poisoned samples are mislabeled, and most of them require an extremely high poisoning rate. This makes them easily detectable by manual inspection. In contrast, clean-label attacks are more stealthy, as they avoid modifying the labels of poisoned samples. However, they generally struggle to achieve stable and satisfactory attack performance and often fail to scale effectively to multi-target attacks. To address this issue, we propose the Feature-based Full-target Clean-label Backdoor Attacks (FFCBA) which consists of two paradigms: Feature-Spanning Backdoor Attacks (FSBA) and Feature-Migrating Backdoor Attacks (FMBA). FSBA leverages class-conditional autoencoders to generate noise triggers that align perturbed in-class samples with the original category's features, ensuring the effectiveness, intra-class consistency, inter-class specificity and natural-feature correlation of triggers. While FSBA supports swift and efficient attacks, its cross-model attack capability is relatively weak. FMBA employs a two-stage class-conditional autoencoder training process that alternates between using out-of-class samples and in-class samples. This allows FMBA to generate triggers with strong target-class features, making it highly effective for cross-model attacks. We conduct experiments on multiple datasets and models, the results show that FFCBA achieves outstanding attack performance and maintains desirable robustness against the state-of-the-art backdoor defenses.</li>
</ul>

<h3>Title: Modeling and Performance Analysis for Semantic Communications Based on Empirical Results</h3>
<ul>
<li><strong>Authors: </strong>Shuai Ma, Bin Shen, Chuanhui Zhang, Youlong Wu, Hang Li, Shiyin Li, Guangming Shi, Naofal Al-Dhahir</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21055">https://arxiv.org/abs/2504.21055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21055">https://arxiv.org/pdf/2504.21055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21055]] Modeling and Performance Analysis for Semantic Communications Based on Empirical Results(https://arxiv.org/abs/2504.21055)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Due to the black-box characteristics of deep learning based semantic encoders and decoders, finding a tractable method for the performance analysis of semantic communications is a challenging problem. In this paper, we propose an Alpha-Beta-Gamma (ABG) formula to model the relationship between the end-to-end measurement and SNR, which can be applied for both image reconstruction tasks and inference tasks. Specifically, for image reconstruction tasks, the proposed ABG formula can well fit the commonly used DL networks, such as SCUNet, and Vision Transformer, for semantic encoding with the multi scale-structural similarity index measure (MS-SSIM) measurement. Furthermore, we find that the upper bound of the MS-SSIM depends on the number of quantized output bits of semantic encoders, and we also propose a closed-form expression to fit the relationship between the MS-SSIM and quantized output bits. To the best of our knowledge, this is the first theoretical expression between end-to-end performance metrics and SNR for semantic communications. Based on the proposed ABG formula, we investigate an adaptive power control scheme for semantic communications over random fading channels, which can effectively guarantee quality of service (QoS) for semantic communications, and then design the optimal power allocation scheme to maximize the energy efficiency of the semantic communication system. Furthermore, by exploiting the bisection algorithm, we develop the power allocation scheme to maximize the minimum QoS of multiple users for OFDMA downlink semantic communication Extensive simulations verify the effectiveness and superiority of the proposed ABG formula and power allocation schemes.</li>
</ul>

<h3>Title: A Hamiltonian Higher-Order Elasticity Framework for Dynamic Diagnostics(2HOED)</h3>
<ul>
<li><strong>Authors: </strong>Ngueuleweu Tiwang Gildas</a></li>
<li><strong>Subjects: </strong>cs.LG, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21062">https://arxiv.org/abs/2504.21062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21062">https://arxiv.org/pdf/2504.21062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21062]] A Hamiltonian Higher-Order Elasticity Framework for Dynamic Diagnostics(2HOED)(https://arxiv.org/abs/2504.21062)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust</a></li>
<li><strong>Abstract: </strong>Machine learning detects patterns, block chain guarantees trust and immutability, and modern causal inference identifies directional linkages, yet none alone exposes the full energetic anatomy of complex systems; the Hamiltonian Higher Order Elasticity Dynamics(2HOED) framework bridges these gaps. Grounded in classical mechanics but extended to Economics order elasticity terms, 2HOED represents economic, social, and physical systems as energy-based Hamiltonians whose position, velocity, acceleration, and jerk of elasticity jointly determine systemic power, Inertia, policy sensitivity, and marginal responses. Because the formalism is scaling free and coordinate agnostic, it transfers seamlessly from financial markets to climate science, from supply chain logistics to epidemiology, thus any discipline in which adaptation and shocks coexist. By embedding standard econometric variables inside a Hamiltonian, 2HOED enriches conventional economic analysis with rigorous diagnostics of resilience, tipping points, and feedback loops, revealing failure modes invisible to linear models. Wavelet spectra, phase space attractors, and topological persistence diagrams derived from 2HOED expose multistage policy leverage that machine learning detects only empirically and block chain secures only after the fact. For economists, physicians and other scientists, the method opens a new causal energetic channel linking biological or mechanical elasticity to macro level outcomes. Portable, interpretable, and computationally light, 2HOED turns data streams into dynamical energy maps, empowering decision makers to anticipate crises, design adaptive policies, and engineer robust systems delivering the predictive punch of AI with the explanatory clarity of physics.</li>
</ul>

<h3>Title: Token-Level Prompt Mixture with Parameter-Free Routing for Federated Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>Shuai Gong, Chaoran Cui, Xiaolin Dong, Xiushan Nie, Lei Zhu, Xiaojun Chang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21063">https://arxiv.org/abs/2504.21063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21063">https://arxiv.org/pdf/2504.21063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21063]] Token-Level Prompt Mixture with Parameter-Free Routing for Federated Domain Generalization(https://arxiv.org/abs/2504.21063)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated domain generalization (FedDG) aims to learn a globally generalizable model from decentralized clients with heterogeneous data while preserving privacy. Recent studies have introduced prompt learning to adapt vision-language models (VLMs) in FedDG by learning a single global prompt. However, such a one-prompt-fits-all learning paradigm typically leads to performance degradation on personalized samples. Although the mixture of experts (MoE) offers a promising solution for specialization, existing MoE-based methods suffer from coarse image-level expert assignment and high communication costs from parameterized routers. To address these limitations, we propose TRIP, a Token-level prompt mixture with parameter-free routing framework for FedDG, which treats multiple prompts as distinct experts. Unlike existing image-level routing designs, TRIP assigns different tokens within an image to specific experts. To ensure communication efficiency, TRIP incorporates a parameter-free routing mechanism based on token clustering and optimal transport. The instance-specific prompt is then synthesized by aggregating experts, weighted by the number of tokens assigned to each. Additionally, TRIP develops an unbiased learning strategy for prompt experts, leveraging the VLM's zero-shot generalization capability. Extensive experiments across four benchmarks demonstrate that TRIP achieves optimal generalization results, with communication of only 1K parameters per round. Our code is available at this https URL.</li>
</ul>

<h3>Title: Frequency Feature Fusion Graph Network For Depression Diagnosis Via fNIRS</h3>
<ul>
<li><strong>Authors: </strong>Chengkai Yang, Xingping Dong, Xiaofen Zong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21064">https://arxiv.org/abs/2504.21064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21064">https://arxiv.org/pdf/2504.21064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21064]] Frequency Feature Fusion Graph Network For Depression Diagnosis Via fNIRS(https://arxiv.org/abs/2504.21064)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Data-driven approaches for depression diagnosis have emerged as a significant research focus in neuromedicine, driven by the development of relevant datasets. Recently, graph neural network (GNN)-based models have gained widespread adoption due to their ability to capture brain channel functional connectivity from both spatial and temporal perspectives. However, their effectiveness is hindered by the absence of a robust temporal biomarker. In this paper, we introduce a novel and effective biomarker for depression diagnosis by leveraging the discrete Fourier transform (DFT) and propose a customized graph network architecture based on Temporal Graph Convolutional Network (TGCN). Our model was trained on a dataset comprising 1,086 subjects, which is over 10 times larger than previous datasets in the field of depression diagnosis. Furthermore, to align with medical requirements, we performed propensity score matching (PSM) to create a refined subset, referred to as the PSM dataset. Experimental results demonstrate that incorporating our newly designed biomarker enhances the representation of temporal characteristics in brain channels, leading to improved F1 scores in both the real-world dataset and the PSM dataset. This advancement has the potential to contribute to the development of more effective depression diagnostic tools. In addition, we used SHapley Additive exPlaination (SHAP) to validate the interpretability of our model, ensuring its practical applicability in medical settings.</li>
</ul>

<h3>Title: A 3D pocket-aware and affinity-guided diffusion model for lead optimization</h3>
<ul>
<li><strong>Authors: </strong>Anjie Qiao, Junjie Xie, Weifeng Huang, Hao Zhang, Jiahua Rao, Shuangjia Zheng, Yuedong Yang, Zhen Wang, Guo-Bo Li, Jinping Lei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21065">https://arxiv.org/abs/2504.21065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21065">https://arxiv.org/pdf/2504.21065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21065]] A 3D pocket-aware and affinity-guided diffusion model for lead optimization(https://arxiv.org/abs/2504.21065)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Molecular optimization, aimed at improving binding affinity or other molecular properties, is a crucial task in drug discovery that often relies on the expertise of medicinal chemists. Recently, deep learning-based 3D generative models showed promise in enhancing the efficiency of molecular optimization. However, these models often struggle to adequately consider binding affinities with protein targets during lead optimization. Herein, we propose a 3D pocket-aware and affinity-guided diffusion model, named Diffleop, to optimize molecules with enhanced binding affinity. The model explicitly incorporates the knowledge of protein-ligand binding affinity to guide the denoising sampling for molecule generation with high affinity. The comprehensive evaluations indicated that Diffleop outperforms baseline models across multiple metrics, especially in terms of binding affinity.</li>
</ul>

<h3>Title: A Brief Review for Compression and Transfer Learning Techniques in DeepFake Detection</h3>
<ul>
<li><strong>Authors: </strong>Andreas Karathanasis, John Violos, Ioannis Kompatsiaris, Symeon Papadopoulos</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21066">https://arxiv.org/abs/2504.21066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21066">https://arxiv.org/pdf/2504.21066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21066]] A Brief Review for Compression and Transfer Learning Techniques in DeepFake Detection(https://arxiv.org/abs/2504.21066)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Training and deploying deepfake detection models on edge devices offers the advantage of maintaining data privacy and confidentiality by processing it close to its source. However, this approach is constrained by the limited computational and memory resources available at the edge. To address this challenge, we explore compression techniques to reduce computational demands and inference time, alongside transfer learning methods to minimize training overhead. Using the Synthbuster, RAISE, and ForenSynths datasets, we evaluate the effectiveness of pruning, knowledge distillation (KD), quantization, fine-tuning, and adapter-based techniques. Our experimental results demonstrate that both compression and transfer learning can be effectively achieved, even with a high compression level of 90%, remaining at the same performance level when the training and validation data originate from the same DeepFake model. However, when the testing dataset is generated by DeepFake models not present in the training set, a domain generalization issue becomes evident.</li>
</ul>

<h3>Title: R^2VFL: A Robust Random Vector Functional Link Network with Huber-Weighted Framework</h3>
<ul>
<li><strong>Authors: </strong>Anuradha Kumari, Mushir Akhtar, P. N. Suganthan, M. Tanveer</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21069">https://arxiv.org/abs/2504.21069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21069">https://arxiv.org/pdf/2504.21069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21069]] R^2VFL: A Robust Random Vector Functional Link Network with Huber-Weighted Framework(https://arxiv.org/abs/2504.21069)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The random vector functional link (RVFL) neural network has shown significant potential in overcoming the constraints of traditional artificial neural networks, such as excessive computation time and suboptimal solutions. However, RVFL faces challenges when dealing with noise and outliers, as it assumes all data samples contribute equally. To address this issue, we propose a novel robust framework, R2VFL, RVFL with Huber weighting function and class probability, which enhances the model's robustness and adaptability by effectively mitigating the impact of noise and outliers in the training data. The Huber weighting function reduces the influence of outliers, while the class probability mechanism assigns less weight to noisy data points, resulting in a more resilient model. We explore two distinct approaches for calculating class centers within the R2VFL framework: the simple average of all data points in each class and the median of each feature, the later providing a robust alternative by minimizing the effect of extreme values. These approaches give rise to two novel variants of the model-R2VFL-A and R2VFL-M. We extensively evaluate the proposed models on 47 UCI datasets, encompassing both binary and multiclass datasets, and conduct rigorous statistical testing, which confirms the superiority of the proposed models. Notably, the models also demonstrate exceptional performance in classifying EEG signals, highlighting their practical applicability in real-world biomedical domain.</li>
</ul>

<h3>Title: Erased but Not Forgotten: How Backdoors Compromise Concept Erasure</h3>
<ul>
<li><strong>Authors: </strong>Jonas Henry Grebe, Tobias Braun, Marcus Rohrbach, Anna Rohrbach</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21072">https://arxiv.org/abs/2504.21072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21072">https://arxiv.org/pdf/2504.21072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21072]] Erased but Not Forgotten: How Backdoors Compromise Concept Erasure(https://arxiv.org/abs/2504.21072)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>The expansion of large-scale text-to-image diffusion models has raised growing concerns about their potential to generate undesirable or harmful content, ranging from fabricated depictions of public figures to sexually explicit images. To mitigate these risks, prior work has devised machine unlearning techniques that attempt to erase unwanted concepts through fine-tuning. However, in this paper, we introduce a new threat model, Toxic Erasure (ToxE), and demonstrate how recent unlearning algorithms, including those explicitly designed for robustness, can be circumvented through targeted backdoor attacks. The threat is realized by establishing a link between a trigger and the undesired content. Subsequent unlearning attempts fail to erase this link, allowing adversaries to produce harmful content. We instantiate ToxE via two established backdoor attacks: one targeting the text encoder and another manipulating the cross-attention layers. Further, we introduce Deep Intervention Score-based Attack (DISA), a novel, deeper backdoor attack that optimizes the entire U-Net using a score-based objective, improving the attack's persistence across different erasure methods. We evaluate five recent concept erasure methods against our threat model. For celebrity identity erasure, our deep attack circumvents erasure with up to 82% success, averaging 57% across all erasure methods. For explicit content erasure, ToxE attacks can elicit up to 9 times more exposed body parts, with DISA yielding an average increase by a factor of 2.9. These results highlight a critical security gap in current unlearning strategies.</li>
</ul>

<h3>Title: A Survey on Parameter-Efficient Fine-Tuning for Foundation Models in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Jieming Bian, Yuanzhe Peng, Lei Wang, Yin Huang, Jie Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21099">https://arxiv.org/abs/2504.21099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21099">https://arxiv.org/pdf/2504.21099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21099]] A Survey on Parameter-Efficient Fine-Tuning for Foundation Models in Federated Learning(https://arxiv.org/abs/2504.21099)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Foundation models have revolutionized artificial intelligence by providing robust, versatile architectures pre-trained on large-scale datasets. However, adapting these massive models to specific downstream tasks requires fine-tuning, which can be prohibitively expensive in computational resources. Parameter-Efficient Fine-Tuning (PEFT) methods address this challenge by selectively updating only a small subset of parameters. Meanwhile, Federated Learning (FL) enables collaborative model training across distributed clients without sharing raw data, making it ideal for privacy-sensitive applications. This survey provides a comprehensive review of the integration of PEFT techniques within federated learning environments. We systematically categorize existing approaches into three main groups: Additive PEFT (which introduces new trainable parameters), Selective PEFT (which fine-tunes only subsets of existing parameters), and Reparameterized PEFT (which transforms model architectures to enable efficient updates). For each category, we analyze how these methods address the unique challenges of federated settings, including data heterogeneity, communication efficiency, computational constraints, and privacy concerns. We further organize the literature based on application domains, covering both natural language processing and computer vision tasks. Finally, we discuss promising research directions, including scaling to larger foundation models, theoretical analysis of federated PEFT methods, and sustainable approaches for resource-constrained environments.</li>
</ul>

<h3>Title: Beyond One-Size-Fits-All: Inversion Learning for Highly Effective NLG Evaluation Prompts</h3>
<ul>
<li><strong>Authors: </strong>Hanhua Hong, Chenghao Xiao, Yang Wang, Yiqi Liu, Wenge Rong, Chenghua Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21117">https://arxiv.org/abs/2504.21117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21117">https://arxiv.org/pdf/2504.21117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21117]] Beyond One-Size-Fits-All: Inversion Learning for Highly Effective NLG Evaluation Prompts(https://arxiv.org/abs/2504.21117)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Evaluating natural language generation (NLG) systems is challenging due to the diversity of valid outputs. While human evaluation is the gold standard, it suffers from inconsistencies, lack of standardisation, and demographic biases, limiting reproducibility. LLM-based evaluation offers a scalable alternative but is highly sensitive to prompt design, where small variations can lead to significant discrepancies. In this work, we propose an inversion learning method that learns effective reverse mappings from model outputs back to their input instructions, enabling the automatic generation of highly effective, model-specific evaluation prompts. Our method requires only a single evaluation sample and eliminates the need for time-consuming manual prompt engineering, thereby improving both efficiency and robustness. Our work contributes toward a new direction for more robust and efficient LLM-based evaluation.</li>
</ul>

<h3>Title: LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Naheed Rayhan, Md. Ashrafuzzaman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21132">https://arxiv.org/abs/2504.21132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21132">https://arxiv.org/pdf/2504.21132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21132]] LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge(https://arxiv.org/abs/2504.21132)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), such as ChatGPT, have demonstrated the capability to generate human like, natural responses across a range of tasks, including task oriented dialogue and question answering. However, their application in real world, critical scenarios is often hindered by a tendency to produce inaccurate information and a limited ability to leverage external knowledge sources. This paper introduces the LLM ENHANCER system, designed to integrate multiple online sources such as Google, Wikipedia, and DuckDuckGo to enhance data accuracy. The LLMs employed within this system are open source. The data acquisition process for the LLM ENHANCER system operates in parallel, utilizing custom agent tools to manage the flow of information. Vector embeddings are used to identify the most pertinent information, which is subsequently supplied to the LLM for user interaction. The LLM ENHANCER system mitigates hallucinations in chat based LLMs while preserving response naturalness and accuracy.</li>
</ul>

<h3>Title: Emotion Recognition in Contemporary Dance Performances Using Laban Movement Analysis</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Turab, Philippe Colantoni, Damien Muselet, Alain Tremeau</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21154">https://arxiv.org/abs/2504.21154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21154">https://arxiv.org/pdf/2504.21154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21154]] Emotion Recognition in Contemporary Dance Performances Using Laban Movement Analysis(https://arxiv.org/abs/2504.21154)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a novel framework for emotion recognition in contemporary dance by improving existing Laban Movement Analysis (LMA) feature descriptors and introducing robust, novel descriptors that capture both quantitative and qualitative aspects of the movement. Our approach extracts expressive characteristics from 3D keypoints data of professional dancers performing contemporary dance under various emotional states, and trains multiple classifiers, including Random Forests and Support Vector Machines. Additionally, we provide in-depth explanation of features and their impact on model predictions using explainable machine learning methods. Overall, our study improves emotion recognition in contemporary dance and offers promising applications in performance analysis, dance training, and human--computer interaction, with a highest accuracy of 96.85\%.</li>
</ul>

<h3>Title: Detecting Manipulated Contents Using Knowledge-Grounded Inference</h3>
<ul>
<li><strong>Authors: </strong>Mark Huasong Meng, Ruizhe Wang, Meng Xu, Chuan Yan, Guangdong Bai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21165">https://arxiv.org/abs/2504.21165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21165">https://arxiv.org/pdf/2504.21165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21165]] Detecting Manipulated Contents Using Knowledge-Grounded Inference(https://arxiv.org/abs/2504.21165)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The detection of manipulated content, a prevalent form of fake news, has been widely studied in recent years. While existing solutions have been proven effective in fact-checking and analyzing fake news based on historical events, the reliance on either intrinsic knowledge obtained during training or manually curated context hinders them from tackling zero-day manipulated content, which can only be recognized with real-time contextual information. In this work, we propose Manicod, a tool designed for detecting zero-day manipulated content. Manicod first sources contextual information about the input claim from mainstream search engines, and subsequently vectorizes the context for the large language model (LLM) through retrieval-augmented generation (RAG). The LLM-based inference can produce a "truthful" or "manipulated" decision and offer a textual explanation for the decision. To validate the effectiveness of Manicod, we also propose a dataset comprising 4270 pieces of manipulated fake news derived from 2500 recent real-world news headlines. Manicod achieves an overall F1 score of 0.856 on this dataset and outperforms existing methods by up to 1.9x in F1 score on their benchmarks on fact-checking and claim verification.</li>
</ul>

<h3>Title: Dance Style Recognition Using Laban Movement Analysis</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Turab, Philippe Colantoni, Damien Muselet, Alain Tremeau</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21166">https://arxiv.org/abs/2504.21166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21166">https://arxiv.org/pdf/2504.21166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21166]] Dance Style Recognition Using Laban Movement Analysis(https://arxiv.org/abs/2504.21166)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>The growing interest in automated movement analysis has presented new challenges in recognition of complex human activities including dance. This study focuses on dance style recognition using features extracted using Laban Movement Analysis. Previous studies for dance style recognition often focus on cross-frame movement analysis, which limits the ability to capture temporal context and dynamic transitions between movements. This gap highlights the need for a method that can add temporal context to LMA features. For this, we introduce a novel pipeline which combines 3D pose estimation, 3D human mesh reconstruction, and floor aware body modeling to effectively extract LMA features. To address the temporal limitation, we propose a sliding window approach that captures movement evolution across time in features. These features are then used to train various machine learning methods for classification, and their explainability explainable AI methods to evaluate the contribution of each feature to classification performance. Our proposed method achieves a highest classification accuracy of 99.18\% which shows that the addition of temporal context significantly improves dance style recognition performance.</li>
</ul>

<h3>Title: Efficient LLMs with AMP: Attention Heads and MLP Pruning</h3>
<ul>
<li><strong>Authors: </strong>Leandro Giusti Mugnaini, Bruno Lopes Yamamoto, Lucas Lauton de Alcantara, Victor Zacarias, Edson Bollis, Lucas Pellicer, Anna Helena Reali Costa, Artur Jordao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21174">https://arxiv.org/abs/2504.21174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21174">https://arxiv.org/pdf/2504.21174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21174]] Efficient LLMs with AMP: Attention Heads and MLP Pruning(https://arxiv.org/abs/2504.21174)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Deep learning drives a new wave in computing systems and triggers the automation of increasingly complex problems. In particular, Large Language Models (LLMs) have significantly advanced cognitive tasks, often matching or even surpassing human-level performance. However, their extensive parameters result in high computational costs and slow inference, posing challenges for deployment in resource-limited settings. Among the strategies to overcome the aforementioned challenges, pruning emerges as a successful mechanism since it reduces model size while maintaining predictive ability. In this paper, we introduce AMP: Attention Heads and MLP Pruning, a novel structured pruning method that efficiently compresses LLMs by removing less critical structures within Multi-Head Attention (MHA) and Multilayer Perceptron (MLP). By projecting the input data onto weights, AMP assesses structural importance and overcomes the limitations of existing techniques, which often fall short in flexibility or efficiency. In particular, AMP surpasses the current state-of-the-art on commonsense reasoning tasks by up to 1.49 percentage points, achieving a 30% pruning ratio with minimal impact on zero-shot task performance. Moreover, AMP also improves inference speeds, making it well-suited for deployment in resource-constrained environments. We confirm the flexibility of AMP on different families of LLMs, including LLaMA and Phi.</li>
</ul>

<h3>Title: Federated One-Shot Learning with Data Privacy and Objective-Hiding</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Egger, Rüdiger Urbanke, Rawad Bitar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.IT, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21182">https://arxiv.org/abs/2504.21182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21182">https://arxiv.org/pdf/2504.21182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21182]] Federated One-Shot Learning with Data Privacy and Objective-Hiding(https://arxiv.org/abs/2504.21182)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Privacy in federated learning is crucial, encompassing two key aspects: safeguarding the privacy of clients' data and maintaining the privacy of the federator's objective from the clients. While the first aspect has been extensively studied, the second has received much less attention. We present a novel approach that addresses both concerns simultaneously, drawing inspiration from techniques in knowledge distillation and private information retrieval to provide strong information-theoretic privacy guarantees. Traditional private function computation methods could be used here; however, they are typically limited to linear or polynomial functions. To overcome these constraints, our approach unfolds in three stages. In stage 0, clients perform the necessary computations locally. In stage 1, these results are shared among the clients, and in stage 2, the federator retrieves its desired objective without compromising the privacy of the clients' data. The crux of the method is a carefully designed protocol that combines secret-sharing-based multi-party computation and a graph-based private information retrieval scheme. We show that our method outperforms existing tools from the literature when properly adapted to this setting.</li>
</ul>

<h3>Title: GLIP-OOD: Zero-Shot Graph OOD Detection with Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Haoyan Xu, Zhengtao Yao, Xuzhi Zhang, Ziyi Wang, Langzhou He, Yushun Dong, Philip S. Yu, Mengyuan Li, Yue Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21186">https://arxiv.org/abs/2504.21186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21186">https://arxiv.org/pdf/2504.21186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21186]] GLIP-OOD: Zero-Shot Graph OOD Detection with Foundation Model(https://arxiv.org/abs/2504.21186)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) detection is critical for ensuring the safety and reliability of machine learning systems, particularly in dynamic and open-world environments. In the vision and text domains, zero-shot OOD detection - which requires no training on in-distribution (ID) data - has made significant progress through the use of large-scale pretrained models such as vision-language models (VLMs) and large language models (LLMs). However, zero-shot OOD detection in graph-structured data remains largely unexplored, primarily due to the challenges posed by complex relational structures and the absence of powerful, large-scale pretrained models for graphs. In this work, we take the first step toward enabling zero-shot graph OOD detection by leveraging a graph foundation model (GFM). We show that, when provided only with class label names, the GFM can perform OOD detection without any node-level supervision - outperforming existing supervised methods across multiple datasets. To address the more practical setting where OOD label names are unavailable, we introduce GLIP-OOD, a novel framework that employs LLMs to generate semantically informative pseudo-OOD labels from unlabeled data. These labels enable the GFM to capture nuanced semantic boundaries between ID and OOD classes and perform fine-grained OOD detection - without requiring any labeled nodes. Our approach is the first to enable node-level graph OOD detection in a fully zero-shot setting, and achieves state-of-the-art performance on four benchmark text-attributed graph datasets.</li>
</ul>

<h3>Title: LIFT: LLM-Based Pragma Insertion for HLS via GNN Supervised Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Neha Prakriya, Zijian Ding, Yizhou Sun, Jason Cong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21187">https://arxiv.org/abs/2504.21187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21187">https://arxiv.org/pdf/2504.21187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21187]] LIFT: LLM-Based Pragma Insertion for HLS via GNN Supervised Fine-Tuning(https://arxiv.org/abs/2504.21187)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>FPGAs are increasingly adopted in datacenter environments for their reconfigurability and energy efficiency. High-Level Synthesis (HLS) tools have eased FPGA programming by raising the abstraction level from RTL to untimed C/C++, yet attaining high performance still demands expert knowledge and iterative manual insertion of optimization pragmas to modify the microarchitecture. To address this challenge, we propose LIFT, a large language model (LLM)-based coding assistant for HLS that automatically generates performance-critical pragmas given a C/C++ design. We fine-tune the LLM by tightly integrating and supervising the training process with a graph neural network (GNN), combining the sequential modeling capabilities of LLMs with the structural and semantic understanding of GNNs necessary for reasoning over code and its control/data dependencies. On average, LIFT produces designs that improve performance by 3.52x and 2.16x than prior state-of the art AutoDSE and HARP respectively, and 66x than GPT-4o.</li>
</ul>

<h3>Title: Artificial Intelligence for Personalized Prediction of Alzheimer's Disease Progression: A Survey of Methods, Data Challenges, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Gulsah Hancerliogullari Koksalmis, Bulent Soykan, Laura J. Brattain, Hsin-Hsiung Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21189">https://arxiv.org/abs/2504.21189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21189">https://arxiv.org/pdf/2504.21189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21189]] Artificial Intelligence for Personalized Prediction of Alzheimer's Disease Progression: A Survey of Methods, Data Challenges, and Future Directions(https://arxiv.org/abs/2504.21189)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate, interpretability, generative</a></li>
<li><strong>Abstract: </strong>Alzheimer's Disease (AD) is marked by significant inter-individual variability in its progression, complicating accurate prognosis and personalized care planning. This heterogeneity underscores the critical need for predictive models capable of forecasting patient-specific disease trajectories. Artificial Intelligence (AI) offers powerful tools to address this challenge by analyzing complex, multi-modal, and longitudinal patient data. This paper provides a comprehensive survey of AI methodologies applied to personalized AD progression prediction. We review key approaches including state-space models for capturing temporal dynamics, deep learning techniques like Recurrent Neural Networks for sequence modeling, Graph Neural Networks (GNNs) for leveraging network structures, and the emerging concept of AI-driven digital twins for individualized simulation. Recognizing that data limitations often impede progress, we examine common challenges such as high dimensionality, missing data, and dataset imbalance. We further discuss AI-driven mitigation strategies, with a specific focus on synthetic data generation using Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to augment and balance datasets. The survey synthesizes the strengths and limitations of current approaches, emphasizing the trend towards multimodal integration and the persistent need for model interpretability and generalizability. Finally, we identify critical open challenges, including robust external validation, clinical integration, and ethical considerations, and outline promising future research directions such as hybrid models, causal inference, and federated learning. This review aims to consolidate current knowledge and guide future efforts in developing clinically relevant AI tools for personalized AD prognostication.</li>
</ul>

<h3>Title: TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts</h3>
<ul>
<li><strong>Authors: </strong>Pradip Kunwar, Minh N. Vu, Maanak Gupta, Mahmoud Abdelsalam, Manish Bhattarai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21190">https://arxiv.org/abs/2504.21190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21190">https://arxiv.org/pdf/2504.21190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21190]] TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts(https://arxiv.org/abs/2504.21190)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose Tensor-Trained Low-Rank Adaptation Mixture of Experts (TT-LoRA MoE), a novel computational framework integrating Parameter-Efficient Fine-Tuning (PEFT) with sparse MoE routing to address scalability challenges in large model deployments. Unlike traditional MoE approaches, which face substantial computational overhead as expert counts grow, TT-LoRA MoE decomposes training into two distinct, optimized stages. First, we independently train lightweight, tensorized low-rank adapters (TT-LoRA experts), each specialized for specific tasks. Subsequently, these expert adapters remain frozen, eliminating inter-task interference and catastrophic forgetting in multi-task setting. A sparse MoE router, trained separately, dynamically leverages base model representations to select exactly one specialized adapter per input at inference time, automating expert selection without explicit task specification. Comprehensive experiments confirm our architecture retains the memory efficiency of low-rank adapters, seamlessly scales to large expert pools, and achieves robust task-level optimization. This structured decoupling significantly enhances computational efficiency and flexibility: uses only 2% of LoRA, 0.3% of Adapters and 0.03% of AdapterFusion parameters and outperforms AdapterFusion by 4 value in multi-tasking, enabling practical and scalable multi-task inference deployments.</li>
</ul>

<h3>Title: Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji, Gregory Arbour, Raymond Ng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21191">https://arxiv.org/abs/2504.21191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21191">https://arxiv.org/pdf/2504.21191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21191]] Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare(https://arxiv.org/abs/2504.21191)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study aims to guide language model selection by investigating: 1) the necessity of finetuning versus zero-shot usage, 2) the benefits of domain-adjacent versus generic pretrained models, 3) the value of further domain-specific pretraining, and 4) the continued relevance of Small Language Models (SLMs) compared to Large Language Models (LLMs) for specific tasks. Using electronic pathology reports from the British Columbia Cancer Registry (BCCR), three classification scenarios with varying difficulty and data size are evaluated. Models include various SLMs and an LLM. SLMs are evaluated both zero-shot and finetuned; the LLM is evaluated zero-shot only. Finetuning significantly improved SLM performance across all scenarios compared to their zero-shot results. The zero-shot LLM outperformed zero-shot SLMs but was consistently outperformed by finetuned SLMs. Domain-adjacent SLMs generally performed better than the generic SLM after finetuning, especially on harder tasks. Further domain-specific pretraining yielded modest gains on easier tasks but significant improvements on the complex, data-scarce task. The results highlight the critical role of finetuning for SLMs in specialized domains, enabling them to surpass zero-shot LLM performance on targeted classification tasks. Pretraining on domain-adjacent or domain-specific data provides further advantages, particularly for complex problems or limited finetuning data. While LLMs offer strong zero-shot capabilities, their performance on these specific tasks did not match that of appropriately finetuned SLMs. In the era of LLMs, SLMs remain relevant and effective, offering a potentially superior performance-resource trade-off compared to LLMs.</li>
</ul>

<h3>Title: Graph Synthetic Out-of-Distribution Exposure with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haoyan Xu, Zhengtao Yao, Ziyi Wang, Zhan Cheng, Xiyang Hu, Mengyuan Li, Yue Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21198">https://arxiv.org/abs/2504.21198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21198">https://arxiv.org/pdf/2504.21198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21198]] Graph Synthetic Out-of-Distribution Exposure with Large Language Models(https://arxiv.org/abs/2504.21198)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) detection in graphs is critical for ensuring model robustness in open-world and safety-sensitive applications. Existing approaches to graph OOD detection typically involve training an in-distribution (ID) classifier using only ID data, followed by the application of post-hoc OOD scoring techniques. Although OOD exposure - introducing auxiliary OOD samples during training - has proven to be an effective strategy for enhancing detection performance, current methods in the graph domain generally assume access to a set of real OOD nodes. This assumption, however, is often impractical due to the difficulty and cost of acquiring representative OOD samples. In this paper, we introduce GOE-LLM, a novel framework that leverages Large Language Models (LLMs) for OOD exposure in graph OOD detection without requiring real OOD nodes. GOE-LLM introduces two pipelines: (1) identifying pseudo-OOD nodes from the initially unlabeled graph using zero-shot LLM annotations, and (2) generating semantically informative synthetic OOD nodes via LLM-prompted text generation. These pseudo-OOD nodes are then used to regularize the training of the ID classifier for improved OOD awareness. We evaluate our approach across multiple benchmark datasets, showing that GOE-LLM significantly outperforms state-of-the-art graph OOD detection methods that do not use OOD exposure and achieves comparable performance to those relying on real OOD data.</li>
</ul>

<h3>Title: Automatic Legal Writing Evaluation of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ramon Pires, Roseval Malaquias Junior, Rodrigo Nogueira</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21202">https://arxiv.org/abs/2504.21202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21202">https://arxiv.org/pdf/2504.21202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21202]] Automatic Legal Writing Evaluation of LLMs(https://arxiv.org/abs/2504.21202)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the recent advances in Large Language Models, benchmarks for evaluating legal writing remain scarce due to the inherent complexity of assessing open-ended responses in this domain. One of the key challenges in evaluating language models on domain-specific tasks is finding test datasets that are public, frequently updated, and contain comprehensive evaluation guidelines. The Brazilian Bar Examination meets these requirements. We introduce oab-bench, a benchmark comprising 105 questions across seven areas of law from recent editions of the exam. The benchmark includes comprehensive evaluation guidelines and reference materials used by human examiners to ensure consistent grading. We evaluate the performance of four LLMs on oab-bench, finding that Claude-3.5 Sonnet achieves the best results with an average score of 7.93 out of 10, passing all 21 exams. We also investigated whether LLMs can serve as reliable automated judges for evaluating legal writing. Our experiments show that frontier models like OpenAI's o1 achieve a strong correlation with human scores when evaluating approved exams, suggesting their potential as reliable automated evaluators despite the inherently subjective nature of legal writing assessment. The source code and the benchmark -- containing questions, evaluation guidelines, model-generated responses, and their respective automated evaluations -- are publicly available.</li>
</ul>

<h3>Title: SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories</h3>
<ul>
<li><strong>Authors: </strong>Connor Dilgren, Purva Chiniya, Luke Griffith, Yu Ding, Yizheng Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21205">https://arxiv.org/abs/2504.21205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21205">https://arxiv.org/pdf/2504.21205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21205]] SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories(https://arxiv.org/abs/2504.21205)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>This paper introduces SecRepoBench, a benchmark to evaluate LLMs on secure code generation in real-world repositories. SecRepoBench has 318 code generation tasks in 27 C/C++ repositories, covering 15 CWEs. We evaluate 19 state-of-the-art LLMs using our benchmark and find that the models struggle with generating correct and secure code. In addition, the performance of LLMs to generate self-contained programs as measured by prior benchmarks do not translate to comparative performance at generating secure and correct code at the repository level in SecRepoBench. We show that the state-of-the-art prompt engineering techniques become less effective when applied to the repository level secure code generation problem. We conduct extensive experiments, including an agentic technique to generate secure code, to demonstrate that our benchmark is currently the most difficult secure coding benchmark, compared to previous state-of-the-art benchmarks. Finally, our comprehensive analysis provides insights into potential directions for enhancing the ability of LLMs to generate correct and secure code in real-world repositories.</li>
</ul>

<h3>Title: FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs</h3>
<ul>
<li><strong>Authors: </strong>Zihan Chen, Xingbo Fu, Yushun Dong, Jundong Li, Cong Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21206">https://arxiv.org/abs/2504.21206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21206">https://arxiv.org/pdf/2504.21206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21206]] FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs(https://arxiv.org/abs/2504.21206)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Graph Learning (FGL) empowers clients to collaboratively train Graph neural networks (GNNs) in a distributed manner while preserving data privacy. However, FGL methods usually require that the graph data owned by all clients is homophilic to ensure similar neighbor distribution patterns of nodes. Such an assumption ensures that the learned knowledge is consistent across the local models from all clients. Therefore, these local models can be properly aggregated as a global model without undermining the overall performance. Nevertheless, when the neighbor distribution patterns of nodes vary across different clients (e.g., when clients hold graphs with different levels of heterophily), their local models may gain different and even conflict knowledge from their node-level predictive tasks. Consequently, aggregating these local models usually leads to catastrophic performance deterioration on the global model. To address this challenge, we propose FedHERO, an FGL framework designed to harness and share insights from heterophilic graphs effectively. At the heart of FedHERO is a dual-channel GNN equipped with a structure learner, engineered to discern the structural knowledge encoded in the local graphs. With this specialized component, FedHERO enables the local model for each client to identify and learn patterns that are universally applicable across graphs with different patterns of node neighbor distributions. FedHERO not only enhances the performance of individual client models by leveraging both local and shared structural insights but also sets a new precedent in this field to effectively handle graph data with various node neighbor distribution patterns. We conduct extensive experiments to validate the superior performance of FedHERO against existing alternatives.</li>
</ul>

<h3>Title: A Cost-Effective LLM-based Approach to Identify Wildlife Trafficking in Online Marketplaces</h3>
<ul>
<li><strong>Authors: </strong>Juliana Barbosa, Ulhas Gondhali, Gohar Petrossian, Kinshuk Sharma, Sunandan Chakraborty, Jennifer Jacquet, Juliana Freire</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21211">https://arxiv.org/abs/2504.21211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21211">https://arxiv.org/pdf/2504.21211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21211]] A Cost-Effective LLM-based Approach to Identify Wildlife Trafficking in Online Marketplaces(https://arxiv.org/abs/2504.21211)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Wildlife trafficking remains a critical global issue, significantly impacting biodiversity, ecological stability, and public health. Despite efforts to combat this illicit trade, the rise of e-commerce platforms has made it easier to sell wildlife products, putting new pressure on wild populations of endangered and threatened species. The use of these platforms also opens a new opportunity: as criminals sell wildlife products online, they leave digital traces of their activity that can provide insights into trafficking activities as well as how they can be disrupted. The challenge lies in finding these traces. Online marketplaces publish ads for a plethora of products, and identifying ads for wildlife-related products is like finding a needle in a haystack. Learning classifiers can automate ad identification, but creating them requires costly, time-consuming data labeling that hinders support for diverse ads and research questions. This paper addresses a critical challenge in the data science pipeline for wildlife trafficking analytics: generating quality labeled data for classifiers that select relevant data. While large language models (LLMs) can directly label advertisements, doing so at scale is prohibitively expensive. We propose a cost-effective strategy that leverages LLMs to generate pseudo labels for a small sample of the data and uses these labels to create specialized classification models. Our novel method automatically gathers diverse and representative samples to be labeled while minimizing the labeling costs. Our experimental evaluation shows that our classifiers achieve up to 95% F1 score, outperforming LLMs at a lower cost. We present real use cases that demonstrate the effectiveness of our approach in enabling analyses of different aspects of wildlife trafficking.</li>
</ul>

<h3>Title: CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks</h3>
<ul>
<li><strong>Authors: </strong>Rui Wang, Junda Wu, Yu Xia, Tong Yu, Ruiyi Zhang, Ryan Rossi, Lina Yao, Julian McAuley</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21228">https://arxiv.org/abs/2504.21228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21228">https://arxiv.org/pdf/2504.21228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21228]] CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks(https://arxiv.org/abs/2504.21228)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are identified as being susceptible to indirect prompt injection attack, where the model undesirably deviates from user-provided instructions by executing tasks injected in the prompt context. This vulnerability stems from LLMs' inability to distinguish between data and instructions within a prompt. In this paper, we propose CachePrune that defends against this attack by identifying and pruning task-triggering neurons from the KV cache of the input prompt context. By pruning such neurons, we encourage the LLM to treat the text spans of input prompt context as only pure data, instead of any indicator of instruction following. These neurons are identified via feature attribution with a loss function induced from an upperbound of the Direct Preference Optimization (DPO) objective. We show that such a loss function enables effective feature attribution with only a few samples. We further improve on the quality of feature attribution, by exploiting an observed triggering effect in instruction following. Our approach does not impose any formatting on the original prompt or introduce extra test-time LLM calls. Experiments show that CachePrune significantly reduces attack success rates without compromising the response quality. Note: This paper aims to defend against indirect prompt injection attacks, with the goal of developing more secure and robust AI systems.</li>
</ul>

<h3>Title: T2ID-CAS: Diffusion Model and Class Aware Sampling to Mitigate Class Imbalance in Neck Ultrasound Anatomical Landmark Detection</h3>
<ul>
<li><strong>Authors: </strong>Manikanta Varaganti, Amulya Vankayalapati, Nour Awad, Gregory R. Dion, Laura J. Brattain</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21231">https://arxiv.org/abs/2504.21231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21231">https://arxiv.org/pdf/2504.21231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21231]] T2ID-CAS: Diffusion Model and Class Aware Sampling to Mitigate Class Imbalance in Neck Ultrasound Anatomical Landmark Detection(https://arxiv.org/abs/2504.21231)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Neck ultrasound (US) plays a vital role in airway management by providing non-invasive, real-time imaging that enables rapid and precise interventions. Deep learning-based anatomical landmark detection in neck US can further facilitate procedural efficiency. However, class imbalance within datasets, where key structures like tracheal rings and vocal folds are underrepresented, presents significant challenges for object detection models. To address this, we propose T2ID-CAS, a hybrid approach that combines a text-to-image latent diffusion model with class-aware sampling to generate high-quality synthetic samples for underrepresented classes. This approach, rarely explored in the ultrasound domain, improves the representation of minority classes. Experimental results using YOLOv9 for anatomical landmark detection in neck US demonstrated that T2ID-CAS achieved a mean Average Precision of 88.2, significantly surpassing the baseline of 66. This highlights its potential as a computationally efficient and scalable solution for mitigating class imbalance in AI-assisted ultrasound-guided interventions.</li>
</ul>

<h3>Title: Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math</h3>
<ul>
<li><strong>Authors: </strong>Haoran Xu, Baolin Peng, Hany Awadalla, Dongdong Chen, Yen-Chun Chen, Mei Gao, Young Jin Kim, Yunsheng Li, Liliang Ren, Yelong Shen, Shuohang Wang, Weijian Xu, Jianfeng Gao, Weizhu Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21233">https://arxiv.org/abs/2504.21233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21233">https://arxiv.org/pdf/2504.21233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21233]] Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math(https://arxiv.org/abs/2504.21233)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-Thought (CoT) significantly enhances formal reasoning capabilities in Large Language Models (LLMs) by training them to explicitly generate intermediate reasoning steps. While LLMs readily benefit from such techniques, improving reasoning in Small Language Models (SLMs) remains challenging due to their limited model capacity. Recent work by Deepseek-R1 demonstrates that distillation from LLM-generated synthetic data can substantially improve the reasoning ability of SLM. However, the detailed modeling recipe is not disclosed. In this work, we present a systematic training recipe for SLMs that consists of four steps: (1) large-scale mid-training on diverse distilled long-CoT data, (2) supervised fine-tuning on high-quality long-CoT data, (3) Rollout DPO leveraging a carefully curated preference dataset, and (4) Reinforcement Learning (RL) with Verifiable Reward. We apply our method on Phi-4-Mini, a compact 3.8B-parameter model. The resulting Phi-4-Mini-Reasoning model exceeds, on math reasoning tasks, much larger reasoning models, e.g., outperforming DeepSeek-R1-Distill-Qwen-7B by 3.2 points and DeepSeek-R1-Distill-Llama-8B by 7.7 points on Math-500. Our results validate that a carefully designed training recipe, with large-scale high-quality CoT data, is effective to unlock strong reasoning capabilities even in resource-constrained small models.</li>
</ul>

<h3>Title: Memorization and Knowledge Injection in Gated LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xu Pan, Ely Hahami, Zechen Zhang, Haim Sompolinsky</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21239">https://arxiv.org/abs/2504.21239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21239">https://arxiv.org/pdf/2504.21239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21239]] Memorization and Knowledge Injection in Gated LLMs(https://arxiv.org/abs/2504.21239)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) currently struggle to sequentially add new memories and integrate new knowledge. These limitations contrast with the human ability to continuously learn from new experiences and acquire knowledge throughout life. Most existing approaches add memories either through large context windows or external memory buffers (e.g., Retrieval-Augmented Generation), and studies on knowledge injection rarely test scenarios resembling everyday life events. In this work, we introduce a continual learning framework, Memory Embedded in Gated LLMs (MEGa), which injects event memories directly into the weights of LLMs. Each memory is stored in a dedicated set of gated low-rank weights. During inference, a gating mechanism activates relevant memory weights by matching query embeddings to stored memory embeddings. This enables the model to both recall entire memories and answer related questions. On two datasets - fictional characters and Wikipedia events - MEGa outperforms baseline approaches in mitigating catastrophic forgetting. Our model draws inspiration from the complementary memory system of the human brain.</li>
</ul>

<h3>Title: Subject Information Extraction for Novelty Detection with Domain Shifts</h3>
<ul>
<li><strong>Authors: </strong>Yangyang Qu, Dazhi Fu, Jicong Fan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21247">https://arxiv.org/abs/2504.21247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21247">https://arxiv.org/pdf/2504.21247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21247]] Subject Information Extraction for Novelty Detection with Domain Shifts(https://arxiv.org/abs/2504.21247)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction</a></li>
<li><strong>Abstract: </strong>Unsupervised novelty detection (UND), aimed at identifying novel samples, is essential in fields like medical diagnosis, cybersecurity, and industrial quality control. Most existing UND methods assume that the training data and testing normal data originate from the same domain and only consider the distribution variation between training data and testing data. However, in real scenarios, it is common for normal testing and training data to originate from different domains, a challenge known as domain shift. The discrepancies between training and testing data often lead to incorrect classification of normal data as novel by existing methods. A typical situation is that testing normal data and training data describe the same subject, yet they differ in the background conditions. To address this problem, we introduce a novel method that separates subject information from background variation encapsulating the domain information to enhance detection performance under domain shifts. The proposed method minimizes the mutual information between the representations of the subject and background while modelling the background variation using a deep Gaussian mixture model, where the novelty detection is conducted on the subject representations solely and hence is not affected by the variation of domains. Extensive experiments demonstrate that our model generalizes effectively to unseen domains and significantly outperforms baseline methods, especially under substantial domain shifts between training and testing data.</li>
</ul>

<h3>Title: Multi-modal Transfer Learning for Dynamic Facial Emotion Recognition in the Wild</h3>
<ul>
<li><strong>Authors: </strong>Ezra Engel, Lishan Li, Chris Hudy, Robert Schleusner</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21248">https://arxiv.org/abs/2504.21248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21248">https://arxiv.org/pdf/2504.21248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21248]] Multi-modal Transfer Learning for Dynamic Facial Emotion Recognition in the Wild(https://arxiv.org/abs/2504.21248)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Facial expression recognition (FER) is a subset of computer vision with important applications for human-computer-interaction, healthcare, and customer service. FER represents a challenging problem-space because accurate classification requires a model to differentiate between subtle changes in facial features. In this paper, we examine the use of multi-modal transfer learning to improve performance on a challenging video-based FER dataset, Dynamic Facial Expression in-the-Wild (DFEW). Using a combination of pretrained ResNets, OpenPose, and OmniVec networks, we explore the impact of cross-temporal, multi-modal features on classification accuracy. Ultimately, we find that these finely-tuned multi-modal feature generators modestly improve accuracy of our transformer-based classification model.</li>
</ul>

<h3>Title: Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA</h3>
<ul>
<li><strong>Authors: </strong>Xuanzhao Dong, Wenhui Zhu, Hao Wang, Xiwen Chen, Peijie Qiu, Rui Yin, Yi Su, Yalin Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21252">https://arxiv.org/abs/2504.21252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21252">https://arxiv.org/pdf/2504.21252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21252]] Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA(https://arxiv.org/abs/2504.21252)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Medical question answering (QA) is a reasoning-intensive task that remains challenging for large language models (LLMs) due to hallucinations and outdated domain knowledge. Retrieval-Augmented Generation (RAG) provides a promising post-training solution by leveraging external knowledge. However, existing medical RAG systems suffer from two key limitations: (1) a lack of modeling for human-like reasoning behaviors during information retrieval, and (2) reliance on suboptimal medical corpora, which often results in the retrieval of irrelevant or noisy snippets. To overcome these challenges, we propose Discuss-RAG, a plug-and-play module designed to enhance the medical QA RAG system through collaborative agent-based reasoning. Our method introduces a summarizer agent that orchestrates a team of medical experts to emulate multi-turn brainstorming, thereby improving the relevance of retrieved content. Additionally, a decision-making agent evaluates the retrieved snippets before their final integration. Experimental results on four benchmark medical QA datasets show that Discuss-RAG consistently outperforms MedRAG, especially significantly improving answer accuracy by up to 16.67% on BioASQ and 12.20% on PubMedQA. The code is available at: this https URL.</li>
</ul>

<h3>Title: ABG-NAS: Adaptive Bayesian Genetic Neural Architecture Search for Graph Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Sixuan Wang, Jiao Yin, Jinli Cao, MingJian Tang, Hua Wang, Yanchun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21254">https://arxiv.org/abs/2504.21254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21254">https://arxiv.org/pdf/2504.21254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21254]] ABG-NAS: Adaptive Bayesian Genetic Neural Architecture Search for Graph Representation Learning(https://arxiv.org/abs/2504.21254)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Effective and efficient graph representation learning is essential for enabling critical downstream tasks, such as node classification, link prediction, and subgraph search. However, existing graph neural network (GNN) architectures often struggle to adapt to diverse and complex graph structures, limiting their ability to provide robust and generalizable representations. To address this challenge, we propose ABG-NAS, a novel framework for automated graph neural network architecture search tailored for efficient graph representation learning. ABG-NAS encompasses three key components: a Comprehensive Architecture Search Space (CASS), an Adaptive Genetic Optimization Strategy (AGOS), and a Bayesian-Guided Tuning Module (BGTM). CASS systematically explores diverse propagation (P) and transformation (T) operations, enabling the discovery of GNN architectures capable of capturing intricate graph characteristics. AGOS dynamically balances exploration and exploitation, ensuring search efficiency and preserving solution diversity. BGTM further optimizes hyperparameters periodically, enhancing the scalability and robustness of the resulting architectures. Empirical evaluations on benchmark datasets (Cora, PubMed, Citeseer, and CoraFull) demonstrate that ABG-NAS consistently outperforms both manually designed GNNs and state-of-the-art neural architecture search (NAS) methods. These results highlight the potential of ABG-NAS to advance graph representation learning by providing scalable and adaptive solutions for diverse graph structures. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine Text-Co-Guided Latent Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Zhifu Zhao, Hanyang Hua, Jianan Li, Shaoxin Wu, Fu Li, Yangtao Zhou, Yang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21266">https://arxiv.org/abs/2504.21266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21266">https://arxiv.org/pdf/2504.21266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21266]] CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine Text-Co-Guided Latent Diffusion(https://arxiv.org/abs/2504.21266)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>In action recognition tasks, feature diversity is essential for enhancing model generalization and performance. Existing methods typically promote feature diversity by expanding the training data in the sample space, which often leads to inefficiencies and semantic inconsistencies. To overcome these problems, we propose a novel Coarse-fine text co-guidance Diffusion model (CoCoDiff). CoCoDiff generates diverse yet semantically consistent features in the latent space by leveraging diffusion and multi-granularity textual guidance. Specifically, our approach feeds spatio-temporal features extracted from skeleton sequences into a latent diffusion model to generate diverse action representations. Meanwhile, we introduce a coarse-fine text co-guided strategy that leverages textual information from large language models (LLMs) to ensure semantic consistency between the generated features and the original inputs. It is noted that CoCoDiff operates as a plug-and-play auxiliary module during training, incurring no additional inference cost. Extensive experiments demonstrate that CoCoDiff achieves SOTA performance on skeleton-based action recognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and Kinetics-Skeleton.</li>
</ul>

<h3>Title: Mamba Based Feature Extraction And Adaptive Multilevel Feature Fusion For 3D Tumor Segmentation From Multi-modal Medical Image</h3>
<ul>
<li><strong>Authors: </strong>Zexin Ji, Beiji Zou, Xiaoyan Kui, Hua Li, Pierre Vera, Su Ruan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21281">https://arxiv.org/abs/2504.21281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21281">https://arxiv.org/pdf/2504.21281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21281]] Mamba Based Feature Extraction And Adaptive Multilevel Feature Fusion For 3D Tumor Segmentation From Multi-modal Medical Image(https://arxiv.org/abs/2504.21281)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Multi-modal 3D medical image segmentation aims to accurately identify tumor regions across different modalities, facing challenges from variations in image intensity and tumor morphology. Traditional convolutional neural network (CNN)-based methods struggle with capturing global features, while Transformers-based methods, despite effectively capturing global context, encounter high computational costs in 3D medical image segmentation. The Mamba model combines linear scalability with long-distance modeling, making it a promising approach for visual representation learning. However, Mamba-based 3D multi-modal segmentation still struggles to leverage modality-specific features and fuse complementary information effectively. In this paper, we propose a Mamba based feature extraction and adaptive multilevel feature fusion for 3D tumor segmentation using multi-modal medical image. We first develop the specific modality Mamba encoder to efficiently extract long-range relevant features that represent anatomical and pathological structures present in each modality. Moreover, we design an bi-level synergistic integration block that dynamically merges multi-modal and multi-level complementary features by the modality attention and channel attention learning. Lastly, the decoder combines deep semantic information with fine-grained details to generate the tumor segmentation map. Experimental results on medical image datasets (PET/CT and MRI multi-sequence) show that our approach achieve competitive performance compared to the state-of-the-art CNN, Transformer, and Mamba-based approaches.</li>
</ul>

<h3>Title: Can We Achieve Efficient Diffusion without Self-Attention? Distilling Self-Attention into Convolutions</h3>
<ul>
<li><strong>Authors: </strong>ZiYi Dong, Chengxing Zhou, Weijian Deng, Pengxu Wei, Xiangyang Ji, Liang Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21292">https://arxiv.org/abs/2504.21292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21292">https://arxiv.org/pdf/2504.21292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21292]] Can We Achieve Efficient Diffusion without Self-Attention? Distilling Self-Attention into Convolutions(https://arxiv.org/abs/2504.21292)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Contemporary diffusion models built upon U-Net or Diffusion Transformer (DiT) architectures have revolutionized image generation through transformer-based attention mechanisms. The prevailing paradigm has commonly employed self-attention with quadratic computational complexity to handle global spatial relationships in complex images, thereby synthesizing high-fidelity images with coherent visual this http URL to conventional wisdom, our systematic layer-wise analysis reveals an interesting discrepancy: self-attention in pre-trained diffusion models predominantly exhibits localized attention patterns, closely resembling convolutional inductive biases. This suggests that global interactions in self-attention may be less critical than commonly this http URL by this, we propose \(\Delta\)ConvFusion to replace conventional self-attention modules with Pyramid Convolution Blocks (\(\Delta\)ConvBlocks).By distilling attention patterns into localized convolutional operations while keeping other components frozen, \(\Delta\)ConvFusion achieves performance comparable to transformer-based counterparts while reducing computational cost by 6929$\times$ and surpassing LinFusion by 5.42$\times$ in efficiency--all without compromising generative fidelity.</li>
</ul>

<h3>Title: Fairness in Graph Learning Augmented with Machine Learning: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Renqiang Luo, Ziqi Xu, Xikun Zhang, Qing Qing, Huafei Huang, Enyan Dai, Zhe Wang, Bo Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21296">https://arxiv.org/abs/2504.21296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21296">https://arxiv.org/pdf/2504.21296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21296]] Fairness in Graph Learning Augmented with Machine Learning: A Survey(https://arxiv.org/abs/2504.21296)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate, fair, transformer</a></li>
<li><strong>Abstract: </strong>Augmenting specialised machine learning techniques into traditional graph learning models has achieved notable success across various domains, including federated graph learning, dynamic graph learning, and graph transformers. However, the intricate mechanisms of these specialised techniques introduce significant challenges in maintaining model fairness, potentially resulting in discriminatory outcomes in high-stakes applications such as recommendation systems, disaster response, criminal justice, and loan approval. This paper systematically examines the unique fairness challenges posed by Graph Learning augmented with Machine Learning (GL-ML). It highlights the complex interplay between graph learning mechanisms and machine learning techniques, emphasising how the augmentation of machine learning both enhances and complicates fairness. Additionally, we explore four critical techniques frequently employed to improve fairness in GL-ML methods. By thoroughly investigating the root causes and broader implications of fairness challenges in this rapidly evolving field, this work establishes a robust foundation for future research and innovation in GL-ML fairness.</li>
</ul>

<h3>Title: BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhiting Fan, Ruizhe Chen, Zuozhu Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21299">https://arxiv.org/abs/2504.21299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21299">https://arxiv.org/pdf/2504.21299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21299]] BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models(https://arxiv.org/abs/2504.21299)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Identifying bias in LLM-generated content is a crucial prerequisite for ensuring fairness in LLMs. Existing methods, such as fairness classifiers and LLM-based judges, face limitations related to difficulties in understanding underlying intentions and the lack of criteria for fairness judgment. In this paper, we introduce BiasGuard, a novel bias detection tool that explicitly analyzes inputs and reasons through fairness specifications to provide accurate judgments. BiasGuard is implemented through a two-stage approach: the first stage initializes the model to explicitly reason based on fairness specifications, while the second stage leverages reinforcement learning to enhance its reasoning and judgment capabilities. Our experiments, conducted across five datasets, demonstrate that BiasGuard outperforms existing tools, improving accuracy and reducing over-fairness misjudgments. We also highlight the importance of reasoning-enhanced decision-making and provide evidence for the effectiveness of our two-stage optimization pipeline.</li>
</ul>

<h3>Title: Confidence in Large Language Model Evaluation: A Bayesian Approach to Limited-Sample Challenges</h3>
<ul>
<li><strong>Authors: </strong>Xiao Xiao, Yu Su, Sijing Zhang, Zhang Chen, Yadong Chen, Tian Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21303">https://arxiv.org/abs/2504.21303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21303">https://arxiv.org/pdf/2504.21303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21303]] Confidence in Large Language Model Evaluation: A Bayesian Approach to Limited-Sample Challenges(https://arxiv.org/abs/2504.21303)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit probabilistic output characteristics, yet conventional evaluation frameworks rely on deterministic scalar metrics. This study introduces a Bayesian approach for LLM capability assessment that integrates prior knowledge through probabilistic inference, addressing limitations under limited-sample regimes. By treating model capabilities as latent variables and leveraging a curated query set to induce discriminative responses, we formalize model ranking as a Bayesian hypothesis testing problem over mutually exclusive capability intervals. Experimental evaluations with GPT-series models demonstrate that the proposed method achieves superior discrimination compared to conventional evaluation methods. Results indicate that even with reduced sample sizes, the approach maintains statistical robustness while providing actionable insights, such as probabilistic statements about a model's likelihood of surpassing specific baselines. This work advances LLM evaluation methodologies by bridging Bayesian inference with practical constraints in real-world deployment scenarios.</li>
</ul>

<h3>Title: Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming</h3>
<ul>
<li><strong>Authors: </strong>Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haoyue Bai, Sixun Dong, Haifeng Chen, Yanjie Fu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21304">https://arxiv.org/abs/2504.21304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21304">https://arxiv.org/pdf/2504.21304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21304]] Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming(https://arxiv.org/abs/2504.21304)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Feature transformation involves generating a new set of features from the original dataset to enhance the data's utility. In certain domains like material performance screening, dimensionality is large and collecting labels is expensive and lengthy. It highly necessitates transforming feature spaces efficiently and without supervision to enhance data readiness and AI utility. However, existing methods fall short in efficient navigation of a vast space of feature combinations, and are mostly designed for supervised settings. To fill this gap, our unique perspective is to leverage a generator-critic duet-play teaming framework using LLM agents and in-context learning to derive pseudo-supervision from unsupervised data. The framework consists of three interconnected steps: (1) Critic agent diagnoses data to generate actionable advice, (2) Generator agent produces tokenized feature transformations guided by the critic's advice, and (3) Iterative refinement ensures continuous improvement through feedback between agents. The generator-critic framework can be generalized to human-agent collaborative generation, by replacing the critic agent with human experts. Extensive experiments demonstrate that the proposed framework outperforms even supervised baselines in feature transformation efficiency, robustness, and practical applicability across diverse datasets.</li>
</ul>

<h3>Title: The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks and Defenses for Diffusion Model Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Siyi Chen, Yimeng Zhang, Sijia Liu, Qing Qu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21307">https://arxiv.org/abs/2504.21307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21307">https://arxiv.org/pdf/2504.21307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21307]] The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks and Defenses for Diffusion Model Unlearning(https://arxiv.org/abs/2504.21307)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, interpretability, diffusion</a></li>
<li><strong>Abstract: </strong>Despite the remarkable generalization capabilities of diffusion models, recent studies have shown that these models can memorize and generate harmful content when prompted with specific text instructions. Although fine-tuning approaches have been developed to mitigate this issue by unlearning harmful concepts, these methods can be easily circumvented through jailbreaking attacks. This indicates that the harmful concept has not been fully erased from the model. However, existing attack methods, while effective, lack interpretability regarding why unlearned models still retain the concept, thereby hindering the development of defense strategies. In this work, we address these limitations by proposing an attack method that learns an orthogonal set of interpretable attack token embeddings. The attack token embeddings can be decomposed into human-interpretable textual elements, revealing that unlearned models still retain the target concept through implicit textual components. Furthermore, these attack token embeddings are robust and transferable across text prompts, initial noises, and unlearned models. Finally, leveraging this diverse set of embeddings, we design a defense method applicable to both our proposed attack and existing attack methods. Experimental results demonstrate the effectiveness of both our attack and defense strategies.</li>
</ul>

<h3>Title: An Evaluation of a Visual Question Answering Strategy for Zero-shot Facial Expression Recognition in Still Images</h3>
<ul>
<li><strong>Authors: </strong>Modesto Castrillón-Santana, Oliverio J Santana, David Freire-Obregón, Daniel Hernández-Sosa, Javier Lorenzo-Navarro</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21309">https://arxiv.org/abs/2504.21309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21309">https://arxiv.org/pdf/2504.21309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21309]] An Evaluation of a Visual Question Answering Strategy for Zero-shot Facial Expression Recognition in Still Images(https://arxiv.org/abs/2504.21309)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Facial expression recognition (FER) is a key research area in computer vision and human-computer interaction. Despite recent advances in deep learning, challenges persist, especially in generalizing to new scenarios. In fact, zero-shot FER significantly reduces the performance of state-of-the-art FER models. To address this problem, the community has recently started to explore the integration of knowledge from Large Language Models for visual tasks. In this work, we evaluate a broad collection of locally executed Visual Language Models (VLMs), avoiding the lack of task-specific knowledge by adopting a Visual Question Answering strategy. We compare the proposed pipeline with state-of-the-art FER models, both integrating and excluding VLMs, evaluating well-known FER benchmarks: AffectNet, FERPlus, and RAF-DB. The results show excellent performance for some VLMs in zero-shot FER scenarios, indicating the need for further exploration to improve FER generalization.</li>
</ul>

<h3>Title: Capturing Conditional Dependence via Auto-regressive Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Xunpeng Huang, Yujin Han, Difan Zou, Yian Ma, Tong Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21314">https://arxiv.org/abs/2504.21314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21314">https://arxiv.org/pdf/2504.21314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21314]] Capturing Conditional Dependence via Auto-regressive Diffusion Models(https://arxiv.org/abs/2504.21314)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated appealing performance in both image and video generation. However, many works discover that they struggle to capture important, high-level relationships that are present in the real world. For example, they fail to learn physical laws from data, and even fail to understand that the objects in the world exist in a stable fashion. This is due to the fact that important conditional dependence structures are not adequately captured in the vanilla diffusion models. In this work, we initiate an in-depth study on strengthening the diffusion model to capture the conditional dependence structures in the data. In particular, we examine the efficacy of the auto-regressive (AR) diffusion models for such purpose and develop the first theoretical results on the sampling error of AR diffusion models under (possibly) the mildest data assumption. Our theoretical findings indicate that, compared with typical diffusion models, the AR variant produces samples with a reduced gap in approximating the data conditional distribution. On the other hand, the overall inference time of the AR-diffusion models is only moderately larger than that for the vanilla diffusion models, making them still practical for large scale applications. We also provide empirical results showing that when there is clear conditional dependence structure in the data, the AR diffusion models captures such structure, whereas vanilla DDPM fails to do so. On the other hand, when there is no obvious conditional dependence across patches of the data, AR diffusion does not outperform DDPM.</li>
</ul>

<h3>Title: How to Backdoor the Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Chen Wu, Qian Ma, Prasenjit Mitra, Sencun Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21323">https://arxiv.org/abs/2504.21323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21323">https://arxiv.org/pdf/2504.21323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21323]] How to Backdoor the Knowledge Distillation(https://arxiv.org/abs/2504.21323)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Knowledge distillation has become a cornerstone in modern machine learning systems, celebrated for its ability to transfer knowledge from a large, complex teacher model to a more efficient student model. Traditionally, this process is regarded as secure, assuming the teacher model is clean. This belief stems from conventional backdoor attacks relying on poisoned training data with backdoor triggers and attacker-chosen labels, which are not involved in the distillation process. Instead, knowledge distillation uses the outputs of a clean teacher model to guide the student model, inherently preventing recognition or response to backdoor triggers as intended by an attacker. In this paper, we challenge this assumption by introducing a novel attack methodology that strategically poisons the distillation dataset with adversarial examples embedded with backdoor triggers. This technique allows for the stealthy compromise of the student model while maintaining the integrity of the teacher model. Our innovative approach represents the first successful exploitation of vulnerabilities within the knowledge distillation process using clean teacher models. Through extensive experiments conducted across various datasets and attack settings, we demonstrate the robustness, stealthiness, and effectiveness of our method. Our findings reveal previously unrecognized vulnerabilities and pave the way for future research aimed at securing knowledge distillation processes against backdoor attacks.</li>
</ul>

<h3>Title: Text-Conditioned Diffusion Model for High-Fidelity Korean Font Generation</h3>
<ul>
<li><strong>Authors: </strong>Abdul Sami, Avinash Kumar, Irfanullah Memon, Youngwon Jo, Muhammad Rizwan, Jaeyoung Choi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21325">https://arxiv.org/abs/2504.21325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21325">https://arxiv.org/pdf/2504.21325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21325]] Text-Conditioned Diffusion Model for High-Fidelity Korean Font Generation(https://arxiv.org/abs/2504.21325)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Automatic font generation (AFG) is the process of creating a new font using only a few examples of the style images. Generating fonts for complex languages like Korean and Chinese, particularly in handwritten styles, presents significant challenges. Traditional AFGs, like Generative adversarial networks (GANs) and Variational Auto-Encoders (VAEs), are usually unstable during training and often face mode collapse problems. They also struggle to capture fine details within font images. To address these problems, we present a diffusion-based AFG method which generates high-quality, diverse Korean font images using only a single reference image, focusing on handwritten and printed styles. Our approach refines noisy images incrementally, ensuring stable training and visually appealing results. A key innovation is our text encoder, which processes phonetic representations to generate accurate and contextually correct characters, even for unseen characters. We used a pre-trained style encoder from DG FONT to effectively and accurately encode the style images. To further enhance the generation quality, we used perceptual loss that guides the model to focus on the global style of generated images. Experimental results on over 2000 Korean characters demonstrate that our model consistently generates accurate and detailed font images and outperforms benchmark methods, making it a reliable tool for generating authentic Korean fonts across different styles.</li>
</ul>

<h3>Title: A Generalized Meta Federated Learning Framework with Theoretical Convergence Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Vahid Jamali, Hamid Saber, Jung Hyun Bae</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21327">https://arxiv.org/abs/2504.21327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21327">https://arxiv.org/pdf/2504.21327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21327]] A Generalized Meta Federated Learning Framework with Theoretical Convergence Guarantees(https://arxiv.org/abs/2504.21327)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Meta federated learning (FL) is a personalized variant of FL, where multiple agents collaborate on training an initial shared model without exchanging raw data samples. The initial model should be trained in a way that current or new agents can easily adapt it to their local datasets after one or a few fine-tuning steps, thus improving the model personalization. Conventional meta FL approaches minimize the average loss of agents on the local models obtained after one step of fine-tuning. In practice, agents may need to apply several fine-tuning steps to adapt the global model to their local data, especially under highly heterogeneous data distributions across agents. To this end, we present a generalized framework for the meta FL by minimizing the average loss of agents on their local model after any arbitrary number $\nu$ of fine-tuning steps. For this generalized framework, we present a variant of the well-known federated averaging (FedAvg) algorithm and conduct a comprehensive theoretical convergence analysis to characterize the convergence speed as well as behavior of the meta loss functions in both the exact and approximated cases. Our experiments on real-world datasets demonstrate superior accuracy and faster convergence for the proposed scheme compared to conventional approaches.</li>
</ul>

<h3>Title: Multi-level datasets training method in Physics-Informed Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Yao-Hsuan Tsai, Hsiao-Tung Juan, Pao-Hsiung Chiu, Chao-An Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21328">https://arxiv.org/abs/2504.21328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21328">https://arxiv.org/pdf/2504.21328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21328]] Multi-level datasets training method in Physics-Informed Neural Networks(https://arxiv.org/abs/2504.21328)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Physics-Informed Neural Networks have emerged as a promising methodology for solving PDEs, gaining significant attention in computer science and various physics-related fields. Despite being demonstrated the ability to incorporate the physics of laws for versatile applications, PINNs still struggle with the challenging problems which are stiff to be solved and/or have high-frequency components in the solutions, resulting in accuracy and convergence issues. It may not only increase computational costs, but also lead to accuracy loss or solution divergence. In this study, an alternative approach is proposed to mitigate the above-mentioned problems. Inspired by the multi-grid method in CFD community, the underlying idea of the current approach is to efficiently remove different frequency errors via training with different levels of training samples, resulting in a simpler way to improve the training accuracy without spending time in fine-tuning of neural network structures, loss weights as well as hyperparameters. To demonstrate the efficacy of current approach, we first investigate canonical 1D ODE with high-frequency component and 2D convection-diffusion equation with V-cycle training strategy. Finally, the current method is employed for the classical benchmark problem of steady Lid-driven cavity flows at different Reynolds numbers, to investigate the applicability and efficacy for the problem involved multiple modes of high and low frequency. By virtue of various training sequence modes, improvement through predictions lead to 30% to 60% accuracy improvement. We also investigate the synergies between current method and transfer learning techniques for more challenging problems (i.e., higher Re). From the present results, it also revealed that the current framework can produce good predictions even for the case of Re=5000, demonstrating the ability to solve complex high-frequency PDEs.</li>
</ul>

<h3>Title: Does the Prompt-based Large Language Model Recognize Students' Demographics and Introduce Bias in Essay Scoring?</h3>
<ul>
<li><strong>Authors: </strong>Kaixun Yang, Mladen Raković, Dragan Gašević, Guanliang Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21330">https://arxiv.org/abs/2504.21330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21330">https://arxiv.org/pdf/2504.21330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21330]] Does the Prompt-based Large Language Model Recognize Students' Demographics and Introduce Bias in Essay Scoring?(https://arxiv.org/abs/2504.21330)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are widely used in Automated Essay Scoring (AES) due to their ability to capture semantic meaning. Traditional fine-tuning approaches required technical expertise, limiting accessibility for educators with limited technical backgrounds. However, prompt-based tools like ChatGPT have made AES more accessible, enabling educators to obtain machine-generated scores using natural-language prompts (i.e., the prompt-based paradigm). Despite advancements, prior studies have shown bias in fine-tuned LLMs, particularly against disadvantaged groups. It remains unclear whether such biases persist or are amplified in the prompt-based paradigm with cutting-edge tools. Since such biases are believed to stem from the demographic information embedded in pre-trained models (i.e., the ability of LLMs' text embeddings to predict demographic attributes), this study explores the relationship between the model's predictive power of students' demographic attributes based on their written works and its predictive bias in the scoring task in the prompt-based paradigm. Using a publicly available dataset of over 25,000 students' argumentative essays, we designed prompts to elicit demographic inferences (i.e., gender, first-language background) from GPT-4o and assessed fairness in automated scoring. Then we conducted multivariate regression analysis to explore the impact of the model's ability to predict demographics on its scoring outcomes. Our findings revealed that (i) prompt-based LLMs can somewhat infer students' demographics, particularly their first-language backgrounds, from their essays; (ii) scoring biases are more pronounced when the LLM correctly predicts students' first-language background than when it does not; and (iii) scoring error for non-native English speakers increases when the LLM correctly identifies them as non-native.</li>
</ul>

<h3>Title: Simple Visual Artifact Detection in Sora-Generated Videos</h3>
<ul>
<li><strong>Authors: </strong>Misora Sugiyama, Hirokatsu Kataoka</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21334">https://arxiv.org/abs/2504.21334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21334">https://arxiv.org/pdf/2504.21334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21334]] Simple Visual Artifact Detection in Sora-Generated Videos(https://arxiv.org/abs/2504.21334)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The December 2024 release of OpenAI's Sora, a powerful video generation model driven by natural language prompts, highlights a growing convergence between large language models (LLMs) and video synthesis. As these multimodal systems evolve into video-enabled LLMs (VidLLMs), capable of interpreting, generating, and interacting with visual content, understanding their limitations and ensuring their safe deployment becomes essential. This study investigates visual artifacts frequently found and reported in Sora-generated videos, which can compromise quality, mislead viewers, or propagate disinformation. We propose a multi-label classification framework targeting four common artifact label types: label 1: boundary / edge defects, label 2: texture / noise issues, label 3: movement / joint anomalies, and label 4: object mismatches / disappearances. Using a dataset of 300 manually annotated frames extracted from 15 Sora-generated videos, we trained multiple 2D CNN architectures (ResNet-50, EfficientNet-B3 / B4, ViT-Base). The best-performing model trained by ResNet-50 achieved an average multi-label classification accuracy of 94.14%. This work supports the broader development of VidLLMs by contributing to (1) the creation of datasets for video quality evaluation, (2) interpretable artifact-based analysis beyond language metrics, and (3) the identification of visual risks relevant to factuality and safety.</li>
</ul>

<h3>Title: UniBiomed: A Universal Foundation Model for Grounded Biomedical Image Interpretation</h3>
<ul>
<li><strong>Authors: </strong>Linshan Wu, Yuxiang Nie, Sunan He, Jiaxin Zhuang, Hao Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21336">https://arxiv.org/abs/2504.21336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21336">https://arxiv.org/pdf/2504.21336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21336]] UniBiomed: A Universal Foundation Model for Grounded Biomedical Image Interpretation(https://arxiv.org/abs/2504.21336)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Multi-modal interpretation of biomedical images opens up novel opportunities in biomedical image analysis. Conventional AI approaches typically rely on disjointed training, i.e., Large Language Models (LLMs) for clinical text generation and segmentation models for target extraction, which results in inflexible real-world deployment and a failure to leverage holistic biomedical information. To this end, we introduce UniBiomed, the first universal foundation model for grounded biomedical image interpretation. UniBiomed is based on a novel integration of Multi-modal Large Language Model (MLLM) and Segment Anything Model (SAM), which effectively unifies the generation of clinical texts and the segmentation of corresponding biomedical objects for grounded interpretation. In this way, UniBiomed is capable of tackling a wide range of biomedical tasks across ten diverse biomedical imaging modalities. To develop UniBiomed, we curate a large-scale dataset comprising over 27 million triplets of images, annotations, and text descriptions across ten imaging modalities. Extensive validation on 84 internal and external datasets demonstrated that UniBiomed achieves state-of-the-art performance in segmentation, disease recognition, region-aware diagnosis, visual question answering, and report generation. Moreover, unlike previous models that rely on clinical experts to pre-diagnose images and manually craft precise textual or visual prompts, UniBiomed can provide automated and end-to-end grounded interpretation for biomedical image analysis. This represents a novel paradigm shift in clinical workflows, which will significantly improve diagnostic efficiency. In summary, UniBiomed represents a novel breakthrough in biomedical AI, unlocking powerful grounded interpretation capabilities for more accurate and efficient biomedical image analysis.</li>
</ul>

<h3>Title: Towards Improved Cervical Cancer Screening: Vision Transformer-Based Classification and Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Khoa Tuan Nguyen, Ho-min Park, Gaeun Oh, Joris Vankerschaver, Wesley De Neve</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21340">https://arxiv.org/abs/2504.21340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21340">https://arxiv.org/pdf/2504.21340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21340]] Towards Improved Cervical Cancer Screening: Vision Transformer-Based Classification and Interpretability(https://arxiv.org/abs/2504.21340)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We propose a novel approach to cervical cell image classification for cervical cancer screening using the EVA-02 transformer model. We developed a four-step pipeline: fine-tuning EVA-02, feature extraction, selecting important features through multiple machine learning models, and training a new artificial neural network with optional loss weighting for improved generalization. With this design, our best model achieved an F1-score of 0.85227, outperforming the baseline EVA-02 model (0.84878). We also utilized Kernel SHAP analysis and identified key features correlating with cell morphology and staining characteristics, providing interpretable insights into the decision-making process of the fine-tuned model. Our code is available at this https URL.</li>
</ul>

<h3>Title: Low latency FPGA implementation of twisted Edward curve cryptography hardware accelerator over prime field</h3>
<ul>
<li><strong>Authors: </strong>Md Rownak Hossain, Md Sazedur Rahman, Kh Shahriya Zaman, Walid El Fezzani, Mohammad Arif Sobhan Bhuiyan, Chia Chao Kang, Teh Jia Yew, Mahdi H. Miraz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21342">https://arxiv.org/abs/2504.21342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21342">https://arxiv.org/pdf/2504.21342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21342]] Low latency FPGA implementation of twisted Edward curve cryptography hardware accelerator over prime field(https://arxiv.org/abs/2504.21342)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The performance of any elliptic curve cryptography hardware accelerator significantly relies on the efficiency of the underlying point multiplication (PM) architecture. This article presents a hardware implementation of field-programmable gate array (FPGA) based modular arithmetic, group operation, and point multiplication unit on the twisted Edwards curve (Edwards25519) over the 256-bit prime field. An original hardware architecture of a unified point operation module in projective coordinates that executes point addition and point doubling within a single module has been developed, taking only 646 clock cycles and ensuring a better security level than conventional approaches. The proposed point multiplication module consumes 1.4 ms time, operating at a maximal clock frequency of 117.8 MHz utilising 164,730 clock cycles having 183.38 kbps throughput on the Xilinx Virtex-5 FPGA platform for 256-bit length of key. The comparative assessment of latency and throughput across various related recent works indicates the effectiveness of our proposed PM architecture. Finally, this high throughput and low latency PM architecture will be a good candidate for rapid data encryption in high-speed wireless communication networks.</li>
</ul>

<h3>Title: Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection</h3>
<ul>
<li><strong>Authors: </strong>Luoting Zhuang, Seyed Mohammad Hossein Tabatabaei, Ramin Salehi-Rad, Linh M. Tran, Denise R. Aberle, Ashley E. Prosper, William Hsu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21344">https://arxiv.org/abs/2504.21344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21344">https://arxiv.org/pdf/2504.21344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21344]] Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection(https://arxiv.org/abs/2504.21344)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Objective: A number of machine learning models have utilized semantic features, deep features, or both to assess lung nodule malignancy. However, their reliance on manual annotation during inference, limited interpretability, and sensitivity to imaging variations hinder their application in real-world clinical settings. Thus, this research aims to integrate semantic features derived from radiologists' assessments of nodules, allowing the model to learn clinically relevant, robust, and explainable features for predicting lung cancer. Methods: We obtained 938 low-dose CT scans from the National Lung Screening Trial with 1,246 nodules and semantic features. The Lung Image Database Consortium dataset contains 1,018 CT scans, with 2,625 lesions annotated for nodule characteristics. Three external datasets were obtained from UCLA Health, the LUNGx Challenge, and the Duke Lung Cancer Screening. We finetuned a pretrained Contrastive Language-Image Pretraining model with a parameter-efficient fine-tuning approach to align imaging and semantic features and predict the one-year lung cancer diagnosis. Results: We evaluated the performance of the one-year diagnosis of lung cancer with AUROC and AUPRC and compared it to three state-of-the-art models. Our model demonstrated an AUROC of 0.90 and AUPRC of 0.78, outperforming baseline state-of-the-art models on external datasets. Using CLIP, we also obtained predictions on semantic features, such as nodule margin (AUROC: 0.81), nodule consistency (0.81), and pleural attachment (0.84), that can be used to explain model predictions. Conclusion: Our approach accurately classifies lung nodules as benign or malignant, providing explainable outputs, aiding clinicians in comprehending the underlying meaning of model predictions. This approach also prevents the model from learning shortcuts and generalizes across clinical settings.</li>
</ul>

<h3>Title: Generative QoE Modeling: A Lightweight Approach for Telecom Networks</h3>
<ul>
<li><strong>Authors: </strong>Vinti Nayar, Kanica Sachdev, Brejesh Lall</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21353">https://arxiv.org/abs/2504.21353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21353">https://arxiv.org/pdf/2504.21353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21353]] Generative QoE Modeling: A Lightweight Approach for Telecom Networks(https://arxiv.org/abs/2504.21353)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Quality of Experience (QoE) prediction plays a crucial role in optimizing resource management and enhancing user satisfaction across both telecommunication and OTT services. While recent advances predominantly rely on deep learning models, this study introduces a lightweight generative modeling framework that balances computational efficiency, interpretability, and predictive accuracy. By validating the use of Vector Quantization (VQ) as a preprocessing technique, continuous network features are effectively transformed into discrete categorical symbols, enabling integration with a Hidden Markov Model (HMM) for temporal sequence modeling. This VQ-HMM pipeline enhances the model's capacity to capture dynamic QoE patterns while supporting probabilistic inference on new and unseen data. Experimental results on publicly available time-series datasets incorporating both objective indicators and subjective QoE scores demonstrate the viability of this approach in real-time and resource-constrained environments, where inference latency is also critical. The framework offers a scalable alternative to complex deep learning methods, particularly in scenarios with limited computational resources or where latency constraints are critical.</li>
</ul>

<h3>Title: Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing</h3>
<ul>
<li><strong>Authors: </strong>Hong Zhang, Zhongjie Duan, Xingjun Wang, Yingda Chen, Yuze Zhao, Yu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21356">https://arxiv.org/abs/2504.21356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21356">https://arxiv.org/pdf/2504.21356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21356]] Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing(https://arxiv.org/abs/2504.21356)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Unified multimodal large language models (MLLMs) aim to integrate multimodal understanding and generation abilities through a single framework. Despite their versatility, existing open-source unified models exhibit performance gaps against domain-specific architectures. To bridge this gap, we present Nexus-Gen, a unified model that synergizes the language reasoning capabilities of LLMs with the image synthesis power of diffusion models. To align the embedding space of the LLM and diffusion model, we conduct a dual-phase alignment training process. (1) The autoregressive LLM learns to predict image embeddings conditioned on multimodal inputs, while (2) the vision decoder is trained to reconstruct high-fidelity images from these embeddings. During training the LLM, we identified a critical discrepancy between the autoregressive paradigm's training and inference phases, where error accumulation in continuous embedding space severely degrades generation quality. To avoid this issue, we introduce a prefilled autoregression strategy that prefills input sequence with position-embedded special tokens instead of continuous embeddings. Through dual-phase training, Nexus-Gen has developed the integrated capability to comprehensively address the image understanding, generation and editing tasks. All models, datasets, and codes are published at this https URL to facilitate further advancements across the field.</li>
</ul>

<h3>Title: A comparative study of deep learning and ensemble learning to extend the horizon of traffic forecasting</h3>
<ul>
<li><strong>Authors: </strong>Xiao Zheng, Saeed Asadi Bagloee, Majid Sarvi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21358">https://arxiv.org/abs/2504.21358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21358">https://arxiv.org/pdf/2504.21358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21358]] A comparative study of deep learning and ensemble learning to extend the horizon of traffic forecasting(https://arxiv.org/abs/2504.21358)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Traffic forecasting is vital for Intelligent Transportation Systems, for which Machine Learning (ML) methods have been extensively explored to develop data-driven Artificial Intelligence (AI) solutions. Recent research focuses on modelling spatial-temporal correlations for short-term traffic prediction, leaving the favourable long-term forecasting a challenging and open issue. This paper presents a comparative study on large-scale real-world signalized arterials and freeway traffic flow datasets, aiming to evaluate promising ML methods in the context of large forecasting horizons up to 30 days. Focusing on modelling capacity for temporal dynamics, we develop one ensemble ML method, eXtreme Gradient Boosting (XGBoost), and a range of Deep Learning (DL) methods, including Recurrent Neural Network (RNN)-based methods and the state-of-the-art Transformer-based method. Time embedding is leveraged to enhance their understanding of seasonality and event factors. Experimental results highlight that while the attention mechanism/Transformer framework is effective for capturing long-range dependencies in sequential data, as the forecasting horizon extends, the key to effective traffic forecasting gradually shifts from temporal dependency capturing to periodicity modelling. Time embedding is particularly effective in this context, helping naive RNN outperform Informer by 31.1% for 30-day-ahead forecasting. Meanwhile, as an efficient and robust model, XGBoost, while learning solely from time features, performs competitively with DL methods. Moreover, we investigate the impacts of various factors like input sequence length, holiday traffic, data granularity, and training data size. The findings offer valuable insights and serve as a reference for future long-term traffic forecasting research and the improvement of AI's corresponding learning capabilities.</li>
</ul>

<h3>Title: Revisiting Diffusion Autoencoder Training for Image Reconstruction Quality</h3>
<ul>
<li><strong>Authors: </strong>Pramook Khungurn, Sukit Seripanitkarn, Phonphrm Thawatdamrongkit, Supasorn Suwajanakorn</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21368">https://arxiv.org/abs/2504.21368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21368">https://arxiv.org/pdf/2504.21368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21368]] Revisiting Diffusion Autoencoder Training for Image Reconstruction Quality(https://arxiv.org/abs/2504.21368)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion autoencoders (DAEs) are typically formulated as a noise prediction model and trained with a linear-$\beta$ noise schedule that spends much of its sampling steps at high noise levels. Because high noise levels are associated with recovering large-scale image structures and low noise levels with recovering details, this configuration can result in low-quality and blurry images. However, it should be possible to improve details while spending fewer steps recovering structures because the latent code should already contain structural information. Based on this insight, we propose a new DAE training method that improves the quality of reconstructed images. We divide training into two phases. In the first phase, the DAE is trained as a vanilla autoencoder by always setting the noise level to the highest, forcing the encoder and decoder to populate the latent code with structural information. In the second phase, we incorporate a noise schedule that spends more time in the low-noise region, allowing the DAE to learn how to perfect the details. Our method results in images that have accurate high-level structures and low-level details while still preserving useful properties of the latent codes.</li>
</ul>

<h3>Title: Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction</h3>
<ul>
<li><strong>Authors: </strong>Máté Gedeon</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21372">https://arxiv.org/abs/2504.21372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21372">https://arxiv.org/pdf/2504.21372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21372]] Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction(https://arxiv.org/abs/2504.21372)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Speech Event Extraction (SpeechEE) is a challenging task that lies at the intersection of Automatic Speech Recognition (ASR) and Natural Language Processing (NLP), requiring the identification of structured event information from spoken language. In this work, we present a modular, pipeline-based SpeechEE framework that integrates high-performance ASR with semantic search-enhanced prompting of Large Language Models (LLMs). Our system first classifies speech segments likely to contain events using a hybrid filtering mechanism including rule-based, BERT-based, and LLM-based models. It then employs few-shot LLM prompting, dynamically enriched via semantic similarity retrieval, to identify event triggers and extract corresponding arguments. We evaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini) highlighting significant performance gains with o1-mini, which achieves 63.3% F1 on trigger classification and 27.8% F1 on argument classification, outperforming prior benchmarks. Our results demonstrate that pipeline approaches, when empowered by retrieval-augmented LLMs, can rival or exceed end-to-end systems while maintaining interpretability and modularity. This work provides practical insights into LLM-driven event extraction and opens pathways for future hybrid models combining textual and acoustic features.</li>
</ul>

<h3>Title: Synergy-CLIP: Extending CLIP with Multi-modal Integration for Robust Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Sangyeon Cho, Jangyeong Jeon, Mingi Kim, Junyeong Kim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21375">https://arxiv.org/abs/2504.21375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21375">https://arxiv.org/pdf/2504.21375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21375]] Synergy-CLIP: Extending CLIP with Multi-modal Integration for Robust Representation Learning(https://arxiv.org/abs/2504.21375)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-modal representation learning has become a pivotal area in artificial intelligence, enabling the integration of diverse modalities such as vision, text, and audio to solve complex problems. However, existing approaches predominantly focus on bimodal interactions, such as image-text pairs, which limits their ability to fully exploit the richness of multi-modal data. Furthermore, the integration of modalities in equal-scale environments remains underexplored due to the challenges of constructing large-scale, balanced datasets. In this study, we propose Synergy-CLIP, a novel framework that extends the contrastive language-image pre-training (CLIP) architecture to enhance multi-modal representation learning by integrating visual, textual, and audio modalities. Unlike existing methods that focus on adapting individual modalities to vanilla-CLIP, Synergy-CLIP aligns and captures latent information across three modalities equally. To address the high cost of constructing large-scale multi-modal datasets, we introduce VGG-sound+, a triple-modal dataset designed to provide equal-scale representation of visual, textual, and audio data. Synergy-CLIP is validated on various downstream tasks, including zero-shot classification, where it outperforms existing baselines. Additionally, we introduce a missing modality reconstruction task, demonstrating Synergy-CLIP's ability to extract synergy among modalities in realistic application scenarios. These contributions provide a robust foundation for advancing multi-modal representation learning and exploring new research directions.</li>
</ul>

<h3>Title: Sparse-to-Sparse Training of Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Inês Cardoso Oliveira, Decebal Constantin Mocanu, Luis A. Leiva</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21380">https://arxiv.org/abs/2504.21380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21380">https://arxiv.org/pdf/2504.21380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21380]] Sparse-to-Sparse Training of Diffusion Models(https://arxiv.org/abs/2504.21380)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) are a powerful type of generative models that have achieved state-of-the-art results in various image synthesis tasks and have shown potential in other domains, such as natural language processing and temporal data modeling. Despite their stable training dynamics and ability to produce diverse high-quality samples, DMs are notorious for requiring significant computational resources, both in the training and inference stages. Previous work has focused mostly on increasing the efficiency of model inference. This paper introduces, for the first time, the paradigm of sparse-to-sparse training to DMs, with the aim of improving both training and inference efficiency. We focus on unconditional generation and train sparse DMs from scratch (Latent Diffusion and ChiroDiff) on six datasets using three different methods (Static-DM, RigL-DM, and MagRan-DM) to study the effect of sparsity in model performance. Our experiments show that sparse DMs are able to match and often outperform their Dense counterparts, while substantially reducing the number of trainable parameters and FLOPs. We also identify safe and effective values to perform sparse-to-sparse training of DMs.</li>
</ul>

<h3>Title: IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided Diffusion for Real-world Image Dehazing</h3>
<ul>
<li><strong>Authors: </strong>Shijun Zhou, Yajing Liu, Chunhui Hao, Zhiyuan Liu, Jiandong Tian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21385">https://arxiv.org/abs/2504.21385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21385">https://arxiv.org/pdf/2504.21385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21385]] IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided Diffusion for Real-world Image Dehazing(https://arxiv.org/abs/2504.21385)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Due to the domain gap between real-world and synthetic hazy images, current data-driven dehazing algorithms trained on synthetic datasets perform well on synthetic data but struggle to generalize to real-world scenarios. To address this challenge, we propose \textbf{I}mage \textbf{D}ehazing \textbf{D}iffusion \textbf{M}odels (IDDM), a novel diffusion process that incorporates the atmospheric scattering model into noise diffusion. IDDM aims to use the gradual haze formation process to help the denoising Unet robustly learn the distribution of clear images from the conditional input hazy images. We design a specialized training strategy centered around IDDM. Diffusion models are leveraged to bridge the domain gap from synthetic to real-world, while the atmospheric scattering model provides physical guidance for haze formation. During the forward process, IDDM simultaneously introduces haze and noise into clear images, and then robustly separates them during the sampling process. By training with physics-guided information, IDDM shows the ability of domain generalization, and effectively restores the real-world hazy images despite being trained on synthetic datasets. Extensive experiments demonstrate the effectiveness of our method through both quantitative and qualitative comparisons with state-of-the-art approaches.</li>
</ul>

<h3>Title: Comparison of Different Deep Neural Network Models in the Cultural Heritage Domain</h3>
<ul>
<li><strong>Authors: </strong>Teodor Boyadzhiev, Gabriele Lagani, Luca Ciampi, Giuseppe Amato, Krassimira Ivanova</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21387">https://arxiv.org/abs/2504.21387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21387">https://arxiv.org/pdf/2504.21387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21387]] Comparison of Different Deep Neural Network Models in the Cultural Heritage Domain(https://arxiv.org/abs/2504.21387)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The integration of computer vision and deep learning is an essential part of documenting and preserving cultural heritage, as well as improving visitor experiences. In recent years, two deep learning paradigms have been established in the field of computer vision: convolutional neural networks and transformer architectures. The present study aims to make a comparative analysis of some representatives of these two techniques of their ability to transfer knowledge from generic dataset, such as ImageNet, to cultural heritage specific tasks. The results of testing examples of the architectures VGG, ResNet, DenseNet, Visual Transformer, Swin Transformer, and PoolFormer, showed that DenseNet is the best in terms of efficiency-computability ratio.</li>
</ul>

<h3>Title: Enhanced Semi-Supervised Stamping Process Monitoring with Physically-Informed Feature Extraction</h3>
<ul>
<li><strong>Authors: </strong>Jianyu Zhang, Jianshe Feng, Yizhang Zhu, Fanyu Qi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21389">https://arxiv.org/abs/2504.21389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21389">https://arxiv.org/pdf/2504.21389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21389]] Enhanced Semi-Supervised Stamping Process Monitoring with Physically-Informed Feature Extraction(https://arxiv.org/abs/2504.21389)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In tackling frequent anomalies in stamping processes, this study introduces a novel semi-supervised in-process anomaly monitoring framework, utilizing accelerometer signals and physics information, to capture the process anomaly effectively. The proposed framework facilitates the construction of a monitoring model with imbalanced sample distribution, which enables in-process condition monitoring in real-time to prevent batch anomalies, which helps to reduce batch defects risk and enhance production yield. Firstly, to effectively capture key features from raw data containing redundant information, a hybrid feature extraction algorithm is proposed to utilize data-driven methods and physical mechanisms simultaneously. Secondly, to address the challenge brought by imbalanced sample distribution, a semi-supervised anomaly detection model is established, which merely employs normal samples to build a golden baseline model, and a novel deviation score is proposed to quantify the anomaly level of each online stamping stroke. The effectiveness of the proposed feature extraction method is validated with various classification algorithms. A real-world in-process dataset from stamping manufacturing workshop is employed to illustrate the superiority of proposed semi-supervised framework with enhance performance for process anomaly monitoring.</li>
</ul>

<h3>Title: An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and Applications to Streaming Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>H. Brendan McMahan, Krishna Pillutla</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21413">https://arxiv.org/abs/2504.21413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21413">https://arxiv.org/pdf/2504.21413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21413]] An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and Applications to Streaming Differential Privacy(https://arxiv.org/abs/2504.21413)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Buffered Linear Toeplitz (BLT) matrices are a family of parameterized lower-triangular matrices that play an important role in streaming differential privacy with correlated noise. Our main result is a BLT inversion theorem: the inverse of a BLT matrix is itself a BLT matrix with different parameters. We also present an efficient and differentiable $O(d^3)$ algorithm to compute the parameters of the inverse BLT matrix, where $d$ is the degree of the original BLT (typically $d < 10$). Our characterization enables direct optimization of BLT parameters for privacy mechanisms through automatic differentiation.</li>
</ul>

<h3>Title: Adapting In-Domain Few-Shot Segmentation to New Domains without Retraining</h3>
<ul>
<li><strong>Authors: </strong>Qi Fan, Kaiqi Liu, Nian Liu, Hisham Cholakkal, Rao Muhammad Anwer, Wenbin Li, Yang Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21414">https://arxiv.org/abs/2504.21414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21414">https://arxiv.org/pdf/2504.21414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21414]] Adapting In-Domain Few-Shot Segmentation to New Domains without Retraining(https://arxiv.org/abs/2504.21414)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Cross-domain few-shot segmentation (CD-FSS) aims to segment objects of novel classes in new domains, which is often challenging due to the diverse characteristics of target domains and the limited availability of support data. Most CD-FSS methods redesign and retrain in-domain FSS models using various domain-generalization techniques, which are effective but costly to train. To address these issues, we propose adapting informative model structures of the well-trained FSS model for target domains by learning domain characteristics from few-shot labeled support samples during inference, thereby eliminating the need for retraining. Specifically, we first adaptively identify domain-specific model structures by measuring parameter importance using a novel structure Fisher score in a data-dependent manner. Then, we progressively train the selected informative model structures with hierarchically constructed training samples, progressing from fewer to more support shots. The resulting Informative Structure Adaptation (ISA) method effectively addresses domain shifts and equips existing well-trained in-domain FSS models with flexible adaptation capabilities for new domains, eliminating the need to redesign or retrain CD-FSS models on base data. Extensive experiments validate the effectiveness of our method, demonstrating superior performance across multiple CD-FSS benchmarks.</li>
</ul>

<h3>Title: Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges</h3>
<ul>
<li><strong>Authors: </strong>Yi Wang, Chengyv Wu, Yang Liao, Maowei You</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21415">https://arxiv.org/abs/2504.21415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21415">https://arxiv.org/pdf/2504.21415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21415]] Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges(https://arxiv.org/abs/2504.21415)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, extraction</a></li>
<li><strong>Abstract: </strong>User authentication is essential to ensure secure access to computer systems, yet traditional methods face limitations in usability, cost, and security. Mouse dynamics authentication, based on the analysis of users' natural interaction behaviors with mouse devices, offers a cost-effective, non-intrusive, and adaptable solution. However, challenges remain in determining the optimal data volume, balancing accuracy and practicality, and effectively capturing temporal behavioral patterns. In this study, we propose a statistical method using Gaussian kernel density estimate (KDE) and Kullback-Leibler (KL) divergence to estimate the sufficient data volume for training authentication models. We introduce the Mouse Authentication Unit (MAU), leveraging Approximate Entropy (ApEn) to optimize segment length for efficient and accurate behavioral representation. Furthermore, we design the Local-Time Mouse Authentication (LT-AMouse) framework, integrating 1D-ResNet for local feature extraction and GRU for modeling long-term temporal dependencies. Taking the Balabit and DFL datasets as examples, we significantly reduced the data scale, particularly by a factor of 10 for the DFL dataset, greatly alleviating the training burden. Additionally, we determined the optimal input recognition unit length for the user authentication system on different datasets based on the slope of Approximate Entropy. Training with imbalanced samples, our model achieved a successful defense AUC 98.52% for blind attack on the DFL dataset and 94.65% on the Balabit dataset, surpassing the current sota performance.</li>
</ul>

<h3>Title: Diff-Prompt: Diffusion-Driven Prompt Generator with Mask Supervision</h3>
<ul>
<li><strong>Authors: </strong>Weicai Yan, Wang Lin, Zirun Guo, Ye Wang, Fangming Feng, Xiaoda Yang, Zehan Wang, Tao Jin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21423">https://arxiv.org/abs/2504.21423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21423">https://arxiv.org/pdf/2504.21423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21423]] Diff-Prompt: Diffusion-Driven Prompt Generator with Mask Supervision(https://arxiv.org/abs/2504.21423)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Prompt learning has demonstrated promising results in fine-tuning pre-trained multimodal models. However, the performance improvement is limited when applied to more complex and fine-grained tasks. The reason is that most existing methods directly optimize the parameters involved in the prompt generation process through loss backpropagation, which constrains the richness and specificity of the prompt representations. In this paper, we propose Diffusion-Driven Prompt Generator (Diff-Prompt), aiming to use the diffusion model to generate rich and fine-grained prompt information for complex downstream tasks. Specifically, our approach consists of three stages. In the first stage, we train a Mask-VAE to compress the masks into latent space. In the second stage, we leverage an improved Diffusion Transformer (DiT) to train a prompt generator in the latent space, using the masks for supervision. In the third stage, we align the denoising process of the prompt generator with the pre-trained model in the semantic space, and use the generated prompts to fine-tune the model. We conduct experiments on a complex pixel-level downstream task, referring expression comprehension, and compare our method with various parameter-efficient fine-tuning approaches. Diff-Prompt achieves a maximum improvement of 8.87 in R@1 and 14.05 in R@5 compared to the foundation model and also outperforms other state-of-the-art methods across multiple metrics. The experimental results validate the effectiveness of our approach and highlight the potential of using generative models for prompt generation. Code is available at this https URL.</li>
</ul>

<h3>Title: SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding</h3>
<ul>
<li><strong>Authors: </strong>Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, ShaoGuo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21435">https://arxiv.org/abs/2504.21435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21435">https://arxiv.org/pdf/2504.21435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21435]] SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding(https://arxiv.org/abs/2504.21435)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid development of Multi-modal Large Language Models (MLLMs), an increasing number of benchmarks have been established to evaluate the video understanding capabilities of these models. However, these benchmarks focus on \textbf{standalone} videos and mainly assess ``visual elements'' like human actions and object states. In reality, contemporary videos often encompass complex and continuous narratives, typically presented as a \textbf{series}. To address this challenge, we propose \textbf{SeriesBench}, a benchmark consisting of 105 carefully curated narrative-driven series, covering 28 specialized tasks that require deep narrative understanding. Specifically, we first select a diverse set of drama series spanning various genres. Then, we introduce a novel long-span narrative annotation method, combined with a full-information transformation approach to convert manual annotations into diverse task formats. To further enhance model capacity for detailed analysis of plot structures and character relationships within series, we propose a novel narrative reasoning framework, \textbf{PC-DCoT}. Extensive results on \textbf{SeriesBench} indicate that existing MLLMs still face significant challenges in understanding narrative-driven series, while \textbf{PC-DCoT} enables these MLLMs to achieve performance improvements. Overall, our \textbf{SeriesBench} and \textbf{PC-DCoT} highlight the critical necessity of advancing model capabilities to understand narrative-driven series, guiding the future development of MLLMs. SeriesBench is publicly available at this https URL.</li>
</ul>

<h3>Title: Whispers of Data: Unveiling Label Distributions in Federated Learning Through Virtual Client Simulation</h3>
<ul>
<li><strong>Authors: </strong>Zhixuan Ma, Haichang Gao, Junxiang Huang, Ping Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21436">https://arxiv.org/abs/2504.21436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21436">https://arxiv.org/pdf/2504.21436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21436]] Whispers of Data: Unveiling Label Distributions in Federated Learning Through Virtual Client Simulation(https://arxiv.org/abs/2504.21436)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning enables collaborative training of a global model across multiple geographically dispersed clients without the need for data sharing. However, it is susceptible to inference attacks, particularly label inference attacks. Existing studies on label distribution inference exhibits sensitive to the specific settings of the victim client and typically underperforms under defensive strategies. In this study, we propose a novel label distribution inference attack that is stable and adaptable to various scenarios. Specifically, we estimate the size of the victim client's dataset and construct several virtual clients tailored to the victim client. We then quantify the temporal generalization of each class label for the virtual clients and utilize the variation in temporal generalization to train an inference model that predicts the label distribution proportions of the victim client. We validate our approach on multiple datasets, including MNIST, Fashion-MNIST, FER2013, and AG-News. The results demonstrate the superiority of our method compared to state-of-the-art techniques. Furthermore, our attack remains effective even under differential privacy defense mechanisms, underscoring its potential for real-world applications.</li>
</ul>

<h3>Title: Rethinking Visual Layer Selection in Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Haoran Chen, Junyan Lin, Xinhao Chen, Yue Fan, Xin Jin, Hui Su, Jianfeng Dong, Jinlan Fu, Xiaoyu Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21447">https://arxiv.org/abs/2504.21447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21447">https://arxiv.org/pdf/2504.21447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21447]] Rethinking Visual Layer Selection in Multimodal LLMs(https://arxiv.org/abs/2504.21447)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have achieved impressive performance across a wide range of tasks, typically using CLIP-ViT as their visual encoder due to its strong text-image alignment capabilities. While prior studies suggest that different CLIP-ViT layers capture different types of information, with shallower layers focusing on fine visual details and deeper layers aligning more closely with textual semantics, most MLLMs still select visual features based on empirical heuristics rather than systematic analysis. In this work, we propose a Layer-wise Representation Similarity approach to group CLIP-ViT layers with similar behaviors into {shallow, middle, and deep} categories and assess their impact on MLLM performance. Building on this foundation, we revisit the visual layer selection problem in MLLMs at scale, training LLaVA-style models ranging from 1.4B to 7B parameters. Through extensive experiments across 10 datasets and 4 tasks, we find that: (1) deep layers are essential for OCR tasks; (2) shallow and middle layers substantially outperform deep layers on reasoning tasks involving counting, positioning, and object localization; (3) a lightweight fusion of features across shallow, middle, and deep layers consistently outperforms specialized fusion baselines and single-layer selections, achieving gains on 9 out of 10 datasets. Our work offers the first principled study of visual layer selection in MLLMs, laying the groundwork for deeper investigations into visual representation learning for MLLMs.</li>
</ul>

<h3>Title: xEEGNet: Towards Explainable AI in EEG Dementia Classification</h3>
<ul>
<li><strong>Authors: </strong>Andrea Zanola, Louis Fabrice Tshimanga, Federico Del Pup, Marco Baiesi, Manfredo Atzori</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21457">https://arxiv.org/abs/2504.21457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21457">https://arxiv.org/pdf/2504.21457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21457]] xEEGNet: Towards Explainable AI in EEG Dementia Classification(https://arxiv.org/abs/2504.21457)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>This work presents xEEGNet, a novel, compact, and explainable neural network for EEG data analysis. It is fully interpretable and reduces overfitting through major parameter reduction. As an applicative use case, we focused on classifying common dementia conditions, Alzheimer's and frontotemporal dementia, versus controls. xEEGNet is broadly applicable to other neurological conditions involving spectral alterations. We initially used ShallowNet, a simple and popular model from the EEGNet-family. Its structure was analyzed and gradually modified to move from a "black box" to a more transparent model, without compromising performance. The learned kernels and weights were examined from a clinical standpoint to assess medical relevance. Model variants, including ShallowNet and the final xEEGNet, were evaluated using robust Nested-Leave-N-Subjects-Out cross-validation for unbiased performance estimates. Variability across data splits was explained using embedded EEG representations, grouped by class and set, with pairwise separability to quantify group distinction. Overfitting was assessed through training-validation loss correlation and training speed. xEEGNet uses only 168 parameters, 200 times fewer than ShallowNet, yet retains interpretability, resists overfitting, achieves comparable median performance (-1.5%), and reduces variability across splits. This variability is explained by embedded EEG representations: higher accuracy correlates with greater separation between test set controls and Alzheimer's cases, without significant influence from training data. xEEGNet's ability to filter specific EEG bands, learn band-specific topographies, and use relevant spectral features demonstrates its interpretability. While large deep learning models are often prioritized for performance, this study shows smaller architectures like xEEGNet can be equally effective in EEG pathology classification.</li>
</ul>

<h3>Title: VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep Network for Diabetic Retinopathy Classification</h3>
<ul>
<li><strong>Authors: </strong>Shamim Rahim Refat, Ziyan Shirin Raha, Shuvashis Sarker, Faika Fairuj Preotee, MD. Musfikur Rahman, Tashreef Muhammad, Mohammad Shafiul Islam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21464">https://arxiv.org/abs/2504.21464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21464">https://arxiv.org/pdf/2504.21464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21464]] VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep Network for Diabetic Retinopathy Classification(https://arxiv.org/abs/2504.21464)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Diabetic retinopathy is a severe eye condition caused by diabetes where the retinal blood vessels get damaged and can lead to vision loss and blindness if not treated. Early and accurate detection is key to intervention and stopping the disease progressing. For addressing this disease properly, this paper presents a comprehensive approach for automated diabetic retinopathy detection by proposing a new hybrid deep learning model called VR-FuseNet. Diabetic retinopathy is a major eye disease and leading cause of blindness especially among diabetic patients so accurate and efficient automated detection methods are required. To address the limitations of existing methods including dataset imbalance, diversity and generalization issues this paper presents a hybrid dataset created from five publicly available diabetic retinopathy datasets. Essential preprocessing techniques such as SMOTE for class balancing and CLAHE for image enhancement are applied systematically to the dataset to improve the robustness and generalizability of the dataset. The proposed VR-FuseNet model combines the strengths of two state-of-the-art convolutional neural networks, VGG19 which captures fine-grained spatial features and ResNet50V2 which is known for its deep hierarchical feature extraction. This fusion improves the diagnostic performance and achieves an accuracy of 91.824%. The model outperforms individual architectures on all performance metrics demonstrating the effectiveness of hybrid feature extraction in Diabetic Retinopathy classification tasks. To make the proposed model more clinically useful and interpretable this paper incorporates multiple XAI techniques. These techniques generate visual explanations that clearly indicate the retinal features affecting the model's prediction such as microaneurysms, hemorrhages and exudates so that clinicians can interpret and validate.</li>
</ul>

<h3>Title: Multiview Point Cloud Registration via Optimization in an Autoencoder Latent Space</h3>
<ul>
<li><strong>Authors: </strong>Luc Vedrenne, Sylvain Faisan, Denis Fortun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21467">https://arxiv.org/abs/2504.21467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21467">https://arxiv.org/pdf/2504.21467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21467]] Multiview Point Cloud Registration via Optimization in an Autoencoder Latent Space(https://arxiv.org/abs/2504.21467)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Point cloud rigid registration is a fundamental problem in 3D computer vision. In the multiview case, we aim to find a set of 6D poses to align a set of objects. Methods based on pairwise registration rely on a subsequent synchronization algorithm, which makes them poorly scalable with the number of views. Generative approaches overcome this limitation, but are based on Gaussian Mixture Models and use an Expectation-Maximization algorithm. Hence, they are not well suited to handle large transformations. Moreover, most existing methods cannot handle high levels of degradations. In this paper, we introduce POLAR (POint cloud LAtent Registration), a multiview registration method able to efficiently deal with a large number of views, while being robust to a high level of degradations and large initial angles. To achieve this, we transpose the registration problem into the latent space of a pretrained autoencoder, design a loss taking degradations into account, and develop an efficient multistart optimization strategy. Our proposed method significantly outperforms state-of-the-art approaches on synthetic and real data. POLAR is available at this http URL or as a standalone package which can be installed with pip install polaregistration.</li>
</ul>

<h3>Title: Quaternion Nuclear Norms Over Frobenius Norms Minimization for Robust Matrix Completion</h3>
<ul>
<li><strong>Authors: </strong>Yu Guo, Guoqing Chen, Tieyong Zeng, Qiyu Jin, Michael Kwok-Po Ng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21468">https://arxiv.org/abs/2504.21468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21468">https://arxiv.org/pdf/2504.21468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21468]] Quaternion Nuclear Norms Over Frobenius Norms Minimization for Robust Matrix Completion(https://arxiv.org/abs/2504.21468)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recovering hidden structures from incomplete or noisy data remains a pervasive challenge across many fields, particularly where multi-dimensional data representation is essential. Quaternion matrices, with their ability to naturally model multi-dimensional data, offer a promising framework for this problem. This paper introduces the quaternion nuclear norm over the Frobenius norm (QNOF) as a novel nonconvex approximation for the rank of quaternion matrices. QNOF is parameter-free and scale-invariant. Utilizing quaternion singular value decomposition, we prove that solving the QNOF can be simplified to solving the singular value $L_1/L_2$ problem. Additionally, we extend the QNOF to robust quaternion matrix completion, employing the alternating direction multiplier method to derive solutions that guarantee weak convergence under mild conditions. Extensive numerical experiments validate the proposed model's superiority, consistently outperforming state-of-the-art quaternion methods.</li>
</ul>

<h3>Title: Robust Orthogonal NMF with Label Propagation for Image Clustering</h3>
<ul>
<li><strong>Authors: </strong>Jingjing Liu, Nian Wu, Xianchao Xiu, Jianhua Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21472">https://arxiv.org/abs/2504.21472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21472">https://arxiv.org/pdf/2504.21472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21472]] Robust Orthogonal NMF with Label Propagation for Image Clustering(https://arxiv.org/abs/2504.21472)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Non-negative matrix factorization (NMF) is a popular unsupervised learning approach widely used in image clustering. However, in real-world clustering scenarios, most existing NMF methods are highly sensitive to noise corruption and are unable to effectively leverage limited supervised information. To overcome these drawbacks, we propose a unified non-convex framework with label propagation called robust orthogonal nonnegative matrix factorization (RONMF). This method not only considers the graph Laplacian and label propagation as regularization terms but also introduces a more effective non-convex structure to measure the reconstruction error and imposes orthogonal constraints on the basis matrix to reduce the noise corruption, thereby achieving higher robustness. To solve RONMF, we develop an alternating direction method of multipliers (ADMM)-based optimization algorithm. In particular, all subproblems have closed-form solutions, which ensures its efficiency. Experimental evaluations on eight public image datasets demonstrate that the proposed RONMF outperforms state-of-the-art NMF methods across various standard metrics and shows excellent robustness. The code will be available at this https URL.</li>
</ul>

<h3>Title: Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines</h3>
<ul>
<li><strong>Authors: </strong>Serry Sibaee, Samar Ahmed, Abdullah Al Harbi, Omer Nacar, Adel Ammar, Yasser Habashi, Wadii Boulila</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21475">https://arxiv.org/abs/2504.21475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21475">https://arxiv.org/pdf/2504.21475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21475]] Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines(https://arxiv.org/abs/2504.21475)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study addresses the critical gap in Arabic natural language processing by developing an effective Arabic Reverse Dictionary (RD) system that enables users to find words based on their descriptions or meanings. We present a novel transformer-based approach with a semi-encoder neural network architecture featuring geometrically decreasing layers that achieves state-of-the-art results for Arabic RD tasks. Our methodology incorporates a comprehensive dataset construction process and establishes formal quality standards for Arabic lexicographic definitions. Experiments with various pre-trained models demonstrate that Arabic-specific models significantly outperform general multilingual embeddings, with ARBERTv2 achieving the best ranking score (0.0644). Additionally, we provide a formal abstraction of the reverse dictionary task that enhances theoretical understanding and develop a modular, extensible Python library (RDTL) with configurable training pipelines. Our analysis of dataset quality reveals important insights for improving Arabic definition construction, leading to eight specific standards for building high-quality reverse dictionary resources. This work contributes significantly to Arabic computational linguistics and provides valuable tools for language learning, academic writing, and professional communication in Arabic.</li>
</ul>

<h3>Title: GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Li, Qi Yao, Yuanda Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21476">https://arxiv.org/abs/2504.21476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21476">https://arxiv.org/pdf/2504.21476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21476]] GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers(https://arxiv.org/abs/2504.21476)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Garment sewing patterns are fundamental design elements that bridge the gap between design concepts and practical manufacturing. The generative modeling of sewing patterns is crucial for creating diversified garments. However, existing approaches are limited either by reliance on a single input modality or by suboptimal generation efficiency. In this work, we present \textbf{\textit{GarmentDiffusion}}, a new generative model capable of producing centimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text, image, and incomplete sewing pattern). Our method efficiently encodes 3D sewing pattern parameters into compact edge token representations, achieving a sequence length that is $\textbf{10}\times$ shorter than that of the autoregressive SewingGPT in DressCode. By employing a diffusion transformer, we simultaneously denoise all edge tokens along the temporal axis, while maintaining a constant number of denoising steps regardless of dataset-specific edge and panel statistics. With all combination of designs of our model, the sewing pattern generation speed is accelerated by $\textbf{100}\times$ compared to SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well as on the largest sewing pattern dataset, namely GarmentCodeData. The project website is available at this https URL.</li>
</ul>

<h3>Title: CAE-DFKD: Bridging the Transferability Gap in Data-Free Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Zherui Zhang, Changwei Wang, Rongtao Xu, Wenhao Xu, Shibiao Xu, Yu Zhang, Li Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21478">https://arxiv.org/abs/2504.21478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21478">https://arxiv.org/pdf/2504.21478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21478]] CAE-DFKD: Bridging the Transferability Gap in Data-Free Knowledge Distillation(https://arxiv.org/abs/2504.21478)</code><input type="text"></li>
<li><strong>Keywords: </strong>data-free</a></li>
<li><strong>Abstract: </strong>Data-Free Knowledge Distillation (DFKD) enables the knowledge transfer from the given pre-trained teacher network to the target student model without access to the real training data. Existing DFKD methods focus primarily on improving image recognition performance on associated datasets, often neglecting the crucial aspect of the transferability of learned representations. In this paper, we propose Category-Aware Embedding Data-Free Knowledge Distillation (CAE-DFKD), which addresses at the embedding level the limitations of previous rely on image-level methods to improve model generalization but fail when directly applied to DFKD. The superiority and flexibility of CAE-DFKD are extensively evaluated, including: \textit{\textbf{i.)}} Significant efficiency advantages resulting from altering the generator training paradigm; \textit{\textbf{ii.)}} Competitive performance with existing DFKD state-of-the-art methods on image recognition tasks; \textit{\textbf{iii.)}} Remarkable transferability of data-free learned representations demonstrated in downstream tasks.</li>
</ul>

<h3>Title: A Comprehensive Study of Exploitable Patterns in Smart Contracts: From Vulnerability to Defense</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Ding, Hongli Peng, Xiaoqi Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21480">https://arxiv.org/abs/2504.21480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21480">https://arxiv.org/pdf/2504.21480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21480]] A Comprehensive Study of Exploitable Patterns in Smart Contracts: From Vulnerability to Defense(https://arxiv.org/abs/2504.21480)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of blockchain technology, smart contracts have enabled the implementation of increasingly complex functionalities. However, ensuring the security of smart contracts remains a persistent challenge across the stages of development, compilation, and execution. Vulnerabilities within smart contracts not only undermine the security of individual applications but also pose significant risks to the broader blockchain ecosystem, as demonstrated by the growing frequency of attacks since 2016, resulting in substantial financial losses. This paper provides a comprehensive analysis of key security risks in Ethereum smart contracts, specifically those written in Solidity and executed on the Ethereum Virtual Machine (EVM). We focus on two prevalent and critical vulnerability types (reentrancy and integer overflow) by examining their underlying mechanisms, replicating attack scenarios, and assessing effective countermeasures.</li>
</ul>

<h3>Title: DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling for Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Hebaixu Wang, Jing Zhang, Haonan Guo, Di Wang, Jiayi Ma, Bo Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21487">https://arxiv.org/abs/2504.21487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21487">https://arxiv.org/pdf/2504.21487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21487]] DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling for Image Restoration(https://arxiv.org/abs/2504.21487)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved remarkable progress in universal image restoration. While existing methods speed up inference by reducing sampling steps, substantial step intervals often introduce cumulative errors. Moreover, they struggle to balance the commonality of degradation representations and restoration quality. To address these challenges, we introduce \textbf{DGSolver}, a diffusion generalist solver with universal posterior sampling. We first derive the exact ordinary differential equations for generalist diffusion models and tailor high-order solvers with a queue-based accelerated sampling strategy to improve both accuracy and efficiency. We then integrate universal posterior sampling to better approximate manifold-constrained gradients, yielding a more accurate noise estimation and correcting errors in inverse inference. Extensive experiments show that DGSolver outperforms state-of-the-art methods in restoration accuracy, stability, and scalability, both qualitatively and quantitatively. Code and models will be available at this https URL.</li>
</ul>

<h3>Title: ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic Segmentation of Remote Sensing Imagery</h3>
<ul>
<li><strong>Authors: </strong>Qinfeng Zhu, Yunxi Jiang, Lei Fan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21491">https://arxiv.org/abs/2504.21491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21491">https://arxiv.org/pdf/2504.21491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21491]] ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic Segmentation of Remote Sensing Imagery(https://arxiv.org/abs/2504.21491)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We propose a result-level category-specific fusion architecture called ClassWise-CRF. This architecture employs a two-stage process: first, it selects expert networks that perform well in specific categories from a pool of candidate networks using a greedy algorithm; second, it integrates the segmentation predictions of these selected networks by adaptively weighting their contributions based on their segmentation performance in each category. Inspired by Conditional Random Field (CRF), the ClassWise-CRF architecture treats the segmentation predictions from multiple networks as confidence vector fields. It leverages segmentation metrics (such as Intersection over Union) from the validation set as priors and employs an exponential weighting strategy to fuse the category-specific confidence scores predicted by each network. This fusion method dynamically adjusts the weights of each network for different categories, achieving category-specific optimization. Building on this, the architecture further optimizes the fused results using unary and pairwise potentials in CRF to ensure spatial consistency and boundary accuracy. To validate the effectiveness of ClassWise-CRF, we conducted experiments on two remote sensing datasets, LoveDA and Vaihingen, using eight classic and advanced semantic segmentation networks. The results show that the ClassWise-CRF architecture significantly improves segmentation performance: on the LoveDA dataset, the mean Intersection over Union (mIoU) metric increased by 1.00% on the validation set and by 0.68% on the test set; on the Vaihingen dataset, the mIoU improved by 0.87% on the validation set and by 0.91% on the test set. These results fully demonstrate the effectiveness and generality of the ClassWise-CRF architecture in semantic segmentation of remote sensing images. The full code is available at this https URL.</li>
</ul>

<h3>Title: Consistency-aware Fake Videos Detection on Short Video Platforms</h3>
<ul>
<li><strong>Authors: </strong>Junxi Wang, Jize liu, Na Zhang, Yaxiong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21495">https://arxiv.org/abs/2504.21495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21495">https://arxiv.org/pdf/2504.21495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21495]] Consistency-aware Fake Videos Detection on Short Video Platforms(https://arxiv.org/abs/2504.21495)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This paper focuses to detect the fake news on the short video platforms. While significant research efforts have been devoted to this task with notable progress in recent years, current detection accuracy remains suboptimal due to the rapid evolution of content manipulation and generation technologies. Existing approaches typically employ a cross-modal fusion strategy that directly combines raw video data with metadata inputs before applying a classification layer. However, our empirical observations reveal a critical oversight: manipulated content frequently exhibits inter-modal inconsistencies that could serve as valuable discriminative features, yet remain underutilized in contemporary detection frameworks. Motivated by this insight, we propose a novel detection paradigm that explicitly identifies and leverages cross-modal contradictions as discriminative cues. Our approach consists of two core modules: Cross-modal Consistency Learning (CMCL) and Multi-modal Collaborative Diagnosis (MMCD). CMCL includes Pseudo-label Generation (PLG) and Cross-modal Consistency Diagnosis (CMCD). In PLG, a Multimodal Large Language Model is used to generate pseudo-labels for evaluating cross-modal semantic consistency. Then, CMCD extracts [CLS] tokens and computes cosine loss to quantify cross-modal inconsistencies. MMCD further integrates multimodal features through Multimodal Feature Fusion (MFF) and Probability Scores Fusion (PSF). MFF employs a co-attention mechanism to enhance semantic interactions across different modalities, while a Transformer is utilized for comprehensive feature fusion. Meanwhile, PSF further integrates the fake news probability scores obtained in the previous step. Extensive experiments on established benchmarks (FakeSV and FakeTT) demonstrate our model exhibits outstanding performance in Fake videos detection.</li>
</ul>

<h3>Title: MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance</h3>
<ul>
<li><strong>Authors: </strong>Mengting Wei, Yante Li, Tuomas Varanka, Yan Jiang, Licai Sun, Guoying Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21497">https://arxiv.org/abs/2504.21497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21497">https://arxiv.org/pdf/2504.21497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21497]] MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance(https://arxiv.org/abs/2504.21497)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a method for video face reenactment that integrates a 3D face parametric model into a latent diffusion framework, aiming to improve shape consistency and motion control in existing video-based face generation approaches. Our approach employs the FLAME (Faces Learned with an Articulated Model and Expressions) model as the 3D face parametric representation, providing a unified framework for modeling face expressions and head pose. This enables precise extraction of detailed face geometry and motion features from driving videos. Specifically, we enhance the latent diffusion model with rich 3D expression and detailed pose information by incorporating depth maps, normal maps, and rendering maps derived from FLAME sequences. A multi-layer face movements fusion module with integrated self-attention mechanisms is used to combine identity and motion latent features within the spatial domain. By utilizing the 3D face parametric model as motion guidance, our method enables parametric alignment of face identity between the reference image and the motion captured from the driving video. Experimental results on benchmark datasets show that our method excels at generating high-quality face animations with precise expression and head pose variation modeling. In addition, it demonstrates strong generalization performance on out-of-domain images. Code is publicly available at this https URL.</li>
</ul>

<h3>Title: Deep Learning Optimization Using Self-Adaptive Weighted Auxiliary Variables</h3>
<ul>
<li><strong>Authors: </strong>Yaru Liu, Yiqi Gu, Michael K. Ng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21501">https://arxiv.org/abs/2504.21501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21501">https://arxiv.org/pdf/2504.21501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21501]] Deep Learning Optimization Using Self-Adaptive Weighted Auxiliary Variables(https://arxiv.org/abs/2504.21501)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we develop a new optimization framework for the least squares learning problem via fully connected neural networks or physics-informed neural networks. The gradient descent sometimes behaves inefficiently in deep learning because of the high non-convexity of loss functions and the vanishing gradient issue. Our idea is to introduce auxiliary variables to separate the layers of the deep neural networks and reformulate the loss functions for ease of optimization. We design the self-adaptive weights to preserve the consistency between the reformulated loss and the original mean squared loss, which guarantees that optimizing the new loss helps optimize the original problem. Numerical experiments are presented to verify the consistency and show the effectiveness and robustness of our models over gradient descent.</li>
</ul>

<h3>Title: Confidential Serverless Computing</h3>
<ul>
<li><strong>Authors: </strong>Patrick Sabanic (1), Masanori Misono (1), Teofil Bodea (1), Julian Pritzi (1), Michael Hackl (1), Dimitrios Stavrakakis (1), Pramod Bhatotia (1) ((1) Technical University of Munich)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.OS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21518">https://arxiv.org/abs/2504.21518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21518">https://arxiv.org/pdf/2504.21518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21518]] Confidential Serverless Computing(https://arxiv.org/abs/2504.21518)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Although serverless computing offers compelling cost and deployment simplicity advantages, a significant challenge remains in securely managing sensitive data as it flows through the network of ephemeral function executions in serverless computing environments within untrusted clouds. While Confidential Virtual Machines (CVMs) offer a promising secure execution environment, their integration with serverless architectures currently faces fundamental limitations in key areas: security, performance, and resource efficiency. We present Hacher, a confidential computing system for secure serverless deployments to overcome these limitations. By employing nested confidential execution and a decoupled guest OS within CVMs, Hacher runs each function in a minimal "trustlet", significantly improving security through a reduced Trusted Computing Base (TCB). Furthermore, by leveraging a data-centric I/O architecture built upon a lightweight LibOS, Hacher optimizes network communication to address performance and resource efficiency challenges. Our evaluation shows that compared to CVM-based deployments, Hacher has 4.3x smaller TCB, improves end-to-end latency (15-93%), achieves higher function density (up to 907x), and reduces inter-function communication (up to 27x) and function chaining latency (16.7-30.2x); thus, Hacher offers a practical system for confidential serverless computing.</li>
</ul>

<h3>Title: Padding Matters -- Exploring Function Detection in PE Files</h3>
<ul>
<li><strong>Authors: </strong>Raphael Springer, Alexander Schmitz, Artur Leinweber, Tobias Urban, Christian Dietrich</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21520">https://arxiv.org/abs/2504.21520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21520">https://arxiv.org/pdf/2504.21520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21520]] Padding Matters -- Exploring Function Detection in PE Files(https://arxiv.org/abs/2504.21520)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Function detection is a well-known problem in binary analysis. While previous research has primarily focused on Linux/ELF, Windows/PE binaries have been overlooked or only partially considered. This paper introduces FuncPEval, a new dataset for Windows x86 and x64 PE files, featuring Chromium and the Conti ransomware, along with ground truth data for 1,092,820 function starts. Utilizing FuncPEval, we evaluate five heuristics-based (Ghidra, IDA, Nucleus, this http URL, SMDA) and three machine-learning-based (DeepDi, RNN, XDA) function start detection tools. Among the tested tools, IDA achieves the highest F1-score (98.44%) for Chromium x64, while DeepDi closely follows (97%) but stands out as the fastest by a significant margin. Working towards explainability, we examine the impact of padding between functions on the detection results. Our analysis shows that all tested tools, except this http URL, are susceptible to randomized padding. The randomized padding significantly diminishes the effectiveness for the RNN, XDA, and Nucleus. Among the learning-based tools, DeepDi exhibits the least sensitivity and demonstrates overall the fastest performance, while Nucleus is the most adversely affected among non-learning-based tools. In addition, we improve the recurrent neural network (RNN) proposed by Shin et al. and enhance the XDA tool, increasing the F1-score by approximately 10%.</li>
</ul>

<h3>Title: CryptoUNets: Applying Convolutional Networks to Encrypted Data for Biomedical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>John Chiang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21543">https://arxiv.org/abs/2504.21543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21543">https://arxiv.org/pdf/2504.21543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21543]] CryptoUNets: Applying Convolutional Networks to Encrypted Data for Biomedical Image Segmentation(https://arxiv.org/abs/2504.21543)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, segmentation</a></li>
<li><strong>Abstract: </strong>In this manuscript, we demonstrate the feasibility of a privacy-preserving U-Net deep learning inference framework, namely, homomorphic encryption-based U-Net inference. That is, U-Net inference can be performed solely using homomorphic encryption techniques. To our knowledge, this is the first work to achieve support perform implement enable U-Net inference entirely based on homomorphic encryption ?. The primary technical challenge lies in data encoding. To address this, we employ a flexible encoding scheme, termed Double Volley Revolver, which enables effective support for skip connections and upsampling operations within the U-Net architecture. We adopt a tailored HE-friendly U-Net design incorporating square activation functions, mean pooling layers, and transposed convolution layers (implemented as ConvTranspose2d in PyTorch) with a kernel size of 2 and stride of 2. After training the model in plaintext, we deploy the resulting parameters using the HEAAN homomorphic encryption library to perform encrypted U-Net inference.</li>
</ul>

<h3>Title: SAM4EM: Efficient memory-based two stage prompt-free segment anything model adapter for complex 3D neuroscience electron microscopy stacks</h3>
<ul>
<li><strong>Authors: </strong>Uzair Shah, Marco Agus, Daniya Boges, Vanessa Chiappini, Mahmood Alzubaidi, Jens Schneider, Markus Hadwiger, Pierre J. Magistretti, Mowafa Househ, Corrado Calı</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21544">https://arxiv.org/abs/2504.21544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21544">https://arxiv.org/pdf/2504.21544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21544]] SAM4EM: Efficient memory-based two stage prompt-free segment anything model adapter for complex 3D neuroscience electron microscopy stacks(https://arxiv.org/abs/2504.21544)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>We present SAM4EM, a novel approach for 3D segmentation of complex neural structures in electron microscopy (EM) data by leveraging the Segment Anything Model (SAM) alongside advanced fine-tuning strategies. Our contributions include the development of a prompt-free adapter for SAM using two stage mask decoding to automatically generate prompt embeddings, a dual-stage fine-tuning method based on Low-Rank Adaptation (LoRA) for enhancing segmentation with limited annotated data, and a 3D memory attention mechanism to ensure segmentation consistency across 3D stacks. We further release a unique benchmark dataset for the segmentation of astrocytic processes and synapses. We evaluated our method on challenging neuroscience segmentation benchmarks, specifically targeting mitochondria, glia, and synapses, with significant accuracy improvements over state-of-the-art (SOTA) methods, including recent SAM-based adapters developed for the medical domain and other vision transformer-based approaches. Experimental results indicate that our approach outperforms existing solutions in the segmentation of complex processes like glia and post-synaptic densities. Our code and models are available at this https URL.</li>
</ul>

<h3>Title: TartuNLP at SemEval-2025 Task 5: Subject Tagging as Two-Stage Information Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Aleksei Dorkin, Kairit Sirts</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21547">https://arxiv.org/abs/2504.21547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21547">https://arxiv.org/pdf/2504.21547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21547]] TartuNLP at SemEval-2025 Task 5: Subject Tagging as Two-Stage Information Retrieval(https://arxiv.org/abs/2504.21547)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We present our submission to the Task 5 of SemEval-2025 that aims to aid librarians in assigning subject tags to the library records by producing a list of likely relevant tags for a given document. We frame the task as an information retrieval problem, where the document content is used to retrieve subject tags from a large subject taxonomy. We leverage two types of encoder models to build a two-stage information retrieval system -- a bi-encoder for coarse-grained candidate extraction at the first stage, and a cross-encoder for fine-grained re-ranking at the second stage. This approach proved effective, demonstrating significant improvements in recall compared to single-stage methods and showing competitive results according to qualitative evaluation.</li>
</ul>

<h3>Title: Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21553">https://arxiv.org/abs/2504.21553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21553">https://arxiv.org/pdf/2504.21553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21553]] Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models(https://arxiv.org/abs/2504.21553)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities in various natural language processing tasks. However, their size presents significant challenges for deployment and inference. This paper investigates the quantization of LLMs, focusing on the LLaMA architecture and its derivatives. We challenge existing assumptions about activation outliers in LLMs and propose a novel mixed-precision quantization approach tailored for LLaMA-like models. Our method leverages the observation that activation spikes in LLaMA architectures are predominantly concentrated in specific projection layers. By applying higher precision (FP16 or FP8) to these layers while quantizing the rest of the model to lower bit-widths, we achieve superior performance compared to existing quantization techniques. Experimental results on LLaMA2, LLaMA3, and Mistral models demonstrate significant improvements in perplexity and zero-shot accuracy, particularly for 8-bit per-tensor quantization. Our approach outperforms general-purpose methods designed to handle outliers across all architecture types, highlighting the benefits of architecture-specific quantization strategies. This research contributes to the ongoing efforts to make LLMs more efficient and deployable, potentially enabling their use in resource-constrained environments. Our findings emphasize the importance of considering model-specific characteristics in developing effective quantization pipelines for state-of-the-art language models by identifying and targeting a small number of projections that concentrate activation spikes.</li>
</ul>

<h3>Title: Iterative Trajectory Exploration for Multimodal Agents</h3>
<ul>
<li><strong>Authors: </strong>Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21561">https://arxiv.org/abs/2504.21561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21561">https://arxiv.org/pdf/2504.21561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21561]] Iterative Trajectory Exploration for Multimodal Agents(https://arxiv.org/abs/2504.21561)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal agents, which integrate a controller (e.g., a large language model) with external tools, have demonstrated remarkable capabilities in tackling complex tasks. However, existing agents need to collect a large number of expert data for fine-tuning to adapt to new environments. In this paper, we propose an online self-exploration method for multimodal agents, namely SPORT, via step-wise preference optimization to refine the trajectories of agents, which automatically generates tasks and learns from solving the generated tasks, without any expert annotation. SPORT operates through four iterative components: task synthesis, step sampling, step verification, and preference tuning. First, we synthesize multi-modal tasks using language models. Then, we introduce a novel search scheme, where step sampling and step verification are executed alternately to solve each generated task. We employ a verifier to provide AI feedback to construct step-wise preference data. The data is subsequently used to update the controller's policy through preference tuning, producing a SPORT Agent. By interacting with real environments, the SPORT Agent evolves into a more refined and capable system. Evaluation in the GTA and GAIA benchmarks show that the SPORT Agent achieves 6.41\% and 3.64\% improvements, underscoring the generalization and effectiveness introduced by our method. The project page is this https URL.</li>
</ul>

<h3>Title: eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes</h3>
<ul>
<li><strong>Authors: </strong>Henry John Krumb, Anirban Mukhopadhyay</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21562">https://arxiv.org/abs/2504.21562</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21562">https://arxiv.org/pdf/2504.21562</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21562]] eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes(https://arxiv.org/abs/2504.21562)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Wireless Capsule Endoscopy is a non-invasive imaging method for the entire gastrointestinal tract, and is a pain-free alternative to traditional endoscopy. It generates extensive video data that requires significant review time, and localizing the capsule after ingestion is a challenge. Techniques like bleeding detection and depth estimation can help with localization of pathologies, but deep learning models are typically too large to run directly on the capsule. Neural Cellular Automata (NCA) for bleeding segmentation and depth estimation are trained on capsule endoscopic images. For monocular depth estimation, we distill a large foundation model into the lean NCA architecture, by treating the outputs of the foundation model as pseudo ground truth. We then port the trained NCA to the ESP32 microcontroller, enabling efficient image processing on hardware as small as a camera capsule. NCA are more accurate (Dice) than other portable segmentation models, while requiring more than 100x fewer parameters stored in memory than other small-scale models. The visual results of NCA depth estimation look convincing, and in some cases beat the realism and detail of the pseudo ground truth. Runtime optimizations on the ESP32-S3 accelerate the average inference speed significantly, by more than factor 3. With several algorithmic adjustments and distillation, it is possible to eNCApsulate NCA models into microcontrollers that fit into wireless capsule endoscopes. This is the first work that enables reliable bleeding segmentation and depth estimation on a miniaturized device, paving the way for precise diagnosis combined with visual odometry as a means of precise localization of the capsule -- on the capsule.</li>
</ul>

<h3>Title: Towards proactive self-adaptive AI for non-stationary environments with dataset shifts</h3>
<ul>
<li><strong>Authors: </strong>David Fernández Narro, Pablo Ferri, Juan M. García-Gómez, Carlos Sáez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21565">https://arxiv.org/abs/2504.21565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21565">https://arxiv.org/pdf/2504.21565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21565]] Towards proactive self-adaptive AI for non-stationary environments with dataset shifts(https://arxiv.org/abs/2504.21565)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI) models deployed in production frequently face challenges in maintaining their performance in non-stationary environments. This issue is particularly noticeable in medical settings, where temporal dataset shifts often occur. These shifts arise when the distributions of training data differ from those of the data encountered during deployment over time. Further, new labeled data to continuously retrain AI is not typically available in a timely manner due to data access limitations. To address these challenges, we propose a proactive self-adaptive AI approach, or pro-adaptive, where we model the temporal trajectory of AI parameters, allowing us to short-term forecast parameter values. To this end, we use polynomial spline bases, within an extensible Functional Data Analysis framework. We validate our methodology with a logistic regression model addressing prior probability shift, covariate shift, and concept shift. This validation is conducted on both a controlled simulated dataset and a publicly available real-world COVID-19 dataset from Mexico, with various shifts occurring between 2020 and 2024. Our results indicate that this approach enhances the performance of AI against shifts compared to baseline stable models trained at different time distances from the present, without requiring updated training data. This work lays the foundation for pro-adaptive AI research against dynamic, non-stationary environments, being compatible with data protection, in resilient AI production environments for health.</li>
</ul>

<h3>Title: Generative AI in Financial Institution: A Global Survey of Opportunities, Threats, and Regulation</h3>
<ul>
<li><strong>Authors: </strong>Bikash Saha, Nanda Rani, Sandeep Kumar Shukla</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21574">https://arxiv.org/abs/2504.21574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21574">https://arxiv.org/pdf/2504.21574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21574]] Generative AI in Financial Institution: A Global Survey of Opportunities, Threats, and Regulation(https://arxiv.org/abs/2504.21574)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, explainability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative Artificial Intelligence (GenAI) is rapidly reshaping the global financial landscape, offering unprecedented opportunities to enhance customer engagement, automate complex workflows, and extract actionable insights from vast financial data. This survey provides an overview of GenAI adoption across the financial ecosystem, examining how banks, insurers, asset managers, and fintech startups worldwide are integrating large language models and other generative tools into their operations. From AI-powered virtual assistants and personalized financial advisory to fraud detection and compliance automation, GenAI is driving innovation across functions. However, this transformation comes with significant cybersecurity and ethical risks. We discuss emerging threats such as AI-generated phishing, deepfake-enabled fraud, and adversarial attacks on AI systems, as well as concerns around bias, opacity, and data misuse. The evolving global regulatory landscape is explored in depth, including initiatives by major financial regulators and international efforts to develop risk-based AI governance. Finally, we propose best practices for secure and responsible adoption - including explainability techniques, adversarial testing, auditability, and human oversight. Drawing from academic literature, industry case studies, and policy frameworks, this chapter offers a perspective on how the financial sector can harness GenAI's transformative potential while navigating the complex risks it introduces.</li>
</ul>

<h3>Title: Cascade Detector Analysis and Application to Biomedical Microscopy</h3>
<ul>
<li><strong>Authors: </strong>Thomas L. Athey, Shashata Sawmya, Nir Shavit</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21598">https://arxiv.org/abs/2504.21598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21598">https://arxiv.org/pdf/2504.21598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21598]] Cascade Detector Analysis and Application to Biomedical Microscopy(https://arxiv.org/abs/2504.21598)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>As both computer vision models and biomedical datasets grow in size, there is an increasing need for efficient inference algorithms. We utilize cascade detectors to efficiently identify sparse objects in multiresolution images. Given an object's prevalence and a set of detectors at different resolutions with known accuracies, we derive the accuracy, and expected number of classifier calls by a cascade detector. These results generalize across number of dimensions and number of cascade levels. Finally, we compare one- and two-level detectors in fluorescent cell detection, organelle segmentation, and tissue segmentation across various microscopy modalities. We show that the multi-level detector achieves comparable performance in 30-75% less time. Our work is compatible with a variety of computer vision models and data domains.</li>
</ul>

<h3>Title: Robust Misinformation Detection by Visiting Potential Commonsense Conflict</h3>
<ul>
<li><strong>Authors: </strong>Bing Wang, Ximing Li, Changchun Li, Bingrui Zhao, Bo Fu, Renchu Guan, Shengsheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21604">https://arxiv.org/abs/2504.21604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21604">https://arxiv.org/pdf/2504.21604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21604]] Robust Misinformation Detection by Visiting Potential Commonsense Conflict(https://arxiv.org/abs/2504.21604)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The development of Internet technology has led to an increased prevalence of misinformation, causing severe negative effects across diverse domains. To mitigate this challenge, Misinformation Detection (MD), aiming to detect online misinformation automatically, emerges as a rapidly growing research topic in the community. In this paper, we propose a novel plug-and-play augmentation method for the MD task, namely Misinformation Detection with Potential Commonsense Conflict (MD-PCC). We take inspiration from the prior studies indicating that fake articles are more likely to involve commonsense conflict. Accordingly, we construct commonsense expressions for articles, serving to express potential commonsense conflicts inferred by the difference between extracted commonsense triplet and golden ones inferred by the well-established commonsense reasoning tool COMET. These expressions are then specified for each article as augmentation. Any specific MD methods can be then trained on those commonsense-augmented articles. Besides, we also collect a novel commonsense-oriented dataset named CoMis, whose all fake articles are caused by commonsense conflict. We integrate MD-PCC with various existing MD backbones and compare them across both 4 public benchmark datasets and CoMis. Empirical results demonstrate that MD-PCC can consistently outperform the existing MD baselines.</li>
</ul>

<h3>Title: RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations</h3>
<ul>
<li><strong>Authors: </strong>Jonas Gwozdz, Andreas Both</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21605">https://arxiv.org/abs/2504.21605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21605">https://arxiv.org/pdf/2504.21605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21605]] RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations(https://arxiv.org/abs/2504.21605)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet systematically assessing their reliability with conflicting information remains difficult. We propose an RDF-based framework to assess multilingual LLM quality, focusing on knowledge conflicts. Our approach captures model responses across four distinct context conditions (complete, incomplete, conflicting, and no-context information) in German and English. This structured representation enables the comprehensive analysis of knowledge leakage-where models favor training data over provided context-error detection, and multilingual consistency. We demonstrate the framework through a fire safety domain experiment, revealing critical patterns in context prioritization and language-specific performance, and demonstrating that our vocabulary was sufficient to express every assessment facet encountered in the 28-question study.</li>
</ul>

<h3>Title: Overlapping data in network protocols: bridging OS and NIDS reassembly gap</h3>
<ul>
<li><strong>Authors: </strong>Lucas Aubard, Johan Mazel, Gilles Guette, Pierre Chifflier</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21618">https://arxiv.org/abs/2504.21618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21618">https://arxiv.org/pdf/2504.21618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21618]] Overlapping data in network protocols: bridging OS and NIDS reassembly gap(https://arxiv.org/abs/2504.21618)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>IPv4, IPv6, and TCP have a common mechanism allowing one to split an original data packet into several chunks. Such chunked packets may have overlapping data portions and, OS network stack implementations may reassemble these overlaps differently. A Network Intrusion Detection System (NIDS) that tries to reassemble a given flow data has to use the same reassembly policy as the monitored host OS; otherwise, the NIDS or the host may be subject to attack. In this paper, we provide several contributions that enable us to analyze NIDS resistance to overlapping data chunks-based attacks. First, we extend state-of-the-art insertion and evasion attack characterizations to address their limitations in an overlap-based context. Second, we propose a new way to model overlap types using Allen's interval algebra, a spatio-temporal reasoning. This new modeling allows us to formalize overlap test cases, which ensures exhaustiveness in overlap coverage and eases the reasoning about and use of reassembly policies. Third, we analyze the reassembly behavior of several OSes and NIDSes when processing the modeled overlap test cases. We show that 1) OS reassembly policies evolve over time and 2) all the tested NIDSes are (still) vulnerable to overlap-based evasion and insertion attacks.</li>
</ul>

<h3>Title: Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21625">https://arxiv.org/abs/2504.21625</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21625">https://arxiv.org/pdf/2504.21625</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21625]] Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability(https://arxiv.org/abs/2504.21625)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The ability to follow instructions accurately is fundamental for Large Language Models (LLMs) to serve as reliable agents in real-world applications. While existing instruction-following benchmarks are either single-turn or introduce new requirements in each turn without allowing self-correction, Meeseeks simulates realistic human-LLM interactions through an iterative feedback process. This design enables models to self-correct based on specific requirement failures, better reflecting real-world user-end usage patterns. The benchmark implements a comprehensive evaluation system with 38 capability tags organized across three dimensions: Intent Recognition, Granular Content Validation, and Output Structure Validation. Through rigorous evaluation across LLMs, Meeseeks provides valuable insights into LLMs' instruction-following capabilities in practical applications.</li>
</ul>

<h3>Title: Sadeed: Advancing Arabic Diacritization Through Small Language Model</h3>
<ul>
<li><strong>Authors: </strong>Zeina Aldallal, Sara Chrouf, Khalil Hennara, Mohamed Motaism Hamed, Muhammad Hreden, Safwan AlModhayan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21635">https://arxiv.org/abs/2504.21635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21635">https://arxiv.org/pdf/2504.21635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21635]] Sadeed: Advancing Arabic Diacritization Through Small Language Model(https://arxiv.org/abs/2504.21635)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Arabic text diacritization remains a persistent challenge in natural language processing due to the language's morphological richness. In this paper, we introduce Sadeed, a novel approach based on a fine-tuned decoder-only language model adapted from Kuwain 1.5B Hennara et al. [2025], a compact model originally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully curated, high-quality diacritized datasets, constructed through a rigorous data-cleaning and normalization pipeline. Despite utilizing modest computational resources, Sadeed achieves competitive results compared to proprietary large language models and outperforms traditional models trained on similar domains. Additionally, we highlight key limitations in current benchmarking practices for Arabic diacritization. To address these issues, we introduce SadeedDiac-25, a new benchmark designed to enable fairer and more comprehensive evaluation across diverse text genres and complexity levels. Together, Sadeed and SadeedDiac-25 provide a robust foundation for advancing Arabic NLP applications, including machine translation, text-to-speech, and language learning tools.</li>
</ul>

<h3>Title: Diffusion-based Adversarial Identity Manipulation for Facial Privacy Protection</h3>
<ul>
<li><strong>Authors: </strong>Liqin Wang, Qianyue Hu, Wei Lu, Xiangyang Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21646">https://arxiv.org/abs/2504.21646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21646">https://arxiv.org/pdf/2504.21646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21646]] Diffusion-based Adversarial Identity Manipulation for Facial Privacy Protection(https://arxiv.org/abs/2504.21646)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, diffusion</a></li>
<li><strong>Abstract: </strong>The success of face recognition (FR) systems has led to serious privacy concerns due to potential unauthorized surveillance and user tracking on social networks. Existing methods for enhancing privacy fail to generate natural face images that can protect facial privacy. In this paper, we propose diffusion-based adversarial identity manipulation (DiffAIM) to generate natural and highly transferable adversarial faces against malicious FR systems. To be specific, we manipulate facial identity within the low-dimensional latent space of a diffusion model. This involves iteratively injecting gradient-based adversarial identity guidance during the reverse diffusion process, progressively steering the generation toward the desired adversarial faces. The guidance is optimized for identity convergence towards a target while promoting semantic divergence from the source, facilitating effective impersonation while maintaining visual naturalness. We further incorporate structure-preserving regularization to preserve facial structure consistency during manipulation. Extensive experiments on both face verification and identification tasks demonstrate that compared with the state-of-the-art, DiffAIM achieves stronger black-box attack transferability while maintaining superior visual quality. We also demonstrate the effectiveness of the proposed approach for commercial FR APIs, including Face++ and Aliyun.</li>
</ul>

<h3>Title: HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation</h3>
<ul>
<li><strong>Authors: </strong>Haiyang Zhou, Wangbo Yu, Jiawen Guan, Xinhua Cheng, Yonghong Tian, Li Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21650">https://arxiv.org/abs/2504.21650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21650">https://arxiv.org/pdf/2504.21650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21650]] HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation(https://arxiv.org/abs/2504.21650)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rapid advancement of diffusion models holds the promise of revolutionizing the application of VR and AR technologies, which typically require scene-level 4D assets for user experience. Nonetheless, existing diffusion models predominantly concentrate on modeling static 3D scenes or object-level dynamics, constraining their capacity to provide truly immersive experiences. To address this issue, we propose HoloTime, a framework that integrates video diffusion models to generate panoramic videos from a single prompt or reference image, along with a 360-degree 4D scene reconstruction method that seamlessly transforms the generated panoramic video into 4D assets, enabling a fully immersive 4D experience for users. Specifically, to tame video diffusion models for generating high-fidelity panoramic videos, we introduce the 360World dataset, the first comprehensive collection of panoramic videos suitable for downstream 4D scene reconstruction tasks. With this curated dataset, we propose Panoramic Animator, a two-stage image-to-video diffusion model that can convert panoramic images into high-quality panoramic videos. Following this, we present Panoramic Space-Time Reconstruction, which leverages a space-time depth estimation method to transform the generated panoramic videos into 4D point clouds, enabling the optimization of a holistic 4D Gaussian Splatting representation to reconstruct spatially and temporally consistent 4D scenes. To validate the efficacy of our method, we conducted a comparative analysis with existing approaches, revealing its superiority in both panoramic video generation and 4D scene reconstruction. This demonstrates our method's capability to create more engaging and realistic immersive environments, thereby enhancing user experiences in VR and AR applications.</li>
</ul>

<h3>Title: Traceback of Poisoning Attacks to Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Baolei Zhang, Haoran Xin, Minghong Fang, Zhuqing Liu, Biao Yi, Tong Li, Zheli Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21668">https://arxiv.org/abs/2504.21668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21668">https://arxiv.org/pdf/2504.21668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21668]] Traceback of Poisoning Attacks to Retrieval-Augmented Generation(https://arxiv.org/abs/2504.21668)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) integrated with retrieval-augmented generation (RAG) systems improve accuracy by leveraging external knowledge sources. However, recent research has revealed RAG's susceptibility to poisoning attacks, where the attacker injects poisoned texts into the knowledge database, leading to attacker-desired responses. Existing defenses, which predominantly focus on inference-time mitigation, have proven insufficient against sophisticated attacks. In this paper, we introduce RAGForensics, the first traceback system for RAG, designed to identify poisoned texts within the knowledge database that are responsible for the attacks. RAGForensics operates iteratively, first retrieving a subset of texts from the database and then utilizing a specially crafted prompt to guide an LLM in detecting potential poisoning texts. Empirical evaluations across multiple datasets demonstrate the effectiveness of RAGForensics against state-of-the-art poisoning attacks. This work pioneers the traceback of poisoned texts in RAG systems, providing a practical and promising defense mechanism to enhance their security.</li>
</ul>

<h3>Title: Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Pan Suo, Yu-Ming Shang, San-Chuan Guo, Xi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21680">https://arxiv.org/abs/2504.21680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21680">https://arxiv.org/pdf/2504.21680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21680]] Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs(https://arxiv.org/abs/2504.21680)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) integrates Large Language Models (LLMs) with external knowledge bases, improving output quality while introducing new security risks. Existing studies on RAG vulnerabilities typically focus on exploiting the retrieval mechanism to inject erroneous knowledge or malicious texts, inducing incorrect outputs. However, these approaches overlook critical weaknesses within LLMs, leaving important attack vectors unexplored and limiting the scope and efficiency of attacks. In this paper, we uncover a novel vulnerability: the safety guardrails of LLMs, while designed for protection, can also be exploited as an attack vector by adversaries. Building on this vulnerability, we propose MutedRAG, a novel denial-of-service attack that reversely leverages the guardrails of LLMs to undermine the availability of RAG systems. By injecting minimalistic jailbreak texts, such as "\textit{How to build a bomb}", into the knowledge base, MutedRAG intentionally triggers the LLM's safety guardrails, causing the system to reject legitimate queries. Besides, due to the high sensitivity of guardrails, a single jailbreak sample can affect multiple queries, effectively amplifying the efficiency of attacks while reducing their costs. Experimental results on three datasets demonstrate that MutedRAG achieves an attack success rate exceeding 60% in many scenarios, requiring only less than one malicious text to each target query on average. In addition, we evaluate potential defense strategies against MutedRAG, finding that some of current mechanisms are insufficient to mitigate this threat, underscoring the urgent need for more robust solutions.</li>
</ul>

<h3>Title: Visual Text Processing: A Comprehensive Review and Unified Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Yan Shu, Weichao Zeng, Fangmin Zhao, Zeyu Chen, Zhenhang Li, Xiaomeng Yang, Yu Zhou, Paolo Rota, Xiang Bai, Lianwen Jin, Xu-Cheng Yin, Nicu Sebe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21682">https://arxiv.org/abs/2504.21682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21682">https://arxiv.org/pdf/2504.21682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21682]] Visual Text Processing: A Comprehensive Review and Unified Evaluation(https://arxiv.org/abs/2504.21682)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Visual text is a crucial component in both document and scene images, conveying rich semantic information and attracting significant attention in the computer vision community. Beyond traditional tasks such as text detection and recognition, visual text processing has witnessed rapid advancements driven by the emergence of foundation models, including text image reconstruction and text image manipulation. Despite significant progress, challenges remain due to the unique properties that differentiate text from general objects. Effectively capturing and leveraging these distinct textual characteristics is essential for developing robust visual text processing models. In this survey, we present a comprehensive, multi-perspective analysis of recent advancements in visual text processing, focusing on two key questions: (1) What textual features are most suitable for different visual text processing tasks? (2) How can these distinctive text features be effectively incorporated into processing frameworks? Furthermore, we introduce VTPBench, a new benchmark that encompasses a broad range of visual text processing datasets. Leveraging the advanced visual quality assessment capabilities of multimodal large language models (MLLMs), we propose VTPScore, a novel evaluation metric designed to ensure fair and reliable evaluation. Our empirical study with more than 20 specific models reveals substantial room for improvement in the current techniques. Our aim is to establish this work as a fundamental resource that fosters future exploration and innovation in the dynamic field of visual text processing. The relevant repository is available at this https URL.</li>
</ul>

<h3>Title: Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction</h3>
<ul>
<li><strong>Authors: </strong>Zihan Zhou, Changrui Dai, Aibo Song, Xiaolin Fang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21692">https://arxiv.org/abs/2504.21692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21692">https://arxiv.org/pdf/2504.21692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21692]] Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction(https://arxiv.org/abs/2504.21692)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Successful video analysis relies on accurate recognition of pixels across frames, and frame reconstruction methods based on video correspondence learning are popular due to their efficiency. Existing frame reconstruction methods, while efficient, neglect the value of direct involvement of multiple reference frames for reconstruction and decision-making aspects, especially in complex situations such as occlusion or fast movement. In this paper, we introduce a Dynamic Memory Prediction (DMP) framework that innovatively utilizes multiple reference frames to concisely and directly enhance frame reconstruction. Its core component is a Reference Frame Memory Engine that dynamically selects frames based on object pixel features to improve tracking accuracy. In addition, a Bidirectional Target Prediction Network is built to utilize multiple reference frames to improve the robustness of the model. Through experiments, our algorithm outperforms the state-of-the-art self-supervised techniques on two fine-grained video object tracking tasks: object segmentation and keypoint tracking.</li>
</ul>

<h3>Title: XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs</h3>
<ul>
<li><strong>Authors: </strong>Marco Arazzi, Vignesh Kumar Kembu, Antonino Nocera, Vinod P</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21700">https://arxiv.org/abs/2504.21700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21700">https://arxiv.org/pdf/2504.21700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21700]] XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs(https://arxiv.org/abs/2504.21700)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models are fundamental actors in the modern IT landscape dominated by AI solutions. However, security threats associated with them might prevent their reliable adoption in critical application scenarios such as government organizations and medical institutions. For this reason, commercial LLMs typically undergo a sophisticated censoring mechanism to eliminate any harmful output they could possibly produce. In response to this, LLM Jailbreaking is a significant threat to such protections, and many previous approaches have already demonstrated its effectiveness across diverse domains. Existing jailbreak proposals mostly adopt a generate-and-test strategy to craft malicious input. To improve the comprehension of censoring mechanisms and design a targeted jailbreak attack, we propose an Explainable-AI solution that comparatively analyzes the behavior of censored and uncensored models to derive unique exploitable alignment patterns. Then, we propose XBreaking, a novel jailbreak attack that exploits these unique patterns to break the security constraints of LLMs by targeted noise injection. Our thorough experimental campaign returns important insights about the censoring mechanisms and demonstrates the effectiveness and performance of our attack.</li>
</ul>

<h3>Title: Vision Transformers in Precision Agriculture: A Comprehensive Survey</h3>
<ul>
<li><strong>Authors: </strong>Saber Mehdipour, Seyed Abolghasem Mirroshandel, Seyed Amirhossein Tabatabaei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21706">https://arxiv.org/abs/2504.21706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21706">https://arxiv.org/pdf/2504.21706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21706]] Vision Transformers in Precision Agriculture: A Comprehensive Survey(https://arxiv.org/abs/2504.21706)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Detecting plant diseases is a crucial aspect of modern agriculture - it plays a key role in maintaining crop health and increasing overall yield. Traditional approaches, though still valuable, often rely on manual inspection or conventional machine learning techniques, both of which face limitations in scalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as a promising alternative, offering benefits such as improved handling of long-range dependencies and better scalability for visual tasks. This survey explores the application of ViTs in precision agriculture, covering tasks from classification to detection and segmentation. We begin by introducing the foundational architecture of ViTs and discuss their transition from Natural Language Processing (NLP) to computer vision. The discussion includes the concept of inductive bias in traditional models like Convolutional Neural Networks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive review of recent literature, focusing on key methodologies, datasets, and performance metrics. The survey also includes a comparative analysis of CNNs and ViTs, with a look at hybrid models and performance enhancements. Technical challenges - such as data requirements, computational demands, and model interpretability - are addressed alongside potential solutions. Finally, we outline potential research directions and technological advancements that could further support the integration of ViTs in real-world agricultural settings. Our goal with this study is to offer practitioners and researchers a deeper understanding of how ViTs are poised to transform smart and precision agriculture.</li>
</ul>

<h3>Title: Cert-SSB: Toward Certified Sample-Specific Backdoor Defense</h3>
<ul>
<li><strong>Authors: </strong>Ting Qiao, Yingjia Wang, Xing Liu, Sixing Wu, Jianbing Li, Yiming Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21730">https://arxiv.org/abs/2504.21730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21730">https://arxiv.org/pdf/2504.21730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21730]] Cert-SSB: Toward Certified Sample-Specific Backdoor Defense(https://arxiv.org/abs/2504.21730)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an attacker manipulates a small portion of the training data to implant hidden backdoors into the model. The compromised model behaves normally on clean samples but misclassifies backdoored samples into the attacker-specified target class, posing a significant threat to real-world DNN applications. Currently, several empirical defense methods have been proposed to mitigate backdoor attacks, but they are often bypassed by more advanced backdoor techniques. In contrast, certified defenses based on randomized smoothing have shown promise by adding random noise to training and testing samples to counteract backdoor attacks. In this paper, we reveal that existing randomized smoothing defenses implicitly assume that all samples are equidistant from the decision boundary. However, it may not hold in practice, leading to suboptimal certification performance. To address this issue, we propose a sample-specific certified backdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic gradient ascent to optimize the noise magnitude for each sample, ensuring a sample-specific noise level that is then applied to multiple poisoned training sets to retrain several smoothed models. After that, Cert-SSB aggregates the predictions of multiple smoothed models to generate the final robust prediction. In particular, in this case, existing certification methods become inapplicable since the optimized noise varies across different samples. To conquer this challenge, we introduce a storage-update-based certification method, which dynamically adjusts each sample's certification region to improve certification performance. We conduct extensive experiments on multiple benchmark datasets, demonstrating the effectiveness of our proposed method. Our code is available at this https URL.</li>
</ul>

<h3>Title: Bilateral Differentially Private Vertical Federated Boosted Decision Trees</h3>
<ul>
<li><strong>Authors: </strong>Bokang Zhang, Zhikun Zhang, Haodong Jiang, Yang Liu, Lihao Zheng, Yuxiao Zhou, Shuaiting Huang, Junfeng Wu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21739">https://arxiv.org/abs/2504.21739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21739">https://arxiv.org/pdf/2504.21739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21739]] Bilateral Differentially Private Vertical Federated Boosted Decision Trees(https://arxiv.org/abs/2504.21739)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate, interpretability</a></li>
<li><strong>Abstract: </strong>Federated learning is a distributed machine learning paradigm that enables collaborative training across multiple parties while ensuring data privacy. Gradient Boosting Decision Trees (GBDT), such as XGBoost, have gained popularity due to their high performance and strong interpretability. Therefore, there has been a growing interest in adapting XGBoost for use in federated settings via cryptographic techniques. However, it should be noted that these approaches may not always provide rigorous theoretical privacy guarantees, and they often come with a high computational cost in terms of time and space requirements. In this paper, we propose a variant of vertical federated XGBoost with bilateral differential privacy guarantee: MaskedXGBoost. We build well-calibrated noise to perturb the intermediate information to protect privacy. The noise is structured with part of its ingredients in the null space of the arithmetical operation for splitting score evaluation in XGBoost, helping us achieve consistently better utility than other perturbation methods and relatively lower overhead than encryption-based techniques. We provide theoretical utility analysis and empirically verify privacy preservation. Compared with other algorithms, our algorithm's superiority in both utility and efficiency has been validated on multiple datasets.</li>
</ul>

<h3>Title: Investigating Literary Motifs in Ancient and Medieval Novels with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Emelie Hallenberg</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21742">https://arxiv.org/abs/2504.21742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21742">https://arxiv.org/pdf/2504.21742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21742]] Investigating Literary Motifs in Ancient and Medieval Novels with Large Language Models(https://arxiv.org/abs/2504.21742)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Greek fictional narratives often termed love novels or romances, ranging from the first century CE to the middle of the 15th century, have long been considered as similar in many ways, not least in the use of particular literary motifs. By applying the use of fine-tuned large language models, this study aims to investigate which motifs exactly that the texts in this corpus have in common, and in which ways they differ from each other. The results show that while some motifs persist throughout the corpus, others fluctuate in frequency, indicating certain trends or external influences. Conclusively, the method proves to adequately extract literary motifs according to a set definition, providing data for both quantitative and qualitative analyses.</li>
</ul>

<h3>Title: Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space</h3>
<ul>
<li><strong>Authors: </strong>Leonhard Sommer, Olaf Dünkel, Christian Theobalt, Adam Kortylewski</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21749">https://arxiv.org/abs/2504.21749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21749">https://arxiv.org/pdf/2504.21749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21749]] Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space(https://arxiv.org/abs/2504.21749)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D morphable models (3DMMs) are a powerful tool to represent the possible shapes and appearances of an object category. Given a single test image, 3DMMs can be used to solve various tasks, such as predicting the 3D shape, pose, semantic correspondence, and instance segmentation of an object. Unfortunately, 3DMMs are only available for very few object categories that are of particular interest, like faces or human bodies, as they require a demanding 3D data acquisition and category-specific training process. In contrast, we introduce a new method, Common3D, that learns 3DMMs of common objects in a fully self-supervised manner from a collection of object-centric videos. For this purpose, our model represents objects as a learned 3D template mesh and a deformation field that is parameterized as an image-conditioned neural network. Different from prior works, Common3D represents the object appearance with neural features instead of RGB colors, which enables the learning of more generalizable representations through an abstraction from pixel intensities. Importantly, we train the appearance features using a contrastive objective by exploiting the correspondences defined through the deformable template mesh. This leads to higher quality correspondence features compared to related works and a significantly improved model performance at estimating 3D object pose and semantic correspondence. Common3D is the first completely self-supervised method that can solve various vision tasks in a zero-shot manner.</li>
</ul>

<h3>Title: VDDP: Verifiable Distributed Differential Privacy under the Client-Server-Verifier Setup</h3>
<ul>
<li><strong>Authors: </strong>Haochen Sun, Xi He</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21752">https://arxiv.org/abs/2504.21752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21752">https://arxiv.org/pdf/2504.21752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21752]] VDDP: Verifiable Distributed Differential Privacy under the Client-Server-Verifier Setup(https://arxiv.org/abs/2504.21752)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Despite differential privacy (DP) often being considered the de facto standard for data privacy, its realization is vulnerable to unfaithful execution of its mechanisms by servers, especially in distributed settings. Specifically, servers may sample noise from incorrect distributions or generate correlated noise while appearing to follow established protocols. This work analyzes these malicious behaviors in a general differential privacy framework within a distributed client-server-verifier setup. To address these adversarial problems, we propose a novel definition called Verifiable Distributed Differential Privacy (VDDP) by incorporating additional verification mechanisms. We also explore the relationship between zero-knowledge proofs (ZKP) and DP, demonstrating that while ZKPs are sufficient for achieving DP under verifiability requirements, they are not necessary. Furthermore, we develop two novel and efficient mechanisms that satisfy VDDP: (1) the Verifiable Distributed Discrete Laplacian Mechanism (VDDLM), which offers up to a $4 \times 10^5$x improvement in proof generation efficiency with only 0.1-0.2x error compared to the previous state-of-the-art verifiable differentially private mechanism; (2) an improved solution to Verifiable Randomized Response (VRR) under local DP, a special case of VDDP, achieving up a reduction of up to 5000x in communication costs and the verifier's overhead.</li>
</ul>

<h3>Title: LASHED: LLMs And Static Hardware Analysis for Early Detection of RTL Bugs</h3>
<ul>
<li><strong>Authors: </strong>Baleegh Ahmad, Hammond Pearce, Ramesh Karri, Benjamin Tan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21770">https://arxiv.org/abs/2504.21770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21770">https://arxiv.org/pdf/2504.21770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21770]] LASHED: LLMs And Static Hardware Analysis for Early Detection of RTL Bugs(https://arxiv.org/abs/2504.21770)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>While static analysis is useful in detecting early-stage hardware security bugs, its efficacy is limited because it requires information to form checks and is often unable to explain the security impact of a detected vulnerability. Large Language Models can be useful in filling these gaps by identifying relevant assets, removing false violations flagged by static analysis tools, and explaining the reported violations. LASHED combines the two approaches (LLMs and Static Analysis) to overcome each other's limitations for hardware security bug detection. We investigate our approach on four open-source SoCs for five Common Weakness Enumerations (CWEs) and present strategies for improvement with better prompt engineering. We find that 87.5% of instances flagged by our recommended scheme are plausible CWEs. In-context learning and asking the model to 'think again' improves LASHED's precision.</li>
</ul>

<h3>Title: Anatomical Similarity as a New Metric to Evaluate Brain Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Bahram Jafrasteh, Wei Peng, Cheng Wan, Yimin Luo, Ehsan Adeli, Qingyu Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21771">https://arxiv.org/abs/2504.21771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21771">https://arxiv.org/pdf/2504.21771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21771]] Anatomical Similarity as a New Metric to Evaluate Brain Generative Models(https://arxiv.org/abs/2504.21771)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative models enhance neuroimaging through data augmentation, quality improvement, and rare condition studies. Despite advances in realistic synthetic MRIs, evaluations focus on texture and perception, lacking sensitivity to crucial anatomical fidelity. This study proposes a new metric, called WASABI (Wasserstein-Based Anatomical Brain Index), to assess the anatomical realism of synthetic brain MRIs. WASABI leverages \textit{SynthSeg}, a deep learning-based brain parcellation tool, to derive volumetric measures of brain regions in each MRI and uses the multivariate Wasserstein distance to compare distributions between real and synthetic anatomies. Based on controlled experiments on two real datasets and synthetic MRIs from five generative models, WASABI demonstrates higher sensitivity in quantifying anatomical discrepancies compared to traditional image-level metrics, even when synthetic images achieve near-perfect visual quality. Our findings advocate for shifting the evaluation paradigm beyond visual inspection and conventional metrics, emphasizing anatomical fidelity as a crucial benchmark for clinically meaningful brain MRI synthesis. Our code is available at this https URL.</li>
</ul>

<h3>Title: MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness</h3>
<ul>
<li><strong>Authors: </strong>Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21773">https://arxiv.org/abs/2504.21773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21773">https://arxiv.org/pdf/2504.21773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21773]] MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness(https://arxiv.org/abs/2504.21773)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the widespread application of large language models (LLMs), the issue of generating non-existing facts, known as hallucination, has garnered increasing attention. Previous research in enhancing LLM confidence estimation mainly focuses on the single problem setting. However, LLM awareness of its internal parameterized knowledge boundary under the more challenging multi-problem setting, which requires answering multiple problems accurately simultaneously, remains underexplored. To bridge this gap, we introduce a novel method, Multiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates the learning of answer prediction and confidence estimation during fine-tuning on instruction data. Extensive experiments demonstrate that our method outperforms baselines by up to 25% in average precision.</li>
</ul>

<h3>Title: Learning Heterogeneous Performance-Fairness Trade-offs in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Rongguang Ye, Ming Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21775">https://arxiv.org/abs/2504.21775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21775">https://arxiv.org/pdf/2504.21775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21775]] Learning Heterogeneous Performance-Fairness Trade-offs in Federated Learning(https://arxiv.org/abs/2504.21775)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, fair</a></li>
<li><strong>Abstract: </strong>Recent methods leverage a hypernet to handle the performance-fairness trade-offs in federated learning. This hypernet maps the clients' preferences between model performance and fairness to preference-specifc models on the trade-off curve, known as local Pareto front. However, existing methods typically adopt a uniform preference sampling distribution to train the hypernet across clients, neglecting the inherent heterogeneity of their local Pareto fronts. Meanwhile, from the perspective of generalization, they do not consider the gap between local and global Pareto fronts on the global dataset. To address these limitations, we propose HetPFL to effectively learn both local and global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA) and Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the optimal preference sampling distribution for each client to accommodate heterogeneous local Pareto fronts. While PHF performs preference-aware fusion of clients' hypernets to ensure the performance of the global Pareto front. We prove that HetPFL converges linearly with respect to the number of rounds, under weaker assumptions than existing methods. Extensive experiments on four datasets show that HetPFL significantly outperforms seven baselines in terms of the quality of learned local and global Pareto fronts.</li>
</ul>

<h3>Title: Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Alessia Hu, Regina Beets-Tan, Lishan Cai, Eduardo Pooch</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21789">https://arxiv.org/abs/2504.21789</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21789">https://arxiv.org/pdf/2504.21789</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21789]] Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation(https://arxiv.org/abs/2504.21789)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Magnetic Resonance Imaging (MRI) plays an important role in identifying clinically significant prostate cancer (csPCa), yet automated methods face challenges such as data imbalance, variable tumor sizes, and a lack of annotated data. This study introduces Anomaly-Driven U-Net (adU-Net), which incorporates anomaly maps derived from biparametric MRI sequences into a deep learning-based segmentation framework to improve csPCa identification. We conduct a comparative analysis of anomaly detection methods and evaluate the integration of anomaly maps into the segmentation pipeline. Anomaly maps, generated using Fixed-Point GAN reconstruction, highlight deviations from normal prostate tissue, guiding the segmentation model to potential cancerous regions. We compare the performance by using the average score, computed as the mean of the AUROC and Average Precision (AP). On the external test set, adU-Net achieves the best average score of 0.618, outperforming the baseline nnU-Net model (0.605). The results demonstrate that incorporating anomaly detection into segmentation improves generalization and performance, particularly with ADC-based anomaly maps, offering a promising direction for automated csPCa identification.</li>
</ul>

<h3>Title: How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Suhas BN, Dominik Mattioli, Saeed Abdullah, Rosa I. Arriaga, Chris W. Wiese, Andrew M. Sherrill</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21800">https://arxiv.org/abs/2504.21800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21800">https://arxiv.org/pdf/2504.21800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21800]] How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues(https://arxiv.org/abs/2504.21800)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>The growing adoption of synthetic data in healthcare is driven by privacy concerns, limited access to real-world data, and the high cost of annotation. This work explores the use of synthetic Prolonged Exposure (PE) therapeutic conversations for Post-Traumatic Stress Disorder (PTSD) as a scalable alternative for training and evaluating clinical models. We systematically compare real and synthetic dialogues using linguistic, structural, and protocol-specific metrics, including turn-taking patterns and treatment fidelity. We also introduce and evaluate PE-specific metrics derived from linguistic analysis and semantic modeling, offering a novel framework for assessing clinical fidelity beyond surface fluency. Our findings show that although synthetic data holds promise for mitigating data scarcity and protecting patient privacy, it can struggle to capture the subtle dynamics of therapeutic interactions. In our dataset, synthetic dialogues match structural features of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99), however, synthetic interactions do not adequately reflect key fidelity markers (e.g., distress monitoring). We highlight gaps in existing evaluation frameworks and advocate for fidelity-aware metrics that go beyond surface fluency to uncover clinically significant failures. Our findings clarify where synthetic data can effectively complement real-world datasets -- and where critical limitations remain.</li>
</ul>

<h3>Title: DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Z.Z. Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, Z.F. Wu, Zhibin Gou, Shirong Ma, Hongxuan Tang, Yuxuan Liu, Wenjun Gao, Daya Guo, Chong Ruan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21801">https://arxiv.org/abs/2504.21801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21801">https://arxiv.org/pdf/2504.21801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21801]] DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition(https://arxiv.org/abs/2504.21801)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce DeepSeek-Prover-V2, an open-source large language model designed for formal theorem proving in Lean 4, with initialization data collected through a recursive theorem proving pipeline powered by DeepSeek-V3. The cold-start training procedure begins by prompting DeepSeek-V3 to decompose complex problems into a series of subgoals. The proofs of resolved subgoals are synthesized into a chain-of-thought process, combined with DeepSeek-V3's step-by-step reasoning, to create an initial cold start for reinforcement learning. This process enables us to integrate both informal and formal mathematical reasoning into a unified model. The resulting model, DeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural theorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49 out of 658 problems from PutnamBench. In addition to standard benchmarks, we introduce ProverBench, a collection of 325 formalized problems, to enrich our evaluation, including 15 selected problems from the recent AIME competitions (years 24-25). Further evaluation on these 15 AIME problems shows that the model successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of these problems using majority voting, highlighting that the gap between formal and informal mathematical reasoning in large language models is substantially narrowing.</li>
</ul>

<h3>Title: Stable Trajectory Clustering: An Efficient Split and Merge Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Atieh Rahmani, Mansoor Davoodi, Justin M. Calabrese</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21808">https://arxiv.org/abs/2504.21808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21808">https://arxiv.org/pdf/2504.21808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21808]] Stable Trajectory Clustering: An Efficient Split and Merge Algorithm(https://arxiv.org/abs/2504.21808)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Clustering algorithms group data points by characteristics to identify patterns. Over the past two decades, researchers have extended these methods to analyze trajectories of humans, animals, and vehicles, studying their behavior and movement across applications. This paper presents whole-trajectory clustering and sub-trajectory clustering algorithms based on DBSCAN line segment clustering, which encompasses two key events: split and merge of line segments. The events are employed by object movement history and the average Euclidean distance between line segments. In this framework, whole-trajectory clustering considers entire entities' trajectories, whereas sub-trajectory clustering employs a sliding window model to identify similar sub-trajectories. Many existing trajectory clustering algorithms respond to temporary anomalies in data by splitting trajectories, which often obscures otherwise consistent clustering patterns and leads to less reliable insights. We introduce the stable trajectory clustering algorithm, which leverages the mean absolute deviation concept to demonstrate that selective omission of transient deviations not only preserves the integrity of clusters but also improves their stability and interpretability. We run all proposed algorithms on real trajectory datasets to illustrate their effectiveness and sensitivity to parameter variations.</li>
</ul>

<h3>Title: Why Compress What You Can Generate? When GPT-4o Generation Ushers in Image Compression Fields</h3>
<ul>
<li><strong>Authors: </strong>Yixin Gao, Xiaohan Pan, Xin Li, Zhibo Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21814">https://arxiv.org/abs/2504.21814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21814">https://arxiv.org/pdf/2504.21814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21814]] Why Compress What You Can Generate? When GPT-4o Generation Ushers in Image Compression Fields(https://arxiv.org/abs/2504.21814)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The rapid development of AIGC foundation models has revolutionized the paradigm of image compression, which paves the way for the abandonment of most pixel-level transform and coding, compelling us to ask: why compress what you can generate if the AIGC foundation model is powerful enough to faithfully generate intricate structure and fine-grained details from nothing more than some compact descriptors, i.e., texts, or cues. Fortunately, recent GPT-4o image generation of OpenAI has achieved impressive cross-modality generation, editing, and design capabilities, which motivates us to answer the above question by exploring its potential in image compression fields. In this work, we investigate two typical compression paradigms: textual coding and multimodal coding (i.e., text + extremely low-resolution image), where all/most pixel-level information is generated instead of compressing via the advanced GPT-4o image generation function. The essential challenge lies in how to maintain semantic and structure consistency during the decoding process. To overcome this, we propose a structure raster-scan prompt engineering mechanism to transform the image into textual space, which is compressed as the condition of GPT-4o image generation. Extensive experiments have shown that the combination of our designed structural raster-scan prompts and GPT-4o's image generation function achieved the impressive performance compared with recent multimodal/generative image compression at ultra-low bitrate, further indicating the potential of AIGC generation in image compression fields.</li>
</ul>

<h3>Title: Active Light Modulation to Counter Manipulation of Speech Visual Content</h3>
<ul>
<li><strong>Authors: </strong>Hadleigh Schwartz, Xiaofeng Yan, Charles J. Carver, Xia Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21846">https://arxiv.org/abs/2504.21846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21846">https://arxiv.org/pdf/2504.21846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21846]] Active Light Modulation to Counter Manipulation of Speech Visual Content(https://arxiv.org/abs/2504.21846)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>High-profile speech videos are prime targets for falsification, owing to their accessibility and influence. This work proposes Spotlight, a low-overhead and unobtrusive system for protecting live speech videos from visual falsification of speaker identity and lip and facial motion. Unlike predominant falsification detection methods operating in the digital domain, Spotlight creates dynamic physical signatures at the event site and embeds them into all video recordings via imperceptible modulated light. These physical signatures encode semantically-meaningful features unique to the speech event, including the speaker's identity and facial motion, and are cryptographically-secured to prevent spoofing. The signatures can be extracted from any video downstream and validated against the portrayed speech content to check its integrity. Key elements of Spotlight include (1) a framework for generating extremely compact (i.e., 150-bit), pose-invariant speech video features, based on locality-sensitive hashing; and (2) an optical modulation scheme that embeds >200 bps into video while remaining imperceptible both in video and live. Prototype experiments on extensive video datasets show Spotlight achieves AUCs $\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified videos. Further, Spotlight is highly robust across recording conditions, video post-processing techniques, and white-box adversarial attacks on its video feature extraction methodologies.</li>
</ul>

<h3>Title: COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning</h3>
<ul>
<li><strong>Authors: </strong>Xindi Wu, Hee Seung Hwang, Polina Kirichenko, Olga Russakovsky</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21850">https://arxiv.org/abs/2504.21850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21850">https://arxiv.org/pdf/2504.21850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21850]] COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning(https://arxiv.org/abs/2504.21850)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) excel at simple vision-language tasks but struggle when faced with complex tasks that require multiple capabilities, such as simultaneously recognizing objects, counting them, and understanding their spatial relationships. This might be partially the result of the fact that Visual Instruction Tuning (VIT), a critical training step for MLLMs, has traditionally focused on scaling data volume, but not the compositional complexity of training examples. We propose COMPACT (COMPositional Atomic-to-complex visual Capability Tuning), which generates a training dataset explicitly controlling for the compositional complexity of the training examples. The data from COMPACT allows MLLMs to train on combinations of atomic capabilities to learn complex capabilities more efficiently. Across all benchmarks, COMPACT achieves comparable performance to the LLaVA-665k VIT while using less than 10% of its data budget, and even outperforms it on several, especially those involving complex multi-capability tasks. For example, COMPACT achieves substantial 83.3% improvement on MMStar and 94.0% improvement on MM-Vet compared to the full-scale VIT on particularly complex questions that require four or more atomic capabilities. COMPACT offers a scalable, data-efficient, visual compositional tuning recipe to improve on complex visual-language tasks.</li>
</ul>

<h3>Title: TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments</h3>
<ul>
<li><strong>Authors: </strong>Sichang Tu, Abigail Powers, Stephen Doogan, Jinho D. Choi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21851">https://arxiv.org/abs/2504.21851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21851">https://arxiv.org/pdf/2504.21851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21851]] TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments(https://arxiv.org/abs/2504.21851)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Objectives: While Large Language Models (LLMs) have been widely used to assist clinicians and support patients, no existing work has explored dialogue systems for standard diagnostic interviews and assessments. This study aims to bridge the gap in mental healthcare accessibility by developing an LLM-powered dialogue system that replicates clinician behavior. Materials and Methods: We introduce TRUST, a framework of cooperative LLM modules capable of conducting formal diagnostic interviews and assessments for Post-Traumatic Stress Disorder (PTSD). To guide the generation of appropriate clinical responses, we propose a Dialogue Acts schema specifically designed for clinical interviews. Additionally, we develop a patient simulation approach based on real-life interview transcripts to replace time-consuming and costly manual testing by clinicians. Results: A comprehensive set of evaluation metrics is designed to assess the dialogue system from both the agent and patient simulation perspectives. Expert evaluations by conversation and clinical specialists show that TRUST performs comparably to real-life clinical interviews. Discussion: Our system performs at the level of average clinicians, with room for future enhancements in communication styles and response appropriateness. Conclusions: Our TRUST framework shows its potential to facilitate mental healthcare availability.</li>
</ul>

<h3>Title: A Survey of Interactive Generative Video</h3>
<ul>
<li><strong>Authors: </strong>Jiwen Yu, Yiran Qin, Haoxuan Che, Quande Liu, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai, Hao Chen, Xihui Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21853">https://arxiv.org/abs/2504.21853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21853">https://arxiv.org/pdf/2504.21853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21853]] A Survey of Interactive Generative Video(https://arxiv.org/abs/2504.21853)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Interactive Generative Video (IGV) has emerged as a crucial technology in response to the growing demand for high-quality, interactive video content across various domains. In this paper, we define IGV as a technology that combines generative capabilities to produce diverse high-quality video content with interactive features that enable user engagement through control signals and responsive feedback. We survey the current landscape of IGV applications, focusing on three major domains: 1) gaming, where IGV enables infinite exploration in virtual worlds; 2) embodied AI, where IGV serves as a physics-aware environment synthesizer for training agents in multimodal interaction with dynamically evolving scenes; and 3) autonomous driving, where IGV provides closed-loop simulation capabilities for safety-critical testing and validation. To guide future development, we propose a comprehensive framework that decomposes an ideal IGV system into five essential modules: Generation, Control, Memory, Dynamics, and Intelligence. Furthermore, we systematically analyze the technical challenges and future directions in realizing each component for an ideal IGV system, such as achieving real-time generation, enabling open-domain control, maintaining long-term coherence, simulating accurate physics, and integrating causal reasoning. We believe that this systematic analysis will facilitate future research and development in the field of IGV, ultimately advancing the technology toward more sophisticated and practical applications.</li>
</ul>

<h3>Title: ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D Physics Modeling for Complex Motion and Interaction</h3>
<ul>
<li><strong>Authors: </strong>Qihao Liu, Ju He, Qihang Yu, Liang-Chieh Chen, Alan Yuille</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.21855">https://arxiv.org/abs/2504.21855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.21855">https://arxiv.org/pdf/2504.21855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.21855]] ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D Physics Modeling for Complex Motion and Interaction(https://arxiv.org/abs/2504.21855)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In recent years, video generation has seen significant advancements. However, challenges still persist in generating complex motions and interactions. To address these challenges, we introduce ReVision, a plug-and-play framework that explicitly integrates parameterized 3D physical knowledge into a pretrained conditional video generation model, significantly enhancing its ability to generate high-quality videos with complex motion and interactions. Specifically, ReVision consists of three stages. First, a video diffusion model is used to generate a coarse video. Next, we extract a set of 2D and 3D features from the coarse video to construct a 3D object-centric representation, which is then refined by our proposed parameterized physical prior model to produce an accurate 3D motion sequence. Finally, this refined motion sequence is fed back into the same video diffusion model as additional conditioning, enabling the generation of motion-consistent videos, even in scenarios involving complex actions and interactions. We validate the effectiveness of our approach on Stable Video Diffusion, where ReVision significantly improves motion fidelity and coherence. Remarkably, with only 1.5B parameters, it even outperforms a state-of-the-art video generation model with over 13B parameters on complex video generation by a substantial margin. Our results suggest that, by incorporating 3D physical knowledge, even a relatively small video diffusion model can generate complex motions and interactions with greater realism and controllability, offering a promising solution for physically plausible video generation.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
