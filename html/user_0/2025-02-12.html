<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-02-12</h1>
<h3>Title: Prompt-Aware Scheduling for Efficient Text-to-Image Inferencing System</h3>
<ul>
<li><strong>Authors: </strong>Shubham Agarwal, Saud Iqbal, Subrata Mitra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06798">https://arxiv.org/abs/2502.06798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06798">https://arxiv.org/pdf/2502.06798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06798]] Prompt-Aware Scheduling for Efficient Text-to-Image Inferencing System(https://arxiv.org/abs/2502.06798)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Traditional ML models utilize controlled approximations during high loads, employing faster, but less accurate models in a process called accuracy scaling. However, this method is less effective for generative text-to-image models due to their sensitivity to input prompts and performance degradation caused by large model loading overheads. This work introduces a novel text-to-image inference system that optimally matches prompts across multiple instances of the same model operating at various approximation levels to deliver high-quality images under high loads and fixed budgets.</li>
</ul>

<h3>Title: Emotion Recognition and Generation: A Comprehensive Review of Face, Speech, and Text Modalities</h3>
<ul>
<li><strong>Authors: </strong>Rebecca Mobbs, Dimitrios Makris, Vasileios Argyriou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06803">https://arxiv.org/abs/2502.06803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06803">https://arxiv.org/pdf/2502.06803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06803]] Emotion Recognition and Generation: A Comprehensive Review of Face, Speech, and Text Modalities(https://arxiv.org/abs/2502.06803)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Emotion recognition and generation have emerged as crucial topics in Artificial Intelligence research, playing a significant role in enhancing human-computer interaction within healthcare, customer service, and other fields. Although several reviews have been conducted on emotion recognition and generation as separate entities, many of these works are either fragmented or limited to specific methodologies, lacking a comprehensive overview of recent developments and trends across different modalities. In this survey, we provide a holistic review aimed at researchers beginning their exploration in emotion recognition and generation. We introduce the fundamental principles underlying emotion recognition and generation across facial, vocal, and textual modalities. This work categorises recent state-of-the-art research into distinct technical approaches and explains the theoretical foundations and motivations behind these methodologies, offering a clearer understanding of their application. Moreover, we discuss evaluation metrics, comparative analyses, and current limitations, shedding light on the challenges faced by researchers in the field. Finally, we propose future research directions to address these challenges and encourage further exploration into developing robust, effective, and ethically responsible emotion recognition and generation systems.</li>
</ul>

<h3>Title: Efficient Diffusion Models: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Hui Shen, Jingxuan Zhang, Boning Xiong, Rui Hu, Shoufa Chen, Zhongwei Wan, Xin Wang, Yu Zhang, Zixuan Gong, Guangyin Bao, Chaofan Tao, Yongfeng Huang, Ye Yuan, Mi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06805">https://arxiv.org/abs/2502.06805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06805">https://arxiv.org/pdf/2502.06805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06805]] Efficient Diffusion Models: A Survey(https://arxiv.org/abs/2502.06805)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as powerful generative models capable of producing high-quality contents such as images, videos, and audio, demonstrating their potential to revolutionize digital content creation. However, these capabilities come at the cost of their significant computational resources and lengthy generation time, underscoring the critical need to develop efficient techniques for practical deployment. In this survey, we provide a systematic and comprehensive review of research on efficient diffusion models. We organize the literature in a taxonomy consisting of three main categories, covering distinct yet interconnected efficient diffusion model topics from algorithm-level, system-level, and framework perspective, respectively. We have also created a GitHub repository where we organize the papers featured in this survey at this https URL. We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient diffusion model research and inspire them to contribute to this important and exciting field.</li>
</ul>

<h3>Title: Logits are All We Need to Adapt Closed Models</h3>
<ul>
<li><strong>Authors: </strong>Gaurush Hiranandani, Haolun Wu, Subhojyoti Mukherjee, Sanmi Koyejo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06806">https://arxiv.org/abs/2502.06806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06806">https://arxiv.org/pdf/2502.06806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06806]] Logits are All We Need to Adapt Closed Models(https://arxiv.org/abs/2502.06806)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Many commercial Large Language Models (LLMs) are often closed-source, limiting developers to prompt tuning for aligning content generation with specific applications. While these models currently do not provide access to token logits, we argue that if such access were available, it would enable more powerful adaptation techniques beyond prompt engineering. In this paper, we propose a token-level probability reweighting framework that, given access to logits and a small amount of task-specific data, can effectively steer black-box LLMs toward application-specific content generation. Our approach views next-token prediction through the lens of supervised classification. We show that aligning black-box LLMs with task-specific data can be formulated as a label noise correction problem, leading to \emph{Plugin} model -- an autoregressive probability reweighting model that operates solely on logits. We provide theoretical justification for why reweighting logits alone is sufficient for task adaptation. Extensive experiments with multiple datasets, LLMs, and reweighting models demonstrate the effectiveness of our method, advocating for broader access to token logits in closed-source models.</li>
</ul>

<h3>Title: Competitive Programming with Large Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>OpenAI: Ahmed El-Kishky, Alexander Wei, Andre Saraiva, Borys Minaev, Daniel Selsam, David Dohan, Francis Song, Hunter Lightman, Ignasi Clavera, Jakub Pachocki, Jerry Tworek, Lorenz Kuhn, Lukasz Kaiser, Mark Chen, Max Schwarzer, Mostafa Rohaninejad, Nat McAleese, o3 contributors, Oleg MÃ¼rk, Rhythm Garg, Rui Shu, Szymon Sidor, Vineet Kosaraju, Wenda Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06807">https://arxiv.org/abs/2502.06807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06807">https://arxiv.org/pdf/2502.06807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06807]] Competitive Programming with Large Reasoning Models(https://arxiv.org/abs/2502.06807)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We show that reinforcement learning applied to large language models (LLMs) significantly boosts performance on complex coding and reasoning tasks. Additionally, we compare two general-purpose reasoning models - OpenAI o1 and an early checkpoint of o3 - with a domain-specific system, o1-ioi, which uses hand-engineered inference strategies designed for competing in the 2024 International Olympiad in Informatics (IOI). We competed live at IOI 2024 with o1-ioi and, using hand-crafted test-time strategies, placed in the 49th percentile. Under relaxed competition constraints, o1-ioi achieved a gold medal. However, when evaluating later models such as o3, we find that o3 achieves gold without hand-crafted domain-specific strategies or relaxed constraints. Our findings show that although specialized pipelines such as o1-ioi yield solid improvements, the scaled-up, general-purpose o3 model surpasses those results without relying on hand-crafted inference heuristics. Notably, o3 achieves a gold medal at the 2024 IOI and obtains a Codeforces rating on par with elite human competitors. Overall, these results indicate that scaling general-purpose reinforcement learning, rather than relying on domain-specific techniques, offers a robust path toward state-of-the-art AI in reasoning domains, such as competitive programming.</li>
</ul>

<h3>Title: Neurons Speak in Ranges: Breaking Free from Discrete Neuronal Attribution</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, Peizhong Ju, A.B. Siddique</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06809">https://arxiv.org/abs/2502.06809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06809">https://arxiv.org/pdf/2502.06809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06809]] Neurons Speak in Ranges: Breaking Free from Discrete Neuronal Attribution(https://arxiv.org/abs/2502.06809)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Interpreting and controlling the internal mechanisms of large language models (LLMs) is crucial for improving their trustworthiness and utility. Recent efforts have primarily focused on identifying and manipulating neurons by establishing discrete mappings between neurons and semantic concepts. However, such mappings struggle to handle the inherent polysemanticity in LLMs, where individual neurons encode multiple, distinct concepts. This makes precise control challenging and complicates downstream interventions. Through an in-depth analysis of both encoder and decoder-based LLMs across multiple text classification datasets, we uncover that while individual neurons encode multiple concepts, their activation magnitudes vary across concepts in distinct, Gaussian-like patterns. Building on this insight, we introduce NeuronLens, a novel range-based interpretation and manipulation framework that provides a finer view of neuron activation distributions to localize concept attribution within a neuron. Extensive empirical evaluations demonstrate that NeuronLens significantly reduces unintended interference, while maintaining precise control for manipulation of targeted concepts, outperforming existing methods.</li>
</ul>

<h3>Title: Aligning Human and Machine Attention for Enhanced Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Avihay Chriqui, Inbal Yahav, Dov Teeni, Ahmed Abbasi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06811">https://arxiv.org/abs/2502.06811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06811">https://arxiv.org/pdf/2502.06811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06811]] Aligning Human and Machine Attention for Enhanced Supervised Learning(https://arxiv.org/abs/2502.06811)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Attention, or prioritization of certain information items over others, is a critical element of any learning process, for both humans and machines. Given that humans continue to outperform machines in certain learning tasks, it seems plausible that machine performance could be enriched by aligning machine attention with human attention mechanisms -- yet research on this topic is sparse and has achieved only limited success. This paper proposes a new approach to address this gap, called Human-Machine Attention Learning (HuMAL). This approach involves reliance on data annotated by humans to reflect their self-perceived attention during specific tasks. We evaluate several alternative strategies for integrating such human attention data into machine learning (ML) algorithms, using a sentiment analysis task (review data from Yelp) and a personality-type classification task (data from myPersonality). The best-performing HuMAL strategy significantly enhances the task performance of fine-tuned transformer models (BERT, as well as GPT-2 and XLNET), and the benefit is particularly pronounced under challenging conditions of imbalanced or sparse labeled data. This research contributes to a deeper understanding of strategies for integrating human attention into ML models and highlights the potential of leveraging human cognition to augment ML in real-world applications.</li>
</ul>

<h3>Title: Harness Local Rewards for Global Benefits: Effective Text-to-Video Generation Alignment with Patch-level Reward Models</h3>
<ul>
<li><strong>Authors: </strong>Shuting Wang, Haihong Tang, Zhicheng Dou, Chenyan Xiong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06812">https://arxiv.org/abs/2502.06812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06812">https://arxiv.org/pdf/2502.06812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06812]] Harness Local Rewards for Global Benefits: Effective Text-to-Video Generation Alignment with Patch-level Reward Models(https://arxiv.org/abs/2502.06812)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The emergence of diffusion models (DMs) has significantly improved the quality of text-to-video generation models (VGMs). However, current VGM optimization primarily emphasizes the global quality of videos, overlooking localized errors, which leads to suboptimal generation capabilities. To address this issue, we propose a post-training strategy for VGMs, HALO, which explicitly incorporates local feedback from a patch reward model, providing detailed and comprehensive training signals with the video reward model for advanced VGM optimization. To develop an effective patch reward model, we distill GPT-4o to continuously train our video reward model, which enhances training efficiency and ensures consistency between video and patch reward distributions. Furthermore, to harmoniously integrate patch rewards into VGM optimization, we introduce a granular DPO (Gran-DPO) algorithm for DMs, allowing collaborative use of both patch and video rewards during the optimization process. Experimental results indicate that our patch reward model aligns well with human annotations and HALO substantially outperforms the baselines across two evaluation methods. Further experiments quantitatively prove the existence of patch defects, and our proposed method could effectively alleviate this issue.</li>
</ul>

<h3>Title: Policy Guided Tree Search for Enhanced LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06813">https://arxiv.org/abs/2502.06813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06813">https://arxiv.org/pdf/2502.06813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06813]] Policy Guided Tree Search for Enhanced LLM Reasoning(https://arxiv.org/abs/2502.06813)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite their remarkable capabilities, large language models often struggle with tasks requiring complex reasoning and planning. While existing approaches like Chain-of-Thought prompting and tree search techniques show promise, they are limited by their reliance on predefined heuristics and computationally expensive exploration strategies. We propose Policy-Guided Tree Search (PGTS), a framework that combines reinforcement learning with structured tree exploration to efficiently navigate reasoning paths. Our key innovation is a learned policy that dynamically decides between expanding, branching, backtracking, or terminating exploration, eliminating the need for manual heuristics or exhaustive search. Experiments across mathematical reasoning, logical deduction, and planning benchmarks demonstrate that PGTS achieves superior reasoning performance while significantly reducing computational costs compared to existing methods. These results establish PGTS as a scalable and effective solution for tackling complex reasoning tasks with LLMs.</li>
</ul>

<h3>Title: Diffusion Instruction Tuning</h3>
<ul>
<li><strong>Authors: </strong>Chen Jin, Ryutaro Tanno, Amrutha Saseendran, Tom Diethe, Philip Teare</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06814">https://arxiv.org/abs/2502.06814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06814">https://arxiv.org/pdf/2502.06814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06814]] Diffusion Instruction Tuning(https://arxiv.org/abs/2502.06814)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We introduce Lavender, a simple supervised fine-tuning (SFT) method that boosts the performance of advanced vision-language models (VLMs) by leveraging state-of-the-art image generation models such as Stable Diffusion. Specifically, Lavender aligns the text-vision attention in the VLM transformer with the equivalent used by Stable Diffusion during SFT, instead of adapting separate encoders. This alignment enriches the model's visual understanding and significantly boosts performance across in- and out-of-distribution tasks. Lavender requires just 0.13 million training examples, 2.5% of typical large-scale SFT datasets, and fine-tunes on standard hardware (8 GPUs) in a single day. It consistently improves state-of-the-art open-source multimodal LLMs (e.g., Llama-3.2-11B, MiniCPM-Llama3-v2.5), achieving up to 30% gains and a 68% boost on challenging out-of-distribution medical QA tasks. By efficiently transferring the visual expertise of image generators with minimal supervision, Lavender offers a scalable solution for more accurate vision-language systems. All code, training data, and models will be shared at this https URL.</li>
</ul>

<h3>Title: Globality Strikes Back: Rethinking the Global Knowledge of CLIP in Training-Free Open-Vocabulary Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jingyun Wang, Cilin Yan, Guoliang Kang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06818">https://arxiv.org/abs/2502.06818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06818">https://arxiv.org/pdf/2502.06818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06818]] Globality Strikes Back: Rethinking the Global Knowledge of CLIP in Training-Free Open-Vocabulary Semantic Segmentation(https://arxiv.org/abs/2502.06818)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent works modify CLIP to perform open-vocabulary semantic segmentation in a training-free manner (TF-OVSS). In CLIP, patch-wise image representations mainly encode the homogeneous image-level properties and thus are not discriminative enough, hindering its application to the dense prediction task. Previous works make image features more distinct across patches, through making each patch mainly attend to itself or the neighboring patches within a narrow local window. However, with their modifications, the ability of CLIP to aggregate global context information, which is known to be useful for distinguishing confusing categories, is largely weakened. In this paper, we propose a new method named GCLIP, which mines the beneficial global knowledge of CLIP to facilitate the TF-OVSS task. Firstly, we aim to equip the last-block attention with image-level properties while not introducing homogeneous attention patterns across patches. In GCLIP, we merge the attention from the global token emerging blocks with the Query-Query attention to realize this goal. Secondly, we aim to make the Value embeddings of the last-block attention module more distinct and semantically correlated. To realize this, we design a novel channel suppression strategy. As the representation of each patch is finally determined by the attention weights and the Value embeddings, our method can generate more discriminative patch-level image features while absorbing global context information. Extensive experiments on five standard benchmarks demonstrate that our method consistently outperforms previous state-of-the-arts.</li>
</ul>

<h3>Title: Functional 3D Scene Synthesis through Human-Scene Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yao Wei, Matteo Toso, Pietro Morerio, Michael Ying Yang, Alessio Del Bue</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06819">https://arxiv.org/abs/2502.06819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06819">https://arxiv.org/pdf/2502.06819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06819]] Functional 3D Scene Synthesis through Human-Scene Optimization(https://arxiv.org/abs/2502.06819)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper presents a novel generative approach that outputs 3D indoor environments solely from a textual description of the scene. Current methods often treat scene synthesis as a mere layout prediction task, leading to rooms with overlapping objects or overly structured scenes, with limited consideration of the practical usability of the generated environment. Instead, our approach is based on a simple, but effective principle: we condition scene synthesis to generate rooms that are usable by humans. This principle is implemented by synthesizing 3D humans that interact with the objects composing the scene. If this human-centric scene generation is viable, the room layout is functional and it leads to a more coherent 3D structure. To this end, we propose a novel method for functional 3D scene synthesis, which consists of reasoning, 3D assembling and optimization. We regard text guided 3D synthesis as a reasoning process by generating a scene graph via a graph diffusion network. Considering object functional co-occurrence, a new strategy is designed to better accommodate human-object interaction and avoidance, achieving human-aware 3D scene optimization. We conduct both qualitative and quantitative experiments to validate the effectiveness of our method in generating coherent 3D scene synthesis results.</li>
</ul>

<h3>Title: LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zhekai Du, Yinjie Min, Jingjing Li, Ke Lu, Changliang Zou, Liuhua Peng, Tingjin Chu, Mingming Gong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06820">https://arxiv.org/abs/2502.06820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06820">https://arxiv.org/pdf/2502.06820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06820]] LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning(https://arxiv.org/abs/2502.06820)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Low-rank adaptation (LoRA) has become a prevalent method for adapting pre-trained large language models to downstream tasks. However, the simple low-rank decomposition form may constrain the hypothesis space. To address this limitation, we introduce Location-aware Cosine Adaptation (LoCA), a novel frequency-domain parameter-efficient fine-tuning method based on inverse Discrete Cosine Transform (iDCT) with selective locations of learnable components. We begin with a comprehensive theoretical comparison between frequency-domain and low-rank decompositions for fine-tuning pre-trained large models. Our analysis reveals that frequency-domain approximation with carefully selected frequency components can surpass the expressivity of traditional low-rank-based methods. Furthermore, we demonstrate that iDCT offers a more efficient implementation compared to inverse Discrete Fourier Transform (iDFT), allowing for better selection and tuning of frequency components while maintaining equivalent expressivity to the optimal iDFT-based adaptation. By employing finite-difference approximation to estimate gradients for discrete locations of learnable coefficients on the DCT spectrum, LoCA dynamically selects the most informative frequency components during training. Experiments on diverse language and vision fine-tuning tasks demonstrate that LoCA offers enhanced parameter efficiency while maintains computational feasibility comparable to low-rank-based methods.</li>
</ul>

<h3>Title: DiffListener: Discrete Diffusion Model for Listener Generation</h3>
<ul>
<li><strong>Authors: </strong>Siyeol Jung, Taehwan Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06822">https://arxiv.org/abs/2502.06822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06822">https://arxiv.org/pdf/2502.06822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06822]] DiffListener: Discrete Diffusion Model for Listener Generation(https://arxiv.org/abs/2502.06822)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The listener head generation (LHG) task aims to generate natural nonverbal listener responses based on the speaker's multimodal cues. While prior work either rely on limited modalities (e.g. audio and facial information) or employ autoregressive approaches which have limitations such as accumulating prediction errors. To address these limitations, we propose DiffListener, a discrete diffusion based approach for non-autoregressive listener head generation. Our model takes the speaker's facial information, audio, and text as inputs, additionally incorporating facial differential information to represent the temporal dynamics of expressions and movements. With this explicit modeling of facial dynamics, DiffListener can generate coherent reaction sequences in a non-autoregressive manner. Through comprehensive experiments, DiffListener demonstrates state-of-the-art performance in both quantitative and qualitative evaluations. The user study shows that DiffListener generates natural context-aware listener reactions that are well synchronized with the speaker. The code and demo videos are available in this https URL</li>
</ul>

<h3>Title: CTR-Driven Advertising Image Generation with Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xingye Chen, Wei Feng, Zhenbang Du, Weizhen Wang, Yanyin Chen, Haohan Wang, Linkai Liu, Yaoyu Li, Jinyuan Zhao, Yu Li, Zheng Zhang, Jingjing Lv, Junjie Shen, Zhangang Lin, Jingping Shao, Yuanjie Shao, Xinge You, Changxin Gao, Nong Sang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GR, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06823">https://arxiv.org/abs/2502.06823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06823">https://arxiv.org/pdf/2502.06823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06823]] CTR-Driven Advertising Image Generation with Multimodal Large Language Models(https://arxiv.org/abs/2502.06823)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In web data, advertising images are crucial for capturing user attention and improving advertising effectiveness. Most existing methods generate background for products primarily focus on the aesthetic quality, which may fail to achieve satisfactory online performance. To address this limitation, we explore the use of Multimodal Large Language Models (MLLMs) for generating advertising images by optimizing for Click-Through Rate (CTR) as the primary objective. Firstly, we build targeted pre-training tasks, and leverage a large-scale e-commerce multimodal dataset to equip MLLMs with initial capabilities for advertising image generation tasks. To further improve the CTR of generated images, we propose a novel reward model to fine-tune pre-trained MLLMs through Reinforcement Learning (RL), which can jointly utilize multimodal features and accurately reflect user click preferences. Meanwhile, a product-centric preference optimization strategy is developed to ensure that the generated background content aligns with the product characteristics after fine-tuning, enhancing the overall relevance and effectiveness of the advertising images. Extensive experiments have demonstrated that our method achieves state-of-the-art performance in both online and offline metrics. Our code and pre-trained models are publicly available at: this https URL.</li>
</ul>

<h3>Title: RLOMM: An Efficient and Robust Online Map Matching Framework with Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Minxiao Chen, Haitao Yuan, Nan Jiang, Zhihan Zheng, Sai Wu, Ao Zhou, Shangguang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06825">https://arxiv.org/abs/2502.06825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06825">https://arxiv.org/pdf/2502.06825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06825]] RLOMM: An Efficient and Robust Online Map Matching Framework with Reinforcement Learning(https://arxiv.org/abs/2502.06825)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Online map matching is a fundamental problem in location-based services, aiming to incrementally match trajectory data step-by-step onto a road network. However, existing methods fail to meet the needs for efficiency, robustness, and accuracy required by large-scale online applications, making this task still a challenging problem. This paper introduces a novel framework that achieves high accuracy and efficient matching while ensuring robustness in handling diverse scenarios. To improve efficiency, we begin by modeling the online map matching problem as an Online Markov Decision Process (OMDP) based on its inherent characteristics. This approach helps efficiently merge historical and real-time data, reducing unnecessary calculations. Next, to enhance the model's robustness, we design a reinforcement learning method, enabling robust handling of real-time data from dynamically changing environments. In particular, we propose a novel model learning process and a comprehensive reward function, allowing the model to make reasonable current matches from a future-oriented perspective, and to continuously update and optimize during the decision-making process based on feedback. Lastly, to address the heterogeneity between trajectories and roads, we design distinct graph structures, facilitating efficient representation learning through graph and recurrent neural networks. To further align trajectory and road data, we introduce contrastive learning to decrease their distance in the latent space, thereby promoting effective integration of the two. Extensive evaluations on three real-world datasets confirm that our method significantly outperforms existing state-of-the-art solutions in terms of accuracy, efficiency and robustness.</li>
</ul>

<h3>Title: Learning to Synthesize Compatible Fashion Items Using Semantic Alignment and Collocation Classification: An Outfit Generation Framework</h3>
<ul>
<li><strong>Authors: </strong>Dongliang Zhou, Haijun Zhang, Kai Yang, Linlin Liu, Han Yan, Xiaofei Xu, Zhao Zhang, Shuicheng Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06827">https://arxiv.org/abs/2502.06827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06827">https://arxiv.org/pdf/2502.06827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06827]] Learning to Synthesize Compatible Fashion Items Using Semantic Alignment and Collocation Classification: An Outfit Generation Framework(https://arxiv.org/abs/2502.06827)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The field of fashion compatibility learning has attracted great attention from both the academic and industrial communities in recent years. Many studies have been carried out for fashion compatibility prediction, collocated outfit recommendation, artificial intelligence (AI)-enabled compatible fashion design, and related topics. In particular, AI-enabled compatible fashion design can be used to synthesize compatible fashion items or outfits in order to improve the design experience for designers or the efficacy of recommendations for customers. However, previous generative models for collocated fashion synthesis have generally focused on the image-to-image translation between fashion items of upper and lower clothing. In this paper, we propose a novel outfit generation framework, i.e., OutfitGAN, with the aim of synthesizing a set of complementary items to compose an entire outfit, given one extant fashion item and reference masks of target synthesized items. OutfitGAN includes a semantic alignment module, which is responsible for characterizing the mapping correspondence between the existing fashion items and the synthesized ones, to improve the quality of the synthesized images, and a collocation classification module, which is used to improve the compatibility of a synthesized outfit. In order to evaluate the performance of our proposed models, we built a large-scale dataset consisting of 20,000 fashion outfits. Extensive experimental results on this dataset show that our OutfitGAN can synthesize photo-realistic outfits and outperform state-of-the-art methods in terms of similarity, authenticity and compatibility measurements.</li>
</ul>

<h3>Title: No Location Left Behind: Measuring and Improving the Fairness of Implicit Representations for Earth Data</h3>
<ul>
<li><strong>Authors: </strong>Daniel Cai, Randall Balestriero</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06831">https://arxiv.org/abs/2502.06831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06831">https://arxiv.org/pdf/2502.06831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06831]] No Location Left Behind: Measuring and Improving the Fairness of Implicit Representations for Earth Data(https://arxiv.org/abs/2502.06831)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Implicit neural representations (INRs) exhibit growing promise in addressing Earth representation challenges, ranging from emissions monitoring to climate modeling. However, existing methods disproportionately prioritize global average performance, whereas practitioners require fine-grained insights to understand biases and variations in these models. To bridge this gap, we introduce FAIR-Earth: a first-of-its-kind dataset explicitly crafted to examine and challenge inequities in Earth representations. FAIR-Earth comprises various high-resolution Earth signals and uniquely aggregates extensive metadata along stratifications like landmass size and population density to assess the fairness of models. Evaluating state-of-the-art INRs across the various modalities of FAIR-Earth, we uncover striking performance disparities. Certain subgroups, especially those associated with high-frequency signals (e.g., islands, coastlines), are consistently poorly modeled by existing methods. In response, we propose spherical wavelet encodings, building on previous spatial encoding research. Leveraging the multi-resolution capabilities of wavelets, our encodings yield consistent performance over various scales and locations, offering more accurate and robust representations of the biased subgroups. These open-source contributions represent a crucial step towards the equitable assessment and deployment of Earth INRs.</li>
</ul>

<h3>Title: Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach</h3>
<ul>
<li><strong>Authors: </strong>Xu Zhang, Kaidi Xu, Ziqing Hu, Ren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06832">https://arxiv.org/abs/2502.06832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06832">https://arxiv.org/pdf/2502.06832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06832]] Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach(https://arxiv.org/abs/2502.06832)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Mixture of Experts (MoE) have shown remarkable success in leveraging specialized expert networks for complex machine learning tasks. However, their susceptibility to adversarial attacks presents a critical challenge for deployment in robust applications. This paper addresses the critical question of how to incorporate robustness into MoEs while maintaining high natural accuracy. We begin by analyzing the vulnerability of MoE components, finding that expert networks are notably more susceptible to adversarial attacks than the router. Based on this insight, we propose a targeted robust training technique that integrates a novel loss function to enhance the adversarial robustness of MoE, requiring only the robustification of one additional expert without compromising training or inference efficiency. Building on this, we introduce a dual-model strategy that linearly combines a standard MoE model with our robustified MoE model using a smoothing parameter. This approach allows for flexible control over the robustness-accuracy trade-off. We further provide theoretical foundations by deriving certified robustness bounds for both the single MoE and the dual-model. To push the boundaries of robustness and accuracy, we propose a novel joint training strategy JTDMoE for the dual-model. This joint training enhances both robustness and accuracy beyond what is achievable with separate models. Experimental results on CIFAR-10 and TinyImageNet datasets using ResNet18 and Vision Transformer (ViT) architectures demonstrate the effectiveness of our proposed methods.</li>
</ul>

<h3>Title: CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction</h3>
<ul>
<li><strong>Authors: </strong>Jaewan Lee, Changyoung Park, Hongjun Yang, Sungbin Lim, Sehui Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06836">https://arxiv.org/abs/2502.06836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06836">https://arxiv.org/pdf/2502.06836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06836]] CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction(https://arxiv.org/abs/2502.06836)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in AI have revolutionized property prediction in materials science and accelerating material discovery. Graph neural networks (GNNs) stand out due to their ability to represent crystal structures as graphs, effectively capturing local interactions and delivering superior predictions. However, these methods often lose critical global information, such as crystal systems and repetitive unit connectivity. To address this, we propose CAST, a cross-attention-based multimodal fusion model that integrates graph and text modalities to preserve essential material information. CAST combines node- and token-level features using cross-attention mechanisms, surpassing previous approaches reliant on material-level embeddings like graph mean-pooling or [CLS] tokens. A masked node prediction pretraining strategy further enhances atomic-level information integration. Our method achieved up to 22.9\% improvement in property prediction across four crystal properties including band gap compared to methods like CrysMMNet and MultiMat. Pretraining was key to aligning node and text embeddings, with attention maps confirming its effectiveness in capturing relationships between nodes and tokens. This study highlights the potential of multimodal learning in materials science, paving the way for more robust predictive models that incorporate both local and global information.</li>
</ul>

<h3>Title: Comparison of CNN-based deep learning architectures for unsteady CFD acceleration on small datasets</h3>
<ul>
<li><strong>Authors: </strong>Sangam Khanal, Shilaj Baral, Joongoo Jeon</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06837">https://arxiv.org/abs/2502.06837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06837">https://arxiv.org/pdf/2502.06837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06837]] Comparison of CNN-based deep learning architectures for unsteady CFD acceleration on small datasets(https://arxiv.org/abs/2502.06837)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>CFD acceleration for virtual nuclear reactors or digital twin technology is a primary goal in the nuclear industry. This study compares advanced convolutional neural network (CNN) architectures for accelerating unsteady computational fluid dynamics (CFD) simulations using small datasets based on a challenging natural convection flow dataset. The advanced architectures such as autoencoders, UNet, and ConvLSTM-UNet, were evaluated under identical conditions to determine their predictive accuracy and robustness in autoregressive time-series predictions. ConvLSTM-UNet consistently outperformed other models, particularly in difference value calculation, achieving lower maximum errors and stable residuals. However, error accumulation remains a challenge, limiting reliable predictions to approximately 10 timesteps. This highlights the need for enhanced strategies to improve long-term prediction stability. The novelty of this work lies in its fair comparison of state-of-the-art CNN models within the RePIT framework, demonstrating their potential for accelerating CFD simulations while identifying limitations under small data conditions. Future research will focus on exploring alternative models, such as graph neural networks and implicit neural representations. These efforts aim to develop a robust hybrid approach for long-term unsteady CFD acceleration, contributing to practical applications in virtual nuclear reactor.</li>
</ul>

<h3>Title: TorchResist: Open-Source Differentiable Resist Simulator</h3>
<ul>
<li><strong>Authors: </strong>Zixiao Wang, Jieya Zhou, Su Zheng, Shuo Yin, Kaichao Liang, Shoubo Hu, Xiao Chen, Bei Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06838">https://arxiv.org/abs/2502.06838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06838">https://arxiv.org/pdf/2502.06838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06838]] TorchResist: Open-Source Differentiable Resist Simulator(https://arxiv.org/abs/2502.06838)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent decades have witnessed remarkable advancements in artificial intelligence (AI), including large language models (LLMs), image and video generative models, and embodied AI systems. These advancements have led to an explosive increase in the demand for computational power, challenging the limits of Moore's Law. Optical lithography, a critical technology in semiconductor manufacturing, faces significant challenges due to its high costs. To address this, various lithography simulators have been developed. However, many of these simulators are limited by their inadequate photoresist modeling capabilities. This paper presents TorchResist, an open-source, differentiable photoresist this http URL employs an analytical approach to model the photoresist process, functioning as a white-box system with at most twenty interpretable parameters. Leveraging modern differentiable programming techniques and parallel computing on GPUs, TorchResist enables seamless co-optimization with other tools across multiple related tasks. Our experimental results demonstrate that TorchResist achieves superior accuracy and efficiency compared to existing solutions. The source code is publicly available.</li>
</ul>

<h3>Title: Vision-Integrated LLMs for Autonomous Driving Assistance : Human Performance Comparison and Trust Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Namhee Kim, Woojin Park</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06843">https://arxiv.org/abs/2502.06843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06843">https://arxiv.org/pdf/2502.06843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06843]] Vision-Integrated LLMs for Autonomous Driving Assistance : Human Performance Comparison and Trust Evaluation(https://arxiv.org/abs/2502.06843)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Traditional autonomous driving systems often struggle with reasoning in complex, unexpected scenarios due to limited comprehension of spatial relationships. In response, this study introduces a Large Language Model (LLM)-based Autonomous Driving (AD) assistance system that integrates a vision adapter and an LLM reasoning module to enhance visual understanding and decision-making. The vision adapter, combining YOLOv4 and Vision Transformer (ViT), extracts comprehensive visual features, while GPT-4 enables human-like spatial reasoning and response generation. Experimental evaluations with 45 experienced drivers revealed that the system closely mirrors human performance in describing situations and moderately aligns with human decisions in generating appropriate responses.</li>
</ul>

<h3>Title: Exploring Model Invariance with Discrete Search for Ultra-Low-Bit Quantization</h3>
<ul>
<li><strong>Authors: </strong>Yuqiao Wen, Yanshuai Cao, Lili Mou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06844">https://arxiv.org/abs/2502.06844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06844">https://arxiv.org/pdf/2502.06844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06844]] Exploring Model Invariance with Discrete Search for Ultra-Low-Bit Quantization(https://arxiv.org/abs/2502.06844)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have been increasing in size due to their success in a wide range of applications. This calls for a pressing need to reduce memory usage to make them more accessible. Post-training quantization is a popular technique which uses fewer bits (e.g., 4--8 bits) to represent the model without retraining it. However, it remains a challenging task to perform quantization in an ultra-low-bit setup (e.g., 2 bits). In this paper, we propose InvarExplore, a unified framework that systematically explores different model invariance at the same time, allowing us to take advantage of the synergy between each type of invariance. Importantly, InvarExplore features a discrete search algorithm that enables us to explore permutation invariance, which is under-studied as it cannot be optimized with gradient-based methods. Results show that InvarExplore is compatible with existing state-of-the-art methods, achieving an add-on performance improvement over strong competing methods.</li>
</ul>

<h3>Title: Prot2Chat: Protein LLM with Early Fusion of Sequence and Structure</h3>
<ul>
<li><strong>Authors: </strong>Zhicong Wang, Zicheng Ma, Ziqiang Cao, Changlong Zhou, Jun Zhang, Yiqin Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06846">https://arxiv.org/abs/2502.06846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06846">https://arxiv.org/pdf/2502.06846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06846]] Prot2Chat: Protein LLM with Early Fusion of Sequence and Structure(https://arxiv.org/abs/2502.06846)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Proteins play a pivotal role in living organisms, yet understanding their functions presents significant challenges, including the limited flexibility of classification-based methods, the inability to effectively leverage spatial structural information, and the lack of systematic evaluation metrics for protein Q&A systems. To address these limitations, we propose Prot2Chat, a novel framework that integrates multimodal protein representations with natural language through a unified module, enabling large language model (LLM)-driven answer generation. Our model incorporates a modified ProteinMPNN encoder, which encodes protein sequence and structural information in a unified manner, a protein-text adapter with cross-attention mechanisms, and a LLaMA3 decoder. To optimize training efficiency, we freeze the encoder and employ LoRA techniques for the decoder. We conducted experiments on two datasets, both automated metrics and expert evaluations demonstrate the superior performance of our model. Furthermore, zero-shot prediction results highlight its strong generalization capabilities. This framework offers a promising solution for bridging protein domain knowledge with natural language understanding, paving the way for transformative advancements in protein-related research.</li>
</ul>

<h3>Title: A Deep Learning Framework Integrating CNN and BiLSTM for Financial Systemic Risk Analysis and Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yu Cheng, Zhen Xu, Yuan Chen, Yuhan Wang, Zhenghao Lin, Jinsong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06847">https://arxiv.org/abs/2502.06847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06847">https://arxiv.org/pdf/2502.06847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06847]] A Deep Learning Framework Integrating CNN and BiLSTM for Financial Systemic Risk Analysis and Prediction(https://arxiv.org/abs/2502.06847)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This study proposes a deep learning model based on the combination of convolutional neural network (CNN) and bidirectional long short-term memory network (BiLSTM) for discriminant analysis of financial systemic risk. The model first uses CNN to extract local patterns of multidimensional features of financial markets, and then models the bidirectional dependency of time series through BiLSTM, to comprehensively characterize the changing laws of systemic risk in spatial features and temporal dynamics. The experiment is based on real financial data sets. The results show that the model is significantly superior to traditional single models (such as BiLSTM, CNN, Transformer, and TCN) in terms of accuracy, recall, and F1 score. The F1-score reaches 0.88, showing extremely high discriminant ability. This shows that the joint strategy of combining CNN and BiLSTM can not only fully capture the complex patterns of market data but also effectively deal with the long-term dependency problem in time series data. In addition, this study also explores the robustness of the model in dealing with data noise and processing high-dimensional data, providing strong support for intelligent financial risk management. In the future, the research will further optimize the model structure, introduce methods such as reinforcement learning and multimodal data analysis, and improve the efficiency and generalization ability of the model to cope with a more complex financial environment.</li>
</ul>

<h3>Title: Survey on Vision-Language-Action Models</h3>
<ul>
<li><strong>Authors: </strong>Adilzhan Adilkhanov, Amir Yelenov, Assylkhan Seitzhanov, Ayan Mazhitov, Azamat Abdikarimov, Danissa Sandykbayeva, Daryn Kenzhebek, Daulet Baimukashev, Dinmukhammed Mukashev, Ilyas Umurbekov, Jabrail Chumakov, Kamila Spanova, Karina Burunchina, Rasul Yermagambet, Rustam Chibar, Saltanat Seitzhan, Soibkhon Khajikhanov, Tasbolat Taunyazov, Temirlan Galimzhanov, Temirlan Kaiyrbay, Tleukhan Mussin, Togzhan Syrymova, Valeriya Kostyukova, Yermakhan Kassym, Madina Yergibay, Margulan Issa, Moldir Zabirova, Nurdaulet Zhuzbay, Nurlan Kabdyshev, Nurlan Zhaniyar, Yerkebulan Massalim, Zerde Nurbayeva, Zhanat Kappassov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06851">https://arxiv.org/abs/2502.06851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06851">https://arxiv.org/pdf/2502.06851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06851]] Survey on Vision-Language-Action Models(https://arxiv.org/abs/2502.06851)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents an AI-generated review of Vision-Language-Action (VLA) models, summarizing key methodologies, findings, and future directions. The content is produced using large language models (LLMs) and is intended only for demonstration purposes. This work does not represent original research, but highlights how AI can help automate literature reviews. As AI-generated content becomes more prevalent, ensuring accuracy, reliability, and proper synthesis remains a challenge. Future research will focus on developing a structured framework for AI-assisted literature reviews, exploring techniques to enhance citation accuracy, source credibility, and contextual understanding. By examining the potential and limitations of LLM in academic writing, this study aims to contribute to the broader discussion of integrating AI into research workflows. This work serves as a preliminary step toward establishing systematic approaches for leveraging AI in literature review generation, making academic knowledge synthesis more efficient and scalable.</li>
</ul>

<h3>Title: EAP-GP: Mitigating Saturation Effect in Gradient-based Automated Circuit Identification</h3>
<ul>
<li><strong>Authors: </strong>Lin Zhang, Wenshuo Dong, Zhuoran Zhang, Shu Yang, Lijie Hu, Ninghao Liu, Pan Zhou, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06852">https://arxiv.org/abs/2502.06852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06852">https://arxiv.org/pdf/2502.06852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06852]] EAP-GP: Mitigating Saturation Effect in Gradient-based Automated Circuit Identification(https://arxiv.org/abs/2502.06852)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Understanding the internal mechanisms of transformer-based language models remains challenging. Mechanistic interpretability based on circuit discovery aims to reverse engineer neural networks by analyzing their internal processes at the level of computational subgraphs. In this paper, we revisit existing gradient-based circuit identification methods and find that their performance is either affected by the zero-gradient problem or saturation effects, where edge attribution scores become insensitive to input changes, resulting in noisy and unreliable attribution evaluations for circuit components. To address the saturation effect, we propose Edge Attribution Patching with GradPath (EAP-GP), EAP-GP introduces an integration path, starting from the input and adaptively following the direction of the difference between the gradients of corrupted and clean inputs to avoid the saturated region. This approach enhances attribution reliability and improves the faithfulness of circuit identification. We evaluate EAP-GP on 6 datasets using GPT-2 Small, GPT-2 Medium, and GPT-2 XL. Experimental results demonstrate that EAP-GP outperforms existing methods in circuit faithfulness, achieving improvements up to 17.7%. Comparisons with manually annotated ground-truth circuits demonstrate that EAP-GP achieves precision and recall comparable to or better than previous approaches, highlighting its effectiveness in identifying accurate circuits.</li>
</ul>

<h3>Title: Can Large Language Models Understand Intermediate Representations?</h3>
<ul>
<li><strong>Authors: </strong>Hailong Jiang, Jianfeng Zhu, Yao Wan, Bo Fang, Hongyu Zhang, Ruoming Jin, Qiang Guan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06854">https://arxiv.org/abs/2502.06854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06854">https://arxiv.org/pdf/2502.06854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06854]] Can Large Language Models Understand Intermediate Representations?(https://arxiv.org/abs/2502.06854)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Intermediate Representations (IRs) are essential in compiler design and program analysis, yet their comprehension by Large Language Models (LLMs) remains underexplored. This paper presents a pioneering empirical study to investigate the capabilities of LLMs, including GPT-4, GPT-3, Gemma 2, LLaMA 3.1, and Code Llama, in understanding IRs. We analyze their performance across four tasks: Control Flow Graph (CFG) reconstruction, decompilation, code summarization, and execution reasoning. Our results indicate that while LLMs demonstrate competence in parsing IR syntax and recognizing high-level structures, they struggle with control flow reasoning, execution semantics, and loop handling. Specifically, they often misinterpret branching instructions, omit critical IR operations, and rely on heuristic-based reasoning, leading to errors in CFG reconstruction, IR decompilation, and execution reasoning. The study underscores the necessity for IR-specific enhancements in LLMs, recommending fine-tuning on structured IR datasets and integration of explicit control flow models to augment their comprehension and handling of IR-related tasks.</li>
</ul>

<h3>Title: Self-Supervised Prompt Optimization</h3>
<ul>
<li><strong>Authors: </strong>Jinyu Xiang, Jiayi Zhang, Zhaoyang Yu, Fengwei Teng, Jinhao Tu, Xinbing Liang, Sirui Hong, Chenglin Wu, Yuyu Luo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06855">https://arxiv.org/abs/2502.06855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06855">https://arxiv.org/pdf/2502.06855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06855]] Self-Supervised Prompt Optimization(https://arxiv.org/abs/2502.06855)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Well-designed prompts are crucial for enhancing Large language models' (LLMs) reasoning capabilities while aligning their outputs with task requirements across diverse domains. However, manually designed prompts require expertise and iterative experimentation. While existing prompt optimization methods aim to automate this process, they rely heavily on external references such as ground truth or by humans, limiting their applicability in real-world scenarios where such data is unavailable or costly to obtain. To address this, we propose Self-Supervised Prompt Optimization (SPO), a cost-efficient framework that discovers effective prompts for both closed and open-ended tasks without requiring external reference. Motivated by the observations that prompt quality manifests directly in LLM outputs and LLMs can effectively assess adherence to task requirements, we derive evaluation and optimization signals purely from output comparisons. Specifically, SPO selects superior prompts through pairwise output comparisons evaluated by an LLM evaluator, followed by an LLM optimizer that aligns outputs with task requirements. Extensive experiments demonstrate that SPO outperforms state-of-the-art prompt optimization methods, achieving comparable or superior results with significantly lower costs (e.g., 1.1% to 5.6% of existing methods) and fewer samples (e.g., three samples). The code is available at this https URL.</li>
</ul>

<h3>Title: Gemstones: A Model Suite for Multi-Faceted Scaling Laws</h3>
<ul>
<li><strong>Authors: </strong>Sean McLeish, John Kirchenbauer, David Yu Miller, Siddharth Singh, Abhinav Bhatele, Micah Goldblum, Ashwinee Panda, Tom Goldstein</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06857">https://arxiv.org/abs/2502.06857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06857">https://arxiv.org/pdf/2502.06857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06857]] Gemstones: A Model Suite for Multi-Faceted Scaling Laws(https://arxiv.org/abs/2502.06857)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Scaling laws are typically fit using a family of models with a narrow range of frozen hyper-parameter choices. In this work we study scaling laws using a wide range of architecture and hyper-parameter choices, and highlight their impact on resulting prescriptions. As a primary artifact of our research, we release the Gemstones: the most comprehensive open-source scaling law dataset to date, consisting of over 4000 checkpoints from transformers with up to 2 billion parameters; these models have been trained with different learning rates, cooldown schedules, and architectural shapes. Our checkpoints enable more complex studies of scaling, such as a law that predicts language modeling performance as a function of model width and depth. By examining the various facets of our model suite, we find that the prescriptions of scaling laws can be highly sensitive to the experimental design process and the specific model checkpoints used during fitting. Code: this https URL</li>
</ul>

<h3>Title: LLM-Supported Natural Language to Bash Translation</h3>
<ul>
<li><strong>Authors: </strong>Finnian Westenfelder, Erik Hemberg, Miguel Tulla, Stephen Moskal, Una-May O'Reilly, Silviu Chiricescu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06858">https://arxiv.org/abs/2502.06858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06858">https://arxiv.org/pdf/2502.06858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06858]] LLM-Supported Natural Language to Bash Translation(https://arxiv.org/abs/2502.06858)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Bourne-Again Shell (Bash) command-line interface for Linux systems has complex syntax and requires extensive specialized knowledge. Using the natural language to Bash command (NL2SH) translation capabilities of large language models (LLMs) for command composition circumvents these issues. However, the NL2SH performance of LLMs is difficult to assess due to inaccurate test data and unreliable heuristics for determining the functional equivalence of Bash commands. We present a manually verified test dataset of 600 instruction-command pairs and a training dataset of 40,939 pairs, increasing the size of previous datasets by 441% and 135%, respectively. Further, we present a novel functional equivalence heuristic that combines command execution with LLM evaluation of command outputs. Our heuristic can determine the functional equivalence of two Bash commands with 95% confidence, a 16% increase over previous heuristics. Evaluation of popular LLMs using our test dataset and heuristic demonstrates that parsing, in-context learning, in-weight learning, and constrained decoding can improve NL2SH accuracy by up to 32%. Our findings emphasize the importance of dataset quality, execution-based evaluation and translation method for advancing NL2SH translation. Our code is available at this https URL</li>
</ul>

<h3>Title: AutoSketch: VLM-assisted Style-Aware Vector Sketch Completion</h3>
<ul>
<li><strong>Authors: </strong>Hsiao-Yuan Chin, I-Chao Shen, Yi-Ting Chiu, Bing-Yu Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06860">https://arxiv.org/abs/2502.06860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06860">https://arxiv.org/pdf/2502.06860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06860]] AutoSketch: VLM-assisted Style-Aware Vector Sketch Completion(https://arxiv.org/abs/2502.06860)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The ability to automatically complete a partial sketch that depicts a complex scene, e.g., "a woman chatting with a man in the park", is very useful. However, existing sketch generation methods create sketches from scratch; they do not complete a partial sketch in the style of the original. To address this challenge, we introduce AutoSketch, a styleaware vector sketch completion method that accommodates diverse sketch styles. Our key observation is that the style descriptions of a sketch in natural language preserve the style during automatic sketch completion. Thus, we use a pretrained vision-language model (VLM) to describe the styles of the partial sketches in natural language and replicate these styles using newly generated strokes. We initially optimize the strokes to match an input prompt augmented by style descriptions extracted from the VLM. Such descriptions allow the method to establish a diffusion prior in close alignment with that of the partial sketch. Next, we utilize the VLM to generate an executable style adjustment code that adjusts the strokes to conform to the desired style. We compare our method with existing methods across various sketch styles and prompts, performed extensive ablation studies and qualitative and quantitative evaluations, and demonstrate that AutoSketch can support various sketch scenarios.</li>
</ul>

<h3>Title: PoincarÃ© Inequality for Local Log-Polyak-Lojasiewicz Measures : Non-asymptotic Analysis in Low-temperature Regime</h3>
<ul>
<li><strong>Authors: </strong>Yun Gong, Zebang Shen, Niao He</a></li>
<li><strong>Subjects: </strong>cs.LG, math.CA, math.FA, math.PR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06862">https://arxiv.org/abs/2502.06862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06862">https://arxiv.org/pdf/2502.06862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06862]] PoincarÃ© Inequality for Local Log-Polyak-Lojasiewicz Measures : Non-asymptotic Analysis in Low-temperature Regime(https://arxiv.org/abs/2502.06862)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Potential functions in highly pertinent applications, such as deep learning in over-parameterized regime, are empirically observed to admit non-isolated minima. To understand the convergence behavior of stochastic dynamics in such landscapes, we propose to study the class of \logPLmeasure\ measures $\mu_\epsilon \propto \exp(-V/\epsilon)$, where the potential $V$ satisfies a local Polyak-Åojasiewicz (PÅ) inequality, and its set of local minima is provably \emph{connected}. Notably, potentials in this class can exhibit local maxima and we characterize its optimal set S to be a compact $\mathcal{C}^2$ \emph{embedding submanifold} of $\mathbb{R}^d$ without boundary. The \emph{non-contractibility} of S distinguishes our function class from the classical convex setting topologically. Moreover, the embedding structure induces a naturally defined Laplacian-Beltrami operator on S, and we show that its first non-trivial eigenvalue provides an \emph{$\epsilon$-independent} lower bound for the \Poincare\ constant in the \Poincare\ inequality of $\mu_\epsilon$. As a direct consequence, Langevin dynamics with such non-convex potential $V$ and diffusion coefficient $\epsilon$ converges to its equilibrium $\mu_\epsilon$ at a rate of $\tilde{\mathcal{O}}(1/\epsilon)$, provided $\epsilon$ is sufficiently small. Here $\tilde{\mathcal{O}}$ hides logarithmic terms.</li>
</ul>

<h3>Title: BF-GAN: Development of an AI-driven Bubbly Flow Image Generation Model Using Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Wen Zhou, Shuichiro Miwa, Yang Liu, Koji Okamoto</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06863">https://arxiv.org/abs/2502.06863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06863">https://arxiv.org/pdf/2502.06863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06863]] BF-GAN: Development of an AI-driven Bubbly Flow Image Generation Model Using Generative Adversarial Networks(https://arxiv.org/abs/2502.06863)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>A generative AI architecture called bubbly flow generative adversarial networks (BF-GAN) is developed, designed to generate realistic and high-quality bubbly flow images through physically conditioned inputs, jg and jf. Initially, 52 sets of bubbly flow experiments under varying conditions are conducted to collect 140,000 bubbly flow images with physical labels of jg and jf for training data. A multi-scale loss function is then developed, incorporating mismatch loss and pixel loss to enhance the generative performance of BF-GAN further. Regarding evaluative metrics of generative AI, the BF-GAN has surpassed conventional GAN. Physically, key parameters of bubbly flow generated by BF-GAN are extracted and compared with measurement values and empirical correlations, validating BF-GAN's generative performance. The comparative analysis demonstrate that the BF-GAN can generate realistic and high-quality bubbly flow images with any given jg and jf within the research scope. BF-GAN offers a generative AI solution for two-phase flow research, substantially lowering the time and cost required to obtain high-quality data. In addition, it can function as a benchmark dataset generator for bubbly flow detection and segmentation algorithms, enhancing overall productivity in this research domain. The BF-GAN model is available online (this https URL).</li>
</ul>

<h3>Title: Knowledge Graph-Guided Retrieval Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiangrong Zhu, Yuexiang Xie, Yi Liu, Yaliang Li, Wei Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06864">https://arxiv.org/abs/2502.06864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06864">https://arxiv.org/pdf/2502.06864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06864]] Knowledge Graph-Guided Retrieval Augmented Generation(https://arxiv.org/abs/2502.06864)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) has emerged as a promising technology for addressing hallucination issues in the responses generated by large language models (LLMs). Existing studies on RAG primarily focus on applying semantic-based approaches to retrieve isolated relevant chunks, which ignore their intrinsic relationships. In this paper, we propose a novel Knowledge Graph-Guided Retrieval Augmented Generation (KG$^2$RAG) framework that utilizes knowledge graphs (KGs) to provide fact-level relationships between chunks, improving the diversity and coherence of the retrieved results. Specifically, after performing a semantic-based retrieval to provide seed chunks, KG$^2$RAG employs a KG-guided chunk expansion process and a KG-based chunk organization process to deliver relevant and important knowledge in well-organized paragraphs. Extensive experiments conducted on the HotpotQA dataset and its variants demonstrate the advantages of KG$^2$RAG compared to existing RAG-based approaches, in terms of both response quality and retrieval quality.</li>
</ul>

<h3>Title: Forbidden Science: Dual-Use AI Challenge Benchmark and Scientific Refusal Tests</h3>
<ul>
<li><strong>Authors: </strong>David Noever, Forrest McKee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06867">https://arxiv.org/abs/2502.06867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06867">https://arxiv.org/pdf/2502.06867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06867]] Forbidden Science: Dual-Use AI Challenge Benchmark and Scientific Refusal Tests(https://arxiv.org/abs/2502.06867)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The development of robust safety benchmarks for large language models requires open, reproducible datasets that can measure both appropriate refusal of harmful content and potential over-restriction of legitimate scientific discourse. We present an open-source dataset and testing framework for evaluating LLM safety mechanisms across mainly controlled substance queries, analyzing four major models' responses to systematically varied prompts. Our results reveal distinct safety profiles: Claude-3.5-sonnet demonstrated the most conservative approach with 73% refusals and 27% allowances, while Mistral attempted to answer 100% of queries. GPT-3.5-turbo showed moderate restriction with 10% refusals and 90% allowances, and Grok-2 registered 20% refusals and 80% allowances. Testing prompt variation strategies revealed decreasing response consistency, from 85% with single prompts to 65% with five variations. This publicly available benchmark enables systematic evaluation of the critical balance between necessary safety restrictions and potential over-censorship of legitimate scientific inquiry, while providing a foundation for measuring progress in AI safety implementation. Chain-of-thought analysis reveals potential vulnerabilities in safety mechanisms, highlighting the complexity of implementing robust safeguards without unduly restricting desirable and valid scientific discourse.</li>
</ul>

<h3>Title: Related Knowledge Perturbation Matters: Rethinking Multiple Pieces of Knowledge Editing in Same-Subject</h3>
<ul>
<li><strong>Authors: </strong>Zenghao Duan, Wenbin Duan, Zhiyi Yin, Yinghan Shen, Shaoling Jing, Jie Zhang, Huawei Shen, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06868">https://arxiv.org/abs/2502.06868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06868">https://arxiv.org/pdf/2502.06868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06868]] Related Knowledge Perturbation Matters: Rethinking Multiple Pieces of Knowledge Editing in Same-Subject(https://arxiv.org/abs/2502.06868)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge editing has become a promising approach for efficiently and precisely updating knowledge embedded in large language models (LLMs). In this work, we focus on Same-Subject Editing, which involves modifying multiple attributes of a single entity to ensure comprehensive and consistent updates to entity-centric knowledge. Through preliminary observation, we identify a significant challenge: Current state-of-the-art editing methods struggle when tasked with editing multiple related knowledge pieces for the same subject. To address the lack of relevant editing data for identical subjects in traditional benchmarks, we introduce the $\text{S}^2\text{RKE}$(Same-Subject Related Knowledge Editing) benchmark. Our extensive experiments reveal that only mainstream locate-then-edit methods, such as ROME and MEMIT, exhibit "related knowledge perturbation," where subsequent edits interfere with earlier ones. Further analysis reveals that these methods over-rely on subject information, neglecting other critical factors, resulting in reduced editing effectiveness.</li>
</ul>

<h3>Title: A Survey on Explainable Deep Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zelei Cheng, Jiahao Yu, Xinyu Xing</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06869">https://arxiv.org/abs/2502.06869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06869">https://arxiv.org/pdf/2502.06869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06869]] A Survey on Explainable Deep Reinforcement Learning(https://arxiv.org/abs/2502.06869)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Deep Reinforcement Learning (DRL) has achieved remarkable success in sequential decision-making tasks across diverse domains, yet its reliance on black-box neural architectures hinders interpretability, trust, and deployment in high-stakes applications. Explainable Deep Reinforcement Learning (XRL) addresses these challenges by enhancing transparency through feature-level, state-level, dataset-level, and model-level explanation techniques. This survey provides a comprehensive review of XRL methods, evaluates their qualitative and quantitative assessment frameworks, and explores their role in policy refinement, adversarial robustness, and security. Additionally, we examine the integration of reinforcement learning with Large Language Models (LLMs), particularly through Reinforcement Learning from Human Feedback (RLHF), which optimizes AI alignment with human preferences. We conclude by highlighting open research challenges and future directions to advance the development of interpretable, reliable, and accountable DRL systems.</li>
</ul>

<h3>Title: Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Chengkai Han, Jingyuan Wang, Yongyao Wang, Xie Yu, Hao Lin, Chao Li, Junjie Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06870">https://arxiv.org/abs/2502.06870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06870">https://arxiv.org/pdf/2502.06870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06870]] Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning(https://arxiv.org/abs/2502.06870)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Effective urban traffic management is vital for sustainable city development, relying on intelligent systems with machine learning tasks such as traffic flow prediction and travel time estimation. Traditional approaches usually focus on static road network and trajectory representation learning, and overlook the dynamic nature of traffic states and trajectories, which is crucial for downstream tasks. To address this gap, we propose TRACK, a novel framework to bridge traffic state and trajectory data for dynamic road network and trajectory representation learning. TRACK leverages graph attention networks (GAT) to encode static and spatial road segment features, and introduces a transformer-based model for trajectory representation learning. By incorporating transition probabilities from trajectory data into GAT attention weights, TRACK captures dynamic spatial features of road segments. Meanwhile, TRACK designs a traffic transformer encoder to capture the spatial-temporal dynamics of road segments from traffic state data. To further enhance dynamic representations, TRACK proposes a co-attentional transformer encoder and a trajectory-traffic state matching task. Extensive experiments on real-life urban traffic datasets demonstrate the superiority of TRACK over state-of-the-art baselines. Case studies confirm TRACK's ability to capture spatial-temporal dynamics effectively.</li>
</ul>

<h3>Title: FlavorDiffusion: Predicting Food Pairings and Chemical Interactions Using Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Seo Jun Pyo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06871">https://arxiv.org/abs/2502.06871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06871">https://arxiv.org/pdf/2502.06871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06871]] FlavorDiffusion: Predicting Food Pairings and Chemical Interactions Using Diffusion Models(https://arxiv.org/abs/2502.06871)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The study of food pairing has evolved beyond subjective expertise with the advent of machine learning. This paper presents FlavorDiffusion, a novel framework leveraging diffusion models to predict food-chemical interactions and ingredient pairings without relying on chromatography. By integrating graph-based embeddings, diffusion processes, and chemical property encoding, FlavorDiffusion addresses data imbalances and enhances clustering quality. Using a heterogeneous graph derived from datasets like Recipe1M and FlavorDB, our model demonstrates superior performance in reconstructing ingredient-ingredient relationships. The addition of a Chemical Structure Prediction (CSP) layer further refines the embedding space, achieving state-of-the-art NMI scores and enabling meaningful discovery of novel ingredient combinations. The proposed framework represents a significant step forward in computational gastronomy, offering scalable, interpretable, and chemically informed solutions for food science.</li>
</ul>

<h3>Title: Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Bo Ni, Zheyuan Liu, Leyao Wang, Yongjia Lei, Yuying Zhao, Xueqi Cheng, Qingkai Zeng, Luna Dong, Yinglong Xia, Krishnaram Kenthapadi, Ryan Rossi, Franck Dernoncourt, Md Mehrab Tanjim, Nesreen Ahmed, Xiaorui Liu, Wenqi Fan, Erik Blasch, Yu Wang, Meng Jiang, Tyler Derr</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06872">https://arxiv.org/abs/2502.06872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06872">https://arxiv.org/pdf/2502.06872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06872]] Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey(https://arxiv.org/abs/2502.06872)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, fair, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) is an advanced technique designed to address the challenges of Artificial Intelligence-Generated Content (AIGC). By integrating context retrieval into content generation, RAG provides reliable and up-to-date external knowledge, reduces hallucinations, and ensures relevant context across a wide range of tasks. However, despite RAG's success and potential, recent studies have shown that the RAG paradigm also introduces new risks, including robustness issues, privacy concerns, adversarial attacks, and accountability issues. Addressing these risks is critical for future applications of RAG systems, as they directly impact their trustworthiness. Although various methods have been developed to improve the trustworthiness of RAG methods, there is a lack of a unified perspective and framework for research in this topic. Thus, in this paper, we aim to address this gap by providing a comprehensive roadmap for developing trustworthy RAG systems. We place our discussion around five key perspectives: reliability, privacy, safety, fairness, explainability, and accountability. For each perspective, we present a general framework and taxonomy, offering a structured approach to understanding the current challenges, evaluating existing solutions, and identifying promising future research directions. To encourage broader adoption and innovation, we also highlight the downstream applications where trustworthy RAG systems have a significant impact.</li>
</ul>

<h3>Title: Multimodal Cognitive Reframing Therapy via Multi-hop Psychotherapeutic Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Subin Kim, Hoonrae Kim, Heejin Do, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06873">https://arxiv.org/abs/2502.06873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06873">https://arxiv.org/pdf/2502.06873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06873]] Multimodal Cognitive Reframing Therapy via Multi-hop Psychotherapeutic Reasoning(https://arxiv.org/abs/2502.06873)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Previous research has revealed the potential of large language models (LLMs) to support cognitive reframing therapy; however, their focus was primarily on text-based methods, often overlooking the importance of non-verbal evidence crucial in real-life therapy. To alleviate this gap, we extend the textual cognitive reframing to multimodality, incorporating visual clues. Specifically, we present a new dataset called Multi Modal-Cognitive Support Conversation (M2CoSC), which pairs each GPT-4-generated dialogue with an image that reflects the virtual client's facial expressions. To better mirror real psychotherapy, where facial expressions lead to interpreting implicit emotional evidence, we propose a multi-hop psychotherapeutic reasoning approach that explicitly identifies and incorporates subtle evidence. Our comprehensive experiments with both LLMs and vision-language models (VLMs) demonstrate that the VLMs' performance as psychotherapists is significantly improved with the M2CoSC dataset. Furthermore, the multi-hop psychotherapeutic reasoning method enables VLMs to provide more thoughtful and empathetic suggestions, outperforming standard prompting methods.</li>
</ul>

<h3>Title: Group Reasoning Emission Estimation Networks</h3>
<ul>
<li><strong>Authors: </strong>Yanming Guo, Xiao Qian, Kevin Credit, Jin Ma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06874">https://arxiv.org/abs/2502.06874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06874">https://arxiv.org/pdf/2502.06874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06874]] Group Reasoning Emission Estimation Networks(https://arxiv.org/abs/2502.06874)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Accurate greenhouse gas (GHG) emission reporting is critical for governments, businesses, and investors. However, adoption remains limited particularly among small and medium enterprises due to high implementation costs, fragmented emission factor databases, and a lack of robust sector classification methods. To address these challenges, we introduce Group Reasoning Emission Estimation Networks (GREEN), an AI-driven carbon accounting framework that standardizes enterprise-level emission estimation, constructs a large-scale benchmark dataset, and leverages a novel reasoning approach with large language models (LLMs). Specifically, we compile textual descriptions for 20,850 companies with validated North American Industry Classification System (NAICS) labels and align these with an economic model of carbon intensity factors. By reframing sector classification as an information retrieval task, we fine-tune Sentence-BERT models using a contrastive learning loss. To overcome the limitations of single-stage models in handling thousands of hierarchical categories, we propose a Group Reasoning method that ensembles LLM classifiers based on the natural NAICS ontology, decomposing the task into multiple sub-classification steps. We theoretically prove that this approach reduces classification uncertainty and computational complexity. Experiments on 1,114 NAICS categories yield state-of-the-art performance (83.68% Top-1, 91.47% Top-10 accuracy), and case studies on 20 companies report a mean absolute percentage error (MAPE) of 45.88%. The project is available at: this https URL.</li>
</ul>

<h3>Title: Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values</h3>
<ul>
<li><strong>Authors: </strong>Vaibhav Mehra, Guy Laban, Hatice Gunes</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06875">https://arxiv.org/abs/2502.06875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06875">https://arxiv.org/pdf/2502.06875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06875]] Beyond Vision: How Large Language Models Interpret Facial Expressions from Valence-Arousal Values(https://arxiv.org/abs/2502.06875)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models primarily operate through text-based inputs and outputs, yet human emotion is communicated through both verbal and non-verbal cues, including facial expressions. While Vision-Language Models analyze facial expressions from images, they are resource-intensive and may depend more on linguistic priors than visual understanding. To address this, this study investigates whether LLMs can infer affective meaning from dimensions of facial expressions-Valence and Arousal values, structured numerical representations, rather than using raw visual input. VA values were extracted using Facechannel from images of facial expressions and provided to LLMs in two tasks: (1) categorizing facial expressions into basic (on the IIMI dataset) and complex emotions (on the Emotic dataset) and (2) generating semantic descriptions of facial expressions (on the Emotic dataset). Results from the categorization task indicate that LLMs struggle to classify VA values into discrete emotion categories, particularly for emotions beyond basic polarities (e.g., happiness, sadness). However, in the semantic description task, LLMs produced textual descriptions that align closely with human-generated interpretations, demonstrating a stronger capacity for free text affective inference of facial expressions.</li>
</ul>

<h3>Title: Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging</h3>
<ul>
<li><strong>Authors: </strong>Jinluan Yang, Dingnan Jin, Anke Tang, Li Shen, Didi Zhu, Zhengyu Chen, Daixin Wang, Qing Cui, Zhiqiang Zhang, Jun Zhou, Fei Wu, Kun Kuang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06876">https://arxiv.org/abs/2502.06876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06876">https://arxiv.org/pdf/2502.06876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06876]] Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging(https://arxiv.org/abs/2502.06876)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Achieving balanced alignment of large language models (LLMs) in terms of Helpfulness, Honesty, and Harmlessness (3H optimization) constitutes a cornerstone of responsible AI, with existing methods like data mixture strategies facing limitations including reliance on expert knowledge and conflicting optimization signals. While model merging offers a promising alternative by integrating specialized models, its potential for 3H optimization remains underexplored. This paper establishes the first comprehensive benchmark for model merging in 3H-aligned LLMs, systematically evaluating 15 methods (12 training-free merging and 3 data mixture techniques) across 10 datasets associated with 5 annotation dimensions, 2 LLM families, and 2 training paradigms. Our analysis reveals three pivotal insights: (i) previously overlooked collaborative/conflicting relationships among 3H dimensions, (ii) the consistent superiority of model merging over data mixture approaches in balancing alignment trade-offs, and (iii) the critical role of parameter-level conflict resolution through redundant component pruning and outlier mitigation. Building on these findings, we propose R-TSVM, a Reweighting-enhanced Task Singular Vector Merging method that incorporates outlier-aware parameter weighting and sparsity-adaptive rank selection strategies adapted to the heavy-tailed parameter distribution and sparsity for LLMs, further improving LLM alignment across multiple evaluations. Our models will be available at this https URL.</li>
</ul>

<h3>Title: WirelessGPT: A Generative Pre-trained Multi-task Learning Framework for Wireless Communication</h3>
<ul>
<li><strong>Authors: </strong>Tingting Yang, Ping Zhang, Mengfan Zheng, Yuxuan Shi, Liwen Jing, Jianbo Huang, Nan Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06877">https://arxiv.org/abs/2502.06877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06877">https://arxiv.org/pdf/2502.06877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06877]] WirelessGPT: A Generative Pre-trained Multi-task Learning Framework for Wireless Communication(https://arxiv.org/abs/2502.06877)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper introduces WirelessGPT, a pioneering foundation model specifically designed for multi-task learning in wireless communication and sensing. Specifically, WirelessGPT leverages large-scale wireless channel datasets for unsupervised pretraining and extracting universal channel representations, which captures complex spatiotemporal dependencies. In fact,this task-agnostic design adapts WirelessGPT seamlessly to a wide range of downstream tasks, using a unified representation with minimal fine-tuning. By unifying communication and sensing functionalities, WirelessGPT addresses the limitations of task-specific models, offering a scalable and efficient solution for integrated sensing and communication (ISAC). With an initial parameter size of around 80 million, WirelessGPT demonstrates significant improvements over conventional methods and smaller AI models, reducing reliance on large-scale labeled data. As the first foundation model capable of supporting diverse tasks across different domains, WirelessGPT establishes a new benchmark, paving the way for future advancements in multi-task wireless systems.</li>
</ul>

<h3>Title: Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction</h3>
<ul>
<li><strong>Authors: </strong>Shengbin Yue, Ting Huang, Zheng Jia, Siyuan Wang, Shujun Liu, Yun Song, Xuanjing Huang, Zhongyu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06882">https://arxiv.org/abs/2502.06882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06882">https://arxiv.org/pdf/2502.06882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06882]] Multi-Agent Simulator Drives Language Models for Legal Intensive Interaction(https://arxiv.org/abs/2502.06882)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have significantly advanced legal intelligence, but the scarcity of scenario data impedes the progress toward interactive legal scenarios. This paper introduces a Multi-agent Legal Simulation Driver (MASER) to scalably generate synthetic data by simulating interactive legal scenarios. Leveraging real-legal case sources, MASER ensures the consistency of legal attributes between participants and introduces a supervisory mechanism to align participants' characters and behaviors as well as addressing distractions. A Multi-stage Interactive Legal Evaluation (MILE) benchmark is further constructed to evaluate LLMs' performance in dynamic legal scenarios. Extensive experiments confirm the effectiveness of our framework.</li>
</ul>

<h3>Title: Topological derivative approach for deep neural network architecture adaptation</h3>
<ul>
<li><strong>Authors: </strong>C G Krishnanunni, Tan Bui-Thanh, Clint Dawson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06885">https://arxiv.org/abs/2502.06885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06885">https://arxiv.org/pdf/2502.06885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06885]] Topological derivative approach for deep neural network architecture adaptation(https://arxiv.org/abs/2502.06885)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This work presents a novel algorithm for progressively adapting neural network architecture along the depth. In particular, we attempt to address the following questions in a mathematically principled way: i) Where to add a new capacity (layer) during the training process? ii) How to initialize the new capacity? At the heart of our approach are two key ingredients: i) the introduction of a ``shape functional" to be minimized, which depends on neural network topology, and ii) the introduction of a topological derivative of the shape functional with respect to the neural network topology. Using an optimal control viewpoint, we show that the network topological derivative exists under certain conditions, and its closed-form expression is derived. In particular, we explore, for the first time, the connection between the topological derivative from a topology optimization framework with the Hamiltonian from optimal control theory. Further, we show that the optimality condition for the shape functional leads to an eigenvalue problem for deep neural architecture adaptation. Our approach thus determines the most sensitive location along the depth where a new layer needs to be inserted during the training phase and the associated parametric initialization for the newly added layer. We also demonstrate that our layer insertion strategy can be derived from an optimal transport viewpoint as a solution to maximizing a topological derivative in $p$-Wasserstein space, where $p>= 1$. Numerical investigations with fully connected network, convolutional neural network, and vision transformer on various regression and classification problems demonstrate that our proposed approach can outperform an ad-hoc baseline network and other architecture adaptation strategies. Further, we also demonstrate other applications of topological derivative in fields such as transfer learning.</li>
</ul>

<h3>Title: Secure Visual Data Processing via Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Pedro Santos, TÃ¢nia Carvalho, Filipe MagalhÃ£es, LuÃ­s Antunes</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06889">https://arxiv.org/abs/2502.06889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06889">https://arxiv.org/pdf/2502.06889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06889]] Secure Visual Data Processing via Federated Learning(https://arxiv.org/abs/2502.06889)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>As the demand for privacy in visual data management grows, safeguarding sensitive information has become a critical challenge. This paper addresses the need for privacy-preserving solutions in large-scale visual data processing by leveraging federated learning. Although there have been developments in this field, previous research has mainly focused on integrating object detection with either anonymization or federated learning. However, these pairs often fail to address complex privacy concerns. On the one hand, object detection with anonymization alone can be vulnerable to reverse techniques. On the other hand, federated learning may not provide sufficient privacy guarantees. Therefore, we propose a new approach that combines object detection, federated learning and anonymization. Combining these three components aims to offer a robust privacy protection strategy by addressing different vulnerabilities in visual data. Our solution is evaluated against traditional centralized models, showing that while there is a slight trade-off in accuracy, the privacy benefits are substantial, making it well-suited for privacy sensitive applications.</li>
</ul>

<h3>Title: LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison</h3>
<ul>
<li><strong>Authors: </strong>Gabriele De Vito, Filomena Ferrucci, Athanasios Angelakis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06890">https://arxiv.org/abs/2502.06890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06890">https://arxiv.org/pdf/2502.06890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06890]] LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison(https://arxiv.org/abs/2502.06890)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The increasing volume of drug combinations in modern therapeutic regimens needs reliable methods for predicting drug-drug interactions (DDIs). While Large Language Models (LLMs) have revolutionized various domains, their potential in pharmaceutical research, particularly in DDI prediction, remains largely unexplored. This study thoroughly investigates LLMs' capabilities in predicting DDIs by uniquely processing molecular structures (SMILES), target organisms, and gene interaction data as raw text input from the latest DrugBank dataset. We evaluated 18 different LLMs, including proprietary models (GPT-4, Claude, Gemini) and open-source variants (from 1.5B to 72B parameters), first assessing their zero-shot capabilities in DDI prediction. We then fine-tuned selected models (GPT-4, Phi-3.5 2.7B, Qwen-2.5 3B, Gemma-2 9B, and Deepseek R1 distilled Qwen 1.5B) to optimize their performance. Our comprehensive evaluation framework included validation across 13 external DDI datasets, comparing against traditional approaches such as l2-regularized logistic regression. Fine-tuned LLMs demonstrated superior performance, with Phi-3.5 2.7B achieving a sensitivity of 0.978 in DDI prediction, with an accuracy of 0.919 on balanced datasets (50% positive, 50% negative cases). This result represents an improvement over both zero-shot predictions and state-of-the-art machine-learning methods used for DDI prediction. Our analysis reveals that LLMs can effectively capture complex molecular interaction patterns and cases where drug pairs target common genes, making them valuable tools for practical applications in pharmaceutical research and clinical settings.</li>
</ul>

<h3>Title: Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks</h3>
<ul>
<li><strong>Authors: </strong>Bowei He, Lihao Yin, Hui-Ling Zhen, Jianping Zhang, Lanqing Hong, Mingxuan Yuan, Chen Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06892">https://arxiv.org/abs/2502.06892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06892">https://arxiv.org/pdf/2502.06892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06892]] Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks(https://arxiv.org/abs/2502.06892)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>The widespread deployment of pre-trained language models (PLMs) has exposed them to textual backdoor attacks, particularly those planted during the pre-training stage. These attacks pose significant risks to high-reliability applications, as they can stealthily affect multiple downstream tasks. While certifying robustness against such threats is crucial, existing defenses struggle with the high-dimensional, interdependent nature of textual data and the lack of access to original poisoned pre-training data. To address these challenges, we introduce \textbf{F}uzzed \textbf{R}andomized \textbf{S}moothing (\textbf{FRS}), a novel approach for efficiently certifying language model robustness against backdoor attacks. FRS integrates software robustness certification techniques with biphased model parameter smoothing, employing Monte Carlo tree search for proactive fuzzing to identify vulnerable textual segments within the Damerau-Levenshtein space. This allows for targeted and efficient text randomization, while eliminating the need for access to poisoned training data during model smoothing. Our theoretical analysis demonstrates that FRS achieves a broader certified robustness radius compared to existing methods. Extensive experiments across various datasets, model configurations, and attack strategies validate FRS's superiority in terms of defense efficiency, accuracy, and robustness.</li>
</ul>

<h3>Title: A New Hybrid Intelligent Approach for Multimodal Detection of Suspected Disinformation on TikTok</h3>
<ul>
<li><strong>Authors: </strong>Jared D.T. Guerrero-Sosa, Andres Montoro-Montarroso, Francisco P. Romero, Jesus Serrano-Guerrero, Jose A. Olivas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.MM, cs.SC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06893">https://arxiv.org/abs/2502.06893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06893">https://arxiv.org/pdf/2502.06893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06893]] A New Hybrid Intelligent Approach for Multimodal Detection of Suspected Disinformation on TikTok(https://arxiv.org/abs/2502.06893)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In the context of the rapid dissemination of multimedia content, identifying disinformation on social media platforms such as TikTok represents a significant challenge. This study introduces a hybrid framework that combines the computational power of deep learning with the interpretability of fuzzy logic to detect suspected disinformation in TikTok videos. The methodology is comprised of two core components: a multimodal feature analyser that extracts and evaluates data from text, audio, and video; and a multimodal disinformation detector based on fuzzy logic. These systems operate in conjunction to evaluate the suspicion of spreading disinformation, drawing on human behavioural cues such as body language, speech patterns, and text coherence. Two experiments were conducted: one focusing on context-specific disinformation and the other on the scalability of the model across broader topics. For each video evaluated, high-quality, comprehensive, well-structured reports are generated, providing a detailed view of the disinformation behaviours.</li>
</ul>

<h3>Title: AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution</h3>
<ul>
<li><strong>Authors: </strong>David S. Bhatti, Yougin Choi, Rahman S M Wahidur, Maleeka Bakhtawar, Sumin Kim, Surin Lee, Yongtae Lee, Heung-No Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06894">https://arxiv.org/abs/2502.06894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06894">https://arxiv.org/pdf/2502.06894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06894]] AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution(https://arxiv.org/abs/2502.06894)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Hyperspectral imaging (HSI) captures spatial and spectral data, enabling analysis of features invisible to conventional systems. The technology is vital in fields such as weather monitoring, food quality control, counterfeit detection, healthcare diagnostics, and extending into defense, agriculture, and industrial automation at the same time. HSI has advanced with improvements in spectral resolution, miniaturization, and computational methods. This study provides an overview of the HSI, its applications, challenges in data fusion and the role of deep learning models in processing HSI data. We discuss how integration of multimodal HSI with AI, particularly with deep learning, improves classification accuracy and operational efficiency. Deep learning enhances HSI analysis in areas like feature extraction, change detection, denoising unmixing, dimensionality reduction, landcover mapping, data augmentation, spectral construction and super resolution. An emerging focus is the fusion of hyperspectral cameras with large language models (LLMs), referred as highbrain LLMs, enabling the development of advanced applications such as low visibility crash detection and face antispoofing. We also highlight key players in HSI industry, its compound annual growth rate and the growing industrial significance. The purpose is to offer insight to both technical and non-technical audience, covering HSI's images, trends, and future directions, while providing valuable information on HSI datasets and software libraries.</li>
</ul>

<h3>Title: Polynomial Regret Concentration of UCB for Non-Deterministic State Transitions</h3>
<ul>
<li><strong>Authors: </strong>Can CÃ¶mer, Jannis BlÃ¼ml, Cedric Derstroff, Kristian Kersting</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06900">https://arxiv.org/abs/2502.06900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06900">https://arxiv.org/pdf/2502.06900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06900]] Polynomial Regret Concentration of UCB for Non-Deterministic State Transitions(https://arxiv.org/abs/2502.06900)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Monte Carlo Tree Search (MCTS) has proven effective in solving decision-making problems in perfect information settings. However, its application to stochastic and imperfect information domains remains limited. This paper extends the theoretical framework of MCTS to stochastic domains by addressing non-deterministic state transitions, where actions lead to probabilistic outcomes. Specifically, building on the work of Shah et al. (2020), we derive polynomial regret concentration bounds for the Upper Confidence Bound algorithm in multi-armed bandit problems with stochastic transitions, offering improved theoretical guarantees. Our primary contribution is proving that these bounds also apply to non-deterministic environments, ensuring robust performance in stochastic settings. This broadens the applicability of MCTS to real-world decision-making problems with probabilistic outcomes, such as in autonomous systems and financial decision-making.</li>
</ul>

<h3>Title: Enabling Autoregressive Models to Fill In Masked Tokens</h3>
<ul>
<li><strong>Authors: </strong>Daniel Israel, Aditya Grover, Guy Van den Broeck</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06901">https://arxiv.org/abs/2502.06901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06901">https://arxiv.org/pdf/2502.06901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06901]] Enabling Autoregressive Models to Fill In Masked Tokens(https://arxiv.org/abs/2502.06901)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Historically, LLMs have been trained using either autoregressive (AR) or masked language modeling (MLM) objectives, with AR models gaining dominance in recent years. However, AR models are inherently incapable of masked infilling, which is the ability to predict masked tokens between past and future context. In contrast, MLM models suffer from intrinsic computational inefficiencies during both training and inference that hinder their scalability. This work introduces MARIA (Masked and Autoregressive Infilling Architecture), a novel approach that leverages the strengths of both paradigms to achieve state-of-the-art masked infilling performance. MARIA combines a pre-trained MLM and AR model by training a linear decoder that takes their concatenated hidden states as input. This minimal modification enables the AR model to perform infilling while retaining its inherent advantages in terms of faster inference with KV caching. Our results demonstrate that MARIA significantly outperforms existing methods, namely discrete diffusion models, on masked infilling tasks.</li>
</ul>

<h3>Title: Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training</h3>
<ul>
<li><strong>Authors: </strong>Deven Mahesh Mistry, Anooshka Bajaj, Yash Aggarwal, Sahaj Singh Maini, Zoran Tiganj</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06902">https://arxiv.org/abs/2502.06902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06902">https://arxiv.org/pdf/2502.06902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06902]] Emergence of Episodic Memory in Transformers: Characterizing Changes in Temporal Structure of Attention Scores During Training(https://arxiv.org/abs/2502.06902)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We investigate in-context temporal biases in attention heads and transformer outputs. Using cognitive science methodologies, we analyze attention scores and outputs of the GPT-2 models of varying sizes. Across attention heads, we observe effects characteristic of human episodic memory, including temporal contiguity, primacy and recency. Transformer outputs demonstrate a tendency toward in-context serial recall. Importantly, this effect is eliminated after the ablation of the induction heads, which are the driving force behind the contiguity effect. Our findings offer insights into how transformers organize information temporally during in-context learning, shedding light on their similarities and differences with human memory and learning.</li>
</ul>

<h3>Title: Can ChatGPT Diagnose Alzheimer's Disease?</h3>
<ul>
<li><strong>Authors: </strong>Quoc-Toan Nguyen, Linh Le, Xuan-The Tran, Thomas Do, Chin-Teng Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06907">https://arxiv.org/abs/2502.06907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06907">https://arxiv.org/pdf/2502.06907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06907]] Can ChatGPT Diagnose Alzheimer's Disease?(https://arxiv.org/abs/2502.06907)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Can ChatGPT diagnose Alzheimer's Disease (AD)? AD is a devastating neurodegenerative condition that affects approximately 1 in 9 individuals aged 65 and older, profoundly impairing memory and cognitive function. This paper utilises 9300 electronic health records (EHRs) with data from Magnetic Resonance Imaging (MRI) and cognitive tests to address an intriguing question: As a general-purpose task solver, can ChatGPT accurately detect AD using EHRs? We present an in-depth evaluation of ChatGPT using a black-box approach with zero-shot and multi-shot methods. This study unlocks ChatGPT's capability to analyse MRI and cognitive test results, as well as its potential as a diagnostic tool for AD. By automating aspects of the diagnostic process, this research opens a transformative approach for the healthcare system, particularly in addressing disparities in resource-limited regions where AD specialists are scarce. Hence, it offers a foundation for a promising method for early detection, supporting individuals with timely interventions, which is paramount for Quality of Life (QoL).</li>
</ul>

<h3>Title: Satisfaction-Aware Incentive Scheme for Federated Learning in Industrial Metaverse: DRL-Based Stackbelberg Game Approach</h3>
<ul>
<li><strong>Authors: </strong>Xiaohuan Li, Shaowen Qin, Xin Tang, Jiawen Kang, Jin Ye, Zhonghua Zhao, Dusit Niyato</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06909">https://arxiv.org/abs/2502.06909</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06909">https://arxiv.org/pdf/2502.06909</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06909]] Satisfaction-Aware Incentive Scheme for Federated Learning in Industrial Metaverse: DRL-Based Stackbelberg Game Approach(https://arxiv.org/abs/2502.06909)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Industrial Metaverse leverages the Industrial Internet of Things (IIoT) to integrate data from diverse devices, employing federated learning and meta-computing to train models in a distributed manner while ensuring data privacy. Achieving an immersive experience for industrial Metaverse necessitates maintaining a balance between model quality and training latency. Consequently, a primary challenge in federated learning tasks is optimizing overall system performance by balancing model quality and training latency. This paper designs a satisfaction function that accounts for data size, Age of Information (AoI), and training latency. Additionally, the satisfaction function is incorporated into the utility functions to incentivize node participation in model training. We model the utility functions of servers and nodes as a two-stage Stackelberg game and employ a deep reinforcement learning approach to learn the Stackelberg equilibrium. This approach ensures balanced rewards and enhances the applicability of the incentive scheme for industrial Metaverse. Simulation results demonstrate that, under the same budget constraints, the proposed incentive scheme improves at least 23.7% utility compared to existing schemes without compromising model accuracy.</li>
</ul>

<h3>Title: Hyper Compressed Fine-Tuning of Large Foundation Models with Quantum Inspired Adapters</h3>
<ul>
<li><strong>Authors: </strong>Snehal Raj, Brian Coyle</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06916">https://arxiv.org/abs/2502.06916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06916">https://arxiv.org/pdf/2502.06916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06916]] Hyper Compressed Fine-Tuning of Large Foundation Models with Quantum Inspired Adapters(https://arxiv.org/abs/2502.06916)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning pre-trained large foundation models for specific tasks has become increasingly challenging due to the computational and storage demands associated with full parameter updates. Parameter-Efficient Fine-Tuning (PEFT) methods address this issue by updating only a small subset of model parameters using adapter modules. In this work, we propose \emph{Quantum-Inspired Adapters}, a PEFT approach inspired by Hamming-weight preserving quantum circuits from quantum machine learning literature. These models can be both expressive and parameter-efficient by operating in a combinatorially large space while simultaneously preserving orthogonality in weight parameters. We test our proposed adapters by adapting large language models and large vision transformers on benchmark datasets. Our method can achieve 99.2\% of the performance of existing fine-tuning methods such LoRA with a 44x parameter compression on language understanding datasets like GLUE and VTAB. Compared to existing orthogonal fine-tuning methods such as OFT or BOFT, we achieve 98\% relative performance with 25x fewer parameters. This demonstrates competitive performance paired with a significant reduction in trainable parameters. Through ablation studies, we determine that combining multiple Hamming-weight orders with orthogonality and matrix compounding are essential for performant fine-tuning. Our findings suggest that Quantum-Inspired Adapters offer a promising direction for efficient adaptation of language and vision models in resource-constrained environments.</li>
</ul>

<h3>Title: Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Mario GarcÃ­a-MÃ¡rquez, Nuria RodrÃ­guez-Barroso, M.Victoria LuzÃ³n, Francisco Herrera</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06917">https://arxiv.org/abs/2502.06917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06917">https://arxiv.org/pdf/2502.06917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06917]] Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning(https://arxiv.org/abs/2502.06917)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning presents a nascent approach to machine learning, enabling collaborative model training across decentralized devices while safeguarding data privacy. However, its distributed nature renders it susceptible to adversarial attacks. Integrating blockchain technology with Federated Learning offers a promising avenue to enhance security and integrity. In this paper, we tackle the potential of blockchain in defending Federated Learning against adversarial attacks. First, we test Proof of Federated Learning, a well known consensus mechanism designed ad-hoc to federated contexts, as a defense mechanism demonstrating its efficacy against Byzantine and backdoor attacks when at least one miner remains uncompromised. Second, we propose Krum Federated Chain, a novel defense strategy combining Krum and Proof of Federated Learning, valid to defend against any configuration of Byzantine or backdoor attacks, even when all miners are compromised. Our experiments conducted on image classification datasets validate the effectiveness of our proposed approaches.</li>
</ul>

<h3>Title: Leveraging GPT-4o Efficiency for Detecting Rework Anomaly in Business Processes</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Derakhshan, Paolo Ceravolo, Fatemeh Mohammadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06918">https://arxiv.org/abs/2502.06918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06918">https://arxiv.org/pdf/2502.06918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06918]] Leveraging GPT-4o Efficiency for Detecting Rework Anomaly in Business Processes(https://arxiv.org/abs/2502.06918)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the effectiveness of GPT-4o-2024-08-06, one of the Large Language Models (LLM) from OpenAI, in detecting business process anomalies, with a focus on rework anomalies. In our study, we developed a GPT-4o-based tool capable of transforming event logs into a structured format and identifying reworked activities within business event logs. The analysis was performed on a synthetic dataset designed to contain rework anomalies but free of loops. To evaluate the anomaly detection capabilities of GPT 4o-2024-08-06, we used three prompting techniques: zero-shot, one-shot, and few-shot. These techniques were tested on different anomaly distributions, namely normal, uniform, and exponential, to identify the most effective approach for each case. The results demonstrate the strong performance of GPT-4o-2024-08-06. On our dataset, the model achieved 96.14% accuracy with one-shot prompting for the normal distribution, 97.94% accuracy with few-shot prompting for the uniform distribution, and 74.21% accuracy with few-shot prompting for the exponential distribution. These results highlight the model's potential as a reliable tool for detecting rework anomalies in event logs and how anomaly distribution and prompting strategy influence the model's performance.</li>
</ul>

<h3>Title: GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units</h3>
<ul>
<li><strong>Authors: </strong>Arghadip Das, Shamik Kundu, Arnab Raha, Soumendu Ghosh, Deepak Mathaikutty, Vijay Raghunathan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06921">https://arxiv.org/abs/2502.06921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06921">https://arxiv.org/pdf/2502.06921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06921]] GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units(https://arxiv.org/abs/2502.06921)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) are vital for learning from graph-structured data, enabling applications in network analysis, recommendation systems, and speech analytics. Deploying them on edge devices like client PCs and laptops enhances real-time processing, privacy, and cloud independence. GNNs aid Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs) and enable event-based vision tasks. However, irregular memory access, sparsity, and dynamic structures cause high latency and energy overhead on resource-constrained devices. While modern edge processors integrate CPUs, GPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregular GNN computations. We introduce GraNNite, the first hardware-aware framework optimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNN accelerators via a structured three-step methodology: (1) enabling NPU execution, (2) optimizing performance, and (3) trading accuracy for efficiency gains. Step 1 employs GraphSplit for workload distribution and StaGr for static aggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boosts performance using EffOp for control-heavy tasks and GraSp for sparsity exploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduce redundancy and memory transfers. Step 3 balances quality versus efficiency, where QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerate attention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs, GraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to 8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higher performance than CPUs and GPUs, respectively, across GNN models.</li>
</ul>

<h3>Title: Do Attention Heads Compete or Cooperate during Counting?</h3>
<ul>
<li><strong>Authors: </strong>PÃ¡l ZsÃ¡mboki, ÃdÃ¡m FraknÃ³i, MÃ¡tÃ© Gedeon, AndrÃ¡s Kornai, Zsolt Zombori</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06923">https://arxiv.org/abs/2502.06923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06923">https://arxiv.org/pdf/2502.06923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06923]] Do Attention Heads Compete or Cooperate during Counting?(https://arxiv.org/abs/2502.06923)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We present an in-depth mechanistic interpretability analysis of training small transformers on an elementary task, counting, which is a crucial deductive step in many algorithms. In particular, we investigate the collaboration/competition among the attention heads: we ask whether the attention heads behave as a pseudo-ensemble, all solving the same subtask, or they perform different subtasks, meaning that they can only solve the original task in conjunction. Our work presents evidence that on the semantics of the counting task, attention heads behave as a pseudo-ensemble, but their outputs need to be aggregated in a non-uniform manner in order to create an encoding that conforms to the syntax. Our source code will be available upon publication.</li>
</ul>

<h3>Title: XAMBA: Enabling Efficient State Space Models on Resource-Constrained Neural Processing Units</h3>
<ul>
<li><strong>Authors: </strong>Arghadip Das, Arnab Raha, Shamik Kundu, Soumendu Kumar Ghosh, Deepak Mathaikutty, Vijay Raghunathan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06924">https://arxiv.org/abs/2502.06924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06924">https://arxiv.org/pdf/2502.06924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06924]] XAMBA: Enabling Efficient State Space Models on Resource-Constrained Neural Processing Units(https://arxiv.org/abs/2502.06924)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>State-Space Models (SSMs) have emerged as efficient alternatives to transformers for sequential data tasks, offering linear or near-linear scalability with sequence length, making them ideal for long-sequence applications in NLP, vision, and edge AI, including real-time transcription, translation, and contextual search. These applications require lightweight, high-performance models for deployment on resource-constrained devices like laptops and PCs. Designing specialized accelerators for every emerging neural network is costly and impractical; instead, optimizing models for existing NPUs in AI PCs provides a scalable solution. To this end, we propose XAMBA, the first framework to enable and optimize SSMs on commercial off-the-shelf (COTS) state-of-the-art (SOTA) NPUs. XAMBA follows a three-step methodology: (1) enabling SSMs on NPUs, (2) optimizing performance to meet KPI requirements, and (3) trading accuracy for additional performance gains. After enabling SSMs on NPUs, XAMBA mitigates key bottlenecks using CumBA and ReduBA, replacing sequential CumSum and ReduceSum operations with matrix-based computations, significantly improving execution speed and memory efficiency. Additionally, ActiBA enhances performance by approximating expensive activation functions (e.g., Swish, Softplus) using piecewise linear mappings, reducing latency with minimal accuracy loss. Evaluations on an Intel Core Ultra Series 2 AI PC show that XAMBA achieves up to 2.6X speed-up over the baseline. Our implementation is available at this https URL.</li>
</ul>

<h3>Title: Occam's model: Selecting simpler representations for better transferability estimation</h3>
<ul>
<li><strong>Authors: </strong>Prabhant Singh, Sibylle Hess, Joaquin Vanschoren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06925">https://arxiv.org/abs/2502.06925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06925">https://arxiv.org/pdf/2502.06925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06925]] Occam's model: Selecting simpler representations for better transferability estimation(https://arxiv.org/abs/2502.06925)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fine-tuning models that have been pre-trained on large datasets has become a cornerstone of modern machine learning workflows. With the widespread availability of online model repositories, such as Hugging Face, it is now easier than ever to fine-tune pre-trained models for specific tasks. This raises a critical question: which pre-trained model is most suitable for a given task? This problem is called transferability estimation. In this work, we introduce two novel and effective metrics for estimating the transferability of pre-trained models. Our approach is grounded in viewing transferability as a measure of how easily a pre-trained model's representations can be trained to separate target classes, providing a unique perspective on transferability estimation. We rigorously evaluate the proposed metrics against state-of-the-art alternatives across diverse problem settings, demonstrating their robustness and practical utility. Additionally, we present theoretical insights that explain our metrics' efficacy and adaptability to various scenarios. We experimentally show that our metrics increase Kendall's Tau by up to 32% compared to the state-of-the-art baselines.</li>
</ul>

<h3>Title: GAS: Generative Avatar Synthesis from a Single Image</h3>
<ul>
<li><strong>Authors: </strong>Yixing Lu, Junting Dong, Youngjoong Kwon, Qin Zhao, Bo Dai, Fernando De la Torre</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06957">https://arxiv.org/abs/2502.06957</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06957">https://arxiv.org/pdf/2502.06957</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06957]] GAS: Generative Avatar Synthesis from a Single Image(https://arxiv.org/abs/2502.06957)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce a generalizable and unified framework to synthesize view-consistent and temporally coherent avatars from a single image, addressing the challenging problem of single-image avatar generation. While recent methods employ diffusion models conditioned on human templates like depth or normal maps, they often struggle to preserve appearance information due to the discrepancy between sparse driving signals and the actual human subject, resulting in multi-view and temporal inconsistencies. Our approach bridges this gap by combining the reconstruction power of regression-based 3D human reconstruction with the generative capabilities of a diffusion model. The dense driving signal from the initial reconstructed human provides comprehensive conditioning, ensuring high-quality synthesis faithful to the reference appearance and structure. Additionally, we propose a unified framework that enables the generalization learned from novel pose synthesis on in-the-wild videos to naturally transfer to novel view synthesis. Our video-based diffusion model enhances disentangled synthesis with high-quality view-consistent renderings for novel views and realistic non-rigid deformations in novel pose animation. Results demonstrate the superior generalization ability of our method across in-domain and out-of-domain in-the-wild datasets. Project page: this https URL</li>
</ul>

<h3>Title: Task Offloading in Vehicular Edge Computing using Deep Reinforcement Learning: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Ashab Uddin, Ahmed Hamdi Sakr, Ning Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06963">https://arxiv.org/abs/2502.06963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06963">https://arxiv.org/pdf/2502.06963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06963]] Task Offloading in Vehicular Edge Computing using Deep Reinforcement Learning: A Survey(https://arxiv.org/abs/2502.06963)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The increasing demand for Intelligent Transportation Systems (ITS) has introduced significant challenges in managing the complex, computation-intensive tasks generated by modern vehicles while offloading tasks to external computing infrastructures such as edge computing (EC), nearby vehicular , and UAVs has become influential solution to these challenges. However, traditional computational offloading strategies often struggle to adapt to the dynamic and heterogeneous nature of vehicular environments. In this study, we explored the potential of Reinforcement Learning (RL) and Deep Reinforcement Learning (DRL) frameworks to optimize computational offloading through adaptive, real-time decision-making, and we have thoroughly investigated the Markov Decision Process (MDP) approaches on the existing literature. The paper focuses on key aspects such as standardized learning models, optimized reward structures, and collaborative multi-agent systems, aiming to advance the understanding and application of DRL in vehicular networks. Our findings offer insights into enhancing the efficiency, scalability, and robustness of ITS, setting the stage for future innovations in this rapidly evolving field.</li>
</ul>

<h3>Title: Model Diffusion for Certifiable Few-shot Transfer Learning</h3>
<ul>
<li><strong>Authors: </strong>Fady Rezk, Royson Lee, Henry Gouk, Timothy Hospedales, Minyoung Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06970">https://arxiv.org/abs/2502.06970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06970">https://arxiv.org/pdf/2502.06970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06970]] Model Diffusion for Certifiable Few-shot Transfer Learning(https://arxiv.org/abs/2502.06970)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In modern large-scale deep learning, a prevalent and effective workflow for solving low-data problems is adapting powerful pre-trained foundation models (FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, while empirically effective, the resulting solutions lack generalisation guarantees to certify their accuracy - which may be required for ethical or legal reasons prior to deployment in high-importance applications. In this paper we develop a novel transfer learning approach that is designed to facilitate non-vacuous learning theoretic generalisation guarantees for downstream tasks, even in the low-shot regime. Specifically, we first use upstream tasks to train a distribution over PEFT parameters. We then learn the downstream task by a sample-and-evaluate procedure -- sampling plausible PEFTs from the trained diffusion model and selecting the one with the highest likelihood on the downstream data. Crucially, this confines our model hypothesis to a finite set of PEFT samples. In contrast to learning in the typical continuous hypothesis spaces of neural network weights, this facilitates tighter risk certificates. We instantiate our bound and show non-trivial generalization guarantees compared to existing learning approaches which lead to vacuous bounds in the low-shot regime.</li>
</ul>

<h3>Title: Investigating the Zone of Proximal Development of Language Models for In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Peng Cui, Mrinmaya Sachan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06990">https://arxiv.org/abs/2502.06990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06990">https://arxiv.org/pdf/2502.06990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06990]] Investigating the Zone of Proximal Development of Language Models for In-Context Learning(https://arxiv.org/abs/2502.06990)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce a learning analytics framework to analyze the in-context learning (ICL) behavior of large language models (LLMs) through the lens of the Zone of Proximal Development (ZPD), an established theory in educational psychology. ZPD delineates the space between what a learner is capable of doing unsupported and what the learner cannot do even with support. We adapt this concept to ICL, measuring the ZPD of LLMs based on model performance on individual examples with and without ICL. Furthermore, we propose an item response theory (IRT) model to predict the distribution of zones for LLMs. Our findings reveal a series of intricate and multifaceted behaviors of ICL, providing new insights into understanding and leveraging this technique. Finally, we demonstrate how our framework can enhance LLM in both inference and fine-tuning scenarios: (1) By predicting a model's zone of proximal development, we selectively apply ICL to queries that are most likely to benefit from demonstrations, achieving a better balance between inference cost and performance; (2) We propose a human-like curriculum for fine-tuning, which prioritizes examples within the model's ZPD. The curriculum results in improved performance, and we explain its effectiveness through an analysis of the training dynamics of LLMs.</li>
</ul>

<h3>Title: Outsourced diffusion sampling: Efficient posterior inference in latent spaces of generative models</h3>
<ul>
<li><strong>Authors: </strong>Siddarth Venkatraman, Mohsin Hasan, Minsu Kim, Luca Scimeca, Marcin Sendera, Yoshua Bengio, Glen Berseth, Nikolay Malkin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06999">https://arxiv.org/abs/2502.06999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06999">https://arxiv.org/pdf/2502.06999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06999]] Outsourced diffusion sampling: Efficient posterior inference in latent spaces of generative models(https://arxiv.org/abs/2502.06999)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Any well-behaved generative model over a variable $\mathbf{x}$ can be expressed as a deterministic transformation of an exogenous ('outsourced') Gaussian noise variable $\mathbf{z}$: $\mathbf{x}=f_\theta(\mathbf{z})$. In such a model (e.g., a VAE, GAN, or continuous-time flow-based model), sampling of the target variable $\mathbf{x} \sim p_\theta(\mathbf{x})$ is straightforward, but sampling from a posterior distribution of the form $p(\mathbf{x}\mid\mathbf{y}) \propto p_\theta(\mathbf{x})r(\mathbf{x},\mathbf{y})$, where $r$ is a constraint function depending on an auxiliary variable $\mathbf{y}$, is generally intractable. We propose to amortize the cost of sampling from such posterior distributions with diffusion models that sample a distribution in the noise space ($\mathbf{z}$). These diffusion samplers are trained by reinforcement learning algorithms to enforce that the transformed samples $f_\theta(\mathbf{z})$ are distributed according to the posterior in the data space ($\mathbf{x}$). For many models and constraints of interest, the posterior in the noise space is smoother than the posterior in the data space, making it more amenable to such amortized inference. Our method enables conditional sampling under unconditional GAN, (H)VAE, and flow-based priors, comparing favorably both with current amortized and non-amortized inference methods. We demonstrate the proposed outsourced diffusion sampling in several experiments with large pretrained prior models: conditional image generation, reinforcement learning with human feedback, and protein structure generation.</li>
</ul>

<h3>Title: From Image to Video: An Empirical Study of Diffusion Representations</h3>
<ul>
<li><strong>Authors: </strong>Pedro VÃ©lez, Luisa F. PolanÃ­a, Yi Yang, Chuhan Zhang, Rishab Kabra, Anurag Arnab, Mehdi S. M. Sajjadi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07001">https://arxiv.org/abs/2502.07001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07001">https://arxiv.org/pdf/2502.07001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07001]] From Image to Video: An Empirical Study of Diffusion Representations(https://arxiv.org/abs/2502.07001)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have revolutionized generative modeling, enabling unprecedented realism in image and video synthesis. This success has sparked interest in leveraging their representations for visual understanding tasks. While recent works have explored this potential for image generation, the visual understanding capabilities of video diffusion models remain largely uncharted. To address this gap, we systematically compare the same model architecture trained for video versus image generation, analyzing the performance of their latent representations on various downstream tasks including image classification, action recognition, depth estimation, and tracking. Results show that video diffusion models consistently outperform their image counterparts, though we find a striking range in the extent of this superiority. We further analyze features extracted from different layers and with varying noise levels, as well as the effect of model size and training budget on representation and generation quality. This work marks the first direct comparison of video and image diffusion objectives for visual understanding, offering insights into the role of temporal information in representation learning.</li>
</ul>

<h3>Title: AstroLoc: Robust Space to Ground Image Localizer</h3>
<ul>
<li><strong>Authors: </strong>Gabriele Berton, Alex Stoken, Carlo Masone</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07003">https://arxiv.org/abs/2502.07003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07003">https://arxiv.org/pdf/2502.07003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07003]] AstroLoc: Robust Space to Ground Image Localizer(https://arxiv.org/abs/2502.07003)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Astronauts take thousands of photos of Earth per day from the International Space Station, which, once localized on Earth's surface, are used for a multitude of tasks, ranging from climate change research to disaster management. The localization process, which has been performed manually for decades, has recently been approached through image retrieval solutions: given an astronaut photo, find its most similar match among a large database of geo-tagged satellite images, in a task called Astronaut Photography Localization (APL). Yet, existing APL approaches are trained only using satellite images, without taking advantage of the millions open-source astronaut photos. In this work we present the first APL pipeline capable of leveraging astronaut photos for training. We first produce full localization information for 300,000 manually weakly labeled astronaut photos through an automated pipeline, and then use these images to train a model, called AstroLoc. AstroLoc learns a robust representation of Earth's surface features through two losses: astronaut photos paired with their matching satellite counterparts in a pairwise loss, and a second loss on clusters of satellite imagery weighted by their relevance to astronaut photography via unsupervised mining. We find that AstroLoc achieves a staggering 35% average improvement in recall@1 over previous SOTA, pushing the limits of existing datasets with a recall@100 consistently over 99%. Finally, we note that AstroLoc, without any fine-tuning, provides excellent results for related tasks like the lost-in-space satellite problem and historical space imagery localization.</li>
</ul>

<h3>Title: Demystifying Singular Defects in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haoqi Wang, Tong Zhang, Mathieu Salzmann</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07004">https://arxiv.org/abs/2502.07004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07004">https://arxiv.org/pdf/2502.07004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07004]] Demystifying Singular Defects in Large Language Models(https://arxiv.org/abs/2502.07004)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large transformer models are known to produce high-norm tokens. In vision transformers (ViTs), such tokens have been mathematically modeled through the singular vectors of the linear approximations of layers. However, in large language models (LLMs), the underlying causes of high-norm tokens remain largely unexplored, and their different properties from those of ViTs require a new analysis framework. In this paper, we provide both theoretical insights and empirical validation across a range of recent models, leading to the following observations: i) The layer-wise singular direction predicts the abrupt explosion of token norms in LLMs. ii) The negative eigenvalues of a layer explain its sudden decay. iii) The computational pathways leading to high-norm tokens differ between initial and noninitial tokens. iv) High-norm tokens are triggered by the right leading singular vector of the matrix approximating the corresponding modules. We showcase two practical applications of these findings: the improvement of quantization schemes and the design of LLM signatures. Our findings not only advance the understanding of singular defects in LLMs but also open new avenues for their application. We expect that this work will stimulate further research into the internal mechanisms of LLMs and will therefore publicly release our code.</li>
</ul>

<h3>Title: Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects</h3>
<ul>
<li><strong>Authors: </strong>Tai Hoang, Huy Le, Philipp Becker, Vien Anh Ngo, Gerhard Neumann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07005">https://arxiv.org/abs/2502.07005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07005">https://arxiv.org/pdf/2502.07005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07005]] Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects(https://arxiv.org/abs/2502.07005)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Manipulating objects with varying geometries and deformable objects is a major challenge in robotics. Tasks such as insertion with different objects or cloth hanging require precise control and effective modelling of complex dynamics. In this work, we frame this problem through the lens of a heterogeneous graph that comprises smaller sub-graphs, such as actuators and objects, accompanied by different edge types describing their interactions. This graph representation serves as a unified structure for both rigid and deformable objects tasks, and can be extended further to tasks comprising multiple actuators. To evaluate this setup, we present a novel and challenging reinforcement learning benchmark, including rigid insertion of diverse objects, as well as rope and cloth manipulation with multiple end-effectors. These tasks present a large search space, as both the initial and target configurations are uniformly sampled in 3D space. To address this issue, we propose a novel graph-based policy model, dubbed Heterogeneous Equivariant Policy (HEPi), utilizing $SE(3)$ equivariant message passing networks as the main backbone to exploit the geometric symmetry. In addition, by modeling explicit heterogeneity, HEPi can outperform Transformer-based and non-heterogeneous equivariant policies in terms of average returns, sample efficiency, and generalization to unseen objects.</li>
</ul>

<h3>Title: Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC</h3>
<ul>
<li><strong>Authors: </strong>Siwei Meng, Yawei Luo, Ping Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07007">https://arxiv.org/abs/2502.07007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07007">https://arxiv.org/pdf/2502.07007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07007]] Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC(https://arxiv.org/abs/2502.07007)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in AI-generated content have significantly improved the realism of 3D and 4D generation. However, most existing methods prioritize appearance consistency while neglecting underlying physical principles, leading to artifacts such as unrealistic deformations, unstable dynamics, and implausible objects interactions. Incorporating physics priors into generative models has become a crucial research direction to enhance structural integrity and motion realism. This survey provides a review of physics-aware generative methods, systematically analyzing how physical constraints are integrated into 3D and 4D generation. First, we examine recent works in incorporating physical priors into static and dynamic 3D generation, categorizing methods based on representation types, including vision-based, NeRF-based, and Gaussian Splatting-based approaches. Second, we explore emerging techniques in 4D generation, focusing on methods that model temporal dynamics with physical simulations. Finally, we conduct a comparative analysis of major methods, highlighting their strengths, limitations, and suitability for different materials and motion dynamics. By presenting an in-depth analysis of physics-grounded AIGC, this survey aims to bridge the gap between generative models and physical realism, providing insights that inspire future research in physically consistent content generation.</li>
</ul>

<h3>Title: DROP: Poison Dilution via Knowledge Distillation for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Georgios Syros, Anshuman Suri, Farinaz Koushanfar, Cristina Nita-Rotaru, Alina Oprea</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07011">https://arxiv.org/abs/2502.07011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07011">https://arxiv.org/pdf/2502.07011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07011]] DROP: Poison Dilution via Knowledge Distillation for Federated Learning(https://arxiv.org/abs/2502.07011)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, robust, steal, extraction, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning is vulnerable to adversarial manipulation, where malicious clients can inject poisoned updates to influence the global model's behavior. While existing defense mechanisms have made notable progress, they fail to protect against adversaries that aim to induce targeted backdoors under different learning and attack configurations. To address this limitation, we introduce DROP (Distillation-based Reduction Of Poisoning), a novel defense mechanism that combines clustering and activity-tracking techniques with extraction of benign behavior from clients via knowledge distillation to tackle stealthy adversaries that manipulate low data poisoning rates and diverse malicious client ratios within the federation. Through extensive experimentation, our approach demonstrates superior robustness compared to existing defenses across a wide range of learning configurations. Finally, we evaluate existing defenses and our method under the challenging setting of non-IID client data distribution and highlight the challenges of designing a resilient FL defense in this setting.</li>
</ul>

<h3>Title: Finding Words Associated with DIF: Predicting Differential Item Functioning using LLMs and Explainable AI</h3>
<ul>
<li><strong>Authors: </strong>Hotaka Maeda, Yikai Lu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07017">https://arxiv.org/abs/2502.07017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07017">https://arxiv.org/pdf/2502.07017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07017]] Finding Words Associated with DIF: Predicting Differential Item Functioning using LLMs and Explainable AI(https://arxiv.org/abs/2502.07017)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, transformer, large language model</a></li>
<li><strong>Abstract: </strong>We fine-tuned and compared several encoder-based Transformer large language models (LLM) to predict differential item functioning (DIF) from the item text. We then applied explainable artificial intelligence (XAI) methods to these models to identify specific words associated with DIF. The data included 42,180 items designed for English language arts and mathematics summative state assessments among students in grades 3 to 11. Prediction $R^2$ ranged from .04 to .32 among eight focal and reference group pairs. Our findings suggest that many words associated with DIF reflect minor sub-domains included in the test blueprint by design, rather than construct-irrelevant item content that should be removed from assessments. This may explain why qualitative reviews of DIF items often yield confusing or inconclusive results. Our approach can be used to screen words associated with DIF during the item-writing process for immediate revision, or help review traditional DIF analysis results by highlighting key words in the text. Extensions of this research can enhance the fairness of assessment programs, especially those that lack resources to build high-quality items, and among smaller subpopulations where we do not have sufficient sample sizes for traditional DIF analyses.</li>
</ul>

<h3>Title: AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements</h3>
<ul>
<li><strong>Authors: </strong>Adriana Eufrosiana Bora, Pierre-Luc St-Charles, Mirko Bronzi, ArsÃ¨ne Fansi Tchango, Bruno Rousseau, Kerrie Mengersen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07022">https://arxiv.org/abs/2502.07022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07022">https://arxiv.org/pdf/2502.07022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07022]] AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements(https://arxiv.org/abs/2502.07022)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite over a decade of legislative efforts to address modern slavery in the supply chains of large corporations, the effectiveness of government oversight remains hampered by the challenge of scrutinizing thousands of statements annually. While Large Language Models (LLMs) can be considered a well established solution for the automatic analysis and summarization of documents, recognizing concrete modern slavery countermeasures taken by companies and differentiating those from vague claims remains a challenging task. To help evaluate and fine-tune LLMs for the assessment of corporate statements, we introduce a dataset composed of 5,731 modern slavery statements taken from the Australian Modern Slavery Register and annotated at the sentence level. This paper details the construction steps for the dataset that include the careful design of annotation specifications, the selection and preprocessing of statements, and the creation of high-quality annotation subsets for effective model evaluations. To demonstrate our dataset's utility, we propose a machine learning methodology for the detection of sentences relevant to mandatory reporting requirements set by the Australian Modern Slavery Act. We then follow this methodology to benchmark modern language models under zero-shot and supervised learning settings.</li>
</ul>

<h3>Title: Detecting Neurodegenerative Diseases using Frame-Level Handwriting Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Sarah Laouedj, Yuzhe Wang, Jesus Villalba, Thomas Thebaud, Laureano Moro-Velazquez, Najim Dehak</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07025">https://arxiv.org/abs/2502.07025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07025">https://arxiv.org/pdf/2502.07025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07025]] Detecting Neurodegenerative Diseases using Frame-Level Handwriting Embeddings(https://arxiv.org/abs/2502.07025)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this study, we explored the use of spectrograms to represent handwriting signals for assessing neurodegenerative diseases, including 42 healthy controls (CTL), 35 subjects with Parkinson's Disease (PD), 21 with Alzheimer's Disease (AD), and 15 with Parkinson's Disease Mimics (PDM). We applied CNN and CNN-BLSTM models for binary classification using both multi-channel fixed-size and frame-based spectrograms. Our results showed that handwriting tasks and spectrogram channel combinations significantly impacted classification performance. The highest F1-score (89.8%) was achieved for AD vs. CTL, while PD vs. CTL reached 74.5%, and PD vs. PDM scored 77.97%. CNN consistently outperformed CNN-BLSTM. Different sliding window lengths were tested for constructing frame-based spectrograms. A 1-second window worked best for AD, longer windows improved PD classification, and window length had little effect on PD vs. PDM.</li>
</ul>

<h3>Title: Automated Consistency Analysis of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Aditya Patwardhan, Vivek Vaidya, Ashish Kundu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07036">https://arxiv.org/abs/2502.07036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07036">https://arxiv.org/pdf/2502.07036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07036]] Automated Consistency Analysis of LLMs(https://arxiv.org/abs/2502.07036)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative AI (Gen AI) with large language models (LLMs) are being widely adopted across the industry, academia and government. Cybersecurity is one of the key sectors where LLMs can be and/or are already being used. There are a number of problems that inhibit the adoption of trustworthy Gen AI and LLMs in cybersecurity and such other critical areas. One of the key challenge to the trustworthiness and reliability of LLMs is: how consistent an LLM is in its responses? In this paper, we have analyzed and developed a formal definition of consistency of responses of LLMs. We have formally defined what is consistency of responses and then develop a framework for consistency evaluation. The paper proposes two approaches to validate consistency: self-validation, and validation across multiple LLMs. We have carried out extensive experiments for several LLMs such as GPT4oMini, GPT3.5, Gemini, Cohere, and Llama3, on a security benchmark consisting of several cybersecurity questions: informational and situational. Our experiments corroborate the fact that even though these LLMs are being considered and/or already being used for several cybersecurity tasks today, they are often inconsistent in their responses, and thus are untrustworthy and unreliable for cybersecurity.</li>
</ul>

<h3>Title: Boosting of Classification Models with Human-in-the-Loop Computational Visual Knowledge Discovery</h3>
<ul>
<li><strong>Authors: </strong>Alice Williams, Boris Kovalerchuk</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07039">https://arxiv.org/abs/2502.07039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07039">https://arxiv.org/pdf/2502.07039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07039]] Boosting of Classification Models with Human-in-the-Loop Computational Visual Knowledge Discovery(https://arxiv.org/abs/2502.07039)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>High-risk artificial intelligence and machine learning classification tasks, such as healthcare diagnosis, require accurate and interpretable prediction models. However, classifier algorithms typically sacrifice individual case-accuracy for overall model accuracy, limiting analysis of class overlap areas regardless of task significance. The Adaptive Boosting meta-algorithm, which won the 2003 GÃ¶del Prize, analytically assigns higher weights to misclassified cases to reclassify. However, it relies on weaker base classifiers that are iteratively strengthened, limiting improvements from base classifiers. Combining visual and computational approaches enables selecting stronger base classifiers before boosting. This paper proposes moving boosting methodology from focusing on only misclassified cases to all cases in the class overlap areas using Computational and Interactive Visual Learning (CIVL) with a Human-in-the-Loop. It builds classifiers in lossless visualizations integrating human domain expertise and visual insights. A Divide and Classify process splits cases to simple and complex, classifying these individually through computational analysis and data visualization with lossless visualization spaces of Parallel Coordinates or other General Line Coordinates. After finding pure and overlap class areas simple cases in pure areas are classified, generating interpretable sub-models like decision rules in Propositional and First-order Logics. Only multidimensional cases in the overlap areas are losslessly visualized simplifying end-user cognitive tasks to identify difficult case patterns, including engineering features to form new classifiable patterns. Demonstration shows a perfectly accurate and losslessly interpretable model of the Iris dataset, and simulated data shows generalized benefits to accuracy and interpretability of models, increasing end-user confidence in discovered models.</li>
</ul>

<h3>Title: Scalable and Ethical Insider Threat Detection through Data Synthesis and Analysis by LLMs</h3>
<ul>
<li><strong>Authors: </strong>Haywood Gelman, John D. Hastings</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07045">https://arxiv.org/abs/2502.07045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07045">https://arxiv.org/pdf/2502.07045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07045]] Scalable and Ethical Insider Threat Detection through Data Synthesis and Analysis by LLMs(https://arxiv.org/abs/2502.07045)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Insider threats wield an outsized influence on organizations, disproportionate to their small numbers. This is due to the internal access insiders have to systems, information, and infrastructure. %One example of this influence is where anonymous respondents submit web-based job search site reviews, an insider threat risk to organizations. Signals for such risks may be found in anonymous submissions to public web-based job search site reviews. This research studies the potential for large language models (LLMs) to analyze and detect insider threat sentiment within job site reviews. Addressing ethical data collection concerns, this research utilizes synthetic data generation using LLMs alongside existing job review datasets. A comparative analysis of sentiment scores generated by LLMs is benchmarked against expert human scoring. Findings reveal that LLMs demonstrate alignment with human evaluations in most cases, thus effectively identifying nuanced indicators of threat sentiment. The performance is lower on human-generated data than synthetic data, suggesting areas for improvement in evaluating real-world data. Text diversity analysis found differences between human-generated and LLM-generated datasets, with synthetic data exhibiting somewhat lower diversity. Overall, the results demonstrate the applicability of LLMs to insider threat detection, and a scalable solution for insider sentiment testing by overcoming ethical and logistical barriers tied to data acquisition.</li>
</ul>

<h3>Title: Large Language Models in Software Security: A Survey of Vulnerability Detection Techniques and Insights</h3>
<ul>
<li><strong>Authors: </strong>Ze Sheng, Zhicheng Chen, Shuning Gu, Heqing Huang, Guofei Gu, Jeff Huang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07049">https://arxiv.org/abs/2502.07049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07049">https://arxiv.org/pdf/2502.07049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07049]] Large Language Models in Software Security: A Survey of Vulnerability Detection Techniques and Insights(https://arxiv.org/abs/2502.07049)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are emerging as transformative tools for software vulnerability detection, addressing critical challenges in the security domain. Traditional methods, such as static and dynamic analysis, often falter due to inefficiencies, high false positive rates, and the growing complexity of modern software systems. By leveraging their ability to analyze code structures, identify patterns, and generate repair sugges- tions, LLMs, exemplified by models like GPT, BERT, and CodeBERT, present a novel and scalable approach to mitigating vulnerabilities. This paper provides a detailed survey of LLMs in vulnerability detection. It examines key aspects, including model architectures, application methods, target languages, fine-tuning strategies, datasets, and evaluation metrics. We also analyze the scope of current research problems, highlighting the strengths and weaknesses of existing approaches. Further, we address challenges such as cross-language vulnerability detection, multimodal data integration, and repository-level analysis. Based on these findings, we propose solutions for issues like dataset scalability, model interpretability, and applications in low-resource scenarios. Our contributions are threefold: (1) a systematic review of how LLMs are applied in vulnerability detection; (2) an analysis of shared patterns and differences across studies, with a unified framework for understanding the field; and (3) a summary of key challenges and future research directions. This work provides valuable insights for advancing LLM-based vulnerability detection. We also maintain and regularly update latest selected paper on this https URL</li>
</ul>

<h3>Title: TOCTOU Resilient Attestation for IoT Networks</h3>
<ul>
<li><strong>Authors: </strong>Pavel Frolikov, Youngil Kim, Renascence Tarafder Prapty, Gene Tsudik</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07053">https://arxiv.org/abs/2502.07053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07053">https://arxiv.org/pdf/2502.07053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07053]] TOCTOU Resilient Attestation for IoT Networks(https://arxiv.org/abs/2502.07053)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Internet-of-Things (IoT) devices are increasingly common in both consumer and industrial settings, often performing safety-critical functions. Although securing these devices is vital, manufacturers typically neglect security issues or address them as an afterthought. This is of particular importance in IoT networks, e.g., in the industrial automation settings. To this end, network attestation -- verifying the software state of all devices in a network -- is a promising mitigation approach. However, current network attestation schemes have certain shortcomings: (1) lengthy TOCTOU (Time-Of-Check-Time-Of-Use) vulnerability windows, (2) high latency and resource overhead, and (3) susceptibility to interference from compromised devices. To address these limitations, we construct TRAIN (TOCTOU-Resilient Attestation for IoT Networks), an efficient technique that minimizes TOCTOU windows, ensures constant-time per-device attestation, and maintains resilience even with multiple compromised devices. We demonstrate TRAIN's viability and evaluate its performance via a fully functional and publicly available prototype.</li>
</ul>

<h3>Title: Tokenization Standards for Linguistic Integrity: Turkish as a Benchmark</h3>
<ul>
<li><strong>Authors: </strong>M. Ali Bayram, Ali Arda Fincan, Ahmet Semih GÃ¼mÃ¼Å, Sercan KarakaÅ, Banu Diri, SavaÅ YÄ±ldÄ±rÄ±m</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07057">https://arxiv.org/abs/2502.07057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07057">https://arxiv.org/pdf/2502.07057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07057]] Tokenization Standards for Linguistic Integrity: Turkish as a Benchmark(https://arxiv.org/abs/2502.07057)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Tokenization is a fundamental preprocessing step in NLP, directly impacting large language models' (LLMs) ability to capture syntactic, morphosyntactic, and semantic structures. This paper introduces a novel framework for systematically evaluating tokenization strategies, addressing challenges in morphologically rich and low-resource languages. Using a Turkish dataset of 6,200 multiple-choice questions from the Massive Multitask Language Understanding (MMLU) benchmark, the framework assesses tokenizers across five key metrics: vocabulary size, token count, processing time, language-specific token percentages (\%TR), and token purity. These metrics provide a structured approach to evaluating how well tokenizers preserve linguistic structures. While \%TR measures the proportion of valid words in the target language, \%Pure assesses the alignment of tokens with meaningful linguistic units, such as roots and valid morphemes, minimizing semantic fragmentation. The findings reveal that \%TR, introduced as a critical metric, exhibits a stronger correlation with downstream performance (e.g., MMLU scores) than token purity, emphasizing its role in improving model accuracy. Additionally, larger model parameters do not necessarily yield better tokenization quality or enhanced results, highlighting the importance of tailored tokenization strategies that prioritize linguistic alignment. This framework sets a new standard for developing robust tokenization methods optimized for morphologically complex and low-resource languages. Future work will refine morphological analysis, explore domain-specific customizations, and conduct cross-linguistic evaluations to further enhance tokenization practices.</li>
</ul>

<h3>Title: Using Contextually Aligned Online Reviews to Measure LLMs' Performance Disparities Across Language Varieties</h3>
<ul>
<li><strong>Authors: </strong>Zixin Tang, Chieh-Yang Huang, Tsung-Chi Li, Ho Yim Sam Ng, Hen-Hsen Huang, Ting-Hao 'Kenneth' Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07058">https://arxiv.org/abs/2502.07058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07058">https://arxiv.org/pdf/2502.07058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07058]] Using Contextually Aligned Online Reviews to Measure LLMs' Performance Disparities Across Language Varieties(https://arxiv.org/abs/2502.07058)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A language can have different varieties. These varieties can affect the performance of natural language processing (NLP) models, including large language models (LLMs), which are often trained on data from widely spoken varieties. This paper introduces a novel and cost-effective approach to benchmark model performance across language varieties. We argue that international online review platforms, such as this http URL, can serve as effective data sources for constructing datasets that capture comments in different language varieties from similar real-world scenarios, like reviews for the same hotel with the same rating using the same language (e.g., Mandarin Chinese) but different language varieties (e.g., Taiwan Mandarin, Mainland Mandarin). To prove this concept, we constructed a contextually aligned dataset comprising reviews in Taiwan Mandarin and Mainland Mandarin and tested six LLMs in a sentiment analysis task. Our results show that LLMs consistently underperform in Taiwan Mandarin.</li>
</ul>

<h3>Title: Federated Continual Learning: Concepts, Challenges, and Solutions</h3>
<ul>
<li><strong>Authors: </strong>Parisa Hamedi, Roozbeh Razavi-Far, Ehsan Hallaji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07059">https://arxiv.org/abs/2502.07059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07059">https://arxiv.org/pdf/2502.07059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07059]] Federated Continual Learning: Concepts, Challenges, and Solutions(https://arxiv.org/abs/2502.07059)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Continual Learning (FCL) has emerged as a robust solution for collaborative model training in dynamic environments, where data samples are continuously generated and distributed across multiple devices. This survey provides a comprehensive review of FCL, focusing on key challenges such as heterogeneity, model stability, communication overhead, and privacy preservation. We explore various forms of heterogeneity and their impact on model performance. Solutions to non-IID data, resource-constrained platforms, and personalized learning are reviewed in an effort to show the complexities of handling heterogeneous data distributions. Next, we review techniques for ensuring model stability and avoiding catastrophic forgetting, which are critical in non-stationary environments. Privacy-preserving techniques are another aspect of FCL that have been reviewed in this work. This survey has integrated insights from federated learning and continual learning to present strategies for improving the efficacy and scalability of FCL systems, making it applicable to a wide range of real-world scenarios.</li>
</ul>

<h3>Title: Zero-Knowledge Proof Frameworks: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Nojan Sheybani, Anees Ahmed, Michel Kinsy, Farinaz Koushanfar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07063">https://arxiv.org/abs/2502.07063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07063">https://arxiv.org/pdf/2502.07063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07063]] Zero-Knowledge Proof Frameworks: A Survey(https://arxiv.org/abs/2502.07063)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Zero-Knowledge Proofs (ZKPs) are a cryptographic primitive that allows a prover to demonstrate knowledge of a secret value to a verifier without revealing anything about the secret itself. ZKPs have shown to be an extremely powerful tool, as evidenced in both industry and academic settings. In recent years, the utilization of user data in practical applications has necessitated the rapid development of privacy-preserving techniques, including ZKPs. This has led to the creation of several robust open-source ZKP frameworks. However, there remains a significant gap in understanding the capabilities and real-world applications of these frameworks. Furthermore, identifying the most suitable frameworks for the developers' specific applications and settings is a challenge, given the variety of options available. The primary goal of our work is to lower the barrier to entry for understanding and building applications with open-source ZKP frameworks. In this work, we survey and evaluate 25 general-purpose, prominent ZKP frameworks. Recognizing that ZKPs have various constructions and underlying arithmetic schemes, our survey aims to provide a comprehensive overview of the ZKP landscape. These systems are assessed based on their usability and performance in SHA-256 and matrix multiplication experiments. Acknowledging that setting up a functional development environment can be challenging for these frameworks, we offer a fully open-source collection of Docker containers. These containers include a working development environment and are accompanied by documented code from our experiments. We conclude our work with a thorough analysis of the practical applications of ZKPs, recommendations for ZKP settings in different application scenarios, and a discussion on the future development of ZKP frameworks.</li>
</ul>

<h3>Title: Contextual Thompson Sampling via Generation of Missing Data</h3>
<ul>
<li><strong>Authors: </strong>Kelly W. Zhang, Tiffany Tianhui Cai, Hongseok Namkoong, Daniel Russo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07064">https://arxiv.org/abs/2502.07064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07064">https://arxiv.org/pdf/2502.07064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07064]] Contextual Thompson Sampling via Generation of Missing Data(https://arxiv.org/abs/2502.07064)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>We introduce a framework for Thompson sampling contextual bandit algorithms, in which the algorithm's ability to quantify uncertainty and make decisions depends on the quality of a generative model that is learned offline. Instead of viewing uncertainty in the environment as arising from unobservable latent parameters, our algorithm treats uncertainty as stemming from missing, but potentially observable, future outcomes. If these future outcomes were all observed, one could simply make decisions using an "oracle" policy fit on the complete dataset. Inspired by this conceptualization, at each decision-time, our algorithm uses a generative model to probabilistically impute missing future outcomes, fits a policy using the imputed complete dataset, and uses that policy to select the next action. We formally show that this algorithm is a generative formulation of Thompson Sampling and prove a state-of-the-art regret bound for it. Notably, our regret bound i) depends on the probabilistic generative model only through the quality of its offline prediction loss, and ii) applies to any method of fitting the "oracle" policy, which easily allows one to adapt Thompson sampling to decision-making settings with fairness and/or resource constraints.</li>
</ul>

<h3>Title: General-Purpose $f$-DP Estimation and Auditing in a Black-Box Setting</h3>
<ul>
<li><strong>Authors: </strong>Ãnder Askin (1), Holger Dette (1), Martin Dunsche (1), Tim Kutta (2), Yun Lu (3), Yu Wei (4), Vassilis Zikas (4) ((1) Ruhr-University Bochum, (2) Aarhus University, (3) University of Victoria, (4) Georgia Institute of Technology)</a></li>
<li><strong>Subjects: </strong>cs.CR, math.ST, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07066">https://arxiv.org/abs/2502.07066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07066">https://arxiv.org/pdf/2502.07066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07066]] General-Purpose $f$-DP Estimation and Auditing in a Black-Box Setting(https://arxiv.org/abs/2502.07066)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In this paper we propose new methods to statistically assess $f$-Differential Privacy ($f$-DP), a recent refinement of differential privacy (DP) that remedies certain weaknesses of standard DP (including tightness under algorithmic composition). A challenge when deploying differentially private mechanisms is that DP is hard to validate, especially in the black-box setting. This has led to numerous empirical methods for auditing standard DP, while $f$-DP remains less explored. We introduce new black-box methods for $f$-DP that, unlike existing approaches for this privacy notion, do not require prior knowledge of the investigated algorithm. Our procedure yields a complete estimate of the $f$-DP trade-off curve, with theoretical guarantees of convergence. Additionally, we propose an efficient auditing method that empirically detects $f$-DP violations with statistical certainty, merging techniques from non-parametric estimation and optimal classification theory. Through experiments on a range of DP mechanisms, we demonstrate the effectiveness of our estimation and auditing procedures.</li>
</ul>

<h3>Title: Specializing Large Language Models to Simulate Survey Response Distributions for Global Populations</h3>
<ul>
<li><strong>Authors: </strong>Yong Cao, Haijiang Liu, Arnav Arora, Isabelle Augenstein, Paul RÃ¶ttger, Daniel Hershcovich</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07068">https://arxiv.org/abs/2502.07068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07068">https://arxiv.org/pdf/2502.07068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07068]] Specializing Large Language Models to Simulate Survey Response Distributions for Global Populations(https://arxiv.org/abs/2502.07068)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large-scale surveys are essential tools for informing social science research and policy, but running surveys is costly and time-intensive. If we could accurately simulate group-level survey results, this would therefore be very valuable to social science research. Prior work has explored the use of large language models (LLMs) for simulating human behaviors, mostly through prompting. In this paper, we are the first to specialize LLMs for the task of simulating survey response distributions. As a testbed, we use country-level results from two global cultural surveys. We devise a fine-tuning method based on first-token probabilities to minimize divergence between predicted and actual response distributions for a given question. Then, we show that this method substantially outperforms other methods and zero-shot classifiers, even on unseen questions, countries, and a completely unseen survey. While even our best models struggle with the task, especially on unseen questions, our results demonstrate the benefits of specialization for simulation, which may accelerate progress towards sufficiently accurate simulation in the future.</li>
</ul>

<h3>Title: IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sayem Mohammad Imtiaz, Astha Singh, Fraol Batole, Hridesh Rajan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07072">https://arxiv.org/abs/2502.07072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07072">https://arxiv.org/pdf/2502.07072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07072]] IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large Language Models(https://arxiv.org/abs/2502.07072)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Not a day goes by without hearing about the impressive feats of large language models (LLMs), and equally, not a day passes without hearing about their challenges. LLMs are notoriously vulnerable to biases in their dataset, leading to issues such as toxicity. While domain-adaptive training has been employed to mitigate these issues, these techniques often address all model parameters indiscriminately during the repair process, resulting in poor repair quality and reduced model versatility. In this paper, we introduce a novel dynamic slicing-based intent-aware LLM repair strategy, IRepair. This approach selectively targets the most error-prone sections of the model for repair. Specifically, we propose dynamically slicing the model's most sensitive layers that require immediate attention, concentrating repair efforts on those areas. This method enables more effective repairs with potentially less impact on the model's overall performance by altering a smaller portion of the model. We evaluated our technique on three models from the GPT2 and GPT-Neo families, with parameters ranging from 800M to 1.6B, in a toxicity mitigation setup. Our results show that IRepair repairs errors 43.6% more effectively while causing 46% less disruption to general performance compared to the closest baseline, direct preference optimization. Our empirical analysis also reveals that errors are more concentrated in a smaller section of the model, with the top 20% of layers exhibiting 773% more error density than the remaining 80\%. This highlights the need for selective repair. Additionally, we demonstrate that a dynamic selection approach is essential for addressing errors dispersed throughout the model, ensuring a robust and efficient repair.</li>
</ul>

<h3>Title: Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lujain Ibrahim, Canfer Akbulut, Rasmi Elasmar, Charvi Rastogi, Minsuk Kahng, Meredith Ringel Morris, Kevin R. McKee, Verena Rieser, Murray Shanahan, Laura Weidinger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07077">https://arxiv.org/abs/2502.07077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07077">https://arxiv.org/pdf/2502.07077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07077]] Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models(https://arxiv.org/abs/2502.07077)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The tendency of users to anthropomorphise large language models (LLMs) is of growing interest to AI developers, researchers, and policy-makers. Here, we present a novel method for empirically evaluating anthropomorphic LLM behaviours in realistic and varied settings. Going beyond single-turn static benchmarks, we contribute three methodological advances in state-of-the-art (SOTA) LLM evaluation. First, we develop a multi-turn evaluation of 14 anthropomorphic behaviours. Second, we present a scalable, automated approach by employing simulations of user interactions. Third, we conduct an interactive, large-scale human subject study (N=1101) to validate that the model behaviours we measure predict real users' anthropomorphic perceptions. We find that all SOTA LLMs evaluated exhibit similar behaviours, characterised by relationship-building (e.g., empathy and validation) and first-person pronoun use, and that the majority of behaviours only first occur after multiple turns. Our work lays an empirical foundation for investigating how design choices influence anthropomorphic model behaviours and for progressing the ethical debate on the desirability of these behaviours. It also showcases the necessity of multi-turn evaluations for complex social phenomena in human-AI interaction.</li>
</ul>

<h3>Title: Evaluating the Systematic Reasoning Abilities of Large Language Models through Graph Coloring</h3>
<ul>
<li><strong>Authors: </strong>Alex Heyman, Joel Zylberberg</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07087">https://arxiv.org/abs/2502.07087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07087">https://arxiv.org/pdf/2502.07087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07087]] Evaluating the Systematic Reasoning Abilities of Large Language Models through Graph Coloring(https://arxiv.org/abs/2502.07087)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Contemporary large language models are powerful problem-solving tools, but they exhibit weaknesses in their reasoning abilities which ongoing research seeks to mitigate. We investigate graph coloring as a means of evaluating an LLM's capacities for systematic step-by-step reasoning and possibility space exploration, as well as effects of semantic problem framing. We test Claude 3.5 Sonnet, Llama 3.1 405B, Gemini 1.5 Pro, GPT-4o, o1-mini, and DeepSeek-R1 on a dataset of $k$-coloring problems with $2 \leq k \leq 4$ and vertex count $4 \leq n \leq 8$, using partial algorithmic solvers to further categorize problems by difficulty. In addition to substantial but varying framing effects, we find that all models except o1-mini and R1 exhibit $>60\%$ error rates on difficult problem types in all frames ($>15\%$ for o1-mini and $>10\%$ for R1), and no model achieves perfect accuracy even in the simple domain of 2-coloring 4-vertex graphs. Our results highlight both the considerable recent progress in LLM systematic reasoning and the limits of its reliability, especially in relation to increasing computational costs. We expect that more complex graph coloring problems, and procedural generation of arbitrary-complexity reasoning problems more broadly, offer further untapped potential for LLM benchmarking.</li>
</ul>

<h3>Title: SMAB: MAB based word Sensitivity Estimation Framework and its Applications in Adversarial Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Saurabh Kumar Pandey, Sachin Vashistha, Debrup Das, Somak Aditya, Monojit Choudhury</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07101">https://arxiv.org/abs/2502.07101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07101">https://arxiv.org/pdf/2502.07101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07101]] SMAB: MAB based word Sensitivity Estimation Framework and its Applications in Adversarial Text Generation(https://arxiv.org/abs/2502.07101)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>To understand the complexity of sequence classification tasks, Hahn et al. (2021) proposed sensitivity as the number of disjoint subsets of the input sequence that can each be individually changed to change the output. Though effective, calculating sensitivity at scale using this framework is costly because of exponential time complexity. Therefore, we introduce a Sensitivity-based Multi-Armed Bandit framework (SMAB), which provides a scalable approach for calculating word-level local (sentence-level) and global (aggregated) sensitivities concerning an underlying text classifier for any dataset. We establish the effectiveness of our approach through various applications. We perform a case study on CHECKLIST generated sentiment analysis dataset where we show that our algorithm indeed captures intuitively high and low-sensitive words. Through experiments on multiple tasks and languages, we show that sensitivity can serve as a proxy for accuracy in the absence of gold data. Lastly, we show that guiding perturbation prompts using sensitivity values in adversarial example generation improves attack success rate by 15.58%, whereas using sensitivity as an additional reward in adversarial paraphrase generation gives a 12.00% improvement over SOTA approaches. Warning: Contains potentially offensive content.</li>
</ul>

<h3>Title: Likelihood-Free Estimation for Spatiotemporal Hawkes processes with missing data and application to predictive policing</h3>
<ul>
<li><strong>Authors: </strong>Pramit Das, Moulinath Banerjee, Yuekai Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07111">https://arxiv.org/abs/2502.07111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07111">https://arxiv.org/pdf/2502.07111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07111]] Likelihood-Free Estimation for Spatiotemporal Hawkes processes with missing data and application to predictive policing(https://arxiv.org/abs/2502.07111)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>With the growing use of AI technology, many police departments use forecasting software to predict probable crime hotspots and allocate patrolling resources effectively for crime prevention. The clustered nature of crime data makes self-exciting Hawkes processes a popular modeling choice. However, one significant challenge in fitting such models is the inherent missingness in crime data due to non-reporting, which can bias the estimated parameters of the predictive model, leading to inaccurate downstream hotspot forecasts, often resulting in over or under-policing in various communities, especially the vulnerable ones. Our work introduces a Wasserstein Generative Adversarial Networks (WGAN) driven likelihood-free approach to account for unreported crimes in Spatiotemporal Hawkes models. We demonstrate through empirical analysis how this methodology improves the accuracy of parametric estimation in the presence of data missingness, leading to more reliable and efficient policing strategies.</li>
</ul>

<h3>Title: Online Scheduling for LLM Inference with KV Cache Constraints</h3>
<ul>
<li><strong>Authors: </strong>Patrick Jaillet, Jiashuo Jiang, Chara Podimata, Zijie Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07115">https://arxiv.org/abs/2502.07115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07115">https://arxiv.org/pdf/2502.07115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07115]] Online Scheduling for LLM Inference with KV Cache Constraints(https://arxiv.org/abs/2502.07115)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) inference, where a trained model generates text one word at a time in response to user prompts, is a computationally intensive process requiring efficient scheduling to optimize latency and resource utilization. A key challenge in LLM inference is the management of the Key-Value (KV) cache, which reduces redundant computations but introduces memory constraints. In this work, we model LLM inference with KV cache constraints theoretically and propose novel batching and scheduling algorithms that minimize inference latency while effectively managing the KV cache's memory. We analyze both semi-online and fully online scheduling models, and our results are threefold. First, we provide a polynomial-time algorithm that achieves exact optimality in terms of average latency in the semi-online prompt arrival model. Second, in the fully online case with a stochastic prompt arrival, we introduce an efficient online scheduling algorithm with constant regret. Third, we prove that no algorithm (deterministic or randomized) can achieve a constant competitive ratio in fully online adversarial settings. Our empirical evaluations on a public LLM inference dataset, using the Llama-70B model on A100 GPUs, show that our approach significantly outperforms benchmark algorithms used currently in practice, achieving lower latency while reducing energy consumption. Overall, our results offer a path toward more sustainable and cost-effective LLM deployment.</li>
</ul>

<h3>Title: SAFE: Self-Supervised Anomaly Detection Framework for Intrusion Detection</h3>
<ul>
<li><strong>Authors: </strong>Elvin Li, Zhengli Shang, Onat Gungor, Tajana Rosing</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07119">https://arxiv.org/abs/2502.07119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07119">https://arxiv.org/pdf/2502.07119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07119]] SAFE: Self-Supervised Anomaly Detection Framework for Intrusion Detection(https://arxiv.org/abs/2502.07119)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>The proliferation of IoT devices has significantly increased network vulnerabilities, creating an urgent need for effective Intrusion Detection Systems (IDS). Machine Learning-based IDS (ML-IDS) offer advanced detection capabilities but rely on labeled attack data, which limits their ability to identify unknown threats. Self-Supervised Learning (SSL) presents a promising solution by using only normal data to detect patterns and anomalies. This paper introduces SAFE, a novel framework that transforms tabular network intrusion data into an image-like format, enabling Masked Autoencoders (MAEs) to learn robust representations of network behavior. The features extracted by the MAEs are then incorporated into a lightweight novelty detector, enhancing the effectiveness of anomaly detection. Experimental results demonstrate that SAFE outperforms the state-of-the-art anomaly detection method, Scale Learning-based Deep Anomaly Detection method (SLAD), by up to 26.2% and surpasses the state-of-the-art SSL-based network intrusion detection approach, Anomal-E, by up to 23.5% in F1-score.</li>
</ul>

<h3>Title: Is Long Range Sequential Modeling Necessary For Colorectal Tumor Segmentation?</h3>
<ul>
<li><strong>Authors: </strong>Abhishek Srivastava, Koushik Biswas, Gorkem Durak, Gulsah Ozden, Mustafa Adli, Ulas Bagci</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07120">https://arxiv.org/abs/2502.07120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07120">https://arxiv.org/pdf/2502.07120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07120]] Is Long Range Sequential Modeling Necessary For Colorectal Tumor Segmentation?(https://arxiv.org/abs/2502.07120)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Segmentation of colorectal cancer (CRC) tumors in 3D medical imaging is both complex and clinically critical, providing vital support for effective radiation therapy planning and survival outcome assessment. Recently, 3D volumetric segmentation architectures incorporating long-range sequence modeling mechanisms, such as Transformers and Mamba, have gained attention for their capacity to achieve high accuracy in 3D medical image segmentation. In this work, we evaluate the effectiveness of these global token modeling techniques by pitting them against our proposed MambaOutUNet within the context of our newly introduced colorectal tumor segmentation dataset (CTS-204). Our findings suggest that robust local token interactions can outperform long-range modeling techniques in cases where the region of interest is small and anatomically complex, proposing a potential shift in 3D tumor segmentation research.</li>
</ul>

<h3>Title: Structural Reformation of Large Language Model Neuron Encapsulation for Divergent Information Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Denis Bakushev, Gideon Boultinghouse, Harriet Oppenheimer, Sebastian Gillingwater, Valentina Ashington, Wilfred Stanborough</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07124">https://arxiv.org/abs/2502.07124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07124">https://arxiv.org/pdf/2502.07124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07124]] Structural Reformation of Large Language Model Neuron Encapsulation for Divergent Information Aggregation(https://arxiv.org/abs/2502.07124)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Structured neuron encapsulation introduces a modular framework that enables more effective aggregation and specialization of information within deep learning architectures. A model modified through this framework demonstrated improved perplexity scores, greater lexical variability, and enhanced consistency in logical reasoning, suggesting that structured parameter distribution contributes to more efficient language representation. Statistical analyses of generated text highlighted a wider range of sentence structures and reduced redundancy in token selection, indicating that encapsulation fosters more adaptable language generation. A detailed evaluation of attention weight distributions revealed that the experimental model exhibited greater divergence in cross-layer activations, supporting the hypothesis that encapsulated neurons assume specialized processing roles. Logical consistency assessments further demonstrated that modular architectures mitigate contradictory outputs, reducing internal conflicts in inferred relationships between linguistic constructs. Computational trade-offs were analyzed, with results showing a minor increase in processing overhead, though improvements in parameter efficiency and structured decision-making compensated for the additional complexity. The mathematical formulation of the encapsulation mechanism confirmed that modular aggregation maintains stable convergence properties while promoting distinct functional roles for different neuron clusters.</li>
</ul>

<h3>Title: Cardiverse: Harnessing LLMs for Novel Card Game Prototyping</h3>
<ul>
<li><strong>Authors: </strong>Danrui Li, Sen Zhang, Sam S. Sohn, Kaidong Hu, Muhammad Usman, Mubbasir Kapadia</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07128">https://arxiv.org/abs/2502.07128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07128">https://arxiv.org/pdf/2502.07128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07128]] Cardiverse: Harnessing LLMs for Novel Card Game Prototyping(https://arxiv.org/abs/2502.07128)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The prototyping of computer games, particularly card games, requires extensive human effort in creative ideation and gameplay evaluation. Recent advances in Large Language Models (LLMs) offer opportunities to automate and streamline these processes. However, it remains challenging for LLMs to design novel game mechanics beyond existing databases, generate consistent gameplay environments, and develop scalable gameplay AI for large-scale evaluations. This paper addresses these challenges by introducing a comprehensive automated card game prototyping framework. The approach highlights a graph-based indexing method for generating novel game designs, an LLM-driven system for consistent game code generation validated by gameplay records, and a gameplay AI constructing method that uses an ensemble of LLM-generated action-value functions optimized through self-play. These contributions aim to accelerate card game prototyping, reduce human labor, and lower barriers to entry for game developers.</li>
</ul>

<h3>Title: Unconstrained Body Recognition at Altitude and Range: Comparing Four Approaches</h3>
<ul>
<li><strong>Authors: </strong>Blake A Myers, Matthew Q Hill, Veda Nandan Gandi, Thomas M Metz, Alice J O'Toole</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07130">https://arxiv.org/abs/2502.07130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07130">https://arxiv.org/pdf/2502.07130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07130]] Unconstrained Body Recognition at Altitude and Range: Comparing Four Approaches(https://arxiv.org/abs/2502.07130)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study presents an investigation of four distinct approaches to long-term person identification using body shape. Unlike short-term re-identification systems that rely on temporary features (e.g., clothing), we focus on learning persistent body shape characteristics that remain stable over time. We introduce a body identification model based on a Vision Transformer (ViT) (Body Identification from Diverse Datasets, BIDDS) and on a Swin-ViT model (Swin-BIDDS). We also expand on previous approaches based on the Linguistic and Non-linguistic Core ResNet Identity Models (LCRIM and NLCRIM), but with improved training. All models are trained on a large and diverse dataset of over 1.9 million images of approximately 5k identities across 9 databases. Performance was evaluated on standard re-identification benchmark datasets (MARS, MSMT17, Outdoor Gait, DeepChange) and on an unconstrained dataset that includes images at a distance (from close-range to 1000m), at altitude (from an unmanned aerial vehicle, UAV), and with clothing change. A comparative analysis across these models provides insights into how different backbone architectures and input image sizes impact long-term body identification performance across real-world conditions.</li>
</ul>

<h3>Title: TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Model Bring? - A Case Study on Korea Financial Texts</h3>
<ul>
<li><strong>Authors: </strong>Yewon Hwang, Sungbum Jung, Hanwool Lee, Sara Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07131">https://arxiv.org/abs/2502.07131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07131">https://arxiv.org/pdf/2502.07131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07131]] TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Model Bring? - A Case Study on Korea Financial Texts(https://arxiv.org/abs/2502.07131)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Domain specificity of embedding models is critical for effective performance. However, existing benchmarks, such as FinMTEB, are primarily designed for high-resource languages, leaving low-resource settings, such as Korean, under-explored. Directly translating established English benchmarks often fails to capture the linguistic and cultural nuances present in low-resource domains. In this paper, titled TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Models Bring? A Case Study on Korea Financial Texts, we introduce KorFinMTEB, a novel benchmark for the Korean financial domain, specifically tailored to reflect its unique cultural characteristics in low-resource languages. Our experimental results reveal that while the models perform robustly on a translated version of FinMTEB, their performance on KorFinMTEB uncovers subtle yet critical discrepancies, especially in tasks requiring deeper semantic understanding, that underscore the limitations of direct translation. This discrepancy highlights the necessity of benchmarks that incorporate language-specific idiosyncrasies and cultural nuances. The insights from our study advocate for the development of domain-specific evaluation frameworks that can more accurately assess and drive the progress of embedding models in low-resource settings.</li>
</ul>

<h3>Title: Towards a Robust Framework for Multimodal Hate Detection: A Study on Video vs. Image-based Content</h3>
<ul>
<li><strong>Authors: </strong>Girish A. Koushik, Diptesh Kanojia, Helen Treharne</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07138">https://arxiv.org/abs/2502.07138</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07138">https://arxiv.org/pdf/2502.07138</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07138]] Towards a Robust Framework for Multimodal Hate Detection: A Study on Video vs. Image-based Content(https://arxiv.org/abs/2502.07138)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Social media platforms enable the propagation of hateful content across different modalities such as textual, auditory, and visual, necessitating effective detection methods. While recent approaches have shown promise in handling individual modalities, their effectiveness across different modality combinations remains unexplored. This paper presents a systematic analysis of fusion-based approaches for multimodal hate detection, focusing on their performance across video and image-based content. Our comprehensive evaluation reveals significant modality-specific limitations: while simple embedding fusion achieves state-of-the-art performance on video content (HateMM dataset) with a 9.9% points F1-score improvement, it struggles with complex image-text relationships in memes (Hateful Memes dataset). Through detailed ablation studies and error analysis, we demonstrate how current fusion approaches fail to capture nuanced cross-modal interactions, particularly in cases involving benign confounders. Our findings provide crucial insights for developing more robust hate detection systems and highlight the need for modality-specific architectural considerations. The code is available at this https URL.</li>
</ul>

<h3>Title: Language-TPP: Integrating Temporal Point Processes with Language Models for Event Analysis</h3>
<ul>
<li><strong>Authors: </strong>Quyu Kong, Yixuan Zhang, Yang Liu, Panrong Tong, Enqi Liu, Feng Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07139">https://arxiv.org/abs/2502.07139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07139">https://arxiv.org/pdf/2502.07139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07139]] Language-TPP: Integrating Temporal Point Processes with Language Models for Event Analysis(https://arxiv.org/abs/2502.07139)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Temporal Point Processes (TPPs) have been widely used for event sequence modeling, but they often struggle to incorporate rich textual event descriptions effectively. Conversely, while Large Language Models (LLMs) have been shown remarkable capabilities in processing textual data, they lack mechanisms for handling temporal dynamics. To bridge this gap, we introduce Language-TPP, a unified framework that integrates TPPs with LLMs for enhanced event sequence modeling. Language-TPP introduces a novel temporal encoding mechanism that converts continuous time intervals into specialized byte-tokens, enabling seamless integration with standard LLM architectures. This approach allows Language-TPP to achieve state-of-the-art performance across multiple TPP tasks, including event time prediction, type prediction, and intensity estimation, on five datasets. Additionally, we demonstrate that incorporating temporal information significantly improves the quality of generated event descriptions.</li>
</ul>

<h3>Title: Few-Shot Multi-Human Neural Rendering Using Geometry Constraints</h3>
<ul>
<li><strong>Authors: </strong>Qian li, Victoria FernÃ ndez Abrevaya, Franck Multon, Adnane Boukhayma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07140">https://arxiv.org/abs/2502.07140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07140">https://arxiv.org/pdf/2502.07140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07140]] Few-Shot Multi-Human Neural Rendering Using Geometry Constraints(https://arxiv.org/abs/2502.07140)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a method for recovering the shape and radiance of a scene consisting of multiple people given solely a few images. Multi-human scenes are complex due to additional occlusion and clutter. For single-human settings, existing approaches using implicit neural representations have achieved impressive results that deliver accurate geometry and appearance. However, it remains challenging to extend these methods for estimating multiple humans from sparse views. We propose a neural implicit reconstruction method that addresses the inherent challenges of this task through the following contributions: First, we propose to use geometry constraints by exploiting pre-computed meshes using a human body model (SMPL). Specifically, we regularize the signed distances using the SMPL mesh and leverage bounding boxes for improved rendering. Second, we propose a ray regularization scheme to minimize rendering inconsistencies, and a saturation regularization for robust optimization in variable illumination. Extensive experiments on both real and synthetic datasets demonstrate the benefits of our approach and show state-of-the-art performance against existing neural reconstruction methods.</li>
</ul>

<h3>Title: Ask Patients with Patience: Enabling LLMs for Human-Centric Medical Dialogue with Grounded Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jiayuan Zhu, Junde Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07143">https://arxiv.org/abs/2502.07143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07143">https://arxiv.org/pdf/2502.07143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07143]] Ask Patients with Patience: Enabling LLMs for Human-Centric Medical Dialogue with Grounded Reasoning(https://arxiv.org/abs/2502.07143)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate and efficient diagnosis in online medical consultations remains a challenge for current large language models. These models often rely on single-turn interactions and lack the ability to refine their predictions through follow-up questions. Additionally, their responses frequently contain complex medical terminology, making them less accessible to non-medical users and creating barriers to effective communication. In this paper, we introduce Ask Patients with Patience (APP), the first multi-turn dialogue that enables LLMs to iteratively refine diagnoses based on grounded reasoning. By integrating medical guidelines and entropy minimization, APP improves both diagnostic accuracy and efficiency. Furthermore, it features human-centric communication that bridges the gap between user comprehension and medical terminology, significantly enhancing user accessibility and engagement. We evaluated APP using a subset of the ReMeDi dataset, comparing it with single-turn and traditional multi-turn LLM baselines. APP achieved higher similarity scores in diagnosis predictions, demonstrating better alignment with ground truth diagnoses. Entropy analysis showed that APP reduces diagnostic uncertainty more rapidly across iterations, increasing confidence in its predictions. APP also excels in user accessibility and empathy, further bridging the gap between complex medical language and user understanding. Code will be released at: this https URL.</li>
</ul>

<h3>Title: Mesh2SSM++: A Probabilistic Framework for Unsupervised Learning of Statistical Shape Model of Anatomies from Surface Meshes</h3>
<ul>
<li><strong>Authors: </strong>Krithika Iyer, Mokshagna Sai Teja Karanam, Shireen Elhabian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07145">https://arxiv.org/abs/2502.07145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07145">https://arxiv.org/pdf/2502.07145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07145]] Mesh2SSM++: A Probabilistic Framework for Unsupervised Learning of Statistical Shape Model of Anatomies from Surface Meshes(https://arxiv.org/abs/2502.07145)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Anatomy evaluation is crucial for understanding the physiological state, diagnosing abnormalities, and guiding medical interventions. Statistical shape modeling (SSM) is vital in this process. By enabling the extraction of quantitative morphological shape descriptors from MRI and CT scans, SSM provides comprehensive descriptions of anatomical variations within a population. However, the effectiveness of SSM in anatomy evaluation hinges on the quality and robustness of the shape models. While deep learning techniques show promise in addressing these challenges by learning complex nonlinear representations of shapes, existing models still have limitations and often require pre-established shape models for training. To overcome these issues, we propose Mesh2SSM++, a novel approach that learns to estimate correspondences from meshes in an unsupervised manner. This method leverages unsupervised, permutation-invariant representation learning to estimate how to deform a template point cloud into subject-specific meshes, forming a correspondence-based shape model. Additionally, our probabilistic formulation allows learning a population-specific template, reducing potential biases associated with template selection. A key feature of Mesh2SSM++ is its ability to quantify aleatoric uncertainty, which captures inherent data variability and is essential for ensuring reliable model predictions and robust decision-making in clinical tasks, especially under challenging imaging conditions. Through extensive validation across diverse anatomies, evaluation metrics, and downstream tasks, we demonstrate that Mesh2SSM++ outperforms existing methods. Its ability to operate directly on meshes, combined with computational efficiency and interpretability through its probabilistic framework, makes it an attractive alternative to traditional and deep learning-based SSM approaches.</li>
</ul>

<h3>Title: Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Feng Chen, Allan Raventos, Nan Cheng, Surya Ganguli, Shaul Druckmann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07154">https://arxiv.org/abs/2502.07154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07154">https://arxiv.org/pdf/2502.07154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07154]] Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning(https://arxiv.org/abs/2502.07154)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in large language models (LLMs) highlights the power of scaling test-time compute to achieve strong performance on complex tasks, such as mathematical reasoning and code generation. This raises a critical question: how should model training be modified to optimize performance under a subsequent test-time compute strategy and budget? To explore this, we focus on pass@N, a simple test-time strategy that searches for a correct answer in $N$ independent samples. We show, surprisingly, that training with cross-entropy (CE) loss can be ${\it misaligned}$ with pass@N in that pass@N accuracy ${\it decreases}$ with longer training. We explain the origins of this misalignment in terms of model overconfidence induced by CE, and experimentally verify our prediction of overconfidence as an impediment to scaling test-time compute via pass@N. Furthermore we suggest a principled, modified training loss that is better aligned to pass@N by limiting model confidence and rescuing pass@N test performance. Our algorithm demonstrates improved mathematical reasoning on MATH and MiniF2F benchmarks under several scenarios: (1) providing answers to math questions; and (2) proving theorems by searching over proof trees of varying shapes. Overall our work underscores the importance of co-designing two traditionally separate phases of LLM development: training-time protocols and test-time search and reasoning strategies.</li>
</ul>

<h3>Title: Explaining 3D Computed Tomography Classifiers with Counterfactuals</h3>
<ul>
<li><strong>Authors: </strong>Joseph Paul Cohen, Louis Blankemeier, Akshay Chaudhari</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07156">https://arxiv.org/abs/2502.07156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07156">https://arxiv.org/pdf/2502.07156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07156]] Explaining 3D Computed Tomography Classifiers with Counterfactuals(https://arxiv.org/abs/2502.07156)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Counterfactual explanations in medical imaging are critical for understanding the predictions made by deep learning models. We extend the Latent Shift counterfactual generation method from 2D applications to 3D computed tomography (CT) scans. We address the challenges associated with 3D data, such as limited training samples and high memory demands, by implementing a slice-based approach. This method leverages a 2D encoder trained on CT slices, which are subsequently combined to maintain 3D context. We demonstrate this technique on two models for clinical phenotype prediction and lung segmentation. Our approach is both memory-efficient and effective for generating interpretable counterfactuals in high-resolution 3D medical imaging.</li>
</ul>

<h3>Title: Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer</h3>
<ul>
<li><strong>Authors: </strong>Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07158">https://arxiv.org/abs/2502.07158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07158">https://arxiv.org/pdf/2502.07158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07158]] Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer(https://arxiv.org/abs/2502.07158)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Early prediction of pediatric cardiac arrest (CA) is critical for timely intervention in high-risk intensive care settings. We introduce PedCA-FT, a novel transformer-based framework that fuses tabular view of EHR with the derived textual view of EHR to fully unleash the interactions of high-dimensional risk factors and their dynamics. By employing dedicated transformer modules for each modality view, PedCA-FT captures complex temporal and contextual patterns to produce robust CA risk estimates. Evaluated on a curated pediatric cohort from the CHOA-CICU database, our approach outperforms ten other artificial intelligence models across five key performance metrics and identifies clinically meaningful risk factors. These findings underscore the potential of multimodal fusion techniques to enhance early CA detection and improve patient care.</li>
</ul>

<h3>Title: Pseudorandomness Properties of Random Reversible Circuits</h3>
<ul>
<li><strong>Authors: </strong>William Gay, William He, Nicholas Kocurek, Ryan O'Donnell</a></li>
<li><strong>Subjects: </strong>cs.CR, math.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07159">https://arxiv.org/abs/2502.07159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07159">https://arxiv.org/pdf/2502.07159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07159]] Pseudorandomness Properties of Random Reversible Circuits(https://arxiv.org/abs/2502.07159)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Motivated by practical concerns in cryptography, we study pseudorandomness properties of permutations on $\{0,1\}^n$ computed by random circuits made from reversible $3$-bit gates (permutations on $\{0,1\}^3$). Our main result is that a random circuit of depth $\sqrt{n} \cdot \tilde{O}(k^3)$, with each layer consisting of $\Theta(n)$ random gates in a fixed two-dimensional nearest-neighbor architecture, yields approximate $k$-wise independent permutations. Our result can be seen as a particularly simple/practical block cipher construction that gives provable statistical security against attackers with access to $k$~input-output pairs within few rounds. The main technical component of our proof consists of two parts: 1. We show that the Markov chain on $k$-tuples of $n$-bit strings induced by a single random $3$-bit one-dimensional nearest-neighbor gate has spectral gap at least $1/n \cdot \tilde{O}(k)$. Then we infer that a random circuit with layers of random gates in a fixed one-dimensional gate architecture yields approximate $k$-wise independent permutations of $\{0,1\}^n$ in depth $n\cdot \tilde{O}(k^2)$ 2. We show that if the $n$ wires are layed out on a two-dimensional lattice of bits, then repeatedly alternating applications of approximate $k$-wise independent permutations of $\{0,1\}^{\sqrt n}$ to the rows and columns of the lattice yields an approximate $k$-wise independent permutation of $\{0,1\}^n$ in small depth. Our work improves on the original work of Gowers, who showed a gap of $1/\mathrm{poly}(n,k)$ for one random gate (with non-neighboring inputs); and, on subsequent work improving the gap to $\Omega(1/n^2k)$ in the same setting.</li>
</ul>

<h3>Title: HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates</h3>
<ul>
<li><strong>Authors: </strong>Lei Lu, Yize Li, Yanzhi Wang, Wei Wang, Wei Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07160">https://arxiv.org/abs/2502.07160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07160">https://arxiv.org/pdf/2502.07160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07160]] HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates(https://arxiv.org/abs/2502.07160)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Image compression under ultra-low bitrates remains challenging for both conventional learned image compression (LIC) and generative vector-quantized (VQ) modeling. Conventional LIC suffers from severe artifacts due to heavy quantization, while generative VQ modeling gives poor fidelity due to the mismatch between learned generative priors and specific inputs. In this work, we propose Hybrid-Diffusion Image Compression (HDCompression), a dual-stream framework that utilizes both generative VQ-modeling and diffusion models, as well as conventional LIC, to achieve both high fidelity and high perceptual quality. Different from previous hybrid methods that directly use pre-trained LIC models to generate low-quality fidelity-preserving information from heavily quantized latent, we use diffusion models to extract high-quality complimentary fidelity information from the ground-truth input, which can enhance the system performance in several aspects: improving indices map prediction, enhancing the fidelity-preserving output of the LIC stream, and refining conditioned image reconstruction with VQ-latent correction. In addition, our diffusion model is based on a dense representative vector (DRV), which is lightweight with very simple sampling schedulers. Extensive experiments demonstrate that our HDCompression outperforms the previous conventional LIC, generative VQ-modeling, and hybrid frameworks in both quantitative metrics and qualitative visualization, providing balanced robust compression performance at ultra-low bitrates.</li>
</ul>

<h3>Title: A Survey on Mamba Architecture for Vision Applications</h3>
<ul>
<li><strong>Authors: </strong>Fady Ibrahim, Guangjun Liu, Guanghui Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07161">https://arxiv.org/abs/2502.07161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07161">https://arxiv.org/pdf/2502.07161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07161]] A Survey on Mamba Architecture for Vision Applications(https://arxiv.org/abs/2502.07161)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Transformers have become foundational for visual tasks such as object detection, semantic segmentation, and video understanding, but their quadratic complexity in attention mechanisms presents scalability challenges. To address these limitations, the Mamba architecture utilizes state-space models (SSMs) for linear scalability, efficient processing, and improved contextual awareness. This paper investigates Mamba architecture for visual domain applications and its recent advancements, including Vision Mamba (ViM) and VideoMamba, which introduce bidirectional scanning, selective scanning mechanisms, and spatiotemporal processing to enhance image and video understanding. Architectural innovations like position embeddings, cross-scan modules, and hierarchical designs further optimize the Mamba framework for global and local feature extraction. These advancements position Mamba as a promising architecture in computer vision research and applications.</li>
</ul>

<h3>Title: Does Training on Synthetic Data Make Models Less Robust?</h3>
<ul>
<li><strong>Authors: </strong>Lingze Zhang, Ellie Pavlick</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07164">https://arxiv.org/abs/2502.07164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07164">https://arxiv.org/pdf/2502.07164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07164]] Does Training on Synthetic Data Make Models Less Robust?(https://arxiv.org/abs/2502.07164)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>An increasingly common practice is to train large language models (LLMs) using synthetic data. Often this synthetic data is produced by the same or similar LLMs as those it is being used to train. This raises the question of whether the synthetic data might in fact exacerbate certain "blindspots" by reinforcing heuristics that the LLM already encodes. In this paper, we conduct simulated experiments on the natural language inference (NLI) task with Llama-2-7B-hf models. We use MultiNLI as the general task and HANS, a targeted evaluation set designed to measure the presence of specific heuristic strategies for NLI, as our "blindspot" task. Our goal is to determine whether performance disparities between the general and blind spot tasks emerge. Our results indicate that synthetic data does not reinforce blindspots in the way we expected. Specifically, we see that, while fine-tuning with synthetic data doesn't necessarily reduce the use of the heuristic, it also does not make it worse as we hypothesized.</li>
</ul>

<h3>Title: Foreign-Object Detection in High-Voltage Transmission Line Based on Improved YOLOv8m</h3>
<ul>
<li><strong>Authors: </strong>Zhenyue Wang, Guowu Yuan, Hao Zhou, Yi Ma, Yutang Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07175">https://arxiv.org/abs/2502.07175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07175">https://arxiv.org/pdf/2502.07175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07175]] Foreign-Object Detection in High-Voltage Transmission Line Based on Improved YOLOv8m(https://arxiv.org/abs/2502.07175)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction</a></li>
<li><strong>Abstract: </strong>The safe operation of high-voltage transmission lines ensures the power grid's security. Various foreign objects attached to the transmission lines, such as balloons, kites and nesting birds, can significantly affect the safe and stable operation of high-voltage transmission lines. With the advancement of computer vision technology, periodic automatic inspection of foreign objects is efficient and necessary. Existing detection methods have low accuracy because foreign objects at-tached to the transmission lines are complex, including occlusions, diverse object types, significant scale variations, and complex backgrounds. In response to the practical needs of the Yunnan Branch of China Southern Power Grid Co., Ltd., this paper proposes an improved YOLOv8m-based model for detecting foreign objects on transmission lines. Experiments are conducted on a dataset collected from Yunnan Power Grid. The proposed model enhances the original YOLOv8m by in-corporating a Global Attention Module (GAM) into the backbone to focus on occluded foreign objects, replacing the SPPF module with the SPPCSPC module to augment the model's multiscale feature extraction capability, and introducing the Focal-EIoU loss function to address the issue of high- and low-quality sample imbalances. These improvements accelerate model convergence and enhance detection accuracy. The experimental results demonstrate that our proposed model achieves a 2.7% increase in mAP_0.5, a 4% increase in mAP_0.5:0.95, and a 6% increase in recall.</li>
</ul>

<h3>Title: MatrixKAN: Parallelized Kolmogorov-Arnold Network</h3>
<ul>
<li><strong>Authors: </strong>Cale Coffman, Lizhong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07176">https://arxiv.org/abs/2502.07176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07176">https://arxiv.org/pdf/2502.07176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07176]] MatrixKAN: Parallelized Kolmogorov-Arnold Network(https://arxiv.org/abs/2502.07176)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Kolmogorov-Arnold Networks (KAN) are a new class of neural network architecture representing a promising alternative to the Multilayer Perceptron (MLP), demonstrating improved expressiveness and interpretability. However, KANs suffer from slow training and inference speeds relative to MLPs due in part to the recursive nature of the underlying B-spline calculations. This issue is particularly apparent with respect to KANs utilizing high-degree B-splines, as the number of required non-parallelizable recursions is proportional to B-spline degree. We solve this issue by proposing MatrixKAN, a novel optimization that parallelizes B-spline calculations with matrix representation and operations, thus significantly improving effective computation time for models utilizing high-degree B-splines. In this paper, we demonstrate the superior scaling of MatrixKAN's computation time relative to B-spline degree. Further, our experiments demonstrate speedups of approximately 40x relative to KAN, with significant additional speedup potential for larger datasets or higher spline degrees.</li>
</ul>

<h3>Title: Improved YOLOv7 model for insulator defect detection</h3>
<ul>
<li><strong>Authors: </strong>Zhenyue Wang, Guowu Yuan, Hao Zhou, Yi Ma, Yutang Ma, Dong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07179">https://arxiv.org/abs/2502.07179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07179">https://arxiv.org/pdf/2502.07179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07179]] Improved YOLOv7 model for insulator defect detection(https://arxiv.org/abs/2502.07179)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Insulators are crucial insulation components and structural supports in power grids, playing a vital role in the transmission lines. Due to temperature fluctuations, internal stress, or damage from hail, insulators are prone to injury. Automatic detection of damaged insulators faces challenges such as diverse types, small defect targets, and complex backgrounds and shapes. Most research for detecting insulator defects has focused on a single defect type or a specific material. However, the insulators in the grid's transmission lines have different colors and materials. Various insulator defects coexist, and the existing methods have difficulty meeting the practical application requirements. Current methods suffer from low detection accuracy and mAP0.5 cannot meet application requirements. This paper proposes an improved YOLOv7 model for multi-type insulator defect detection. First, our model replaces the SPPCSPC module with the RFB module to enhance the network's feature extraction capability. Second, a CA mechanism is introduced into the head part to enhance the network's feature representation ability and to improve detection accuracy. Third, a WIoU loss function is employed to address the low-quality samples hindering model generalization during training, thereby improving the model's overall performance. The experimental results indicate that the proposed model exhibits enhancements across various performance metrics. Specifically, there is a 1.6% advancement in mAP_0.5, a corresponding 1.6% enhancement in mAP_0.5:0.95, a 1.3% elevation in precision, and a 1% increase in recall. Moreover, the model achieves parameter reduction by 3.2 million, leading to a decrease of 2.5 GFLOPS in computational cost. Notably, there is also an improvement of 2.81 milliseconds in single-image detection speed.</li>
</ul>

<h3>Title: Refine Knowledge of Large Language Models via Adaptive Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Yinghui Li, Haojing Huang, Jiayi Kuang, Yangning Li, Shu-Yu Guo, Chao Qu, Xiaoyu Tan, Hai-Tao Zheng, Ying Shen, Philip S. Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07184">https://arxiv.org/abs/2502.07184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07184">https://arxiv.org/pdf/2502.07184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07184]] Refine Knowledge of Large Language Models via Adaptive Contrastive Learning(https://arxiv.org/abs/2502.07184)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>How to alleviate the hallucinations of Large Language Models (LLMs) has always been the fundamental goal pursued by the LLMs research community. Looking through numerous hallucination-related studies, a mainstream category of methods is to reduce hallucinations by optimizing the knowledge representation of LLMs to change their output. Considering that the core focus of these works is the knowledge acquired by models, and knowledge has long been a central theme in human societal progress, we believe that the process of models refining knowledge can greatly benefit from the way humans learn. In our work, by imitating the human learning process, we design an Adaptive Contrastive Learning strategy. Our method flexibly constructs different positive and negative samples for contrastive learning based on LLMs' actual mastery of knowledge. This strategy helps LLMs consolidate the correct knowledge they already possess, deepen their understanding of the correct knowledge they have encountered but not fully grasped, forget the incorrect knowledge they previously learned, and honestly acknowledge the knowledge they lack. Extensive experiments and detailed analyses on widely used datasets demonstrate the effectiveness of our method.</li>
</ul>

<h3>Title: A Large-Scale Benchmark for Vietnamese Sentence Paraphrases</h3>
<ul>
<li><strong>Authors: </strong>Sang Quang Nguyen, Kiet Van Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07188">https://arxiv.org/abs/2502.07188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07188">https://arxiv.org/pdf/2502.07188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07188]] A Large-Scale Benchmark for Vietnamese Sentence Paraphrases(https://arxiv.org/abs/2502.07188)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents ViSP, a high-quality Vietnamese dataset for sentence paraphrasing, consisting of 1.2M original-paraphrase pairs collected from various domains. The dataset was constructed using a hybrid approach that combines automatic paraphrase generation with manual evaluation to ensure high quality. We conducted experiments using methods such as back-translation, EDA, and baseline models like BART and T5, as well as large language models (LLMs), including GPT-4o, Gemini-1.5, Aya, Qwen-2.5, and Meta-Llama-3.1 variants. To the best of our knowledge, this is the first large-scale study on Vietnamese paraphrasing. We hope that our dataset and findings will serve as a valuable foundation for future research and applications in Vietnamese paraphrase tasks.</li>
</ul>

<h3>Title: Exploring Neural Network Pruning with Screening Methods</h3>
<ul>
<li><strong>Authors: </strong>Mingyuan Wang, Yangzi Guo, Sida Liu, Yanwen Xiao</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07189">https://arxiv.org/abs/2502.07189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07189">https://arxiv.org/pdf/2502.07189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07189]] Exploring Neural Network Pruning with Screening Methods(https://arxiv.org/abs/2502.07189)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) such as convolutional neural networks (CNNs) for visual tasks, recurrent neural networks (RNNs) for sequence data, and transformer models for rich linguistic or multimodal tasks, achieved unprecedented performance on a wide range of tasks. The impressive performance of modern DNNs is partially attributed to their sheer scale. The latest deep learning models have tens to hundreds of millions of parameters which makes the inference processes resource-intensive. The high computational complexity of these networks prevents their deployment on resource-limited devices such as mobile platforms, IoT devices, and edge computing systems because these devices require energy-efficient and real-time processing capabilities. This paper proposes and evaluates a network pruning framework that eliminates non-essential parameters based on a statistical analysis of network component significance across classification categories. The proposed method uses screening methods coupled with a weighted scheme to assess connection and channel contributions for unstructured and structured pruning which allows for the elimination of unnecessary network elements without significantly degrading model performance. Extensive experimental validation on real-world vision datasets for both fully connected neural networks (FNNs) and CNNs has shown that the proposed framework produces competitive lean networks compared to the original networks. Moreover, the proposed framework outperforms state-of-art network pruning methods in two out of three cases.</li>
</ul>

<h3>Title: Provably Efficient RLHF Pipeline: A Unified View from Contextual Bandits</h3>
<ul>
<li><strong>Authors: </strong>Long-Fei Li, Yu-Yang Qian, Peng Zhao, Zhi-Hua Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07193">https://arxiv.org/abs/2502.07193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07193">https://arxiv.org/pdf/2502.07193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07193]] Provably Efficient RLHF Pipeline: A Unified View from Contextual Bandits(https://arxiv.org/abs/2502.07193)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) is a widely used approach for aligning Large Language Models (LLMs) with human preferences. While recent advancements have provided valuable insights into various stages and settings of RLHF, a comprehensive theoretical understanding of the entire RLHF pipeline remains lacking. Towards this end, we propose a unified framework for the RLHF pipeline from the view of contextual bandits and provide provable efficiency guarantees. In particular, we decompose the RLHF process into two distinct stages: (post-)training and deployment, exploring both passive and active data collection strategies during the training phase. By employing the Bradley-Terry preference model with a linearly parameterized reward function, we reformulate RLHF as a contextual preference bandit problem. We then develop novel algorithms for each stage, demonstrating significant improvements over existing approaches in both statistical and computational efficiency. Finally, we apply our method to train and deploy Llama-3-8B-Instruct on the Ultrafeedback-binarized dataset, and empirical results confirm the effectiveness of our approach.</li>
</ul>

<h3>Title: Dense Object Detection Based on De-homogenized Queries</h3>
<ul>
<li><strong>Authors: </strong>Yueming Huang, Chenrui Ma, Hao Zhou, Hao Wu, Guowu Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07194">https://arxiv.org/abs/2502.07194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07194">https://arxiv.org/pdf/2502.07194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07194]] Dense Object Detection Based on De-homogenized Queries(https://arxiv.org/abs/2502.07194)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Dense object detection is widely used in automatic driving, video surveillance, and other fields. This paper focuses on the challenging task of dense object detection. Currently, detection methods based on greedy algorithms, such as non-maximum suppression (NMS), often produce many repetitive predictions or missed detections in dense scenarios, which is a common problem faced by NMS-based algorithms. Through the end-to-end DETR (DEtection TRansformer), as a type of detector that can incorporate the post-processing de-duplication capability of NMS, etc., into the network, we found that homogeneous queries in the query-based detector lead to a reduction in the de-duplication capability of the network and the learning efficiency of the encoder, resulting in duplicate prediction and missed detection problems. To solve this problem, we propose learnable differentiated encoding to de-homogenize the queries, and at the same time, queries can communicate with each other via differentiated encoding information, replacing the previous self-attention among the queries. In addition, we used joint loss on the output of the encoder that considered both location and confidence prediction to give a higher-quality initialization for queries. Without cumbersome decoder stacking and guaranteeing accuracy, our proposed end-to-end detection framework was more concise and reduced the number of parameters by about 8% compared to deformable DETR. Our method achieved excellent results on the challenging CrowdHuman dataset with 93.6% average precision (AP), 39.2% MR-2, and 84.3% JI. The performance overperformed previous SOTA methods, such as Iter-E2EDet (Progressive End-to-End Object Detection) and MIP (One proposal, Multiple predictions). In addition, our method is more robust in various scenarios with different densities.</li>
</ul>

<h3>Title: Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Xingpei Ma, Jiaran Cai, Yuansheng Guan, Shenneng Huang, Qiang Zhang, Shunsi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07203">https://arxiv.org/abs/2502.07203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07203">https://arxiv.org/pdf/2502.07203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07203]] Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion(https://arxiv.org/abs/2502.07203)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent diffusion-based talking face generation models have demonstrated impressive potential in synthesizing videos that accurately match a speech audio clip with a given reference identity. However, existing approaches still encounter significant challenges due to uncontrollable factors, such as inaccurate lip-sync, inappropriate head posture and the lack of fine-grained control over facial expressions. In order to introduce more face-guided conditions beyond speech audio clips, a novel two-stage training framework Playmate is proposed to generate more lifelike facial expressions and talking faces. In the first stage, we introduce a decoupled implicit 3D representation along with a meticulously designed motion-decoupled module to facilitate more accurate attribute disentanglement and generate expressive talking videos directly from audio cues. Then, in the second stage, we introduce an emotion-control module to encode emotion control information into the latent space, enabling fine-grained control over emotions and thereby achieving the ability to generate talking videos with desired emotion. Extensive experiments demonstrate that Playmate outperforms existing state-of-the-art methods in terms of video quality and lip-synchronization, and improves flexibility in controlling emotion and head pose. The code will be available at this https URL.</li>
</ul>

<h3>Title: A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07207">https://arxiv.org/abs/2502.07207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07207">https://arxiv.org/pdf/2502.07207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07207]] A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning(https://arxiv.org/abs/2502.07207)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) pose a significant security risk to organizations and industries. These attacks often lead to severe data breaches and compromise the system for a long time. Mitigating these sophisticated attacks is highly challenging due to the stealthy and persistent nature of APTs. Machine learning models are often employed to tackle this challenge by bringing automation and scalability to APT detection. Nevertheless, these intelligent methods are data-driven, and thus, highly affected by the quality and relevance of input data. This paper aims to analyze measurements considered when recording network traffic and conclude which features contribute more to detecting APT samples. To do this, we study the features associated with various APT cases and determine their importance using a machine learning framework. To ensure the generalization of our findings, several feature selection techniques are employed and paired with different classifiers to evaluate their effectiveness. Our findings provide insights into how APT detection can be enhanced in real-world scenarios.</li>
</ul>

<h3>Title: Improve the Training Efficiency of DRL for Wireless Communication Resource Allocation: The Role of Generative Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Xinren Zhang, Jiadong Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07211">https://arxiv.org/abs/2502.07211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07211">https://arxiv.org/pdf/2502.07211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07211]] Improve the Training Efficiency of DRL for Wireless Communication Resource Allocation: The Role of Generative Diffusion Models(https://arxiv.org/abs/2502.07211)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Dynamic resource allocation in mobile wireless networks involves complex, time-varying optimization problems, motivating the adoption of deep reinforcement learning (DRL). However, most existing works rely on pre-trained policies, overlooking dynamic environmental changes that rapidly invalidate the policies. Periodic retraining becomes inevitable but incurs prohibitive computational costs and energy consumption-critical concerns for resource-constrained wireless systems. We identify three root causes of inefficient retraining: high-dimensional state spaces, suboptimal action spaces exploration-exploitation trade-offs, and reward design limitations. To overcome these limitations, we propose Diffusion-based Deep Reinforcement Learning (D2RL), which leverages generative diffusion models (GDMs) to holistically enhance all three DRL components. Iterative refinement process and distribution modelling of GDMs enable (1) the generation of diverse state samples to improve environmental understanding, (2) balanced action space exploration to escape local optima, and (3) the design of discriminative reward functions that better evaluate action quality. Our framework operates in two modes: Mode I leverages GDMs to explore reward spaces and design discriminative reward functions that rigorously evaluate action quality, while Mode II synthesizes diverse state samples to enhance environmental understanding and generalization. Extensive experiments demonstrate that D2RL achieves faster convergence and reduced computational costs over conventional DRL methods for resource allocation in wireless communications while maintaining competitive policy performance. This work underscores the transformative potential of GDMs in overcoming fundamental DRL training bottlenecks for wireless networks, paving the way for practical, real-time deployments.</li>
</ul>

<h3>Title: Evaluation for Regression Analyses on Evolving Data Streams</h3>
<ul>
<li><strong>Authors: </strong>Yibin Sun, Heitor Murilo Gomes, Bernhard Pfahringer, Albert Bifet</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07213">https://arxiv.org/abs/2502.07213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07213">https://arxiv.org/pdf/2502.07213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07213]] Evaluation for Regression Analyses on Evolving Data Streams(https://arxiv.org/abs/2502.07213)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The paper explores the challenges of regression analysis in evolving data streams, an area that remains relatively underexplored compared to classification. We propose a standardized evaluation process for regression and prediction interval tasks in streaming contexts. Additionally, we introduce an innovative drift simulation strategy capable of synthesizing various drift types, including the less-studied incremental drift. Comprehensive experiments with state-of-the-art methods, conducted under the proposed process, validate the effectiveness and robustness of our approach.</li>
</ul>

<h3>Title: Pareto Optimal Algorithmic Recourse in Multi-cost Function</h3>
<ul>
<li><strong>Authors: </strong>Wen-Ling Chen, Hong-Chang Huang, Kai-Hung Lin, Shang-Wei Hwang, Hao-Tsung Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07214">https://arxiv.org/abs/2502.07214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07214">https://arxiv.org/pdf/2502.07214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07214]] Pareto Optimal Algorithmic Recourse in Multi-cost Function(https://arxiv.org/abs/2502.07214)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In decision-making systems, algorithmic recourse aims to identify minimal-cost actions to alter an individual features, thereby obtaining a desired outcome. This empowers individuals to understand, question, or alter decisions that negatively affect them. However, due to the variety and sensitivity of system environments and individual personalities, quantifying the cost of a single function is nearly impossible while considering multiple criteria situations. Most current recourse mechanisms use gradient-based methods that assume cost functions are differentiable, often not applicable in real-world scenarios, resulting in sub-optimal solutions that compromise various criteria. These solutions are typically intractable and lack rigorous theoretical foundations, raising concerns regarding interpretability, reliability, and transparency from the explainable AI (XAI) perspective. To address these issues, this work proposes an algorithmic recourse framework that handles non-differentiable and discrete multi-cost functions. By formulating recourse as a multi-objective optimization problem and assigning weights to different criteria based on their importance, our method identifies Pareto optimal recourse recommendations. To demonstrate scalability, we incorporate the concept of epsilon-net, proving the ability to find approximated Pareto optimal actions. Experiments show the trade-off between different criteria and the methods scalability in large graphs. Compared to current heuristic practices, our approach provides a stronger theoretical foundation and better aligns recourse suggestions with real-world requirements.</li>
</ul>

<h3>Title: SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Wenxi Li, Yuchen Guo, Jilai Zheng, Haozhe Lin, Chao Ma, Lu Fang, Xiaokang Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07216">https://arxiv.org/abs/2502.07216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07216">https://arxiv.org/pdf/2502.07216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07216]] SparseFormer: Detecting Objects in HRW Shots via Sparse Vision Transformer(https://arxiv.org/abs/2502.07216)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent years have seen an increase in the use of gigapixel-level image and video capture systems and benchmarks with high-resolution wide (HRW) shots. However, unlike close-up shots in the MS COCO dataset, the higher resolution and wider field of view raise unique challenges, such as extreme sparsity and huge scale changes, causing existing close-up detectors inaccuracy and inefficiency. In this paper, we present a novel model-agnostic sparse vision transformer, dubbed SparseFormer, to bridge the gap of object detection between close-up and HRW shots. The proposed SparseFormer selectively uses attentive tokens to scrutinize the sparsely distributed windows that may contain objects. In this way, it can jointly explore global and local attention by fusing coarse- and fine-grained features to handle huge scale changes. SparseFormer also benefits from a novel Cross-slice non-maximum suppression (C-NMS) algorithm to precisely localize objects from noisy windows and a simple yet effective multi-scale strategy to improve accuracy. Extensive experiments on two HRW benchmarks, PANDA and DOTA-v1.0, demonstrate that the proposed SparseFormer significantly improves detection accuracy (up to 5.8%) and speed (up to 3x) over the state-of-the-art approaches.</li>
</ul>

<h3>Title: LUNAR: LLM Unlearning via Neural Activation Redirection</h3>
<ul>
<li><strong>Authors: </strong>William F. Shen, Xinchi Qiu, Meghdad Kurmanji, Alex Iacob, Lorenzo Sani, Yihong Chen, Nicola Cancedda, Nicholas D. Lane</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07218">https://arxiv.org/abs/2502.07218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07218">https://arxiv.org/pdf/2502.07218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07218]] LUNAR: LLM Unlearning via Neural Activation Redirection(https://arxiv.org/abs/2502.07218)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) benefit from training on ever larger amounts of textual data, but as a result, they increasingly incur the risk of leaking private information. The ability to selectively remove knowledge from LLMs is, therefore, a highly desirable capability. In this paper, we propose LUNAR, a novel unlearning methodology grounded in the Linear Representation Hypothesis. LUNAR operates by redirecting the representations of unlearned data to regions that trigger the model's inherent ability to express its inability to answer. LUNAR achieves state-of-the-art unlearning performance while significantly enhancing the controllability of the unlearned model during inference. Specifically, LUNAR achieves between 2.9x to 11.7x improvements on combined "unlearning efficacy" and "model utility" score ("Deviation Score") on the PISTOL dataset across various base models. We also demonstrate, through quantitative analysis and qualitative examples, LUNAR's superior controllability in generating coherent and contextually aware responses, mitigating undesired side effects of existing methods. Moreover, we demonstrate that LUNAR is robust against white-box adversarial attacks and versatile in handling real-world scenarios, such as processing sequential unlearning requests.</li>
</ul>

<h3>Title: MLLM4PUE: Toward Universal Embeddings in Computational Pathology through Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Qifeng Zhou, Thao M. Dang, Wenliang Zhong, Yuzhi Guo, Hehuan Ma, Saiyang Na, Junzhou Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07221">https://arxiv.org/abs/2502.07221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07221">https://arxiv.org/pdf/2502.07221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07221]] MLLM4PUE: Toward Universal Embeddings in Computational Pathology through Multimodal LLMs(https://arxiv.org/abs/2502.07221)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Pathology plays a critical role in diagnosing a wide range of diseases, yet existing approaches often rely heavily on task-specific models trained on extensive, well-labeled datasets. These methods face sustainability challenges due to the diversity of pathologies and the labor-intensive nature of data collection. To address these limitations, we highlight the need for universal multimodal embeddings that can support multiple downstream tasks. Previous approaches often involve fine-tuning CLIP-based models, which handle images and text separately, limiting their ability to capture complex multimodal relationships. Additionally, these models are evaluated across diverse datasets without a unified benchmark for assessing multimodal embeddings in pathology. To address these challenges, we propose MLLM4PUE, a novel framework that leverages Multimodal Large Language Models (MLLMs) to generate Pathology Universal Embeddings. The MLLM4PUE framework not only facilitates robust integration of images and text but also enhances understanding and fusion capabilities across various tasks. We further introduce the Pathology Multimodal Embedding Benchmark (PMEB), a comprehensive benchmark designed to assess the quality of pathology multimodal embeddings. PMEB comprises 15 original tasks drawn from 14 datasets, organized into three meta-tasks: retrieval, classification, and composed retrieval. Experimental results demonstrate the superiority of MLLM4PUE, illustrating MLLM-based models can effectively support a wide range of downstream tasks and unify the research direction for foundation models in pathology.</li>
</ul>

<h3>Title: A Memory Efficient Randomized Subspace Optimization Method for Training Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yiming Chen, Yuan Zhang, Yin Liu, Kun Yuan, Zaiwen Wen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07222">https://arxiv.org/abs/2502.07222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07222">https://arxiv.org/pdf/2502.07222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07222]] A Memory Efficient Randomized Subspace Optimization Method for Training Large Language Models(https://arxiv.org/abs/2502.07222)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The memory challenges associated with training Large Language Models (LLMs) have become a critical concern, particularly when using the Adam optimizer. To address this issue, numerous memory-efficient techniques have been proposed, with GaLore standing out as a notable example designed to reduce the memory footprint of optimizer states. However, these approaches do not alleviate the memory burden imposed by activations, rendering them unsuitable for scenarios involving long context sequences or large mini-batches. Moreover, their convergence properties are still not well-understood in the literature. In this work, we introduce a Randomized Subspace Optimization framework for pre-training and fine-tuning LLMs. Our approach decomposes the high-dimensional training problem into a series of lower-dimensional subproblems. At each iteration, a random subspace is selected, and the parameters within that subspace are optimized. This structured reduction in dimensionality allows our method to simultaneously reduce memory usage for both activations and optimizer states. We establish comprehensive convergence guarantees and derive rates for various scenarios, accommodating different optimization strategies to solve the subproblems. Extensive experiments validate the superior memory and communication efficiency of our method, achieving performance comparable to GaLore and Adam.</li>
</ul>

<h3>Title: CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Sen Peng, Mingyue Wang, Jianfei He, Jijia Yang, Xiaohua Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07225">https://arxiv.org/abs/2502.07225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07225">https://arxiv.org/pdf/2502.07225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07225]] CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models(https://arxiv.org/abs/2502.07225)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Latent diffusion models have recently demonstrated superior capabilities in many downstream image synthesis tasks. However, customization of latent diffusion models using unauthorized data can severely compromise the privacy and intellectual property rights of data owners. Adversarial examples as protective perturbations have been developed to defend against unauthorized data usage by introducing imperceptible noise to customization samples, preventing diffusion models from effectively learning them. In this paper, we first reveal that the primary reason adversarial examples are effective as protective perturbations in latent diffusion models is the distortion of their latent representations, as demonstrated through qualitative and quantitative experiments. We then propose the Contrastive Adversarial Training (CAT) utilizing adapters as an adaptive attack against these protection methods, highlighting their lack of robustness. Extensive experiments demonstrate that our CAT method significantly reduces the effectiveness of protective perturbations in customization configurations, urging the community to reconsider and enhance the robustness of existing protective perturbation methods. Code is available at \hyperlink{here}{this https URL}.</li>
</ul>

<h3>Title: Revisiting the Auxiliary Data in Backdoor Purification</h3>
<ul>
<li><strong>Authors: </strong>Shaokui Wei, Shanchao Yang, Jiayin Liu, Hongyuan Zha</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07231">https://arxiv.org/abs/2502.07231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07231">https://arxiv.org/pdf/2502.07231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07231]] Revisiting the Auxiliary Data in Backdoor Purification(https://arxiv.org/abs/2502.07231)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Backdoor attacks occur when an attacker subtly manipulates machine learning models during the training phase, leading to unintended behaviors when specific triggers are present. To mitigate such emerging threats, a prevalent strategy is to cleanse the victim models by various backdoor purification techniques. Despite notable achievements, current state-of-the-art (SOTA) backdoor purification techniques usually rely on the availability of a small clean dataset, often referred to as auxiliary dataset. However, acquiring an ideal auxiliary dataset poses significant challenges in real-world applications. This study begins by assessing the SOTA backdoor purification techniques across different types of real-world auxiliary datasets. Our findings indicate that the purification effectiveness fluctuates significantly depending on the type of auxiliary dataset used. Specifically, a high-quality in-distribution auxiliary dataset is essential for effective purification, whereas datasets from varied or out-of-distribution sources significantly degrade the defensive performance. Based on this, we propose Guided Input Calibration (GIC), which aims to improve purification efficacy by employing a learnable transformation. Guided by the victim model itself, GIC aligns the characteristics of the auxiliary dataset with those of the original training set. Comprehensive experiments demonstrate that GIC can substantially enhance purification performance across diverse types of auxiliary datasets. The code and data will be available via this https URL.</li>
</ul>

<h3>Title: Simplifying Adversarially Robust PAC Learning with Tolerance</h3>
<ul>
<li><strong>Authors: </strong>Hassan Ashtiani, Vinayak Pathak, Ruth Urner</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07232">https://arxiv.org/abs/2502.07232</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07232">https://arxiv.org/pdf/2502.07232</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07232]] Simplifying Adversarially Robust PAC Learning with Tolerance(https://arxiv.org/abs/2502.07232)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Adversarially robust PAC learning has proved to be challenging, with the currently best known learners [Montasser et al., 2021a] relying on improper methods based on intricate compression schemes, resulting in sample complexity exponential in the VC-dimension. A series of follow up work considered a slightly relaxed version of the problem called adversarially robust learning with tolerance [Ashtiani et al., 2023, Bhattacharjee et al., 2023, Raman et al., 2024] and achieved better sample complexity in terms of the VC-dimension. However, those algorithms were either improper and complex, or required additional assumptions on the hypothesis class H. We prove, for the first time, the existence of a simpler learner that achieves a sample complexity linear in the VC-dimension without requiring additional assumptions on H. Even though our learner is improper, it is "almost proper" in the sense that it outputs a hypothesis that is "similar" to a hypothesis in H. We also use the ideas from our algorithm to construct a semi-supervised learner in the tolerant setting. This simple algorithm achieves comparable bounds to the previous (non-tolerant) semi-supervised algorithm of Attias et al. [2022a], but avoids the use of intricate subroutines from previous works, and is "almost proper."</li>
</ul>

<h3>Title: DrugImproverGPT: A Large Language Model for Drug Optimization with Fine-Tuning via Structured Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Xuefeng Liu, Songhao Jiang, Siyu Chen, Zhuoran Yang, Yuxin Chen, Ian Foster, Rick Stevens</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, q-bio.BM, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07237">https://arxiv.org/abs/2502.07237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07237">https://arxiv.org/pdf/2502.07237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07237]] DrugImproverGPT: A Large Language Model for Drug Optimization with Fine-Tuning via Structured Policy Optimization(https://arxiv.org/abs/2502.07237)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Finetuning a Large Language Model (LLM) is crucial for generating results towards specific objectives. This research delves into the realm of drug optimization and introduce a novel reinforcement learning algorithm to finetune a drug optimization LLM-based generative model, enhancing the original drug across target objectives, while retains the beneficial chemical properties of the original drug. This work is comprised of two primary components: (1) DrugImprover: A framework tailored for improving robustness and efficiency in drug optimization. It includes a LLM designed for drug optimization and a novel Structured Policy Optimization (SPO) algorithm, which is theoretically grounded. This algorithm offers a unique perspective for fine-tuning the LLM-based generative model by aligning the improvement of the generated molecule with the input molecule under desired objectives. (2) A dataset of 1 million compounds, each with OEDOCK docking scores on 5 human proteins associated with cancer cells and 24 binding sites from SARS-CoV-2 virus. We conduct a comprehensive evaluation of SPO and demonstrate its effectiveness in improving the original drug across target properties. Our code and dataset will be publicly available at: this https URL.</li>
</ul>

<h3>Title: Diffusion Suction Grasping with Large-Scale Parcel Dataset</h3>
<ul>
<li><strong>Authors: </strong>Ding-Tao Huang, Xinyi He, Debei Hua, Dongfang Yu, En-Te Lin, Long Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07238">https://arxiv.org/abs/2502.07238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07238">https://arxiv.org/pdf/2502.07238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07238]] Diffusion Suction Grasping with Large-Scale Parcel Dataset(https://arxiv.org/abs/2502.07238)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While recent advances in object suction grasping have shown remarkable progress, significant challenges persist particularly in cluttered and complex parcel handling scenarios. Two fundamental limitations hinder current approaches: (1) the lack of a comprehensive suction grasp dataset tailored for parcel manipulation tasks, and (2) insufficient adaptability to diverse object characteristics including size variations, geometric complexity, and textural diversity. To address these challenges, we present Parcel-Suction-Dataset, a large-scale synthetic dataset containing 25 thousand cluttered scenes with 410 million precision-annotated suction grasp poses. This dataset is generated through our novel geometric sampling algorithm that enables efficient generation of optimal suction grasps incorporating both physical constraints and material properties. We further propose Diffusion-Suction, an innovative framework that reformulates suction grasp prediction as a conditional generation task through denoising diffusion probabilistic models. Our method iteratively refines random noise into suction grasp score maps through visual-conditioned guidance from point cloud observations, effectively learning spatial point-wise affordances from our synthetic dataset. Extensive experiments demonstrate that the simple yet efficient Diffusion-Suction achieves new state-of-the-art performance compared to previous models on both Parcel-Suction-Dataset and the public SuctionNet-1Billion benchmark.</li>
</ul>

<h3>Title: Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Jiecheng Lu, Shihao Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07244">https://arxiv.org/abs/2502.07244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07244">https://arxiv.org/pdf/2502.07244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07244]] Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting(https://arxiv.org/abs/2502.07244)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, generative</a></li>
<li><strong>Abstract: </strong>Autoregressive attention-based time series forecasting (TSF) has drawn increasing interest, with mechanisms like linear attention sometimes outperforming vanilla attention. However, deeper Transformer architectures frequently misalign with autoregressive objectives, obscuring the underlying VAR structure embedded within linear attention and hindering their ability to capture the data generative processes in TSF. In this work, we first show that a single linear attention layer can be interpreted as a dynamic vector autoregressive (VAR) structure. We then explain that existing multi-layer Transformers have structural mismatches with the autoregressive forecasting objective, which impair interpretability and generalization ability. To address this, we show that by rearranging the MLP, attention, and input-output flow, multi-layer linear attention can also be aligned as a VAR model. Then, we propose Structural Aligned Mixture of VAR (SAMoVAR), a linear Transformer variant that integrates interpretable dynamic VAR weights for multivariate TSF. By aligning the Transformer architecture with autoregressive objectives, SAMoVAR delivers improved performance, interpretability, and computational efficiency, comparing to SOTA TSF models.</li>
</ul>

<h3>Title: Robust Indoor Localization in Dynamic Environments: A Multi-source Unsupervised Domain Adaptation Framework</h3>
<ul>
<li><strong>Authors: </strong>Jiyu Jiao, Xiaojun Wang, Chengpei Han</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.pop-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07246">https://arxiv.org/abs/2502.07246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07246">https://arxiv.org/pdf/2502.07246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07246]] Robust Indoor Localization in Dynamic Environments: A Multi-source Unsupervised Domain Adaptation Framework(https://arxiv.org/abs/2502.07246)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fingerprint localization has gained significant attention due to its cost-effective deployment, low complexity, and high efficacy. However, traditional methods, while effective for static data, often struggle in dynamic environments where data distributions and feature spaces evolve-a common occurrence in real-world scenarios. To address the challenges of robustness and adaptability in fingerprint localization for dynamic indoor environments, this paper proposes DF-Loc, an end-to-end dynamic fingerprint localization system based on multi-source unsupervised domain adaptation (MUDA). DF-Loc leverages historical data from multiple time scales to facilitate knowledge transfer in specific feature spaces, thereby enhancing generalization capabilities in the target domain and reducing reliance on labeled data. Specifically, the system incorporates a Quality Control (QC) module for CSI data preprocessing and employs image processing techniques for CSI fingerprint feature reconstruction. Additionally, a multi-scale attention-based feature fusion backbone network is designed to extract multi-level transferable fingerprint features. Finally, a dual-stage alignment model aligns the distributions of multiple source-target domain pairs, improving regression characteristics in the target domain. Extensive experiments conducted in office and classroom environments demonstrate that DF-Loc outperforms comparative methods in terms of both localization accuracy and robustness. With 60% of reference points used for training, DF-Loc achieves average localization errors of 0.79m and 3.72m in "same-test" scenarios, and 0.94m and 4.39m in "different-test" scenarios, respectively. This work pioneers an end-to-end multi-source transfer learning approach for fingerprint localization, providing valuable insights for future research in dynamic environments.</li>
</ul>

<h3>Title: NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection</h3>
<ul>
<li><strong>Authors: </strong>Liying Han, Gaofeng Dong, Xiaomin Ouyang, Lance Kaplan, Federico Cerutti, Mani Srivastava</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07250">https://arxiv.org/abs/2502.07250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07250">https://arxiv.org/pdf/2502.07250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07250]] NARCE: A Mamba-Based Neural Algorithmic Reasoner Framework for Online Complex Event Detection(https://arxiv.org/abs/2502.07250)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current machine learning models excel in short-span perception tasks but struggle to derive high-level insights from long-term observation, a capability central to understanding complex events (CEs). CEs, defined as sequences of short-term atomic events (AEs) governed by spatiotemporal rules, are challenging to detect online due to the need to extract meaningful patterns from long and noisy sensor data while ignoring irrelevant events. We hypothesize that state-based methods are well-suited for CE detection, as they capture event progression through state transitions without requiring long-term memory. Baseline experiments validate this, demonstrating that the state-space model Mamba outperforms existing architectures. However, Mamba's reliance on extensive labeled data, which are difficult to obtain, motivates our second hypothesis: decoupling CE rule learning from noisy sensor data can reduce data requirements. To address this, we propose NARCE, a framework that combines Neural Algorithmic Reasoning (NAR) to split the task into two components: (i) learning CE rules independently of sensor data using synthetic concept traces generated by LLMs and (ii) mapping sensor inputs to these rules via an adapter. Our results show that NARCE outperforms baselines in accuracy, generalization to unseen and longer sensor data, and data efficiency, significantly reducing annotation costs while advancing robust CE detection.</li>
</ul>

<h3>Title: GENERator: A Long-Context Generative Genomic Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Wei Wu, Qiuyi Li, Mingyang Li, Kun Fu, Fuli Feng, Jieping Ye, Hui Xiong, Zheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, q-bio.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07272">https://arxiv.org/abs/2502.07272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07272">https://arxiv.org/pdf/2502.07272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07272]] GENERator: A Long-Context Generative Genomic Foundation Model(https://arxiv.org/abs/2502.07272)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Advancements in DNA sequencing technologies have significantly improved our ability to decode genomic sequences. However, the prediction and interpretation of these sequences remain challenging due to the intricate nature of genetic material. Large language models (LLMs) have introduced new opportunities for biological sequence analysis. Recent developments in genomic language models have underscored the potential of LLMs in deciphering DNA sequences. Nonetheless, existing models often face limitations in robustness and application scope, primarily due to constraints in model structure and training data scale. To address these limitations, we present GENERator, a generative genomic foundation model featuring a context length of 98k base pairs (bp) and 1.2B parameters. Trained on an expansive dataset comprising 386B bp of eukaryotic DNA, the GENERator demonstrates state-of-the-art performance across both established and newly proposed benchmarks. The model adheres to the central dogma of molecular biology, accurately generating protein-coding sequences that translate into proteins structurally analogous to known families. It also shows significant promise in sequence optimization, particularly through the prompt-responsive generation of promoter sequences with specific activity profiles. These capabilities position the GENERator as a pivotal tool for genomic research and biotechnological advancement, enhancing our ability to interpret and predict complex biological systems and enabling precise genomic interventions.</li>
</ul>

<h3>Title: Dataset Ownership Verification in Contrastive Pre-trained Models</h3>
<ul>
<li><strong>Authors: </strong>Yuechen Xie, Jie Song, Mengqi Xue, Haofei Zhang, Xingen Wang, Bingde Hu, Genlang Chen, Mingli Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07276">https://arxiv.org/abs/2502.07276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07276">https://arxiv.org/pdf/2502.07276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07276]] Dataset Ownership Verification in Contrastive Pre-trained Models(https://arxiv.org/abs/2502.07276)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>High-quality open-source datasets, which necessitate substantial efforts for curation, has become the primary catalyst for the swift progress of deep learning. Concurrently, protecting these datasets is paramount for the well-being of the data owner. Dataset ownership verification emerges as a crucial method in this domain, but existing approaches are often limited to supervised models and cannot be directly extended to increasingly popular unsupervised pre-trained models. In this work, we propose the first dataset ownership verification method tailored specifically for self-supervised pre-trained models by contrastive learning. Its primary objective is to ascertain whether a suspicious black-box backbone has been pre-trained on a specific unlabeled dataset, aiding dataset owners in upholding their rights. The proposed approach is motivated by our empirical insights that when models are trained with the target dataset, the unary and binary instance relationships within the embedding space exhibit significant variations compared to models trained without the target dataset. We validate the efficacy of this approach across multiple contrastive pre-trained models including SimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that our method rejects the null hypothesis with a $p$-value markedly below $0.05$, surpassing all previous methodologies. Our code is available at this https URL.</li>
</ul>

<h3>Title: Enhancing Video Understanding: Deep Neural Networks for Spatiotemporal Analysis</h3>
<ul>
<li><strong>Authors: </strong>Amir Hosein Fadaei, Mohammad-Reza A. Dehaqani</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07277">https://arxiv.org/abs/2502.07277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07277">https://arxiv.org/pdf/2502.07277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07277]] Enhancing Video Understanding: Deep Neural Networks for Spatiotemporal Analysis(https://arxiv.org/abs/2502.07277)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>It's no secret that video has become the primary way we share information online. That's why there's been a surge in demand for algorithms that can analyze and understand video content. It's a trend going to continue as video continues to dominate the digital landscape. These algorithms will extract and classify related features from the video and will use them to describe the events and objects in the video. Deep neural networks have displayed encouraging outcomes in the realm of feature extraction and video description. This paper will explore the spatiotemporal features found in videos and recent advancements in deep neural networks in video understanding. We will review some of the main trends in video understanding models and their structural design, the main problems, and some offered solutions in this topic. We will also review and compare significant video understanding and action recognition datasets.</li>
</ul>

<h3>Title: Articulate That Object Part (ATOP): 3D Part Articulation from Text and Motion Personalization</h3>
<ul>
<li><strong>Authors: </strong>Aditya Vora, Sauradip Nag, Hao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07278">https://arxiv.org/abs/2502.07278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07278">https://arxiv.org/pdf/2502.07278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07278]] Articulate That Object Part (ATOP): 3D Part Articulation from Text and Motion Personalization(https://arxiv.org/abs/2502.07278)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present ATOP (Articulate That Object Part), a novel method based on motion personalization to articulate a 3D object with respect to a part and its motion as prescribed in a text prompt. Specifically, the text input allows us to tap into the power of modern-day video diffusion to generate plausible motion samples for the right object category and part. In turn, the input 3D object provides image prompting to personalize the generated video to that very object we wish to articulate. Our method starts with a few-shot finetuning for category-specific motion generation, a key first step to compensate for the lack of articulation awareness by current video diffusion models. For this, we finetune a pre-trained multi-view image generation model for controllable multi-view video generation, using a small collection of video samples obtained for the target object category. This is followed by motion video personalization that is realized by multi-view rendered images of the target 3D object. At last, we transfer the personalized video motion to the target 3D object via differentiable rendering to optimize part motion parameters by a score distillation sampling loss. We show that our method is capable of generating realistic motion videos and predict 3D motion parameters in a more accurate and generalizable way, compared to prior works.</li>
</ul>

<h3>Title: Exploratory Diffusion Policy for Unsupervised Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Chengyang Ying, Huayu Chen, Xinning Zhou, Zhongkai Hao, Hang Su, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07279">https://arxiv.org/abs/2502.07279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07279">https://arxiv.org/pdf/2502.07279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07279]] Exploratory Diffusion Policy for Unsupervised Reinforcement Learning(https://arxiv.org/abs/2502.07279)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Unsupervised reinforcement learning (RL) aims to pre-train agents by exploring states or skills in reward-free environments, facilitating the adaptation to downstream tasks. However, existing methods often overlook the fitting ability of pre-trained policies and struggle to handle the heterogeneous pre-training data, which are crucial for achieving efficient exploration and fast fine-tuning. To address this gap, we propose Exploratory Diffusion Policy (EDP), which leverages the strong expressive ability of diffusion models to fit the explored data, both boosting exploration and obtaining an efficient initialization for downstream tasks. Specifically, we estimate the distribution of collected data in the replay buffer with the diffusion policy and propose a score intrinsic reward, encouraging the agent to explore unseen states. For fine-tuning the pre-trained diffusion policy on downstream tasks, we provide both theoretical analyses and practical algorithms, including an alternating method of Q function optimization and diffusion policy distillation. Extensive experiments demonstrate the effectiveness of EDP in efficient exploration during pre-training and fast adaptation during fine-tuning.</li>
</ul>

<h3>Title: MIGT: Memory Instance Gated Transformer Framework for Financial Portfolio Management</h3>
<ul>
<li><strong>Authors: </strong>Fengchen Gu, Angelos Stefanidis, Ãngel GarcÃ­a-FernÃ¡ndez, Jionglong Su, Huakang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07280">https://arxiv.org/abs/2502.07280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07280">https://arxiv.org/pdf/2502.07280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07280]] MIGT: Memory Instance Gated Transformer Framework for Financial Portfolio Management(https://arxiv.org/abs/2502.07280)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep reinforcement learning (DRL) has been applied in financial portfolio management to improve returns in changing market conditions. However, unlike most fields where DRL is widely used, the stock market is more volatile and dynamic as it is affected by several factors such as global events and investor sentiment. Therefore, it remains a challenge to construct a DRL-based portfolio management framework with strong return capability, stable training, and generalization ability. This study introduces a new framework utilizing the Memory Instance Gated Transformer (MIGT) for effective portfolio management. By incorporating a novel Gated Instance Attention module, which combines a transformer variant, instance normalization, and a Lite Gate Unit, our approach aims to maximize investment returns while ensuring the learning process's stability and reducing outlier impacts. Tested on the Dow Jones Industrial Average 30, our framework's performance is evaluated against fifteen other strategies using key financial metrics like the cumulative return and risk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight MIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns and a minimum 2.36% increase in risk-return ratios over competing strategies, marking a significant advancement in DRL for portfolio management.</li>
</ul>

<h3>Title: VLWE: Variety-based Learning with Errors for Vector Encryption through Algebraic Geometry</h3>
<ul>
<li><strong>Authors: </strong>Dongfang Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07284">https://arxiv.org/abs/2502.07284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07284">https://arxiv.org/pdf/2502.07284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07284]] VLWE: Variety-based Learning with Errors for Vector Encryption through Algebraic Geometry(https://arxiv.org/abs/2502.07284)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack</a></li>
<li><strong>Abstract: </strong>Lattice-based cryptography is a foundation for post-quantum security, with the Learning with Errors (LWE) problem as a core component in key exchange, encryption, and homomorphic computation. Structured variants like Ring-LWE (RLWE) and Module-LWE (MLWE) improve efficiency using polynomial rings but remain constrained by traditional polynomial multiplication rules, limiting their ability to handle structured vectorized data. This work introduces Variety-LWE (VLWE), a new structured lattice problem based on algebraic geometry. Unlike RLWE and MLWE, which use polynomial quotient rings with standard multiplication, VLWE operates over multivariate polynomial rings defined by algebraic varieties. A key difference is that these polynomials lack mixed variables, and multiplication is coordinate-wise rather than following standard polynomial multiplication. This enables direct encoding and homomorphic processing of high-dimensional data while preserving worst-case to average-case hardness reductions. We prove VLWE's security by reducing it to multiple independent Ideal-SVP instances, demonstrating resilience against classical and quantum attacks. Additionally, we analyze hybrid algebraic-lattice attacks, showing that existing Grobner basis and lattice reduction methods do not directly threaten VLWE. We further construct a vector homomorphic encryption scheme based on VLWE, supporting structured computations while controlling noise growth. This scheme offers advantages in privacy-preserving machine learning, encrypted search, and secure computations over structured data. VLWE emerges as a novel and independent paradigm in lattice-based cryptography, leveraging algebraic geometry to enable new cryptographic capabilities beyond traditional polynomial quotient rings.</li>
</ul>

<h3>Title: Small Language Model Makes an Effective Long Text Extractor</h3>
<ul>
<li><strong>Authors: </strong>Yelin Chen, Fanjin Zhang, Jie Tang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07286">https://arxiv.org/abs/2502.07286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07286">https://arxiv.org/pdf/2502.07286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07286]] Small Language Model Makes an Effective Long Text Extractor(https://arxiv.org/abs/2502.07286)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Named Entity Recognition (NER) is a fundamental problem in natural language processing (NLP). However, the task of extracting longer entity spans (e.g., awards) from extended texts (e.g., homepages) is barely explored. Current NER methods predominantly fall into two categories: span-based methods and generation-based methods. Span-based methods require the enumeration of all possible token-pair spans, followed by classification on each span, resulting in substantial redundant computations and excessive GPU memory usage. In contrast, generation-based methods involve prompting or fine-tuning large language models (LLMs) to adapt to downstream NER tasks. However, these methods struggle with the accurate generation of longer spans and often incur significant time costs for effective fine-tuning. To address these challenges, this paper introduces a lightweight span-based NER method called SeNER, which incorporates a bidirectional arrow attention mechanism coupled with LogN-Scaling on the [CLS] token to embed long texts effectively, and comprises a novel bidirectional sliding-window plus-shaped attention (BiSPA) mechanism to reduce redundant candidate token-pair spans significantly and model interactions between token-pair spans simultaneously. Extensive experiments demonstrate that our method achieves state-of-the-art extraction accuracy on three long NER datasets and is capable of extracting entities from long texts in a GPU-memory-friendly manner. Code: this https URL</li>
</ul>

<h3>Title: KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level</h3>
<ul>
<li><strong>Authors: </strong>Ruining Deng, Tianyuan Yao, Yucheng Tang, Junlin Guo, Siqi Lu, Juming Xiong, Lining Yu, Quan Huu Cap, Pengzhou Cai, Libin Lan, Ze Zhao, Adrian Galdran, Amit Kumar, Gunjan Deotale, Dev Kumar Das, Inyoung Paik, Joonho Lee, Geongyu Lee, Yujia Chen, Wangkai Li, Zhaoyang Li, Xuege Hou, Zeyuan Wu, Shengjin Wang, Maximilian Fischer, Lars Kramer, Anghong Du, Le Zhang, Maria Sanchez Sanchez, Helena Sanchez Ulloa, David Ribalta Heredia, Carlos Perez de Arenaza Garcia, Shuoyu Xu, Bingdou He, Xinping Cheng, Tao Wang, Noemie Moreau, Katarzyna Bozek, Shubham Innani, Ujjwal Baid, Kaura Solomon Kefas, Bennett A. Landman, Yu Wang, Shilin Zhao, Mengmeng Yin, Haichun Yang, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07288">https://arxiv.org/abs/2502.07288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07288">https://arxiv.org/pdf/2502.07288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07288]] KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level(https://arxiv.org/abs/2502.07288)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Chronic kidney disease (CKD) is a major global health issue, affecting over 10% of the population and causing significant mortality. While kidney biopsy remains the gold standard for CKD diagnosis and treatment, the lack of comprehensive benchmarks for kidney pathology segmentation hinders progress in the field. To address this, we organized the Kidney Pathology Image Segmentation (KPIs) Challenge, introducing a dataset that incorporates preclinical rodent models of CKD with over 10,000 annotated glomeruli from 60+ Periodic Acid Schiff (PAS)-stained whole slide images. The challenge includes two tasks, patch-level segmentation and whole slide image segmentation and detection, evaluated using the Dice Similarity Coefficient (DSC) and F1-score. By encouraging innovative segmentation methods that adapt to diverse CKD models and tissue conditions, the KPIs Challenge aims to advance kidney pathology analysis, establish new benchmarks, and enable precise, large-scale quantification for disease research and diagnosis.</li>
</ul>

<h3>Title: Learning Inverse Laplacian Pyramid for Progressive Depth Completion</h3>
<ul>
<li><strong>Authors: </strong>Kun Wang, Zhiqiang Yan, Junkai Fan, Jun Li, Jian Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07289">https://arxiv.org/abs/2502.07289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07289">https://arxiv.org/pdf/2502.07289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07289]] Learning Inverse Laplacian Pyramid for Progressive Depth Completion(https://arxiv.org/abs/2502.07289)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Depth completion endeavors to reconstruct a dense depth map from sparse depth measurements, leveraging the information provided by a corresponding color image. Existing approaches mostly hinge on single-scale propagation strategies that iteratively ameliorate initial coarse depth estimates through pixel-level message passing. Despite their commendable outcomes, these techniques are frequently hampered by computational inefficiencies and a limited grasp of scene context. To circumvent these challenges, we introduce LP-Net, an innovative framework that implements a multi-scale, progressive prediction paradigm based on Laplacian Pyramid decomposition. Diverging from propagation-based approaches, LP-Net initiates with a rudimentary, low-resolution depth prediction to encapsulate the global scene context, subsequently refining this through successive upsampling and the reinstatement of high-frequency details at incremental scales. We have developed two novel modules to bolster this strategy: 1) the Multi-path Feature Pyramid module, which segregates feature maps into discrete pathways, employing multi-scale transformations to amalgamate comprehensive spatial information, and 2) the Selective Depth Filtering module, which dynamically learns to apply both smoothness and sharpness filters to judiciously mitigate noise while accentuating intricate details. By integrating these advancements, LP-Net not only secures state-of-the-art (SOTA) performance across both outdoor and indoor benchmarks such as KITTI, NYUv2, and TOFDC, but also demonstrates superior computational efficiency. At the time of submission, LP-Net ranks 1st among all peer-reviewed methods on the official KITTI leaderboard.</li>
</ul>

<h3>Title: Treatment Effect Estimation for Exponential Family Outcomes using Neural Networks with Targeted Regularization</h3>
<ul>
<li><strong>Authors: </strong>Jiahong Li, Zeqin Yang, Jiayi Dan, Jixing Xu, Zhichao Zou, Peng Zhen, Jiecheng Guo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07295">https://arxiv.org/abs/2502.07295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07295">https://arxiv.org/pdf/2502.07295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07295]] Treatment Effect Estimation for Exponential Family Outcomes using Neural Networks with Targeted Regularization(https://arxiv.org/abs/2502.07295)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural Networks (NNs) have became a natural choice for treatment effect estimation due to their strong approximation capabilities. Nevertheless, how to design NN-based estimators with desirable properties, such as low bias and doubly robustness, still remains a significant challenge. A common approach to address this is targeted regularization, which modifies the objective function of NNs. However, existing works on targeted regularization are limited to Gaussian-distributed outcomes, significantly restricting their applicability in real-world scenarios. In this work, we aim to bridge this blank by extending this framework to the boarder exponential family outcomes. Specifically, we first derive the von-Mises expansion of the Average Dose function of Canonical Functions (ADCF), which inspires us how to construct a doubly robust estimator with good properties. Based on this, we develop a NN-based estimator for ADCF by generalizing functional targeted regularization to exponential families, and provide the corresponding theoretical convergence rate. Extensive experimental results demonstrate the effectiveness of our proposed model.</li>
</ul>

<h3>Title: Generation of Drug-Induced Cardiac Reactions towards Virtual Clinical Trials</h3>
<ul>
<li><strong>Authors: </strong>Qian Shao, Bang Du, Zepeng Li, Qiyuan Chen, Hongxia Xu, Jimeng Sun, Jian Wu, Jintai Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07297">https://arxiv.org/abs/2502.07297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07297">https://arxiv.org/pdf/2502.07297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07297]] Generation of Drug-Induced Cardiac Reactions towards Virtual Clinical Trials(https://arxiv.org/abs/2502.07297)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Clinical trials are pivotal in cardiac drug development, yet they often fail due to inadequate efficacy and unexpected safety issues, leading to significant financial losses. Using in-silico trials to replace a part of physical clinical trials, e.g., leveraging advanced generative models to generate drug-influenced electrocardiograms (ECGs), seems an effective method to reduce financial risk and potential harm to trial participants. While existing generative models have demonstrated progress in ECG generation, they fall short in modeling drug reactions due to limited fidelity and inability to capture individualized drug response patterns. In this paper, we propose a Drug-Aware Diffusion Model (DADM), which could simulate individualized drug reactions while ensuring fidelity. To ensure fidelity, we construct a set of ordinary differential equations to provide external physical knowledge (EPK) of the realistic ECG morphology. The EPK is used to adaptively constrain the morphology of the generated ECGs through a dynamic cross-attention (DCA) mechanism. Furthermore, we propose an extension of ControlNet to incorporate demographic and drug data, simulating individual drug reactions. We compare DADM with the other eight state-of-the-art ECG generative models on two real-world databases covering 8 types of drug regimens. The results demonstrate that DADM can more accurately simulate drug-induced changes in ECGs, improving the accuracy by at least 5.79% and recall by 8%.</li>
</ul>

<h3>Title: CASC-AI: Consensus-aware Self-corrective AI Agents for Noise Cell Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ruining Deng, Yihe Yang, David J. Pisapia, Benjamin Liechty, Junchao Zhu, Juming Xiong, Junlin Guo, Zhengyi Lu, Jiacheng Wang, Xing Yao, Runxuan Yu, Rendong Zhang, Gaurav Rudravaram, Mengmeng Yin, Pinaki Sarder, Haichun Yang, Yuankai Huo, Mert R. Sabuncu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07302">https://arxiv.org/abs/2502.07302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07302">https://arxiv.org/pdf/2502.07302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07302]] CASC-AI: Consensus-aware Self-corrective AI Agents for Noise Cell Segmentation(https://arxiv.org/abs/2502.07302)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Multi-class cell segmentation in high-resolution gigapixel whole slide images (WSI) is crucial for various clinical applications. However, training such models typically requires labor-intensive, pixel-wise annotations by domain experts. Recent efforts have democratized this process by involving lay annotators without medical expertise. However, conventional non-agent-based approaches struggle to handle annotation noise adaptively, as they lack mechanisms to mitigate false positives (FP) and false negatives (FN) at both the image-feature and pixel levels. In this paper, we propose a consensus-aware self-corrective AI agent that leverages the Consensus Matrix to guide its learning process. The Consensus Matrix defines regions where both the AI and annotators agree on cell and non-cell annotations, which are prioritized with stronger supervision. Conversely, areas of disagreement are adaptively weighted based on their feature similarity to high-confidence agreement regions, with more similar regions receiving greater attention. Additionally, contrastive learning is employed to separate features of noisy regions from those of reliable agreement regions by maximizing their dissimilarity. This paradigm enables the AI to iteratively refine noisy labels, enhancing its robustness. Validated on one real-world lay-annotated cell dataset and two simulated noisy datasets, our method demonstrates improved segmentation performance, effectively correcting FP and FN errors and showcasing its potential for training robust models on noisy datasets. The official implementation and cell annotations are publicly available at this https URL.</li>
</ul>

<h3>Title: TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation</h3>
<ul>
<li><strong>Authors: </strong>Navid Rajabi, Jana Kosecka</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07306">https://arxiv.org/abs/2502.07306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07306">https://arxiv.org/pdf/2502.07306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07306]] TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation(https://arxiv.org/abs/2502.07306)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we propose a modular approach for the Vision-Language Navigation (VLN) task by decomposing the problem into four sub-modules that use state-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs) in a zero-shot setting. Given navigation instruction in natural language, we first prompt LLM to extract the landmarks and the order in which they are visited. Assuming the known model of the environment, we retrieve the top-k locations of the last landmark and generate $k$ path hypotheses from the starting location to the last landmark using the shortest path algorithm on the topological map of the environment. Each path hypothesis is represented by a sequence of panoramas. We then use dynamic programming to compute the alignment score between the sequence of panoramas and the sequence of landmark names, which match scores obtained from VLM. Finally, we compute the nDTW metric between the hypothesis that yields the highest alignment score to evaluate the path fidelity. We demonstrate superior performance compared to other approaches that use joint semantic maps like VLMaps \cite{vlmaps} on the complex R2R-Habitat \cite{r2r} instruction dataset and quantify in detail the effect of visual grounding on navigation performance.</li>
</ul>

<h3>Title: CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction</h3>
<ul>
<li><strong>Authors: </strong>Junlong Li, Daya Guo, Dejian Yang, Runxin Xu, Yu Wu, Junxian He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07316">https://arxiv.org/abs/2502.07316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07316">https://arxiv.org/pdf/2502.07316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07316]] CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction(https://arxiv.org/abs/2502.07316)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning is a fundamental capability of Large Language Models. While prior research predominantly focuses on enhancing narrow skills like math or code generation, improving performance on many other reasoning tasks remains challenging due to sparse and fragmented training data. To address this issue, we propose CodeI/O, a novel approach that systematically condenses diverse reasoning patterns inherently embedded in contextually-grounded codes, through transforming the original code into a code input-output prediction format. By training models to predict inputs/outputs given code and test cases entirely in natural language as Chain-of-Thought (CoT) rationales, we expose them to universal reasoning primitives -- like logic flow planning, state-space searching, decision tree traversal, and modular decomposition -- while decoupling structured reasoning from code-specific syntax and preserving procedural rigor. Experimental results demonstrate CodeI/O leads to consistent improvements across symbolic, scientific, logic, math & numerical, and commonsense reasoning tasks. By matching the existing ground-truth outputs or re-executing the code with predicted inputs, we can verify each prediction and further enhance the CoTs through multi-turn revision, resulting in CodeI/O++ and achieving higher performance. Our data and models are available at this https URL.</li>
</ul>

<h3>Title: Learnable Residual-based Latent Denoising in Semantic Communication</h3>
<ul>
<li><strong>Authors: </strong>Mingkai Xu, Yongpeng Wu, Yuxuan Shi, Xiang-Gen Xia, Wenjun Zhang, Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07319">https://arxiv.org/abs/2502.07319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07319">https://arxiv.org/pdf/2502.07319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07319]] Learnable Residual-based Latent Denoising in Semantic Communication(https://arxiv.org/abs/2502.07319)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A latent denoising semantic communication (SemCom) framework is proposed for robust image transmission over noisy channels. By incorporating a learnable latent denoiser into the receiver, the received signals are preprocessed to effectively remove the channel noise and recover the semantic information, thereby enhancing the quality of the decoded images. Specifically, a latent denoising mapping is established by an iterative residual learning approach to improve the denoising efficiency while ensuring stable performance. Moreover, channel signal-to-noise ratio (SNR) is utilized to estimate and predict the latent similarity score (SS) for conditional denoising, where the number of denoising steps is adapted based on the predicted SS sequence, further reducing the communication latency. Finally, simulations demonstrate that the proposed framework can effectively and efficiently remove the channel noise at various levels and reconstruct visual-appealing images.</li>
</ul>

<h3>Title: MEMIT-Merge: Addressing MEMIT's Key-Value Conflicts in Same-Subject Batch Editing for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zilu Dong, Xiangqing Shen, Rui Xia</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07322">https://arxiv.org/abs/2502.07322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07322">https://arxiv.org/pdf/2502.07322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07322]] MEMIT-Merge: Addressing MEMIT's Key-Value Conflicts in Same-Subject Batch Editing for LLMs(https://arxiv.org/abs/2502.07322)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>As large language models continue to scale up, knowledge editing techniques that modify models' internal knowledge without full retraining have gained significant attention. MEMIT, a prominent batch editing algorithm, stands out for its capability to perform mass knowledge modifications. However, we uncover a critical limitation that MEMIT's editing efficacy significantly deteriorates when processing batches containing multiple edits sharing the same subject. Our analysis reveals that the root cause lies in MEMIT's key value modeling framework: When multiple facts with the same subject in a batch are modeled through MEMIT's key value mechanism, identical keys (derived from the shared subject) are forced to represent different values (corresponding to different knowledge), resulting in updates conflicts during editing. Addressing this issue, we propose MEMIT-Merge, an enhanced approach that merges value computation processes for facts sharing the same subject, effectively resolving the performance degradation in same-subject batch editing scenarios. Experimental results demonstrate that when MEMIT's edit success rate drops to around 50% at larger batch sizes, MEMIT-Merge maintains a success rate exceeding 90%, showcasing remarkable robustness to subject entity collisions.</li>
</ul>

<h3>Title: Semantic to Structure: Learning Structural Representations for Infringement Detection</h3>
<ul>
<li><strong>Authors: </strong>Chuanwei Huang, Zexi Jia, Hongyan Fei, Yeshuang Zhu, Zhiqiang Yuan, Jinchao Zhang, Jie Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07323">https://arxiv.org/abs/2502.07323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07323">https://arxiv.org/pdf/2502.07323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07323]] Semantic to Structure: Learning Structural Representations for Infringement Detection(https://arxiv.org/abs/2502.07323)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Structural information in images is crucial for aesthetic assessment, and it is widely recognized in the artistic field that imitating the structure of other works significantly infringes on creators' rights. The advancement of diffusion models has led to AI-generated content imitating artists' structural creations, yet effective detection methods are still lacking. In this paper, we define this phenomenon as "structural infringement" and propose a corresponding detection method. Additionally, we develop quantitative metrics and create manually annotated datasets for evaluation: the SIA dataset of synthesized data, and the SIR dataset of real data. Due to the current lack of datasets for structural infringement detection, we propose a new data synthesis strategy based on diffusion models and LLM, successfully training a structural infringement detection model. Experimental results show that our method can successfully detect structural infringements and achieve notable improvements on annotated test sets.</li>
</ul>

<h3>Title: Long-term simulation of physical and mechanical behaviors using curriculum-transfer-learning based physics-informed neural networks</h3>
<ul>
<li><strong>Authors: </strong>Yuan Guo, Zhuojia Fu, Jian Min, Shiyu Lin, Xiaoting Liu, Youssef F. Rashed, Xiaoying Zhuang</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07325">https://arxiv.org/abs/2502.07325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07325">https://arxiv.org/pdf/2502.07325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07325]] Long-term simulation of physical and mechanical behaviors using curriculum-transfer-learning based physics-informed neural networks(https://arxiv.org/abs/2502.07325)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes a Curriculum-Transfer-Learning based physics-informed neural network (CTL-PINN) for long-term simulation of physical and mechanical behaviors. The main innovation of CTL-PINN lies in decomposing long-term problems into a sequence of short-term subproblems. Initially, the standard PINN is employed to solve the first sub-problem. As the simulation progresses, subsequent time-domain problems are addressed using a curriculum learning approach that integrates information from previous steps. Furthermore, transfer learning techniques are incorporated, allowing the model to effectively utilize prior training data and solve sequential time domain transfer problems. CTL-PINN combines the strengths of curriculum learning and transfer learning, overcoming the limitations of standard PINNs, such as local optimization issues, and addressing the inaccuracies over extended time domains encountered in CL-PINN and the low computational efficiency of TL-PINN. The efficacy and robustness of CTL-PINN are demonstrated through applications to nonlinear wave propagation, Kirchhoff plate dynamic response, and the hydrodynamic model of the Three Gorges Reservoir Area, showcasing its superior capability in addressing long-term computational challenges.</li>
</ul>

<h3>Title: EMERALD: Evidence Management for Continuous Certification as a Service in the Cloud</h3>
<ul>
<li><strong>Authors: </strong>Christian Banse, BjÃ¶rn Fanta, Juncal Alonso, Cristina Martinez</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07330">https://arxiv.org/abs/2502.07330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07330">https://arxiv.org/pdf/2502.07330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07330]] EMERALD: Evidence Management for Continuous Certification as a Service in the Cloud(https://arxiv.org/abs/2502.07330)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The conspicuous lack of cloud-specific security certifications, in addition to the existing market fragmentation, hinder transparency and accountability in the provision and usage of European cloud services. Both issues ultimately reflect on the level of customers' trustworthiness and adoption of cloud services. The upcoming demand for continuous certification has not yet been definitively addressed and it remains unclear how the level 'high' of the European Cybersecurity Certification Scheme for Cloud Services (EUCS) shall be technologically achieved. The introduction of AI in cloud services is raising the complexity of certification even further. This paper presents the EMERALD Certification-as-a-Service (CaaS) concept for continuous certification of harmonized cybersecurity schemes, like the EUCS. EMERALD CaaS aims to provide agile and lean re-certification to consumers that adhere to a defined level of security and trust in a uniform way across heterogeneous environments consisting of combinations of different resources (Cloud, Edge, IoT). Initial findings suggest that EMERALD will significantly contribute to continuous certification, boosting providers and users of cloud services to maintain regulatory compliance towards the latest and upcoming security schemes.</li>
</ul>

<h3>Title: ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus Segmentation with Prototype Consistency Alignment and Conditional Self-Training</h3>
<ul>
<li><strong>Authors: </strong>Siyue Li, Yongcheng Yao, Junru Zhong, Shutian Zhao, Yudong Zhang, Shuihua Wang, Jin Hong, Weitian Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07331">https://arxiv.org/abs/2502.07331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07331">https://arxiv.org/pdf/2502.07331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07331]] ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus Segmentation with Prototype Consistency Alignment and Conditional Self-Training(https://arxiv.org/abs/2502.07331)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Manual segmentation is labor-intensive, and automatic segmentation remains challenging due to the inherent variability in meniscal morphology, partial volume effects, and low contrast between the meniscus and surrounding tissues. To address these challenges, we propose ERANet, an innovative semi-supervised framework for meniscus segmentation that effectively leverages both labeled and unlabeled images through advanced augmentation and learning strategies. ERANet integrates three key components: edge replacement augmentation (ERA), prototype consistency alignment (PCA), and a conditional self-training (CST) strategy within a mean teacher architecture. ERA introduces anatomically relevant perturbations by simulating meniscal variations, ensuring that augmentations align with the structural context. PCA enhances segmentation performance by aligning intra-class features and promoting compact, discriminative feature representations, particularly in scenarios with limited labeled data. CST improves segmentation robustness by iteratively refining pseudo-labels and mitigating the impact of label noise during training. Together, these innovations establish ERANet as a robust and scalable solution for meniscus segmentation, effectively addressing key barriers to practical implementation. We validated ERANet comprehensively on 3D Double Echo Steady State (DESS) and 3D Fast/Turbo Spin Echo (FSE/TSE) MRI sequences. The results demonstrate the superior performance of ERANet compared to state-of-the-art methods. The proposed framework achieves reliable and accurate segmentation of meniscus structures, even when trained on minimal labeled data. Extensive ablation studies further highlight the synergistic contributions of ERA, PCA, and CST, solidifying ERANet as a transformative solution for semi-supervised meniscus segmentation in medical imaging.</li>
</ul>

<h3>Title: Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering</h3>
<ul>
<li><strong>Authors: </strong>Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Chen Qian, Fanchao Qi, Baobao Chang, Maosong Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07340">https://arxiv.org/abs/2502.07340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07340">https://arxiv.org/pdf/2502.07340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07340]] Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering(https://arxiv.org/abs/2502.07340)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training LLMs on data that contains unfamiliar knowledge during the instruction tuning stage can make LLMs overconfident and encourage hallucinations. To address this challenge, we introduce a novel framework, NOVA, which identifies high-quality data that aligns well with the LLM's learned knowledge to reduce hallucinations. NOVA includes Internal Consistency Probing (ICP) and Semantic Equivalence Identification (SEI) to measure how familiar the LLM is with instruction data. Specifically, ICP evaluates the LLM's understanding of the given instruction by calculating the tailored consistency among multiple self-generated responses. SEI further assesses the familiarity of the LLM with the target response by comparing it to the generated responses, using the proposed semantic clustering and well-designed voting strategy. Finally, we introduce an expert-aligned reward model, considering characteristics beyond just familiarity to enhance data quality. By considering data quality and avoiding unfamiliar data, we can utilize the selected data to effectively align LLMs to follow instructions and hallucinate less. Extensive experiments and analysis show that NOVA significantly reduces hallucinations and allows LLMs to maintain a strong ability to follow instructions.</li>
</ul>

<h3>Title: Integrating Physics and Data-Driven Approaches: An Explainable and Uncertainty-Aware Hybrid Model for Wind Turbine Power Prediction</h3>
<ul>
<li><strong>Authors: </strong>Alfonso GijÃ³n, Simone Eiraudo, Antonio Manjavacas, Daniele Salvatore Schiera, Miguel Molina-Solana, Juan GÃ³mez-Romero</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07344">https://arxiv.org/abs/2502.07344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07344">https://arxiv.org/pdf/2502.07344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07344]] Integrating Physics and Data-Driven Approaches: An Explainable and Uncertainty-Aware Hybrid Model for Wind Turbine Power Prediction(https://arxiv.org/abs/2502.07344)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The rapid growth of the wind energy sector underscores the urgent need to optimize turbine operations and ensure effective maintenance through early fault detection systems. While traditional empirical and physics-based models offer approximate predictions of power generation based on wind speed, they often fail to capture the complex, non-linear relationships between other input variables and the resulting power output. Data-driven machine learning methods present a promising avenue for improving wind turbine modeling by leveraging large datasets, enhancing prediction accuracy but often at the cost of interpretability. In this study, we propose a hybrid semi-parametric model that combines the strengths of both approaches, applied to a dataset from a wind farm with four turbines. The model integrates a physics-inspired submodel, providing a reasonable approximation of power generation, with a non-parametric submodel that predicts the residuals. This non-parametric submodel is trained on a broader range of variables to account for phenomena not captured by the physics-based component. The hybrid model achieves a 37% improvement in prediction accuracy over the physics-based model. To enhance interpretability, SHAP values are used to analyze the influence of input features on the residual submodel's output. Additionally, prediction uncertainties are quantified using a conformalized quantile regression method. The combination of these techniques, alongside the physics grounding of the parametric submodel, provides a flexible, accurate, and reliable framework. Ultimately, this study opens the door for evaluating the impact of unmodeled variables on wind turbine power generation, offering a basis for potential optimization.</li>
</ul>

<h3>Title: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xu Huang, Wenhao Zhu, Hanxu Hu, Conghui He, Lei Li, Shujian Huang, Fei Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07346">https://arxiv.org/abs/2502.07346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07346">https://arxiv.org/pdf/2502.07346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07346]] BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models(https://arxiv.org/abs/2502.07346)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Previous multilingual benchmarks focus primarily on simple understanding tasks, but for large language models(LLMs), we emphasize proficiency in instruction following, reasoning, long context understanding, code generation, and so on. However, measuring these advanced capabilities across languages is underexplored. To address the disparity, we introduce BenchMAX, a multi-way multilingual evaluation benchmark that allows for fair comparisons of these important abilities across languages. To maintain high quality, three distinct native-speaking annotators independently annotate each sample within all tasks after the data was machine-translated from English into 16 other languages. Additionally, we present a novel translation challenge stemming from dataset construction. Extensive experiments on BenchMAX reveal varying effectiveness of core capabilities across languages, highlighting performance gaps that cannot be bridged by simply scaling up model size. BenchMAX serves as a comprehensive multilingual evaluation platform, providing a promising test bed to promote the development of multilingual language models. The dataset and code are publicly accessible.</li>
</ul>

<h3>Title: Multi-Task-oriented Nighttime Haze Imaging Enhancer for Vision-driven Measurement Systems</h3>
<ul>
<li><strong>Authors: </strong>Ai Chen, Yuxu Lu, Dong Yang, Junlin Zhou, Yan Fu, Duanbing Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07351">https://arxiv.org/abs/2502.07351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07351">https://arxiv.org/pdf/2502.07351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07351]] Multi-Task-oriented Nighttime Haze Imaging Enhancer for Vision-driven Measurement Systems(https://arxiv.org/abs/2502.07351)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Salient object detection (SOD) plays a critical role in vision-driven measurement systems (VMS), facilitating the detection and segmentation of key visual elements in an image. However, adverse imaging conditions such as haze during the day, low light, and haze at night severely degrade image quality, and complicating the SOD process. To address these challenges, we propose a multi-task-oriented nighttime haze imaging enhancer (MToIE), which integrates three tasks: daytime dehazing, low-light enhancement, and nighttime dehazing. The MToIE incorporates two key innovative components: First, the network employs a task-oriented node learning mechanism to handle three specific degradation types: day-time haze, low light, and night-time haze conditions, with an embedded self-attention module enhancing its performance in nighttime imaging. In addition, multi-receptive field enhancement module that efficiently extracts multi-scale features through three parallel depthwise separable convolution branches with different dilation rates, capturing comprehensive spatial information with minimal computational overhead. To ensure optimal image reconstruction quality and visual characteristics, we suggest a hybrid loss function. Extensive experiments on different types of weather/imaging conditions illustrate that MToIE surpasses existing methods, significantly enhancing the accuracy and reliability of vision systems across diverse imaging scenarios. The code is available at this https URL.</li>
</ul>

<h3>Title: Bridging the Evaluation Gap: Leveraging Large Language Models for Topic Model Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Zhiyin Tan, Jennifer D'Souza</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07352">https://arxiv.org/abs/2502.07352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07352">https://arxiv.org/pdf/2502.07352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07352]] Bridging the Evaluation Gap: Leveraging Large Language Models for Topic Model Evaluation(https://arxiv.org/abs/2502.07352)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This study presents a framework for automated evaluation of dynamically evolving topic taxonomies in scientific literature using Large Language Models (LLMs). In digital library systems, topic modeling plays a crucial role in efficiently organizing and retrieving scholarly content, guiding researchers through complex knowledge landscapes. As research domains proliferate and shift, traditional human centric and static evaluation methods struggle to maintain relevance. The proposed approach harnesses LLMs to measure key quality dimensions, such as coherence, repetitiveness, diversity, and topic-document alignment, without heavy reliance on expert annotators or narrow statistical metrics. Tailored prompts guide LLM assessments, ensuring consistent and interpretable evaluations across various datasets and modeling techniques. Experiments on benchmark corpora demonstrate the method's robustness, scalability, and adaptability, underscoring its value as a more holistic and dynamic alternative to conventional evaluation strategies.</li>
</ul>

<h3>Title: LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation</h3>
<ul>
<li><strong>Authors: </strong>Zican Dong, Junyi Li, Jinhao Jiang, Mingyu Xu, Wayne Xin Zhao, Bingning Wang, Weipeng Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07365">https://arxiv.org/abs/2502.07365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07365">https://arxiv.org/pdf/2502.07365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07365]] LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation(https://arxiv.org/abs/2502.07365)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have gained extended context windows through scaling positional encodings and lightweight continual pre-training. However, this often leads to degraded performance on short-text tasks, while the reasons for this degradation remain insufficiently explored. In this work, we identify two primary factors contributing to this issue: distribution drift in hidden states and attention scores, and catastrophic forgetting during continual pre-training. To address these challenges, we propose Long Context Pre-training with Restoration Distillation (LongReD), a novel approach designed to mitigate short-text performance degradation through minimizing the distribution discrepancy between the extended and original models. Besides training on long texts, LongReD distills the hidden state of selected layers from the original model on short texts. Additionally, LongReD also introduces a short-to-long distillation, aligning the output distribution on short texts with that on long texts by leveraging skipped positional indices. Experiments on common text benchmarks demonstrate that LongReD effectively preserves the model's short-text performance while maintaining comparable or even better capacity to handle long texts than baselines.</li>
</ul>

<h3>Title: USRNet: Unified Scene Recovery Network for Enhancing Traffic Imaging under Multiple Adverse Weather Conditions</h3>
<ul>
<li><strong>Authors: </strong>Yuxu Lu, Ai Chen, Dong Yang, Ryan Wen Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07372">https://arxiv.org/abs/2502.07372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07372">https://arxiv.org/pdf/2502.07372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07372]] USRNet: Unified Scene Recovery Network for Enhancing Traffic Imaging under Multiple Adverse Weather Conditions(https://arxiv.org/abs/2502.07372)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Advancements in computer vision technology have facilitated the extensive deployment of intelligent transportation systems and visual surveillance systems across various applications, including autonomous driving, public safety, and environmental monitoring. However, adverse weather conditions such as haze, rain, snow, and more complex mixed degradation can significantly degrade image quality. The degradation compromises the accuracy and reliability of these systems across various scenarios. To tackle the challenge of developing adaptable models for scene restoration, we introduce the unified scene recovery network (USRNet), capable of handling multiple types of image degradation. The USRNet features a sophisticated architecture consisting of a scene encoder, an attention-driven node independent learning mechanism (NILM), an edge decoder, and a scene restoration module. The scene encoder, powered by advanced residual blocks, extracts deep features from degraded images in a progressive manner, ensuring thorough encoding of degradation information. To enhance the USRNet's adaptability in diverse weather conditions, we introduce NILM, which enables the network to learn and respond to different scenarios with precision, thereby increasing its robustness. The edge decoder is designed to extract edge features with precision, which is essential for maintaining image sharpness. Experimental results demonstrate that USRNet surpasses existing methods in handling complex imaging degradations, thereby improving the accuracy and reliability of visual systems across diverse scenarios. The code resources for this work can be accessed in this https URL.</li>
</ul>

<h3>Title: EvoFlow: Evolving Diverse Agentic Workflows On The Fly</h3>
<ul>
<li><strong>Authors: </strong>Guibin Zhang, Kaijie Chen, Guancheng Wan, Heng Chang, Hong Cheng, Kun Wang, Shuyue Hu, Lei Bai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.MA, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07373">https://arxiv.org/abs/2502.07373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07373">https://arxiv.org/pdf/2502.07373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07373]] EvoFlow: Evolving Diverse Agentic Workflows On The Fly(https://arxiv.org/abs/2502.07373)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The past two years have witnessed the evolution of large language model (LLM)-based multi-agent systems from labor-intensive manual design to partial automation (\textit{e.g.}, prompt engineering, communication topology) and eventually to fully automated design. However, existing agentic automation pipelines often lack LLM heterogeneity and focus on single-objective performance optimization, limiting their potential to combine weaker models for more customized and cost-effective solutions. To address this challenge, we propose EvoFlow, a niching evolutionary algorithm-based framework to automatically search a population of heterogeneous and complexity-adaptive agentic workflows, rather than a single homogeneous, complex workflow. Technically, EvoFlow performs \textit{(1) tag-based retrieval} to extract parent workflows from an agentic population, evolves new workflows through \textit{(2) crossover} and \textit{(3) mutation}, and employs \textit{(4) niching-based selection} to maintain population diversity and quality. Extensive evaluations across seven benchmarks demonstrate that EvoFlow is: \textbf{(I) diverse}, evolving a population of workflows ranging from simple I/O tasks to complex multi-turn interactions; \textbf{(II) high-performing}, outperforming previous handcrafted and automated workflows by $1.23\%\sim29.86\%$; \textbf{(III) economical}, surpassing powerful \llmname{o1-preview} at $12.4\%$ of its inference cost using weaker open-source models.</li>
</ul>

<h3>Title: Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Hongyu An, Xinfeng Zhang, Shijie Zhao, Li Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07381">https://arxiv.org/abs/2502.07381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07381">https://arxiv.org/pdf/2502.07381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07381]] Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution(https://arxiv.org/abs/2502.07381)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Due to limitations of storage and bandwidth, videos stored and transmitted on the Internet are usually low-quality with low-resolution and compression noise. Although video super-resolution (VSR) is an efficient technique to enhance video resolution, relatively VSR methods focus on compressed videos. Directly applying general VSR approaches leads to the failure of improving practical videos, especially when frames are highly compressed at a low bit rate. Recently, diffusion models have achieved superior performance in low-level visual tasks, and their high-realism generation capability enables them to be applied in VSR. To synthesize more compression-lost details and refine temporal consistency, we propose a novel Spatial Degradation-Aware and Temporal Consistent (SDATC) diffusion model for compressed VSR. Specifically, we introduce a distortion Control module (DCM) to modulate diffusion model inputs and guide the generation. Next, the diffusion model executes the denoising process for texture generation with fine-tuned spatial prompt-based compression-aware module (PCAM) and spatio-temporal attention module (STAM). PCAM extracts features to encode specific compression information dynamically. STAM extends the spatial attention mechanism to a spatio-temporal dimension for capturing temporal correlation. Extensive experimental results on benchmark datasets demonstrate the effectiveness of the proposed modules in enhancing compressed videos.</li>
</ul>

<h3>Title: Interpretable Rules for Online Failure Prediction: A Case Study on the Metro do Porto dataset</h3>
<ul>
<li><strong>Authors: </strong>Matthias Jakobs, Bruno Veloso, Joao Gama</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07394">https://arxiv.org/abs/2502.07394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07394">https://arxiv.org/pdf/2502.07394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07394]] Interpretable Rules for Online Failure Prediction: A Case Study on the Metro do Porto dataset(https://arxiv.org/abs/2502.07394)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, explainability</a></li>
<li><strong>Abstract: </strong>Due to their high predictive performance, predictive maintenance applications have increasingly been approached with Deep Learning techniques in recent years. However, as in other real-world application scenarios, the need for explainability is often stated but not sufficiently addressed. This study will focus on predicting failures on Metro trains in Porto, Portugal. While recent works have found high-performing deep neural network architectures that feature a parallel explainability pipeline, the generated explanations are fairly complicated and need help explaining why the failures are happening. This work proposes a simple online rule-based explainability approach with interpretable features that leads to straightforward, interpretable rules. We showcase our approach on MetroPT2 and find that three specific sensors on the Metro do Porto trains suffice to predict the failures present in the dataset with simple rules.</li>
</ul>

<h3>Title: No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips</h3>
<ul>
<li><strong>Authors: </strong>Ido Galil, Moshe Kimhi, Ran El-Yaniv</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07408">https://arxiv.org/abs/2502.07408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07408">https://arxiv.org/pdf/2502.07408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07408]] No Data, No Optimization: A Lightweight Method To Disrupt Neural Networks With Sign-Flips(https://arxiv.org/abs/2502.07408)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, data-free</a></li>
<li><strong>Abstract: </strong>Deep Neural Networks (DNNs) can be catastrophically disrupted by flipping only a handful of sign bits in their parameters. We introduce Deep Neural Lesion (DNL), a data-free, lightweight method that locates these critical parameters and triggers massive accuracy drops. We validate its efficacy on a wide variety of computer vision models and datasets. The method requires no training data or optimization and can be carried out via common exploits software, firmware or hardware based attack vectors. An enhanced variant that uses a single forward and backward pass further amplifies the damage beyond DNL's zero-pass approach. Flipping just two sign bits in ResNet50 on ImageNet reduces accuracy by 99.8\%. We also show that selectively protecting a small fraction of vulnerable sign bits provides a practical defense against such attacks.</li>
</ul>

<h3>Title: MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification</h3>
<ul>
<li><strong>Authors: </strong>Anh-Tien Nguyen, Duy Minh Ho Nguyen, Nghiem Tuong Diep, Trung Quoc Nguyen, Nhat Ho, Jacqueline Michelle Metsch, Miriam Cindy Maurer, Daniel Sonntag, Hanibal Bohnenberger, Anne-Christin Hauschild</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07409">https://arxiv.org/abs/2502.07409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07409">https://arxiv.org/pdf/2502.07409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07409]] MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification(https://arxiv.org/abs/2502.07409)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust</a></li>
<li><strong>Abstract: </strong>Whole slide pathology image classification presents challenges due to gigapixel image sizes and limited annotation labels, hindering model generalization. This paper introduces a prompt learning method to adapt large vision-language models for few-shot pathology classification. We first extend the Prov-GigaPath vision foundation model, pre-trained on 1.3 billion pathology image tiles, into a vision-language model by adding adaptors and aligning it with medical text encoders via contrastive learning on 923K image-text pairs. The model is then used to extract visual features and text embeddings from few-shot annotations and fine-tunes with learnable prompt embeddings. Unlike prior methods that combine prompts with frozen features using prefix embeddings or self-attention, we propose multi-granular attention that compares interactions between learnable prompts with individual image patches and groups of them. This approach improves the model's ability to capture both fine-grained details and broader context, enhancing its recognition of complex patterns across sub-regions. To further improve accuracy, we leverage (unbalanced) optimal transport-based visual-text distance to secure model robustness by mitigating perturbations that might occur during the data augmentation process. Empirical experiments on lung, kidney, and breast pathology modalities validate the effectiveness of our approach; thereby, we surpass several of the latest competitors and consistently improve performance across diverse architectures, including CLIP, PLIP, and Prov-GigaPath integrated PLIP. We release our implementations and pre-trained models at this MGPATH.</li>
</ul>

<h3>Title: Mining Power Destruction Attacks in the Presence of Petty-Compliant Mining Pools</h3>
<ul>
<li><strong>Authors: </strong>Roozbeh Sarenche, Svetla Nikova, Bart Preneel</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07410">https://arxiv.org/abs/2502.07410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07410">https://arxiv.org/pdf/2502.07410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07410]] Mining Power Destruction Attacks in the Presence of Petty-Compliant Mining Pools(https://arxiv.org/abs/2502.07410)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Bitcoin's security relies on its Proof-of-Work consensus, where miners solve puzzles to propose blocks. The puzzle's difficulty is set by the difficulty adjustment mechanism (DAM), based on the network's available mining power. Attacks that destroy some portion of mining power can exploit the DAM to lower difficulty, making such attacks profitable. In this paper, we analyze three types of mining power destruction attacks in the presence of petty-compliant mining pools: selfish mining, bribery, and mining power distraction attacks. We analyze selfish mining while accounting for the distribution of mining power among pools, a factor often overlooked in the literature. Our findings indicate that selfish mining can be more destructive when the non-adversarial mining share is well distributed among pools. We also introduce a novel bribery attack, where the adversarial pool bribes petty-compliant pools to orphan others' blocks. For small pools, we demonstrate that the bribery attack can dominate strategies like selfish mining or undercutting. Lastly, we present the mining distraction attack, where the adversarial pool incentivizes petty-compliant pools to abandon Bitcoin's puzzle and mine for a simpler puzzle, thus wasting some part of their mining power. Similar to the previous attacks, this attack can lower the mining difficulty, but with the difference that it does not generate any evidence of mining power destruction, such as orphan blocks.</li>
</ul>

<h3>Title: EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Sheng Zhou, Junbin Xiao, Qingyun Li, Yicong Li, Xun Yang, Dan Guo, Meng Wang, Tat-Seng Chua, Angela Yao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07411">https://arxiv.org/abs/2502.07411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07411">https://arxiv.org/pdf/2502.07411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07411]] EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering(https://arxiv.org/abs/2502.07411)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce EgoTextVQA, a novel and rigorously constructed benchmark for egocentric QA assistance involving scene text. EgoTextVQA contains 1.5K ego-view videos and 7K scene-text aware questions that reflect real-user needs in outdoor driving and indoor house-keeping activities. The questions are designed to elicit identification and reasoning on scene text in an egocentric and dynamic environment. With EgoTextVQA, we comprehensively evaluate 10 prominent multimodal large language models. Currently, all models struggle, and the best results (Gemini 1.5 Pro) are around 33% accuracy, highlighting the severe deficiency of these techniques in egocentric QA assistance. Our further investigations suggest that precise temporal grounding and multi-frame reasoning, along with high resolution and auxiliary scene-text inputs, are key for better performance. With thorough analyses and heuristic suggestions, we hope EgoTextVQA can serve as a solid testbed for research in egocentric scene-text QA assistance.</li>
</ul>

<h3>Title: Fast-COS: A Fast One-Stage Object Detector Based on Reparameterized Attention Vision Transformer for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Novendra Setyawan, Ghufron Wahyu Kurniawan, Chi-Chia Sun, Wen-Kai Kuo, Jun-Wei Hsieh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07417">https://arxiv.org/abs/2502.07417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07417">https://arxiv.org/pdf/2502.07417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07417]] Fast-COS: A Fast One-Stage Object Detector Based on Reparameterized Attention Vision Transformer for Autonomous Driving(https://arxiv.org/abs/2502.07417)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>The perception system is a a critical role of an autonomous driving system for ensuring safety. The driving scene perception system fundamentally represents an object detection task that requires achieving a balance between accuracy and processing speed. Many contemporary methods focus on improving detection accuracy but often overlook the importance of real-time detection capabilities when computational resources are limited. Thus, it is vital to investigate efficient object detection strategies for driving scenes. This paper introduces Fast-COS, a novel single-stage object detection framework crafted specifically for driving scene applications. The research initiates with an analysis of the backbone, considering both macro and micro architectural designs, yielding the Reparameterized Attention Vision Transformer (RAViT). RAViT utilizes Reparameterized Multi-Scale Depth-Wise Convolution (RepMSDW) and Reparameterized Self-Attention (RepSA) to enhance computational efficiency and feature extraction. In extensive tests across GPU, edge, and mobile platforms, RAViT achieves 81.4% Top-1 accuracy on the ImageNet-1K dataset, demonstrating significant throughput improvements over comparable backbone models such as ResNet, FastViT, RepViT, and EfficientFormer. Additionally, integrating RepMSDW into a feature pyramid network forms RepFPN, enabling fast and multi-scale feature fusion. Fast-COS enhances object detection in driving scenes, attaining an AP50 score of 57.2% on the BDD100K dataset and 80.0% on the TJU-DHD Traffic dataset. It surpasses leading models in efficiency, delivering up to 75.9% faster GPU inference and 1.38 higher throughput on edge devices compared to FCOS, YOLOF, and RetinaNet. These findings establish Fast-COS as a highly scalable and reliable solution suitable for real-time applications, especially in resource-limited environments like autonomous driving systems</li>
</ul>

<h3>Title: Entity Linking using LLMs for Automated Product Carbon Footprint Estimation</h3>
<ul>
<li><strong>Authors: </strong>Steffen Castle, Julian Moreno Schneider, Leonhard Hennig, Georg Rehm</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07418">https://arxiv.org/abs/2502.07418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07418">https://arxiv.org/pdf/2502.07418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07418]] Entity Linking using LLMs for Automated Product Carbon Footprint Estimation(https://arxiv.org/abs/2502.07418)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Growing concerns about climate change and sustainability are driving manufacturers to take significant steps toward reducing their carbon footprints. For these manufacturers, a first step towards this goal is to identify the environmental impact of the individual components of their products. We propose a system leveraging large language models (LLMs) to automatically map components from manufacturer Bills of Materials (BOMs) to Life Cycle Assessment (LCA) database entries by using LLMs to expand on available component information. Our approach reduces the need for manual data processing, paving the way for more accessible sustainability practices.</li>
</ul>

<h3>Title: MoENAS: Mixture-of-Expert based Neural Architecture Search for jointly Accurate, Fair, and Robust Edge Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Lotfi Abdelkrim Mecharbat, Alberto Marchisio, Muhammad Shafique, Mohammad M. Ghassemi, Tuka Alhanai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07422">https://arxiv.org/abs/2502.07422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07422">https://arxiv.org/pdf/2502.07422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07422]] MoENAS: Mixture-of-Expert based Neural Architecture Search for jointly Accurate, Fair, and Robust Edge Deep Neural Networks(https://arxiv.org/abs/2502.07422)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>There has been a surge in optimizing edge Deep Neural Networks (DNNs) for accuracy and efficiency using traditional optimization techniques such as pruning, and more recently, employing automatic design methodologies. However, the focus of these design techniques has often overlooked critical metrics such as fairness, robustness, and generalization. As a result, when evaluating SOTA edge DNNs' performance in image classification using the FACET dataset, we found that they exhibit significant accuracy disparities (14.09%) across 10 different skin tones, alongside issues of non-robustness and poor generalizability. In response to these observations, we introduce Mixture-of-Experts-based Neural Architecture Search (MoENAS), an automatic design technique that navigates through a space of mixture of experts to discover accurate, fair, robust, and general edge DNNs. MoENAS improves the accuracy by 4.02% compared to SOTA edge DNNs and reduces the skin tone accuracy disparities from 14.09% to 5.60%, while enhancing robustness by 3.80% and minimizing overfitting to 0.21%, all while keeping model size close to state-of-the-art models average size (+0.4M). With these improvements, MoENAS establishes a new benchmark for edge DNN design, paving the way for the development of more inclusive and robust edge DNNs.</li>
</ul>

<h3>Title: RomanLens: Latent Romanization and its role in Multilinguality in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Alan Saji (1), Jaavid Aktar Husain (2), Thanmay Jayakumar (1 and 3), Raj Dabre (1, 3, 4 and 5), Anoop Kunchukuttan (1, 3 and 6), Mitesh M. Khapra (1 and 3), Ratish Puduppully (7) ((1) Nilekani Centre at AI4Bharat, (2) Singapore University of Technology and Design, (3) Indian Institute of Technology Madras, India, (4) National Institute of Information and Communications Technology, Kyoto, Japan, (5) Indian Institute of Technology Bombay, India, (6) Microsoft, India, (7) IT University of Copenhagen)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07424">https://arxiv.org/abs/2502.07424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07424">https://arxiv.org/pdf/2502.07424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07424]] RomanLens: Latent Romanization and its role in Multilinguality in LLMs(https://arxiv.org/abs/2502.07424)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) exhibit remarkable multilingual generalization despite being predominantly trained on English-centric corpora. A fundamental question arises: how do LLMs achieve such robust multilingual capabilities? For non-Latin script languages, we investigate the role of romanization - the representation of non-Latin scripts using Latin characters - as a bridge in multilingual processing. Using mechanistic interpretability techniques, we analyze next-token generation and find that intermediate layers frequently represent target words in romanized form before transitioning to native script, a phenomenon we term Latent Romanization. Further, through activation patching experiments, we demonstrate that LLMs encode semantic concepts similarly across native and romanized scripts, suggesting a shared underlying representation. Additionally in translation towards non Latin languages, our findings reveal that when the target language is in romanized form, its representations emerge earlier in the model's layers compared to native script. These insights contribute to a deeper understanding of multilingual representation in LLMs and highlight the implicit role of romanization in facilitating language transfer. Our work provides new directions for potentially improving multilingual language modeling and interpretability.</li>
</ul>

<h3>Title: ArthroPhase: A Novel Dataset and Method for Phase Recognition in Arthroscopic Video</h3>
<ul>
<li><strong>Authors: </strong>Ali Bahari Malayeri, Matthias Seibold, Nicola Cavalcanti, Jonas Hein, Sascha Jecklin, Lazaros Vlachopoulos, Sandro Fucentese, Sandro Hodel, Philipp Furnstahl</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07431">https://arxiv.org/abs/2502.07431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07431">https://arxiv.org/pdf/2502.07431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07431]] ArthroPhase: A Novel Dataset and Method for Phase Recognition in Arthroscopic Video(https://arxiv.org/abs/2502.07431)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>This study aims to advance surgical phase recognition in arthroscopic procedures, specifically Anterior Cruciate Ligament (ACL) reconstruction, by introducing the first arthroscopy dataset and developing a novel transformer-based model. We aim to establish a benchmark for arthroscopic surgical phase recognition by leveraging spatio-temporal features to address the specific challenges of arthroscopic videos including limited field of view, occlusions, and visual distortions. We developed the ACL27 dataset, comprising 27 videos of ACL surgeries, each labeled with surgical phases. Our model employs a transformer-based architecture, utilizing temporal-aware frame-wise feature extraction through a ResNet-50 and transformer layers. This approach integrates spatio-temporal features and introduces a Surgical Progress Index (SPI) to quantify surgery progression. The model's performance was evaluated using accuracy, precision, recall, and Jaccard Index on the ACL27 and Cholec80 datasets. The proposed model achieved an overall accuracy of 72.91% on the ACL27 dataset. On the Cholec80 dataset, the model achieved a comparable performance with the state-of-the-art methods with an accuracy of 92.4%. The SPI demonstrated an output error of 10.6% and 9.86% on ACL27 and Cholec80 datasets respectively, indicating reliable surgery progression estimation. This study introduces a significant advancement in surgical phase recognition for arthroscopy, providing a comprehensive dataset and a robust transformer-based model. The results validate the model's effectiveness and generalizability, highlighting its potential to improve surgical training, real-time assistance, and operational efficiency in orthopedic surgery. The publicly available dataset and code will facilitate future research and development in this critical field.</li>
</ul>

<h3>Title: Optimizing Knowledge Distillation in Transformers: Enabling Multi-Head Attention without Alignment Barriers</h3>
<ul>
<li><strong>Authors: </strong>Zhaodong Bing, Linze Li, Jiajun Liang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07436">https://arxiv.org/abs/2502.07436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07436">https://arxiv.org/pdf/2502.07436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07436]] Optimizing Knowledge Distillation in Transformers: Enabling Multi-Head Attention without Alignment Barriers(https://arxiv.org/abs/2502.07436)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Knowledge distillation (KD) in transformers often faces challenges due to misalignment in the number of attention heads between teacher and student models. Existing methods either require identical head counts or introduce projectors to bridge dimensional gaps, limiting flexibility and efficiency. We propose Squeezing-Heads Distillation (SHD), a novel approach that enables seamless knowledge transfer between models with varying head counts by compressing multi-head attention maps via efficient linear approximation. Unlike prior work, SHD eliminates alignment barriers without additional parameters or architectural modifications. Our method dynamically approximates the combined effect of multiple teacher heads into fewer student heads, preserving fine-grained attention patterns while reducing redundancy. Experiments across language (LLaMA, GPT) and vision (DiT, MDT) generative and vision (DeiT) discriminative tasks demonstrate SHD's effectiveness: it outperforms logit-based and feature-alignment KD baselines, achieving state-of-the-art results in image classification, image generation language fine-tuning, and language pre-training. The key innovations of flexible head compression, projector-free design, and linear-time complexity make SHD a versatile and scalable solution for distilling modern transformers. This work bridges a critical gap in KD, enabling efficient deployment of compact models without compromising performance.</li>
</ul>

<h3>Title: Forget What You Know about LLMs Evaluations - LLMs are Like a Chameleon</h3>
<ul>
<li><strong>Authors: </strong>Nurit Cohen-Inger, Yehonatan Elisha, Bracha Shapira, Lior Rokach, Seffi Cohen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07445">https://arxiv.org/abs/2502.07445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07445">https://arxiv.org/pdf/2502.07445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07445]] Forget What You Know about LLMs Evaluations - LLMs are Like a Chameleon(https://arxiv.org/abs/2502.07445)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often appear to excel on public benchmarks, but these high scores may mask an overreliance on dataset-specific surface cues rather than true language understanding. We introduce the Chameleon Benchmark Overfit Detector (C-BOD), a meta-evaluation framework that systematically distorts benchmark prompts via a parametric transformation and detects overfitting of LLMs. By rephrasing inputs while preserving their semantic content and labels, C-BOD exposes whether a model's performance is driven by memorized patterns. Evaluated on the MMLU benchmark using 26 leading LLMs, our method reveals an average performance degradation of 2.15% under modest perturbations, with 20 out of 26 models exhibiting statistically significant differences. Notably, models with higher baseline accuracy exhibit larger performance differences under perturbation, and larger LLMs tend to be more sensitive to rephrasings indicating that both cases may overrely on fixed prompt patterns. In contrast, the Llama family and models with lower baseline accuracy show insignificant degradation, suggesting reduced dependency on superficial cues. Moreover, C-BOD's dataset- and model-agnostic design allows easy integration into training pipelines to promote more robust language understanding. Our findings challenge the community to look beyond leaderboard scores and prioritize resilience and generalization in LLM evaluation.</li>
</ul>

<h3>Title: RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Viacheslav Vasilev, Julia Agafonova, Nikolai Gerasimenko, Alexander Kapitanov, Polina Mikhailova, Evelina Mironova, Denis Dimitrov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07455">https://arxiv.org/abs/2502.07455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07455">https://arxiv.org/pdf/2502.07455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07455]] RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation(https://arxiv.org/abs/2502.07455)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Text-to-image generation models have gained popularity among users around the world. However, many of these models exhibit a strong bias toward English-speaking cultures, ignoring or misrepresenting the unique characteristics of other language groups, countries, and nationalities. The lack of cultural awareness can reduce the generation quality and lead to undesirable consequences such as unintentional insult, and the spread of prejudice. In contrast to the field of natural language processing, cultural awareness in computer vision has not been explored as extensively. In this paper, we strive to reduce this gap. We propose a RusCode benchmark for evaluating the quality of text-to-image generation containing elements of the Russian cultural code. To do this, we form a list of 19 categories that best represent the features of Russian visual culture. Our final dataset consists of 1250 text prompts in Russian and their translations into English. The prompts cover a wide range of topics, including complex concepts from art, popular culture, folk traditions, famous people's names, natural objects, scientific achievements, etc. We present the results of a human evaluation of the side-by-side comparison of Russian visual concepts representations using popular generative models.</li>
</ul>

<h3>Title: FedAPA: Server-side Gradient-Based Adaptive Personalized Aggregation for Federated Learning on Heterogeneous Data</h3>
<ul>
<li><strong>Authors: </strong>Yuxia Sun, Aoxiang Sun, Siyi Pan, Zhixiao Fu, Jingcai Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07456">https://arxiv.org/abs/2502.07456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07456">https://arxiv.org/pdf/2502.07456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07456]] FedAPA: Server-side Gradient-Based Adaptive Personalized Aggregation for Federated Learning on Heterogeneous Data(https://arxiv.org/abs/2502.07456)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Personalized federated learning (PFL) tailors models to clients' unique data distributions while preserving privacy. However, existing aggregation-weight-based PFL methods often struggle with heterogeneous data, facing challenges in accuracy, computational efficiency, and communication overhead. We propose FedAPA, a novel PFL method featuring a server-side, gradient-based adaptive aggregation strategy to generate personalized models, by updating aggregation weights based on gradients of client-parameter changes with respect to the aggregation weights in a centralized manner. FedAPA guarantees theoretical convergence and achieves superior accuracy and computational efficiency compared to 10 PFL competitors across three datasets, with competitive communication overhead.</li>
</ul>

<h3>Title: Bidirectional Uncertainty-Aware Region Learning for Semi-Supervised Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shiwei Zhou, Haifeng Zhao, Dengdi Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07457">https://arxiv.org/abs/2502.07457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07457">https://arxiv.org/pdf/2502.07457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07457]] Bidirectional Uncertainty-Aware Region Learning for Semi-Supervised Medical Image Segmentation(https://arxiv.org/abs/2502.07457)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In semi-supervised medical image segmentation, the poor quality of unlabeled data and the uncertainty in the model's predictions lead to models that inevitably produce erroneous pseudo-labels. These errors accumulate throughout model training, thereby weakening the model's performance. We found that these erroneous pseudo-labels are typically concentrated in high-uncertainty regions. Traditional methods improve performance by directly discarding pseudo-labels in these regions, but this can also result in neglecting potentially valuable training data. To alleviate this problem, we propose a bidirectional uncertainty-aware region learning strategy. In training labeled data, we focus on high-uncertainty regions, using precise label information to guide the model's learning in potentially uncontrollable areas. Meanwhile, in the training of unlabeled data, we concentrate on low-uncertainty regions to reduce the interference of erroneous pseudo-labels on the model. Through this bidirectional learning strategy, the model's overall performance has significantly improved. Extensive experiments show that our proposed method achieves significant performance improvement on different medical image segmentation tasks.</li>
</ul>

<h3>Title: PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian</h3>
<ul>
<li><strong>Authors: </strong>Erfan Moosavi Monazzah, Vahid Rahimzadeh, Yadollah Yaghoobzadeh, Azadeh Shakery, Mohammad Taher Pilehvar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07459">https://arxiv.org/abs/2502.07459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07459">https://arxiv.org/pdf/2502.07459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07459]] PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian(https://arxiv.org/abs/2502.07459)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models predominantly reflect Western cultures, largely due to the dominance of English-centric training data. This imbalance presents a significant challenge, as LLMs are increasingly used across diverse contexts without adequate evaluation of their cultural competence in non-English languages, including Persian. To address this gap, we introduce PerCul, a carefully constructed dataset designed to assess the sensitivity of LLMs toward Persian culture. PerCul features story-based, multiple-choice questions that capture culturally nuanced scenarios. Unlike existing benchmarks, PerCul is curated with input from native Persian annotators to ensure authenticity and to prevent the use of translation as a shortcut. We evaluate several state-of-the-art multilingual and Persian-specific LLMs, establishing a foundation for future research in cross-cultural NLP evaluation. Our experiments demonstrate a 11.3% gap between best closed source model and layperson baseline while the gap increases to 21.3% by using the best open-weight model. You can access the dataset from here: this https URL</li>
</ul>

<h3>Title: Logarithmic Regret for Online KL-Regularized Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Heyang Zhao, Chenlu Ye, Wei Xiong, Quanquan Gu, Tong Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07460">https://arxiv.org/abs/2502.07460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07460">https://arxiv.org/pdf/2502.07460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07460]] Logarithmic Regret for Online KL-Regularized Reinforcement Learning(https://arxiv.org/abs/2502.07460)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Reinforcement Learning from Human Feedback (RLHF) have shown that KL-regularization plays a pivotal role in improving the efficiency of RL fine-tuning for large language models (LLMs). Despite its empirical advantage, the theoretical difference between KL-regularized RL and standard RL remains largely under-explored. While there is a recent line of work on the theoretical analysis of KL-regularized objective in decision making \citep{xiong2024iterative, xie2024exploratory,zhao2024sharp}, these analyses either reduce to the traditional RL setting or rely on strong coverage assumptions. In this paper, we propose an optimism-based KL-regularized online contextual bandit algorithm, and provide a novel analysis of its regret. By carefully leveraging the benign optimization landscape induced by the KL-regularization and the optimistic reward estimation, our algorithm achieves an $\mathcal{O}\big(\eta\log (N_{\mathcal R} T)\cdot d_{\mathcal R}\big)$ logarithmic regret bound, where $\eta, N_{\mathcal R},T,d_{\mathcal R}$ denote the KL-regularization parameter, the cardinality of the reward function class, number of rounds, and the complexity of the reward function class. Furthermore, we extend our algorithm and analysis to reinforcement learning by developing a novel decomposition over transition steps and also obtain a similar logarithmic regret bound.</li>
</ul>

<h3>Title: Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Lin Zhu, Xinbing Wang, Chenghu Zhou, Qinying Gu, Nanyang Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07466">https://arxiv.org/abs/2502.07466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07466">https://arxiv.org/pdf/2502.07466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07466]] Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models(https://arxiv.org/abs/2502.07466)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Given a style-reference image as the additional image condition, text-to-image diffusion models have demonstrated impressive capabilities in generating images that possess the content of text prompts while adopting the visual style of the reference image. However, current state-of-the-art methods often struggle to disentangle content and style from style-reference images, leading to issues such as content leakages. To address this issue, we propose a masking-based method that efficiently decouples content from style without the need of tuning any model parameters. By simply masking specific elements in the style reference's image features, we uncover a critical yet under-explored principle: guiding with appropriately-selected fewer conditions (e.g., dropping several image feature elements) can efficiently avoid unwanted content flowing into the diffusion models, enhancing the style transfer performances of text-to-image diffusion models. In this paper, we validate this finding both theoretically and experimentally. Extensive experiments across various styles demonstrate the effectiveness of our masking-based method and support our theoretical results.</li>
</ul>

<h3>Title: Automated Road Extraction and Centreline Fitting in LiDAR Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Wang, Muhammad Ibrahim, Atif Mansoor, Hasnein Tareque, Ajmal Mian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07486">https://arxiv.org/abs/2502.07486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07486">https://arxiv.org/pdf/2502.07486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07486]] Automated Road Extraction and Centreline Fitting in LiDAR Point Clouds(https://arxiv.org/abs/2502.07486)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Road information extraction from 3D point clouds is useful for urban planning and traffic management. Existing methods often rely on local features and the refraction angle of lasers from kerbs, which makes them sensitive to variable kerb designs and issues in high-density areas due to data homogeneity. We propose an approach for extracting road points and fitting centrelines using a top-down view of LiDAR based ground-collected point clouds. This prospective view reduces reliance on specific kerb design and results in better road extraction. We first perform statistical outlier removal and density-based clustering to reduce noise from 3D point cloud data. Next, we perform ground point filtering using a grid-based segmentation method that adapts to diverse road scenarios and terrain characteristics. The filtered points are then projected onto a 2D plane, and the road is extracted by a skeletonisation algorithm. The skeleton is back-projected onto the 3D point cloud with calculated normals, which guide a region growing algorithm to find nearby road points. The extracted road points are then smoothed with the Savitzky-Golay filter to produce the final centreline. Our initial approach without post-processing of road skeleton achieved 67% in IoU by testing on the Perth CBD dataset with different road types. Incorporating the post-processing of the road skeleton improved the extraction of road points around the smoothed skeleton. The refined approach achieved a higher IoU value of 73% and with 23% reduction in the processing time. Our approach offers a generalised and computationally efficient solution that combines 3D and 2D processing techniques, laying the groundwork for future road reconstruction and 3D-to-2D point cloud alignment.</li>
</ul>

<h3>Title: Improving Adaptive Moment Optimization via Preconditioner Diagonalization</h3>
<ul>
<li><strong>Authors: </strong>Son Nguyen, Bo Liu, Lizhang Chen, Qiang Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07488">https://arxiv.org/abs/2502.07488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07488">https://arxiv.org/pdf/2502.07488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07488]] Improving Adaptive Moment Optimization via Preconditioner Diagonalization(https://arxiv.org/abs/2502.07488)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Modern adaptive optimization methods, such as Adam and its variants, have emerged as the most widely used tools in deep learning over recent years. These algorithms offer automatic mechanisms for dynamically adjusting the update step based on estimates of gradient statistics. Compared to traditional algorithms like Stochastic Gradient Descent, these adaptive methods are typically more robust to model scale and hyperparameter tuning. However, the gradient statistics employed by these methods often do not leverage sufficient gradient covariance information, leading to suboptimal updates in certain directions of the parameter space and potentially slower convergence. In this work, we keep track of such covariance statistics in the form of a structured preconditioner matrix. Unlike other works, our approach does not apply direct approximations to estimate this matrix. We instead implement an invertible transformation that maps the preconditioner matrix into a new space where it becomes approximately diagonal. This enables a diagonal approximation of the preconditioner matrix in the transformed space, offering several computational advantages. Empirical results show that our approach can substantially enhance the convergence speed of modern adaptive optimizers. Notably, for large language models like LLaMA, we can achieve a speedup of 2x compared to the baseline Adam. Additionally, our method can be integrated with memory-efficient optimizers like Adafactor to manage computational overhead.</li>
</ul>

<h3>Title: Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More</h3>
<ul>
<li><strong>Authors: </strong>Xialie Zhuang, Zhikai Jia, Jianjin Li, Zhenyu Zhang, Li Shen, Zheng Cao, Shiwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07490">https://arxiv.org/abs/2502.07490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07490">https://arxiv.org/pdf/2502.07490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07490]] Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More(https://arxiv.org/abs/2502.07490)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are discovered to suffer from accurately retrieving key information. To address this, we propose Mask-Enhanced Autoregressive Prediction (MEAP), a simple yet effective training paradigm that seamlessly integrates Masked Language Modeling (MLM) into Next-Token Prediction (NTP) to enhance the latter's in-context retrieval capabilities. Specifically, MEAP first randomly masks a small fraction of input tokens and then directly performs the standard next-token prediction autoregressive using a decoder-only Transformer. MEAP eliminates the need for bidirectional attention or encoder-decoder architectures for MLM, incurring no additional computational overhead during pre-training or inference. Intensive experiments demonstrate that MEAP substantially outperforms NTP on key information retrieval and long-context reasoning tasks, while performing on par or better on commonsense reasoning tasks. The benefits of MEAP also extend to supervised fine-tuning, where it shows remarkable advantages in lost-in-the-middle scenarios, outperforming NTP by 11.77 percentage points. Our analysis indicates that MEAP's effectiveness arises from its ability to promote more distinguishable attention scores by concentrating on a reduced set of non-masked tokens. This mechanism improves the model's focus on task-relevant signals while mitigating the influence of peripheral context. These findings position MEAP as a promising training paradigm for large language models.</li>
</ul>

<h3>Title: Exploring Patterns Behind Sports</h3>
<ul>
<li><strong>Authors: </strong>Chang Liu, Chengcheng Ma, XuanQi Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07491">https://arxiv.org/abs/2502.07491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07491">https://arxiv.org/pdf/2502.07491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07491]] Exploring Patterns Behind Sports(https://arxiv.org/abs/2502.07491)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a comprehensive framework for time series prediction using a hybrid model that combines ARIMA and LSTM. The model incorporates feature engineering techniques, including embedding and PCA, to transform raw data into a lower-dimensional representation while retaining key information. The embedding technique is used to convert categorical data into continuous vectors, facilitating the capture of complex relationships. PCA is applied to reduce dimensionality and extract principal components, enhancing model performance and computational efficiency. To handle both linear and nonlinear patterns in the data, the ARIMA model captures linear trends, while the LSTM model models complex nonlinear dependencies. The hybrid model is trained on historical data and achieves high accuracy, as demonstrated by low RMSE and MAE scores. Additionally, the paper employs the run test to assess the randomness of sequences, providing insights into the underlying patterns. Ablation studies are conducted to validate the roles of different components in the model, demonstrating the significance of each module. The paper also utilizes the SHAP method to quantify the impact of traditional advantages on the predicted results, offering a detailed understanding of feature importance. The KNN method is used to determine the optimal prediction interval, further enhancing the model's accuracy. The results highlight the effectiveness of combining traditional statistical methods with modern deep learning techniques for robust time series forecasting in Sports.</li>
</ul>

<h3>Title: RoMA: Robust Malware Attribution via Byte-level Adversarial Training with Global Perturbations and Adversarial Consistency Regularization</h3>
<ul>
<li><strong>Authors: </strong>Yuxia Sun, Huihong Chen, Jingcai Guo, Aoxiang Sun, Zhetao Li, Haolin Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07492">https://arxiv.org/abs/2502.07492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07492">https://arxiv.org/pdf/2502.07492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07492]] RoMA: Robust Malware Attribution via Byte-level Adversarial Training with Global Perturbations and Adversarial Consistency Regularization(https://arxiv.org/abs/2502.07492)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Attributing APT (Advanced Persistent Threat) malware to their respective groups is crucial for threat intelligence and cybersecurity. However, APT adversaries often conceal their identities, rendering attribution inherently adversarial. Existing machine learning-based attribution models, while effective, remain highly vulnerable to adversarial attacks. For example, the state-of-the-art byte-level model MalConv sees its accuracy drop from over 90% to below 2% under PGD (projected gradient descent) attacks. Existing gradient-based adversarial training techniques for malware detection or image processing were applied to malware attribution in this study, revealing that both robustness and training efficiency require significant improvement. To address this, we propose RoMA, a novel single-step adversarial training approach that integrates global perturbations to generate enhanced adversarial samples and employs adversarial consistency regularization to improve representation quality and resilience. A novel APT malware dataset named AMG18, with diverse samples and realistic class imbalances, is introduced for evaluation. Extensive experiments show that RoMA significantly outperforms seven competing methods in both adversarial robustness (e.g., achieving over 80% robust accuracy-more than twice that of the next-best method under PGD attacks) and training efficiency (e.g., more than twice as fast as the second-best method in terms of accuracy), while maintaining superior standard accuracy in non-adversarial scenarios.</li>
</ul>

<h3>Title: Decentralized Entropy-Driven Ransomware Detection Using Autonomous Neural Graph Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Ekaterina Starchenko, Hugo Bellinghamshire, David Pickering, Tristan Weatherspoon, Nathaniel Berkhamstead, Elizabeth Green, Magnus Rothschild</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07498">https://arxiv.org/abs/2502.07498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07498">https://arxiv.org/pdf/2502.07498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07498]] Decentralized Entropy-Driven Ransomware Detection Using Autonomous Neural Graph Embeddings(https://arxiv.org/abs/2502.07498)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The increasing sophistication of cyber threats has necessitated the development of advanced detection mechanisms capable of identifying and mitigating ransomware attacks with high precision and efficiency. A novel framework, termed Decentralized Entropy-Driven Detection (DED), is introduced, leveraging autonomous neural graph embeddings and entropy-based anomaly scoring to address the limitations of traditional methods. The framework operates on a distributed network of nodes, eliminating single points of failure and enhancing resilience against targeted attacks. Experimental results demonstrate its ability to achieve detection accuracy exceeding 95\%, with false positive rates maintained below 2\% across diverse ransomware variants. The integration of graph-based modeling and machine learning techniques enables the framework to capture complex system interactions, facilitating the identification of subtle anomalies indicative of ransomware activity. Comparative analysis against existing methods highlights its superior performance in terms of detection rates and computational efficiency. Case studies further validate its effectiveness in real-world scenarios, showcasing its ability to detect and mitigate ransomware attacks within minutes of their initiation. The proposed framework represents a significant step forward in cybersecurity, offering a scalable and adaptive solution to the growing challenge of ransomware detection.</li>
</ul>

<h3>Title: Unified Graph Networks (UGN): A Deep Neural Framework for Solving Graph Problems</h3>
<ul>
<li><strong>Authors: </strong>Rudrajit Dawn, Madhusudan Ghosh, Partha Basuchowdhuri, Sudip Kumar Naskar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07500">https://arxiv.org/abs/2502.07500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07500">https://arxiv.org/pdf/2502.07500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07500]] Unified Graph Networks (UGN): A Deep Neural Framework for Solving Graph Problems(https://arxiv.org/abs/2502.07500)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Deep neural networks have enabled researchers to create powerful generalized frameworks, such as transformers, that can be used to solve well-studied problems in various application domains, such as text and image. However, such generalized frameworks are not available for solving graph problems. Graph structures are ubiquitous in many applications around us and many graph problems have been widely studied over years. In recent times, there has been a surge in deep neural network based approaches to solve graph problems, with growing availability of graph structured datasets across diverse domains. Nevertheless, existing methods are mostly tailored to solve a specific task and lack the capability to create a generalized model leading to solutions for different downstream tasks. In this work, we propose a novel, resource-efficient framework named \emph{U}nified \emph{G}raph \emph{N}etwork (UGN) by leveraging the feature extraction capability of graph convolutional neural networks (GCN) and 2-dimensional convolutional neural networks (Conv2D). UGN unifies various graph learning tasks, such as link prediction, node classification, community detection, graph-to-graph translation, knowledge graph completion, and more, within a cohesive framework, while exercising minimal task-specific extensions (e.g., formation of supernodes for coarsening massive networks to increase scalability, use of \textit{mean target connectivity matrix} (MTCM) representation for achieving scalability in graph translation task, etc.) to enhance the generalization capability of graph learning and analysis. We test the novel UGN framework for six uncorrelated graph problems, using twelve different datasets. Experimental results show that UGN outperforms the state-of-the-art baselines by a significant margin on ten datasets, while producing comparable results on the remaining dataset.</li>
</ul>

<h3>Title: Efficient Continuous Group Convolutions for Local SE(3) Equivariance in 3D Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Lisa Weijler, Pedro Hermosilla</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07505">https://arxiv.org/abs/2502.07505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07505">https://arxiv.org/pdf/2502.07505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07505]] Efficient Continuous Group Convolutions for Local SE(3) Equivariance in 3D Point Clouds(https://arxiv.org/abs/2502.07505)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Extending the translation equivariance property of convolutional neural networks to larger symmetry groups has been shown to reduce sample complexity and enable more discriminative feature learning. Further, exploiting additional symmetries facilitates greater weight sharing than standard convolutions, leading to an enhanced network expressivity without an increase in parameter count. However, extending the equivariant properties of a convolution layer comes at a computational cost. In particular, for 3D data, expanding equivariance to the SE(3) group (rotation and translation) results in a 6D convolution operation, which is not tractable for larger data samples such as 3D scene scans. While efforts have been made to develop efficient SE(3) equivariant networks, existing approaches rely on discretization or only introduce global rotation equivariance. This limits their applicability to point clouds representing a scene composed of multiple objects. This work presents an efficient, continuous, and local SE(3) equivariant convolution layer for point cloud processing based on general group convolution and local reference frames. Our experiments show that our approach achieves competitive or superior performance across a range of datasets and tasks, including object classification and semantic segmentation, with negligible computational overhead.</li>
</ul>

<h3>Title: Scaling Off-Policy Reinforcement Learning with Batch and Weight Normalization</h3>
<ul>
<li><strong>Authors: </strong>Daniel Palenicek, Florian Vogt, Jan Peters</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07523">https://arxiv.org/abs/2502.07523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07523">https://arxiv.org/pdf/2502.07523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07523]] Scaling Off-Policy Reinforcement Learning with Batch and Weight Normalization(https://arxiv.org/abs/2502.07523)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reinforcement learning has achieved significant milestones, but sample efficiency remains a bottleneck for real-world applications. Recently, CrossQ has demonstrated state-of-the-art sample efficiency with a low update-to-data (UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with higher UTD ratios. We identify challenges in the training dynamics, which are emphasized by higher UTD ratios. To address these, we integrate weight normalization into the CrossQ framework, a solution that stabilizes training, has been shown to prevent potential loss of plasticity and keeps the effective learning rate constant. Our proposed approach reliably scales with increasing UTD ratios, achieving competitive performance across 25 challenging continuous control tasks on the DeepMind Control Suite and Myosuite benchmarks, notably the complex dog and humanoid environments. This work eliminates the need for drastic interventions, such as network resets, and offers a simple yet robust pathway for improving sample efficiency and scalability in model-free reinforcement learning.</li>
</ul>

<h3>Title: CodePhys: Robust Video-based Remote Physiological Measurement through Latent Codebook Querying</h3>
<ul>
<li><strong>Authors: </strong>Shuyang Chu, Menghan Xia, Mengyao Yuan, Xin Liu, Tapio Seppanen, Guoying Zhao, Jingang Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07526">https://arxiv.org/abs/2502.07526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07526">https://arxiv.org/pdf/2502.07526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07526]] CodePhys: Robust Video-based Remote Physiological Measurement through Latent Codebook Querying(https://arxiv.org/abs/2502.07526)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Remote photoplethysmography (rPPG) aims to measure non-contact physiological signals from facial videos, which has shown great potential in many applications. Most existing methods directly extract video-based rPPG features by designing neural networks for heart rate estimation. Although they can achieve acceptable results, the recovery of rPPG signal faces intractable challenges when interference from real-world scenarios takes place on facial video. Specifically, facial videos are inevitably affected by non-physiological factors (e.g., camera device noise, defocus, and motion blur), leading to the distortion of extracted rPPG signals. Recent rPPG extraction methods are easily affected by interference and degradation, resulting in noisy rPPG signals. In this paper, we propose a novel method named CodePhys, which innovatively treats rPPG measurement as a code query task in a noise-free proxy space (i.e., codebook) constructed by ground-truth PPG signals. We consider noisy rPPG features as queries and generate high-fidelity rPPG features by matching them with noise-free PPG features from the codebook. Our approach also incorporates a spatial-aware encoder network with a spatial attention mechanism to highlight physiologically active areas and uses a distillation loss to reduce the influence of non-periodic visual interference. Experimental results on four benchmark datasets demonstrate that CodePhys outperforms state-of-the-art methods in both intra-dataset and cross-dataset settings.</li>
</ul>

<h3>Title: VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Sixiao Zheng, Zimian Peng, Yanpeng Zhou, Yi Zhu, Hang Xu, Xiangru Huang, Yanwei Fu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07531">https://arxiv.org/abs/2502.07531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07531">https://arxiv.org/pdf/2502.07531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07531]] VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation(https://arxiv.org/abs/2502.07531)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent image-to-video generation methods have demonstrated success in enabling control over one or two visual elements, such as camera trajectory or object motion. However, these methods are unable to offer control over multiple visual elements due to limitations in data and network efficacy. In this paper, we introduce VidCRAFT3, a novel framework for precise image-to-video generation that enables control over camera motion, object motion, and lighting direction simultaneously. To better decouple control over each visual element, we propose the Spatial Triple-Attention Transformer, which integrates lighting direction, text, and image in a symmetric way. Since most real-world video datasets lack lighting annotations, we construct a high-quality synthetic video dataset, the VideoLightingDirection (VLD) dataset. This dataset includes lighting direction annotations and objects of diverse appearance, enabling VidCRAFT3 to effectively handle strong light transmission and reflection effects. Additionally, we propose a three-stage training strategy that eliminates the need for training data annotated with multiple visual elements (camera motion, object motion, and lighting direction) simultaneously. Extensive experiments on benchmark datasets demonstrate the efficacy of VidCRAFT3 in producing high-quality video content, surpassing existing state-of-the-art methods in terms of control granularity and visual coherence. All code and data will be publicly available. Project page: this https URL.</li>
</ul>

<h3>Title: Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Erik Larsson, Joel Oskarsson, Tomas Landelius, Fredrik Lindsten</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07532">https://arxiv.org/abs/2502.07532</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07532">https://arxiv.org/pdf/2502.07532</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07532]] Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with Diffusion(https://arxiv.org/abs/2502.07532)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Machine learning methods have been shown to be effective for weather forecasting, based on the speed and accuracy compared to traditional numerical models. While early efforts primarily concentrated on deterministic predictions, the field has increasingly shifted toward probabilistic forecasting to better capture the forecast uncertainty. Most machine learning-based models have been designed for global-scale predictions, with only limited work targeting regional or limited area forecasting, which allows more specialized and flexible modeling for specific locations. This work introduces Diffusion-LAM, a probabilistic limited area weather model leveraging conditional diffusion. By conditioning on boundary data from surrounding regions, our approach generates forecasts within a defined area. Experimental results on the MEPS limited area dataset demonstrate the potential of Diffusion-LAM to deliver accurate probabilistic forecasts, highlighting its promise for limited-area weather prediction.</li>
</ul>

<h3>Title: Grammar Control in Dialogue Response Generation for Language Learning Chatbots</h3>
<ul>
<li><strong>Authors: </strong>Dominik Glandorf, Peng Cui, Detmar Meurers, Mrinmaya Sachan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07544">https://arxiv.org/abs/2502.07544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07544">https://arxiv.org/pdf/2502.07544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07544]] Grammar Control in Dialogue Response Generation for Language Learning Chatbots(https://arxiv.org/abs/2502.07544)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chatbots based on large language models offer cheap conversation practice opportunities for language learners. However, they are hard to control for linguistic forms that correspond to learners' current needs, such as grammar. We control grammar in chatbot conversation practice by grounding a dialogue response generation model in a pedagogical repository of grammar skills. We also explore how this control helps learners to produce specific grammar. We comprehensively evaluate prompting, fine-tuning, and decoding strategies for grammar-controlled dialogue response generation. Strategically decoding Llama3 outperforms GPT-3.5 when tolerating minor response quality losses. Our simulation predicts grammar-controlled responses to support grammar acquisition adapted to learner proficiency. Existing language learning chatbots and research on second language acquisition benefit from these affordances. Code available on GitHub.</li>
</ul>

<h3>Title: Attention Learning is Needed to Efficiently Learn Parity Function</h3>
<ul>
<li><strong>Authors: </strong>Yaomengxi Han, Debarghya Ghoshdastidar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07553">https://arxiv.org/abs/2502.07553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07553">https://arxiv.org/pdf/2502.07553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07553]] Attention Learning is Needed to Efficiently Learn Parity Function(https://arxiv.org/abs/2502.07553)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers, with their attention mechanisms, have emerged as the state-of-the-art architectures of sequential modeling and empirically outperform feed-forward neural networks (FFNNs) across many fields, such as natural language processing and computer vision. However, their generalization ability, particularly for low-sensitivity functions, remains less studied. We bridge this gap by analyzing transformers on the $k$-parity problem. Daniely and Malach (NeurIPS 2020) show that FFNNs with one hidden layer and $O(nk^7 \log k)$ parameters can learn $k$-parity, where the input length $n$ is typically much larger than $k$. In this paper, we prove that FFNNs require at least $\Omega(n)$ parameters to learn $k$-parity, while transformers require only $O(k)$ parameters, surpassing the theoretical lower bound needed by FFNNs. We further prove that this parameter efficiency cannot be achieved with fixed attention heads. Our work establishes transformers as theoretically superior to FFNNs in learning parity function, showing how their attention mechanisms enable parameter-efficient generalization in functions with low sensitivity.</li>
</ul>

<h3>Title: O1 Embedder: Let Retrievers Think Before Action</h3>
<ul>
<li><strong>Authors: </strong>Ruin Yan, Zheng Liu, Defu Lian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07555">https://arxiv.org/abs/2502.07555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07555">https://arxiv.org/pdf/2502.07555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07555]] O1 Embedder: Let Retrievers Think Before Action(https://arxiv.org/abs/2502.07555)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing power of large language models (LLMs) has revolutionized how people access and utilize information. Notably, the LLMs excel at performing fine-grained data representation, which facilitates precise retrieval of information. They also generate high-quality answers based on external references, enabling the production of useful knowledge. The recent introduction of reasoning models, like OpenAI O1 and DeepSeek R1, marks another leap forward, highlighting LLMs' ability to think progressively before delivering final answers. This breakthrough significantly improves the ability to address complex tasks, e.g., coding and math proofs. Inspired by this progress, we aim to develop similar capabilities for retrieval models, which hold great promise for tackling critical challenges in the field, including multi-task retrieval, zero-shot retrieval, and tasks requiring intensive reasoning of complex relationships. With this motivation, we propose a novel approach called O1 Embedder, which generates useful thoughts for the input query before making retrieval for the target documents. To realize this objective, we conquer two technical difficulties. First, we design a data synthesis workflow, creating training signals for O1 Embedder by generating initial thoughts from an LLM-expert and subsequently refining them using a retrieval committee. Second, we optimize the training process, enabling a pre-trained model to be jointly fine-tuned to generate retrieval thoughts via behavior cloning and perform dense retrieval through contrastive learning. Our approach is evaluated by comprehensive experiments, where substantial improvements are achieved across 12 popular datasets, spanning both in-domain and out-of-domain scenarios. These results highlight O1 Embedder's remarkable accuracy and generalizability, paving the way for the development of next-generation IR foundation models.</li>
</ul>

<h3>Title: JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation</h3>
<ul>
<li><strong>Authors: </strong>Shenyi Zhang, Yuchen Zhai, Keyan Guo, Hongxin Hu, Shengnan Guo, Zheng Fang, Lingchen Zhao, Chao Shen, Cong Wang, Qian Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07557">https://arxiv.org/abs/2502.07557</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07557">https://arxiv.org/pdf/2502.07557</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07557]] JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation(https://arxiv.org/abs/2502.07557)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Despite the implementation of safety alignment strategies, large language models (LLMs) remain vulnerable to jailbreak attacks, which undermine these safety guardrails and pose significant security threats. Some defenses have been proposed to detect or mitigate jailbreaks, but they are unable to withstand the test of time due to an insufficient understanding of jailbreak mechanisms. In this work, we investigate the mechanisms behind jailbreaks based on the Linear Representation Hypothesis (LRH), which states that neural networks encode high-level concepts as subspaces in their hidden representations. We define the toxic semantics in harmful and jailbreak prompts as toxic concepts and describe the semantics in jailbreak prompts that manipulate LLMs to comply with unsafe requests as jailbreak concepts. Through concept extraction and analysis, we reveal that LLMs can recognize the toxic concepts in both harmful and jailbreak prompts. However, unlike harmful prompts, jailbreak prompts activate the jailbreak concepts and alter the LLM output from rejection to compliance. Building on our analysis, we propose a comprehensive jailbreak defense framework, JBShield, consisting of two key components: jailbreak detection JBShield-D and mitigation JBShield-M. JBShield-D identifies jailbreak prompts by determining whether the input activates both toxic and jailbreak concepts. When a jailbreak prompt is detected, JBShield-M adjusts the hidden representations of the target LLM by enhancing the toxic concept and weakening the jailbreak concept, ensuring LLMs produce safe content. Extensive experiments demonstrate the superior performance of JBShield, achieving an average detection accuracy of 0.95 and reducing the average attack success rate of various jailbreak attacks to 2% from 61% across distinct LLMs.</li>
</ul>

<h3>Title: LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid</h3>
<ul>
<li><strong>Authors: </strong>Weigao Sun, Disen Lan, Yiran Zhong, Xiaoye Qu, Yu Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07563">https://arxiv.org/abs/2502.07563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07563">https://arxiv.org/pdf/2502.07563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07563]] LASP-2: Rethinking Sequence Parallelism for Linear Attention and Its Hybrid(https://arxiv.org/abs/2502.07563)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Linear sequence modeling approaches, such as linear attention, provide advantages like linear-time training and constant-memory inference over sequence lengths. However, existing sequence parallelism (SP) methods are either not optimized for the right-product-first feature of linear attention or use a ring-style communication strategy, which results in lower computation parallelism, limits their scalability for longer sequences in distributed systems. In this paper, we introduce LASP-2, a new SP method to enhance both communication and computation parallelism when training linear attention transformer models with very-long input sequences. Compared to previous work LASP, LASP-2 rethinks the minimal communication requirement for SP on linear attention layers, reorganizes the whole communication-computation workflow of LASP. In this way, only one single AllGather collective communication is needed on intermediate memory states, whose sizes are independent of the sequence length, leading to significant improvements of both communication and computation parallelism, as well as their overlap. Additionally, we extend LASP-2 to LASP-2H by applying similar communication redesign to standard attention modules, offering an efficient SP solution for hybrid models that blend linear and standard attention layers. Our evaluation on a Linear-Llama3 model, a variant of Llama3 with linear attention replacing standard attention, demonstrates the effectiveness of LASP-2 and LASP-2H. Specifically, LASP-2 achieves training speed improvements of 15.2% over LASP and 36.6% over Ring Attention, with a sequence length of 2048K across 64 GPUs. The Code is released as a part of: this https URL.</li>
</ul>

<h3>Title: Single-Step Consistent Diffusion Samplers</h3>
<ul>
<li><strong>Authors: </strong>Pascal Jutras-DubÃ©, Patrick Pynadath, Ruqi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07579">https://arxiv.org/abs/2502.07579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07579">https://arxiv.org/pdf/2502.07579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07579]] Single-Step Consistent Diffusion Samplers(https://arxiv.org/abs/2502.07579)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Sampling from unnormalized target distributions is a fundamental yet challenging task in machine learning and statistics. Existing sampling algorithms typically require many iterative steps to produce high-quality samples, leading to high computational costs that limit their practicality in time-sensitive or resource-constrained settings. In this work, we introduce consistent diffusion samplers, a new class of samplers designed to generate high-fidelity samples in a single step. We first develop a distillation algorithm to train a consistent diffusion sampler from a pretrained diffusion model without pre-collecting large datasets of samples. Our algorithm leverages incomplete sampling trajectories and noisy intermediate states directly from the diffusion process. We further propose a method to train a consistent diffusion sampler from scratch, fully amortizing exploration by training a single model that both performs diffusion sampling and skips intermediate steps using a self-consistency loss. Through extensive experiments on a variety of unnormalized distributions, we show that our approach yields high-fidelity samples using less than 1% of the network evaluations required by traditional diffusion samplers.</li>
</ul>

<h3>Title: Generative Modeling with Bayesian Sample Inference</h3>
<ul>
<li><strong>Authors: </strong>Marten Lienen, Marcel Kollovieh, Stephan GÃ¼nnemann</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07580">https://arxiv.org/abs/2502.07580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07580">https://arxiv.org/pdf/2502.07580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07580]] Generative Modeling with Bayesian Sample Inference(https://arxiv.org/abs/2502.07580)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We derive a novel generative model from the simple act of Gaussian posterior inference. Treating the generated sample as an unknown variable to infer lets us formulate the sampling process in the language of Bayesian probability. Our model uses a sequence of prediction and posterior update steps to narrow down the unknown sample from a broad initial belief. In addition to a rigorous theoretical analysis, we establish a connection between our model and diffusion models and show that it includes Bayesian Flow Networks (BFNs) as a special case. In our experiments, we demonstrate improved performance over both BFNs and Variational Diffusion Models, achieving competitive likelihood scores on CIFAR10 and ImageNet.</li>
</ul>

<h3>Title: We Can't Understand AI Using our Existing Vocabulary</h3>
<ul>
<li><strong>Authors: </strong>John Hewitt, Robert Geirhos, Been Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07586">https://arxiv.org/abs/2502.07586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07586">https://arxiv.org/pdf/2502.07586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07586]] We Can't Understand AI Using our Existing Vocabulary(https://arxiv.org/abs/2502.07586)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This position paper argues that, in order to understand AI, we cannot rely on our existing vocabulary of human words. Instead, we should strive to develop neologisms: new words that represent precise human concepts that we want to teach machines, or machine concepts that we need to learn. We start from the premise that humans and machines have differing concepts. This means interpretability can be framed as a communication problem: humans must be able to reference and control machine concepts, and communicate human concepts to machines. Creating a shared human-machine language through developing neologisms, we believe, could solve this communication problem. Successful neologisms achieve a useful amount of abstraction: not too detailed, so they're reusable in many contexts, and not too high-level, so they convey precise information. As a proof of concept, we demonstrate how a "length neologism" enables controlling LLM response length, while a "diversity neologism" allows sampling more variable responses. Taken together, we argue that we cannot understand AI using our existing vocabulary, and expanding it through neologisms creates opportunities for both controlling and understanding machines better.</li>
</ul>

<h3>Title: SEMU: Singular Value Decomposition for Efficient Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Marcin Sendera, Åukasz Struski, Kamil KsiÄÅ¼ek, Kryspin Musiol, Jacek Tabor, Dawid Rymarczyk</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07587">https://arxiv.org/abs/2502.07587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07587">https://arxiv.org/pdf/2502.07587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07587]] SEMU: Singular Value Decomposition for Efficient Machine Unlearning(https://arxiv.org/abs/2502.07587)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>While the capabilities of generative foundational models have advanced rapidly in recent years, methods to prevent harmful and unsafe behaviors remain underdeveloped. Among the pressing challenges in AI safety, machine unlearning (MU) has become increasingly critical to meet upcoming safety regulations. Most existing MU approaches focus on altering the most significant parameters of the model. However, these methods often require fine-tuning substantial portions of the model, resulting in high computational costs and training instabilities, which are typically mitigated by access to the original training dataset. In this work, we address these limitations by leveraging Singular Value Decomposition (SVD) to create a compact, low-dimensional projection that enables the selective forgetting of specific data points. We propose Singular Value Decomposition for Efficient Machine Unlearning (SEMU), a novel approach designed to optimize MU in two key aspects. First, SEMU minimizes the number of model parameters that need to be modified, effectively removing unwanted knowledge while making only minimal changes to the model's weights. Second, SEMU eliminates the dependency on the original training dataset, preserving the model's previously acquired knowledge without additional data requirements. Extensive experiments demonstrate that SEMU achieves competitive performance while significantly improving efficiency in terms of both data usage and the number of modified parameters.</li>
</ul>

<h3>Title: Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiacong Xu, Shao-Yuan Lo, Bardia Safaei, Vishal M. Patel, Isht Dwivedi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07601">https://arxiv.org/abs/2502.07601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07601">https://arxiv.org/pdf/2502.07601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07601]] Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models(https://arxiv.org/abs/2502.07601)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Zero-Shot Anomaly Detection (ZSAD) is an emerging AD paradigm. Unlike the traditional unsupervised AD setting that requires a large number of normal samples to train a model, ZSAD is more practical for handling data-restricted real-world scenarios. Recently, Multimodal Large Language Models (MLLMs) have shown revolutionary reasoning capabilities in various vision tasks. However, the reasoning of image abnormalities remains underexplored due to the lack of corresponding datasets and benchmarks. To facilitate research in AD & reasoning, we establish the first visual instruction tuning dataset, Anomaly-Instruct-125k, and the evaluation benchmark, VisA-D&R. Through investigation with our benchmark, we reveal that current MLLMs like GPT-4o cannot accurately detect and describe fine-grained anomalous details in images. To address this, we propose Anomaly-OneVision (Anomaly-OV), the first specialist visual assistant for ZSAD and reasoning. Inspired by human behavior in visual inspection, Anomaly-OV leverages a Look-Twice Feature Matching (LTFM) mechanism to adaptively select and emphasize abnormal visual tokens. Extensive experiments demonstrate that Anomaly-OV achieves significant improvements over advanced generalist models in both detection and reasoning. Extensions to medical and 3D AD are provided for future study. The link to our project page: this https URL</li>
</ul>

<h3>Title: Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing</h3>
<ul>
<li><strong>Authors: </strong>Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07608">https://arxiv.org/abs/2502.07608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07608">https://arxiv.org/pdf/2502.07608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07608]] Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing(https://arxiv.org/abs/2502.07608)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) show promise for health applications when combined with behavioral sensing data. Traditional approaches convert sensor data into text prompts, but this process is prone to errors, computationally expensive, and requires domain expertise. These challenges are particularly acute when processing extended time series data. While time series foundation models (TFMs) have recently emerged as powerful tools for learning representations from temporal data, bridging TFMs and LLMs remains challenging. Here, we present Time2Lang, a framework that directly maps TFM outputs to LLM representations without intermediate text conversion. Our approach first trains on synthetic data using periodicity prediction as a pretext task, followed by evaluation on mental health classification tasks. We validate Time2Lang on two longitudinal wearable and mobile sensing datasets: daily depression prediction using step count data (17,251 days from 256 participants) and flourishing classification based on conversation duration (46 participants over 10 weeks). Time2Lang maintains near constant inference times regardless of input length, unlike traditional prompting methods. The generated embeddings preserve essential time-series characteristics such as auto-correlation. Our results demonstrate that TFMs and LLMs can be effectively integrated while minimizing information loss and enabling performance transfer across these distinct modeling paradigms. To our knowledge, we are the first to integrate a TFM and an LLM for health, thus establishing a foundation for future research combining general-purpose large models for complex healthcare tasks.</li>
</ul>

<h3>Title: Tractable Transformers for Flexible Conditional Generation</h3>
<ul>
<li><strong>Authors: </strong>Anji Liu, Xuejie Liu, Dayuan Zhao, Mathias Niepert, Yitao Liang, Guy Van den Broeck</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07616">https://arxiv.org/abs/2502.07616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07616">https://arxiv.org/pdf/2502.07616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07616]] Tractable Transformers for Flexible Conditional Generation(https://arxiv.org/abs/2502.07616)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Non-autoregressive (NAR) generative models are valuable because they can handle diverse conditional generation tasks in a more principled way than their autoregressive (AR) counterparts, which are constrained by sequential dependency requirements. Recent advancements in NAR models, such as diffusion language models, have demonstrated superior performance in unconditional generation compared to AR models (e.g., GPTs) of similar sizes. However, such improvements do not always lead to improved conditional generation performance. We show that a key reason for this gap is the difficulty in generalizing to conditional probability queries unseen during training. As a result, strong unconditional generation performance does not guarantee high-quality conditional generation. This paper proposes Tractable Transformers (Tracformer), a Transformer-based generative model that is more robust to different conditional generation tasks. Unlike existing models that rely solely on global contextual features derived from full inputs, Tracformers incorporate a sparse Transformer encoder to capture both local and global contextual information. This information is routed through a decoder for conditional generation. Empirical results demonstrate that Tracformers achieve state-of-the-art conditional generation performance on text modeling compared to recent diffusion and AR model baselines.</li>
</ul>

<h3>Title: Consistency Training with Physical Constraints</h3>
<ul>
<li><strong>Authors: </strong>Che-Chia Chang, Chen-Yang Dai, Te-Sheng Lin, Ming-Chih Lai, Chieh-Hsin Lai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07636">https://arxiv.org/abs/2502.07636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07636">https://arxiv.org/pdf/2502.07636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07636]] Consistency Training with Physical Constraints(https://arxiv.org/abs/2502.07636)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We propose a physics-aware Consistency Training (CT) method that accelerates sampling in Diffusion Models with physical constraints. Our approach leverages a two-stage strategy: (1) learning the noise-to-data mapping via CT, and (2) incorporating physics constraints as a regularizer. Experiments on toy examples show that our method generates samples in a single step while adhering to the imposed constraints. This approach has the potential to efficiently solve partial differential equations (PDEs) using deep generative modeling.</li>
</ul>

<h3>Title: Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving</h3>
<ul>
<li><strong>Authors: </strong>Yong Lin, Shange Tang, Bohan Lyu, Jiayun Wu, Hongzhou Lin, Kaiyu Yang, Jia Li, Mengzhou Xia, Danqi Chen, Sanjeev Arora, Chi Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07640">https://arxiv.org/abs/2502.07640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07640">https://arxiv.org/pdf/2502.07640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07640]] Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving(https://arxiv.org/abs/2502.07640)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce Goedel-Prover, an open-source large language model (LLM) that achieves the state-of-the-art (SOTA) performance in automated formal proof generation for mathematical problems. The key challenge in this field is the scarcity of formalized math statements and proofs, which we tackle in the following ways. We train statement formalizers to translate the natural language math problems from Numina into formal language (Lean 4), creating a dataset of 1.64 million formal statements. LLMs are used to check that the formal statements accurately preserve the content of the original natural language problems. We then iteratively build a large dataset of formal proofs by training a series of provers. Each prover succeeds in proving many statements that the previous ones could not, and these new proofs are added to the training set for the next prover. The final prover outperforms all existing open-source models in whole-proof generation. On the miniF2F benchmark, it achieves a 57.6% success rate (Pass@32), exceeding the previous best open-source model by 7.6%. On PutnamBench, Goedel-Prover successfully solves 7 problems (Pass@512), ranking first on the leaderboard. Furthermore, it generates 29.7K formal proofs for Lean Workbook problems, nearly doubling the 15.7K produced by earlier works.</li>
</ul>

<h3>Title: FoQA: A Faroese Question-Answering Dataset</h3>
<ul>
<li><strong>Authors: </strong>Annika Simonsen, Dan Saattrup Nielsen, Hafsteinn Einarsson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07642">https://arxiv.org/abs/2502.07642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07642">https://arxiv.org/pdf/2502.07642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07642]] FoQA: A Faroese Question-Answering Dataset(https://arxiv.org/abs/2502.07642)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present FoQA, a Faroese extractive question-answering (QA) dataset with 2,000 samples, created using a semi-automated approach combining Large Language Models (LLMs) and human validation. The dataset was generated from Faroese Wikipedia articles using GPT-4-turbo for initial QA generation, followed by question rephrasing to increase complexity and native speaker validation to ensure quality. We provide baseline performance metrics for FoQA across multiple models, including LLMs and BERT, demonstrating its effectiveness in evaluating Faroese QA performance. The dataset is released in three versions: a validated set of 2,000 samples, a complete set of all 10,001 generated samples, and a set of 2,395 rejected samples for error analysis.</li>
</ul>

<h3>Title: Auto-Drafting Police Reports from Noisy ASR Outputs: A Trust-Centered LLM Approach</h3>
<ul>
<li><strong>Authors: </strong>Param Kulkarni, Yingchi Liu, Hao-Ming Fu, Shaohua Yang, Isuru Gunasekara, Matt Peloquin, Noah Spitzer-Williams, Xiaotian Zhou, Xiaozhong Liu, Zhengping Ji, Yasser Ibrahim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07677">https://arxiv.org/abs/2502.07677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07677">https://arxiv.org/pdf/2502.07677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07677]] Auto-Drafting Police Reports from Noisy ASR Outputs: A Trust-Centered LLM Approach(https://arxiv.org/abs/2502.07677)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Achieving a delicate balance between fostering trust in law en- forcement and protecting the rights of both officers and civilians continues to emerge as a pressing research and product challenge in the world today. In the pursuit of fairness and transparency, this study presents an innovative AI-driven system designed to generate police report drafts from complex, noisy, and multi-role dialogue data. Our approach intelligently extracts key elements of law enforcement interactions and includes them in the draft, producing structured narratives that are not only high in quality but also reinforce accountability and procedural clarity. This frame- work holds the potential to transform the reporting process, ensur- ing greater oversight, consistency, and fairness in future policing practices. A demonstration video of our system can be accessed at this https URL Y-kpCHNO/view?usp=sharing</li>
</ul>

<h3>Title: Matrix3D: Large Photogrammetry Model All-in-One</h3>
<ul>
<li><strong>Authors: </strong>Yuanxun Lu, Jingyang Zhang, Tian Fang, Jean-Daniel Nahmias, Yanghai Tsin, Long Quan, Xun Cao, Yao Yao, Shiwei Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07685">https://arxiv.org/abs/2502.07685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07685">https://arxiv.org/pdf/2502.07685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07685]] Matrix3D: Large Photogrammetry Model All-in-One(https://arxiv.org/abs/2502.07685)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We present Matrix3D, a unified model that performs several photogrammetry subtasks, including pose estimation, depth prediction, and novel view synthesis using just the same model. Matrix3D utilizes a multi-modal diffusion transformer (DiT) to integrate transformations across several modalities, such as images, camera parameters, and depth maps. The key to Matrix3D's large-scale multi-modal training lies in the incorporation of a mask learning strategy. This enables full-modality model training even with partially complete data, such as bi-modality data of image-pose and image-depth pairs, thus significantly increases the pool of available training data. Matrix3D demonstrates state-of-the-art performance in pose estimation and novel view synthesis tasks. Additionally, it offers fine-grained control through multi-round interactions, making it an innovative tool for 3D content creation. Project page: this https URL.</li>
</ul>

<h3>Title: Large Language Models as Proxies for Theories of Human Linguistic Cognition</h3>
<ul>
<li><strong>Authors: </strong>Imry Ziv, Nur Lan, Emmanuel Chemla, Roni Katzir</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07687">https://arxiv.org/abs/2502.07687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07687">https://arxiv.org/pdf/2502.07687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07687]] Large Language Models as Proxies for Theories of Human Linguistic Cognition(https://arxiv.org/abs/2502.07687)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We consider the possible role of current large language models (LLMs) in the study of human linguistic cognition. We focus on the use of such models as proxies for theories of cognition that are relatively linguistically-neutral in their representations and learning but differ from current LLMs in key ways. We illustrate this potential use of LLMs as proxies for theories of cognition in the context of two kinds of questions: (a) whether the target theory accounts for the acquisition of a given pattern from a given corpus; and (b) whether the target theory makes a given typologically-attested pattern easier to acquire than another, typologically-unattested pattern. For each of the two questions we show, building on recent literature, how current LLMs can potentially be of help, but we note that at present this help is quite limited.</li>
</ul>

<h3>Title: Magic 1-For-1: Generating One Minute Video Clips within One Minute</h3>
<ul>
<li><strong>Authors: </strong>Hongwei Yi, Shitong Shao, Tian Ye, Jiantong Zhao, Qingyu Yin, Michael Lingelbach, Li Yuan, Yonghong Tian, Enze Xie, Daquan Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07701">https://arxiv.org/abs/2502.07701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07701">https://arxiv.org/pdf/2502.07701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07701]] Magic 1-For-1: Generating One Minute Video Clips within One Minute(https://arxiv.org/abs/2502.07701)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this technical report, we present Magic 1-For-1 (Magic141), an efficient video generation model with optimized memory consumption and inference latency. The key idea is simple: factorize the text-to-video generation task into two separate easier tasks for diffusion step distillation, namely text-to-image generation and image-to-video generation. We verify that with the same optimization algorithm, the image-to-video task is indeed easier to converge over the text-to-video task. We also explore a bag of optimization tricks to reduce the computational cost of training the image-to-video (I2V) models from three aspects: 1) model convergence speedup by using a multi-modal prior condition injection; 2) inference latency speed up by applying an adversarial step distillation, and 3) inference memory cost optimization with parameter sparsification. With those techniques, we are able to generate 5-second video clips within 3 seconds. By applying a test time sliding window, we are able to generate a minute-long video within one minute with significantly improved visual quality and motion dynamics, spending less than 1 second for generating 1 second video clips on average. We conduct a series of preliminary explorations to find out the optimal tradeoff between computational cost and video quality during diffusion step distillation and hope this could be a good foundation model for open-source explorations. The code and the model weights are available at this https URL.</li>
</ul>

<h3>Title: PRVQL: Progressive Knowledge-guided Refinement for Robust Egocentric Visual Query Localization</h3>
<ul>
<li><strong>Authors: </strong>Bing Fan, Yunhe Feng, Yapeng Tian, Yuewei Lin, Yan Huang, Heng Fan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07707">https://arxiv.org/abs/2502.07707</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07707">https://arxiv.org/pdf/2502.07707</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07707]] PRVQL: Progressive Knowledge-guided Refinement for Robust Egocentric Visual Query Localization(https://arxiv.org/abs/2502.07707)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Egocentric visual query localization (EgoVQL) focuses on localizing the target of interest in space and time from first-person videos, given a visual query. Despite recent progressive, existing methods often struggle to handle severe object appearance changes and cluttering background in the video due to lacking sufficient target cues, leading to degradation. Addressing this, we introduce PRVQL, a novel Progressive knowledge-guided Refinement framework for EgoVQL. The core is to continuously exploit target-relevant knowledge directly from videos and utilize it as guidance to refine both query and video features for improving target localization. Our PRVQL contains multiple processing stages. The target knowledge from one stage, comprising appearance and spatial knowledge extracted via two specially designed knowledge learning modules, are utilized as guidance to refine the query and videos features for the next stage, which are used to generate more accurate knowledge for further feature refinement. With such a progressive process, target knowledge in PRVQL can be gradually improved, which, in turn, leads to better refined query and video features for localization in the final stage. Compared to previous methods, our PRVQL, besides the given object cues, enjoys additional crucial target information from a video as guidance to refine features, and hence enhances EgoVQL in complicated scenes. In our experiments on challenging Ego4D, PRVQL achieves state-of-the-art result and largely surpasses other methods, showing its efficacy. Our code, model and results will be released at this https URL.</li>
</ul>

<h3>Title: Near-Optimal Sample Complexity in Reward-Free Kernel-Based Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Aya Kayal, Sattar Vakili, Laura Toni, Alberto Bernacchia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07715">https://arxiv.org/abs/2502.07715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07715">https://arxiv.org/pdf/2502.07715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07715]] Near-Optimal Sample Complexity in Reward-Free Kernel-Based Reinforcement Learning(https://arxiv.org/abs/2502.07715)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) problems are being considered under increasingly more complex structures. While tabular and linear models have been thoroughly explored, the analytical study of RL under nonlinear function approximation, especially kernel-based models, has recently gained traction for their strong representational capacity and theoretical tractability. In this context, we examine the question of statistical efficiency in kernel-based RL within the reward-free RL framework, specifically asking: how many samples are required to design a near-optimal policy? Existing work addresses this question under restrictive assumptions about the class of kernel functions. We first explore this question by assuming a generative model, then relax this assumption at the cost of increasing the sample complexity by a factor of H, the length of the episode. We tackle this fundamental problem using a broad class of kernels and a simpler algorithm compared to prior work. Our approach derives new confidence intervals for kernel ridge regression, specific to our RL setting, which may be of broader applicability. We further validate our theoretical findings through simulations.</li>
</ul>

<h3>Title: Making Language Models Robust Against Negation</h3>
<ul>
<li><strong>Authors: </strong>MohammadHossein Rezaei, Eduardo Blanco</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07717">https://arxiv.org/abs/2502.07717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07717">https://arxiv.org/pdf/2502.07717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07717]] Making Language Models Robust Against Negation(https://arxiv.org/abs/2502.07717)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Negation has been a long-standing challenge for language models. Previous studies have shown that they struggle with negation in many natural language understanding tasks. In this work, we propose a self-supervised method to make language models more robust against negation. We introduce a novel task, Next Sentence Polarity Prediction (NSPP), and a variation of the Next Sentence Prediction (NSP) task. We show that BERT and RoBERTa further pre-trained on our tasks outperform the off-the-shelf versions on nine negation-related benchmarks. Most notably, our pre-training tasks yield between 1.8% and 9.1% improvement on CondaQA, a large question-answering corpus requiring reasoning over negation.</li>
</ul>

<h3>Title: TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning</h3>
<ul>
<li><strong>Authors: </strong>Mengyang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07721">https://arxiv.org/abs/2502.07721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07721">https://arxiv.org/pdf/2502.07721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07721]] TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning(https://arxiv.org/abs/2502.07721)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The prevalence of noisy labels in real-world datasets poses a significant impediment to the effective deployment of deep learning models. While meta-learning strategies have emerged as a promising approach for addressing this challenge, existing methods often suffer from limited transferability and task-specific designs. This paper introduces TMLC-Net, a novel Transferable Meta-Learner for Correcting Noisy Labels, designed to overcome these limitations. TMLC-Net learns a general-purpose label correction strategy that can be readily applied across diverse datasets and model architectures without requiring extensive retraining or fine-tuning. Our approach integrates three core components: (1) Normalized Noise Perception, which captures and normalizes training dynamics to handle distribution shifts; (2) Time-Series Encoding, which models the temporal evolution of sample statistics using a recurrent neural network; and (3) Subclass Decoding, which predicts a corrected label distribution based on the learned representations. We conduct extensive experiments on benchmark datasets with various noise types and levels, demonstrating that TMLC-Net consistently outperforms state-of-the-art methods in terms of both accuracy and robustness to label noise. Furthermore, we analyze the transferability of TMLC-Net, showcasing its adaptability to new datasets and noise conditions, and establishing its potential as a broadly applicable solution for robust deep learning in noisy environments.</li>
</ul>

<h3>Title: EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices</h3>
<ul>
<li><strong>Authors: </strong>Camile Lendering, Bernardo Perrone Ribeiro, Å½iga EmerÅ¡iÄ, Peter Peer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07734">https://arxiv.org/abs/2502.07734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07734">https://arxiv.org/pdf/2502.07734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07734]] EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices(https://arxiv.org/abs/2502.07734)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric, transformer</a></li>
<li><strong>Abstract: </strong>Ear recognition is a contactless and unobtrusive biometric technique with applications across various domains. However, deploying high-performing ear recognition models on resource-constrained devices is challenging, limiting their applicability and widespread adoption. This paper introduces EdgeEar, a lightweight model based on a proposed hybrid CNN-transformer architecture to solve this problem. By incorporating low-rank approximations into specific linear layers, EdgeEar reduces its parameter count by a factor of 50 compared to the current state-of-the-art, bringing it below two million while maintaining competitive accuracy. Evaluation on the Unconstrained Ear Recognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the lowest EER while significantly reducing computational costs. These findings demonstrate the feasibility of efficient and accurate ear recognition, which we believe will contribute to the wider adoption of ear biometrics.</li>
</ul>

<h3>Title: Revisiting Non-Acyclic GFlowNets in Discrete Environments</h3>
<ul>
<li><strong>Authors: </strong>Nikita Morozov, Ian Maksimov, Daniil Tiapkin, Sergey Samsonov</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07735">https://arxiv.org/abs/2502.07735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07735">https://arxiv.org/pdf/2502.07735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07735]] Revisiting Non-Acyclic GFlowNets in Discrete Environments(https://arxiv.org/abs/2502.07735)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Flow Networks (GFlowNets) are a family of generative models that learn to sample objects from a given probability distribution, potentially known up to a normalizing constant. Instead of working in the object space, GFlowNets proceed by sampling trajectories in an appropriately constructed directed acyclic graph environment, greatly relying on the acyclicity of the graph. In our paper, we revisit the theory that relaxes the acyclicity assumption and present a simpler theoretical framework for non-acyclic GFlowNets in discrete environments. Moreover, we provide various novel theoretical insights related to training with fixed backward policies, the nature of flow functions, and connections between entropy-regularized RL and non-acyclic GFlowNets, which naturally generalize the respective concepts and theoretical results from the acyclic setting. In addition, we experimentally re-examine the concept of loss stability in non-acyclic GFlowNet training, as well as validate our own theoretical findings.</li>
</ul>

<h3>Title: Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling</h3>
<ul>
<li><strong>Authors: </strong>Shuhuai Ren, Shuming Ma, Xu Sun, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07737">https://arxiv.org/abs/2502.07737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07737">https://arxiv.org/pdf/2502.07737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07737]] Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling(https://arxiv.org/abs/2502.07737)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR) video generation, but it suffers from suboptimal unidirectional dependencies and slow inference speed. In this work, we propose a semi-autoregressive (semi-AR) framework, called Next-Block Prediction (NBP), for video generation. By uniformly decomposing video content into equal-sized blocks (e.g., rows or frames), we shift the generation unit from individual tokens to blocks, allowing each token in the current block to simultaneously predict the corresponding token in the next block. Unlike traditional AR modeling, our framework employs bidirectional attention within each block, enabling tokens to capture more robust spatial dependencies. By predicting multiple tokens in parallel, NBP models significantly reduce the number of generation steps, leading to faster and more efficient inference. Our model achieves FVD scores of 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by an average of 4.4. Furthermore, thanks to the reduced number of inference steps, the NBP model generates 8.89 frames (128x128 resolution) per second, achieving an 11x speedup. We also explored model scales ranging from 700M to 3B parameters, observing significant improvements in generation quality, with FVD scores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600, demonstrating the scalability of our approach.</li>
</ul>

<h3>Title: Advancing climate model interpretability: Feature attribution for Arctic melt anomalies</h3>
<ul>
<li><strong>Authors: </strong>Tolulope Ale, Nicole-Jeanne Schlegel, Vandana P. Janeja</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07741">https://arxiv.org/abs/2502.07741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07741">https://arxiv.org/pdf/2502.07741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07741]] Advancing climate model interpretability: Feature attribution for Arctic melt anomalies(https://arxiv.org/abs/2502.07741)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The focus of our work is improving the interpretability of anomalies in climate models and advancing our understanding of Arctic melt dynamics. The Arctic and Antarctic ice sheets are experiencing rapid surface melting and increased freshwater runoff, contributing significantly to global sea level rise. Understanding the mechanisms driving snowmelt in these regions is crucial. ERA5, a widely used reanalysis dataset in polar climate studies, offers extensive climate variables and global data assimilation. However, its snowmelt model employs an energy imbalance approach that may oversimplify the complexity of surface melt. In contrast, the Glacier Energy and Mass Balance (GEMB) model incorporates additional physical processes, such as snow accumulation, firn densification, and meltwater percolation/refreezing, providing a more detailed representation of surface melt dynamics. In this research, we focus on analyzing surface snowmelt dynamics of the Greenland Ice Sheet using feature attribution for anomalous melt events in ERA5 and GEMB models. We present a novel unsupervised attribution method leveraging counterfactual explanation method to analyze detected anomalies in ERA5 and GEMB. Our anomaly detection results are validated using MEaSUREs ground-truth data, and the attributions are evaluated against established feature ranking methods, including XGBoost, Shapley values, and Random Forest. Our attribution framework identifies the physics behind each model and the climate features driving melt anomalies. These findings demonstrate the utility of our attribution method in enhancing the interpretability of anomalies in climate models and advancing our understanding of Arctic melt dynamics.</li>
</ul>

<h3>Title: HiPoNet: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data</h3>
<ul>
<li><strong>Authors: </strong>Siddharth Viswanath, Hiren Madhu, Dhananjay Bhaskar, Jake Kovalic, Dave Johnson, Rex Ying, Christopher Tape, Ian Adelstein, Michael Perlmutter, Smita Krishnaswamy</a></li>
<li><strong>Subjects: </strong>cs.LG, math.AT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07746">https://arxiv.org/abs/2502.07746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07746">https://arxiv.org/pdf/2502.07746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07746]] HiPoNet: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data(https://arxiv.org/abs/2502.07746)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we propose HiPoNet, an end-to-end differentiable neural network for regression, classification, and representation learning on high-dimensional point clouds. Single-cell data can have high dimensionality exceeding the capabilities of existing methods point cloud tailored for 3D data. Moreover, modern single-cell and spatial experiments now yield entire cohorts of datasets (i.e. one on every patient), necessitating models that can process large, high-dimensional point clouds at scale. Most current approaches build a single nearest-neighbor graph, discarding important geometric information. In contrast, HiPoNet forms higher-order simplicial complexes through learnable feature reweighting, generating multiple data views that disentangle distinct biological processes. It then employs simplicial wavelet transforms to extract multi-scale features - capturing both local and global topology. We empirically show that these components preserve topological information in the learned representations, and that HiPoNet significantly outperforms state-of-the-art point-cloud and graph-based models on single cell. We also show an application of HiPoNet on spatial transcriptomics datasets using spatial co-ordinates as one of the views. Overall, HiPoNet offers a robust and scalable solution for high-dimensional data analysis.</li>
</ul>

<h3>Title: WHODUNIT: Evaluation benchmark for culprit detection in mystery stories</h3>
<ul>
<li><strong>Authors: </strong>Kshitij Gupta</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07747">https://arxiv.org/abs/2502.07747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07747">https://arxiv.org/pdf/2502.07747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07747]] WHODUNIT: Evaluation benchmark for culprit detection in mystery stories(https://arxiv.org/abs/2502.07747)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We present a novel data set, WhoDunIt, to assess the deductive reasoning capabilities of large language models (LLM) within narrative contexts. Constructed from open domain mystery novels and short stories, the dataset challenges LLMs to identify the perpetrator after reading and comprehending the story. To evaluate model robustness, we apply a range of character-level name augmentations, including original names, name swaps, and substitutions with well-known real and/or fictional entities from popular discourse. We further use various prompting styles to investigate the influence of prompting on deductive reasoning accuracy. We conduct evaluation study with state-of-the-art models, specifically GPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with majority response selection to ensure reliability. The results demonstrate that while LLMs perform reliably on unaltered texts, accuracy diminishes with certain name substitutions, particularly those with wide recognition. This dataset is publicly available here.</li>
</ul>

<h3>Title: PFedDST: Personalized Federated Learning with Decentralized Selection Training</h3>
<ul>
<li><strong>Authors: </strong>Mengchen Fan, Keren Li, Tianyun Zhang, Qing Tian, Baocheng Geng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07750">https://arxiv.org/abs/2502.07750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07750">https://arxiv.org/pdf/2502.07750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07750]] PFedDST: Personalized Federated Learning with Decentralized Selection Training(https://arxiv.org/abs/2502.07750)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Distributed Learning (DL) enables the training of machine learning models across multiple devices, yet it faces challenges like non-IID data distributions and device capability disparities, which can impede training efficiency. Communication bottlenecks further complicate traditional Federated Learning (FL) setups. To mitigate these issues, we introduce the Personalized Federated Learning with Decentralized Selection Training (PFedDST) framework. PFedDST enhances model training by allowing devices to strategically evaluate and select peers based on a comprehensive communication score. This score integrates loss, task similarity, and selection frequency, ensuring optimal peer connections. This selection strategy is tailored to increase local personalization and promote beneficial peer collaborations to strengthen the stability and efficiency of the training process. Our experiments demonstrate that PFedDST not only enhances model accuracy but also accelerates convergence. This approach outperforms state-of-the-art methods in handling data heterogeneity, delivering both faster and more effective training in diverse and decentralized systems.</li>
</ul>

<h3>Title: CausalGeD: Blending Causality and Diffusion for Spatial Gene Expression Generation</h3>
<ul>
<li><strong>Authors: </strong>Rabeya Tus Sadia, Md Atik Ahamed, Qiang Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV, q-bio.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07751">https://arxiv.org/abs/2502.07751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07751">https://arxiv.org/pdf/2502.07751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07751]] CausalGeD: Blending Causality and Diffusion for Spatial Gene Expression Generation(https://arxiv.org/abs/2502.07751)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>The integration of single-cell RNA sequencing (scRNA-seq) and spatial transcriptomics (ST) data is crucial for understanding gene expression in spatial context. Existing methods for such integration have limited performance, with structural similarity often below 60\%, We attribute this limitation to the failure to consider causal relationships between genes. We present CausalGeD, which combines diffusion and autoregressive processes to leverage these relationships. By generalizing the Causal Attention Transformer from image generation to gene expression data, our model captures regulatory mechanisms without predefined relationships. Across 10 tissue datasets, CausalGeD outperformed state-of-the-art baselines by 5- 32\% in key metrics, including Pearson's correlation and structural similarity, advancing both technical and biological insights.</li>
</ul>

<h3>Title: Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension</h3>
<ul>
<li><strong>Authors: </strong>Wenbo Gong, Meyer Scetbon, Chao Ma, Edward Meeds</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07752">https://arxiv.org/abs/2502.07752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07752">https://arxiv.org/pdf/2502.07752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07752]] Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension(https://arxiv.org/abs/2502.07752)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Designing efficient optimizers for large language models (LLMs) with low-memory requirements and fast convergence is an important and challenging problem. This paper makes a step towards the systematic design of such optimizers through the lens of structured Fisher information matrix (FIM) approximation. We show that many state-of-the-art efficient optimizers can be viewed as solutions to FIM approximation (under the Frobenius norm) with specific structural assumptions. Building on these insights, we propose two design recommendations of practical efficient optimizers for LLMs, involving the careful selection of structural assumptions to balance generality and efficiency, and enhancing memory efficiency of optimizers with general structures through a novel low-rank extension framework. We demonstrate how to use each design approach by deriving new memory-efficient optimizers: Row and Column Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation (Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the effectiveness, showing faster and better convergence than existing memory-efficient baselines and Adam with little memory overhead. Notably, Alice achieves better than 2x faster convergence over Adam, while RACS delivers strong performance on the 1B model with SGD-like memory.</li>
</ul>

<h3>Title: Direct Ascent Synthesis: Revealing Hidden Generative Capabilities in Discriminative Models</h3>
<ul>
<li><strong>Authors: </strong>Stanislav Fort, Jonathan Whitaker</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07753">https://arxiv.org/abs/2502.07753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07753">https://arxiv.org/pdf/2502.07753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07753]] Direct Ascent Synthesis: Revealing Hidden Generative Capabilities in Discriminative Models(https://arxiv.org/abs/2502.07753)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, generative</a></li>
<li><strong>Abstract: </strong>We demonstrate that discriminative models inherently contain powerful generative capabilities, challenging the fundamental distinction between discriminative and generative architectures. Our method, Direct Ascent Synthesis (DAS), reveals these latent capabilities through multi-resolution optimization of CLIP model representations. While traditional inversion attempts produce adversarial patterns, DAS achieves high-quality image synthesis by decomposing optimization across multiple spatial scales (1x1 to 224x224), requiring no additional training. This approach not only enables diverse applications -- from text-to-image generation to style transfer -- but maintains natural image statistics ($1/f^2$ spectrum) and guides the generation away from non-robust adversarial patterns. Our results demonstrate that standard discriminative models encode substantially richer generative knowledge than previously recognized, providing new perspectives on model interpretability and the relationship between adversarial examples and natural image synthesis.</li>
</ul>

<h3>Title: An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Ali Labbaf Khaniki, Sahabeh Saadati, Mohammad Manthouri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07755">https://arxiv.org/abs/2502.07755</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07755">https://arxiv.org/pdf/2502.07755</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07755]] An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating(https://arxiv.org/abs/2502.07755)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>This paper presents a novel Natural Language Processing (NLP) framework for enhancing medical diagnosis through the integration of advanced techniques in data augmentation, feature extraction, and classification. The proposed approach employs back-translation to generate diverse paraphrased datasets, improving robustness and mitigating overfitting in classification tasks. Leveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with Dynamic Contextual Positional Gating (DCPG), the model captures fine-grained contextual and positional relationships, dynamically adjusting the influence of positional information based on semantic context to produce high-quality text embeddings. For classification, an Attention-Based Feedforward Neural Network (ABFNN) is utilized, effectively focusing on the most relevant features to improve decision-making accuracy. Applied to the classification of symptoms, clinical notes, and other medical texts, this architecture demonstrates its ability to address the complexities of medical data. The combination of data augmentation, contextual embedding generation, and advanced classification mechanisms offers a robust and accurate diagnostic tool, with potential applications in automated medical diagnosis and clinical decision support. This method demonstrates the effectiveness of the proposed NLP framework for medical diagnosis, achieving remarkable results with an accuracy of 99.78%, recall of 99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not only underscore the model's robust performance in classifying medical texts with exceptional precision and reliability but also highlight its superiority over existing methods, making it a highly promising tool for automated diagnostic systems.</li>
</ul>

<h3>Title: Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras</h3>
<ul>
<li><strong>Authors: </strong>Nektarios A. Valous, Eckhard Hitzer, DragoÅ DuÅe, Rodrigo Rojas Moraleda, Ferdinand Popp, Meggy Suarez-Carmona, Anna Berthel, Ismini Papageorgiou, Carlo Fremd, Alexander RÃ¶lle, Christina C. Westhoff, BÃ©nÃ©dicte Lenoir, Niels Halama, Inka ZÃ¶rnig, Dirk JÃ¤ger</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07758">https://arxiv.org/abs/2502.07758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07758">https://arxiv.org/pdf/2502.07758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07758]] Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras(https://arxiv.org/abs/2502.07758)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hypercomplex image processing extends conventional techniques in a unified paradigm encompassing algebraic and geometric principles. This work leverages quaternions and the two-dimensional orthogonal planes split framework (splitting of a quaternion - representing a pixel - into pairs of orthogonal 2D planes) for natural/biomedical image analysis through the following computational workflows and outcomes: natural/biomedical image re-colorization, natural image de-colorization, natural/biomedical image contrast enhancement, computational re-staining and stain separation in histological images, and performance gains in machine/deep learning pipelines for histological images. The workflows are analyzed separately for natural and biomedical images to showcase the effectiveness of the proposed approaches. The proposed workflows can regulate color appearance (e.g. with alternative renditions and grayscale conversion) and image contrast, be part of automated image processing pipelines (e.g. isolating stain components, boosting learning models), and assist in digital pathology applications (e.g. enhancing biomarker visibility, enabling colorblind-friendly renditions). Employing only basic arithmetic and matrix operations, this work offers a computationally accessible methodology - in the hypercomplex domain - that showcases versatility and consistency across image processing tasks and a range of computer vision and biomedical applications. The proposed non-data-driven methods achieve comparable or better results (particularly in cases involving well-known methods) to those reported in the literature, showcasing the potential of robust theoretical frameworks with practical effectiveness. Results, methods, and limitations are detailed alongside discussion of promising extensions, emphasizing the potential of feature-rich mathematical/computational frameworks for natural and biomedical images.</li>
</ul>

<h3>Title: Scalable Fingerprinting of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anshul Nasery, Jonathan Hayase, Creston Brooks, Peiyao Sheng, Himanshu Tyagi, Pramod Viswanath, Sewoong Oh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07760">https://arxiv.org/abs/2502.07760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07760">https://arxiv.org/pdf/2502.07760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07760]] Scalable Fingerprinting of Large Language Models(https://arxiv.org/abs/2502.07760)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Model fingerprinting has emerged as a powerful tool for model owners to identify their shared model given API access. However, to lower false discovery rate, fight fingerprint leakage, and defend against coalitions of model users attempting to bypass detection, we argue that {\em scalability} is critical, i.e., scaling up the number of fingerprints one can embed into a model. Hence, we pose scalability as a crucial requirement for fingerprinting schemes. We experiment with fingerprint design at a scale significantly larger than previously considered, and introduce a new method, dubbed Perinucleus sampling, to generate scalable, persistent, and harmless fingerprints. We demonstrate that this scheme can add 24,576 fingerprints to a Llama-3.1-8B model -- two orders of magnitude more than existing schemes -- without degrading the model's utility. Our inserted fingerprints persist even after supervised fine-tuning on standard post-training data. We further address security risks for fingerprinting, and theoretically and empirically show how a scalable fingerprinting scheme like ours can mitigate these risks.</li>
</ul>

<h3>Title: Auditing Prompt Caching in Language Model APIs</h3>
<ul>
<li><strong>Authors: </strong>Chenchen Gu, Xiang Lisa Li, Rohith Kuditipudi, Percy Liang, Tatsunori Hashimoto</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07776">https://arxiv.org/abs/2502.07776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07776">https://arxiv.org/pdf/2502.07776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07776]] Auditing Prompt Caching in Language Model APIs(https://arxiv.org/abs/2502.07776)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Prompt caching in large language models (LLMs) results in data-dependent timing variations: cached prompts are processed faster than non-cached prompts. These timing differences introduce the risk of side-channel timing attacks. For example, if the cache is shared across users, an attacker could identify cached prompts from fast API response times to learn information about other users' prompts. Because prompt caching may cause privacy leakage, transparency around the caching policies of API providers is important. To this end, we develop and conduct statistical audits to detect prompt caching in real-world LLM API providers. We detect global cache sharing across users in seven API providers, including OpenAI, resulting in potential privacy leakage about users' prompts. Timing variations due to prompt caching can also result in leakage of information about model architecture. Namely, we find evidence that OpenAI's embedding model is a decoder-only Transformer, which was previously not publicly known.</li>
</ul>

<h3>Title: Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Anirudh Sundara Rajan, Yong Jae Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07778">https://arxiv.org/abs/2502.07778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07778">https://arxiv.org/pdf/2502.07778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07778]] Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection(https://arxiv.org/abs/2502.07778)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Detecting AI generated images is a challenging yet essential task. A primary difficulty arises from the detectors tendency to rely on spurious patterns, such as compression artifacts, which can influence its decisions. These issues often stem from specific patterns that the detector associates with the real data distribution, making it difficult to isolate the actual generative traces. We argue that an image should be classified as fake if and only if it contains artifacts introduced by the generative model. Based on this premise, we propose Stay Positive, an algorithm designed to constrain the detectors focus to generative artifacts while disregarding those associated with real data. Experimental results demonstrate that detectors trained with Stay Positive exhibit reduced susceptibility to spurious correlations, leading to improved generalization and robustness to post processing. Additionally, unlike detectors that associate artifacts with real images, those that focus purely on fake artifacts are better at detecting inpainted real images.</li>
</ul>

<h3>Title: DarwinLM: Evolutionary Structured Pruning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shengkun Tang, Oliver Sieberling, Eldar Kurtic, Zhiqiang Shen, Dan Alistarh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07780">https://arxiv.org/abs/2502.07780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07780">https://arxiv.org/pdf/2502.07780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07780]] DarwinLM: Evolutionary Structured Pruning of Large Language Models(https://arxiv.org/abs/2502.07780)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved significant success across various NLP tasks. However, their massive computational costs limit their widespread use, particularly in real-time applications. Structured pruning offers an effective solution by compressing models and directly providing end-to-end speed improvements, regardless of the hardware environment. Meanwhile, different components of the model exhibit varying sensitivities towards pruning, calling for \emph{non-uniform} model compression. However, a pruning method should not only identify a capable substructure, but also account for post-compression training. To this end, we propose \sysname, a method for \emph{training-aware} structured pruning. \sysname builds upon an evolutionary search process, generating multiple offspring models in each generation through mutation, and selecting the fittest for survival. To assess the effect of post-training, we incorporate a lightweight, multistep training process within the offspring population, progressively increasing the number of tokens and eliminating poorly performing models in each selection stage. We validate our method through extensive experiments on Llama-2-7B, Llama-3.1-8B and Qwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured pruning. For instance, \sysname surpasses ShearedLlama while requiring $5\times$ less training data during post-compression training.</li>
</ul>

<h3>Title: Curvature Tuning: Provable Training-free Model Steering From a Single Parameter</h3>
<ul>
<li><strong>Authors: </strong>Leyang Hu, Randall Balestriero</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07783">https://arxiv.org/abs/2502.07783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07783">https://arxiv.org/pdf/2502.07783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07783]] Curvature Tuning: Provable Training-free Model Steering From a Single Parameter(https://arxiv.org/abs/2502.07783)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>The scaling of model size and data size has reshaped the paradigm of AI. As a result, the common protocol to leverage the latest models is to steer them towards a specific downstream task of interest through {\em fine-tuning}. Despite its importance, the main methods for fine-tuning remain limited to full or low-rank adapters--containing countless hyper-parameters and lacking interpretability. In this paper, we take a step back and demonstrate how novel and explainable post-training steering solutions can be derived theoretically from {\em spline operators}, a rich mathematical framing of Deep Networks that was recently developed. Our method--coined \textbf{Curvature Tuning (CT)}--has a single parameter that provably modulates the curvature of the model's decision boundary henceforth allowing training-free steering. This makes CT both more efficient and interpretable than conventional fine-tuning methods. We empirically validate its effectiveness in improving generalization and robustness of pretrained models. For example, CT improves out-of-distribution transfer performances of ResNet-18/50 by 2.57\%/1.74\% across seventeen downstream datasets, and improves RobustBench robust accuracy by 11.76\%/348.44\%. Additionally, we apply CT to ReLU-based Swin-T/S, improving their generalization on nine downstream datasets by 2.43\%/3.33\%. Our code is available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: MatSwap: Light-aware material transfers in images</h3>
<ul>
<li><strong>Authors: </strong>Ivan Lopes, Valentin Deschaintre, Yannick Hold-Geoffroy, Raoul de Charette</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07784">https://arxiv.org/abs/2502.07784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07784">https://arxiv.org/pdf/2502.07784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07784]] MatSwap: Light-aware material transfers in images(https://arxiv.org/abs/2502.07784)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present MatSwap, a method to transfer materials to designated surfaces in an image photorealistically. Such a task is non-trivial due to the large entanglement of material appearance, geometry, and lighting in a photograph. In the literature, material editing methods typically rely on either cumbersome text engineering or extensive manual annotations requiring artist knowledge and 3D scene properties that are impractical to obtain. In contrast, we propose to directly learn the relationship between the input material -- as observed on a flat surface -- and its appearance within the scene, without the need for explicit UV mapping. To achieve this, we rely on a custom light- and geometry-aware diffusion model. We fine-tune a large-scale pre-trained text-to-image model for material transfer using our synthetic dataset, preserving its strong priors to ensure effective generalization to real images. As a result, our method seamlessly integrates a desired material into the target location in the photograph while retaining the identity of the scene. We evaluate our method on synthetic and real images and show that it compares favorably to recent work both qualitatively and quantitatively. We will release our code and data upon publication.</li>
</ul>

<h3>Title: Pippo: High-Resolution Multi-View Humans from a Single Image</h3>
<ul>
<li><strong>Authors: </strong>Yash Kant, Ethan Weber, Jin Kyu Kim, Rawal Khirodkar, Su Zhaoen, Julieta Martinez, Igor Gilitschenski, Shunsuke Saito, Timur Bagautdinov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.07785">https://arxiv.org/abs/2502.07785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.07785">https://arxiv.org/pdf/2502.07785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.07785]] Pippo: High-Resolution Multi-View Humans from a Single Image(https://arxiv.org/abs/2502.07785)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>We present Pippo, a generative model capable of producing 1K resolution dense turnaround videos of a person from a single casually clicked photo. Pippo is a multi-view diffusion transformer and does not require any additional inputs - e.g., a fitted parametric model or camera parameters of the input image. We pre-train Pippo on 3B human images without captions, and conduct multi-view mid-training and post-training on studio captured humans. During mid-training, to quickly absorb the studio dataset, we denoise several (up to 48) views at low-resolution, and encode target cameras coarsely using a shallow MLP. During post-training, we denoise fewer views at high-resolution and use pixel-aligned controls (e.g., Spatial anchor and Plucker rays) to enable 3D consistent generations. At inference, we propose an attention biasing technique that allows Pippo to simultaneously generate greater than 5 times as many views as seen during training. Finally, we also introduce an improved metric to evaluate 3D consistency of multi-view generations, and show that Pippo outperforms existing works on multi-view human generation from a single image.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
