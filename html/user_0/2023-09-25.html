<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Towards a Near-real-time Protocol Tunneling Detector based on Machine Learning Techniques. (arXiv:2309.12720v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12720">http://arxiv.org/abs/2309.12720</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12720]] Towards a Near-real-time Protocol Tunneling Detector based on Machine Learning Techniques(http://arxiv.org/abs/2309.12720)</code></li>
<li>Summary: <p>In the very last years, cybersecurity attacks have increased at an
unprecedented pace, becoming ever more sophisticated and costly. Their impact
has involved both private/public companies and critical infrastructures. At the
same time, due to the COVID-19 pandemic, the security perimeters of many
organizations expanded, causing an increase of the attack surface exploitable
by threat actors through malware and phishing attacks. Given these factors, it
is of primary importance to monitor the security perimeter and the events
occurring in the monitored network, according to a tested security strategy of
detection and response. In this paper, we present a protocol tunneling detector
prototype which inspects, in near real time, a company's network traffic using
machine learning techniques. Indeed, tunneling attacks allow malicious actors
to maximize the time in which their activity remains undetected. The detector
monitors unencrypted network flows and extracts features to detect possible
occurring attacks and anomalies, by combining machine learning and deep
learning. The proposed module can be embedded in any network security
monitoring platform able to provide network flow information along with its
metadata. The detection capabilities of the implemented prototype have been
tested both on benign and malicious datasets. Results show 97.1% overall
accuracy and an F1-score equals to 95.6%.
</p></li>
</ul>

<h3>Title: A New Security Threat in MCUs -- SoC-wide timing side channels and how to find them. (arXiv:2309.12925v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12925">http://arxiv.org/abs/2309.12925</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12925]] A New Security Threat in MCUs -- SoC-wide timing side channels and how to find them(http://arxiv.org/abs/2309.12925)</code></li>
<li>Summary: <p>Microarchitectural timing side channels have been thoroughly investigated as
a security threat in hardware designs featuring shared buffers (e.g., caches)
and/or parallelism between attacker and victim task execution. Contradicting
common intuitions, recent activities demonstrate, however, that this threat is
real also in microcontroller SoCs without such features. In this paper, we
describe SoC-wide timing side channels previously neglected by security
analysis and present a new formal method to close this gap. In a case study
with the RISC-V Pulpissimo SoC platform, our method found a vulnerability to a
so far unknown attack variant that allows an attacker to obtain information
about a victim's memory access behavior. After implementing a conservative fix,
we were able to verify that the SoC is now secure w.r.t. timing side channels.
</p></li>
</ul>

<h3>Title: Current file Overview PassViz: A Visualisation System for Analysing Leaked Passwords. (arXiv:2309.12968v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12968">http://arxiv.org/abs/2309.12968</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12968]] Current file Overview PassViz: A Visualisation System for Analysing Leaked Passwords(http://arxiv.org/abs/2309.12968)</code></li>
<li>Summary: <p>Passwords remain the most widely used form of user authentication, despite
advancements in other methods. However, their limitations, such as
susceptibility to attacks, especially weak passwords defined by human users,
are well-documented. The existence of weak human-defined passwords has led to
repeated password leaks from websites, many of which are of large scale. While
such password leaks are unfortunate security incidents, they provide security
researchers and practitioners with good opportunities to learn valuable
insights from such leaked passwords, in order to identify ways to improve
password policies and other security controls on passwords. Researchers have
proposed different data visualisation techniques to help analyse leaked
passwords. However, many approaches rely solely on frequency analysis, with
limited exploration of distance-based graphs. This paper reports PassViz, a
novel method that combines the edit distance with the t-SNE (t-distributed
stochastic neighbour embedding) dimensionality reduction algorithm for
visualising and analysing leaked passwords in a 2-D space. We implemented
PassViz as an easy-to-use command-line tool for visualising large-scale
password databases, and also as a graphical user interface (GUI) to support
interactive visual analytics of small password databases. Using the
"000webhost" leaked database as an example, we show how PassViz can be used to
visually analyse different aspects of leaked passwords and to facilitate the
discovery of previously unknown password patterns. Overall, our approach
empowers researchers and practitioners to gain valuable insights and improve
password security through effective data visualisation and analysis.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception?. (arXiv:2309.13038v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13038">http://arxiv.org/abs/2309.13038</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13038]] Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception?(http://arxiv.org/abs/2309.13038)</code></li>
<li>Summary: <p>Hand-crafted image quality metrics, such as PSNR and SSIM, are commonly used
to evaluate model privacy risk under reconstruction attacks. Under these
metrics, reconstructed images that are determined to resemble the original one
generally indicate more privacy leakage. Images determined as overall
dissimilar, on the other hand, indicate higher robustness against attack.
However, there is no guarantee that these metrics well reflect human opinions,
which, as a judgement for model privacy leakage, are more trustworthy. In this
paper, we comprehensively study the faithfulness of these hand-crafted metrics
to human perception of privacy information from the reconstructed images. On 5
datasets ranging from natural images, faces, to fine-grained classes, we use 4
existing attack methods to reconstruct images from many different
classification models and, for each reconstructed image, we ask multiple human
annotators to assess whether this image is recognizable. Our studies reveal
that the hand-crafted metrics only have a weak correlation with the human
evaluation of privacy leakage and that even these metrics themselves often
contradict each other. These observations suggest risks of current metrics in
the community. To address this potential risk, we propose a learning-based
measure called SemSim to evaluate the Semantic Similarity between the original
and reconstructed images. SemSim is trained with a standard triplet loss, using
an original image as an anchor, one of its recognizable reconstructed images as
a positive sample, and an unrecognizable one as a negative. By training on
human annotations, SemSim exhibits a greater reflection of privacy leakage on
the semantic level. We show that SemSim has a significantly higher correlation
with human judgment compared with existing metrics. Moreover, this strong
correlation generalizes to unseen datasets, models and attack methods.
</p></li>
</ul>

<h3>Title: A Toolchain for Privacy-Preserving Distributed Aggregation on Edge-Devices. (arXiv:2309.12483v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12483">http://arxiv.org/abs/2309.12483</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12483]] A Toolchain for Privacy-Preserving Distributed Aggregation on Edge-Devices(http://arxiv.org/abs/2309.12483)</code></li>
<li>Summary: <p>Valuable insights, such as frequently visited environments in the wake of the
COVID-19 pandemic, can oftentimes only be gained by analyzing sensitive data
spread across edge-devices like smartphones. To facilitate such an analysis, we
present a toolchain for a distributed, privacy-preserving aggregation of local
data by taking the limited resources of edge-devices into account. The
distributed aggregation is based on secure summation and simultaneously
satisfies the notion of differential privacy. In this way, other parties can
neither learn the sensitive data of single clients nor a single client's
influence on the final result. We perform an evaluation of the power
consumption, the running time and the bandwidth overhead on real as well as
simulated devices and demonstrate the flexibility of our toolchain by
presenting an extension of the summation of histograms to distributed
clustering.
</p></li>
</ul>

<h3>Title: Truncated Laplace and Gaussian mechanisms of RDP. (arXiv:2309.12647v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12647">http://arxiv.org/abs/2309.12647</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12647]] Truncated Laplace and Gaussian mechanisms of RDP(http://arxiv.org/abs/2309.12647)</code></li>
<li>Summary: <p>The Laplace mechanism and the Gaussian mechanism are primary mechanisms in
differential privacy, widely applicable to many scenarios involving numerical
data. However, due to the infinite-range random variables they generate, the
Laplace and Gaussian mechanisms may return values that are semantically
impossible, such as negative numbers. To address this issue, we have designed
the truncated Laplace mechanism and Gaussian mechanism. For a given truncation
interval [a, b], the truncated Gaussian mechanism ensures the same Renyi
Differential Privacy (RDP) as the untruncated mechanism, regardless of the
values chosen for the truncation interval [a, b]. Similarly, the truncated
Laplace mechanism, for specified interval [a, b], maintains the same RDP as the
untruncated mechanism. We provide the RDP expressions for each of them. We
believe that our study can further enhance the utility of differential privacy
in specific applications.
</p></li>
</ul>

<h3>Title: Understanding Deep Gradient Leakage via Inversion Influence Functions. (arXiv:2309.13016v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13016">http://arxiv.org/abs/2309.13016</a></li>
<li>Code URL: https://github.com/illidanlab/inversion-influence-function</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13016]] Understanding Deep Gradient Leakage via Inversion Influence Functions(http://arxiv.org/abs/2309.13016)</code></li>
<li>Summary: <p>Deep Gradient Leakage (DGL) is a highly effective attack that recovers
private training images from gradient vectors. This attack casts significant
privacy challenges on distributed learning from clients with sensitive data,
where clients are required to share gradients. Defending against such attacks
requires but lacks an understanding of when and how privacy leakage happens,
mostly because of the black-box nature of deep networks. In this paper, we
propose a novel Inversion Influence Function (I$^2$F) that establishes a
closed-form connection between the recovered images and the private gradients
by implicitly solving the DGL problem. Compared to directly solving DGL, I$^2$F
is scalable for analyzing deep networks, requiring only oracle access to
gradients and Jacobian-vector products. We empirically demonstrate that I$^2$F
effectively approximated the DGL generally on different model architectures,
datasets, attack implementations, and noise-based defenses. With this novel
tool, we provide insights into effective gradient perturbation directions, the
unfairness of privacy protection, and privacy-preferred model initialization.
Our codes are provided in
https://github.com/illidanlab/inversion-influence-function.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures. (arXiv:2309.12955v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12955">http://arxiv.org/abs/2309.12955</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12955]] On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures(http://arxiv.org/abs/2309.12955)</code></li>
<li>Summary: <p>Collaborative perception, which greatly enhances the sensing capability of
connected and autonomous vehicles (CAVs) by incorporating data from external
resources, also brings forth potential security risks. CAVs' driving decisions
rely on remote untrusted data, making them susceptible to attacks carried out
by malicious participants in the collaborative perception system. However,
security analysis and countermeasures for such threats are absent. To
understand the impact of the vulnerability, we break the ground by proposing
various real-time data fabrication attacks in which the attacker delivers
crafted malicious data to victims in order to perturb their perception results,
leading to hard brakes or increased collision risks. Our attacks demonstrate a
high success rate of over 86\% on high-fidelity simulated scenarios and are
realizable in real-world experiments. To mitigate the vulnerability, we present
a systematic anomaly detection approach that enables benign vehicles to jointly
reveal malicious fabrication. It detects 91.5% of attacks with a false positive
rate of 3% in simulated scenarios and significantly mitigates attack impacts in
real-world scenarios.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Synthetic Image Detection: Highlights from the IEEE Video and Image Processing Cup 2022 Student Competition. (arXiv:2309.12428v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12428">http://arxiv.org/abs/2309.12428</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12428]] Synthetic Image Detection: Highlights from the IEEE Video and Image Processing Cup 2022 Student Competition(http://arxiv.org/abs/2309.12428)</code></li>
<li>Summary: <p>The Video and Image Processing (VIP) Cup is a student competition that takes
place each year at the IEEE International Conference on Image Processing. The
2022 IEEE VIP Cup asked undergraduate students to develop a system capable of
distinguishing pristine images from generated ones. The interest in this topic
stems from the incredible advances in the AI-based generation of visual data,
with tools that allows the synthesis of highly realistic images and videos.
While this opens up a large number of new opportunities, it also undermines the
trustworthiness of media content and fosters the spread of disinformation on
the internet. Recently there was strong concern about the generation of
extremely realistic images by means of editing software that includes the
recent technology on diffusion models. In this context, there is a need to
develop robust and automatic tools for synthetic image detection.
</p></li>
</ul>

<h3>Title: Multimodal Deep Learning for Scientific Imaging Interpretation. (arXiv:2309.12460v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12460">http://arxiv.org/abs/2309.12460</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12460]] Multimodal Deep Learning for Scientific Imaging Interpretation(http://arxiv.org/abs/2309.12460)</code></li>
<li>Summary: <p>In the domain of scientific imaging, interpreting visual data often demands
an intricate combination of human expertise and deep comprehension of the
subject materials. This study presents a novel methodology to linguistically
emulate and subsequently evaluate human-like interactions with Scanning
Electron Microscopy (SEM) images, specifically of glass materials. Leveraging a
multimodal deep learning framework, our approach distills insights from both
textual and visual data harvested from peer-reviewed articles, further
augmented by the capabilities of GPT-4 for refined data synthesis and
evaluation. Despite inherent challenges--such as nuanced interpretations and
the limited availability of specialized datasets--our model (GlassLLaVA) excels
in crafting accurate interpretations, identifying key features, and detecting
defects in previously unseen SEM images. Moreover, we introduce versatile
evaluation metrics, suitable for an array of scientific imaging applications,
which allows for benchmarking against research-grounded answers. Benefiting
from the robustness of contemporary Large Language Models, our model adeptly
aligns with insights from research papers. This advancement not only
underscores considerable progress in bridging the gap between human and machine
interpretation in scientific imaging, but also hints at expansive avenues for
future research and broader application.
</p></li>
</ul>

<h3>Title: Impact of architecture on robustness and interpretability of multispectral deep neural networks. (arXiv:2309.12463v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12463">http://arxiv.org/abs/2309.12463</a></li>
<li>Code URL: https://github.com/hendrycks/robustness</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12463]] Impact of architecture on robustness and interpretability of multispectral deep neural networks(http://arxiv.org/abs/2309.12463)</code></li>
<li>Summary: <p>Including information from additional spectral bands (e.g., near-infrared)
can improve deep learning model performance for many vision-oriented tasks.
There are many possible ways to incorporate this additional information into a
deep learning model, but the optimal fusion strategy has not yet been
determined and can vary between applications. At one extreme, known as "early
fusion," additional bands are stacked as extra channels to obtain an input
image with more than three channels. At the other extreme, known as "late
fusion," RGB and non-RGB bands are passed through separate branches of a deep
learning model and merged immediately before a final classification or
segmentation layer. In this work, we characterize the performance of a suite of
multispectral deep learning models with different fusion approaches, quantify
their relative reliance on different input bands and evaluate their robustness
to naturalistic image corruptions affecting one or more input channels.
</p></li>
</ul>

<h3>Title: Improving Machine Learning Robustness via Adversarial Training. (arXiv:2309.12593v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12593">http://arxiv.org/abs/2309.12593</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12593]] Improving Machine Learning Robustness via Adversarial Training(http://arxiv.org/abs/2309.12593)</code></li>
<li>Summary: <p>As Machine Learning (ML) is increasingly used in solving various tasks in
real-world applications, it is crucial to ensure that ML algorithms are robust
to any potential worst-case noises, adversarial attacks, and highly unusual
situations when they are designed. Studying ML robustness will significantly
help in the design of ML algorithms. In this paper, we investigate ML
robustness using adversarial training in centralized and decentralized
environments, where ML training and testing are conducted in one or multiple
computers. In the centralized environment, we achieve a test accuracy of 65.41%
and 83.0% when classifying adversarial examples generated by Fast Gradient Sign
Method and DeepFool, respectively. Comparing to existing studies, these results
demonstrate an improvement of 18.41% for FGSM and 47% for DeepFool. In the
decentralized environment, we study Federated learning (FL) robustness by using
adversarial training with independent and identically distributed (IID) and
non-IID data, respectively, where CIFAR-10 is used in this research. In the IID
data case, our experimental results demonstrate that we can achieve such a
robust accuracy that it is comparable to the one obtained in the centralized
environment. Moreover, in the non-IID data case, the natural accuracy drops
from 66.23% to 57.82%, and the robust accuracy decreases by 25% and 23.4% in
C&amp;W and Projected Gradient Descent (PGD) attacks, compared to the IID data
case, respectively. We further propose an IID data-sharing approach, which
allows for increasing the natural accuracy to 85.04% and the robust accuracy
from 57% to 72% in C&amp;W attacks and from 59% to 67% in PGD attacks.
</p></li>
</ul>

<h3>Title: On Sparse Modern Hopfield Model. (arXiv:2309.12673v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12673">http://arxiv.org/abs/2309.12673</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12673]] On Sparse Modern Hopfield Model(http://arxiv.org/abs/2309.12673)</code></li>
<li>Summary: <p>We introduce the sparse modern Hopfield model as a sparse extension of the
modern Hopfield model. Like its dense counterpart, the sparse modern Hopfield
model equips a memory-retrieval dynamics whose one-step approximation
corresponds to the sparse attention mechanism. Theoretically, our key
contribution is a principled derivation of a closed-form sparse Hopfield energy
using the convex conjugate of the sparse entropic regularizer. Building upon
this, we derive the sparse memory retrieval dynamics from the sparse energy
function and show its one-step approximation is equivalent to the
sparse-structured attention. Importantly, we provide a sparsity-dependent
memory retrieval error bound which is provably tighter than its dense analog.
The conditions for the benefits of sparsity to arise are therefore identified
and discussed. In addition, we show that the sparse modern Hopfield model
maintains the robust theoretical properties of its dense counterpart, including
rapid fixed point convergence and exponential memory capacity. Empirically, we
use both synthetic and real-world datasets to demonstrate that the sparse
Hopfield model outperforms its dense counterpart in many situations.
</p></li>
</ul>

<h3>Title: HANS, are you clever? Clever Hans Effect Analysis of Neural Systems. (arXiv:2309.12481v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12481">http://arxiv.org/abs/2309.12481</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12481]] HANS, are you clever? Clever Hans Effect Analysis of Neural Systems(http://arxiv.org/abs/2309.12481)</code></li>
<li>Summary: <p>Instruction-tuned Large Language Models (It-LLMs) have been exhibiting
outstanding abilities to reason around cognitive states, intentions, and
reactions of all people involved, letting humans guide and comprehend
day-to-day social interactions effectively. In fact, several multiple-choice
questions (MCQ) benchmarks have been proposed to construct solid assessments of
the models' abilities. However, earlier works are demonstrating the presence of
inherent "order bias" in It-LLMs, posing challenges to the appropriate
evaluation. In this paper, we investigate It-LLMs' resilience abilities towards
a series of probing tests using four MCQ benchmarks. Introducing adversarial
examples, we show a significant performance gap, mainly when varying the order
of the choices, which reveals a selection bias and brings into discussion
reasoning abilities. Following a correlation between first positions and model
choices due to positional bias, we hypothesized the presence of structural
heuristics in the decision-making process of the It-LLMs, strengthened by
including significant examples in few-shot scenarios. Finally, by using the
Chain-of-Thought (CoT) technique, we elicit the model to reason and mitigate
the bias by obtaining more robust models.
</p></li>
</ul>

<h3>Title: Semantic similarity prediction is better than other semantic similarity measures. (arXiv:2309.12697v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12697">http://arxiv.org/abs/2309.12697</a></li>
<li>Code URL: https://github.com/aieng-lab/stsscore</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12697]] Semantic similarity prediction is better than other semantic similarity measures(http://arxiv.org/abs/2309.12697)</code></li>
<li>Summary: <p>Semantic similarity between natural language texts is typically measured
either by looking at the overlap between subsequences (e.g., BLEU) or by using
embeddings (e.g., BERTScore, S-BERT). Within this paper, we argue that when we
are only interested in measuring the semantic similarity, it is better to
directly predict the similarity using a fine-tuned model for such a task. Using
a fine-tuned model for the STS-B from the GLUE benchmark, we define the
STSScore approach and show that the resulting similarity is better aligned with
our expectations on a robust semantic similarity measure than other approaches.
</p></li>
</ul>

<h3>Title: Audience-specific Explanations for Machine Translation. (arXiv:2309.12998v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12998">http://arxiv.org/abs/2309.12998</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12998]] Audience-specific Explanations for Machine Translation(http://arxiv.org/abs/2309.12998)</code></li>
<li>Summary: <p>In machine translation, a common problem is that the translation of certain
words even if translated can cause incomprehension of the target language
audience due to different cultural backgrounds. A solution to solve this
problem is to add explanations for these words. In a first step, we therefore
need to identify these words or phrases. In this work we explore techniques to
extract example explanations from a parallel corpus. However, the sparsity of
sentences containing words that need to be explained makes building the
training dataset extremely difficult. In this work, we propose a semi-automatic
technique to extract these explanations from a large parallel corpus.
Experiments on English-&gt;German language pair show that our method is able to
extract sentence so that more than 10% of the sentences contain explanation,
while only 1.9% of the original sentences contain explanations. In addition,
experiments on English-&gt;French and English-&gt;Chinese language pairs also show
similar conclusions. This is therefore an essential first automatic step to
create a explanation dataset. Furthermore we show that the technique is robust
for all three language pairs.
</p></li>
</ul>

<h3>Title: Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation. (arXiv:2309.12545v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12545">http://arxiv.org/abs/2309.12545</a></li>
<li>Code URL: https://github.com/junqi-jiang/proplace</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12545]] Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation(http://arxiv.org/abs/2309.12545)</code></li>
<li>Summary: <p>Counterfactual Explanations (CEs) have received increasing interest as a
major methodology for explaining neural network classifiers. Usually, CEs for
an input-output pair are defined as data points with minimum distance to the
input that are classified with a different label than the output. To tackle the
established problem that CEs are easily invalidated when model parameters are
updated (e.g. retrained), studies have proposed ways to certify the robustness
of CEs under model parameter changes bounded by a norm ball. However, existing
methods targeting this form of robustness are not sound or complete, and they
may generate implausible CEs, i.e., outliers wrt the training dataset. In fact,
no existing method simultaneously optimises for proximity and plausibility
while preserving robustness guarantees. In this work, we propose Provably
RObust and PLAusible Counterfactual Explanations (PROPLACE), a method
leveraging on robust optimisation techniques to address the aforementioned
limitations in the literature. We formulate an iterative algorithm to compute
provably robust CEs and prove its convergence, soundness and completeness.
Through a comparative experiment involving six baselines, five of which target
robustness, we show that PROPLACE achieves state-of-the-art performances
against metrics on three evaluation aspects.
</p></li>
</ul>

<h3>Title: Zero-Regret Performative Prediction Under Inequality Constraints. (arXiv:2309.12618v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12618">http://arxiv.org/abs/2309.12618</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12618]] Zero-Regret Performative Prediction Under Inequality Constraints(http://arxiv.org/abs/2309.12618)</code></li>
<li>Summary: <p>Performative prediction is a recently proposed framework where predictions
guide decision-making and hence influence future data distributions. Such
performative phenomena are ubiquitous in various areas, such as transportation,
finance, public policy, and recommendation systems. To date, work on
performative prediction has only focused on unconstrained scenarios, neglecting
the fact that many real-world learning problems are subject to constraints.
This paper bridges this gap by studying performative prediction under
inequality constraints. Unlike most existing work that provides only
performative stable points, we aim to find the optimal solutions. Anticipating
performative gradients is a challenging task, due to the agnostic performative
effect on data distributions. To address this issue, we first develop a robust
primal-dual framework that requires only approximate gradients up to a certain
accuracy, yet delivers the same order of performance as the stochastic
primal-dual algorithm without performativity. Based on this framework, we then
propose an adaptive primal-dual algorithm for location families. Our analysis
demonstrates that the proposed adaptive primal-dual algorithm attains
$\ca{O}(\sqrt{T})$ regret and constraint violations, using only $\sqrt{T} + 2T$
samples, where $T$ is the time horizon. To our best knowledge, this is the
first study and analysis on the optimality of the performative prediction
problem under inequality constraints. Finally, we validate the effectiveness of
our algorithm and theoretical results through numerical simulations.
</p></li>
</ul>

<h3>Title: Sequential Action-Induced Invariant Representation for Reinforcement Learning. (arXiv:2309.12628v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12628">http://arxiv.org/abs/2309.12628</a></li>
<li>Code URL: https://github.com/dmu-xmu/sar</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12628]] Sequential Action-Induced Invariant Representation for Reinforcement Learning(http://arxiv.org/abs/2309.12628)</code></li>
<li>Summary: <p>How to accurately learn task-relevant state representations from
high-dimensional observations with visual distractions is a realistic and
challenging problem in visual reinforcement learning. Recently, unsupervised
representation learning methods based on bisimulation metrics, contrast,
prediction, and reconstruction have shown the ability for task-relevant
information extraction. However, due to the lack of appropriate mechanisms for
the extraction of task information in the prediction, contrast, and
reconstruction-related approaches and the limitations of bisimulation-related
methods in domains with sparse rewards, it is still difficult for these methods
to be effectively extended to environments with distractions. To alleviate
these problems, in the paper, the action sequences, which contain
task-intensive signals, are incorporated into representation learning.
Specifically, we propose a Sequential Action--induced invariant Representation
(SAR) method, in which the encoder is optimized by an auxiliary learner to only
preserve the components that follow the control signals of sequential actions,
so the agent can be induced to learn the robust representation against
distractions. We conduct extensive experiments on the DeepMind Control suite
tasks with distractions while achieving the best performance over strong
baselines. We also demonstrate the effectiveness of our method at disregarding
task-irrelevant information by deploying SAR to real-world CARLA-based
autonomous driving with natural distractions. Finally, we provide the analysis
results of generalization drawn from the generalization decay and t-SNE
visualization. Code and demo videos are available at
https://github.com/DMU-XMU/SAR.git.
</p></li>
</ul>

<h3>Title: Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes. (arXiv:2309.12658v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12658">http://arxiv.org/abs/2309.12658</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12658]] Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes(http://arxiv.org/abs/2309.12658)</code></li>
<li>Summary: <p>Deep Gaussian Process (DGP) models offer a powerful nonparametric approach
for Bayesian inference, but exact inference is typically intractable,
motivating the use of various approximations. However, existing approaches,
such as mean-field Gaussian assumptions, limit the expressiveness and efficacy
of DGP models, while stochastic approximation can be computationally expensive.
To tackle these challenges, we introduce Neural Operator Variational Inference
(NOVI) for Deep Gaussian Processes. NOVI uses a neural generator to obtain a
sampler and minimizes the Regularized Stein Discrepancy in L2 space between the
generated distribution and true posterior. We solve the minimax problem using
Monte Carlo estimation and subsampling stochastic optimization techniques. We
demonstrate that the bias introduced by our method can be controlled by
multiplying the Fisher divergence with a constant, which leads to robust error
control and ensures the stability and precision of the algorithm. Our
experiments on datasets ranging from hundreds to tens of thousands demonstrate
the effectiveness and the faster convergence rate of the proposed method. We
achieve a classification accuracy of 93.56 on the CIFAR10 dataset,
outperforming SOTA Gaussian process methods. Furthermore, our method guarantees
theoretically controlled prediction error for DGP models and demonstrates
remarkable performance on various datasets. We are optimistic that NOVI has the
potential to enhance the performance of deep Bayesian nonparametric models and
could have significant implications for various practical applications
</p></li>
</ul>

<h3>Title: Higher-order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes. (arXiv:2309.12971v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12971">http://arxiv.org/abs/2309.12971</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12971]] Higher-order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes(http://arxiv.org/abs/2309.12971)</code></li>
<li>Summary: <p>Despite the recent successes of vanilla Graph Neural Networks (GNNs) on many
tasks, their foundation on pairwise interaction networks inherently limits
their capacity to discern latent higher-order interactions in complex systems.
To bridge this capability gap, we propose a novel approach exploiting the rich
mathematical theory of simplicial complexes (SCs) - a robust tool for modeling
higher-order interactions. Current SC-based GNNs are burdened by high
complexity and rigidity, and quantifying higher-order interaction strengths
remains challenging. Innovatively, we present a higher-order Flower-Petals (FP)
model, incorporating FP Laplacians into SCs. Further, we introduce a
Higher-order Graph Convolutional Network (HiGCN) grounded in FP Laplacians,
capable of discerning intrinsic features across varying topological scales. By
employing learnable graph filters, a parameter group within each FP Laplacian
domain, we can identify diverse patterns where the filters' weights serve as a
quantifiable measure of higher-order interaction strengths. The theoretical
underpinnings of HiGCN's advanced expressiveness are rigorously demonstrated.
Additionally, our empirical investigations reveal that the proposed model
accomplishes state-of-the-art (SOTA) performance on a range of graph tasks and
provides a scalable and flexible solution to explore higher-order interactions
in graphs.
</p></li>
</ul>

<h3>Title: Graph Neural Network for Stress Predictions in Stiffened Panels Under Uniform Loading. (arXiv:2309.13022v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13022">http://arxiv.org/abs/2309.13022</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13022]] Graph Neural Network for Stress Predictions in Stiffened Panels Under Uniform Loading(http://arxiv.org/abs/2309.13022)</code></li>
<li>Summary: <p>Machine learning (ML) and deep learning (DL) techniques have gained
significant attention as reduced order models (ROMs) to computationally
expensive structural analysis methods, such as finite element analysis (FEA).
Graph neural network (GNN) is a particular type of neural network which
processes data that can be represented as graphs. This allows for efficient
representation of complex geometries that can change during conceptual design
of a structure or a product. In this study, we propose a novel graph embedding
technique for efficient representation of 3D stiffened panels by considering
separate plate domains as vertices. This approach is considered using Graph
Sampling and Aggregation (GraphSAGE) to predict stress distributions in
stiffened panels with varying geometries. A comparison between a
finite-element-vertex graph representation is conducted to demonstrate the
effectiveness of the proposed approach. A comprehensive parametric study is
performed to examine the effect of structural geometry on the prediction
performance. Our results demonstrate the immense potential of graph neural
networks with the proposed graph embedding method as robust reduced-order
models for 3D structures.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion. (arXiv:2309.12708v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12708">http://arxiv.org/abs/2309.12708</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12708]] PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion(http://arxiv.org/abs/2309.12708)</code></li>
<li>Summary: <p>Semantic Scene Completion (SSC) aims to jointly generate space occupancies
and semantic labels for complex 3D scenes. Most existing SSC models focus on
volumetric representations, which are memory-inefficient for large outdoor
spaces. Point clouds provide a lightweight alternative but existing benchmarks
lack outdoor point cloud scenes with semantic labels. To address this, we
introduce PointSSC, the first cooperative vehicle-infrastructure point cloud
benchmark for semantic scene completion. These scenes exhibit long-range
perception and minimal occlusion. We develop an automated annotation pipeline
leveraging Segment Anything to efficiently assign semantics. To benchmark
progress, we propose a LiDAR-based model with a Spatial-Aware Transformer for
global and local feature extraction and a Completion and Segmentation
Cooperative Module for joint completion and segmentation. PointSSC provides a
challenging testbed to drive advances in semantic point cloud completion for
real-world navigation.
</p></li>
</ul>

<h3>Title: Accurate and Fast Compressed Video Captioning. (arXiv:2309.12867v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12867">http://arxiv.org/abs/2309.12867</a></li>
<li>Code URL: https://github.com/acherstyx/CoCap</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12867]] Accurate and Fast Compressed Video Captioning(http://arxiv.org/abs/2309.12867)</code></li>
<li>Summary: <p>Existing video captioning approaches typically require to first sample video
frames from a decoded video and then conduct a subsequent process (e.g.,
feature extraction and/or captioning model learning). In this pipeline, manual
frame sampling may ignore key information in videos and thus degrade
performance. Additionally, redundant information in the sampled frames may
result in low efficiency in the inference of video captioning. Addressing this,
we study video captioning from a different perspective in compressed domain,
which brings multi-fold advantages over the existing pipeline: 1) Compared to
raw images from the decoded video, the compressed video, consisting of
I-frames, motion vectors and residuals, is highly distinguishable, which allows
us to leverage the entire video for learning without manual sampling through a
specialized model design; 2) The captioning model is more efficient in
inference as smaller and less redundant information is processed. We propose a
simple yet effective end-to-end transformer in the compressed domain for video
captioning that enables learning from the compressed video for captioning. We
show that even with a simple design, our method can achieve state-of-the-art
performance on different benchmarks while running almost 2x faster than
existing approaches. Code is available at https://github.com/acherstyx/CoCap.
</p></li>
</ul>

<h3>Title: ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation Extraction. (arXiv:2309.12892v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12892">http://arxiv.org/abs/2309.12892</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12892]] ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation Extraction(http://arxiv.org/abs/2309.12892)</code></li>
<li>Summary: <p>Event Relation Extraction (ERE) aims to extract multiple kinds of relations
among events in texts. However, existing methods singly categorize event
relations as different classes, which are inadequately capturing the intrinsic
semantics of these relations. To comprehensively understand their intrinsic
semantics, in this paper, we obtain prototype representations for each type of
event relation and propose a Prototype-Enhanced Matching (ProtoEM) framework
for the joint extraction of multiple kinds of event relations. Specifically,
ProtoEM extracts event relations in a two-step manner, i.e., prototype
representing and prototype matching. In the first step, to capture the
connotations of different event relations, ProtoEM utilizes examples to
represent the prototypes corresponding to these relations. Subsequently, to
capture the interdependence among event relations, it constructs a dependency
graph for the prototypes corresponding to these relations and utilized a Graph
Neural Network (GNN)-based module for modeling. In the second step, it obtains
the representations of new event pairs and calculates their similarity with
those prototypes obtained in the first step to evaluate which types of event
relations they belong to. Experimental results on the MAVEN-ERE dataset
demonstrate that the proposed ProtoEM framework can effectively represent the
prototypes of event relations and further obtain a significant improvement over
baseline models.
</p></li>
</ul>

<h3>Title: Nested Event Extraction upon Pivot Element Recogniton. (arXiv:2309.12960v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12960">http://arxiv.org/abs/2309.12960</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12960]] Nested Event Extraction upon Pivot Element Recogniton(http://arxiv.org/abs/2309.12960)</code></li>
<li>Summary: <p>Nested Event Extraction (NEE) aims to extract complex event structures where
an event contains other events as its arguments recursively. Nested events
involve a kind of Pivot Elements (PEs) that simultaneously act as arguments of
outer events and as triggers of inner events, and thus connect them into nested
structures. This special characteristic of PEs brings challenges to existing
NEE methods, as they cannot well cope with the dual identities of PEs.
Therefore, this paper proposes a new model, called PerNee, which extracts
nested events mainly based on recognizing PEs. Specifically, PerNee first
recognizes the triggers of both inner and outer events and further recognizes
the PEs via classifying the relation type between trigger pairs. In order to
obtain better representations of triggers and arguments to further improve NEE
performance, it incorporates the information of both event types and argument
roles into PerNee through prompt learning. Since existing NEE datasets (e.g.,
Genia11) are limited to specific domains and contain a narrow range of event
types with nested structures, we systematically categorize nested events in
generic domain and construct a new NEE dataset, namely ACE2005-Nest.
Experimental results demonstrate that PerNee consistently achieves
state-of-the-art performance on ACE2005-Nest, Genia11 and Genia13.
</p></li>
</ul>

<h3>Title: Confidence Calibration for Systems with Cascaded Predictive Modules. (arXiv:2309.12510v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12510">http://arxiv.org/abs/2309.12510</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12510]] Confidence Calibration for Systems with Cascaded Predictive Modules(http://arxiv.org/abs/2309.12510)</code></li>
<li>Summary: <p>Existing conformal prediction algorithms estimate prediction intervals at
target confidence levels to characterize the performance of a regression model
on new test samples. However, considering an autonomous system consisting of
multiple modules, prediction intervals constructed for individual modules fall
short of accommodating uncertainty propagation over different modules and thus
cannot provide reliable predictions on system behavior. We address this
limitation and present novel solutions based on conformal prediction to provide
prediction intervals calibrated for a predictive system consisting of cascaded
modules (e.g., an upstream feature extraction module and a downstream
regression module). Our key idea is to leverage module-level validation data to
characterize the system-level error distribution without direct access to
end-to-end validation data. We provide theoretical justification and empirical
experimental results to demonstrate the effectiveness of proposed solutions. In
comparison to prediction intervals calibrated for individual modules, our
solutions generate improved intervals with more accurate performance guarantees
for system predictions, which are demonstrated on both synthetic systems and
real-world systems performing overlap prediction for indoor navigation using
the Matterport3D dataset.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h2>fair</h2>
<h3>Title: Fairness Hub Technical Briefs: AUC Gap. (arXiv:2309.12371v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12371">http://arxiv.org/abs/2309.12371</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12371]] Fairness Hub Technical Briefs: AUC Gap(http://arxiv.org/abs/2309.12371)</code></li>
<li>Summary: <p>To measure bias, we encourage teams to consider using AUC Gap: the absolute
difference between the highest and lowest test AUC for subgroups (e.g., gender,
race, SES, prior knowledge). It is agnostic to the AI/ML algorithm used and it
captures the disparity in model performance for any number of subgroups, which
enables non-binary fairness assessments such as for intersectional identity
groups. The LEVI teams use a wide range of AI/ML models in pursuit of a common
goal of doubling math achievement in low-income middle schools. Ensuring that
the models, which are trained on datasets collected in many different contexts,
do not introduce or amplify biases is important for achieving the LEVI goal. We
offer here a versatile and easy-to-compute measure of model bias for all LEVI
teams in order to create a common benchmark and an analytical basis for sharing
what strategies have worked for different teams.
</p></li>
</ul>

<h3>Title: Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?. (arXiv:2309.12632v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12632">http://arxiv.org/abs/2309.12632</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12632]] Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?(http://arxiv.org/abs/2309.12632)</code></li>
<li>Summary: <p>Following the great success of various deep learning methods in image and
object classification, the biomedical image processing society is also
overwhelmed with their applications to various automatic diagnosis cases.
Unfortunately, most of the deep learning-based classification attempts in the
literature solely focus on the aim of extreme accuracy scores, without
considering interpretability, or patient-wise separation of training and test
data. For example, most lung nodule classification papers using deep learning
randomly shuffle data and split it into training, validation, and test sets,
causing certain images from the CT scan of a person to be in the training set,
while other images of the exact same person to be in the validation or testing
image sets. This can result in reporting misleading accuracy rates and the
learning of irrelevant features, ultimately reducing the real-life usability of
these models. When the deep neural networks trained on the traditional, unfair
data shuffling method are challenged with new patient images, it is observed
that the trained models perform poorly. In contrast, deep neural networks
trained with strict patient-level separation maintain their accuracy rates even
when new patient images are tested. Heat-map visualizations of the activations
of the deep neural networks trained with strict patient-level separation
indicate a higher degree of focus on the relevant nodules. We argue that the
research question posed in the title has a positive answer only if the deep
neural networks are trained with images of patients that are strictly isolated
from the validation and testing patient sets.
</p></li>
</ul>

<h3>Title: Pursuing Counterfactual Fairness via Sequential Autoencoder Across Domains. (arXiv:2309.13005v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13005">http://arxiv.org/abs/2309.13005</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13005]] Pursuing Counterfactual Fairness via Sequential Autoencoder Across Domains(http://arxiv.org/abs/2309.13005)</code></li>
<li>Summary: <p>Recognizing the prevalence of domain shift as a common challenge in machine
learning, various domain generalization (DG) techniques have been developed to
enhance the performance of machine learning systems when dealing with
out-of-distribution (OOD) data. Furthermore, in real-world scenarios, data
distributions can gradually change across a sequence of sequential domains.
While current methodologies primarily focus on improving model effectiveness
within these new domains, they often overlook fairness issues throughout the
learning process. In response, we introduce an innovative framework called
Counterfactual Fairness-Aware Domain Generalization with Sequential Autoencoder
(CDSAE). This approach effectively separates environmental information and
sensitive attributes from the embedded representation of classification
features. This concurrent separation not only greatly improves model
generalization across diverse and unfamiliar domains but also effectively
addresses challenges related to unfair classification. Our strategy is rooted
in the principles of causal inference to tackle these dual issues. To examine
the intricate relationship between semantic information, sensitive attributes,
and environmental cues, we systematically categorize exogenous uncertainty
factors into four latent variables: 1) semantic information influenced by
sensitive attributes, 2) semantic information unaffected by sensitive
attributes, 3) environmental cues influenced by sensitive attributes, and 4)
environmental cues unaffected by sensitive attributes. By incorporating
fairness regularization, we exclusively employ semantic information for
classification purposes. Empirical validation on synthetic and real-world
datasets substantiates the effectiveness of our approach, demonstrating
improved accuracy levels while ensuring the preservation of fairness in the
evolving landscape of continuous domains.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Data-driven Preference Learning Methods for Multiple Criteria Sorting with Temporal Criteria. (arXiv:2309.12620v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12620">http://arxiv.org/abs/2309.12620</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12620]] Data-driven Preference Learning Methods for Multiple Criteria Sorting with Temporal Criteria(http://arxiv.org/abs/2309.12620)</code></li>
<li>Summary: <p>The advent of predictive methodologies has catalyzed the emergence of
data-driven decision support across various domains. However, developing models
capable of effectively handling input time series data presents an enduring
challenge. This study presents novel preference learning approaches to multiple
criteria sorting problems in the presence of temporal criteria. We first
formulate a convex quadratic programming model characterized by fixed time
discount factors, operating within a regularization framework. Additionally, we
propose an ensemble learning algorithm designed to consolidate the outputs of
multiple, potentially weaker, optimizers, a process executed efficiently
through parallel computation. To enhance scalability and accommodate learnable
time discount factors, we introduce a novel monotonic Recurrent Neural Network
(mRNN). It is designed to capture the evolving dynamics of preferences over
time while upholding critical properties inherent to MCS problems, including
criteria monotonicity, preference independence, and the natural ordering of
classes. The proposed mRNN can describe the preference dynamics by depicting
marginal value functions and personalized time discount factors along with
time, effectively amalgamating the interpretability of traditional MCS methods
with the predictive potential offered by deep preference learning models.
Comprehensive assessments of the proposed models are conducted, encompassing
synthetic data scenarios and a real-case study centered on classifying valuable
users within a mobile gaming app based on their historical in-app behavioral
sequences. Empirical findings underscore the notable performance improvements
achieved by the proposed models when compared to a spectrum of baseline
methods, spanning machine learning, deep learning, and conventional multiple
criteria sorting approaches.
</p></li>
</ul>

<h3>Title: Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming. (arXiv:2309.12701v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12701">http://arxiv.org/abs/2309.12701</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12701]] Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming(http://arxiv.org/abs/2309.12701)</code></li>
<li>Summary: <p>Decision trees are known to be intrinsically interpretable as they can be
inspected and interpreted by humans. Furthermore, recent hardware advances have
rekindled an interest for optimal decision tree algorithms, that produce more
accurate trees than the usual greedy approaches. However, these optimal
algorithms return a single tree optimizing a hand defined
interpretability-performance trade-off, obtained by specifying a maximum number
of decision nodes, giving no further insights about the quality of this
trade-off. In this paper, we propose a new Markov Decision Problem (MDP)
formulation for finding optimal decision trees. The main interest of this
formulation is that we can compute the optimal decision trees for several
interpretability-performance trade-offs by solving a single dynamic program,
letting the user choose a posteriori the tree that best suits their needs.
Empirically, we show that our method is competitive with state-of-the-art
algorithms in terms of accuracy and runtime while returning a whole set of
trees on the interpretability-performance Pareto front.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: License Plate Super-Resolution Using Diffusion Models. (arXiv:2309.12506v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12506">http://arxiv.org/abs/2309.12506</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12506]] License Plate Super-Resolution Using Diffusion Models(http://arxiv.org/abs/2309.12506)</code></li>
<li>Summary: <p>In surveillance, accurately recognizing license plates is hindered by their
often low quality and small dimensions, compromising recognition precision.
Despite advancements in AI-based image super-resolution, methods like
Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs)
still fall short in enhancing license plate images. This study leverages the
cutting-edge diffusion model, which has consistently outperformed other deep
learning techniques in image restoration. By training this model using a
curated dataset of Saudi license plates, both in low and high resolutions, we
discovered the diffusion model's superior efficacy. The method achieves a
12.55\% and 37.32% improvement in Peak Signal-to-Noise Ratio (PSNR) over SwinIR
and ESRGAN, respectively. Moreover, our method surpasses these techniques in
terms of Structural Similarity Index (SSIM), registering a 4.89% and 17.66%
improvement over SwinIR and ESRGAN, respectively. Furthermore, 92% of human
evaluators preferred our images over those from other algorithms. In essence,
this research presents a pioneering solution for license plate
super-resolution, with tangible potential for surveillance systems.
</p></li>
</ul>

<h3>Title: MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation. (arXiv:2309.13042v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13042">http://arxiv.org/abs/2309.13042</a></li>
<li>Code URL: https://github.com/jiahao000/mosaicfusion</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13042]] MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation(http://arxiv.org/abs/2309.13042)</code></li>
<li>Summary: <p>We present MosaicFusion, a simple yet effective diffusion-based data
augmentation approach for large vocabulary instance segmentation. Our method is
training-free and does not rely on any label supervision. Two key designs
enable us to employ an off-the-shelf text-to-image diffusion model as a useful
dataset generator for object instances and mask annotations. First, we divide
an image canvas into several regions and perform a single round of diffusion
process to generate multiple instances simultaneously, conditioning on
different text prompts. Second, we obtain corresponding instance masks by
aggregating cross-attention maps associated with object prompts across layers
and diffusion time steps, followed by simple thresholding and edge-aware
refinement processing. Without bells and whistles, our MosaicFusion can produce
a significant amount of synthetic labeled data for both rare and novel
categories. Experimental results on the challenging LVIS long-tailed and
open-vocabulary benchmarks demonstrate that MosaicFusion can significantly
improve the performance of existing instance segmentation models, especially
for rare and novel categories. Code will be released at
https://github.com/Jiahao000/MosaicFusion.
</p></li>
</ul>

<h3>Title: A Diffusion-Model of Joint Interactive Navigation. (arXiv:2309.12508v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12508">http://arxiv.org/abs/2309.12508</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12508]] A Diffusion-Model of Joint Interactive Navigation(http://arxiv.org/abs/2309.12508)</code></li>
<li>Summary: <p>Simulation of autonomous vehicle systems requires that simulated traffic
participants exhibit diverse and realistic behaviors. The use of prerecorded
real-world traffic scenarios in simulation ensures realism but the rarity of
safety critical events makes large scale collection of driving scenarios
expensive. In this paper, we present DJINN - a diffusion based method of
generating traffic scenarios. Our approach jointly diffuses the trajectories of
all agents, conditioned on a flexible set of state observations from the past,
present, or future. On popular trajectory forecasting datasets, we report state
of the art performance on joint trajectory metrics. In addition, we demonstrate
how DJINN flexibly enables direct test-time sampling from a variety of valuable
conditional distributions including goal-based sampling, behavior-class
sampling, and scenario editing.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: DualToken-ViT: Position-aware Efficient Vision Transformer with Dual Token Fusion. (arXiv:2309.12424v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12424">http://arxiv.org/abs/2309.12424</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12424]] DualToken-ViT: Position-aware Efficient Vision Transformer with Dual Token Fusion(http://arxiv.org/abs/2309.12424)</code></li>
<li>Summary: <p>Self-attention-based vision transformers (ViTs) have emerged as a highly
competitive architecture in computer vision. Unlike convolutional neural
networks (CNNs), ViTs are capable of global information sharing. With the
development of various structures of ViTs, ViTs are increasingly advantageous
for many vision tasks. However, the quadratic complexity of self-attention
renders ViTs computationally intensive, and their lack of inductive biases of
locality and translation equivariance demands larger model sizes compared to
CNNs to effectively learn visual features. In this paper, we propose a
light-weight and efficient vision transformer model called DualToken-ViT that
leverages the advantages of CNNs and ViTs. DualToken-ViT effectively fuses the
token with local information obtained by convolution-based structure and the
token with global information obtained by self-attention-based structure to
achieve an efficient attention structure. In addition, we use position-aware
global tokens throughout all stages to enrich the global information, which
further strengthening the effect of DualToken-ViT. Position-aware global tokens
also contain the position information of the image, which makes our model
better for vision tasks. We conducted extensive experiments on image
classification, object detection and semantic segmentation tasks to demonstrate
the effectiveness of DualToken-ViT. On the ImageNet-1K dataset, our models of
different scales achieve accuracies of 75.4% and 79.4% with only 0.5G and 1.0G
FLOPs, respectively, and our model with 1.0G FLOPs outperforms LightViT-T using
global tokens by 0.7%.
</p></li>
</ul>

<h3>Title: DeFormer: Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image. (arXiv:2309.12594v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12594">http://arxiv.org/abs/2309.12594</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12594]] DeFormer: Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image(http://arxiv.org/abs/2309.12594)</code></li>
<li>Summary: <p>Accurate 3D shape abstraction from a single 2D image is a long-standing
problem in computer vision and graphics. By leveraging a set of primitives to
represent the target shape, recent methods have achieved promising results.
However, these methods either use a relatively large number of primitives or
lack geometric flexibility due to the limited expressibility of the primitives.
In this paper, we propose a novel bi-channel Transformer architecture,
integrated with parameterized deformable models, termed DeFormer, to
simultaneously estimate the global and local deformations of primitives. In
this way, DeFormer can abstract complex object shapes while using a small
number of primitives which offer a broader geometry coverage and finer details.
Then, we introduce a force-driven dynamic fitting and a cycle-consistent
re-projection loss to optimize the primitive parameters. Extensive experiments
on ShapeNet across various settings show that DeFormer achieves better
reconstruction accuracy over the state-of-the-art, and visualizes with
consistent semantic correspondences for improved interpretability.
</p></li>
</ul>

<h3>Title: CINFormer: Transformer network with multi-stage CNN feature injection for surface defect segmentation. (arXiv:2309.12639v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12639">http://arxiv.org/abs/2309.12639</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12639]] CINFormer: Transformer network with multi-stage CNN feature injection for surface defect segmentation(http://arxiv.org/abs/2309.12639)</code></li>
<li>Summary: <p>Surface defect inspection is of great importance for industrial manufacture
and production. Though defect inspection methods based on deep learning have
made significant progress, there are still some challenges for these methods,
such as indistinguishable weak defects and defect-like interference in the
background. To address these issues, we propose a transformer network with
multi-stage CNN (Convolutional Neural Network) feature injection for surface
defect segmentation, which is a UNet-like structure named CINFormer. CINFormer
presents a simple yet effective feature integration mechanism that injects the
multi-level CNN features of the input image into different stages of the
transformer network in the encoder. This can maintain the merit of CNN
capturing detailed features and that of transformer depressing noises in the
background, which facilitates accurate defect detection. In addition, CINFormer
presents a Top-K self-attention module to focus on tokens with more important
information about the defects, so as to further reduce the impact of the
redundant background. Extensive experiments conducted on the surface defect
datasets DAGM 2007, Magnetic tile, and NEU show that the proposed CINFormer
achieves state-of-the-art performance in defect detection.
</p></li>
</ul>

<h3>Title: Global Context Aggregation Network for Lightweight Saliency Detection of Surface Defects. (arXiv:2309.12641v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12641">http://arxiv.org/abs/2309.12641</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12641]] Global Context Aggregation Network for Lightweight Saliency Detection of Surface Defects(http://arxiv.org/abs/2309.12641)</code></li>
<li>Summary: <p>Surface defect inspection is a very challenging task in which surface defects
usually show weak appearances or exist under complex backgrounds. Most
high-accuracy defect detection methods require expensive computation and
storage overhead, making them less practical in some resource-constrained
defect detection applications. Although some lightweight methods have achieved
real-time inference speed with fewer parameters, they show poor detection
accuracy in complex defect scenarios. To this end, we develop a Global Context
Aggregation Network (GCANet) for lightweight saliency detection of surface
defects on the encoder-decoder structure. First, we introduce a novel
transformer encoder on the top layer of the lightweight backbone, which
captures global context information through a novel Depth-wise Self-Attention
(DSA) module. The proposed DSA performs element-wise similarity in channel
dimension while maintaining linear complexity. In addition, we introduce a
novel Channel Reference Attention (CRA) module before each decoder block to
strengthen the representation of multi-level features in the bottom-up path.
The proposed CRA exploits the channel correlation between features at different
layers to adaptively enhance feature representation. The experimental results
on three public defect datasets demonstrate that the proposed network achieves
a better trade-off between accuracy and running efficiency compared with other
17 state-of-the-art methods. Specifically, GCANet achieves competitive accuracy
(91.79% $F_{\beta}^{w}$, 93.55% $S_\alpha$, and 97.35% $E_\phi$) on
SD-saliency-900 while running 272fps on a single gpu.
</p></li>
</ul>

<h3>Title: Exploiting Modality-Specific Features For Multi-Modal Manipulation Detection And Grounding. (arXiv:2309.12657v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12657">http://arxiv.org/abs/2309.12657</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12657]] Exploiting Modality-Specific Features For Multi-Modal Manipulation Detection And Grounding(http://arxiv.org/abs/2309.12657)</code></li>
<li>Summary: <p>AI-synthesized text and images have gained significant attention,
particularly due to the widespread dissemination of multi-modal manipulations
on the internet, which has resulted in numerous negative impacts on society.
Existing methods for multi-modal manipulation detection and grounding primarily
focus on fusing vision-language features to make predictions, while overlooking
the importance of modality-specific features, leading to sub-optimal results.
In this paper, we construct a simple and novel transformer-based framework for
multi-modal manipulation detection and grounding tasks. Our framework
simultaneously explores modality-specific features while preserving the
capability for multi-modal alignment. To achieve this, we introduce
visual/language pre-trained encoders and dual-branch cross-attention (DCA) to
extract and fuse modality-unique features. Furthermore, we design decoupled
fine-grained classifiers (DFC) to enhance modality-specific feature mining and
mitigate modality competition. Moreover, we propose an implicit manipulation
query (IMQ) that adaptively aggregates global contextual cues within each
modality using learnable queries, thereby improving the discovery of forged
details. Extensive experiments on the $\rm DGM^4$ dataset demonstrate the
superior performance of our proposed model compared to state-of-the-art
approaches.
</p></li>
</ul>

<h3>Title: Transformer-based Image Compression with Variable Image Quality Objectives. (arXiv:2309.12717v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12717">http://arxiv.org/abs/2309.12717</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12717]] Transformer-based Image Compression with Variable Image Quality Objectives(http://arxiv.org/abs/2309.12717)</code></li>
<li>Summary: <p>This paper presents a Transformer-based image compression system that allows
for a variable image quality objective according to the user's preference.
Optimizing a learned codec for different quality objectives leads to
reconstructed images with varying visual characteristics. Our method provides
the user with the flexibility to choose a trade-off between two image quality
objectives using a single, shared model. Motivated by the success of
prompt-tuning techniques, we introduce prompt tokens to condition our
Transformer-based autoencoder. These prompt tokens are generated adaptively
based on the user's preference and input image through learning a prompt
generation network. Extensive experiments on commonly used quality metrics
demonstrate the effectiveness of our method in adapting the encoding and/or
decoding processes to a variable quality objective. While offering the
additional flexibility, our proposed method performs comparably to the
single-objective methods in terms of rate-distortion performance.
</p></li>
</ul>

<h3>Title: Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where. (arXiv:2309.12757v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12757">http://arxiv.org/abs/2309.12757</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12757]] Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where(http://arxiv.org/abs/2309.12757)</code></li>
<li>Summary: <p>While image data starts to enjoy the simple-but-effective self-supervised
learning scheme built upon masking and self-reconstruction objective thanks to
the introduction of tokenization procedure and vision transformer backbone,
convolutional neural networks as another important and widely-adopted
architecture for image data, though having contrastive-learning techniques to
drive the self-supervised learning, still face the difficulty of leveraging
such straightforward and general masking operation to benefit their learning
process significantly. In this work, we aim to alleviate the burden of
including masking operation into the contrastive-learning framework for
convolutional neural networks as an extra augmentation method. In addition to
the additive but unwanted edges (between masked and unmasked regions) as well
as other adverse effects caused by the masking operations for ConvNets, which
have been discussed by prior works, we particularly identify the potential
problem where for one view in a contrastive sample-pair the randomly-sampled
masking regions could be overly concentrated on important/salient objects thus
resulting in misleading contrastiveness to the other view. To this end, we
propose to explicitly take the saliency constraint into consideration in which
the masked regions are more evenly distributed among the foreground and
background for realizing the masking-based augmentation. Moreover, we introduce
hard negative samples by masking larger regions of salient patches in an input
image. Extensive experiments conducted on various datasets, contrastive
learning mechanisms, and downstream tasks well verify the efficacy as well as
the superior performance of our proposed method with respect to several
state-of-the-art baselines.
</p></li>
</ul>

<h3>Title: Associative Transformer Is A Sparse Representation Learner. (arXiv:2309.12862v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12862">http://arxiv.org/abs/2309.12862</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12862]] Associative Transformer Is A Sparse Representation Learner(http://arxiv.org/abs/2309.12862)</code></li>
<li>Summary: <p>Emerging from the monolithic pairwise attention mechanism in conventional
Transformer models, there is a growing interest in leveraging sparse
interactions that align more closely with biological principles. Approaches
including the Set Transformer and the Perceiver employ cross-attention
consolidated with a latent space that forms an attention bottleneck with
limited capacity. Building upon recent neuroscience studies of Global Workspace
Theory and associative memory, we propose the Associative Transformer (AiT).
AiT induces low-rank explicit memory that serves as both priors to guide
bottleneck attention in the shared workspace and attractors within associative
memory of a Hopfield network. Through joint end-to-end training, these priors
naturally develop module specialization, each contributing a distinct inductive
bias to form attention bottlenecks. A bottleneck can foster competition among
inputs for writing information into the memory. We show that AiT is a sparse
representation learner, learning distinct priors through the bottlenecks that
are complexity-invariant to input quantities and dimensions. AiT demonstrates
its superiority over methods such as the Set Transformer, Vision Transformer,
and Coordination in various vision tasks.
</p></li>
</ul>

<h3>Title: Bridging Sensor Gaps via Single-Direction Tuning for Hyperspectral Image Classification. (arXiv:2309.12865v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12865">http://arxiv.org/abs/2309.12865</a></li>
<li>Code URL: https://github.com/cecilia-xue/hyt-nas</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12865]] Bridging Sensor Gaps via Single-Direction Tuning for Hyperspectral Image Classification(http://arxiv.org/abs/2309.12865)</code></li>
<li>Summary: <p>Recently, some researchers started exploring the use of ViTs in tackling HSI
classification and achieved remarkable results. However, the training of ViT
models requires a considerable number of training samples, while hyperspectral
data, due to its high annotation costs, typically has a relatively small number
of training samples. This contradiction has not been effectively addressed. In
this paper, aiming to solve this problem, we propose the single-direction
tuning (SDT) strategy, which serves as a bridge, allowing us to leverage
existing labeled HSI datasets even RGB datasets to enhance the performance on
new HSI datasets with limited samples. The proposed SDT inherits the idea of
prompt tuning, aiming to reuse pre-trained models with minimal modifications
for adaptation to new tasks. But unlike prompt tuning, SDT is custom-designed
to accommodate the characteristics of HSIs. The proposed SDT utilizes a
parallel architecture, an asynchronous cold-hot gradient update strategy, and
unidirectional interaction. It aims to fully harness the potent representation
learning capabilities derived from training on heterologous, even cross-modal
datasets. In addition, we also introduce a novel Triplet-structured transformer
(Tri-Former), where spectral attention and spatial attention modules are merged
in parallel to construct the token mixing component for reducing computation
cost and a 3D convolution-based channel mixer module is integrated to enhance
stability and keep structure information. Comparison experiments conducted on
three representative HSI datasets captured by different sensors demonstrate the
proposed Tri-Former achieves better performance compared to several
state-of-the-art methods. Homologous, heterologous and cross-modal tuning
experiments verified the effectiveness of the proposed SDT.
</p></li>
</ul>

<h3>Title: Decoding Affect in Dyadic Conversations: Leveraging Semantic Similarity through Sentence Embedding. (arXiv:2309.12646v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12646">http://arxiv.org/abs/2309.12646</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12646]] Decoding Affect in Dyadic Conversations: Leveraging Semantic Similarity through Sentence Embedding(http://arxiv.org/abs/2309.12646)</code></li>
<li>Summary: <p>Recent advancements in Natural Language Processing (NLP) have highlighted the
potential of sentence embeddings in measuring semantic similarity. Yet, its
application in analyzing real-world dyadic interactions and predicting the
affect of conversational participants remains largely uncharted. To bridge this
gap, the present study utilizes verbal conversations within 50 married couples
talking about conflicts and pleasant activities. Transformer-based model
all-MiniLM-L6-v2 was employed to obtain the embeddings of the utterances from
each speaker. The overall similarity of the conversation was then quantified by
the average cosine similarity between the embeddings of adjacent utterances.
Results showed that semantic similarity had a positive association with wives'
affect during conflict (but not pleasant) conversations. Moreover, this
association was not observed with husbands' affect regardless of conversation
types. Two validation checks further provided support for the validity of the
similarity measure and showed that the observed patterns were not mere
artifacts of data. The present study underscores the potency of sentence
embeddings in understanding the association between interpersonal dynamics and
individual affect, paving the way for innovative applications in affective and
relationship sciences.
</p></li>
</ul>

<h3>Title: AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer. (arXiv:2309.12689v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12689">http://arxiv.org/abs/2309.12689</a></li>
<li>Code URL: https://github.com/kiwi-lilo/amplify</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12689]] AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer(http://arxiv.org/abs/2309.12689)</code></li>
<li>Summary: <p>Mixup is an effective data augmentation method that generates new augmented
samples by aggregating linear combinations of different original samples.
However, if there are noises or aberrant features in the original samples,
Mixup may propagate them to the augmented samples, leading to over-sensitivity
of the model to these outliers . To solve this problem, this paper proposes a
new Mixup method called AMPLIFY. This method uses the Attention mechanism of
Transformer itself to reduce the influence of noises and aberrant values in the
original samples on the prediction results, without increasing additional
trainable parameters, and the computational cost is very low, thereby avoiding
the problem of high resource consumption in common Mixup methods such as
Sentence Mixup . The experimental results show that, under a smaller
computational resource cost, AMPLIFY outperforms other Mixup methods in text
classification tasks on 7 benchmark datasets, providing new ideas and new ways
to further improve the performance of pre-trained models based on the Attention
mechanism, such as BERT, ALBERT, RoBERTa, and GPT. Our code can be obtained at
https://github.com/kiwi-lilo/AMPLIFY.
</p></li>
</ul>

<h3>Title: StyloMetrix: An Open-Source Multilingual Tool for Representing Stylometric Vectors. (arXiv:2309.12810v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12810">http://arxiv.org/abs/2309.12810</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12810]] StyloMetrix: An Open-Source Multilingual Tool for Representing Stylometric Vectors(http://arxiv.org/abs/2309.12810)</code></li>
<li>Summary: <p>This work aims to provide an overview on the open-source multilanguage tool
called StyloMetrix. It offers stylometric text representations that cover
various aspects of grammar, syntax and lexicon. StyloMetrix covers four
languages: Polish as the primary language, English, Ukrainian and Russian. The
normalized output of each feature can become a fruitful course for machine
learning models and a valuable addition to the embeddings layer for any deep
learning algorithm. We strive to provide a concise, but exhaustive overview on
the application of the StyloMetrix vectors as well as explain the sets of the
developed linguistic features. The experiments have shown promising results in
supervised content classification with simple algorithms as Random Forest
Classifier, Voting Classifier, Logistic Regression and others. The deep
learning assessments have unveiled the usefulness of the StyloMetrix vectors at
enhancing an embedding layer extracted from Transformer architectures. The
StyloMetrix has proven itself to be a formidable source for the machine
learning and deep learning algorithms to execute different classification
tasks.
</p></li>
</ul>

<h3>Title: On Separate Normalization in Self-supervised Transformers. (arXiv:2309.12931v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12931">http://arxiv.org/abs/2309.12931</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12931]] On Separate Normalization in Self-supervised Transformers(http://arxiv.org/abs/2309.12931)</code></li>
<li>Summary: <p>Self-supervised training methods for transformers have demonstrated
remarkable performance across various domains. Previous transformer-based
models, such as masked autoencoders (MAE), typically utilize a single
normalization layer for both the [CLS] symbol and the tokens. We propose in
this paper a simple modification that employs separate normalization layers for
the tokens and the [CLS] symbol to better capture their distinct
characteristics and enhance downstream task performance. Our method aims to
alleviate the potential negative effects of using the same normalization
statistics for both token types, which may not be optimally aligned with their
individual roles. We empirically show that by utilizing a separate
normalization layer, the [CLS] embeddings can better encode the global
contextual information and are distributed more uniformly in its anisotropic
space. When replacing the conventional normalization layer with the two
separate layers, we observe an average 2.7% performance improvement over the
image, natural language, and graph domains.
</p></li>
</ul>

<h3>Title: SPION: Layer-Wise Sparse Training of Transformer via Convolutional Flood Filling. (arXiv:2309.12578v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12578">http://arxiv.org/abs/2309.12578</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12578]] SPION: Layer-Wise Sparse Training of Transformer via Convolutional Flood Filling(http://arxiv.org/abs/2309.12578)</code></li>
<li>Summary: <p>Sparsifying the Transformer has garnered considerable interest, as training
the Transformer is very computationally demanding. Prior efforts to sparsify
the Transformer have either used a fixed pattern or data-driven approach to
reduce the number of operations involving the computation of multi-head
attention, which is the main bottleneck of the Transformer. However, existing
methods suffer from inevitable problems, such as the potential loss of
essential sequence features due to the uniform fixed pattern applied across all
layers, and an increase in the model size resulting from the use of additional
parameters to learn sparsity patterns in attention operations. In this paper,
we propose a novel sparsification scheme for the Transformer that integrates
convolution filters and the flood filling method to efficiently capture the
layer-wise sparse pattern in attention operations. Our sparsification approach
reduces the computational complexity and memory footprint of the Transformer
during training. Efficient implementations of the layer-wise sparsified
attention algorithm on GPUs are developed, demonstrating a new SPION that
achieves up to 3.08X speedup over existing state-of-the-art sparse Transformer
models, with better evaluation quality.
</p></li>
</ul>

<h3>Title: BayesDLL: Bayesian Deep Learning Library. (arXiv:2309.12928v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12928">http://arxiv.org/abs/2309.12928</a></li>
<li>Code URL: https://github.com/minyoungkim21/bayesdll</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12928]] BayesDLL: Bayesian Deep Learning Library(http://arxiv.org/abs/2309.12928)</code></li>
<li>Summary: <p>We release a new Bayesian neural network library for PyTorch for large-scale
deep networks. Our library implements mainstream approximate Bayesian inference
algorithms: variational inference, MC-dropout, stochastic-gradient MCMC, and
Laplace approximation. The main differences from other existing Bayesian neural
network libraries are as follows: 1) Our library can deal with very large-scale
deep networks including Vision Transformers (ViTs). 2) We need virtually zero
code modifications for users (e.g., the backbone network definition codes do
not neet to be modified at all). 3) Our library also allows the pre-trained
model weights to serve as a prior mean, which is very useful for performing
Bayesian inference with the large-scale foundation models like ViTs that are
hard to optimise from scratch with the downstream data alone. Our code is
publicly available at: \url{https://github.com/SamsungLabs/BayesDLL}\footnote{A
mirror repository is also available at:
\url{https://github.com/minyoungkim21/BayesDLL}.}.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Foundation Metrics: Quantifying Effectiveness of Healthcare Conversations powered by Generative AI. (arXiv:2309.12444v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12444">http://arxiv.org/abs/2309.12444</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12444]] Foundation Metrics: Quantifying Effectiveness of Healthcare Conversations powered by Generative AI(http://arxiv.org/abs/2309.12444)</code></li>
<li>Summary: <p>Generative Artificial Intelligence is set to revolutionize healthcare
delivery by transforming traditional patient care into a more personalized,
efficient, and proactive process. Chatbots, serving as interactive
conversational models, will probably drive this patient-centered transformation
in healthcare. Through the provision of various services, including diagnosis,
personalized lifestyle recommendations, and mental health support, the
objective is to substantially augment patient health outcomes, all the while
mitigating the workload burden on healthcare providers. The life-critical
nature of healthcare applications necessitates establishing a unified and
comprehensive set of evaluation metrics for conversational models. Existing
evaluation metrics proposed for various generic large language models (LLMs)
demonstrate a lack of comprehension regarding medical and health concepts and
their significance in promoting patients' well-being. Moreover, these metrics
neglect pivotal user-centered aspects, including trust-building, ethics,
personalization, empathy, user comprehension, and emotional support. The
purpose of this paper is to explore state-of-the-art LLM-based evaluation
metrics that are specifically applicable to the assessment of interactive
conversational models in healthcare. Subsequently, we present an comprehensive
set of evaluation metrics designed to thoroughly assess the performance of
healthcare chatbots from an end-user perspective. These metrics encompass an
evaluation of language processing abilities, impact on real-world clinical
tasks, and effectiveness in user-interactive conversations. Finally, we engage
in a discussion concerning the challenges associated with defining and
implementing these metrics, with particular emphasis on confounding factors
such as the target audience, evaluation methods, and prompt techniques involved
in the evaluation process.
</p></li>
</ul>

<h3>Title: Learning to Diversify Neural Text Generation via Degenerative Model. (arXiv:2309.12619v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12619">http://arxiv.org/abs/2309.12619</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12619]] Learning to Diversify Neural Text Generation via Degenerative Model(http://arxiv.org/abs/2309.12619)</code></li>
<li>Summary: <p>Neural language models often fail to generate diverse and informative texts,
limiting their applicability in real-world problems. While previous approaches
have proposed to address these issues by identifying and penalizing undesirable
behaviors (e.g., repetition, overuse of frequent words) from language models,
we propose an alternative approach based on an observation: models primarily
learn attributes within examples that are likely to cause degeneration
problems. Based on this observation, we propose a new approach to prevent
degeneration problems by training two models. Specifically, we first train a
model that is designed to amplify undesirable patterns. We then enhance the
diversity of the second model by focusing on patterns that the first model
fails to learn. Extensive experiments on two tasks, namely language modeling
and dialogue generation, demonstrate the effectiveness of our approach.
</p></li>
</ul>

<h3>Title: Change Management using Generative Modeling on Digital Twins. (arXiv:2309.12421v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12421">http://arxiv.org/abs/2309.12421</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12421]] Change Management using Generative Modeling on Digital Twins(http://arxiv.org/abs/2309.12421)</code></li>
<li>Summary: <p>A key challenge faced by small and medium-sized business entities is securely
managing software updates and changes. Specifically, with rapidly evolving
cybersecurity threats, changes/updates/patches to software systems are
necessary to stay ahead of emerging threats and are often mandated by
regulators or statutory authorities to counter these. However, security
patches/updates require stress testing before they can be released in the
production system. Stress testing in production environments is risky and poses
security threats. Large businesses usually have a non-production environment
where such changes can be made and tested before being released into
production. Smaller businesses do not have such facilities. In this work, we
show how "digital twins", especially for a mix of IT and IoT environments, can
be created on the cloud. These digital twins act as a non-production
environment where changes can be applied, and the system can be securely tested
before patch release. Additionally, the non-production digital twin can be used
to collect system data and run stress tests on the environment, both manually
and automatically. In this paper, we show how using a small sample of real
data/interactions, Generative Artificial Intelligence (AI) models can be used
to generate testing scenarios to check for points of failure.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges. (arXiv:2309.12426v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12426">http://arxiv.org/abs/2309.12426</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12426]] Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges(http://arxiv.org/abs/2309.12426)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have demonstrated impressive zero shot
performance on a wide range of NLP tasks, demonstrating the ability to reason
and apply commonsense. A relevant application is to use them for creating high
quality synthetic datasets for downstream tasks. In this work, we probe whether
GPT-4 can be used to augment existing extractive reading comprehension
datasets. Automating data annotation processes has the potential to save large
amounts of time, money and effort that goes into manually labelling datasets.
In this paper, we evaluate the performance of GPT-4 as a replacement for human
annotators for low resource reading comprehension tasks, by comparing
performance after fine tuning, and the cost associated with annotation. This
work serves to be the first analysis of LLMs as synthetic data augmenters for
QA systems, highlighting the unique opportunities and challenges. Additionally,
we release augmented versions of low resource datasets, that will allow the
research community to create further benchmarks for evaluation of generated
datasets.
</p></li>
</ul>

<h3>Title: Is it Possible to Modify Text to a Target Readability Level? An Initial Investigation Using Zero-Shot Large Language Models. (arXiv:2309.12551v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12551">http://arxiv.org/abs/2309.12551</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12551]] Is it Possible to Modify Text to a Target Readability Level? An Initial Investigation Using Zero-Shot Large Language Models(http://arxiv.org/abs/2309.12551)</code></li>
<li>Summary: <p>Text simplification is a common task where the text is adapted to make it
easier to understand. Similarly, text elaboration can make a passage more
sophisticated, offering a method to control the complexity of reading
comprehension tests. However, text simplification and elaboration tasks are
limited to only relatively alter the readability of texts. It is useful to
directly modify the readability of any text to an absolute target readability
level to cater to a diverse audience. Ideally, the readability of
readability-controlled generated text should be independent of the source text.
Therefore, we propose a novel readability-controlled text modification task.
The task requires the generation of 8 versions at various target readability
levels for each input text. We introduce novel readability-controlled text
modification metrics. The baselines for this task use ChatGPT and Llama-2, with
an extension approach introducing a two-step process (generating paraphrases by
passing through the language model twice). The zero-shot approaches are able to
push the readability of the paraphrases in the desired direction but the final
readability remains correlated with the original text's readability. We also
find greater drops in semantic and lexical similarity between the source and
target texts with greater shifts in the readability.
</p></li>
</ul>

<h3>Title: HRoT: Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering. (arXiv:2309.12669v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12669">http://arxiv.org/abs/2309.12669</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12669]] HRoT: Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering(http://arxiv.org/abs/2309.12669)</code></li>
<li>Summary: <p>Answering numerical questions over hybrid contents from the given tables and
text(TextTableQA) is a challenging task. Recently, Large Language Models (LLMs)
have gained significant attention in the NLP community. With the emergence of
large language models, In-Context Learning and Chain-of-Thought prompting have
become two particularly popular research topics in this field. In this paper,
we introduce a new prompting strategy called Hybrid prompt strategy and
Retrieval of Thought for TextTableQA. Through In-Context Learning, we prompt
the model to develop the ability of retrieval thinking when dealing with hybrid
data. Our method achieves superior performance compared to the fully-supervised
SOTA on the MultiHiertt dataset in the few-shot setting.
</p></li>
</ul>

<h3>Title: Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models. (arXiv:2309.12767v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12767">http://arxiv.org/abs/2309.12767</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12767]] Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models(http://arxiv.org/abs/2309.12767)</code></li>
<li>Summary: <p>Large Language Models (LLMs), acting as a powerful reasoner and generator,
exhibit extraordinary performance across various natural language tasks, such
as question answering (QA). Among these tasks, Multi-Hop Question Answering
(MHQA) stands as a widely discussed category, necessitating seamless
integration between LLMs and the retrieval of external knowledge. Existing
methods employ LLM to generate reasoning paths and plans, and utilize IR to
iteratively retrieve related knowledge, but these approaches have inherent
flaws. On one hand, Information Retriever (IR) is hindered by the low quality
of generated queries by LLM. On the other hand, LLM is easily misguided by the
irrelevant knowledge by IR. These inaccuracies, accumulated by the iterative
interaction between IR and LLM, lead to a disaster in effectiveness at the end.
To overcome above barriers, in this paper, we propose a novel pipeline for MHQA
called Furthest-Reasoning-with-Plan-Assessment (FuRePA), including an improved
framework (Furthest Reasoning) and an attached module (Plan Assessor). 1)
Furthest reasoning operates by masking previous reasoning path and generated
queries for LLM, encouraging LLM generating chain of thought from scratch in
each iteration. This approach enables LLM to break the shackle built by
previous misleading thoughts and queries (if any). 2) The Plan Assessor is a
trained evaluator that selects an appropriate plan from a group of candidate
plans proposed by LLM. Our methods are evaluated on three highly recognized
public multi-hop question answering datasets and outperform state-of-the-art on
most metrics (achieving a 10%-12% in answer accuracy).
</p></li>
</ul>

<h3>Title: ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT. (arXiv:2309.12808v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12808">http://arxiv.org/abs/2309.12808</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12808]] ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT(http://arxiv.org/abs/2309.12808)</code></li>
<li>Summary: <p>As a common approach to learning English, reading comprehension primarily
entails reading articles and answering related questions. However, the
complexity of designing effective exercises results in students encountering
standardized questions, making it challenging to align with individualized
learners' reading comprehension ability. By leveraging the advanced
capabilities offered by large language models, exemplified by ChatGPT, this
paper presents a novel personalized support system for reading comprehension,
referred to as ChatPRCS, based on the Zone of Proximal Development theory.
ChatPRCS employs methods including reading comprehension proficiency
prediction, question generation, and automatic evaluation, among others, to
enhance reading comprehension instruction. First, we develop a new algorithm
that can predict learners' reading comprehension abilities using their
historical data as the foundation for generating questions at an appropriate
level of difficulty. Second, a series of new ChatGPT prompt patterns is
proposed to address two key aspects of reading comprehension objectives:
question generation, and automated evaluation. These patterns further improve
the quality of generated questions. Finally, by integrating personalized
ability and reading comprehension prompt patterns, ChatPRCS is systematically
validated through experiments. Empirical results demonstrate that it provides
learners with high-quality reading comprehension questions that are broadly
aligned with expert-crafted questions at a statistical level.
</p></li>
</ul>

<h3>Title: Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts. (arXiv:2309.12863v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12863">http://arxiv.org/abs/2309.12863</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12863]] Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts(http://arxiv.org/abs/2309.12863)</code></li>
<li>Summary: <p>Neural machine translation (NMT) has shown impressive performance when
trained on large-scale corpora. However, generic NMT systems have demonstrated
poor performance on out-of-domain translation. To mitigate this issue, several
domain adaptation methods have recently been proposed which often lead to
better translation quality than genetic NMT systems. While there has been some
continuous progress in NMT for English and other European languages, domain
adaption in Arabic has received little attention in the literature. The current
study, therefore, aims to explore the effectiveness of domain-specific
adaptation for Arabic MT (AMT), in yet unexplored domain, financial news
articles. To this end, we developed carefully a parallel corpus for
Arabic-English (AR- EN) translation in the financial domain for benchmarking
different domain adaptation methods. We then fine-tuned several pre-trained NMT
and Large Language models including ChatGPT-3.5 Turbo on our dataset. The
results showed that the fine-tuning is successful using just a few well-aligned
in-domain AR-EN segments. The quality of ChatGPT translation was superior than
other models based on automatic and human evaluations. To the best of our
knowledge, this is the first work on fine-tuning ChatGPT towards financial
domain transfer learning. To contribute to research in domain translation, we
made our datasets and fine-tuned models available at
https://huggingface.co/asas-ai/.
</p></li>
</ul>

<h3>Title: AnglE-Optimized Text Embeddings. (arXiv:2309.12871v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12871">http://arxiv.org/abs/2309.12871</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12871]] AnglE-Optimized Text Embeddings(http://arxiv.org/abs/2309.12871)</code></li>
<li>Summary: <p>High-quality text embedding is pivotal in improving semantic textual
similarity (STS) tasks, which are crucial components in Large Language Model
(LLM) applications. However, a common challenge existing text embedding models
face is the problem of vanishing gradients, primarily due to their reliance on
the cosine function in the optimization objective, which has saturation zones.
To address this issue, this paper proposes a novel angle-optimized text
embedding model called AnglE. The core idea of AnglE is to introduce angle
optimization in a complex space. This novel approach effectively mitigates the
adverse effects of the saturation zone in the cosine function, which can impede
gradient and hinder optimization processes. To set up a comprehensive STS
evaluation, we experimented on existing short-text STS datasets and a newly
collected long-text STS dataset from GitHub Issues. Furthermore, we examine
domain-specific STS scenarios with limited labeled data and explore how AnglE
works with LLM-annotated data. Extensive experiments were conducted on various
tasks including short-text STS, long-text STS, and domain-specific STS tasks.
The results show that AnglE outperforms the state-of-the-art (SOTA) STS models
that ignore the cosine saturation zone. These findings demonstrate the ability
of AnglE to generate high-quality text embeddings and the usefulness of angle
optimization in STS.
</p></li>
</ul>

<h3>Title: Affect Recognition in Conversations Using Large Language Models. (arXiv:2309.12881v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12881">http://arxiv.org/abs/2309.12881</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12881]] Affect Recognition in Conversations Using Large Language Models(http://arxiv.org/abs/2309.12881)</code></li>
<li>Summary: <p>Affect recognition, encompassing emotions, moods, and feelings, plays a
pivotal role in human communication. In the realm of conversational artificial
intelligence (AI), the ability to discern and respond to human affective cues
is a critical factor for creating engaging and empathetic interactions. This
study delves into the capacity of large language models (LLMs) to recognise
human affect in conversations, with a focus on both open-domain chit-chat
dialogues and task-oriented dialogues. Leveraging three diverse datasets,
namely IEMOCAP, EmoWOZ, and DAIC-WOZ, covering a spectrum of dialogues from
casual conversations to clinical interviews, we evaluated and compared LLMs'
performance in affect recognition. Our investigation explores the zero-shot and
few-shot capabilities of LLMs through in-context learning (ICL) as well as
their model capacities through task-specific fine-tuning. Additionally, this
study takes into account the potential impact of automatic speech recognition
(ASR) errors on LLM predictions. With this work, we aim to shed light on the
extent to which LLMs can replicate human-like affect recognition capabilities
in conversations.
</p></li>
</ul>

<h3>Title: TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts. (arXiv:2309.12934v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12934">http://arxiv.org/abs/2309.12934</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12934]] TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts(http://arxiv.org/abs/2309.12934)</code></li>
<li>Summary: <p>Recent advances in Large Language Models (LLMs) have enabled the generation
of open-ended high-quality texts, that are non-trivial to distinguish from
human-written texts. We refer to such LLM-generated texts as \emph{deepfake
texts}. There are currently over 11K text generation models in the huggingface
model repo. As such, users with malicious intent can easily use these
open-sourced LLMs to generate harmful texts and misinformation at scale. To
mitigate this problem, a computational method to determine if a given text is a
deepfake text or not is desired--i.e., Turing Test (TT). In particular, in this
work, we investigate the more general version of the problem, known as
\emph{Authorship Attribution (AA)}, in a multi-class setting--i.e., not only
determining if a given text is a deepfake text or not but also being able to
pinpoint which LLM is the author. We propose \textbf{TopRoBERTa} to improve
existing AA solutions by capturing more linguistic patterns in deepfake texts
by including a Topological Data Analysis (TDA) layer in the RoBERTa model. We
show the benefits of having a TDA layer when dealing with noisy, imbalanced,
and heterogeneous datasets, by extracting TDA features from the reshaped
$pooled\_output$ of RoBERTa as input. We use RoBERTa to capture contextual
representations (i.e., semantic and syntactic linguistic features), while using
TDA to capture the shape and structure of data (i.e., linguistic structures).
Finally, \textbf{TopRoBERTa}, outperforms the vanilla RoBERTa in 2/3 datasets,
achieving up to 7\% increase in Macro F1 score.
</p></li>
</ul>

<h3>Title: Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models. (arXiv:2309.12940v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12940">http://arxiv.org/abs/2309.12940</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12940]] Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models(http://arxiv.org/abs/2309.12940)</code></li>
<li>Summary: <p>Task-oriented dialogue (TOD) systems facilitate users in executing various
activities via multi-turn dialogues, but Large Language Models (LLMs) often
struggle to comprehend these intricate contexts. In this study, we propose a
novel "Self-Explanation" prompting strategy to enhance the comprehension
abilities of LLMs in multi-turn dialogues. This task-agnostic approach requires
the model to analyze each dialogue utterance before task execution, thereby
improving performance across various dialogue-centric tasks. Experimental
results from six benchmark datasets confirm that our method consistently
outperforms other zero-shot prompts and matches or exceeds the efficacy of
few-shot prompts, demonstrating its potential as a powerful tool in enhancing
LLMs' comprehension in complex dialogue tasks.
</p></li>
</ul>

<h3>Title: ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs. (arXiv:2309.13007v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.13007">http://arxiv.org/abs/2309.13007</a></li>
<li>Code URL: https://github.com/dinobby/reconcile</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.13007]] ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs(http://arxiv.org/abs/2309.13007)</code></li>
<li>Summary: <p>Large Language Models (LLMs) still struggle with complex reasoning tasks.
Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a
multi-model multi-agent framework designed as a round table conference among
diverse LLM agents to foster diverse thoughts and discussion for improved
consensus. ReConcile enhances the reasoning capabilities of LLMs by holding
multiple rounds of discussion, learning to convince other agents to improve
their answers, and employing a confidence-weighted voting mechanism. In each
round, ReConcile initiates discussion between agents via a 'discussion prompt'
that consists of (a) grouped answers and explanations generated by each agent
in the previous round, (b) their uncertainties, and (c) demonstrations of
answer-rectifying human explanations, used for convincing other agents. This
discussion prompt enables each agent to revise their responses in light of
insights from other agents. Once a consensus is reached and the discussion
ends, ReConcile determines the final answer by leveraging the confidence of
each agent in a weighted voting scheme. We implement ReConcile with ChatGPT,
Bard, and Claude2 as the three agents. Our experimental results on various
benchmarks demonstrate that ReConcile significantly enhances the reasoning
performance of the agents (both individually and as a team), surpassing prior
single-agent and multi-agent baselines by 7.7% and also outperforming GPT-4 on
some of these datasets. We also experiment with GPT-4 itself as one of the
agents in ReConcile and demonstrate that its initial performance also improves
by absolute 10.0% through discussion and feedback from other agents. Finally,
we also analyze the accuracy after every round and observe that ReConcile
achieves better and faster consensus between agents, compared to a multi-agent
debate baseline. Our code is available at: https://github.com/dinobby/ReConcile
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Spatially Guiding Unsupervised Semantic Segmentation Through Depth-Informed Feature Distillation and Sampling. (arXiv:2309.12378v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12378">http://arxiv.org/abs/2309.12378</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12378]] Spatially Guiding Unsupervised Semantic Segmentation Through Depth-Informed Feature Distillation and Sampling(http://arxiv.org/abs/2309.12378)</code></li>
<li>Summary: <p>Traditionally, training neural networks to perform semantic segmentation
required expensive human-made annotations. But more recently, advances in the
field of unsupervised learning have made significant progress on this issue and
towards closing the gap to supervised algorithms. To achieve this, semantic
knowledge is distilled by learning to correlate randomly sampled features from
images across an entire dataset. In this work, we build upon these advances by
incorporating information about the structure of the scene into the training
process through the use of depth information. We achieve this by (1) learning
depth-feature correlation by spatially correlate the feature maps with the
depth maps to induce knowledge about the structure of the scene and (2)
implementing farthest-point sampling to more effectively select relevant
features by utilizing 3D sampling techniques on depth information of the scene.
Finally, we demonstrate the effectiveness of our technical contributions
through extensive experimentation and present significant improvements in
performance across multiple benchmark datasets.
</p></li>
</ul>

<h3>Title: Triple-View Knowledge Distillation for Semi-Supervised Semantic Segmentation. (arXiv:2309.12557v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12557">http://arxiv.org/abs/2309.12557</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12557]] Triple-View Knowledge Distillation for Semi-Supervised Semantic Segmentation(http://arxiv.org/abs/2309.12557)</code></li>
<li>Summary: <p>To alleviate the expensive human labeling, semi-supervised semantic
segmentation employs a few labeled images and an abundant of unlabeled images
to predict the pixel-level label map with the same size. Previous methods often
adopt co-training using two convolutional networks with the same architecture
but different initialization, which fails to capture the sufficiently diverse
features. This motivates us to use tri-training and develop the triple-view
encoder to utilize the encoders with different architectures to derive diverse
features, and exploit the knowledge distillation skill to learn the
complementary semantics among these encoders. Moreover, existing methods simply
concatenate the features from both encoder and decoder, resulting in redundant
features that require large memory cost. This inspires us to devise a
dual-frequency decoder that selects those important features by projecting the
features from the spatial domain to the frequency domain, where the
dual-frequency channel attention mechanism is introduced to model the feature
importance. Therefore, we propose a Triple-view Knowledge Distillation
framework, termed TriKD, for semi-supervised semantic segmentation, including
the triple-view encoder and the dual-frequency decoder. Extensive experiments
were conducted on two benchmarks, \ie, Pascal VOC 2012 and Cityscapes, whose
results verify the superiority of the proposed method with a good tradeoff
between precision and inference speed.
</p></li>
</ul>

<h3>Title: Decision Fusion Network with Perception Fine-tuning for Defect Classification. (arXiv:2309.12630v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12630">http://arxiv.org/abs/2309.12630</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12630]] Decision Fusion Network with Perception Fine-tuning for Defect Classification(http://arxiv.org/abs/2309.12630)</code></li>
<li>Summary: <p>Surface defect inspection is an important task in industrial inspection. Deep
learning-based methods have demonstrated promising performance in this domain.
Nevertheless, these methods still suffer from misjudgment when encountering
challenges such as low-contrast defects and complex backgrounds. To overcome
these issues, we present a decision fusion network (DFNet) that incorporates
the semantic decision with the feature decision to strengthen the decision
ability of the network. In particular, we introduce a decision fusion module
(DFM) that extracts a semantic vector from the semantic decision branch and a
feature vector for the feature decision branch and fuses them to make the final
classification decision. In addition, we propose a perception fine-tuning
module (PFM) that fine-tunes the foreground and background during the
segmentation stage. PFM generates the semantic and feature outputs that are
sent to the classification decision stage. Furthermore, we present an
inner-outer separation weight matrix to address the impact of label edge
uncertainty during segmentation supervision. Our experimental results on the
publicly available datasets including KolektorSDD2 (96.1% AP) and
Magnetic-tile-defect-datasets (94.6% mAP) demonstrate the effectiveness of the
proposed method.
</p></li>
</ul>

<h3>Title: FP-PET: Large Model, Multiple Loss And Focused Practice. (arXiv:2309.12650v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12650">http://arxiv.org/abs/2309.12650</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12650]] FP-PET: Large Model, Multiple Loss And Focused Practice(http://arxiv.org/abs/2309.12650)</code></li>
<li>Summary: <p>This study presents FP-PET, a comprehensive approach to medical image
segmentation with a focus on CT and PET images. Utilizing a dataset from the
AutoPet2023 Challenge, the research employs a variety of machine learning
models, including STUNet-large, SwinUNETR, and VNet, to achieve
state-of-the-art segmentation performance. The paper introduces an aggregated
score that combines multiple evaluation metrics such as Dice score, false
positive volume (FPV), and false negative volume (FNV) to provide a holistic
measure of model effectiveness. The study also discusses the computational
challenges and solutions related to model training, which was conducted on
high-performance GPUs. Preprocessing and postprocessing techniques, including
gaussian weighting schemes and morphological operations, are explored to
further refine the segmentation output. The research offers valuable insights
into the challenges and solutions for advanced medical image segmentation.
</p></li>
</ul>

<h3>Title: NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything. (arXiv:2309.12790v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12790">http://arxiv.org/abs/2309.12790</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12790]] NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything(http://arxiv.org/abs/2309.12790)</code></li>
<li>Summary: <p>With the development of the neural field, reconstructing the 3D model of a
target object from multi-view inputs has recently attracted increasing
attention from the community. Existing methods normally learn a neural field
for the whole scene, while it is still under-explored how to reconstruct a
certain object indicated by users on-the-fly. Considering the Segment Anything
Model (SAM) has shown effectiveness in segmenting any 2D images, in this paper,
we propose Neural Object Cloning (NOC), a novel high-quality 3D object
reconstruction method, which leverages the benefits of both neural field and
SAM from two aspects. Firstly, to separate the target object from the scene, we
propose a novel strategy to lift the multi-view 2D segmentation masks of SAM
into a unified 3D variation field. The 3D variation field is then projected
into 2D space and generates the new prompts for SAM. This process is iterative
until convergence to separate the target object from the scene. Then, apart
from 2D masks, we further lift the 2D features of the SAM encoder into a 3D SAM
field in order to improve the reconstruction quality of the target object. NOC
lifts the 2D masks and features of SAM into the 3D neural field for
high-quality target object reconstruction. We conduct detailed experiments on
several benchmark datasets to demonstrate the advantages of our method. The
code will be released.
</p></li>
</ul>

<h3>Title: Scalable Semantic 3D Mapping of Coral Reefs with Deep Learning. (arXiv:2309.12804v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12804">http://arxiv.org/abs/2309.12804</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12804]] Scalable Semantic 3D Mapping of Coral Reefs with Deep Learning(http://arxiv.org/abs/2309.12804)</code></li>
<li>Summary: <p>Coral reefs are among the most diverse ecosystems on our planet, and are
depended on by hundreds of millions of people. Unfortunately, most coral reefs
are existentially threatened by global climate change and local anthropogenic
pressures. To better understand the dynamics underlying deterioration of reefs,
monitoring at high spatial and temporal resolution is key. However,
conventional monitoring methods for quantifying coral cover and species
abundance are limited in scale due to the extensive manual labor required.
Although computer vision tools have been employed to aid in this process, in
particular SfM photogrammetry for 3D mapping and deep neural networks for image
segmentation, analysis of the data products creates a bottleneck, effectively
limiting their scalability. This paper presents a new paradigm for mapping
underwater environments from ego-motion video, unifying 3D mapping systems that
use machine learning to adapt to challenging conditions under water, combined
with a modern approach for semantic segmentation of images. The method is
exemplified on coral reefs in the northern Gulf of Aqaba, Red Sea,
demonstrating high-precision 3D semantic mapping at unprecedented scale with
significantly reduced required labor costs: a 100 m video transect acquired
within 5 minutes of diving with a cheap consumer-grade camera can be fully
automatically analyzed within 5 minutes. Our approach significantly scales up
coral reef monitoring by taking a leap towards fully automatic analysis of
video transects. The method democratizes coral reef transects by reducing the
labor, equipment, logistics, and computing cost. This can help to inform
conservation policies more efficiently. The underlying computational method of
learning-based Structure-from-Motion has broad implications for fast low-cost
mapping of underwater environments other than coral reefs.
</p></li>
</ul>

<h3>Title: Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography. (arXiv:2309.12829v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12829">http://arxiv.org/abs/2309.12829</a></li>
<li>Code URL: https://github.com/naamiinepal/synthetic-boost</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12829]] Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography(http://arxiv.org/abs/2309.12829)</code></li>
<li>Summary: <p>Accurate segmentation is essential for echocardiography-based assessment of
cardiovascular diseases (CVDs). However, the variability among sonographers and
the inherent challenges of ultrasound images hinder precise segmentation. By
leveraging the joint representation of image and text modalities,
Vision-Language Segmentation Models (VLSMs) can incorporate rich contextual
information, potentially aiding in accurate and explainable segmentation.
However, the lack of readily available data in echocardiography hampers the
training of VLSMs. In this study, we explore using synthetic datasets from
Semantic Diffusion Models (SDMs) to enhance VLSMs for echocardiography
segmentation. We evaluate results for two popular VLSMs (CLIPSeg and CRIS)
using seven different kinds of language prompts derived from several
attributes, automatically extracted from echocardiography images, segmentation
masks, and their metadata. Our results show improved metrics and faster
convergence when pretraining VLSMs on SDM-generated synthetic images before
finetuning on real images. The code, configs, and prompts are available at
https://github.com/naamiinepal/synthetic-boost.
</p></li>
</ul>

<h3>Title: Background Activation Suppression for Weakly Supervised Object Localization and Semantic Segmentation. (arXiv:2309.12943v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.12943">http://arxiv.org/abs/2309.12943</a></li>
<li>Code URL: https://github.com/wpy1999/bas-extension</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.12943]] Background Activation Suppression for Weakly Supervised Object Localization and Semantic Segmentation(http://arxiv.org/abs/2309.12943)</code></li>
<li>Summary: <p>Weakly supervised object localization and semantic segmentation aim to
localize objects using only image-level labels. Recently, a new paradigm has
emerged by generating a foreground prediction map (FPM) to achieve pixel-level
localization. While existing FPM-based methods use cross-entropy to evaluate
the foreground prediction map and to guide the learning of the generator, this
paper presents two astonishing experimental observations on the object
localization learning process: For a trained network, as the foreground mask
expands, 1) the cross-entropy converges to zero when the foreground mask covers
only part of the object region. 2) The activation value continuously increases
until the foreground mask expands to the object boundary. Therefore, to achieve
a more effective localization performance, we argue for the usage of activation
value to learn more object regions. In this paper, we propose a Background
Activation Suppression (BAS) method. Specifically, an Activation Map Constraint
(AMC) module is designed to facilitate the learning of generator by suppressing
the background activation value. Meanwhile, by using foreground region guidance
and area constraint, BAS can learn the whole region of the object. In the
inference phase, we consider the prediction maps of different categories
together to obtain the final localization results. Extensive experiments show
that BAS achieves significant and consistent improvement over the baseline
methods on the CUB-200-2011 and ILSVRC datasets. In addition, our method also
achieves state-of-the-art weakly supervised semantic segmentation performance
on the PASCAL VOC 2012 and MS COCO 2014 datasets. Code and models are available
at https://github.com/wpy1999/BAS-Extension.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
