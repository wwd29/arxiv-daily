<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-02-06</h1>
<h3>Title: Detection of Machine-Generated Text: Literature Survey</h3>
<ul>
<li><strong>Authors: </strong>Dmytro Valiaiev</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01642">https://arxiv.org/abs/2402.01642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01642">https://arxiv.org/pdf/2402.01642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01642]] Detection of Machine-Generated Text: Literature Survey(https://arxiv.org/abs/2402.01642)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>Since language models produce fake text quickly and easily, there is an oversupply of such content in the public domain. The degree of sophistication and writing style has reached a point where differentiating between human authored and machine-generated content is nearly impossible. As a result, works generated by language models rather than human authors have gained significant media attention and stirred controversy.Concerns regarding the possible influence of advanced language models on society have also arisen, needing a fuller knowledge of these processes. Natural language generation (NLG) and generative pre-trained transformer (GPT) models have revolutionized a variety of sectors: the scope not only permeated throughout journalism and customer service but also reached academia. To mitigate the hazardous implications that may arise from the use of these models, preventative measures must be implemented, such as providing human agents with the capacity to distinguish between artificially made and human composed texts utilizing automated systems and possibly reverse-engineered language models. Furthermore, to ensure a balanced and responsible approach, it is critical to have a full grasp of the socio-technological ramifications of these breakthroughs. This literature survey aims to compile and synthesize accomplishments and developments in the aforementioned work, while also identifying future prospects. It also gives an overview of machine-generated text trends and explores the larger societal implications. Ultimately, this survey intends to contribute to the development of robust and effective approaches for resolving the issues connected with the usage and detection of machine-generated text by exploring the interplay between the capabilities of language models and their possible implications.</li>
</ul>

<h3>Title: L-TUNING: Synchronized Label Tuning for Prompt and Prefix in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Md. Kowsher, Md. Shohanur Islam Sobuj, Asif Mahmud, Nusrat Jahan Prottasha, Prakash Bhat</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01643">https://arxiv.org/abs/2402.01643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01643">https://arxiv.org/pdf/2402.01643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01643]] L-TUNING: Synchronized Label Tuning for Prompt and Prefix in LLMs(https://arxiv.org/abs/2402.01643)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Efficiently fine-tuning Large Language Models (LLMs) for specific tasks presents a considerable challenge in natural language processing. Traditional methods, like prompt or prefix tuning, typically rely on arbitrary tokens for training, leading to prolonged training times and generalized token use across various class labels. To address these issues, this paper introduces L-Tuning, an efficient fine-tuning approach designed for classification tasks within the Natural Language Inference (NLI) framework. Diverging from conventional methods, L-Tuning focuses on the fine-tuning of label tokens processed through a pre-trained LLM, thereby harnessing its pre-existing semantic knowledge. This technique not only improves the fine-tuning accuracy and efficiency but also facilitates the generation of distinct label embeddings for each class, enhancing the model's training nuance. Our experimental results indicate a significant improvement in training efficiency and classification accuracy with L-Tuning compared to traditional approaches, marking a promising advancement in fine-tuning LLMs for complex language tasks. \\ Code is available at: \textcolor{red}{\href{https://github.com/Kowsher/L-Tuning}{\texttt{https://github.com/Kowsher/L-Tuning}}}.</li>
</ul>

<h3>Title: Tracing the Genealogies of Ideas with Large Language Model Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Lucian Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01661">https://arxiv.org/abs/2402.01661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01661">https://arxiv.org/pdf/2402.01661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01661]] Tracing the Genealogies of Ideas with Large Language Model Embeddings(https://arxiv.org/abs/2402.01661)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, I present a novel method to detect intellectual influence across a large corpus. Taking advantage of the unique affordances of large language models in encoding semantic and structural meaning while remaining robust to paraphrasing, we can search for substantively similar ideas and hints of intellectual influence in a computationally efficient manner. Such a method allows us to operationalize different levels of confidence: we can allow for direct quotation, paraphrase, or speculative similarity while remaining open about the limitations of each threshold. I apply an ensemble method combining General Text Embeddings, a state-of-the-art sentence embedding method optimized to capture semantic content and an Abstract Meaning Representation graph representation designed to capture structural similarities in argumentation style and the use of metaphor. I apply this method to vectorize sentences from a corpus of roughly 400,000 nonfiction books and academic publications from the 19th century for instances of ideas and arguments appearing in Darwin's publications. This functions as an initial evaluation and proof of concept; the method is not limited to detecting Darwinian ideas but is capable of detecting similarities on a large scale in a wide range of corpora and contexts.</li>
</ul>

<h3>Title: Language models align with human judgments on key grammatical  constructions</h3>
<ul>
<li><strong>Authors: </strong>Jennifer Hu, Kyle Mahowald, Gary Lupyan, Anna Ivanova, Roger Levy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01676">https://arxiv.org/abs/2402.01676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01676">https://arxiv.org/pdf/2402.01676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01676]] Language models align with human judgments on key grammatical  constructions(https://arxiv.org/abs/2402.01676)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Do Large Language Models (LLMs) make human-like linguistic generalizations? Dentella et al. (2023; "DGL") prompt several LLMs ("Is the following sentence grammatically correct in English?") to elicit grammaticality judgments of 80 English sentences, concluding that LLMs demonstrate a "yes-response bias" and a "failure to distinguish grammatical from ungrammatical sentences". We re-evaluate LLM performance using well-established practices and find that DGL's data in fact provide evidence for just how well LLMs capture human behaviors. Models not only achieve high accuracy overall, but also capture fine-grained variation in human linguistic judgments.</li>
</ul>

<h3>Title: Large Language Model based Multi-Agents: A Survey of Progress and  Challenges</h3>
<ul>
<li><strong>Authors: </strong>Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, Xiangliang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01680">https://arxiv.org/abs/2402.01680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01680">https://arxiv.org/pdf/2402.01680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01680]] Large Language Model based Multi-Agents: A Survey of Progress and  Challenges(https://arxiv.org/abs/2402.01680)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges. Our goal is for readers to gain substantial insights on the following questions: What domains and environments do LLM-based multi-agents simulate? How are these agents profiled and how do they communicate? What mechanisms contribute to the growth of agents' capacities? For those interested in delving into this field of study, we also summarize the commonly used datasets or benchmarks for them to have convenient access. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository, dedicated to outlining the research on LLM-based multi-agent systems.</li>
</ul>

<h3>Title: Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social  Media Communications</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Zhou, Paiheng Xu, Xiyao Wang, Xuan Lu, Ge Gao, Wei Ai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01681">https://arxiv.org/abs/2402.01681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01681">https://arxiv.org/pdf/2402.01681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01681]] Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social  Media Communications(https://arxiv.org/abs/2402.01681)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Emojis, which encapsulate semantics beyond mere words or phrases, have become prevalent in social network communications. This has spurred increasing scholarly interest in exploring their attributes and functionalities. However, emoji-related research and application face two primary challenges. First, researchers typically rely on crowd-sourcing to annotate emojis in order to understand their sentiments, usage intentions, and semantic meanings. Second, subjective interpretations by users can often lead to misunderstandings of emojis and cause the communication barrier. Large Language Models (LLMs) have achieved significant success in various annotation tasks, with ChatGPT demonstrating expertise across multiple domains. In our study, we assess ChatGPT's effectiveness in handling previously annotated and downstream tasks. Our objective is to validate the hypothesis that ChatGPT can serve as a viable alternative to human annotators in emoji research and that its ability to explain emoji meanings can enhance clarity and transparency in online communications. Our findings indicate that ChatGPT has extensive knowledge of emojis. It is adept at elucidating the meaning of emojis across various application scenarios and demonstrates the potential to replace human annotators in a range of tasks.</li>
</ul>

<h3>Title: A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs  Using the CGC-LORA Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Chao Song, Zhihao Ye, Qiqiang Lin, Qiuying Peng, Jun Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01684">https://arxiv.org/abs/2402.01684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01684">https://arxiv.org/pdf/2402.01684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01684]] A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs  Using the CGC-LORA Algorithm(https://arxiv.org/abs/2402.01684)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the productive evolution of large language models (LLMs) in the field of natural language processing (NLP), tons of effort has been made to effectively fine-tune common pre-trained LLMs to fulfill a variety of tasks in one or multiple specific domain. In practice, there are two prevailing ways, in which the adaptation can be achieved: (i) Multiple Independent Models: Pre-trained LLMs are fine-tuned a few times independently using the corresponding training samples from each task. (ii) An Integrated Model: Samples from all tasks are employed to fine-tune a pre-trianed LLM unitedly. To address the high computing cost and seesawing issue simultaneously, we propose a unified framework that implements a 1 + N mutli-task fine-tuning pattern in LLMs using a novel Customized Gate Control (CGC) Low-rank Adaptation (LoRA) algorithm. Our work aims to take an advantage of both MTL (i.e., CGC) and PEFT (i.e., LoRA) scheme. For a given cluster of tasks, we design an innovative layer that contains two types of experts as additional trainable parameters to make LoRA be compatible with MTL. To comprehensively evaluate the proposed framework, we conduct well-designed experiments on two public datasets. The experimental results demonstrate that the unified framework with CGC-LoRA modules achieves higher evaluation scores than all benchmarks on both two datasets.</li>
</ul>

<h3>Title: SMUTF: Schema Matching Using Generative Tags and Hybrid Features</h3>
<ul>
<li><strong>Authors: </strong>Yu Zhang, Mei Di, Haozheng Luo, Chenwei Xu, Richard Tzong-Han Tsai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01685">https://arxiv.org/abs/2402.01685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01685">https://arxiv.org/pdf/2402.01685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01685]] SMUTF: Schema Matching Using Generative Tags and Hybrid Features(https://arxiv.org/abs/2402.01685)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>We introduce SMUTF, a unique approach for large-scale tabular data schema matching (SM), which assumes that supervised learning does not affect performance in open-domain tasks, thereby enabling effective cross-domain matching. This system uniquely combines rule-based feature engineering, pre-trained language models, and generative large language models. In an innovative adaptation inspired by the Humanitarian Exchange Language, we deploy 'generative tags' for each data column, enhancing the effectiveness of SM. SMUTF exhibits extensive versatility, working seamlessly with any pre-existing pre-trained embeddings, classification methods, and generative models. Recognizing the lack of extensive, publicly available datasets for SM, we have created and open-sourced the HDXSM dataset from the public humanitarian data. We believe this to be the most exhaustive SM dataset currently available. In evaluations across various public datasets and the novel HDXSM dataset, SMUTF demonstrated exceptional performance, surpassing existing state-of-the-art models in terms of accuracy and efficiency, and} improving the F1 score by 11.84% and the AUC of ROC by 5.08%.</li>
</ul>

<h3>Title: Linguistic-Based Mild Cognitive Impairment Detection Using Informative  Loss</h3>
<ul>
<li><strong>Authors: </strong>Ali Pourramezan Fard, Mohammad H. Mahoor, Muath Alsuhaibani, Hiroko H. Dodgec</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01690">https://arxiv.org/abs/2402.01690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01690">https://arxiv.org/pdf/2402.01690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01690]] Linguistic-Based Mild Cognitive Impairment Detection Using Informative  Loss(https://arxiv.org/abs/2402.01690)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This paper presents a deep learning method using Natural Language Processing (NLP) techniques, to distinguish between Mild Cognitive Impairment (MCI) and Normal Cognitive (NC) conditions in older adults. We propose a framework that analyzes transcripts generated from video interviews collected within the I-CONECT study project, a randomized controlled trial aimed at improving cognitive functions through video chats. Our proposed NLP framework consists of two Transformer-based modules, namely Sentence Embedding (SE) and Sentence Cross Attention (SCA). First, the SE module captures contextual relationships between words within each sentence. Subsequently, the SCA module extracts temporal features from a sequence of sentences. This feature is then used by a Multi-Layer Perceptron (MLP) for the classification of subjects into MCI or NC. To build a robust model, we propose a novel loss function, called InfoLoss, that considers the reduction in entropy by observing each sequence of sentences to ultimately enhance the classification accuracy. The results of our comprehensive model evaluation using the I-CONECT dataset show that our framework can distinguish between MCI and NC with an average area under the curve of 84.75%.</li>
</ul>

<h3>Title: Quality of Answers of Generative Large Language Models vs Peer Patients  for Interpreting Lab Test Results for Lay Patients: Evaluation Study</h3>
<ul>
<li><strong>Authors: </strong>Zhe He, Balu Bhasuran, Qiao Jin, Shubo Tian, Karim Hanna, Cindy Shavor, Lisbeth Garcia Arguello, Patrick Murray, Zhiyong Lu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01693">https://arxiv.org/abs/2402.01693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01693">https://arxiv.org/pdf/2402.01693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01693]] Quality of Answers of Generative Large Language Models vs Peer Patients  for Interpreting Lab Test Results for Lay Patients: Evaluation Study(https://arxiv.org/abs/2402.01693)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Lab results are often confusing and hard to understand. Large language models (LLMs) such as ChatGPT have opened a promising avenue for patients to get their questions answered. We aim to assess the feasibility of using LLMs to generate relevant, accurate, helpful, and unharmful responses to lab test-related questions asked by patients and to identify potential issues that can be mitigated with augmentation approaches. We first collected lab test results related question and answer data from Yahoo! Answers and selected 53 QA pairs for this study. Using the LangChain framework and ChatGPT web portal, we generated responses to the 53 questions from four LLMs including GPT-4, Meta LLaMA 2, MedAlpaca, and ORCA_mini. We first assessed the similarity of their answers using standard QA similarity-based evaluation metrics including ROUGE, BLEU, METEOR, BERTScore. We also utilized an LLM-based evaluator to judge whether a target model has higher quality in terms of relevance, correctness, helpfulness, and safety than the baseline model. Finally, we performed a manual evaluation with medical experts for all the responses to seven selected questions on the same four aspects. The results of Win Rate and medical expert evaluation both showed that GPT-4's responses achieved better scores than all the other LLM responses and human responses on all four aspects (relevance, correctness, helpfulness, and safety). However, LLM responses occasionally also suffer from a lack of interpretation in one's medical context, incorrect statements, and lack of references. We find that compared to other three LLMs and human answer from the Q&A website, GPT-4's responses are more accurate, helpful, relevant, and safer. However, there are cases which GPT-4 responses are inaccurate and not individualized. We identified a number of ways to improve the quality of LLM responses.</li>
</ul>

<h3>Title: ARGS: Alignment as Reward-Guided Search</h3>
<ul>
<li><strong>Authors: </strong>Maxim Khanov, Jirayu Burapacheep, Yixuan Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01694">https://arxiv.org/abs/2402.01694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01694">https://arxiv.org/pdf/2402.01694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01694]] ARGS: Alignment as Reward-Guided Search(https://arxiv.org/abs/2402.01694)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models with human objectives is paramount, yet common approaches including RLHF suffer from unstable and resource-intensive training. In response to this challenge, we introduce ARGS, Alignment as Reward-Guided Search, a novel framework that integrates alignment into the decoding process, eliminating the need for expensive RL training. By adjusting the model's probabilistic predictions using a reward signal, ARGS generates texts with semantic diversity while being aligned with human preferences, offering a promising and flexible solution for aligning language models. Notably, ARGS demonstrates consistent enhancements in average reward compared to baselines across diverse alignment tasks and various model dimensions. For example, under the same greedy-based decoding strategy, our method improves the average reward by 19.56% relative to the baseline and secures a preference or tie score of 64.33% in GPT-4 evaluation. We believe that our framework, emphasizing decoding-time alignment, paves the way for more responsive language models in the future. Code is publicly available at: \url{https://github.com/deeplearning-wisc/args}.</li>
</ul>

<h3>Title: Language-Guided World Models: A Model-Based Approach to AI Control</h3>
<ul>
<li><strong>Authors: </strong>Alex Zhang, Khanh Nguyen, Jens Tuyls, Albert Lin, Karthik Narasimhan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01695">https://arxiv.org/abs/2402.01695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01695">https://arxiv.org/pdf/2402.01695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01695]] Language-Guided World Models: A Model-Based Approach to AI Control(https://arxiv.org/abs/2402.01695)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Installing probabilistic world models into artificial agents opens an efficient channel for humans to communicate with and control these agents. In addition to updating agent policies, humans can modify their internal world models in order to influence their decisions. The challenge, however, is that currently existing world models are difficult for humans to adapt because they lack a natural communication interface. Aimed at addressing this shortcoming, we develop Language-Guided World Models (LWMs), which can capture environment dynamics by reading language descriptions. These models enhance agent communication efficiency, allowing humans to simultaneously alter their behavior on multiple tasks with concise language feedback. They also enable agents to self-learn from texts originally written to instruct humans. To facilitate the development of LWMs, we design a challenging benchmark based on the game of MESSENGER (Hanjie et al., 2021), requiring compositional generalization to new language descriptions and environment dynamics. Our experiments reveal that the current state-of-the-art Transformer architecture performs poorly on this benchmark, motivating us to design a more robust architecture. To showcase the practicality of our proposed LWMs, we simulate a scenario where these models augment the interpretability and safety of an agent by enabling it to generate and discuss plans with a human before execution. By effectively incorporating language feedback on the plan, the models boost the agent performance in the real environment by up to three times without collecting any interactive experiences in this environment.</li>
</ul>

<h3>Title: Large language model empowered participatory urban planning</h3>
<ul>
<li><strong>Authors: </strong>Zhilun Zhou, Yuming Lin, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01698">https://arxiv.org/abs/2402.01698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01698">https://arxiv.org/pdf/2402.01698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01698]] Large language model empowered participatory urban planning(https://arxiv.org/abs/2402.01698)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Participatory urban planning is the mainstream of modern urban planning and involves the active engagement of different stakeholders. However, the traditional participatory paradigm encounters challenges in time and manpower, while the generative planning tools fail to provide adjustable and inclusive solutions. This research introduces an innovative urban planning approach integrating Large Language Models (LLMs) within the participatory process. The framework, based on the crafted LLM agent, consists of role-play, collaborative generation, and feedback iteration, solving a community-level land-use task catering to 1000 distinct interests. Empirical experiments in diverse urban communities exhibit LLM's adaptability and effectiveness across varied planning scenarios. The results were evaluated on four metrics, surpassing human experts in satisfaction and inclusion, and rivaling state-of-the-art reinforcement learning methods in service and ecology. Further analysis shows the advantage of LLM agents in providing adjustable and inclusive solutions with natural language reasoning and strong scalability. While implementing the recent advancements in emulating human behavior for planning, this work envisions both planners and citizens benefiting from low-cost, efficient LLM agents, which is crucial for enhancing participation and realizing participatory urban planning.</li>
</ul>

<h3>Title: Fluent dreaming for language models</h3>
<ul>
<li><strong>Authors: </strong>T. Ben Thompson (1), Zygimantas Straznickas (1), Michael Sklar (1) ((1) Confirm Labs)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01702">https://arxiv.org/abs/2402.01702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01702">https://arxiv.org/pdf/2402.01702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01702]] Fluent dreaming for language models(https://arxiv.org/abs/2402.01702)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Feature visualization, also known as "dreaming", offers insights into vision models by optimizing the inputs to maximize a neuron's activation or other internal component. However, dreaming has not been successfully applied to language models because the input space is discrete. We extend Greedy Coordinate Gradient, a method from the language model adversarial attack literature, to design the Evolutionary Prompt Optimization (EPO) algorithm. EPO optimizes the input prompt to simultaneously maximize the Pareto frontier between a chosen internal feature and prompt fluency, enabling fluent dreaming for language models. We demonstrate dreaming with neurons, output logits and arbitrary directions in activation space. We measure the fluency of the resulting prompts and compare language model dreaming with max-activating dataset examples. Critically, fluent dreaming allows automatically exploring the behavior of model internals in reaction to mildly out-of-distribution prompts. Code for running EPO is available at https://github.com/Confirm-Solutions/dreamy. A companion page demonstrating code usage is at https://confirmlabs.org/posts/dreamy.html</li>
</ul>

<h3>Title: States as Strings as Strategies: Steering Language Models with  Game-Theoretic Solvers</h3>
<ul>
<li><strong>Authors: </strong>Ian Gemp, Yoram Bachrach, Marc Lanctot, Roma Patel, Vibhavari Dasagi, Luke Marris, Georgios Piliouras, Karl Tuyls</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01704">https://arxiv.org/abs/2402.01704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01704">https://arxiv.org/pdf/2402.01704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01704]] States as Strings as Strategies: Steering Language Models with  Game-Theoretic Solvers(https://arxiv.org/abs/2402.01704)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Game theory is the study of mathematical models of strategic interactions among rational agents. Language is a key medium of interaction for humans, though it has historically proven difficult to model dialogue and its strategic motivations mathematically. A suitable model of the players, strategies, and payoffs associated with linguistic interactions (i.e., a binding to the conventional symbolic logic of game theory) would enable existing game-theoretic algorithms to provide strategic solutions in the space of language. In other words, a binding could provide a route to computing stable, rational conversational strategies in dialogue. Large language models (LLMs) have arguably reached a point where their generative capabilities can enable realistic, human-like simulations of natural dialogue. By prompting them in various ways, we can steer their responses towards different output utterances. Leveraging the expressivity of natural language, LLMs can also help us quickly generate new dialogue scenarios, which are grounded in real world applications. In this work, we present one possible binding from dialogue to game theory as well as generalizations of existing equilibrium finding algorithms to this setting. In addition, by exploiting LLMs generation capabilities along with our proposed binding, we can synthesize a large repository of formally-defined games in which one can study and test game-theoretic solution concepts. We also demonstrate how one can combine LLM-driven game generation, game-theoretic solvers, and imitation learning to construct a process for improving the strategic capabilities of LLMs.</li>
</ul>

<h3>Title: MULTIVERSE: Exposing Large Language Model Alignment Problems in Diverse  Worlds</h3>
<ul>
<li><strong>Authors: </strong>Xiaolong Jin, Zhuo Zhang, Xiangyu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01706">https://arxiv.org/abs/2402.01706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01706">https://arxiv.org/pdf/2402.01706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01706]] MULTIVERSE: Exposing Large Language Model Alignment Problems in Diverse  Worlds(https://arxiv.org/abs/2402.01706)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) alignment aims to ensure that LLM outputs match with human values. Researchers have demonstrated the severity of alignment problems with a large spectrum of jailbreak techniques that can induce LLMs to produce malicious content during conversations. Finding the corresponding jailbreaking prompts usually requires substantial human intelligence or computation resources. In this paper, we report that LLMs have different levels of alignment in various contexts. As such, by systematically constructing many contexts, called worlds, leveraging a Domain Specific Language describing possible worlds (e.g., time, location, characters, actions and languages) and the corresponding compiler, we can cost-effectively expose latent alignment issues. Given the low cost of our method, we are able to conduct a large scale study regarding LLM alignment issues in different worlds. Our results show that our method outperforms the-state-of-the-art jailbreaking techniques on both effectiveness and efficiency. In addition, our results indicate that existing LLMs are extremely vulnerable to nesting worlds and programming language worlds. They imply that existing alignment training focuses on the real-world and is lacking in various (virtual) worlds where LLMs can be exploited.</li>
</ul>

<h3>Title: Not My Voice! A Taxonomy of Ethical and Safety Harms of Speech  Generators</h3>
<ul>
<li><strong>Authors: </strong>Wiebke Hutiri, Oresiti Papakyriakopoulos, Alice Xiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01708">https://arxiv.org/abs/2402.01708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01708">https://arxiv.org/pdf/2402.01708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01708]] Not My Voice! A Taxonomy of Ethical and Safety Harms of Speech  Generators(https://arxiv.org/abs/2402.01708)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, generative</a></li>
<li><strong>Abstract: </strong>The rapid and wide-scale adoption of AI to generate human speech poses a range of significant ethical and safety risks to society that need to be addressed. For example, a growing number of speech generation incidents are associated with swatting attacks in the United States, where anonymous perpetrators create synthetic voices that call police officers to close down schools and hospitals, or to violently gain access to innocent citizens' homes. Incidents like this demonstrate that multimodal generative AI risks and harms do not exist in isolation, but arise from the interactions of multiple stakeholders and technical AI systems. In this paper we analyse speech generation incidents to study how patterns of specific harms arise. We find that specific harms can be categorised according to the exposure of affected individuals, that is to say whether they are a subject of, interact with, suffer due to, or are excluded from speech generation systems. Similarly, specific harms are also a consequence of the motives of the creators and deployers of the systems. Based on these insights we propose a conceptual framework for modelling pathways to ethical and safety harms of AI, which we use to develop a taxonomy of harms of speech generators. Our relational approach captures the complexity of risks and harms in sociotechnical AI systems, and yields an extensible taxonomy that can support appropriate policy interventions and decision making for responsible multimodal model development and release of speech generators.</li>
</ul>

<h3>Title: Socially Aware Synthetic Data Generation for Suicidal Ideation Detection  Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hamideh Ghanadian, Isar Nejadgholi, Hussein Al Osman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01712">https://arxiv.org/abs/2402.01712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01712">https://arxiv.org/pdf/2402.01712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01712]] Socially Aware Synthetic Data Generation for Suicidal Ideation Detection  Using Large Language Models(https://arxiv.org/abs/2402.01712)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.</li>
</ul>

<h3>Title: Prompting Large Language Models for Zero-Shot Clinical Prediction with  Structured Longitudinal Electronic Health Record Data</h3>
<ul>
<li><strong>Authors: </strong>Yinghao Zhu, Zixiang Wang, Junyi Gao, Yuning Tong, Jingkun An, Weibin Liao, Ewen M. Harrison, Liantao Ma, Chengwei Pan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01713">https://arxiv.org/abs/2402.01713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01713">https://arxiv.org/pdf/2402.01713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01713]] Prompting Large Language Models for Zero-Shot Clinical Prediction with  Structured Longitudinal Electronic Health Record Data(https://arxiv.org/abs/2402.01713)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The inherent complexity of structured longitudinal Electronic Health Records (EHR) data poses a significant challenge when integrated with Large Language Models (LLMs), which are traditionally tailored for natural language processing. Motivated by the urgent need for swift decision-making during new disease outbreaks, where traditional predictive models often fail due to a lack of historical data, this research investigates the adaptability of LLMs, like GPT-4, to EHR data. We particularly focus on their zero-shot capabilities, which enable them to make predictions in scenarios in which they haven't been explicitly trained. In response to the longitudinal, sparse, and knowledge-infused nature of EHR data, our prompting approach involves taking into account specific EHR characteristics such as units and reference ranges, and employing an in-context learning strategy that aligns with clinical contexts. Our comprehensive experiments on the MIMIC-IV and TJH datasets demonstrate that with our elaborately designed prompting framework, LLMs can improve prediction performance in key tasks such as mortality, length-of-stay, and 30-day readmission by about 35\%, surpassing ML models in few-shot settings. Our research underscores the potential of LLMs in enhancing clinical decision-making, especially in urgent healthcare situations like the outbreak of emerging diseases with no labeled data. The code is publicly available at https://github.com/yhzhu99/llm4healthcare for reproducibility.</li>
</ul>

<h3>Title: ChatGPT vs Gemini vs LLaMA on Multilingual Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Alessio Buscemi, Daniele Proverbio</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01715">https://arxiv.org/abs/2402.01715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01715">https://arxiv.org/pdf/2402.01715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01715]] ChatGPT vs Gemini vs LLaMA on Multilingual Sentiment Analysis(https://arxiv.org/abs/2402.01715)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Automated sentiment analysis using Large Language Model (LLM)-based models like ChatGPT, Gemini or LLaMA2 is becoming widespread, both in academic research and in industrial applications. However, assessment and validation of their performance in case of ambiguous or ironic text is still poor. In this study, we constructed nuanced and ambiguous scenarios, we translated them in 10 languages, and we predicted their associated sentiment using popular LLMs. The results are validated against post-hoc human responses. Ambiguous scenarios are often well-coped by ChatGPT and Gemini, but we recognise significant biases and inconsistent performance across models and evaluated human languages. This work provides a standardised methodology for automated sentiment analysis evaluation and makes a call for action to further improve the algorithms and their underlying data, to improve their performance, interpretability and applicability.</li>
</ul>

<h3>Title: From RAG to QA-RAG: Integrating Generative AI for Pharmaceutical  Regulatory Compliance Process</h3>
<ul>
<li><strong>Authors: </strong>Jaewoong Kim (Sungkyunkwan University), Moohong Min (Sungkyunkwan University)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01717">https://arxiv.org/abs/2402.01717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01717">https://arxiv.org/pdf/2402.01717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01717]] From RAG to QA-RAG: Integrating Generative AI for Pharmaceutical  Regulatory Compliance Process(https://arxiv.org/abs/2402.01717)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Regulatory compliance in the pharmaceutical industry entails navigating through complex and voluminous guidelines, often requiring significant human resources. To address these challenges, our study introduces a chatbot model that utilizes generative AI and the Retrieval Augmented Generation (RAG) method. This chatbot is designed to search for guideline documents relevant to the user inquiries and provide answers based on the retrieved guidelines. Recognizing the inherent need for high reliability in this domain, we propose the Question and Answer Retrieval Augmented Generation (QA-RAG) model. In comparative experiments, the QA-RAG model demonstrated a significant improvement in accuracy, outperforming all other baselines including conventional RAG methods. This paper details QA-RAG's structure and performance evaluation, emphasizing its potential for the regulatory compliance domain in the pharmaceutical industry and beyond. We have made our work publicly available for further research and development.</li>
</ul>

<h3>Title: Measuring Moral Inconsistencies in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Vamshi Krishna Bonagiri, Sreeram Vennam, Manas Gaur, Ponnurangam Kumaraguru</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01719">https://arxiv.org/abs/2402.01719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01719">https://arxiv.org/pdf/2402.01719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01719]] Measuring Moral Inconsistencies in Large Language Models(https://arxiv.org/abs/2402.01719)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A Large Language Model~(LLM) is considered consistent if semantically equivalent prompts produce semantically equivalent responses. Despite recent advancements showcasing the impressive capabilities of LLMs in conversational systems, we show that even state-of-the-art LLMs are highly inconsistent in their generations, questioning their reliability. Prior research has tried to measure this with task-specific accuracies. However, this approach is unsuitable for moral scenarios, such as the trolley problem, with no ``correct'' answer. To address this issue, we propose a novel information-theoretic measure called Semantic Graph Entropy~(SGE) to measure the consistency of an LLM in moral scenarios. We leverage ``Rules of Thumb''~(RoTs) to explain a model's decision-making strategies and further enhance our metric. Compared to existing consistency metrics, SGE correlates better with human judgments across five LLMs. In the future, we aim to investigate the root causes of LLM inconsistencies and propose improvements.</li>
</ul>

<h3>Title: Enhancing Large Language Model Performance To Answer Questions and  Extract Information More Accurately</h3>
<ul>
<li><strong>Authors: </strong>Liang Zhang, Katherine Jijo, Spurthi Setty, Eden Chung, Fatima Javid, Natan Vidra, Tommy Clifford</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01722">https://arxiv.org/abs/2402.01722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01722">https://arxiv.org/pdf/2402.01722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01722]] Enhancing Large Language Model Performance To Answer Questions and  Extract Information More Accurately(https://arxiv.org/abs/2402.01722)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) generate responses to questions; however, their effectiveness is often hindered by sub-optimal quality of answers and occasional failures to provide accurate responses to questions. To address these challenges, a fine-tuning process is employed, involving feedback and examples to refine models. The objective is to enhance AI models through continuous feedback loops, utilizing metrics such as cosine similarity, LLM evaluation and Rouge-L scores to evaluate the models. Leveraging LLMs like GPT-3.5, GPT4ALL, and LLaMA2, and Claude, this approach is benchmarked on financial datasets, including the FinanceBench and RAG Instruct Benchmark Tester Dataset, illustrating the necessity of fine-tuning. The results showcase the capability of fine-tuned models to surpass the accuracy of zero-shot LLMs, providing superior question and answering capabilities. Notably, the combination of fine-tuning the LLM with a process known as Retrieval Augmented Generation (RAG) proves to generate responses with improved accuracy.</li>
</ul>

<h3>Title: An Empirical Study on Large Language Models in Accuracy and Robustness  under Chinese Industrial Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Zongjie Li, Wenying Qiu, Pingchuan Ma, Yichen Li, You Li, Sijia He, Baozheng Jiang, Shuai Wang, Weixi Gu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01723">https://arxiv.org/abs/2402.01723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01723">https://arxiv.org/pdf/2402.01723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01723]] An Empirical Study on Large Language Models in Accuracy and Robustness  under Chinese Industrial Scenarios(https://arxiv.org/abs/2402.01723)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent years have witnessed the rapid development of large language models (LLMs) in various domains. To better serve the large number of Chinese users, many commercial vendors in China have adopted localization strategies, training and providing local LLMs specifically customized for Chinese users. Furthermore, looking ahead, one of the key future applications of LLMs will be practical deployment in industrial production by enterprises and users in those sectors. However, the accuracy and robustness of LLMs in industrial scenarios have not been well studied. In this paper, we present a comprehensive empirical study on the accuracy and robustness of LLMs in the context of the Chinese industrial production area. We manually collected 1,200 domain-specific problems from 8 different industrial sectors to evaluate LLM accuracy. Furthermore, we designed a metamorphic testing framework containing four industrial-specific stability categories with eight abilities, totaling 13,631 questions with variants to evaluate LLM robustness. In total, we evaluated 9 different LLMs developed by Chinese vendors, as well as four different LLMs developed by global vendors. Our major findings include: (1) Current LLMs exhibit low accuracy in Chinese industrial contexts, with all LLMs scoring less than 0.6. (2) The robustness scores vary across industrial sectors, and local LLMs overall perform worse than global ones. (3) LLM robustness differs significantly across abilities. Global LLMs are more robust under logical-related variants, while advanced local LLMs perform better on problems related to understanding Chinese industrial terminology. Our study results provide valuable guidance for understanding and promoting the industrial domain capabilities of LLMs from both development and industrial enterprise perspectives. The results further motivate possible research directions and tooling support.</li>
</ul>

<h3>Title: Fortifying Ethical Boundaries in AI: Advanced Strategies for Enhancing  Security in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yunhong He, Jianling Qiu, Wei Zhang, Zhengqing Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01725">https://arxiv.org/abs/2402.01725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01725">https://arxiv.org/pdf/2402.01725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01725]] Fortifying Ethical Boundaries in AI: Advanced Strategies for Enhancing  Security in Large Language Models(https://arxiv.org/abs/2402.01725)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have significantly enhanced capabilities in natural language processing and artificial intelligence. These models, including GPT-3.5 and LLaMA-2, have revolutionized text generation, translation, and question-answering tasks due to the transformative Transformer model. Despite their widespread use, LLMs present challenges such as ethical dilemmas when models are compelled to respond inappropriately, susceptibility to phishing attacks, and privacy violations. This paper addresses these challenges by introducing a multi-pronged approach that includes: 1) filtering sensitive vocabulary from user input to prevent unethical responses; 2) detecting role-playing to halt interactions that could lead to 'prison break' scenarios; 3) implementing custom rule engines to restrict the generation of prohibited content; and 4) extending these methodologies to various LLM derivatives like Multi-Model Large Language Models (MLLMs). Our approach not only fortifies models against unethical manipulations and privacy breaches but also maintains their high performance across tasks. We demonstrate state-of-the-art performance under various attack prompts, without compromising the model's core functionalities. Furthermore, the introduction of differentiated security levels empowers users to control their personal data disclosure. Our methods contribute to reducing social risks and conflicts arising from technological abuse, enhance data protection, and promote social equity. Collectively, this research provides a framework for balancing the efficiency of question-answering systems with user privacy and ethical standards, ensuring a safer user experience and fostering trust in AI technology.</li>
</ul>

<h3>Title: Guidance for AI-Mediated Communication: AI Does Not Alter Perceptions of  Text Messages</h3>
<ul>
<li><strong>Authors: </strong>N'yoma Diamond</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01726">https://arxiv.org/abs/2402.01726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01726">https://arxiv.org/pdf/2402.01726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01726]] Guidance for AI-Mediated Communication: AI Does Not Alter Perceptions of  Text Messages(https://arxiv.org/abs/2402.01726)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>For many people, anxiety, depression, and other social and mental factors can make composing text messages an active challenge. To remedy this problem, large language models (LLMs) may yet prove to be the perfect tool to assist users that would otherwise find texting difficult or stressful. However, despite rapid uptake in LLM usage, considerations for their assistive usage in text message composition have not been explored. A primary concern regarding LLM usage is that poor public sentiment regarding AI introduces the possibility that its usage may harm perceptions of AI-assisted text messages, making usage counter-productive. To (in)validate this possibility, we explore how the belief that a text message did or did not receive AI assistance in composition alters its perceived tone, clarity, and ability to convey intent. In this study, we survey the perceptions of 26 participants on 18 randomly labeled pre-composed text messages. In analyzing the participants' ratings of message tone, clarity, and ability to convey intent, we find that there is no statistically significant evidence that the belief that AI is utilized alters recipient perceptions. This provides hopeful evidence that LLM-based text message composition assistance can be implemented without the risk of counter-productive outcomes.</li>
</ul>

<h3>Title: Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain  Specific Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Weimin Fu, Shijie Li, Yifang Zhao, Haocheng Ma, Raj Dutta, Xuan Zhang, Kaichen Yang, Yier Jin, Xiaolong Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01728">https://arxiv.org/abs/2402.01728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01728">https://arxiv.org/pdf/2402.01728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01728]] Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain  Specific Knowledge(https://arxiv.org/abs/2402.01728)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>In the rapidly evolving semiconductor industry, where research, design, verification, and manufacturing are intricately linked, the potential of Large Language Models to revolutionize hardware design and security verification is immense. The primary challenge, however, lies in the complexity of hardware specific issues that are not adequately addressed by the natural language or software code knowledge typically acquired during the pretraining stage. Additionally, the scarcity of datasets specific to the hardware domain poses a significant hurdle in developing a foundational model. Addressing these challenges, this paper introduces Hardware Phi 1.5B, an innovative large language model specifically tailored for the hardware domain of the semiconductor industry. We have developed a specialized, tiered dataset comprising small, medium, and large subsets and focused our efforts on pretraining using the medium dataset. This approach harnesses the compact yet efficient architecture of the Phi 1.5B model. The creation of this first pretrained, hardware domain specific large language model marks a significant advancement, offering improved performance in hardware design and verification tasks and illustrating a promising path forward for AI applications in the semiconductor sector.</li>
</ul>

<h3>Title: Contextualization Distillation from Large Language Model for Knowledge  Graph Completion</h3>
<ul>
<li><strong>Authors: </strong>Dawei Li, Zhen Tan, Tianlong Chen, Huan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01729">https://arxiv.org/abs/2402.01729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01729">https://arxiv.org/pdf/2402.01729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01729]] Contextualization Distillation from Large Language Model for Knowledge  Graph Completion(https://arxiv.org/abs/2402.01729)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>While textual information significantly enhances the performance of pre-trained language models (PLMs) in knowledge graph completion (KGC), the static and noisy nature of existing corpora collected from Wikipedia articles or synsets definitions often limits the potential of PLM-based KGC models. To surmount these challenges, we introduce the Contextualization Distillation strategy, a versatile plug-in-and-play approach compatible with both discriminative and generative KGC frameworks. Our method begins by instructing large language models (LLMs) to transform compact, structural triplets into context-rich segments. Subsequently, we introduce two tailored auxiliary tasks, reconstruction and contextualization, allowing smaller KGC models to assimilate insights from these enriched triplets. Comprehensive evaluations across diverse datasets and KGC techniques highlight the efficacy and adaptability of our approach, revealing consistent performance enhancements irrespective of underlying pipelines or architectures. Moreover, our analysis makes our method more explainable and provides insight into generating path selection, as well as the choosing of suitable distillation tasks. All the code and data in this work will be released at https://github.com/David-Li0406/Contextulization-Distillation</li>
</ul>

<h3>Title: Evaluating LLM - Generated Multimodal Diagnosis from Medical Images and  Symptom Analysis</h3>
<ul>
<li><strong>Authors: </strong>Dimitrios P. Panagoulias, Maria Virvou, George A. Tsihrintzis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01730">https://arxiv.org/abs/2402.01730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01730">https://arxiv.org/pdf/2402.01730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01730]] Evaluating LLM - Generated Multimodal Diagnosis from Medical Images and  Symptom Analysis(https://arxiv.org/abs/2402.01730)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) constitute a breakthrough state-of-the-art Artificial Intelligence technology which is rapidly evolving and promises to aid in medical diagnosis. However, the correctness and the accuracy of their returns has not yet been properly evaluated. In this work, we propose an LLM evaluation paradigm that incorporates two independent steps of a novel methodology, namely (1) multimodal LLM evaluation via structured interactions and (2) follow-up, domain-specific analysis based on data extracted via the previous interactions. Using this paradigm, (1) we evaluate the correctness and accuracy of LLM-generated medical diagnosis with publicly available multimodal multiple-choice questions(MCQs) in the domain of Pathology and (2) proceed to a systemic and comprehensive analysis of extracted results. We used GPT-4-Vision-Preview as the LLM to respond to complex, medical questions consisting of both images and text, and we explored a wide range of diseases, conditions, chemical compounds, and related entity types that are included in the vast knowledge domain of Pathology. GPT-4-Vision-Preview performed quite well, scoring approximately 84\% of correct diagnoses. Next, we further analyzed the findings of our work, following an analytical approach which included Image Metadata Analysis, Named Entity Recognition and Knowledge Graphs. Weaknesses of GPT-4-Vision-Preview were revealed on specific knowledge paths, leading to a further understanding of its shortcomings in specific areas. Our methodology and findings are not limited to the use of GPT-4-Vision-Preview, but a similar approach can be followed to evaluate the usefulness and accuracy of other LLMs and, thus, improve their use with further optimization.</li>
</ul>

<h3>Title: Development and Testing of Retrieval Augmented Generation in Large  Language Models -- A Case Study Report</h3>
<ul>
<li><strong>Authors: </strong>YuHe Ke, Liyuan Jin, Kabilan Elangovan, Hairil Rizal Abdullah, Nan Liu, Alex Tiong Heng Sia, Chai Rick Soh, Joshua Yi Min Tung, Jasmine Chiat Ling Ong, Daniel Shu Wei Ting</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01733">https://arxiv.org/abs/2402.01733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01733">https://arxiv.org/pdf/2402.01733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01733]] Development and Testing of Retrieval Augmented Generation in Large  Language Models -- A Case Study Report(https://arxiv.org/abs/2402.01733)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Purpose: Large Language Models (LLMs) hold significant promise for medical applications. Retrieval Augmented Generation (RAG) emerges as a promising approach for customizing domain knowledge in LLMs. This case study presents the development and evaluation of an LLM-RAG pipeline tailored for healthcare, focusing specifically on preoperative medicine. Methods: We developed an LLM-RAG model using 35 preoperative guidelines and tested it against human-generated responses, with a total of 1260 responses evaluated. The RAG process involved converting clinical documents into text using Python-based frameworks like LangChain and Llamaindex, and processing these texts into chunks for embedding and retrieval. Vector storage techniques and selected embedding models to optimize data retrieval, using Pinecone for vector storage with a dimensionality of 1536 and cosine similarity for loss metrics. Human-generated answers, provided by junior doctors, were used as a comparison. Results: The LLM-RAG model generated answers within an average of 15-20 seconds, significantly faster than the 10 minutes typically required by humans. Among the basic LLMs, GPT4.0 exhibited the best accuracy of 80.1%. This accuracy was further increased to 91.4% when the model was enhanced with RAG. Compared to the human-generated instructions, which had an accuracy of 86.3%, the performance of the GPT4.0 RAG model demonstrated non-inferiority (p=0.610). Conclusions: In this case study, we demonstrated a LLM-RAG model for healthcare implementation. The pipeline shows the advantages of grounded knowledge, upgradability, and scalability as important aspects of healthcare LLM deployment.</li>
</ul>

<h3>Title: Assistive Large Language Model Agents for Socially-Aware Negotiation  Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Yuncheng Hua, Lizhen Qu, Gholamreza Haffari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01737">https://arxiv.org/abs/2402.01737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01737">https://arxiv.org/pdf/2402.01737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01737]] Assistive Large Language Model Agents for Socially-Aware Negotiation  Dialogues(https://arxiv.org/abs/2402.01737)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we aim to develop LLM agents to mitigate social norm violations in negotiations in a multi-agent setting. We simulate real-world negotiations by letting two large Language Models (LLMs) play the roles of two negotiators in each conversation. A third LLM acts as a remediation agent to rewrite utterances violating norms for improving negotiation outcomes. As it is a novel task, no manually constructed data is available. To address this limitation, we introduce a value impact based In-Context Learning (ICL) method to identify high-quality ICL examples for the LLM-based remediation agents, where the value impact function measures the quality of negotiation outcomes. We show the connection of this method to policy learning and provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different topics: product sale, housing price, and salary negotiation. The source code and the generated dataset will be publicly available upon acceptance.</li>
</ul>

<h3>Title: C4Q: A Chatbot for Quantum</h3>
<ul>
<li><strong>Authors: </strong>Yaiza Aragons-Soria, Manuel Oriol</a></li>
<li><strong>Subjects: </strong>cs.CL, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01738">https://arxiv.org/abs/2402.01738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01738">https://arxiv.org/pdf/2402.01738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01738]] C4Q: A Chatbot for Quantum(https://arxiv.org/abs/2402.01738)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Quantum computing is a growing field that promises many real-world applications such as quantum cryptography or quantum finance. The number of people able to use quantum computing is however still very small. This limitation comes from the difficulty to understand the concepts and to know how to start coding. Therefore, there is a need for tools that can assist non-expert in overcoming this complexity. One possibility would be to use existing conversational agents. Unfortunately ChatGPT and other Large-Language Models produce inaccurate results. This article presents C4Q, a chatbot that answers accurately basic questions and guides users when trying to code quantum programs. Contrary to other approaches C4Q uses a pre-trained large language model only to discover and classify user requests. It then generates an accurate answer using an own engine. Thanks to this architectural design, C4Q's answers are always correct, and thus C4Q can become a support tool that makes quantum computing more available to non-experts.</li>
</ul>

<h3>Title: OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models</h3>
<ul>
<li><strong>Authors: </strong>Fuzhao Xue, Zian Zheng, Yao Fu, Jinjie Ni, Zangwei Zheng, Wangchunshu Zhou, Yang You</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01739">https://arxiv.org/abs/2402.01739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01739">https://arxiv.org/pdf/2402.01739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01739]] OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models(https://arxiv.org/abs/2402.01739)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To help the open-source community have a better understanding of Mixture-of-Experts (MoE) based large language models (LLMs), we train and release OpenMoE, a series of fully open-sourced and reproducible decoder-only MoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T tokens. Our investigation confirms that MoE-based LLMs can offer a more favorable cost-effectiveness trade-off than dense LLMs, highlighting the potential effectiveness for future LLM development. One more important contribution of this study is an in-depth analysis of the routing mechanisms within our OpenMoE models, leading to three significant findings: Context-Independent Specialization, Early Routing Learning, and Drop-towards-the-End. We discovered that routing decisions in MoE models are predominantly based on token IDs, with minimal context relevance. The token-to-expert assignments are determined early in the pre-training phase and remain largely unchanged. This imperfect routing can result in performance degradation, particularly in sequential tasks like multi-turn conversations, where tokens appearing later in a sequence are more likely to be dropped. Finally, we rethink our design based on the above-mentioned observations and analysis. To facilitate future MoE LLM development, we propose potential strategies for mitigating the issues we found and further improving off-the-shelf MoE LLM designs.</li>
</ul>

<h3>Title: Compensatory Biases Under Cognitive Load: Reducing Selection Bias in  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>J. E. Eicher, R. F. Irgoli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01740">https://arxiv.org/abs/2402.01740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01740">https://arxiv.org/pdf/2402.01740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01740]] Compensatory Biases Under Cognitive Load: Reducing Selection Bias in  Large Language Models(https://arxiv.org/abs/2402.01740)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) like gpt-3.5-turbo and claude-instant-1.2 have become instrumental in interpreting and executing semantic-based tasks. Unfortunately, these models' inherent biases, akin to human cognitive biases, adversely affect their performance. Particularly affected is object selection from lists; a fundamental operation in digital navigation and decision-making. This research critically examines these biases and quantifies the effects on a representative list selection task. To explore these biases, we conducted a series of controlled experiments, manipulating temperature, list length, object identity, object type, prompt complexity, and model. This enabled us to isolate and measure the influence of the biases on selection behavior. Our findings show that bias structure is strongly dependent on the model, with object type modulating the magnitude of the effect. With a strong primacy effect, causing the first objects in a list to be disproprotionately represented in outputs. Furthermore the usage of guard rails, a prompt engineering method of ensuring a response structure, can increase bias and decrease instruction adherence when combined with a selection task. The bias is ablated when the guard rail step is separated from the list sampling step, lowering the complexity of each individual task. The implications of this research are two-fold, practically providing a guide for designing unbiased LLM applications and theoretically suggesting that LLMs experience a form of cognitive load compensated for by increasing bias.</li>
</ul>

<h3>Title: Development and Testing of a Novel Large Language Model-Based Clinical  Decision Support Systems for Medication Safety in 12 Clinical Specialties</h3>
<ul>
<li><strong>Authors: </strong>Jasmine Chiat Ling Ong, Liyuan Jin, Kabilan Elangovan, Gilbert Yong San Lim, Daniel Yan Zheng Lim, Gerald Gui Ren Sng, Yuhe Ke, Joshua Yi Min Tung, Ryan Jian Zhong, Christopher Ming Yao Koh, Keane Zhi Hao Lee, Xiang Chen, Jack Kian Chng, Aung Than, Ken Junyang Goh, Daniel Shu Wei Ting</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01741">https://arxiv.org/abs/2402.01741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01741">https://arxiv.org/pdf/2402.01741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01741]] Development and Testing of a Novel Large Language Model-Based Clinical  Decision Support Systems for Medication Safety in 12 Clinical Specialties(https://arxiv.org/abs/2402.01741)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Importance: We introduce a novel Retrieval Augmented Generation (RAG)-Large Language Model (LLM) as a Clinical Decision Support System (CDSS) for safe medication prescription. This model addresses the limitations of traditional rule-based CDSS by providing relevant prescribing error alerts tailored to patient context and institutional guidelines. Objective: The study evaluates the efficacy of an LLM-based CDSS in identifying medication errors across various medical and surgical case vignettes, compared to a human expert panel. It also examines clinician preferences among different CDSS integration modalities: junior pharmacist, LLM-based CDSS alone, and a combination of both. Design, Setting, and Participants: Utilizing a RAG model with GPT-4.0, the study involved 61 prescribing error scenarios within 23 clinical vignettes across 12 specialties. An expert panel assessed these cases using the PCNE classification and NCC MERP index. Three junior pharmacists independently reviewed each vignette under simulated conditions. Main Outcomes and Measures: The study assesses the LLM-based CDSS's accuracy, precision, recall, and F1 scores in identifying Drug-Related Problems (DRPs), compared to junior pharmacists alone or in an assistive mode with the CDSS. Results: The co-pilot mode of RAG-LLM significantly improved DRP identification accuracy by 22% over solo pharmacists. It showed higher recall and F1 scores, indicating better detection of severe DRPs, despite a slight decrease in precision. Accuracy varied across categories when pharmacists had access to RAG-LLM responses. Conclusions: The RAG-LLM based CDSS enhances medication error identification accuracy when used with junior pharmacists, especially in detecting severe DRPs.</li>
</ul>

<h3>Title: Towards Optimizing the Costs of LLM Usage</h3>
<ul>
<li><strong>Authors: </strong>Shivanshu Shekhar, Tanishq Dubey, Koyel Mukherjee, Apoorv Saxena, Atharv Tyagi, Nishanth Kotla</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01742">https://arxiv.org/abs/2402.01742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01742">https://arxiv.org/pdf/2402.01742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01742]] Towards Optimizing the Costs of LLM Usage(https://arxiv.org/abs/2402.01742)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative AI and LLMs in particular are heavily used nowadays for various document processing tasks such as question answering and summarization. However, different LLMs come with different capabilities for different tasks as well as with different costs, tokenization, and latency. In fact, enterprises are already incurring huge costs of operating or using LLMs for their respective use cases. In this work, we propose optimizing the usage costs of LLMs by estimating their output quality (without actually invoking the LLMs), and then solving an optimization routine for the LLM selection to either keep costs under a budget, or minimize the costs, in a quality and latency aware manner. We propose a model to predict the output quality of LLMs on document processing tasks like summarization, followed by an LP rounding algorithm to optimize the selection of LLMs. We study optimization problems trading off the quality and costs, both theoretically and empirically. We further propose a sentence simplification model for reducing the number of tokens in a controlled manner. Additionally, we propose several deterministic heuristics for reducing tokens in a quality aware manner, and study the related optimization problem of applying the heuristics optimizing the quality and cost trade-off. We perform extensive empirical validation of our methods on not only enterprise datasets but also on open-source datasets, annotated by us, and show that we perform much better compared to closest baselines. Our methods reduce costs by 40%- 90% while improving quality by 4%-7%. We will release the annotated open source datasets to the community for further research and exploration.</li>
</ul>

<h3>Title: PACE: A Pragmatic Agent for Enhancing Communication Efficiency Using  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaxuan Li, Minxi Yang, Dahua Gao, Wenlong Xu, Guangming Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01750">https://arxiv.org/abs/2402.01750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01750">https://arxiv.org/pdf/2402.01750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01750]] PACE: A Pragmatic Agent for Enhancing Communication Efficiency Using  Large Language Models(https://arxiv.org/abs/2402.01750)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current communication technologies face limitations in terms of theoretical capacity, spectrum availability, and power resources. Pragmatic communication, leveraging terminal intelligence for selective data transmission, offers resource conservation. Existing research lacks universal intention resolution tools, limiting applicability to specific tasks. This paper proposes an image pragmatic communication framework based on a Pragmatic Agent for Communication Efficiency (PACE) using Large Language Models (LLM). In this framework, PACE sequentially performs semantic perception, intention resolution, and intention-oriented coding. To ensure the effective utilization of LLM in communication, a knowledge base is designed to supplement the necessary knowledge, dedicated prompts are introduced to facilitate understanding of pragmatic communication scenarios and task requirements, and a chain of thought is designed to assist in making reasonable trade-offs between transmission efficiency and cost. For experimental validation, this paper constructs an image pragmatic communication dataset along with corresponding evaluation standards. Simulation results indicate that the proposed method outperforms traditional and non-LLM-based pragmatic communication in terms of transmission efficiency.</li>
</ul>

<h3>Title: Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's  Dementia</h3>
<ul>
<li><strong>Authors: </strong>Balamurali B T, Jer-Ming Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01751">https://arxiv.org/abs/2402.01751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01751">https://arxiv.org/pdf/2402.01751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01751]] Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's  Dementia(https://arxiv.org/abs/2402.01751)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) find increasing applications in many fields. Here, three LLM chatbots (ChatGPT-3.5, ChatGPT-4 and Bard) are assessed - in their current form, as publicly available - for their ability to recognize Alzheimer's Dementia (AD) and Cognitively Normal (CN) individuals using textual input derived from spontaneous speech recordings. Zero-shot learning approach is used at two levels of independent queries, with the second query (chain-of-thought prompting) eliciting more detailed than the first. Each LLM chatbot's performance is evaluated on the prediction generated in terms of accuracy, sensitivity, specificity, precision and F1 score. LLM chatbots generated three-class outcome ("AD", "CN", or "Unsure"). When positively identifying AD, Bard produced highest true-positives (89% recall) and highest F1 score (71%), but tended to misidentify CN as AD, with high confidence (low "Unsure" rates); for positively identifying CN, GPT-4 resulted in the highest true-negatives at 56% and highest F1 score (62%), adopting a diplomatic stance (moderate "Unsure" rates). Overall, three LLM chatbots identify AD vs CN surpassing chance-levels but do not currently satisfy clinical application.</li>
</ul>

<h3>Title: Systematic Literature Review: Computational Approaches for Humour Style  Classification</h3>
<ul>
<li><strong>Authors: </strong>Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01759">https://arxiv.org/abs/2402.01759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01759">https://arxiv.org/pdf/2402.01759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01759]] Systematic Literature Review: Computational Approaches for Humour Style  Classification(https://arxiv.org/abs/2402.01759)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding various humour styles is essential for comprehending the multifaceted nature of humour and its impact on fields such as psychology and artificial intelligence. This understanding has revealed that humour, depending on the style employed, can either have therapeutic or detrimental effects on an individual's health and relationships. Although studies dedicated exclusively to computational-based humour style analysis remain somewhat rare, an expansive body of research thrives within related task, particularly binary humour and sarcasm recognition. In this systematic literature review (SLR), we survey the landscape of computational techniques applied to these related tasks and also uncover their fundamental relevance to humour style analysis. Through this study, we unveil common approaches, illuminate various datasets and evaluation metrics, and effectively navigate the complex terrain of humour research. Our efforts determine potential research gaps and outlined promising directions. Furthermore, the SLR identifies a range of features and computational models that can seamlessly transition from related tasks like binary humour and sarcasm detection to invigorate humour style classification. These features encompass incongruity, sentiment and polarity analysis, ambiguity detection, acoustic nuances, visual cues, contextual insights, and more. The computational models that emerge contain traditional machine learning paradigms, neural network architectures, transformer-based models, and specialised models attuned to the nuances of humour. Finally, the SLR provides access to existing datasets related to humour and sarcasm, facilitating the work of future researchers.</li>
</ul>

<h3>Title: Rethinking Interpretability in the Era of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chandan Singh, Jeevana Priya Inala, Michel Galley, Rich Caruana, Jianfeng Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01761">https://arxiv.org/abs/2402.01761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01761">https://arxiv.org/pdf/2402.01761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01761]] Rethinking Interpretability in the Era of Large Language Models(https://arxiv.org/abs/2402.01761)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Interpretable machine learning has exploded as an area of interest over the last decade, sparked by the rise of increasingly large datasets and deep neural networks. Simultaneously, large language models (LLMs) have demonstrated remarkable capabilities across a wide array of tasks, offering a chance to rethink opportunities in interpretable machine learning. Notably, the capability to explain in natural language allows LLMs to expand the scale and complexity of patterns that can be given to a human. However, these new capabilities raise new challenges, such as hallucinated explanations and immense computational costs. In this position paper, we start by reviewing existing methods to evaluate the emerging field of LLM interpretation (both interpreting LLMs and using LLMs for explanation). We contend that, despite their limitations, LLMs hold the opportunity to redefine interpretability with a more ambitious scope across many applications, including in auditing LLMs themselves. We highlight two emerging research priorities for LLM interpretation: using LLMs to directly analyze new datasets and to generate interactive explanations.</li>
</ul>

<h3>Title: LLMs Simulate Big Five Personality Traits: Further Evidence</h3>
<ul>
<li><strong>Authors: </strong>Aleksandra Sorokovikova, Natalia Fedorova, Sharwin Rezagholi, Ivan P. Yamshchikov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01765">https://arxiv.org/abs/2402.01765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01765">https://arxiv.org/pdf/2402.01765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01765]] LLMs Simulate Big Five Personality Traits: Further Evidence(https://arxiv.org/abs/2402.01765)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>An empirical investigation into the simulation of the Big Five personality traits by large language models (LLMs), namely Llama2, GPT4, and Mixtral, is presented. We analyze the personality traits simulated by these models and their stability. This contributes to the broader understanding of the capabilities of LLMs to simulate personality traits and the respective implications for personalized human-computer interaction.</li>
</ul>

<h3>Title: LLM Voting: Human Choices and AI Collective Decision Making</h3>
<ul>
<li><strong>Authors: </strong>Joshua C. Yang, Marcin Korecki, Damian Dailisan, Carina I. Hausladen, Dirk Helbing</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01766">https://arxiv.org/abs/2402.01766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01766">https://arxiv.org/pdf/2402.01766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01766]] LLM Voting: Human Choices and AI Collective Decision Making(https://arxiv.org/abs/2402.01766)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the voting behaviors of Large Language Models (LLMs), particularly OpenAI's GPT4 and LLaMA2, and their alignment with human voting patterns. Our approach included a human voting experiment to establish a baseline for human preferences and a parallel experiment with LLM agents. The study focused on both collective outcomes and individual preferences, revealing differences in decision-making and inherent biases between humans and LLMs. We observed a trade-off between preference diversity and alignment in LLMs, with a tendency towards more uniform choices as compared to the diverse preferences of human voters. This finding indicates that LLMs could lead to more homogenized collective outcomes when used in voting assistance, underscoring the need for cautious integration of LLMs into democratic processes.</li>
</ul>

<h3>Title: Redefining "Hallucination" in LLMs: Towards a psychology-informed  framework for mitigating misinformation</h3>
<ul>
<li><strong>Authors: </strong>Elijah Berberette, Jack Hutchins, Amir Sadovnik</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01769">https://arxiv.org/abs/2402.01769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01769">https://arxiv.org/pdf/2402.01769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01769]] Redefining "Hallucination" in LLMs: Towards a psychology-informed  framework for mitigating misinformation(https://arxiv.org/abs/2402.01769)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, large language models (LLMs) have become incredibly popular, with ChatGPT for example being used by over a billion users. While these models exhibit remarkable language understanding and logical prowess, a notable challenge surfaces in the form of "hallucinations." This phenomenon results in LLMs outputting misinformation in a confident manner, which can lead to devastating consequences with such a large user base. However, we question the appropriateness of the term "hallucination" in LLMs, proposing a psychological taxonomy based on cognitive biases and other psychological phenomena. Our approach offers a more fine-grained understanding of this phenomenon, allowing for targeted solutions. By leveraging insights from how humans internally resolve similar challenges, we aim to develop strategies to mitigate LLM hallucinations. This interdisciplinary approach seeks to move beyond conventional terminology, providing a nuanced understanding and actionable pathways for improvement in LLM reliability.</li>
</ul>

<h3>Title: BlackMamba: Mixture of Experts for State-Space Models</h3>
<ul>
<li><strong>Authors: </strong>Quentin Anthony, Yury Tokpanov, Paolo Glorioso, Beren Millidge</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01771">https://arxiv.org/abs/2402.01771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01771">https://arxiv.org/pdf/2402.01771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01771]] BlackMamba: Mixture of Experts for State-Space Models(https://arxiv.org/abs/2402.01771)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>State-space models (SSMs) have recently demonstrated competitive performance to transformers at large-scale language modeling benchmarks while achieving linear time and memory complexity as a function of sequence length. Mamba, a recently released SSM model, shows impressive performance in both language modeling and long sequence processing tasks. Simultaneously, mixture-of-expert (MoE) models have shown remarkable performance while significantly reducing the compute and latency costs of inference at the expense of a larger memory footprint. In this paper, we present BlackMamba, a novel architecture that combines the Mamba SSM with MoE to obtain the benefits of both. We demonstrate that BlackMamba performs competitively against both Mamba and transformer baselines, and outperforms in inference and training FLOPs. We fully train and open-source 340M/1.5B and 630M/2.8B BlackMamba models on 300B tokens of a custom dataset. We show that BlackMamba inherits and combines both of the benefits of SSM and MoE architectures, combining linear-complexity generation from SSM with cheap and fast inference from MoE. We release all weights, checkpoints, and inference code open-source. Inference code at: https://github.com/Zyphra/BlackMamba</li>
</ul>

<h3>Title: When Benchmarks are Targets: Revealing the Sensitivity of Large Language  Model Leaderboards</h3>
<ul>
<li><strong>Authors: </strong>Norah Alzahrani, Hisham Abdullah Alyahya, Yazeed Alnumay, Sultan Alrashed, Shaykhah Alsubaie, Yusef Almushaykeh, Faisal Mirza, Nouf Alotaibi, Nora Altwairesh, Areeb Alowisheq, M Saiful Bari, Haidar Khan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01781">https://arxiv.org/abs/2402.01781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01781">https://arxiv.org/pdf/2402.01781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01781]] When Benchmarks are Targets: Revealing the Sensitivity of Large Language  Model Leaderboards(https://arxiv.org/abs/2402.01781)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value - we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance of LLMs is highly sensitive to (often minute) details. We show that for popular multiple choice question benchmarks (e.g. MMLU) minor perturbations to the benchmark, such as changing the order of choices or the method of answer selection, result in changes in rankings up to 8 positions. We explain this phenomenon by conducting systematic experiments over three broad categories of benchmark perturbations and identifying the sources of this behavior. Our analysis results in several best-practice recommendations, including the advantage of a hybrid scoring method for answer selection. Our study highlights the dangers of relying on simple benchmark evaluations and charts the path for more robust evaluation schemes on the existing benchmarks.</li>
</ul>

<h3>Title: Hierarchical Multi-Label Classification of Online Vaccine Concerns</h3>
<ul>
<li><strong>Authors: </strong>Chloe Qinyu Zhu, Rickard Stureborg, Bhuwan Dhingra</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01783">https://arxiv.org/abs/2402.01783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01783">https://arxiv.org/pdf/2402.01783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01783]] Hierarchical Multi-Label Classification of Online Vaccine Concerns(https://arxiv.org/abs/2402.01783)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vaccine concerns are an ever-evolving target, and can shift quickly as seen during the COVID-19 pandemic. Identifying longitudinal trends in vaccine concerns and misinformation might inform the healthcare space by helping public health efforts strategically allocate resources or information campaigns. We explore the task of detecting vaccine concerns in online discourse using large language models (LLMs) in a zero-shot setting without the need for expensive training datasets. Since real-time monitoring of online sources requires large-scale inference, we explore cost-accuracy trade-offs of different prompting strategies and offer concrete takeaways that may inform choices in system designs for current applications. An analysis of different prompting strategies reveals that classifying the concerns over multiple passes through the LLM, each consisting a boolean question whether the text mentions a vaccine concern or not, works the best. Our results indicate that GPT-4 can strongly outperform crowdworker accuracy when compared to ground truth annotations provided by experts on the recently introduced VaxConcerns dataset, achieving an overall F1 score of 78.7%.</li>
</ul>

<h3>Title: LitLLM: A Toolkit for Scientific Literature Review</h3>
<ul>
<li><strong>Authors: </strong>Shubham Agarwal, Issam H. Laradji, Laurent Charlin, Christopher Pal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01788">https://arxiv.org/abs/2402.01788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01788">https://arxiv.org/pdf/2402.01788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01788]] LitLLM: A Toolkit for Scientific Literature Review(https://arxiv.org/abs/2402.01788)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conducting literature reviews for scientific papers is essential for understanding research, its limitations, and building on existing work. It is a tedious task which makes an automatic literature review generator appealing. Unfortunately, many existing works that generate such reviews using Large Language Models (LLMs) have significant limitations. They tend to hallucinate-generate non-actual information-and ignore the latest research they have not been trained on. To address these limitations, we propose a toolkit that operates on Retrieval Augmented Generation (RAG) principles, specialized prompting and instructing techniques with the help of LLMs. Our system first initiates a web search to retrieve relevant papers by summarizing user-provided abstracts into keywords using an off-the-shelf LLM. Authors can enhance the search by supplementing it with relevant papers or keywords, contributing to a tailored retrieval process. Second, the system re-ranks the retrieved papers based on the user-provided abstract. Finally, the related work section is generated based on the re-ranked results and the abstract. There is a substantial reduction in time and effort for literature review compared to traditional methods, establishing our toolkit as an efficient alternative. Our open-source toolkit is accessible at https://github.com/shubhamagarwal92/LitLLM and Huggingface space (https://huggingface.co/spaces/shubhamagarwal92/LitLLM) with the video demo at https://youtu.be/E2ggOZBAFw0.</li>
</ul>

<h3>Title: An introduction to graphical tensor notation for mechanistic  interpretability</h3>
<ul>
<li><strong>Authors: </strong>Jordan K. Taylor</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01790">https://arxiv.org/abs/2402.01790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01790">https://arxiv.org/pdf/2402.01790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01790]] An introduction to graphical tensor notation for mechanistic  interpretability(https://arxiv.org/abs/2402.01790)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Graphical tensor notation is a simple way of denoting linear operations on tensors, originating from physics. Modern deep learning consists almost entirely of operations on or between tensors, so easily understanding tensor operations is quite important for understanding these systems. This is especially true when attempting to reverse-engineer the algorithms learned by a neural network in order to understand its behavior: a field known as mechanistic interpretability. It's often easy to get confused about which operations are happening between tensors and lose sight of the overall structure, but graphical tensor notation makes it easier to parse things at a glance and see interesting equivalences. The first half of this document introduces the notation and applies it to some decompositions (SVD, CP, Tucker, and tensor network decompositions), while the second half applies it to some existing some foundational approaches for mechanistically understanding language models, loosely following ``A Mathematical Framework for Transformer Circuits'', then constructing an example ``induction head'' circuit in graphical tensor notation.</li>
</ul>

<h3>Title: Robust support vector machines via conic optimization</h3>
<ul>
<li><strong>Authors: </strong>Valentina Cepeda, Andrs Gmez, Shaoning Han</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01797">https://arxiv.org/abs/2402.01797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01797">https://arxiv.org/pdf/2402.01797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01797]] Robust support vector machines via conic optimization(https://arxiv.org/abs/2402.01797)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We consider the problem of learning support vector machines robust to uncertainty. It has been established in the literature that typical loss functions, including the hinge loss, are sensible to data perturbations and outliers, thus performing poorly in the setting considered. In contrast, using the 0-1 loss or a suitable non-convex approximation results in robust estimators, at the expense of large computational costs. In this paper we use mixed-integer optimization techniques to derive a new loss function that better approximates the 0-1 loss compared with existing alternatives, while preserving the convexity of the learning problem. In our computational results, we show that the proposed estimator is competitive with the standard SVMs with the hinge loss in outlier-free regimes and better in the presence of outliers.</li>
</ul>

<h3>Title: Large Language Models for Time Series: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Xiyuan Zhang, Ranak Roy Chowdhury, Rajesh K. Gupta, Jingbo Shang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01801">https://arxiv.org/abs/2402.01801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01801">https://arxiv.org/pdf/2402.01801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01801]] Large Language Models for Time Series: A Survey(https://arxiv.org/abs/2402.01801)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have seen significant use in domains such as natural language processing and computer vision. Going beyond text, image and graphics, LLMs present a significant potential for analysis of time series data, benefiting domains such as climate, IoT, healthcare, traffic, audio and finance. This survey paper provides an in-depth exploration and a detailed taxonomy of the various methodologies employed to harness the power of LLMs for time series analysis. We address the inherent challenge of bridging the gap between LLMs' original text data training and the numerical nature of time series data, and explore strategies for transferring and distilling knowledge from LLMs to numerical time series analysis. We detail various methodologies, including (1) direct prompting of LLMs, (2) time series quantization, (3) alignment techniques, (4) utilization of the vision modality as a bridging mechanism, and (5) the combination of LLMs with tools. Additionally, this survey offers a comprehensive overview of the existing multimodal time series and text datasets and delves into the challenges and future opportunities of this emerging field. We maintain an up-to-date Github repository which includes all the papers and datasets discussed in the survey.</li>
</ul>

<h3>Title: An Auction-based Marketplace for Model Trading in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yue Cui, Liuyi Yao, Yaliang Li, Ziqian Chen, Bolin Ding, Xiaofang Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01802">https://arxiv.org/abs/2402.01802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01802">https://arxiv.org/pdf/2402.01802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01802]] An Auction-based Marketplace for Model Trading in Federated Learning(https://arxiv.org/abs/2402.01802)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, fair</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is increasingly recognized for its efficacy in training models using locally distributed data. However, the proper valuation of shared data in this collaborative process remains insufficiently addressed. In this work, we frame FL as a marketplace of models, where clients act as both buyers and sellers, engaging in model trading. This FL market allows clients to gain monetary reward by selling their own models and improve local model performance through the purchase of others' models. We propose an auction-based solution to ensure proper pricing based on performance gain. Incentive mechanisms are designed to encourage clients to truthfully reveal their model valuations. Furthermore, we introduce a reinforcement learning (RL) framework for marketing operations, aiming to achieve maximum trading volumes under the dynamic and evolving market status. Experimental results on four datasets demonstrate that the proposed FL market can achieve high trading revenue and fair downstream task accuracy.</li>
</ul>

<h3>Title: Exploring the Limitations of Graph Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Palaash Agrawal, Shavak Vasania, Cheston Tan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01805">https://arxiv.org/abs/2402.01805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01805">https://arxiv.org/pdf/2402.01805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01805]] Exploring the Limitations of Graph Reasoning in Large Language Models(https://arxiv.org/abs/2402.01805)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pretrained Large Language Models have demonstrated various types of reasoning capabilities through language-based prompts alone. However, in this paper, we test the depth of graph reasoning for 5 different LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2 and Palm-2) through the problems of graph reasoning. In particular, we design 10 distinct problems of graph traversal, each representing increasing levels of complexity. Further, we analyze the performance of models across various settings such as varying sizes of graphs as well as different forms of k-shot prompting. We highlight various limitations, biases, and properties of LLMs through this benchmarking process, such as an inverse relation to the average degrees of freedom of traversal per node in graphs, the overall negative impact of k-shot prompting on graph reasoning tasks, and a positive response bias which prevents LLMs from identifying the absence of a valid solution. Finally, we propose a new prompting technique specially designed for graph traversal tasks, known as PathCompare, which shows a notable increase in the performance of LLMs in comparison to standard prompting and CoT.</li>
</ul>

<h3>Title: HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack  on Text</h3>
<ul>
<li><strong>Authors: </strong>Han Liu, Zhi Xu, Xiaotong Zhang, Feng Zhang, Fenglong Ma, Hongyang Chen, Hong Yu, Xianchao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01806">https://arxiv.org/abs/2402.01806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01806">https://arxiv.org/pdf/2402.01806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01806]] HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack  on Text(https://arxiv.org/abs/2402.01806)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Black-box hard-label adversarial attack on text is a practical and challenging task, as the text data space is inherently discrete and non-differentiable, and only the predicted label is accessible. Research on this problem is still in the embryonic stage and only a few methods are available. Nevertheless, existing methods rely on the complex heuristic algorithm or unreliable gradient estimation strategy, which probably fall into the local optimum and inevitably consume numerous queries, thus are difficult to craft satisfactory adversarial examples with high semantic similarity and low perturbation rate in a limited query budget. To alleviate above issues, we propose a simple yet effective framework to generate high quality textual adversarial examples under the black-box hard-label attack scenarios, named HQA-Attack. Specifically, after initializing an adversarial example randomly, HQA-attack first constantly substitutes original words back as many as possible, thus shrinking the perturbation rate. Then it leverages the synonym set of the remaining changed words to further optimize the adversarial example with the direction which can improve the semantic similarity and satisfy the adversarial condition simultaneously. In addition, during the optimizing procedure, it searches a transition synonym word for each changed word, thus avoiding traversing the whole synonym set and reducing the query number to some extent. Extensive experimental results on five text classification datasets, three natural language inference datasets and two real-world APIs have shown that the proposed HQA-Attack method outperforms other strong baselines significantly.</li>
</ul>

<h3>Title: AOC-IDS: Autonomous Online Framework with Contrastive Learning for  Intrusion Detection</h3>
<ul>
<li><strong>Authors: </strong>Xinchen Zhang, Running Zhao, Zhihan Jiang, Zhicong Sun, Yulong Ding, Edith C.H. Ngai, Shuang-Hua Yang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01807">https://arxiv.org/abs/2402.01807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01807">https://arxiv.org/pdf/2402.01807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01807]] AOC-IDS: Autonomous Online Framework with Contrastive Learning for  Intrusion Detection(https://arxiv.org/abs/2402.01807)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The rapid expansion of the Internet of Things (IoT) has raised increasing concern about targeted cyber attacks. Previous research primarily focused on static Intrusion Detection Systems (IDSs), which employ offline training to safeguard IoT systems. However, such static IDSs struggle with real-world scenarios where IoT system behaviors and attack strategies can undergo rapid evolution, necessitating dynamic and adaptable IDSs. In response to this challenge, we propose AOC-IDS, a novel online IDS that features an autonomous anomaly detection module (ADM) and a labor-free online framework for continual adaptation. In order to enhance data comprehension, the ADM employs an Autoencoder (AE) with a tailored Cluster Repelling Contrastive (CRC) loss function to generate distinctive representation from limited or incrementally incoming data in the online setting. Moreover, to reduce the burden of manual labeling, our online framework leverages pseudo-labels automatically generated from the decision-making process in the ADM to facilitate periodic updates of the ADM. The elimination of human intervention for labeling and decision-making boosts the system's compatibility and adaptability in the online setting to remain synchronized with dynamic environments. Experimental validation using the NSL-KDD and UNSW-NB15 datasets demonstrates the superior performance and adaptability of AOC-IDS, surpassing the state-of-the-art solutions. The code is released at https://github.com/xinchen930/AOC-IDS.</li>
</ul>

<h3>Title: A Distributionally Robust Optimisation Approach to Fair Credit Scoring</h3>
<ul>
<li><strong>Authors: </strong>Pablo Casas, Christophe Mues, Huan Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01811">https://arxiv.org/abs/2402.01811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01811">https://arxiv.org/pdf/2402.01811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01811]] A Distributionally Robust Optimisation Approach to Fair Credit Scoring(https://arxiv.org/abs/2402.01811)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Credit scoring has been catalogued by the European Commission and the Executive Office of the US President as a high-risk classification task, a key concern being the potential harms of making loan approval decisions based on models that would be biased against certain groups. To address this concern, recent credit scoring research has considered a range of fairness-enhancing techniques put forward by the machine learning community to reduce bias and unfair treatment in classification systems. While the definition of fairness or the approach they follow to impose it may vary, most of these techniques, however, disregard the robustness of the results. This can create situations where unfair treatment is effectively corrected in the training set, but when producing out-of-sample classifications, unfair treatment is incurred again. Instead, in this paper, we will investigate how to apply Distributionally Robust Optimisation (DRO) methods to credit scoring, thereby empirically evaluating how they perform in terms of fairness, ability to classify correctly, and the robustness of the solution against changes in the marginal proportions. In so doing, we find DRO methods to provide a substantial improvement in terms of fairness, with almost no loss in performance. These results thus indicate that DRO can improve fairness in credit scoring, provided that further advances are made in efficiently implementing these systems. In addition, our analysis suggests that many of the commonly used fairness metrics are unsuitable for a credit scoring setting, as they depend on the choice of classification threshold.</li>
</ul>

<h3>Title: Distilling LLMs' Decomposition Abilities into Compact Language Models</h3>
<ul>
<li><strong>Authors: </strong>Denis Tarasov, Kumar Shridhar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01812">https://arxiv.org/abs/2402.01812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01812">https://arxiv.org/pdf/2402.01812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01812]] Distilling LLMs' Decomposition Abilities into Compact Language Models(https://arxiv.org/abs/2402.01812)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated proficiency in their reasoning abilities, yet their large size presents scalability challenges and limits any further customization. In contrast, compact models offer customized training but often fall short in solving complex reasoning tasks. This study focuses on distilling the LLMs' decomposition skills into compact models using offline reinforcement learning. We leverage the advancements in the LLM`s capabilities to provide feedback and generate a specialized task-specific dataset for training compact models. The development of an AI-generated dataset and the establishment of baselines constitute the primary contributions of our work, underscoring the potential of compact models in replicating complex problem-solving skills.</li>
</ul>

<h3>Title: Ecologically rational meta-learned inference explains human category  learning</h3>
<ul>
<li><strong>Authors: </strong>Akshay K. Jagadish, Julian Coda-Forno, Mirko Thalmann, Eric Schulz, Marcel Binz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01821">https://arxiv.org/abs/2402.01821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01821">https://arxiv.org/pdf/2402.01821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01821]] Ecologically rational meta-learned inference explains human category  learning(https://arxiv.org/abs/2402.01821)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ecological rationality refers to the notion that humans are rational agents adapted to their environment. However, testing this theory remains challenging due to two reasons: the difficulty in defining what tasks are ecologically valid and building rational models for these tasks. In this work, we demonstrate that large language models can generate cognitive tasks, specifically category learning tasks, that match the statistics of real-world tasks, thereby addressing the first challenge. We tackle the second challenge by deriving rational agents adapted to these tasks using the framework of meta-learning, leading to a class of models called ecologically rational meta-learned inference (ERMI). ERMI quantitatively explains human data better than seven other cognitive models in two different experiments. It additionally matches human behavior on a qualitative level: (1) it finds the same tasks difficult that humans find difficult, (2) it becomes more reliant on an exemplar-based strategy for assigning categories with learning, and (3) it generalizes to unseen stimuli in a human-like way. Furthermore, we show that ERMI's ecologically valid priors allow it to achieve state-of-the-art performance on the OpenML-CC18 classification benchmark.</li>
</ul>

<h3>Title: Building Guardrails for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yi Dong, Ronghui Mu, Gaojie Jin, Yi Qi, Jinwei Hu, Xingyu Zhao, Jie Meng, Wenjie Ruan, Xiaowei Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01822">https://arxiv.org/abs/2402.01822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01822">https://arxiv.org/pdf/2402.01822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01822]] Building Guardrails for Large Language Models(https://arxiv.org/abs/2402.01822)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) become more integrated into our daily lives, it is crucial to identify and mitigate their risks, especially when the risks can have profound impacts on human users and societies. Guardrails, which filter the inputs or outputs of LLMs, have emerged as a core safeguarding technology. This position paper takes a deep look at current open-source solutions (Llama Guard, Nvidia NeMo, Guardrails AI), and discusses the challenges and the road towards building more complete solutions. Drawing on robust evidence from previous research, we advocate for a systematic approach to construct guardrails for LLMs, based on comprehensive consideration of diverse contexts across various LLMs applications. We propose employing socio-technical methods through collaboration with a multi-disciplinary team to pinpoint precise technical requirements, exploring advanced neural-symbolic implementations to embrace the complexity of the requirements, and developing verification and testing to ensure the utmost quality of the final product.</li>
</ul>

<h3>Title: Leveraging Large Language Models for Analyzing Blood Pressure Variations  Across Biological Sex from Scientific Literature</h3>
<ul>
<li><strong>Authors: </strong>Yuting Guo, Seyedeh Somayyeh Mousavi, Reza Sameni, Abeed Sarker</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01826">https://arxiv.org/abs/2402.01826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01826">https://arxiv.org/pdf/2402.01826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01826]] Leveraging Large Language Models for Analyzing Blood Pressure Variations  Across Biological Sex from Scientific Literature(https://arxiv.org/abs/2402.01826)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hypertension, defined as blood pressure (BP) that is above normal, holds paramount significance in the realm of public health, as it serves as a critical precursor to various cardiovascular diseases (CVDs) and significantly contributes to elevated mortality rates worldwide. However, many existing BP measurement technologies and standards might be biased because they do not consider clinical outcomes, comorbidities, or demographic factors, making them inconclusive for diagnostic purposes. There is limited data-driven research focused on studying the variance in BP measurements across these variables. In this work, we employed GPT-35-turbo, a large language model (LLM), to automatically extract the mean and standard deviation values of BP for both males and females from a dataset comprising 25 million abstracts sourced from PubMed. 993 article abstracts met our predefined inclusion criteria (i.e., presence of references to blood pressure, units of blood pressure such as mmHg, and mention of biological sex). Based on the automatically-extracted information from these articles, we conducted an analysis of the variations of BP values across biological sex. Our results showed the viability of utilizing LLMs to study the BP variations across different demographic factors.</li>
</ul>

<h3>Title: Retrieval Augmented End-to-End Spoken Dialog Models</h3>
<ul>
<li><strong>Authors: </strong>Mingqiu Wang, Izhak Shafran, Hagen Soltau, Wei Han, Yuan Cao, Dian Yu, Laurent El Shafey</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01828">https://arxiv.org/abs/2402.01828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01828">https://arxiv.org/pdf/2402.01828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01828]] Retrieval Augmented End-to-End Spoken Dialog Models(https://arxiv.org/abs/2402.01828)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We recently developed SLM, a joint speech and language model, which fuses a pretrained foundational speech model and a large language model (LLM), while preserving the in-context learning capability intrinsic to the pretrained LLM. In this paper, we apply SLM to speech dialog applications where the dialog states are inferred directly from the audio signal. Task-oriented dialogs often contain domain-specific entities, i.e., restaurants, hotels, train stations, and city names, which are difficult to recognize, however, critical for the downstream applications. Inspired by the RAG (retrieval-augmented generation) paradigm, we propose a retrieval augmented SLM (ReSLM) that overcomes this weakness. We first train a speech retriever to retrieve text entities mentioned in the audio. The retrieved entities are then added as text inputs to the underlying SLM to bias model predictions. We evaluated ReSLM on speech MultiWoz task (DSTC-11 challenge), and found that this retrieval augmentation boosts model performance, achieving joint goal accuracy (38.6% vs 32.7%), slot error rate (20.6% vs 24.8%) and ASR word error rate (5.5% vs 6.7%). While demonstrated on dialog state tracking, our approach is broadly applicable to other speech tasks requiring contextual information or domain-specific entities, such as contextual ASR with biasing capability.</li>
</ul>

<h3>Title: Peer-review-in-LLMs: Automatic Evaluation Method for LLMs in  Open-environment</h3>
<ul>
<li><strong>Authors: </strong>Kun-Peng Ning, Shuo Yang, Yu-Yang Liu, Jia-Yu Yao, Zhen-Hui Liu, Yu Wang, Ming Pang, Li Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01830">https://arxiv.org/abs/2402.01830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01830">https://arxiv.org/pdf/2402.01830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01830]] Peer-review-in-LLMs: Automatic Evaluation Method for LLMs in  Open-environment(https://arxiv.org/abs/2402.01830)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing large language models (LLMs) evaluation methods typically focus on testing the performance on some closed-environment and domain-specific benchmarks with human annotations. In this paper, we explore a novel unsupervised evaluation direction, utilizing peer-review mechanisms to measure LLMs automatically. In this setting, both open-source and closed-source LLMs lie in the same environment, capable of answering unlabeled questions and evaluating each other, where each LLM's response score is jointly determined by other anonymous ones. To obtain the ability hierarchy among these models, we assign each LLM a learnable capability parameter to adjust the final ranking. We formalize it as a constrained optimization problem, intending to maximize the consistency of each LLM's capabilities and scores. The key assumption behind is that high-level LLM can evaluate others' answers more accurately than low-level ones, while higher-level LLM can also achieve higher response scores. Moreover, we propose three metrics called PEN, CIN, and LIS to evaluate the gap in aligning human rankings. We perform experiments on multiple datasets with these metrics, validating the effectiveness of the proposed approach.</li>
</ul>

<h3>Title: SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training?</h3>
<ul>
<li><strong>Authors: </strong>Hasan Abed Al Kader Hammoud, Hani Itani, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01832">https://arxiv.org/abs/2402.01832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01832">https://arxiv.org/pdf/2402.01832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01832]] SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training?(https://arxiv.org/abs/2402.01832)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>We present SynthCLIP, a novel framework for training CLIP models with entirely synthetic text-image pairs, significantly departing from previous methods relying on real data. Leveraging recent text-to-image (TTI) generative networks and large language models (LLM), we are able to generate synthetic datasets of images and corresponding captions at any scale, with no human intervention. With training at scale, SynthCLIP achieves performance comparable to CLIP models trained on real datasets. We also introduce SynthCI-30M, a purely synthetic dataset comprising 30 million captioned images. Our code, trained models, and generated data are released at https://github.com/hammoudhasan/SynthCLIP</li>
</ul>

<h3>Title: QPP and HPPK: Unifying Non-Commutativity for Quantum-Secure Cryptography  with Galois Permutation Group</h3>
<ul>
<li><strong>Authors: </strong>Randy Kuang</a></li>
<li><strong>Subjects: </strong>cs.CR, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01852">https://arxiv.org/abs/2402.01852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01852">https://arxiv.org/pdf/2402.01852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01852]] QPP and HPPK: Unifying Non-Commutativity for Quantum-Secure Cryptography  with Galois Permutation Group(https://arxiv.org/abs/2402.01852)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>In response to the evolving landscape of quantum computing and the escalating vulnerabilities in classical cryptographic systems, our paper introduces a unified cryptographic framework. Rooted in the innovative work of Kuang et al., we leverage two novel primitives: the Quantum Permutation Pad (QPP) for symmetric key encryption and the Homomorphic Polynomial Public Key (HPPK) for Key Encapsulation Mechanism (KEM) and Digital Signatures (DS). Our approach adeptly confronts the challenges posed by quantum advancements. Utilizing the Galois Permutation Group's matrix representations and inheriting its bijective and non-commutative properties, QPP achieves quantum-secure symmetric key encryption, seamlessly extending Shannon's perfect secrecy to both classical and quantum-native systems. Meanwhile, HPPK, free from NP-hard problems, fortifies symmetric encryption for the plain public key. It accomplishes this by concealing the mathematical structure through modular multiplications or arithmetic representations of Galois Permutation Group over hidden rings, harnessing their partial homomorphic properties. This allows for secure computation on encrypted data during secret encapsulations, bolstering the security of the plain public key. The seamless integration of KEM and DS within HPPK cryptography yields compact key, cipher, and signature sizes, demonstrating exceptional performance. This paper organically unifies QPP and HPPK under the Galois Permutation Group, marking a significant advancement in laying the groundwork for quantum-resistant cryptographic protocols. Our contribution propels the development of secure communication systems amid the era of quantum computing.</li>
</ul>

<h3>Title: Position Paper: Assessing Robustness, Privacy, and Fairness in Federated  Learning Integrated with Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Xi Li, Jiaqi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01857">https://arxiv.org/abs/2402.01857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01857">https://arxiv.org/pdf/2402.01857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01857]] Position Paper: Assessing Robustness, Privacy, and Fairness in Federated  Learning Integrated with Foundation Models(https://arxiv.org/abs/2402.01857)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, robust, federate, fair</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL), while a breakthrough in decentralized machine learning, contends with significant challenges such as limited data availability and the variability of computational resources, which can stifle the performance and scalability of the models. The integration of Foundation Models (FMs) into FL presents a compelling solution to these issues, with the potential to enhance data richness and reduce computational demands through pre-training and data augmentation. However, this incorporation introduces novel issues in terms of robustness, privacy, and fairness, which have not been sufficiently addressed in the existing research. We make a preliminary investigation into this field by systematically evaluating the implications of FM-FL integration across these dimensions. We analyze the trade-offs involved, uncover the threats and issues introduced by this integration, and propose a set of criteria and strategies for navigating these challenges. Furthermore, we identify potential research directions for advancing this field, laying a foundation for future development in creating reliable, secure, and equitable FL systems.</li>
</ul>

<h3>Title: Explaining latent representations of generative models with large  multimodal models</h3>
<ul>
<li><strong>Authors: </strong>Mengdan Zhu, Zhenke Liu, Bo Pan, Abhinav Angirekula, Liang Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01858">https://arxiv.org/abs/2402.01858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01858">https://arxiv.org/pdf/2402.01858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01858]] Explaining latent representations of generative models with large  multimodal models(https://arxiv.org/abs/2402.01858)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Learning interpretable representations of data generative latent factors is an important topic for the development of artificial intelligence. With the rise of the large multimodal model, it can align images with text to generate answers. In this work, we propose a framework to comprehensively explain each latent factor in the generative models using a large multimodal model. We further measure the uncertainty of our generated explanations, quantitatively evaluate the performance of explanation generation among multiple large multimodal models, and qualitatively visualize the variations of each latent factor to learn the disentanglement effects of different generative models on explanations. Finally, we discuss the explanatory capabilities and limitations of state-of-the-art large multimodal models.</li>
</ul>

<h3>Title: Parametric Feature Transfer: One-shot Federated Learning with Foundation  Models</h3>
<ul>
<li><strong>Authors: </strong>Mahdi Beitollahi, Alex Bie, Sobhan Hemati, Leo Maxime Brunswic, Xu Li, Xi Chen, Guojun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01862">https://arxiv.org/abs/2402.01862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01862">https://arxiv.org/pdf/2402.01862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01862]] Parametric Feature Transfer: One-shot Federated Learning with Foundation  Models(https://arxiv.org/abs/2402.01862)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>In one-shot federated learning (FL), clients collaboratively train a global model in a single round of communication. Existing approaches for one-shot FL enhance communication efficiency at the expense of diminished accuracy. This paper introduces FedPFT (Federated Learning with Parametric Feature Transfer), a methodology that harnesses the transferability of foundation models to enhance both accuracy and communication efficiency in one-shot FL. The approach involves transferring per-client parametric models (specifically, Gaussian mixtures) of features extracted from foundation models. Subsequently, each parametric model is employed to generate synthetic features for training a classifier head. Experimental results on eight datasets demonstrate that FedPFT enhances the communication-accuracy frontier in both centralized and decentralized FL scenarios, as well as across diverse data-heterogeneity settings such as covariate shift and task shift, with improvements of up to 20.6%. Additionally, FedPFT adheres to the data minimization principle of FL, as clients do not send real features. We demonstrate that sending real features is vulnerable to potent reconstruction attacks. Moreover, we show that FedPFT is amenable to formal privacy guarantees via differential privacy, demonstrating favourable privacy-accuracy tradeoffs.</li>
</ul>

<h3>Title: DFML: Decentralized Federated Mutual Learning</h3>
<ul>
<li><strong>Authors: </strong>Yasser H. Khalil, Amir H. Estiri, Mahdi Beitollahi, Nader Asadi, Sobhan Hemati, Xu Li, Guojun Zhang, Xi Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01863">https://arxiv.org/abs/2402.01863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01863">https://arxiv.org/pdf/2402.01863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01863]] DFML: Decentralized Federated Mutual Learning(https://arxiv.org/abs/2402.01863)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In the realm of real-world devices, centralized servers in Federated Learning (FL) present challenges including communication bottlenecks and susceptibility to a single point of failure. Additionally, contemporary devices inherently exhibit model and data heterogeneity. Existing work lacks a Decentralized FL (DFL) framework capable of accommodating such heterogeneity without imposing architectural restrictions or assuming the availability of public data. To address these issues, we propose a Decentralized Federated Mutual Learning (DFML) framework that is serverless, supports nonrestrictive heterogeneous models, and avoids reliance on public data. DFML effectively handles model and data heterogeneity through mutual learning, which distills knowledge between clients, and cyclically varying the amount of supervision and distillation signals. Extensive experimental results demonstrate consistent effectiveness of DFML in both convergence speed and global accuracy, outperforming prevalent baselines under various conditions. For example, with the CIFAR-100 dataset and 50 clients, DFML achieves a substantial increase of +17.20% and +19.95% in global accuracy under Independent and Identically Distributed (IID) and non-IID data shifts, respectively.</li>
</ul>

<h3>Title: What Will My Model Forget? Forecasting Forgotten Examples in Language  Model Refinement</h3>
<ul>
<li><strong>Authors: </strong>Xisen Jin, Xiang Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01865">https://arxiv.org/abs/2402.01865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01865">https://arxiv.org/pdf/2402.01865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01865]] What Will My Model Forget? Forecasting Forgotten Examples in Language  Model Refinement(https://arxiv.org/abs/2402.01865)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Language models deployed in the wild make errors. However, simply updating the model with the corrected error instances causes catastrophic forgetting -- the updated model makes errors on instances learned during the instruction tuning or upstream training phase. Randomly replaying upstream data yields unsatisfactory performance and often comes with high variance and poor controllability. To this end, we try to forecast upstream examples that will be forgotten due to a model update for improved controllability of the replay process and interpretability. We train forecasting models given a collection of online learned examples and corresponding forgotten upstream pre-training examples. We propose a partially interpretable forecasting model based on the observation that changes in pre-softmax logit scores of pretraining examples resemble that of online learned examples, which performs decently on BART but fails on T5 models. We further show a black-box classifier based on inner products of example representations achieves better forecasting performance over a series of setups. Finally, we show that we reduce forgetting of upstream pretraining examples by replaying examples that are forecasted to be forgotten, demonstrating the practical utility of forecasting example forgetting.</li>
</ul>

<h3>Title: Leveraging Large Language Models for Structure Learning in Prompted Weak  Supervision</h3>
<ul>
<li><strong>Authors: </strong>Jinyan Su, Peilin Yu, Jieyu Zhang, Stephen H. Bach</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01867">https://arxiv.org/abs/2402.01867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01867">https://arxiv.org/pdf/2402.01867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01867]] Leveraging Large Language Models for Structure Learning in Prompted Weak  Supervision(https://arxiv.org/abs/2402.01867)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prompted weak supervision (PromptedWS) applies pre-trained large language models (LLMs) as the basis for labeling functions (LFs) in a weak supervision framework to obtain large labeled datasets. We further extend the use of LLMs in the loop to address one of the key challenges in weak supervision: learning the statistical dependency structure among supervision sources. In this work, we ask the LLM how similar are these prompted LFs. We propose a Structure Refining Module, a simple yet effective first approach based on the similarities of the prompts by taking advantage of the intrinsic structure in the embedding space. At the core of Structure Refining Module are Labeling Function Removal (LaRe) and Correlation Structure Generation (CosGen). Compared to previous methods that learn the dependencies from weak labels, our method finds the dependencies which are intrinsic to the LFs and less dependent on the data. We show that our Structure Refining Module improves the PromptedWS pipeline by up to 12.7 points on the benchmark tasks. We also explore the trade-offs between efficiency and performance with comprehensive ablation experiments and analysis. Code for this project can be found in https://github.com/BatsResearch/su-bigdata23-code.</li>
</ul>

<h3>Title: APIServe: Efficient API Support for Large-Language Model Inferencing</h3>
<ul>
<li><strong>Authors: </strong>Reyna Abhyankar, Zijian He, Vikranth Srivatsa, Hao Zhang, Yiying Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01869">https://arxiv.org/abs/2402.01869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01869">https://arxiv.org/pdf/2402.01869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01869]] APIServe: Efficient API Support for Large-Language Model Inferencing(https://arxiv.org/abs/2402.01869)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are increasingly integrated with external tools and APIs like ChatGPT plugins to extend their capability beyond language-centric tasks. However, today's LLM inference systems are designed for standalone LLMs. They treat API calls as new requests, causing unnecessary recomputation of already computed contexts, which accounts for 37-40% of total model forwarding time. This paper presents APIServe, the first LLM inference framework targeting API-augmented LLMs. APISERVE minimizes the GPU resource waste caused by API calls and dedicates saved memory for serving more requests. APISERVE improves the overall serving throughput by 1.6x and completes 2x more requests per second compared to the state-of-the-art LLM inference systems.</li>
</ul>

<h3>Title: The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement  Learning and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Moschoula Pternea, Prerna Singh, Abir Chakraborty, Yagna Oruganti, Mirco Milletari, Sayli Bapat, Kebei Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01874">https://arxiv.org/abs/2402.01874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01874">https://arxiv.org/pdf/2402.01874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01874]] The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement  Learning and Large Language Models(https://arxiv.org/abs/2402.01874)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we review research studies that combine Reinforcement Learning (RL) and Large Language Models (LLMs), two areas that owe their momentum to the development of deep neural networks. We propose a novel taxonomy of three main classes based on the way that the two model types interact with each other. The first class, RL4LLM, includes studies where RL is leveraged to improve the performance of LLMs on tasks related to Natural Language Processing. L4LLM is divided into two sub-categories depending on whether RL is used to directly fine-tune an existing LLM or to improve the prompt of the LLM. In the second class, LLM4RL, an LLM assists the training of an RL model that performs a task that is not inherently related to natural language. We further break down LLM4RL based on the component of the RL training framework that the LLM assists or replaces, namely reward shaping, goal generation, and policy function. Finally, in the third class, RL+LLM, an LLM and an RL agent are embedded in a common planning framework without either of them contributing to training or fine-tuning of the other. We further branch this class to distinguish between studies with and without natural language feedback. We use this taxonomy to explore the motivations behind the synergy of LLMs and RL and explain the reasons for its success, while pinpointing potential shortcomings and areas where further research is needed, as well as alternative methodologies that serve the same goal.</li>
</ul>

<h3>Title: $$-zero: Gradient-based Optimization of $\ell_0$-norm Adversarial  Examples</h3>
<ul>
<li><strong>Authors: </strong>Antonio Emanuele Cin, Francesco Villani, Maura Pintor, Lea Schnherr, Battista Biggio, Marcello Pelillo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01879">https://arxiv.org/abs/2402.01879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01879">https://arxiv.org/pdf/2402.01879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01879]] $$-zero: Gradient-based Optimization of $\ell_0$-norm Adversarial  Examples(https://arxiv.org/abs/2402.01879)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Evaluating the adversarial robustness of deep networks to gradient-based attacks is challenging. While most attacks consider $\ell_2$- and $\ell_\infty$-norm constraints to craft input perturbations, only a few investigate sparse $\ell_1$- and $\ell_0$-norm attacks. In particular, $\ell_0$-norm attacks remain the least studied due to the inherent complexity of optimizing over a non-convex and non-differentiable constraint. However, evaluating adversarial robustness under these attacks could reveal weaknesses otherwise left untested with more conventional $\ell_2$- and $\ell_\infty$-norm attacks. In this work, we propose a novel $\ell_0$-norm attack, called $\sigma$-zero, which leverages an ad hoc differentiable approximation of the $\ell_0$ norm to facilitate gradient-based optimization, and an adaptive projection operator to dynamically adjust the trade-off between loss minimization and perturbation sparsity. Extensive evaluations using MNIST, CIFAR10, and ImageNet datasets, involving robust and non-robust models, show that $\sigma$-zero finds minimum $\ell_0$-norm adversarial examples without requiring any time-consuming hyperparameter tuning, and that it outperforms all competing sparse attacks in terms of success rate, perturbation size, and scalability.</li>
</ul>

<h3>Title: Large Language Model Agent for Hyper-Parameter Optimization</h3>
<ul>
<li><strong>Authors: </strong>Siyi Liu, Chen Gao, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01881">https://arxiv.org/abs/2402.01881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01881">https://arxiv.org/pdf/2402.01881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01881]] Large Language Model Agent for Hyper-Parameter Optimization(https://arxiv.org/abs/2402.01881)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Hyperparameter optimization is critical in modern machine learning, requiring expert knowledge, numerous trials, and high computational and human resources. Despite the advancements in Automated Machine Learning (AutoML), challenges in terms of trial efficiency, setup complexity, and interoperability still persist. To address these issues, we introduce a novel paradigm leveraging Large Language Models (LLMs) to automate hyperparameter optimization across diverse machine learning tasks, which is named AgentHPO (short for LLM Agent-based Hyperparameter Optimization). Specifically, AgentHPO processes the task information autonomously, conducts experiments with specific hyperparameters (HPs), and iteratively optimizes them based on historical trials. This human-like optimization process largely reduces the number of required trials, simplifies the setup process, and enhances interpretability and user trust, compared to traditional AutoML methods. Extensive empirical experiments conducted on 12 representative machine-learning tasks indicate that AgentHPO not only matches but also often surpasses the best human trials in terms of performance while simultaneously providing explainable results. Further analysis sheds light on the strategies employed by the LLM in optimizing these tasks, highlighting its effectiveness and adaptability in various scenarios.</li>
</ul>

<h3>Title: S2malloc: Statistically Secure Allocator for Use-After-Free Protection  And More</h3>
<ul>
<li><strong>Authors: </strong>Ruizhe Wang, Meng Xu, N. Asokan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01894">https://arxiv.org/abs/2402.01894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01894">https://arxiv.org/pdf/2402.01894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01894]] S2malloc: Statistically Secure Allocator for Use-After-Free Protection  And More(https://arxiv.org/abs/2402.01894)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, defense, attack</a></li>
<li><strong>Abstract: </strong>Attacks on heap memory, encompassing memory overflow, double and invalid free, use-after-free (UAF), and various heap spraying techniques are ever-increasing. Existing entropy-based secure memory allocators provide statistical defenses against virtually all of these attack vectors. Although they claim protections against UAF attacks, their designs are not tailored to detect (failed) attempts. Consequently, to beat this entropy-based protection, an attacker can simply launch the same attack repeatedly with the potential use of heap spraying to further improve their chance of success. We introduce S2malloc, aiming to enhance UAF-attempt detection without compromising other security guarantees or introducing significant performance overhead. To achieve this, we use three innovative constructs in secure allocator design: free block canaries (FBC) to detect UAF attempts, random in-block offset (RIO) to stop the attacker from accurately overwriting the victim object, and random bag layout (RBL) to impede attackers from estimating the block size based on its address. We show that (a) by reserving 25% of the object size for the RIO offset, an 8-byte canary offers a 69% protection rate if the attacker reuses the same pointer and 96% protection rate if the attacker does not, against UAF exploitation attempts targeting a 64 bytes object, with equal or higher security guarantees against all other attacks; and (b) S2malloc is practical, with only a 2.8% run-time overhead on PARSEC and an 11.5% overhead on SPEC. Compared to state-of-the-art entropy-based allocators, S2malloc improves UAF-protection without incurring additional performance overhead. Compared to UAF-mitigating allocators, S2malloc trades off a minuscule probability of failed protection for significantly lower overhead.</li>
</ul>

<h3>Title: EBV: Electronic Bee-Veterinarian for Principled Mining and Forecasting  of Honeybee Time Series</h3>
<ul>
<li><strong>Authors: </strong>Mst. Shamima Hossain, Christos Faloutsos, Boris Baer, Hyoseung Kim, Vassilis J. Tsotras</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01902">https://arxiv.org/abs/2402.01902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01902">https://arxiv.org/pdf/2402.01902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01902]] EBV: Electronic Bee-Veterinarian for Principled Mining and Forecasting  of Honeybee Time Series(https://arxiv.org/abs/2402.01902)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Honeybees are vital for pollination and food production. Among many factors, extreme temperature (e.g., due to climate change) is particularly dangerous for bee health. Anticipating such extremities would allow beekeepers to take early preventive action. Thus, given sensor (temperature) time series data from beehives, how can we find patterns and do forecasting? Forecasting is crucial as it helps spot unexpected behavior and thus issue warnings to the beekeepers. In that case, what are the right models for forecasting? ARIMA, RNNs, or something else? We propose the EBV (Electronic Bee-Veterinarian) method, which has the following desirable properties: (i) principled: it is based on a) diffusion equations from physics and b) control theory for feedback-loop controllers; (ii) effective: it works well on multiple, real-world time sequences, (iii) explainable: it needs only a handful of parameters (e.g., bee strength) that beekeepers can easily understand and trust, and (iv) scalable: it performs linearly in time. We applied our method to multiple real-world time sequences, and found that it yields accurate forecasting (up to 49% improvement in RMSE compared to baselines), and segmentation. Specifically, discontinuities detected by EBV mostly coincide with domain expert's opinions, showcasing our approach's potential and practical feasibility. Moreover, EBV is scalable and fast, taking about 20 minutes on a stock laptop for reconstructing two months of sensor data.</li>
</ul>

<h3>Title: On Catastrophic Inheritance of Large Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Hao Chen, Bhiksha Raj, Xing Xie, Jindong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01909">https://arxiv.org/abs/2402.01909</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01909">https://arxiv.org/pdf/2402.01909</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01909]] On Catastrophic Inheritance of Large Foundation Models(https://arxiv.org/abs/2402.01909)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>Large foundation models (LFMs) are claiming incredible performances. Yet great concerns have been raised about their mythic and uninterpreted potentials not only in machine learning, but also in various other disciplines. In this position paper, we propose to identify a neglected issue deeply rooted in LFMs: Catastrophic Inheritance, describing the weaknesses and limitations inherited from biased large-scale pre-training data to behaviors of LFMs on the downstream tasks, including samples that are corrupted, long-tailed, noisy, out-of-distributed, to name a few. Such inheritance can potentially cause catastrophes to downstream applications, such as bias, lack of generalization, deteriorated performance, security vulnerability, privacy leakage, and value misalignment. We discuss the challenges behind this issue and propose UIM, a framework to Understand the catastrophic inheritance of LFMs from both pre-training and downstream adaptation, Interpret the implications of catastrophic inheritance on downstream tasks, and how to Mitigate it. UIM aims to unite both the machine learning and social sciences communities for more responsible and promising AI development and deployment.</li>
</ul>

<h3>Title: From PEFT to DEFT: Parameter Efficient Finetuning for Reducing  Activation Density in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Bharat Runwal, Tejaswini Pedapati, Pin-Yu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01911">https://arxiv.org/abs/2402.01911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01911">https://arxiv.org/pdf/2402.01911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01911]] From PEFT to DEFT: Parameter Efficient Finetuning for Reducing  Activation Density in Transformers(https://arxiv.org/abs/2402.01911)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Pretrained Language Models (PLMs) have become the de facto starting point for fine-tuning on downstream tasks. However, as model sizes continue to increase, traditional fine-tuning of all parameters becomes challenging. To address this, parameter-efficient fine-tuning (PEFT) methods have gained popularity as a means to adapt PLMs effectively. In parallel, recent studies have revealed the presence of activation sparsity within the intermediate outputs of the multilayer perception (MLP) blocks in transformers. Low activation density enables efficient model inference on sparsity-aware hardware. Building upon this insight, in this work, we propose a novel density loss that encourages higher activation sparsity (equivalently, lower activation density) in the pre-trained models. We demonstrate the effectiveness of our approach by utilizing mainstream PEFT techniques including QLoRA, LoRA, Adapter, Prompt/Prefix Tuning to facilitate efficient model adaptation across diverse downstream tasks. Experiments show that our proposed method DEFT, Density-Efficient Fine-Tuning, can reduce the activation density consistently and up to $\boldsymbol{50.72\%}$ on RoBERTa$_\mathrm{Large}$, and $\boldsymbol {53.19\%}$ (encoder density) and $\boldsymbol{90.60\%}$ (decoder density) on Flan-T5$_\mathrm{XXL}$ ($\boldsymbol{11B}$) compared to PEFT using GLUE and QA (SQuAD) benchmarks respectively while maintaining competitive performance on downstream tasks. We also showcase that DEFT works complementary with quantized and pruned models</li>
</ul>

<h3>Title: Robust Inverse Graphics via Probabilistic Inference</h3>
<ul>
<li><strong>Authors: </strong>Tuan Anh Le, Pavel Sountsov, Matthew D. Hoffman, Ben Lee, Brian Patton, Rif A. Saurous</a></li>
<li><strong>Subjects: </strong>cs.CV, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01915">https://arxiv.org/abs/2402.01915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01915">https://arxiv.org/pdf/2402.01915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01915]] Robust Inverse Graphics via Probabilistic Inference(https://arxiv.org/abs/2402.01915)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>How do we infer a 3D scene from a single image in the presence of corruptions like rain, snow or fog? Straightforward domain randomization relies on knowing the family of corruptions ahead of time. Here, we propose a Bayesian approach-dubbed robust inverse graphics (RIG)-that relies on a strong scene prior and an uninformative uniform corruption prior, making it applicable to a wide range of corruptions. Given a single image, RIG performs posterior inference jointly over the scene and the corruption. We demonstrate this idea by training a neural radiance field (NeRF) scene prior and using a secondary NeRF to represent the corruptions over which we place an uninformative prior. RIG, trained only on clean data, outperforms depth estimators and alternative NeRF approaches that perform point estimation instead of full inference. The results hold for a number of scene prior architectures based on normalizing flows and diffusion models. For the latter, we develop reconstruction-guidance with auxiliary latents (ReGAL)-a diffusion conditioning algorithm that is applicable in the presence of auxiliary latent variables such as the corruption. RIG demonstrates how scene priors can be used beyond generation tasks.</li>
</ul>

<h3>Title: Preference Poisoning Attacks on Reward Model Learning</h3>
<ul>
<li><strong>Authors: </strong>Junlin Wu, Jiongxiao Wang, Chaowei Xiao, Chenguang Wang, Ning Zhang, Yevgeniy Vorobeychik</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01920">https://arxiv.org/abs/2402.01920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01920">https://arxiv.org/pdf/2402.01920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01920]] Preference Poisoning Attacks on Reward Model Learning(https://arxiv.org/abs/2402.01920)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Learning utility, or reward, models from pairwise comparisons is a fundamental component in a number of application domains. These approaches inherently entail collecting preference information from people, with feedback often provided anonymously. Since preferences are subjective, there is no gold standard to compare against; yet, reliance of high-impact systems on preference learning creates a strong motivation for malicious actors to skew data collected in this fashion to their ends. We investigate the nature and extent of this vulnerability systematically by considering a threat model in which an attacker can flip a small subset of preference comparisons with the goal of either promoting or demoting a target outcome. First, we propose two classes of algorithmic approaches for these attacks: a principled gradient-based framework, and several variants of rank-by-distance methods. Next, we demonstrate the efficacy of best attacks in both these classes in successfully achieving malicious goals on datasets from three diverse domains: autonomous control, recommendation system, and textual prompt-response preference learning. We find that the best attacks are often highly successful, achieving in the most extreme case 100% success rate with only 0.3% of the data poisoned. However, which attack is best can vary significantly across domains, demonstrating the value of our comprehensive vulnerability analysis that involves several classes of attack algorithms. In addition, we observe that the simpler and more scalable rank-by-distance approaches are often competitive with the best, and on occasion significantly outperform gradient-based methods. Finally, we show that several state-of-the-art defenses against other classes of poisoning attacks exhibit, at best, limited efficacy in our setting.</li>
</ul>

<h3>Title: Robust Counterfactual Explanations in Machine Learning: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Junqi Jiang, Francesco Leofante, Antonio Rago, Francesca Toni</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01928">https://arxiv.org/abs/2402.01928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01928">https://arxiv.org/pdf/2402.01928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01928]] Robust Counterfactual Explanations in Machine Learning: A Survey(https://arxiv.org/abs/2402.01928)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Counterfactual explanations (CEs) are advocated as being ideally suited to providing algorithmic recourse for subjects affected by the predictions of machine learning models. While CEs can be beneficial to affected individuals, recent work has exposed severe issues related to the robustness of state-of-the-art methods for obtaining CEs. Since a lack of robustness may compromise the validity of CEs, techniques to mitigate this risk are in order. In this survey, we review works in the rapidly growing area of robust CEs and perform an in-depth analysis of the forms of robustness they consider. We also discuss existing solutions and their limitations, providing a solid foundation for future developments.</li>
</ul>

<h3>Title: Digits micro-model for accurate and secure transactions</h3>
<ul>
<li><strong>Authors: </strong>Chirag Chhablani, Nikhita Sharma, Jordan Hosier, Vijay K. Gurbani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01931">https://arxiv.org/abs/2402.01931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01931">https://arxiv.org/pdf/2402.01931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01931]] Digits micro-model for accurate and secure transactions(https://arxiv.org/abs/2402.01931)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Automatic Speech Recognition (ASR) systems are used in the financial domain to enhance the caller experience by enabling natural language understanding and facilitating efficient and intuitive interactions. Increasing use of ASR systems requires that such systems exhibit very low error rates. The predominant ASR models to collect numeric data are large, general-purpose commercial models -- Google Speech-to-text (STT), or Amazon Transcribe -- or open source (OpenAI's Whisper). Such ASR models are trained on hundreds of thousands of hours of audio data and require considerable resources to run. Despite recent progress large speech recognition models, we highlight the potential of smaller, specialized "micro" models. Such light models can be trained perform well on number recognition specific tasks, competing with general models like Whisper or Google STT while using less than 80 minutes of training time and occupying at least an order of less memory resources. Also, unlike larger speech recognition models, micro-models are trained on carefully selected and curated datasets, which makes them highly accurate, agile, and easy to retrain, while using low compute resources. We present our work on creating micro models for multi-digit number recognition that handle diverse speaking styles reflecting real-world pronunciation patterns. Our work contributes to domain-specific ASR models, improving digit recognition accuracy, and privacy of data. An added advantage, their low resource consumption allows them to be hosted on-premise, keeping private data local instead uploading to an external cloud. Our results indicate that our micro-model makes less errors than the best-of-breed commercial or open-source ASRs in recognizing digits (1.8% error rate of our best micro-model versus 5.8% error rate of Whisper), and has a low memory footprint (0.66 GB VRAM for our model versus 11 GB VRAM for Whisper).</li>
</ul>

<h3>Title: Precedence-Constrained Winter Value for Effective Graph Data Valuation</h3>
<ul>
<li><strong>Authors: </strong>Hongliang Chi, Jin Wei, Charu Aggarwal, Yao Ma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01943">https://arxiv.org/abs/2402.01943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01943">https://arxiv.org/pdf/2402.01943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01943]] Precedence-Constrained Winter Value for Effective Graph Data Valuation(https://arxiv.org/abs/2402.01943)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Data valuation is essential for quantifying data's worth, aiding in assessing data quality and determining fair compensation. While existing data valuation methods have proven effective in evaluating the value of Euclidean data, they face limitations when applied to the increasingly popular graph-structured data. Particularly, graph data valuation introduces unique challenges, primarily stemming from the intricate dependencies among nodes and the exponential growth in value estimation costs. To address the challenging problem of graph data valuation, we put forth an innovative solution, Precedence-Constrained Winter (PC-Winter) Value, to account for the complex graph structure. Furthermore, we develop a variety of strategies to address the computational challenges and enable efficient approximation of PC-Winter. Extensive experiments demonstrate the effectiveness of PC-Winter across diverse datasets and tasks.</li>
</ul>

<h3>Title: Guarantees in Software Security</h3>
<ul>
<li><strong>Authors: </strong>Marcel Bhme</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01944">https://arxiv.org/abs/2402.01944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01944">https://arxiv.org/pdf/2402.01944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01944]] Guarantees in Software Security(https://arxiv.org/abs/2402.01944)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>We review general approaches to reason about the security of a software system and reflect upon the guarantees they provide. We introduce a taxonomy of fundamental challenges towards the provision of guarantees, and discuss how these challenges are routinely exploited to attack a system in spite of credible assurances about the absence of such bugs. It is only when we identify, study, and acknowledge the flaws in our current reasoning systems today that we can develop effective mitigation strategies in the future. To this end, we finally propose a research programme whose goal it is to tackle the software security challenges of this decade.</li>
</ul>

<h3>Title: OPSurv: Orthogonal Polynomials Quadrature Algorithm for Survival  Analysis</h3>
<ul>
<li><strong>Authors: </strong>Lilian W. Bialokozowicz, Hoang M. Le, Tristan Sylvain, Peter A. I. Forsyth, Vineel Nagisetty, Greg Mori</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.FA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01955">https://arxiv.org/abs/2402.01955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01955">https://arxiv.org/pdf/2402.01955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01955]] OPSurv: Orthogonal Polynomials Quadrature Algorithm for Survival  Analysis(https://arxiv.org/abs/2402.01955)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces the Orthogonal Polynomials Quadrature Algorithm for Survival Analysis (OPSurv), a new method providing time-continuous functional outputs for both single and competing risks scenarios in survival analysis. OPSurv utilizes the initial zero condition of the Cumulative Incidence function and a unique decomposition of probability densities using orthogonal polynomials, allowing it to learn functional approximation coefficients for each risk event and construct Cumulative Incidence Function estimates via Gauss--Legendre quadrature. This approach effectively counters overfitting, particularly in competing risks scenarios, enhancing model expressiveness and control. The paper further details empirical validations and theoretical justifications of OPSurv, highlighting its robust performance as an advancement in survival analysis with competing risks.</li>
</ul>

<h3>Title: Analyzing Neural Network-Based Generative Diffusion Models through  Convex Optimization</h3>
<ul>
<li><strong>Authors: </strong>Fangzhao Zhang, Mert Pilanci</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01965">https://arxiv.org/abs/2402.01965</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01965">https://arxiv.org/pdf/2402.01965</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01965]] Analyzing Neural Network-Based Generative Diffusion Models through  Convex Optimization(https://arxiv.org/abs/2402.01965)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models are becoming widely used in state-of-the-art image, video and audio generation. Score-based diffusion models stand out among these methods, necessitating the estimation of score function of the input data distribution. In this study, we present a theoretical framework to analyze two-layer neural network-based diffusion models by reframing score matching and denoising score matching as convex optimization. Though existing diffusion theory is mainly asymptotic, we characterize the exact predicted score function and establish the convergence result for neural network-based diffusion models with finite data. This work contributes to understanding what neural network-based diffusion model learns in non-asymptotic settings.</li>
</ul>

<h3>Title: MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate  Speech and Target Detection Using Transformer Ensembles</h3>
<ul>
<li><strong>Authors: </strong>Amrita Ganguly, Al Nahian Bin Emran, Sadiya Sayara Chowdhury Puspo, Md Nishat Raihan, Dhiman Goswami, Marcos Zampieri</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01967">https://arxiv.org/abs/2402.01967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01967">https://arxiv.org/pdf/2402.01967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01967]] MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate  Speech and Target Detection Using Transformer Ensembles(https://arxiv.org/abs/2402.01967)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The automatic identification of offensive language such as hate speech is important to keep discussions civil in online communities. Identifying hate speech in multimodal content is a particularly challenging task because offensiveness can be manifested in either words or images or a juxtaposition of the two. This paper presents the MasonPerplexity submission for the Shared Task on Multimodal Hate Speech Event Detection at CASE 2024 at EACL 2024. The task is divided into two sub-tasks: sub-task A focuses on the identification of hate speech and sub-task B focuses on the identification of targets in text-embedded images during political events. We use an XLM-roBERTa-large model for sub-task A and an ensemble approach combining XLM-roBERTa-base, BERTweet-large, and BERT-base for sub-task B. Our approach obtained 0.8347 F1-score in sub-task A and 0.6741 F1-score in sub-task B ranking 3rd on both sub-tasks.</li>
</ul>

<h3>Title: Simulation-Enhanced Data Augmentation for Machine Learning Pathloss  Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ahmed P. Mohamed, Byunghyun Lee, Yaguang Zhang, Max Hollingsworth, C. Robert Anderson, James V. Krogmeier, David J. Love</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01969">https://arxiv.org/abs/2402.01969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01969">https://arxiv.org/pdf/2402.01969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01969]] Simulation-Enhanced Data Augmentation for Machine Learning Pathloss  Prediction(https://arxiv.org/abs/2402.01969)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) offers a promising solution to pathloss prediction. However, its effectiveness can be degraded by the limited availability of data. To alleviate these challenges, this paper introduces a novel simulation-enhanced data augmentation method for ML pathloss prediction. Our method integrates synthetic data generated from a cellular coverage simulator and independently collected real-world datasets. These datasets were collected through an extensive measurement campaign in different environments, including farms, hilly terrains, and residential areas. This comprehensive data collection provides vital ground truth for model training. A set of channel features was engineered, including geographical attributes derived from LiDAR datasets. These features were then used to train our prediction model, incorporating the highly efficient and robust gradient boosting ML algorithm, CatBoost. The integration of synthetic data, as demonstrated in our study, significantly improves the generalizability of the model in different environments, achieving a remarkable improvement of approximately 12dB in terms of mean absolute error for the best-case scenario. Moreover, our analysis reveals that even a small fraction of measurements added to the simulation training set, with proper data balance, can significantly enhance the model's performance.</li>
</ul>

<h3>Title: Hypergraph-Transformer (HGT) for Interactive Event Prediction in  Laparoscopic and Robotic Surgery</h3>
<ul>
<li><strong>Authors: </strong>Lianhao Yin, Yutong Ban, Jennifer Eckhoff, Ozanan Meireles, Daniela Rus, Guy Rosman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01974">https://arxiv.org/abs/2402.01974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01974">https://arxiv.org/pdf/2402.01974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01974]] Hypergraph-Transformer (HGT) for Interactive Event Prediction in  Laparoscopic and Robotic Surgery(https://arxiv.org/abs/2402.01974)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding and anticipating intraoperative events and actions is critical for intraoperative assistance and decision-making during minimally invasive surgery. Automated prediction of events, actions, and the following consequences is addressed through various computational approaches with the objective of augmenting surgeons' perception and decision-making capabilities. We propose a predictive neural network that is capable of understanding and predicting critical interactive aspects of surgical workflow from intra-abdominal video, while flexibly leveraging surgical knowledge graphs. The approach incorporates a hypergraph-transformer (HGT) structure that encodes expert knowledge into the network design and predicts the hidden embedding of the graph. We verify our approach on established surgical datasets and applications, including the detection and prediction of action triplets, and the achievement of the Critical View of Safety (CVS). Moreover, we address specific, safety-related tasks, such as predicting the clipping of cystic duct or artery without prior achievement of the CVS. Our results demonstrate the superiority of our approach compared to unstructured alternatives.</li>
</ul>

<h3>Title: SOCIALITE-LLAMA: An Instruction-Tuned Model for Social Scientific Tasks</h3>
<ul>
<li><strong>Authors: </strong>Gourab Dey, Adithya V Ganesan, Yash Kumar Lal, Manal Shah, Shreyashee Sinha, Matthew Matero, Salvatore Giorgi, Vivek Kulkarni, H. Andrew Schwartz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01980">https://arxiv.org/abs/2402.01980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01980">https://arxiv.org/pdf/2402.01980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01980]] SOCIALITE-LLAMA: An Instruction-Tuned Model for Social Scientific Tasks(https://arxiv.org/abs/2402.01980)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Social science NLP tasks, such as emotion or humor detection, are required to capture the semantics along with the implicit pragmatics from text, often with limited amounts of training data. Instruction tuning has been shown to improve the many capabilities of large language models (LLMs) such as commonsense reasoning, reading comprehension, and computer programming. However, little is known about the effectiveness of instruction tuning on the social domain where implicit pragmatic cues are often needed to be captured. We explore the use of instruction tuning for social science NLP tasks and introduce Socialite-Llama -- an open-source, instruction-tuned Llama. On a suite of 20 social science tasks, Socialite-Llama improves upon the performance of Llama as well as matches or improves upon the performance of a state-of-the-art, multi-task finetuned model on a majority of them. Further, Socialite-Llama also leads to improvement on 5 out of 6 related social tasks as compared to Llama, suggesting instruction tuning can lead to generalized social understanding. All resources including our code, model and dataset can be found through bit.ly/socialitellama.</li>
</ul>

<h3>Title: Self-Debiasing Large Language Models: Zero-Shot Recognition and  Reduction of Stereotypes</h3>
<ul>
<li><strong>Authors: </strong>Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow, Md Mehrab Tanjim, Tong Yu, Hanieh Deilamsalehy, Ruiyi Zhang, Sungchul Kim, Franck Dernoncourt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.01981">https://arxiv.org/abs/2402.01981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.01981">https://arxiv.org/pdf/2402.01981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.01981]] Self-Debiasing Large Language Models: Zero-Shot Recognition and  Reduction of Stereotypes(https://arxiv.org/abs/2402.01981)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable advances in language generation and understanding but are also prone to exhibiting harmful social biases. While recognition of these behaviors has generated an abundance of bias mitigation techniques, most require modifications to the training data, model parameters, or decoding strategy, which may be infeasible without access to a trainable model. In this work, we leverage the zero-shot capabilities of LLMs to reduce stereotyping in a technique we introduce as zero-shot self-debiasing. With two approaches, self-debiasing via explanation and self-debiasing via reprompting, we show that self-debiasing can significantly reduce the degree of stereotyping across nine different social groups while relying only on the LLM itself and a simple prompt, with explanations correctly identifying invalid assumptions and reprompting delivering the greatest reductions in bias. We hope this work opens inquiry into other zero-shot techniques for bias mitigation.</li>
</ul>

<h3>Title: GenFace: A Large-Scale Fine-Grained Face Forgery Benchmark and Cross  Appearance-Edge Learning</h3>
<ul>
<li><strong>Authors: </strong>Yaning Zhang, Zitong Yu, Xiaobin Huang, Linlin Shen, Jianfeng Ren</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02003">https://arxiv.org/abs/2402.02003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02003">https://arxiv.org/pdf/2402.02003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02003]] GenFace: A Large-Scale Fine-Grained Face Forgery Benchmark and Cross  Appearance-Edge Learning(https://arxiv.org/abs/2402.02003)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rapid advancement of photorealistic generators has reached a critical juncture where the discrepancy between authentic and manipulated images is increasingly indistinguishable. Thus, benchmarking and advancing techniques detecting digital manipulation become an urgent issue. Although there have been a number of publicly available face forgery datasets, the forgery faces are mostly generated using GAN-based synthesis technology, which does not involve the most recent technologies like diffusion. The diversity and quality of images generated by diffusion models have been significantly improved and thus a much more challenging face forgery dataset shall be used to evaluate SOTA forgery detection literature. In this paper, we propose a large-scale, diverse, and fine-grained high-fidelity dataset, namely GenFace, to facilitate the advancement of deepfake detection, which contains a large number of forgery faces generated by advanced generators such as the diffusion-based model and more detailed labels about the manipulation approaches and adopted generators. In addition to evaluating SOTA approaches on our benchmark, we design an innovative cross appearance-edge learning (CAEL) detector to capture multi-grained appearance and edge global representations, and detect discriminative and general forgery traces. Moreover, we devise an appearance-edge cross-attention (AECA) module to explore the various integrations across two domains. Extensive experiment results and visualizations show that our detection model outperforms the state of the arts on different settings like cross-generator, cross-forgery, and cross-dataset evaluations. Code and datasets will be available at \url{https://github.com/Jenine-321/GenFace</li>
</ul>

<h3>Title: Topology-Informed Graph Transformer</h3>
<ul>
<li><strong>Authors: </strong>Yun Young Choi, Sun Woo Park, Minho Lee, Youngho Woo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02005">https://arxiv.org/abs/2402.02005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02005">https://arxiv.org/pdf/2402.02005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02005]] Topology-Informed Graph Transformer(https://arxiv.org/abs/2402.02005)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have revolutionized performance in Natural Language Processing and Vision, paving the way for their integration with Graph Neural Networks (GNNs). One key challenge in enhancing graph transformers is strengthening the discriminative power of distinguishing isomorphisms of graphs, which plays a crucial role in boosting their predictive performances. To address this challenge, we introduce 'Topology-Informed Graph Transformer (TIGT)', a novel transformer enhancing both discriminative power in detecting graph isomorphisms and the overall performance of Graph Transformers. TIGT consists of four components: A topological positional embedding layer using non-isomorphic universal covers based on cyclic subgraphs of graphs to ensure unique graph representation: A dual-path message-passing layer to explicitly encode topological characteristics throughout the encoder layers: A global attention mechanism: And a graph information layer to recalibrate channel-wise graph features for better feature representation. TIGT outperforms previous Graph Transformers in classifying synthetic dataset aimed at distinguishing isomorphism classes of graphs. Additionally, mathematical analysis and empirical evaluations highlight our model's competitive edge over state-of-the-art Graph Transformers across various benchmark datasets.</li>
</ul>

<h3>Title: PresAIse, An Enterprises Prescriptive AI Solution</h3>
<ul>
<li><strong>Authors: </strong>Wei Sun, Scott McFaddin, Linh Ha Tran, Shivaram Subramanian, Kristjan Greenewald, Yeshi Tenzin, Zack Xue, Youssef Drissi, Markus Ettl</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02006">https://arxiv.org/abs/2402.02006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02006">https://arxiv.org/pdf/2402.02006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02006]] PresAIse, An Enterprises Prescriptive AI Solution(https://arxiv.org/abs/2402.02006)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Prescriptive AI represents a transformative shift in decision-making, offering causal insights and actionable recommendations. Despite its huge potential, enterprise adoption often faces several challenges. The first challenge is caused by the limitations of observational data for accurate causal inference which is typically a prerequisite for good decision-making. The second pertains to the interpretability of recommendations, which is crucial for enterprise decision-making settings. The third challenge is the silos between data scientists and business users, hindering effective collaboration. This paper outlines an initiative from IBM Research, aiming to address some of these challenges by offering a suite of prescriptive AI solutions. Leveraging insights from various research papers, the solution suite includes scalable causal inference methods, interpretable decision-making approaches, and the integration of large language models (LLMs) to bridge communication gaps via a conversation agent. A proof-of-concept, PresAIse, demonstrates the solutions' potential by enabling non-ML experts to interact with prescriptive AI models via a natural language interface, democratizing advanced analytics for strategic decision-making.</li>
</ul>

<h3>Title: Understanding Time Series Anomaly State Detection through One-Class  Classification</h3>
<ul>
<li><strong>Authors: </strong>Hanxu Zhou, Yuan Zhang, Guangjie Leng, Ruofan Wang, Zhi-Qin John Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02007">https://arxiv.org/abs/2402.02007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02007">https://arxiv.org/pdf/2402.02007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02007]] Understanding Time Series Anomaly State Detection through One-Class  Classification(https://arxiv.org/abs/2402.02007)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>For a long time, research on time series anomaly detection has mainly focused on finding outliers within a given time series. Admittedly, this is consistent with some practical problems, but in other practical application scenarios, people are concerned about: assuming a standard time series is given, how to judge whether another test time series deviates from the standard time series, which is more similar to the problem discussed in one-class classification (OCC). Therefore, in this article, we try to re-understand and define the time series anomaly detection problem through OCC, which we call 'time series anomaly state detection problem'. We first use stochastic processes and hypothesis testing to strictly define the 'time series anomaly state detection problem', and its corresponding anomalies. Then, we use the time series classification dataset to construct an artificial dataset corresponding to the problem. We compile 38 anomaly detection algorithms and correct some of the algorithms to adapt to handle this problem. Finally, through a large number of experiments, we fairly compare the actual performance of various time series anomaly detection algorithms, providing insights and directions for future research by researchers.</li>
</ul>

<h3>Title: How well do LLMs cite relevant medical references? An evaluation  framework and analyses</h3>
<ul>
<li><strong>Authors: </strong>Kevin Wu, Eric Wu, Ally Cassasola, Angela Zhang, Kevin Wei, Teresa Nguyen, Sith Riantawan, Patricia Shi Riantawan, Daniel E. Ho, James Zou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02008">https://arxiv.org/abs/2402.02008</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02008">https://arxiv.org/pdf/2402.02008</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02008]] How well do LLMs cite relevant medical references? An evaluation  framework and analyses(https://arxiv.org/abs/2402.02008)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are currently being used to answer medical questions across a variety of clinical domains. Recent top-performing commercial LLMs, in particular, are also capable of citing sources to support their responses. In this paper, we ask: do the sources that LLMs generate actually support the claims that they make? To answer this, we propose three contributions. First, as expert medical annotations are an expensive and time-consuming bottleneck for scalable evaluation, we demonstrate that GPT-4 is highly accurate in validating source relevance, agreeing 88% of the time with a panel of medical doctors. Second, we develop an end-to-end, automated pipeline called \textit{SourceCheckup} and use it to evaluate five top-performing LLMs on a dataset of 1200 generated questions, totaling over 40K pairs of statements and sources. Interestingly, we find that between ~50% to 90% of LLM responses are not fully supported by the sources they provide. We also evaluate GPT-4 with retrieval augmented generation (RAG) and find that, even still, around 30\% of individual statements are unsupported, while nearly half of its responses are not fully supported. Third, we open-source our curated dataset of medical questions and expert annotations for future evaluations. Given the rapid pace of LLM development and the potential harms of incorrect or outdated medical information, it is crucial to also understand and quantify their capability to produce relevant, trustworthy medical references.</li>
</ul>

<h3>Title: Robust Multi-Task Learning with Excess Risks</h3>
<ul>
<li><strong>Authors: </strong>Yifei He, Shiji Zhou, Guojun Zhang, Hyokun Yun, Yi Xu, Belinda Zeng, Trishul Chilimbi, Han Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02009">https://arxiv.org/abs/2402.02009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02009">https://arxiv.org/pdf/2402.02009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02009]] Robust Multi-Task Learning with Excess Risks(https://arxiv.org/abs/2402.02009)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-task learning (MTL) considers learning a joint model for multiple tasks by optimizing a convex combination of all task losses. To solve the optimization problem, existing methods use an adaptive weight updating scheme, where task weights are dynamically adjusted based on their respective losses to prioritize difficult tasks. However, these algorithms face a great challenge whenever label noise is present, in which case excessive weights tend to be assigned to noisy tasks that have relatively large Bayes optimal errors, thereby overshadowing other tasks and causing performance to drop across the board. To overcome this limitation, we propose Multi-Task Learning with Excess Risks (ExcessMTL), an excess risk-based task balancing method that updates the task weights by their distances to convergence instead. Intuitively, ExcessMTL assigns higher weights to worse-trained tasks that are further from convergence. To estimate the excess risks, we develop an efficient and accurate method with Taylor approximation. Theoretically, we show that our proposed algorithm achieves convergence guarantees and Pareto stationarity. Empirically, we evaluate our algorithm on various MTL benchmarks and demonstrate its superior performance over existing methods in the presence of label noise.</li>
</ul>

<h3>Title: GenFormer: A Deep-Learning-Based Approach for Generating Multivariate  Stochastic Processes</h3>
<ul>
<li><strong>Authors: </strong>Haoran Zhao, Wayne Isaac Tan Uy</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02010">https://arxiv.org/abs/2402.02010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02010">https://arxiv.org/pdf/2402.02010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02010]] GenFormer: A Deep-Learning-Based Approach for Generating Multivariate  Stochastic Processes(https://arxiv.org/abs/2402.02010)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Stochastic generators are essential to produce synthetic realizations that preserve target statistical properties. We propose GenFormer, a stochastic generator for spatio-temporal multivariate stochastic processes. It is constructed using a Transformer-based deep learning model that learns a mapping between a Markov state sequence and time series values. The synthetic data generated by the GenFormer model preserves the target marginal distributions and approximately captures other desired statistical properties even in challenging applications involving a large number of spatial locations and a long simulation horizon. The GenFormer model is applied to simulate synthetic wind speed data at various stations in Florida to calculate exceedance probabilities for risk management.</li>
</ul>

<h3>Title: Precise Knowledge Transfer via Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Shitong Shao, Zhiqiang Shen, Linrui Gong, Huanran Chen, Xu Dai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02012">https://arxiv.org/abs/2402.02012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02012">https://arxiv.org/pdf/2402.02012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02012]] Precise Knowledge Transfer via Flow Matching(https://arxiv.org/abs/2402.02012)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a novel knowledge transfer framework that introduces continuous normalizing flows for progressive knowledge transformation and leverages multi-step sampling strategies to achieve precision knowledge transfer. We name this framework Knowledge Transfer with Flow Matching (FM-KT), which can be integrated with a metric-based distillation method with any form (\textit{e.g.} vanilla KD, DKD, PKD and DIST) and a meta-encoder with any available architecture (\textit{e.g.} CNN, MLP and Transformer). By introducing stochastic interpolants, FM-KD is readily amenable to arbitrary noise schedules (\textit{e.g.}, VP-ODE, VE-ODE, Rectified flow) for normalized flow path estimation. We theoretically demonstrate that the training objective of FM-KT is equivalent to minimizing the upper bound of the teacher feature map or logit negative log-likelihood. Besides, FM-KT can be viewed as a unique implicit ensemble method that leads to performance gains. By slightly modifying the FM-KT framework, FM-KT can also be transformed into an online distillation framework OFM-KT with desirable performance gains. Through extensive experiments on CIFAR-100, ImageNet-1k, and MS-COCO datasets, we empirically validate the scalability and state-of-the-art performance of our proposed methods among relevant comparison approaches.</li>
</ul>

<h3>Title: Position Paper: The Landscape and Challenges of HPC Research and LLMs</h3>
<ul>
<li><strong>Authors: </strong>Le Chen, Nesreen K. Ahmed, Akash Dutta, Arijit Bhattacharjee, Sixing Yu, Quazi Ishtiaque Mahmud, Waqwoya Abebe, Hung Phan, Aishwarya Sarkar, Branden Butler, Niranjan Hasabnis, Gal Oren, Vy A. Vo, Juan Pablo Munoz, Theodore L. Willke, Tim Mattson, Ali Jannesari</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02018">https://arxiv.org/abs/2402.02018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02018">https://arxiv.org/pdf/2402.02018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02018]] Position Paper: The Landscape and Challenges of HPC Research and LLMs(https://arxiv.org/abs/2402.02018)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, language models (LMs), especially large language models (LLMs), have revolutionized the field of deep learning. Both encoder-decoder models and prompt-based techniques have shown immense potential for natural language processing and code-based tasks. Over the past several years, many research labs and institutions have invested heavily in high-performance computing, approaching or breaching exascale performance levels. In this paper, we posit that adapting and utilizing such language model-based techniques for tasks in high-performance computing (HPC) would be very beneficial. This study presents our reasoning behind the aforementioned position and highlights how existing ideas can be improved and adapted for HPC tasks.</li>
</ul>

<h3>Title: NeuV-SLAM: Fast Neural Multiresolution Voxel Optimization for RGBD Dense  SLAM</h3>
<ul>
<li><strong>Authors: </strong>Wenzhi Guo, Bing Wang, Lijun Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02020">https://arxiv.org/abs/2402.02020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02020">https://arxiv.org/pdf/2402.02020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02020]] NeuV-SLAM: Fast Neural Multiresolution Voxel Optimization for RGBD Dense  SLAM(https://arxiv.org/abs/2402.02020)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce NeuV-SLAM, a novel dense simultaneous localization and mapping pipeline based on neural multiresolution voxels, characterized by ultra-fast convergence and incremental expansion capabilities. This pipeline utilizes RGBD images as input to construct multiresolution neural voxels, achieving rapid convergence while maintaining robust incremental scene reconstruction and camera tracking. Central to our methodology is to propose a novel implicit representation, termed VDF that combines the implementation of neural signed distance field (SDF) voxels with an SDF activation strategy. This approach entails the direct optimization of color features and SDF values anchored within the voxels, substantially enhancing the rate of scene convergence. To ensure the acquisition of clear edge delineation, SDF activation is designed, which maintains exemplary scene representation fidelity even under constraints of voxel resolution. Furthermore, in pursuit of advancing rapid incremental expansion with low computational overhead, we developed hashMV, a novel hash-based multiresolution voxel management structure. This architecture is complemented by a strategically designed voxel generation technique that synergizes with a two-dimensional scene prior. Our empirical evaluations, conducted on the Replica and ScanNet Datasets, substantiate NeuV-SLAM's exceptional efficacy in terms of convergence speed, tracking accuracy, scene reconstruction, and rendering quality.</li>
</ul>

<h3>Title: Unlearnable Examples For Time Series</h3>
<ul>
<li><strong>Authors: </strong>Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02028">https://arxiv.org/abs/2402.02028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02028">https://arxiv.org/pdf/2402.02028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02028]] Unlearnable Examples For Time Series(https://arxiv.org/abs/2402.02028)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect</a></li>
<li><strong>Abstract: </strong>Unlearnable examples (UEs) refer to training samples modified to be unlearnable to Deep Neural Networks (DNNs). These examples are usually generated by adding error-minimizing noises that can fool a DNN model into believing that there is nothing (no error) to learn from the data. The concept of UE has been proposed as a countermeasure against unauthorized data exploitation on personal data. While UE has been extensively studied on images, it is unclear how to craft effective UEs for time series data. In this work, we introduce the first UE generation method to protect time series data from unauthorized training by deep learning models. To this end, we propose a new form of error-minimizing noise that can be \emph{selectively} applied to specific segments of time series, rendering them unlearnable to DNN models while remaining imperceptible to human observers. Through extensive experiments on a wide range of time series datasets, we demonstrate that the proposed UE generation method is effective in both classification and generation tasks. It can protect time series data against unauthorized exploitation, while preserving their utility for legitimate usage, thereby contributing to the development of secure and trustworthy machine learning systems.</li>
</ul>

<h3>Title: ScribFormer: Transformer Makes CNN Work Better for Scribble-based  Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zihan Li, Yuan Zheng, Dandan Shan, Shuzhou Yang, Qingde Li, Beizhan Wang, Yuanting Zhang, Qingqi Hong, Dinggang Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02029">https://arxiv.org/abs/2402.02029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02029">https://arxiv.org/pdf/2402.02029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02029]] ScribFormer: Transformer Makes CNN Work Better for Scribble-based  Medical Image Segmentation(https://arxiv.org/abs/2402.02029)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Most recent scribble-supervised segmentation methods commonly adopt a CNN framework with an encoder-decoder architecture. Despite its multiple benefits, this framework generally can only capture small-range feature dependency for the convolutional layer with the local receptive field, which makes it difficult to learn global shape information from the limited information provided by scribble annotations. To address this issue, this paper proposes a new CNN-Transformer hybrid solution for scribble-supervised medical image segmentation called ScribFormer. The proposed ScribFormer model has a triple-branch structure, i.e., the hybrid of a CNN branch, a Transformer branch, and an attention-guided class activation map (ACAM) branch. Specifically, the CNN branch collaborates with the Transformer branch to fuse the local features learned from CNN with the global representations obtained from Transformer, which can effectively overcome limitations of existing scribble-supervised segmentation methods. Furthermore, the ACAM branch assists in unifying the shallow convolution features and the deep convolution features to improve model's performance further. Extensive experiments on two public datasets and one private dataset show that our ScribFormer has superior performance over the state-of-the-art scribble-supervised segmentation methods, and achieves even better results than the fully-supervised segmentation methods. The code is released at https://github.com/HUANGLIZI/ScribFormer.</li>
</ul>

<h3>Title: Panacea: Pareto Alignment via Preference Adaptation for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yifan Zhong, Chengdong Ma, Xiaoyuan Zhang, Ziran Yang, Qingfu Zhang, Siyuan Qi, Yaodong Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02030">https://arxiv.org/abs/2402.02030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02030">https://arxiv.org/pdf/2402.02030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02030]] Panacea: Pareto Alignment via Preference Adaptation for LLMs(https://arxiv.org/abs/2402.02030)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current methods for large language model alignment typically use scalar human preference labels. However, this convention tends to oversimplify the multi-dimensional and heterogeneous nature of human preferences, leading to reduced expressivity and even misalignment. This paper presents Panacea, an innovative approach that reframes alignment as a multi-dimensional preference optimization problem. Panacea trains a single model capable of adapting online and Pareto-optimally to diverse sets of preferences without the need for further tuning. A major challenge here is using a low-dimensional preference vector to guide the model's behavior, despite it being governed by an overwhelmingly large number of parameters. To address this, Panacea is designed to use singular value decomposition (SVD)-based low-rank adaptation, which allows the preference vector to be simply injected online as singular values. Theoretically, we prove that Panacea recovers the entire Pareto front with common loss aggregation methods under mild conditions. Moreover, our experiments demonstrate, for the first time, the feasibility of aligning a single LLM to represent a spectrum of human preferences through various optimization methods. Our work marks a step forward in effectively and efficiently aligning models to diverse and intricate human preferences in a controllable and Pareto-optimal manner.</li>
</ul>

<h3>Title: Multi-fidelity physics constrained neural networks for dynamical systems</h3>
<ul>
<li><strong>Authors: </strong>Hao Zhou, Sibo Cheng, Rossella Arcucci</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02031">https://arxiv.org/abs/2402.02031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02031">https://arxiv.org/pdf/2402.02031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02031]] Multi-fidelity physics constrained neural networks for dynamical systems(https://arxiv.org/abs/2402.02031)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Physics-constrained neural networks are commonly employed to enhance prediction robustness compared to purely data-driven models, achieved through the inclusion of physical constraint losses during the model training process. However, one of the major challenges of physics-constrained neural networks consists of the training complexity especially for high-dimensional systems. In fact, conventional physics-constrained models rely on singular-fidelity data necessitating the assessment of physical constraints within high-dimensional fields, which introduces computational difficulties. Furthermore, due to the fixed input size of the neural networks, employing multi-fidelity training data can also be cumbersome. In this paper, we propose the Multi-Scale Physics-Constrained Neural Network (MSPCNN), which offers a novel methodology for incorporating data with different levels of fidelity into a unified latent space through a customised multi-fidelity autoencoder. Additionally, multiple decoders are concurrently trained to map latent representations of inputs into various fidelity physical spaces. As a result, during the training of predictive models, physical constraints can be evaluated within low-fidelity spaces, yielding a trade-off between training efficiency and accuracy. In addition, unlike conventional methods, MSPCNN also manages to employ multi-fidelity data to train the predictive model. We assess the performance of MSPCNN in two fluid dynamics problems, namely a two-dimensional Burgers' system and a shallow water system. Numerical results clearly demonstrate the enhancement of prediction accuracy and noise robustness when introducing physical constraints in low-fidelity fields. On the other hand, as expected, the training complexity can be significantly reduced by computing physical constraint loss in the low-fidelity field rather than the high-fidelity one.</li>
</ul>

<h3>Title: RobustTSF: Towards Theory and Design of Robust Time Series Forecasting  with Anomalies</h3>
<ul>
<li><strong>Authors: </strong>Hao Cheng, Qingsong Wen, Yang Liu, Liang Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02032">https://arxiv.org/abs/2402.02032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02032">https://arxiv.org/pdf/2402.02032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02032]] RobustTSF: Towards Theory and Design of Robust Time Series Forecasting  with Anomalies(https://arxiv.org/abs/2402.02032)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time series forecasting is an important and forefront task in many real-world applications. However, most of time series forecasting techniques assume that the training data is clean without anomalies. This assumption is unrealistic since the collected time series data can be contaminated in practice. The forecasting model will be inferior if it is directly trained by time series with anomalies. Thus it is essential to develop methods to automatically learn a robust forecasting model from the contaminated data. In this paper, we first statistically define three types of anomalies, then theoretically and experimentally analyze the loss robustness and sample robustness when these anomalies exist. Based on our analyses, we propose a simple and efficient algorithm to learn a robust forecasting model. Extensive experiments show that our method is highly robust and outperforms all existing approaches. The code is available at https://github.com/haochenglouis/RobustTSF.</li>
</ul>

<h3>Title: Universal Post-Training Reverse-Engineering Defense Against Backdoors in  Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Xi Li, Hang Wang, David J. Miller, George Kesidis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02034">https://arxiv.org/abs/2402.02034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02034">https://arxiv.org/pdf/2402.02034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02034]] Universal Post-Training Reverse-Engineering Defense Against Backdoors in  Deep Neural Networks(https://arxiv.org/abs/2402.02034)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>A variety of defenses have been proposed against backdoors attacks on deep neural network (DNN) classifiers. Universal methods seek to reliably detect and/or mitigate backdoors irrespective of the incorporation mechanism used by the attacker, while reverse-engineering methods often explicitly assume one. In this paper, we describe a new detector that: relies on internal feature map of the defended DNN to detect and reverse-engineer the backdoor and identify its target class; can operate post-training (without access to the training dataset); is highly effective for various incorporation mechanisms (i.e., is universal); and which has low computational overhead and so is scalable. Our detection approach is evaluated for different attacks on a benchmark CIFAR-10 image classifier.</li>
</ul>

<h3>Title: Interpreting Graph Neural Networks with In-Distributed Proxies</h3>
<ul>
<li><strong>Authors: </strong>Zhuomin Chen, Jiaxing Zhang, Jingchao Ni, Xiaoting Li, Yuchen Bian, Md Mezbahul Islam, Ananda Mohan Mondal, Hua Wei, Dongsheng Luo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02036">https://arxiv.org/abs/2402.02036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02036">https://arxiv.org/pdf/2402.02036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02036]] Interpreting Graph Neural Networks with In-Distributed Proxies(https://arxiv.org/abs/2402.02036)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have become a building block in graph data processing, with wide applications in critical domains. The growing needs to deploy GNNs in high-stakes applications necessitate explainability for users in the decision-making processes. A popular paradigm for the explainability of GNNs is to identify explainable subgraphs by comparing their labels with the ones of original graphs. This task is challenging due to the substantial distributional shift from the original graphs in the training set to the set of explainable subgraphs, which prevents accurate prediction of labels with the subgraphs. To address it, in this paper, we propose a novel method that generates proxy graphs for explainable subgraphs that are in the distribution of training data. We introduce a parametric method that employs graph generators to produce proxy graphs. A new training objective based on information theory is designed to ensure that proxy graphs not only adhere to the distribution of training data but also preserve essential explanatory factors. Such generated proxy graphs can be reliably used for approximating the predictions of the true labels of explainable subgraphs. Empirical evaluations across various datasets demonstrate our method achieves more accurate explanations for GNNs.</li>
</ul>

<h3>Title: MLIP: Enhancing Medical Visual Representation with Divergence Encoder  and Knowledge-guided Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhe Li, Laurence T. Yang, Bocheng Ren, Xin Nie, Zhangyang Gao, Cheng Tan, Stan Z. Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02045">https://arxiv.org/abs/2402.02045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02045">https://arxiv.org/pdf/2402.02045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02045]] MLIP: Enhancing Medical Visual Representation with Divergence Encoder  and Knowledge-guided Contrastive Learning(https://arxiv.org/abs/2402.02045)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The scarcity of annotated data has sparked significant interest in unsupervised pre-training methods that leverage medical reports as auxiliary signals for medical visual representation learning. However, existing research overlooks the multi-granularity nature of medical visual representation and lacks suitable contrastive learning techniques to improve the models' generalizability across different granularities, leading to the underutilization of image-text information. To address this, we propose MLIP, a novel framework leveraging domain-specific medical knowledge as guiding signals to integrate language information into the visual domain through image-text contrastive learning. Our model includes global contrastive learning with our designed divergence encoder, local token-knowledge-patch alignment contrastive learning, and knowledge-guided category-level contrastive learning with expert knowledge. Experimental evaluations reveal the efficacy of our model in enhancing transfer performance for tasks such as image classification, object detection, and semantic segmentation. Notably, MLIP surpasses state-of-the-art methods even with limited annotated data, highlighting the potential of multimodal pre-training in advancing medical representation learning.</li>
</ul>

<h3>Title: TCI-Former: Thermal Conduction-Inspired Transformer for Infrared Small  Target Detection</h3>
<ul>
<li><strong>Authors: </strong>Tianxiang Chen, Zhentao Tan, Qi Chu, Yue Wu, Bin Liu, Nenghai Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02046">https://arxiv.org/abs/2402.02046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02046">https://arxiv.org/pdf/2402.02046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02046]] TCI-Former: Thermal Conduction-Inspired Transformer for Infrared Small  Target Detection(https://arxiv.org/abs/2402.02046)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Infrared small target detection (ISTD) is critical to national security and has been extensively applied in military areas. ISTD aims to segment small target pixels from background. Most ISTD networks focus on designing feature extraction blocks or feature fusion modules, but rarely describe the ISTD process from the feature map evolution perspective. In the ISTD process, the network attention gradually shifts towards target areas. We abstract this process as the directional movement of feature map pixels to target areas through convolution, pooling and interactions with surrounding pixels, which can be analogous to the movement of thermal particles constrained by surrounding variables and particles. In light of this analogy, we propose Thermal Conduction-Inspired Transformer (TCI-Former) based on the theoretical principles of thermal conduction. According to thermal conduction differential equation in heat dynamics, we derive the pixel movement differential equation (PMDE) in the image domain and further develop two modules: Thermal Conduction-Inspired Attention (TCIA) and Thermal Conduction Boundary Module (TCBM). TCIA incorporates finite difference method with PMDE to reach a numerical approximation so that target body features can be extracted. To further remove errors in boundary areas, TCBM is designed and supervised by boundary masks to refine target body features with fine boundary details. Experiments on IRSTD-1k and NUAA-SIRST demonstrate the superiority of our method.</li>
</ul>

<h3>Title: Feature Selection using the concept of Peafowl Mating in IDS</h3>
<ul>
<li><strong>Authors: </strong>Partha Ghosh, Joy Sharma, Nilesh Pandey</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02052">https://arxiv.org/abs/2402.02052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02052">https://arxiv.org/pdf/2402.02052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02052]] Feature Selection using the concept of Peafowl Mating in IDS(https://arxiv.org/abs/2402.02052)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Cloud computing has high applicability as an Internet based service that relies on sharing computing resources. Cloud computing provides services that are Infrastructure based, Platform based and Software based. The popularity of this technology is due to its superb performance, high level of computing ability, low cost of services, scalability, availability and flexibility. The obtainability and openness of data in cloud environment make it vulnerable to the world of cyber-attacks. To detect the attacks Intrusion Detection System is used, that can identify the attacks and ensure information security. Such a coherent and proficient Intrusion Detection System is proposed in this paper to achieve higher certainty levels regarding safety in cloud environment. In this paper, the mating behavior of peafowl is incorporated into an optimization algorithm which in turn is used as a feature selection algorithm. The algorithm is used to reduce the huge size of cloud data so that the IDS can work efficiently on the cloud to detect intrusions. The proposed model has been experimented with NSL-KDD dataset as well as Kyoto dataset and have proved to be a better as well as an efficient IDS.</li>
</ul>

<h3>Title: Neural Scaling Laws on Graphs</h3>
<ul>
<li><strong>Authors: </strong>Jingzhe Liu, Haitao Mao, Zhikai Chen, Tong Zhao, Neil Shah, Jiliang Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02054">https://arxiv.org/abs/2402.02054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02054">https://arxiv.org/pdf/2402.02054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02054]] Neural Scaling Laws on Graphs(https://arxiv.org/abs/2402.02054)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep graph models (e.g., graph neural networks and graph transformers) have become important techniques for leveraging knowledge across various types of graphs. Yet, the scaling properties of deep graph models have not been systematically investigated, casting doubt on the feasibility of achieving large graph models through enlarging the model and dataset sizes. In this work, we delve into neural scaling laws on graphs from both model and data perspectives. We first verify the validity of such laws on graphs, establishing formulations to describe the scaling behaviors. For model scaling, we investigate the phenomenon of scaling law collapse and identify overfitting as the potential reason. Moreover, we reveal that the model depth of deep graph models can impact the model scaling behaviors, which differ from observations in other domains such as CV and NLP. For data scaling, we suggest that the number of graphs can not effectively metric the graph data volume in scaling law since the sizes of different graphs are highly irregular. Instead, we reform the data scaling law with the number of edges as the metric to address the irregular graph sizes. We further demonstrate the reformed law offers a unified view of the data scaling behaviors for various fundamental graph tasks including node classification, link prediction, and graph classification. This work provides valuable insights into neural scaling laws on graphs, which can serve as an essential step toward large graph models.</li>
</ul>

<h3>Title: Break the Sequential Dependency of LLM Inference Using Lookahead  Decoding</h3>
<ul>
<li><strong>Authors: </strong>Yichao Fu, Peter Bailis, Ion Stoica, Hao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02057">https://arxiv.org/abs/2402.02057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02057">https://arxiv.org/pdf/2402.02057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02057]] Break the Sequential Dependency of LLM Inference Using Lookahead  Decoding(https://arxiv.org/abs/2402.02057)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autoregressive decoding of large language models (LLMs) is memory bandwidth bounded, resulting in high latency and significant wastes of the parallel processing power of modern accelerators. Existing methods for accelerating LLM decoding often require a draft model (e.g., speculative decoding), which is nontrivial to obtain and unable to generalize. In this paper, we introduce Lookahead decoding, an exact, parallel decoding algorithm that accelerates LLM decoding without needing auxiliary models or data stores. It allows trading per-step log(FLOPs) to reduce the number of total decoding steps, is more parallelizable on single or multiple modern accelerators, and is compatible with concurrent memory-efficient attention (e.g., FlashAttention). Our implementation of Lookahead decoding can speed up autoregressive decoding by up to 1.8x on MT-bench and 4x with strong scaling on multiple GPUs in code completion tasks. Our code is avialable at https://github.com/hao-ai-lab/LookaheadDecoding</li>
</ul>

<h3>Title: DiffVein: A Unified Diffusion Network for Finger Vein Segmentation and  Authentication</h3>
<ul>
<li><strong>Authors: </strong>Yanjun Liu, Wenming Yang, Qingmin Liao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02060">https://arxiv.org/abs/2402.02060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02060">https://arxiv.org/pdf/2402.02060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02060]] DiffVein: A Unified Diffusion Network for Finger Vein Segmentation and  Authentication(https://arxiv.org/abs/2402.02060)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, biometric, extraction, diffusion, transformer, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Finger vein authentication, recognized for its high security and specificity, has become a focal point in biometric research. Traditional methods predominantly concentrate on vein feature extraction for discriminative modeling, with a limited exploration of generative approaches. Suffering from verification failure, existing methods often fail to obtain authentic vein patterns by segmentation. To fill this gap, we introduce DiffVein, a unified diffusion model-based framework which simultaneously addresses vein segmentation and authentication tasks. DiffVein is composed of two dedicated branches: one for segmentation and the other for denoising. For better feature interaction between these two branches, we introduce two specialized modules to improve their collective performance. The first, a mask condition module, incorporates the semantic information of vein patterns from the segmentation branch into the denoising process. Additionally, we also propose a Semantic Difference Transformer (SD-Former), which employs Fourier-space self-attention and cross-attention modules to extract category embedding before feeding it to the segmentation task. In this way, our framework allows for a dynamic interplay between diffusion and segmentation embeddings, thus vein segmentation and authentication tasks can inform and enhance each other in the joint training. To further optimize our model, we introduce a Fourier-space Structural Similarity (FourierSIM) loss function, which is tailored to improve the denoising network's learning efficacy. Extensive experiments on the USM and THU-MVFV3V datasets substantiates DiffVein's superior performance, setting new benchmarks in both vein segmentation and authentication tasks.</li>
</ul>

<h3>Title: RIDERS: Radar-Infrared Depth Estimation for Robust Sensing</h3>
<ul>
<li><strong>Authors: </strong>Han Li, Yukai Ma, Yuehao Huang, Yaqing Gu, Weihua Xu, Yong Liu, Xingxing Zuo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02067">https://arxiv.org/abs/2402.02067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02067">https://arxiv.org/pdf/2402.02067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02067]] RIDERS: Radar-Infrared Depth Estimation for Robust Sensing(https://arxiv.org/abs/2402.02067)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Dense depth recovery is crucial in autonomous driving, serving as a foundational element for obstacle avoidance, 3D object detection, and local path planning. Adverse weather conditions, including haze, dust, rain, snow, and darkness, introduce significant challenges to accurate dense depth estimation, thereby posing substantial safety risks in autonomous driving. These challenges are particularly pronounced for traditional depth estimation methods that rely on short electromagnetic wave sensors, such as visible spectrum cameras and near-infrared LiDAR, due to their susceptibility to diffraction noise and occlusion in such environments. To fundamentally overcome this issue, we present a novel approach for robust metric depth estimation by fusing a millimeter-wave Radar and a monocular infrared thermal camera, which are capable of penetrating atmospheric particles and unaffected by lighting conditions. Our proposed Radar-Infrared fusion method achieves highly accurate and finely detailed dense depth estimation through three stages, including monocular depth prediction with global scale alignment, quasi-dense Radar augmentation by learning Radar-pixels correspondences, and local scale refinement of dense depth using a scale map learner. Our method achieves exceptional visual quality and accurate metric estimation by addressing the challenges of ambiguity and misalignment that arise from directly fusing multi-modal long-wave features. We evaluate the performance of our approach on the NTU4DRadLM dataset and our self-collected challenging ZJU-Multispectrum dataset. Especially noteworthy is the unprecedented robustness demonstrated by our proposed method in smoky scenarios. Our code will be released at \url{https://github.com/MMOCKING/RIDERS}.</li>
</ul>

<h3>Title: Exploring the Robustness of Task-oriented Dialogue Systems for  Colloquial German Varieties</h3>
<ul>
<li><strong>Authors: </strong>Ekaterina Artemova, Verena Blaschke, Barbara Plank</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02078">https://arxiv.org/abs/2402.02078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02078">https://arxiv.org/pdf/2402.02078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02078]] Exploring the Robustness of Task-oriented Dialogue Systems for  Colloquial German Varieties(https://arxiv.org/abs/2402.02078)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Mainstream cross-lingual task-oriented dialogue (ToD) systems leverage the transfer learning paradigm by training a joint model for intent recognition and slot-filling in English and applying it, zero-shot, to other languages. We address a gap in prior research, which often overlooked the transfer to lower-resource colloquial varieties due to limited test data. Inspired by prior work on English varieties, we craft and manually evaluate perturbation rules that transform German sentences into colloquial forms and use them to synthesize test sets in four ToD datasets. Our perturbation rules cover 18 distinct language phenomena, enabling us to explore the impact of each perturbation on slot and intent performance. Using these new datasets, we conduct an experimental evaluation across six different transformers. Here, we demonstrate that when applied to colloquial varieties, ToD systems maintain their intent recognition performance, losing 6% (4.62 percentage points) in accuracy on average. However, they exhibit a significant drop in slot detection, with a decrease of 31% (21 percentage points) in slot F1 score. Our findings are further supported by a transfer experiment from Standard American English to synthetic Urban African American Vernacular English.</li>
</ul>

<h3>Title: Risk-Sensitive Diffusion: Learning the Underlying Distribution from  Noisy Samples</h3>
<ul>
<li><strong>Authors: </strong>Yangming Li, Max Ruiz Luyten, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02081">https://arxiv.org/abs/2402.02081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02081">https://arxiv.org/pdf/2402.02081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02081]] Risk-Sensitive Diffusion: Learning the Underlying Distribution from  Noisy Samples(https://arxiv.org/abs/2402.02081)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While achieving remarkable performances, we show that diffusion models are fragile to the presence of noisy samples, limiting their potential in the vast amount of settings where, unlike image synthesis, we are not blessed with clean data. Motivated by our finding that such fragility originates from the distribution gaps between noisy and clean samples along the diffusion process, we introduce risk-sensitive SDE, a stochastic differential equation that is parameterized by the risk (i.e., data "dirtiness") to adjust the distributions of noisy samples, reducing misguidance while benefiting from their contained information. The optimal expression for risk-sensitive SDE depends on the specific noise distribution, and we derive its parameterizations that minimize the misguidance of noisy samples for both Gaussian and general non-Gaussian perturbations. We conduct extensive experiments on both synthetic and real-world datasets (e.g., medical time series), showing that our model effectively recovers the clean data distribution from noisy samples, significantly outperforming conditional generation baselines.</li>
</ul>

<h3>Title: Revisiting the Markov Property for Machine Translation</h3>
<ul>
<li><strong>Authors: </strong>Cunxiao Du, Hao Zhou, Zhaopeng Tu, Jing Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02084">https://arxiv.org/abs/2402.02084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02084">https://arxiv.org/pdf/2402.02084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02084]] Revisiting the Markov Property for Machine Translation(https://arxiv.org/abs/2402.02084)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we re-examine the Markov property in the context of neural machine translation. We design a Markov Autoregressive Transformer~(MAT) and undertake a comprehensive assessment of its performance across four WMT benchmarks. Our findings indicate that MAT with an order larger than 4 can generate translations with quality on par with that of conventional autoregressive transformers. In addition, counter-intuitively, we also find that the advantages of utilizing a higher-order MAT do not specifically contribute to the translation of longer sentences.</li>
</ul>

<h3>Title: DeCoF: Generated Video Detection via Frame Consistency</h3>
<ul>
<li><strong>Authors: </strong>Long Ma, Jiajia Zhang, Hongping Deng, Ningyu Zhang, Yong Liao, Haiyang Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02085">https://arxiv.org/abs/2402.02085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02085">https://arxiv.org/pdf/2402.02085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02085]] DeCoF: Generated Video Detection via Frame Consistency(https://arxiv.org/abs/2402.02085)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>The escalating quality of video generated by advanced video generation methods leads to new security challenges in society, which makes generated video detection an urgent research priority.To foster collaborative research in this area, we construct the first open-source dataset explicitly for generated video detection, providing a valuable resource for the community to benchmark and improve detection methodologies. Through a series of carefully designed probe experiments, our study explores the significance of temporal and spatial artifacts in developing general and robust detectors for generated video. Based on the principle of video frame consistency, we introduce a simple yet effective detection model (DeCoF) that eliminates the impact of spatial artifacts during generalizing feature learning. Our extensive experiments demonstrate the efficacy of DeCoF in detecting videos produced by unseen video generation models and confirm its powerful generalization capabilities across several commercial proprietary models.</li>
</ul>

<h3>Title: DCS-Net: Pioneering Leakage-Free Point Cloud Pretraining Framework with  Global Insights</h3>
<ul>
<li><strong>Authors: </strong>Zhe Li, Zhangyang Gao, Cheng Tan, Stan Z. Li, Laurence T. Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02088">https://arxiv.org/abs/2402.02088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02088">https://arxiv.org/pdf/2402.02088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02088]] DCS-Net: Pioneering Leakage-Free Point Cloud Pretraining Framework with  Global Insights(https://arxiv.org/abs/2402.02088)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Masked autoencoding and generative pretraining have achieved remarkable success in computer vision and natural language processing, and more recently, they have been extended to the point cloud domain. Nevertheless, existing point cloud models suffer from the issue of information leakage due to the pre-sampling of center points, which leads to trivial proxy tasks for the models. These approaches primarily focus on local feature reconstruction, limiting their ability to capture global patterns within point clouds. In this paper, we argue that the reduced difficulty of pretext tasks hampers the model's capacity to learn expressive representations. To address these limitations, we introduce a novel solution called the Differentiable Center Sampling Network (DCS-Net). It tackles the information leakage problem by incorporating both global feature reconstruction and local feature reconstruction as non-trivial proxy tasks, enabling simultaneous learning of both the global and local patterns within point cloud. Experimental results demonstrate that our method enhances the expressive capacity of existing point cloud models and effectively addresses the issue of information leakage.</li>
</ul>

<h3>Title: Recent Advances in Digital Image and Video Forensics, Anti-forensics and  Counter Anti-forensics</h3>
<ul>
<li><strong>Authors: </strong>Maryam Al-Fehani, Saif Al-Kuwari</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02089">https://arxiv.org/abs/2402.02089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02089">https://arxiv.org/pdf/2402.02089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02089]] Recent Advances in Digital Image and Video Forensics, Anti-forensics and  Counter Anti-forensics(https://arxiv.org/abs/2402.02089)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Image and video forensics have recently gained increasing attention due to the proliferation of manipulated images and videos, especially on social media platforms, such as Twitter and Instagram, which spread disinformation and fake news. This survey explores image and video identification and forgery detection covering both manipulated digital media and generative media. However, media forgery detection techniques are susceptible to anti-forensics; on the other hand, such anti-forensics techniques can themselves be detected. We therefore further cover both anti-forensics and counter anti-forensics techniques in image and video. Finally, we conclude this survey by highlighting some open problems in this domain.</li>
</ul>

<h3>Title: Physical Perception Network and an All-weather Multi-modality Benchmark  for Adverse Weather Image Fusion</h3>
<ul>
<li><strong>Authors: </strong>Xilai Li, Wuyang Liu, Xiaosong Li, Haishu Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02090">https://arxiv.org/abs/2402.02090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02090">https://arxiv.org/pdf/2402.02090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02090]] Physical Perception Network and an All-weather Multi-modality Benchmark  for Adverse Weather Image Fusion(https://arxiv.org/abs/2402.02090)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Multi-modality image fusion (MMIF) integrates the complementary information from different modal images to provide comprehensive and objective interpretation of a scenes. However, existing MMIF methods lack the ability to resist different weather interferences in real-life scenarios, preventing them from being useful in practical applications such as autonomous driving. To bridge this research gap, we proposed an all-weather MMIF model. Regarding deep learning architectures, their network designs are often viewed as a black box, which limits their multitasking capabilities. For deweathering module, we propose a physically-aware clear feature prediction module based on an atmospheric scattering model that can deduce variations in light transmittance from both scene illumination and depth. For fusion module, We utilize a learnable low-rank representation model to decompose images into low-rank and sparse components. This highly interpretable feature separation allows us to better observe and understand images. Furthermore, we have established a benchmark for MMIF research under extreme weather conditions. It encompasses multiple scenes under three types of weather: rain, haze, and snow, with each weather condition further subdivided into various impact levels. Extensive fusion experiments under adverse weather demonstrate that the proposed algorithm has excellent detail recovery and multi-modality feature extraction capabilities.</li>
</ul>

<h3>Title: Wireguard: An Efficient Solution for Securing IoT Device Connectivity</h3>
<ul>
<li><strong>Authors: </strong>Haseebullah Jumakhan, Amir Mirzaeinia</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02093">https://arxiv.org/abs/2402.02093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02093">https://arxiv.org/pdf/2402.02093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02093]] Wireguard: An Efficient Solution for Securing IoT Device Connectivity(https://arxiv.org/abs/2402.02093)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>The proliferation of vulnerable Internet-of-Things (IoT) devices has enabled large-scale cyberattacks. Solutions like Hestia and HomeSnitch have failed to comprehensively address IoT security needs. This research evaluates if Wireguard, an emerging VPN protocol, can provide efficient security tailored for resource-constrained IoT systems. We compared Wireguards performance against standard protocols OpenVPN and IPsec in a simulated IoT environment. Metrics measured included throughput, latency, and jitter during file transfers. Initial results reveal Wireguard's potential as a lightweight yet robust IoT security solution despite disadvantages for Wireguard in our experimental environment. With further testing, Wireguards simplicity and low overhead could enable widespread VPN adoption to harden IoT devices against attacks. The protocols advantages in setup time, performance, and compatibility make it promising for integration especially on weak IoT processors and networks.</li>
</ul>

<h3>Title: Deep Semantic-Visual Alignment for Zero-Shot Remote Sensing Image Scene  Classification</h3>
<ul>
<li><strong>Authors: </strong>Wenjia Xu, Jiuniu Wang, Zhiwei Wei, Mugen Peng, Yirong Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02094">https://arxiv.org/abs/2402.02094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02094">https://arxiv.org/pdf/2402.02094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02094]] Deep Semantic-Visual Alignment for Zero-Shot Remote Sensing Image Scene  Classification(https://arxiv.org/abs/2402.02094)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep neural networks have achieved promising progress in remote sensing (RS) image classification, for which the training process requires abundant samples for each class. However, it is time-consuming and unrealistic to annotate labels for each RS category, given the fact that the RS target database is increasing dynamically. Zero-shot learning (ZSL) allows for identifying novel classes that are not seen during training, which provides a promising solution for the aforementioned problem. However, previous ZSL models mainly depend on manually-labeled attributes or word embeddings extracted from language models to transfer knowledge from seen classes to novel classes. Besides, pioneer ZSL models use convolutional neural networks pre-trained on ImageNet, which focus on the main objects appearing in each image, neglecting the background context that also matters in RS scene classification. To address the above problems, we propose to collect visually detectable attributes automatically. We predict attributes for each class by depicting the semantic-visual similarity between attributes and images. In this way, the attribute annotation process is accomplished by machine instead of human as in other methods. Moreover, we propose a Deep Semantic-Visual Alignment (DSVA) that take advantage of the self-attention mechanism in the transformer to associate local image regions together, integrating the background context information for prediction. The DSVA model further utilizes the attribute attention maps to focus on the informative image regions that are essential for knowledge transfer in ZSL, and maps the visual images into attribute space to perform ZSL classification. With extensive experiments, we show that our model outperforms other state-of-the-art models by a large margin on a challenging large-scale RS scene classification benchmark.</li>
</ul>

<h3>Title: Seeing is not always believing: The Space of Harmless Perturbations</h3>
<ul>
<li><strong>Authors: </strong>Lu Chen, Shaofeng Li, Benhao Huang, Fan Yang, Zheng Li, Jie Li, Yuan Luo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02095">https://arxiv.org/abs/2402.02095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02095">https://arxiv.org/pdf/2402.02095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02095]] Seeing is not always believing: The Space of Harmless Perturbations(https://arxiv.org/abs/2402.02095)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In the context of deep neural networks, we expose the existence of a harmless perturbation space, where perturbations leave the network output entirely unaltered. Perturbations within this harmless perturbation space, regardless of their magnitude when applied to images, exhibit no impact on the network's outputs of the original images. Specifically, given any linear layer within the network, where the input dimension $n$ exceeds the output dimension $m$, we demonstrate the existence of a continuous harmless perturbation subspace with a dimension of $(n-m)$. Inspired by this, we solve for a family of general perturbations that consistently influence the network output, irrespective of their magnitudes. With these theoretical findings, we explore the application of harmless perturbations for privacy-preserving data usage. Our work reveals the difference between DNNs and human perception that the significant perturbations captured by humans may not affect the recognition of DNNs. As a result, we utilize this gap to design a type of harmless perturbation that is meaningless for humans while maintaining its recognizable features for DNNs.</li>
</ul>

<h3>Title: Decomposition-based and Interference Perception for Infrared and Visible  Image Fusion in Complex Scenes</h3>
<ul>
<li><strong>Authors: </strong>Xilai Li, Xiaosong Li, Haishu Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02096">https://arxiv.org/abs/2402.02096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02096">https://arxiv.org/pdf/2402.02096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02096]] Decomposition-based and Interference Perception for Infrared and Visible  Image Fusion in Complex Scenes(https://arxiv.org/abs/2402.02096)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Infrared and visible image fusion has emerged as a prominent research in computer vision. However, little attention has been paid on complex scenes fusion, causing existing techniques to produce sub-optimal results when suffers from real interferences. To fill this gap, we propose a decomposition-based and interference perception image fusion method. Specifically, we classify the pixels of visible image from the degree of scattering of light transmission, based on which we then separate the detail and energy information of the image. This refined decomposition facilitates the proposed model in identifying more interfering pixels that are in complex scenes. To strike a balance between denoising and detail preservation, we propose an adaptive denoising scheme for fusing detail components. Meanwhile, we propose a new weighted fusion rule by considering the distribution of image energy information from the perspective of multiple directions. Extensive experiments in complex scenes fusions cover adverse weathers, noise, blur, overexposure, fire, as well as downstream tasks including semantic segmentation, object detection, salient object detection and depth estimation, consistently indicate the effectiveness and superiority of the proposed method compared with the recent representative methods.</li>
</ul>

<h3>Title: Are Large Language Models Good Prompt Optimizers?</h3>
<ul>
<li><strong>Authors: </strong>Ruotian Ma, Xiaolei Wang, Xin Zhou, Jian Li, Nan Du, Tao Gui, Qi Zhang, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02101">https://arxiv.org/abs/2402.02101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02101">https://arxiv.org/pdf/2402.02101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02101]] Are Large Language Models Good Prompt Optimizers?(https://arxiv.org/abs/2402.02101)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LLM-based Automatic Prompt Optimization, which typically utilizes LLMs as Prompt Optimizers to self-reflect and refine prompts, has shown promising performance in recent studies. Despite the success, the underlying mechanism of this approach remains unexplored, and the true effectiveness of LLMs as Prompt Optimizers requires further validation. In this work, we conducted a comprehensive study to uncover the actual mechanism of LLM-based Prompt Optimization. Our findings reveal that the LLM optimizers struggle to identify the true causes of errors during reflection, tending to be biased by their own prior knowledge rather than genuinely reflecting on the errors. Furthermore, even when the reflection is semantically valid, the LLM optimizers often fail to generate appropriate prompts for the target models with a single prompt refinement step, partly due to the unpredictable behaviors of the target models. Based on the observations, we introduce a new "Automatic Behavior Optimization" paradigm, which directly optimizes the target model's behavior in a more controllable manner. We hope our study can inspire new directions for automatic prompt optimization development.</li>
</ul>

<h3>Title: ParZC: Parametric Zero-Cost Proxies for Efficient NAS</h3>
<ul>
<li><strong>Authors: </strong>Peijie Dong, Lujun Li, Xinglin Pan, Zimian Wei, Xiang Liu, Qiang Wang, Xiaowen Chu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02105">https://arxiv.org/abs/2402.02105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02105">https://arxiv.org/pdf/2402.02105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02105]] ParZC: Parametric Zero-Cost Proxies for Efficient NAS(https://arxiv.org/abs/2402.02105)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent advancements in Zero-shot Neural Architecture Search (NAS) highlight the efficacy of zero-cost proxies in various NAS benchmarks. Several studies propose the automated design of zero-cost proxies to achieve SOTA performance but require tedious searching progress. Furthermore, we identify a critical issue with current zero-cost proxies: they aggregate node-wise zero-cost statistics without considering the fact that not all nodes in a neural network equally impact performance estimation. Our observations reveal that node-wise zero-cost statistics significantly vary in their contributions to performance, with each node exhibiting a degree of uncertainty. Based on this insight, we introduce a novel method called Parametric Zero-Cost Proxies (ParZC) framework to enhance the adaptability of zero-cost proxies through parameterization. To address the node indiscrimination, we propose a Mixer Architecture with Bayesian Network (MABN) to explore the node-wise zero-cost statistics and estimate node-specific uncertainty. Moreover, we propose DiffKendall as a loss function to directly optimize Kendall's Tau coefficient in a differentiable manner so that our ParZC can better handle the discrepancies in ranking architectures. Comprehensive experiments on NAS-Bench-101, 201, and NDS demonstrate the superiority of our proposed ParZC compared to existing zero-shot NAS methods. Additionally, we demonstrate the versatility and adaptability of ParZC by transferring it to the Vision Transformer search space.</li>
</ul>

<h3>Title: Zero-shot Sentiment Analysis in Low-Resource Languages Using a  Multilingual Sentiment Lexicon</h3>
<ul>
<li><strong>Authors: </strong>Fajri Koto, Tilman Beck, Zeerak Talat, Iryna Gurevych, Timothy Baldwin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02113">https://arxiv.org/abs/2402.02113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02113">https://arxiv.org/pdf/2402.02113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02113]] Zero-shot Sentiment Analysis in Low-Resource Languages Using a  Multilingual Sentiment Lexicon(https://arxiv.org/abs/2402.02113)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Improving multilingual language models capabilities in low-resource languages is generally difficult due to the scarcity of large-scale data in those languages. In this paper, we relax the reliance on texts in low-resource languages by using multilingual lexicons in pretraining to enhance multilingual capabilities. Specifically, we focus on zero-shot sentiment analysis tasks across 34 languages, including 6 high/medium-resource languages, 25 low-resource languages, and 3 code-switching datasets. We demonstrate that pretraining using multilingual lexicons, without using any sentence-level sentiment data, achieves superior zero-shot performance compared to models fine-tuned on English sentiment datasets, and large language models like GPT--3.5, BLOOMZ, and XGLM. These findings are observable for unseen low-resource languages to code-mixed scenarios involving high-resource languages.</li>
</ul>

<h3>Title: Handling Delayed Feedback in Distributed Online Optimization : A  Projection-Free Approach</h3>
<ul>
<li><strong>Authors: </strong>Tuan-Anh Nguyen, Nguyen Kim Thang, Denis Trystram</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02114">https://arxiv.org/abs/2402.02114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02114">https://arxiv.org/pdf/2402.02114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02114]] Handling Delayed Feedback in Distributed Online Optimization : A  Projection-Free Approach(https://arxiv.org/abs/2402.02114)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning at the edges has become increasingly important as large quantities of data are continually generated locally. Among others, this paradigm requires algorithms that are simple (so that they can be executed by local devices), robust (again uncertainty as data are continually generated), and reliable in a distributed manner under network issues, especially delays. In this study, we investigate the problem of online convex optimization under adversarial delayed feedback. We propose two projection-free algorithms for centralised and distributed settings in which they are carefully designed to achieve a regret bound of O(\sqrt{B}) where B is the sum of delay, which is optimal for the OCO problem in the delay setting while still being projection-free. We provide an extensive theoretical study and experimentally validate the performance of our algorithms by comparing them with existing ones on real-world problems.</li>
</ul>

<h3>Title: Enhancing crop classification accuracy by synthetic SAR-Optical data  generation using deep learning</h3>
<ul>
<li><strong>Authors: </strong>Ali Mirzaei, Hossein Bagheri, Iman Khosravi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02121">https://arxiv.org/abs/2402.02121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02121">https://arxiv.org/pdf/2402.02121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02121]] Enhancing crop classification accuracy by synthetic SAR-Optical data  generation using deep learning(https://arxiv.org/abs/2402.02121)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Crop classification using remote sensing data has emerged as a prominent research area in recent decades. Studies have demonstrated that fusing SAR and optical images can significantly enhance the accuracy of classification. However, a major challenge in this field is the limited availability of training data, which adversely affects the performance of classifiers. In agricultural regions, the dominant crops typically consist of one or two specific types, while other crops are scarce. Consequently, when collecting training samples to create a map of agricultural products, there is an abundance of samples from the dominant crops, forming the majority classes. Conversely, samples from other crops are scarce, representing the minority classes. Addressing this issue requires overcoming several challenges and weaknesses associated with traditional data generation methods. These methods have been employed to tackle the imbalanced nature of the training data. Nevertheless, they still face limitations in effectively handling the minority classes. Overall, the issue of inadequate training data, particularly for minority classes, remains a hurdle that traditional methods struggle to overcome. In this research, We explore the effectiveness of conditional tabular generative adversarial network (CTGAN) as a synthetic data generation method based on a deep learning network, in addressing the challenge of limited training data for minority classes in crop classification using the fusion of SAR-optical data. Our findings demonstrate that the proposed method generates synthetic data with higher quality that can significantly increase the number of samples for minority classes leading to better performance of crop classifiers.</li>
</ul>

<h3>Title: Rendering Graphs for Graph Reasoning in Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yanbin Wei, Shuai Fu, Weisen Jiang, James T. Kwok, Yu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02130">https://arxiv.org/abs/2402.02130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02130">https://arxiv.org/pdf/2402.02130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02130]] Rendering Graphs for Graph Reasoning in Multimodal Large Language Models(https://arxiv.org/abs/2402.02130)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used for various tasks with graph structures, such as robotic planning, knowledge graph completion, and common-sense reasoning. Though LLMs can comprehend graph information in a textual format, they overlook the rich visual modality, which is an intuitive way for humans to comprehend structural information and conduct graph reasoning. The potential benefits and capabilities of representing graph structures as visual images (i.e., visual graph) is still unexplored. In this paper, we take the first step in incorporating visual information into graph reasoning tasks and propose a new benchmark GITQA, where each sample is a tuple (graph, image, textual description). We conduct extensive experiments on the GITQA benchmark using state-of-the-art multimodal LLMs. Results on graph reasoning tasks show that combining textual and visual information together performs better than using one modality alone. Moreover, the LLaVA-7B/13B models finetuned on the training set achieve higher accuracy than the closed-source model GPT-4(V). We also study the effects of augmentations in graph reasoning.</li>
</ul>

<h3>Title: Do Moral Judgment and Reasoning Capability of LLMs Change with Language?  A Study using the Multilingual Defining Issues Test</h3>
<ul>
<li><strong>Authors: </strong>Aditi Khandelwal, Utkarsh Agarwal, Kumar Tanmay, Monojit Choudhury</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02135">https://arxiv.org/abs/2402.02135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02135">https://arxiv.org/pdf/2402.02135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02135]] Do Moral Judgment and Reasoning Capability of LLMs Change with Language?  A Study using the Multilingual Defining Issues Test(https://arxiv.org/abs/2402.02135)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper explores the moral judgment and moral reasoning abilities exhibited by Large Language Models (LLMs) across languages through the Defining Issues Test. It is a well known fact that moral judgment depends on the language in which the question is asked. We extend the work of beyond English, to 5 new languages (Chinese, Hindi, Russian, Spanish and Swahili), and probe three LLMs -- ChatGPT, GPT-4 and Llama2Chat-70B -- that shows substantial multilingual text processing and generation abilities. Our study shows that the moral reasoning ability for all models, as indicated by the post-conventional score, is substantially inferior for Hindi and Swahili, compared to Spanish, Russian, Chinese and English, while there is no clear trend for the performance of the latter four languages. The moral judgments too vary considerably by the language.</li>
</ul>

<h3>Title: Generative Visual Compression: A Review</h3>
<ul>
<li><strong>Authors: </strong>Bolin Chen, Shanzhi Yin, Peilin Chen, Shiqi Wang, Yan Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02140">https://arxiv.org/abs/2402.02140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02140">https://arxiv.org/pdf/2402.02140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02140]] Generative Visual Compression: A Review(https://arxiv.org/abs/2402.02140)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence Generated Content (AIGC) is leading a new technical revolution for the acquisition of digital content and impelling the progress of visual compression towards competitive performance gains and diverse functionalities over traditional codecs. This paper provides a thorough review on the recent advances of generative visual compression, illustrating great potentials and promising applications in ultra-low bitrate communication, user-specified reconstruction/filtering, and intelligent machine analysis. In particular, we review the visual data compression methodologies with deep generative models, and summarize how compact representation and high-fidelity reconstruction could be actualized via generative techniques. In addition, we generalize related generative compression technologies for machine vision and intelligent analytics. Finally, we discuss the fundamental challenges on generative visual compression techniques and envision their future research directions.</li>
</ul>

<h3>Title: Zero-shot sketch-based remote sensing image retrieval based on  multi-level and attention-guided tokenization</h3>
<ul>
<li><strong>Authors: </strong>Bo Yang, Chen Wang, Xiaoshuang Ma, Beiping Song, Zhuang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02141">https://arxiv.org/abs/2402.02141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02141">https://arxiv.org/pdf/2402.02141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02141]] Zero-shot sketch-based remote sensing image retrieval based on  multi-level and attention-guided tokenization(https://arxiv.org/abs/2402.02141)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Effectively and efficiently retrieving images from remote sensing databases is a critical challenge in the realm of remote sensing big data. Utilizing hand-drawn sketches as retrieval inputs offers intuitive and user-friendly advantages, yet the potential of multi-level feature integration from sketches remains underexplored, leading to suboptimal retrieval performance. To address this gap, our study introduces a novel zero-shot, sketch-based retrieval method for remote sensing images, leveraging multi-level, attention-guided tokenization. This approach starts by employing multi-level self-attention feature extraction to tokenize the query sketches, as well as self-attention feature extraction to tokenize the candidate images. It then employs cross-attention mechanisms to establish token correspondence between these two modalities, facilitating the computation of sketch-to-image similarity. Our method demonstrates superior retrieval accuracy over existing sketch-based remote sensing image retrieval techniques, as evidenced by tests on four datasets. Notably, it also exhibits robust zero-shot learning capabilities and strong generalizability in handling unseen categories and novel remote sensing data. The method's scalability can be further enhanced by the pre-calculation of retrieval tokens for all candidate images in a database. This research underscores the significant potential of multi-level, attention-guided tokenization in cross-modal remote sensing image retrieval. For broader accessibility and research facilitation, we have made the code and dataset used in this study publicly available online. Code and dataset are available at https://github.com/Snowstormfly/Cross-modal-retrieval-MLAGT.</li>
</ul>

<h3>Title: Probing Critical Learning Dynamics of PLMs for Hate Speech Detection</h3>
<ul>
<li><strong>Authors: </strong>Sarah Masud, Mohammad Aflah Khan, Vikram Goyal, Md Shad Akhtar, Tanmoy Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02144">https://arxiv.org/abs/2402.02144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02144">https://arxiv.org/pdf/2402.02144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02144]] Probing Critical Learning Dynamics of PLMs for Hate Speech Detection(https://arxiv.org/abs/2402.02144)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite the widespread adoption, there is a lack of research into how various critical aspects of pretrained language models (PLMs) affect their performance in hate speech detection. Through five research questions, our findings and recommendations lay the groundwork for empirically investigating different aspects of PLMs' use in hate speech detection. We deep dive into comparing different pretrained models, evaluating their seed robustness, finetuning settings, and the impact of pretraining data collection time. Our analysis reveals early peaks for downstream tasks during pretraining, the limited benefit of employing a more recent pretraining corpus, and the significance of specific layers during finetuning. We further call into question the use of domain-specific models and highlight the need for dynamic datasets for benchmarking hate speech detection.</li>
</ul>

<h3>Title: Analyzing Sentiment Polarity Reduction in News Presentation through  Contextual Perturbation and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Alapan Kuila, Somnath Jena, Sudeshna Sarkar, Partha Pratim Chakrabarti</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02145">https://arxiv.org/abs/2402.02145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02145">https://arxiv.org/pdf/2402.02145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02145]] Analyzing Sentiment Polarity Reduction in News Presentation through  Contextual Perturbation and Large Language Models(https://arxiv.org/abs/2402.02145)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>In today's media landscape, where news outlets play a pivotal role in shaping public opinion, it is imperative to address the issue of sentiment manipulation within news text. News writers often inject their own biases and emotional language, which can distort the objectivity of reporting. This paper introduces a novel approach to tackle this problem by reducing the polarity of latent sentiments in news content. Drawing inspiration from adversarial attack-based sentence perturbation techniques and a prompt based method using ChatGPT, we employ transformation constraints to modify sentences while preserving their core semantics. Using three perturbation methods: replacement, insertion, and deletion coupled with a context-aware masked language model, we aim to maximize the desired sentiment score for targeted news aspects through a beam search algorithm. Our experiments and human evaluations demonstrate the effectiveness of these two models in achieving reduced sentiment polarity with minimal modifications while maintaining textual similarity, fluency, and grammatical correctness. Comparative analysis confirms the competitive performance of the adversarial attack based perturbation methods and prompt-based methods, offering a promising solution to foster more objective news reporting and combat emotional language bias in the media.</li>
</ul>

<h3>Title: Improving Diffusion Models for Inverse Problems Using Optimal Posterior  Covariance</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Peng, Ziyang Zheng, Wenrui Dai, Nuoqian Xiao, Chenglin Li, Junni Zou, Hongkai Xiong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02149">https://arxiv.org/abs/2402.02149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02149">https://arxiv.org/pdf/2402.02149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02149]] Improving Diffusion Models for Inverse Problems Using Optimal Posterior  Covariance(https://arxiv.org/abs/2402.02149)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Recent diffusion models provide a promising zero-shot solution to noisy linear inverse problems without retraining for specific inverse problems. In this paper, we propose the first unified interpretation for existing zero-shot methods from the perspective of approximating the conditional posterior mean for the reverse diffusion process of conditional sampling. We reveal that recent methods are equivalent to making isotropic Gaussian approximations to intractable posterior distributions over clean images given diffused noisy images, with the only difference in the handcrafted design of isotropic posterior covariances. Inspired by this finding, we propose a general plug-and-play posterior covariance optimization based on maximum likelihood estimation to improve recent methods. To achieve optimal posterior covariance without retraining, we provide general solutions based on two approaches specifically designed to leverage pre-trained models with and without reverse covariances. Experimental results demonstrate that the proposed methods significantly enhance the overall performance or robustness to hyperparameters of recent methods. Code is available at https://github.com/xypeng9903/k-diffusion-inverse-problems</li>
</ul>

<h3>Title: Evaluating the Robustness of Off-Road Autonomous Driving Segmentation  against Adversarial Attacks: A Dataset-Centric analysis</h3>
<ul>
<li><strong>Authors: </strong>Pankaj Deoli, Rohit Kumar, Axel Vierling, Karsten Berns</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02154">https://arxiv.org/abs/2402.02154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02154">https://arxiv.org/pdf/2402.02154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02154]] Evaluating the Robustness of Off-Road Autonomous Driving Segmentation  against Adversarial Attacks: A Dataset-Centric analysis(https://arxiv.org/abs/2402.02154)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, segmentation</a></li>
<li><strong>Abstract: </strong>This study investigates the vulnerability of semantic segmentation models to adversarial input perturbations, in the domain of off- road autonomous driving. Despite good performance in generic conditions, the state-of-the-art classifiers are often susceptible to (even) small perturbations, ultimately resulting in inaccurate predic- tions with high confidence. Prior research has directed their focus on making models more robust by modifying the architecture and training with noisy input images, but has not explored the influence of datasets in adversarial attacks. Our study aims to address this gap by examining the impact of non-robust features in off-road datasets and comparing the effects of adversarial attacks on different seg- mentation network architectures. To enable this, a robust dataset is created consisting of only robust features and training the net- works on this robustified dataset. We present both qualitative and quantitative analysis of our findings, which have important impli- cations on improving the robustness of machine learning models in off-road autonomous driving applications. Additionally, this work contributes to the safe navigation of autonomous robot Unimog U5023 in rough off-road unstructured environments by evaluating the robustness of segmentation outputs. The code is publicly avail- able at https:// github.com/ rohtkumar/ adversarial_attacks_ on_segmentation</li>
</ul>

<h3>Title: Data Poisoning for In-context Learning</h3>
<ul>
<li><strong>Authors: </strong>Pengfei He, Han Xu, Yue Xing, Hui Liu, Makoto Yamada, Jiliang Tang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02160">https://arxiv.org/abs/2402.02160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02160">https://arxiv.org/pdf/2402.02160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02160]] Data Poisoning for In-context Learning(https://arxiv.org/abs/2402.02160)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>In the domain of large language models (LLMs), in-context learning (ICL) has been recognized for its innovative ability to adapt to new tasks, relying on examples rather than retraining or fine-tuning. This paper delves into the critical issue of ICL's susceptibility to data poisoning attacks, an area not yet fully explored. We wonder whether ICL is vulnerable, with adversaries capable of manipulating example data to degrade model performance. To address this, we introduce ICLPoison, a specialized attacking framework conceived to exploit the learning mechanisms of ICL. Our approach uniquely employs discrete text perturbations to strategically influence the hidden states of LLMs during the ICL process. We outline three representative strategies to implement attacks under our framework, each rigorously evaluated across a variety of models and tasks. Our comprehensive tests, including trials on the sophisticated GPT-4 model, demonstrate that ICL's performance is significantly compromised under our framework. These revelations indicate an urgent need for enhanced defense mechanisms to safeguard the integrity and reliability of LLMs in applications relying on in-context learning.</li>
</ul>

<h3>Title: Towards Optimal Adversarial Robust Q-learning with Bellman  Infinity-error</h3>
<ul>
<li><strong>Authors: </strong>Haoran Li, Zicheng Zhang, Wang Luo, Congying Han, Yudong Hu, Tiande Guo, Shichen Liao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02165">https://arxiv.org/abs/2402.02165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02165">https://arxiv.org/pdf/2402.02165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02165]] Towards Optimal Adversarial Robust Q-learning with Bellman  Infinity-error(https://arxiv.org/abs/2402.02165)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Establishing robust policies is essential to counter attacks or disturbances affecting deep reinforcement learning (DRL) agents. Recent studies explore state-adversarial robustness and suggest the potential lack of an optimal robust policy (ORP), posing challenges in setting strict robustness constraints. This work further investigates ORP: At first, we introduce a consistency assumption of policy (CAP) stating that optimal actions in the Markov decision process remain consistent with minor perturbations, supported by empirical and theoretical evidence. Building upon CAP, we crucially prove the existence of a deterministic and stationary ORP that aligns with the Bellman optimal policy. Furthermore, we illustrate the necessity of $L^{\infty}$-norm when minimizing Bellman error to attain ORP. This finding clarifies the vulnerability of prior DRL algorithms that target the Bellman optimal policy with $L^{1}$-norm and motivates us to train a Consistent Adversarial Robust Deep Q-Network (CAR-DQN) by minimizing a surrogate of Bellman Infinity-error. The top-tier performance of CAR-DQN across various benchmarks validates its practical effectiveness and reinforces the soundness of our theoretical analysis.</li>
</ul>

<h3>Title: One Graph Model for Cross-domain Dynamic Link Prediction</h3>
<ul>
<li><strong>Authors: </strong>Xuanwen Huang, Wei Chow, Yang Wang, Ziwei Chai, Chunping Wang, Lei Chen, Yang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02168">https://arxiv.org/abs/2402.02168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02168">https://arxiv.org/pdf/2402.02168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02168]] One Graph Model for Cross-domain Dynamic Link Prediction(https://arxiv.org/abs/2402.02168)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This work proposes DyExpert, a dynamic graph model for cross-domain link prediction. It can explicitly model historical evolving processes to learn the evolution pattern of a specific downstream graph and subsequently make pattern-specific link predictions. DyExpert adopts a decode-only transformer and is capable of efficiently parallel training and inference by \textit{conditioned link generation} that integrates both evolution modeling and link prediction. DyExpert is trained by extensive dynamic graphs across diverse domains, comprising 6M dynamic edges. Extensive experiments on eight untrained graphs demonstrate that DyExpert achieves state-of-the-art performance in cross-domain link prediction. Compared to the advanced baseline under the same setting, DyExpert achieves an average of 11.40% improvement Average Precision across eight graphs. More impressive, it surpasses the fully supervised performance of 8 advanced baselines on 6 untrained graphs.</li>
</ul>

<h3>Title: Enhancing Complex Question Answering over Knowledge Graphs through  Evidence Pattern Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Wentao Ding, Jinmao Li, Liangchuan Luo, Yuzhong Qu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02175">https://arxiv.org/abs/2402.02175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02175">https://arxiv.org/pdf/2402.02175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02175]] Enhancing Complex Question Answering over Knowledge Graphs through  Evidence Pattern Retrieval(https://arxiv.org/abs/2402.02175)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Information retrieval (IR) methods for KGQA consist of two stages: subgraph extraction and answer reasoning. We argue current subgraph extraction methods underestimate the importance of structural dependencies among evidence facts. We propose Evidence Pattern Retrieval (EPR) to explicitly model the structural dependencies during subgraph extraction. We implement EPR by indexing the atomic adjacency pattern of resource pairs. Given a question, we perform dense retrieval to obtain atomic patterns formed by resource pairs. We then enumerate their combinations to construct candidate evidence patterns. These evidence patterns are scored using a neural model, and the best one is selected to extract a subgraph for downstream answer reasoning. Experimental results demonstrate that the EPR-based approach has significantly improved the F1 scores of IR-KGQA methods by over 10 points on ComplexWebQuestions and achieves competitive performance on WebQuestionsSP.</li>
</ul>

<h3>Title: Evolution Guided Generative Flow Networks</h3>
<ul>
<li><strong>Authors: </strong>Zarif Ikram, Ling Pan, Dianbo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02186">https://arxiv.org/abs/2402.02186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02186">https://arxiv.org/pdf/2402.02186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02186]] Evolution Guided Generative Flow Networks(https://arxiv.org/abs/2402.02186)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Flow Networks (GFlowNets) are a family of probabilistic generative models that learn to sample compositional objects proportional to their rewards. One big challenge of GFlowNets is training them effectively when dealing with long time horizons and sparse rewards. To address this, we propose Evolution guided generative flow networks (EGFN), a simple but powerful augmentation to the GFlowNets training using Evolutionary algorithms (EA). Our method can work on top of any GFlowNets training objective, by training a set of agent parameters using EA, storing the resulting trajectories in the prioritized replay buffer, and training the GFlowNets agent using the stored trajectories. We present a thorough investigation over a wide range of toy and real-world benchmark tasks showing the effectiveness of our method in handling long trajectories and sparse rewards.</li>
</ul>

<h3>Title: Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yongshuo Zong, Ondrej Bohdal, Tingyang Yu, Yongxin Yang, Timothy Hospedales</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02207">https://arxiv.org/abs/2402.02207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02207">https://arxiv.org/pdf/2402.02207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02207]] Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large  Language Models(https://arxiv.org/abs/2402.02207)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Current vision large language models (VLLMs) exhibit remarkable capabilities yet are prone to generate harmful content and are vulnerable to even the simplest jailbreaking attacks. Our initial analysis finds that this is due to the presence of harmful data during vision-language instruction fine-tuning, and that VLLM fine-tuning can cause forgetting of safety alignment previously learned by the underpinning LLM. To address this issue, we first curate a vision-language safe instruction-following dataset VLGuard covering various harmful categories. Our experiments demonstrate that integrating this dataset into standard vision-language fine-tuning or utilizing it for post-hoc fine-tuning effectively safety aligns VLLMs. This alignment is achieved with minimal impact on, or even enhancement of, the models' helpfulness. The versatility of our safety fine-tuning dataset makes it a valuable resource for safety-testing existing VLLMs, training new models or safeguarding pre-trained VLLMs. Empirical results demonstrate that fine-tuned VLLMs effectively reject unsafe instructions and substantially reduce the success rates of several black-box adversarial attacks, which approach zero in many cases. The code and dataset are available at https://github.com/ys-zong/VLGuard.</li>
</ul>

<h3>Title: On the Exploitation of DCT-Traces in the Generative-AI Domain</h3>
<ul>
<li><strong>Authors: </strong>Orazio Pontorno (1), Luca Guarnera (1), Sebastiano Battiato (1) ((1) University of Catania)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02209">https://arxiv.org/abs/2402.02209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02209">https://arxiv.org/pdf/2402.02209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02209]] On the Exploitation of DCT-Traces in the Generative-AI Domain(https://arxiv.org/abs/2402.02209)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative</a></li>
<li><strong>Abstract: </strong>Since their appearance, Deepfakes represent one of the toughest challenges in the world of Cybersecurity and Digital Forensics. In recent years, researchers have discovered that generative models leave unique traces in synthetic data that, if analyzed and identified in detail, can be exploited to improve the generalization limitations of existing deepfake detectors. To capture this evidence, in this paper we analyzed deepfake images in the frequency domain, examining in detail the beta-AC coefficients of the Discrete Cosine Transform (DCT). Recognizing that not all coefficients contribute equally to image recognition, we hypothesize the existence of a unique "discriminative fingerprint" for each type of image, embedded in specific combinations of coefficients. To identify them, Machine Learning classifiers were trained on various combinations of coefficients. The integration of the Explainable AI (XAI) LIME algorithm combined with a neural classifier to explore alternative combinations of coefficients provides a deeper insight into the discriminative features of synthetic images. Experimental results reveal the significant potential of using a specific combination of beta-AC coefficients in order to improve the analysis of traces left by generative models.</li>
</ul>

<h3>Title: Wavelet-Decoupling Contrastive Enhancement Network for Fine-Grained  Skeleton-Based Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Haochen Chang, Jing Chen, Yilin Li, Jixiang Chen, Xiaofeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02210">https://arxiv.org/abs/2402.02210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02210">https://arxiv.org/pdf/2402.02210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02210]] Wavelet-Decoupling Contrastive Enhancement Network for Fine-Grained  Skeleton-Based Action Recognition(https://arxiv.org/abs/2402.02210)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Skeleton-based action recognition has attracted much attention, benefiting from its succinctness and robustness. However, the minimal inter-class variation in similar action sequences often leads to confusion. The inherent spatiotemporal coupling characteristics make it challenging to mine the subtle differences in joint motion trajectories, which is critical for distinguishing confusing fine-grained actions. To alleviate this problem, we propose a Wavelet-Attention Decoupling (WAD) module that utilizes discrete wavelet transform to effectively disentangle salient and subtle motion features in the time-frequency domain. Then, the decoupling attention adaptively recalibrates their temporal responses. To further amplify the discrepancies in these subtle motion features, we propose a Fine-grained Contrastive Enhancement (FCE) module to enhance attention towards trajectory features by contrastive learning. Extensive experiments are conducted on the coarse-grained dataset NTU RGB+D and the fine-grained dataset FineGYM. Our methods perform competitively compared to state-of-the-art methods and can discriminate confusing fine-grained actions well.</li>
</ul>

<h3>Title: A Data Generation Perspective to the Mechanism of In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Haitao Mao, Guangliang Liu, Yao Ma, Rongrong Wang, Jiliang Tang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02212">https://arxiv.org/abs/2402.02212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02212">https://arxiv.org/pdf/2402.02212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02212]] A Data Generation Perspective to the Mechanism of In-Context Learning(https://arxiv.org/abs/2402.02212)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-Context Learning (ICL) empowers Large Language Models (LLMs) with the capacity to learn in context, achieving downstream generalization without gradient updates but with a few in-context examples. Despite the encouraging empirical success, the underlying mechanism of ICL remains unclear, and existing research offers various viewpoints of understanding. These studies propose intuition-driven and ad-hoc technical solutions for interpreting ICL, illustrating an ambiguous road map. In this paper, we leverage a data generation perspective to reinterpret recent efforts and demonstrate the potential broader usage of popular technical solutions, approaching a systematic angle. For a conceptual definition, we rigorously adopt the terms of skill learning and skill recognition. The difference between them is skill learning can learn new data generation functions from in-context data. We also provide a comprehensive study on the merits and weaknesses of different solutions, and highlight the uniformity among them given the perspective of data generation, establishing a technical foundation for future research to incorporate the strengths of different lines of research.</li>
</ul>

<h3>Title: CoFiNet: Unveiling Camouflaged Objects with Multi-Scale Finesse</h3>
<ul>
<li><strong>Authors: </strong>Cunhan Guo, Heyan Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02217">https://arxiv.org/abs/2402.02217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02217">https://arxiv.org/pdf/2402.02217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02217]] CoFiNet: Unveiling Camouflaged Objects with Multi-Scale Finesse(https://arxiv.org/abs/2402.02217)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Camouflaged Object Detection (COD) is a critical aspect of computer vision aimed at identifying concealed objects, with applications spanning military, industrial, medical and monitoring domains. To address the problem of poor detail segmentation effect, we introduce a novel method for camouflage object detection, named CoFiNet. Our approach primarily focuses on multi-scale feature fusion and extraction, with special attention to the model's segmentation effectiveness for detailed features, enhancing its ability to effectively detect camouflaged objects. CoFiNet adopts a coarse-to-fine strategy. A multi-scale feature integration module is laveraged to enhance the model's capability of fusing context feature. A multi-activation selective kernel module is leveraged to grant the model the ability to autonomously alter its receptive field, enabling it to selectively choose an appropriate receptive field for camouflaged objects of different sizes. During mask generation, we employ the dual-mask strategy for image segmentation, separating the reconstruction of coarse and fine masks, which significantly enhances the model's learning capacity for details. Comprehensive experiments were conducted on four different datasets, demonstrating that CoFiNet achieves state-of-the-art performance across all datasets. The experiment results of CoFiNet underscore its effectiveness in camouflage object detection and highlight its potential in various practical application scenarios.</li>
</ul>

<h3>Title: Rethinking the Starting Point: Enhancing Performance and Fairness of  Federated Learning via Collaborative Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Yun-Wei Chu, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher G. Brinton</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02225">https://arxiv.org/abs/2402.02225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02225">https://arxiv.org/pdf/2402.02225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02225]] Rethinking the Starting Point: Enhancing Performance and Fairness of  Federated Learning via Collaborative Pre-Training(https://arxiv.org/abs/2402.02225)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate, fair</a></li>
<li><strong>Abstract: </strong>Most existing federated learning (FL) methodologies have assumed training begins from a randomly initialized model. Recently, several studies have empirically demonstrated that leveraging a pre-trained model can offer advantageous initializations for FL. In this paper, we propose a collaborative pre-training approach, CoPreFL, which strategically designs a pre-trained model to serve as a good initialization for any downstream FL task. The key idea of our pre-training algorithm is a meta-learning procedure which mimics downstream distributed scenarios, enabling it to adapt to any unforeseen FL task. CoPreFL's pre-training optimization procedure also strikes a balance between average performance and fairness, with the aim of addressing these competing challenges in downstream FL tasks through intelligent initializations. Extensive experimental results validate that our pre-training method provides a robust initialization for any unseen downstream FL task, resulting in enhanced average performance and more equitable predictions.</li>
</ul>

<h3>Title: Invisible Finger: Practical Electromagnetic Interference Attack on  Touchscreen-based Electronic Devices</h3>
<ul>
<li><strong>Authors: </strong>Haoqi Shan, Boyi Zhang, Zihao Zhan, Dean Sullivan, Shuo Wang, Yier Jin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02227">https://arxiv.org/abs/2402.02227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02227">https://arxiv.org/pdf/2402.02227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02227]] Invisible Finger: Practical Electromagnetic Interference Attack on  Touchscreen-based Electronic Devices(https://arxiv.org/abs/2402.02227)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Touchscreen-based electronic devices such as smart phones and smart tablets are widely used in our daily life. While the security of electronic devices have been heavily investigated recently, the resilience of touchscreens against various attacks has yet to be thoroughly investigated. In this paper, for the first time, we show that touchscreen-based electronic devices are vulnerable to intentional electromagnetic interference (IEMI) attacks in a systematic way and how to conduct this attack in a practical way. Our contribution lies in not just demonstrating the attack, but also analyzing and quantifying the underlying mechanism allowing the novel IEMI attack on touchscreens in detail. We show how to calculate both the minimum amount of electric field and signal frequency required to induce touchscreen ghost touches. We further analyze our IEMI attack on real touchscreens with different magnitudes, frequencies, duration, and multitouch patterns. The mechanism of controlling the touchscreen-enabled electronic devices with IEMI signals is also elaborated. We design and evaluate an out-of-sight touchscreen locator and touch injection feedback mechanism to assist a practical IEMI attack. Our attack works directly on the touchscreen circuit regardless of the touchscreen scanning mechanism or operating system. Our attack can inject short-tap, long-press, and omni-directional gestures on touchscreens from a distance larger than the average thickness of common tabletops. Compared with the state-of-the-art touchscreen attack, ours can accurately inject different types of touch events without the need for sensing signal synchronization, which makes our attack more robust and practical. In addition, rather than showing a simple proof-of-concept attack, we present and demonstrate the first ready-to-use IEMI based touchscreen attack vector with end-to-end attack scenarios.</li>
</ul>

<h3>Title: Federated Learning with Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Adrien Banse, Jan Kreischer, Xavier Oliva i Jrgens</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02230">https://arxiv.org/abs/2402.02230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02230">https://arxiv.org/pdf/2402.02230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02230]] Federated Learning with Differential Privacy(https://arxiv.org/abs/2402.02230)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL), as a type of distributed machine learning, is capable of significantly preserving client's private data from being shared among different parties. Nevertheless, private information can still be divulged by analyzing uploaded parameter weights from clients. In this report, we showcase our empirical benchmark of the effect of the number of clients and the addition of differential privacy (DP) mechanisms on the performance of the model on different types of data. Our results show that non-i.i.d and small datasets have the highest decrease in performance in a distributed and differentially private setting.</li>
</ul>

<h3>Title: Image Fusion via Vision-Language Model</h3>
<ul>
<li><strong>Authors: </strong>Zixiang Zhao, Lilun Deng, Haowen Bai, Yukun Cui, Zhipeng Zhang, Yulun Zhang, Haotong Qin, Dongdong Chen, Jiangshe Zhang, Peng Wang, Luc Van Gool</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02235">https://arxiv.org/abs/2402.02235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02235">https://arxiv.org/pdf/2402.02235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02235]] Image Fusion via Vision-Language Model(https://arxiv.org/abs/2402.02235)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Image fusion integrates essential information from multiple source images into a single composite, emphasizing the highlighting structure and textures, and refining imperfect areas. Existing methods predominantly focus on pixel-level and semantic visual features for recognition. However, they insufficiently explore the deeper semantic information at a text-level beyond vision. Therefore, we introduce a novel fusion paradigm named image Fusion via vIsion-Language Model (FILM), for the first time, utilizing explicit textual information in different source images to guide image fusion. In FILM, input images are firstly processed to generate semantic prompts, which are then fed into ChatGPT to obtain rich textual descriptions. These descriptions are fused in the textual domain and guide the extraction of crucial visual features from the source images through cross-attention, resulting in a deeper level of contextual understanding directed by textual semantic information. The final fused image is created by vision feature decoder. This paradigm achieves satisfactory results in four image fusion tasks: infrared-visible, medical, multi-exposure, and multi-focus image fusion. We also propose a vision-language dataset containing ChatGPT-based paragraph descriptions for the ten image fusion datasets in four fusion tasks, facilitating future research in vision-language model-based image fusion. Code and dataset will be released.</li>
</ul>

<h3>Title: Distributional Reduction: Unifying Dimensionality Reduction and  Clustering with Gromov-Wasserstein Projection</h3>
<ul>
<li><strong>Authors: </strong>Hugues Van Assel, Cdric Vincent-Cuaz, Nicolas Courty, Rmi Flamary, Pascal Frossard, Titouan Vayer</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02239">https://arxiv.org/abs/2402.02239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02239">https://arxiv.org/pdf/2402.02239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02239]] Distributional Reduction: Unifying Dimensionality Reduction and  Clustering with Gromov-Wasserstein Projection(https://arxiv.org/abs/2402.02239)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Unsupervised learning aims to capture the underlying structure of potentially large and high-dimensional datasets. Traditionally, this involves using dimensionality reduction methods to project data onto interpretable spaces or organizing points into meaningful clusters. In practice, these methods are used sequentially, without guaranteeing that the clustering aligns well with the conducted dimensionality reduction. In this work, we offer a fresh perspective: that of distributions. Leveraging tools from optimal transport, particularly the Gromov-Wasserstein distance, we unify clustering and dimensionality reduction into a single framework called distributional reduction. This allows us to jointly address clustering and dimensionality reduction with a single optimization problem. Through comprehensive experiments, we highlight the versatility and interpretability of our method and show that it outperforms existing approaches across a variety of image and genomics datasets.</li>
</ul>

<h3>Title: Recommendations on Statistical Randomness Test Batteries for  Cryptographic Purposes</h3>
<ul>
<li><strong>Authors: </strong>Elena Almaraz Luengo, Luis Javier Garca Villalba</a></li>
<li><strong>Subjects: </strong>cs.CR, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02240">https://arxiv.org/abs/2402.02240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02240">https://arxiv.org/pdf/2402.02240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02240]] Recommendations on Statistical Randomness Test Batteries for  Cryptographic Purposes(https://arxiv.org/abs/2402.02240)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Security in different applications is closely related to the goodness of the sequences generated for such purposes. Not only in Cryptography but also in other areas, it is necessary to obtain long sequences of random numbers or that, at least, behave as such. To decide whether the generator used produces sequences that are random, unpredictable and independent, statistical checks are needed. Different batteries of hypothesis tests have been proposed for this purpose. In this work, a survey of the main test batteries is presented, indicating their pros and cons, giving some guidelines for their use and presenting some practical examples.</li>
</ul>

<h3>Title: Beyond the Limits: A Survey of Techniques to Extend the Context Length  in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xindi Wang, Mahsa Salmani, Parsa Omidi, Xiangyu Ren, Mehdi Rezagholizadeh, Armaghan Eshaghi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02244">https://arxiv.org/abs/2402.02244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02244">https://arxiv.org/pdf/2402.02244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02244]] Beyond the Limits: A Survey of Techniques to Extend the Context Length  in Large Language Models(https://arxiv.org/abs/2402.02244)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, large language models (LLMs) have shown remarkable capabilities including understanding context, engaging in logical reasoning, and generating responses. However, this is achieved at the expense of stringent computational and memory requirements, hindering their ability to effectively support long input sequences. This survey provides an inclusive review of the recent techniques and methods devised to extend the sequence length in LLMs, thereby enhancing their capacity for long-context understanding. In particular, we review and categorize a wide range of techniques including architectural modifications, such as modified positional encoding and altered attention mechanisms, which are designed to enhance the processing of longer sequences while avoiding a proportional increase in computational requirements. The diverse methodologies investigated in this study can be leveraged across different phases of LLMs, i.e., training, fine-tuning and inference. This enables LLMs to efficiently process extended sequences. The limitations of the current methodologies is discussed in the last section along with the suggestions for future research directions, underscoring the importance of sequence length in the continued advancement of LLMs.</li>
</ul>

<h3>Title: Revisiting Generative Adversarial Networks for Binary Semantic  Segmentation on Imbalanced Datasets</h3>
<ul>
<li><strong>Authors: </strong>Lei Xu, Moncef Gabbouj</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02245">https://arxiv.org/abs/2402.02245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02245">https://arxiv.org/pdf/2402.02245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02245]] Revisiting Generative Adversarial Networks for Binary Semantic  Segmentation on Imbalanced Datasets(https://arxiv.org/abs/2402.02245)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Anomalous pavement surface conditions detection aims to detect pixels representing anomalous states, such as cracks, on pavement surface images automatically by algorithms. Recently, deep learning models have been intensively applied to related topics with outstanding performance. However, most existing deep learning-related solutions rarely achieve a stable performance on diverse datasets. To address this issue, in this work, we propose a deep learning framework based on conditional Generative Adversarial Networks for anomalous region detection on pavement images at the pixel level. In particular, the proposed framework is developed to enhance the generator's ability to estimate the probability feature map from heterogeneous inputs with two training stages and multiscale feature representation. Moreover, several attention mechanisms are incorporated into the proposed framework to mitigate the performance deterioration of model training on severely imbalanced datasets. We implement experiments on six accessible pavement datasets. Extensive qualitative and quantitative experiments demonstrate that the proposed framework can achieve SOTA results on these datasets efficiently and robustly.</li>
</ul>

<h3>Title: ExTTNet: A Deep Learning Algorithm for Extracting Table Texts from  Invoice Images</h3>
<ul>
<li><strong>Authors: </strong>Adem Akdoan, Murat Kurt</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.IR, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02246">https://arxiv.org/abs/2402.02246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02246">https://arxiv.org/pdf/2402.02246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02246]] ExTTNet: A Deep Learning Algorithm for Extracting Table Texts from  Invoice Images(https://arxiv.org/abs/2402.02246)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this work, product tables in invoices are obtained autonomously via a deep learning model, which is named as ExTTNet. Firstly, text is obtained from invoice images using Optical Character Recognition (OCR) techniques. Tesseract OCR engine [37] is used for this process. Afterwards, the number of existing features is increased by using feature extraction methods to increase the accuracy. Labeling process is done according to whether each text obtained as a result of OCR is a table element or not. In this study, a multilayer artificial neural network model is used. The training has been carried out with an Nvidia RTX 3090 graphics card and taken $162$ minutes. As a result of the training, the F1 score is $0.92$.</li>
</ul>

<h3>Title: Frequency Explains the Inverse Correlation of Large Language Models'  Size, Training Data Amount, and Surprisal's Fit to Reading Times</h3>
<ul>
<li><strong>Authors: </strong>Byung-Doh Oh, Shisen Yue, William Schuler</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02255">https://arxiv.org/abs/2402.02255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02255">https://arxiv.org/pdf/2402.02255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02255]] Frequency Explains the Inverse Correlation of Large Language Models'  Size, Training Data Amount, and Surprisal's Fit to Reading Times(https://arxiv.org/abs/2402.02255)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that as Transformer-based language models become larger and are trained on very large amounts of data, the fit of their surprisal estimates to naturalistic human reading times degrades. The current work presents a series of analyses showing that word frequency is a key explanatory factor underlying these two trends. First, residual errors from four language model families on four corpora show that the inverse correlation between model size and fit to reading times is the strongest on the subset of least frequent words, which is driven by excessively accurate predictions of larger model variants. Additionally, training dynamics reveal that during later training steps, all model variants learn to predict rare words and that larger model variants do so more accurately, which explains the detrimental effect of both training data amount and model size on fit to reading times. Finally, a feature attribution analysis demonstrates that larger model variants are able to accurately predict rare words based on both an effectively longer context window size as well as stronger local associations compared to smaller model variants. Taken together, these results indicate that Transformer-based language models' surprisal estimates diverge from human-like expectations due to the superhumanly complex associations they learn for predicting rare words.</li>
</ul>

<h3>Title: XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event  Prediction</h3>
<ul>
<li><strong>Authors: </strong>Tingsong Xiao, Zelin Xu, Wenchong He, Jim Su, Yupu Zhang, Raymond Opoku, Ronald Ison, Jason Petho, Jiang Bian, Patrick Tighe, Parisa Rashidi, Zhe Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02258">https://arxiv.org/abs/2402.02258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02258">https://arxiv.org/pdf/2402.02258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02258]] XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event  Prediction(https://arxiv.org/abs/2402.02258)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Event prediction aims to forecast the time and type of a future event based on a historical event sequence. Despite its significance, several challenges exist, including the irregularity of time intervals between consecutive events, the existence of cycles, periodicity, and multi-scale event interactions, as well as the high computational costs for long event sequences. Existing neural temporal point processes (TPPs) methods do not capture the multi-scale nature of event interactions, which is common in many real-world applications such as clinical event data. To address these issues, we propose the cross-temporal-scale transformer (XTSFormer), designed specifically for irregularly timed event data. Our model comprises two vital components: a novel Feature-based Cycle-aware Time Positional Encoding (FCPE) that adeptly captures the cyclical nature of time, and a hierarchical multi-scale temporal attention mechanism. These scales are determined by a bottom-up clustering algorithm. Extensive experiments on several real-world datasets show that our XTSFormer outperforms several baseline methods in prediction performance.</li>
</ul>

<h3>Title: Data Quality Matters: Suicide Intention Detection on Social Media Posts  Using a RoBERTa-CNN Model</h3>
<ul>
<li><strong>Authors: </strong>Emily Lin, Jian Sun, Hsingyu Chen, Mohammad H. Mahoor</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02262">https://arxiv.org/abs/2402.02262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02262">https://arxiv.org/pdf/2402.02262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02262]] Data Quality Matters: Suicide Intention Detection on Social Media Posts  Using a RoBERTa-CNN Model(https://arxiv.org/abs/2402.02262)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Suicide remains a global health concern for the field of health, which urgently needs innovative approaches for early detection and intervention. In this paper, we focus on identifying suicidal intentions in SuicideWatch Reddit posts and present a novel approach to suicide detection using the cutting-edge RoBERTa-CNN model, a variant of RoBERTa (Robustly optimized BERT approach). RoBERTa is used for various Natural Language Processing (NLP) tasks, including text classification and sentiment analysis. The effectiveness of the RoBERTa lies in its ability to capture textual information and form semantic relationships within texts. By adding the Convolution Neural Network (CNN) layer to the original model, the RoBERTa enhances its ability to capture important patterns from heavy datasets. To evaluate the RoBERTa-CNN, we experimented on the Suicide and Depression Detection dataset and obtained solid results. For example, RoBERTa-CNN achieves 98% mean accuracy with the standard deviation (STD) of 0.0009. It also reaches over 97.5% mean AUC value with an STD of 0.0013. In the meanwhile, RoBERTa-CNN outperforms competitive methods, demonstrating the robustness and ability to capture nuanced linguistic patterns for suicidal intentions. Therefore, RoBERTa-CNN can detect suicide intention on text data very well.</li>
</ul>

<h3>Title: MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly  Mixed Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Yatong Bai, Mo Zhou, Vishal M. Patel, Somayeh Sojoudi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02263">https://arxiv.org/abs/2402.02263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02263">https://arxiv.org/pdf/2402.02263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02263]] MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly  Mixed Classifiers(https://arxiv.org/abs/2402.02263)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial robustness often comes at the cost of degraded accuracy, impeding the real-life application of robust classification models. Training-based solutions for better trade-offs are limited by incompatibilities with already-trained high-performance large models, necessitating the exploration of training-free ensemble approaches. Observing that robust models are more confident in correct predictions than in incorrect ones on clean and adversarial data alike, we speculate amplifying this "benign confidence property" can reconcile accuracy and robustness in an ensemble setting. To achieve so, we propose "MixedNUTS", a training-free method where the output logits of a robust classifier and a standard non-robust classifier are processed by nonlinear transformations with only three parameters, which are optimized through an efficient algorithm. MixedNUTS then converts the transformed logits into probabilities and mixes them as the overall output. On CIFAR-10, CIFAR-100, and ImageNet datasets, experimental results with custom strong adaptive attacks demonstrate MixedNUTS's vastly improved accuracy and near-SOTA robustness -- it boosts CIFAR-100 clean accuracy by 7.86 points, sacrificing merely 0.87 points in robust accuracy.</li>
</ul>

<h3>Title: Federated Learning with New Knowledge: Fundamentals, Advances, and  Futures</h3>
<ul>
<li><strong>Authors: </strong>Lixu Wang, Yang Zhao, Jiahua Dong, Ating Yin, Qinbin Li, Xiao Wang, Dusit Niyato, Qi Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02268">https://arxiv.org/abs/2402.02268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02268">https://arxiv.org/pdf/2402.02268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02268]] Federated Learning with New Knowledge: Fundamentals, Advances, and  Futures(https://arxiv.org/abs/2402.02268)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a privacy-preserving distributed learning approach that is rapidly developing in an era where privacy protection is increasingly valued. It is this rapid development trend, along with the continuous emergence of new demands for FL in the real world, that prompts us to focus on a very important problem: Federated Learning with New Knowledge. The primary challenge here is to effectively incorporate various new knowledge into existing FL systems and evolve these systems to reduce costs, extend their lifespan, and facilitate sustainable development. In this paper, we systematically define the main sources of new knowledge in FL, including new features, tasks, models, and algorithms. For each source, we thoroughly analyze and discuss how to incorporate new knowledge into existing FL systems and examine the impact of the form and timing of new knowledge arrival on the incorporation process. Furthermore, we comprehensively discuss the potential future directions for FL with new knowledge, considering a variety of factors such as scenario setups, efficiency, and security. There is also a continuously updating repository for this topic: https://github.com/conditionWang/FLNK.</li>
</ul>

<h3>Title: SudokuSens: Enhancing Deep Learning Robustness for IoT Sensing  Applications using a Generative Approach</h3>
<ul>
<li><strong>Authors: </strong>Tianshi Wang, Jinyang Li, Ruijie Wang, Denizhan Kara, Shengzhong Liu, Davis Wertheimer, Antoni Viros-i-Martin, Raghu Ganti, Mudhakar Srivatsa, Tarek Abdelzaher</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02275">https://arxiv.org/abs/2402.02275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02275">https://arxiv.org/pdf/2402.02275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02275]] SudokuSens: Enhancing Deep Learning Robustness for IoT Sensing  Applications using a Generative Approach(https://arxiv.org/abs/2402.02275)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces SudokuSens, a generative framework for automated generation of training data in machine-learning-based Internet-of-Things (IoT) applications, such that the generated synthetic data mimic experimental configurations not encountered during actual sensor data collection. The framework improves the robustness of resulting deep learning models, and is intended for IoT applications where data collection is expensive. The work is motivated by the fact that IoT time-series data entangle the signatures of observed objects with the confounding intrinsic properties of the surrounding environment and the dynamic environmental disturbances experienced. To incorporate sufficient diversity into the IoT training data, one therefore needs to consider a combinatorial explosion of training cases that are multiplicative in the number of objects considered and the possible environmental conditions in which such objects may be encountered. Our framework substantially reduces these multiplicative training needs. To decouple object signatures from environmental conditions, we employ a Conditional Variational Autoencoder (CVAE) that allows us to reduce data collection needs from multiplicative to (nearly) linear, while synthetically generating (data for) the missing conditions. To obtain robustness with respect to dynamic disturbances, a session-aware temporal contrastive learning approach is taken. Integrating the aforementioned two approaches, SudokuSens significantly improves the robustness of deep learning for IoT applications. We explore the degree to which SudokuSens benefits downstream inference tasks in different data sets and discuss conditions under which the approach is particularly effective.</li>
</ul>

<h3>Title: SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State  Tracking</h3>
<ul>
<li><strong>Authors: </strong>Atharva Kulkarni, Bo-Hsiang Tseng, Joel Ruben Antony Moniz, Dhivya Piraviperumal, Hong Yu, Shruti Bhargava</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02285">https://arxiv.org/abs/2402.02285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02285">https://arxiv.org/pdf/2402.02285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02285]] SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State  Tracking(https://arxiv.org/abs/2402.02285)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-context learning with Large Language Models (LLMs) has emerged as a promising avenue of research in Dialog State Tracking (DST). However, the best-performing in-context learning methods involve retrieving and adding similar examples to the prompt, requiring access to labeled training data. Procuring such training data for a wide range of domains and applications is time-consuming, expensive, and, at times, infeasible. While zero-shot learning requires no training data, it significantly lags behind the few-shot setup. Thus, `\textit{Can we efficiently generate synthetic data for any dialogue schema to enable few-shot prompting?}' Addressing this question, we propose \method, a data generation framework tailored for DST, utilizing LLMs. Our approach only requires the dialogue schema and a few hand-crafted dialogue templates to synthesize natural, coherent, and free-flowing dialogues with DST annotations. Few-shot learning using data from {\method} results in $4-5%$ improvement in Joint Goal Accuracy over the zero-shot baseline on MultiWOZ 2.1 and 2.4. Remarkably, our few-shot learning approach recovers nearly $98%$ of the performance compared to the few-shot setup using human-annotated training data. Our synthetic data and code can be accessed at https://github.com/apple/ml-synthdst</li>
</ul>

<h3>Title: Multi-Level Feature Aggregation and Recursive Alignment Network for  Real-Time Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yanhua Zhang, Ke Zhang, Jingyu Wang, Yulin Wu, Wuwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02286">https://arxiv.org/abs/2402.02286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02286">https://arxiv.org/pdf/2402.02286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02286]] Multi-Level Feature Aggregation and Recursive Alignment Network for  Real-Time Semantic Segmentation(https://arxiv.org/abs/2402.02286)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Real-time semantic segmentation is a crucial research for real-world applications. However, many methods lay particular emphasis on reducing the computational complexity and model size, while largely sacrificing the accuracy. In some scenarios, such as autonomous navigation and driver assistance system, accuracy and speed are equally important. To tackle this problem, we propose a novel Multi-level Feature Aggregation and Recursive Alignment Network (MFARANet), aiming to achieve high segmentation accuracy at real-time inference speed. We employ ResNet-18 as the backbone to ensure efficiency, and propose three core components to compensate for the reduced model capacity due to the shallow backbone. Specifically, we first design Multi-level Feature Aggregation Module (MFAM) to aggregate the hierarchical features in the encoder to each scale to benefit subsequent spatial alignment and multi-scale inference. Then, we build Recursive Alignment Module (RAM) by combining the flow-based alignment module with recursive upsampling architecture for accurate and efficient spatial alignment between multi-scale score maps. Finally, the Adaptive Scores Fusion Module (ASFM) is proposed to adaptively fuse multi-scale scores so that the final prediction can favor objects of multiple scales. Comprehensive experiments on three benchmark datasets including Cityscapes, CamVid and PASCAL-Context show the effectiveness and efficiency of our method. In particular, we achieve a better balance between speed and accuracy than state-of-the-art real-time methods on Cityscapes and CamVid datasets. Code is available at: https://github.com/Yanhua-Zhang/MFARANet.</li>
</ul>

<h3>Title: $\textit{A Contrario}$ Paradigm for YOLO-based Infrared Small Target  Detection</h3>
<ul>
<li><strong>Authors: </strong>Alina Ciocarlan, Sylvie Le Hgarat-Mascle, Sidonie Lefebvre, Arnaud Woiselle, Clara Barbanson</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02288">https://arxiv.org/abs/2402.02288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02288">https://arxiv.org/pdf/2402.02288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02288]] $\textit{A Contrario}$ Paradigm for YOLO-based Infrared Small Target  Detection(https://arxiv.org/abs/2402.02288)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Detecting small to tiny targets in infrared images is a challenging task in computer vision, especially when it comes to differentiating these targets from noisy or textured backgrounds. Traditional object detection methods such as YOLO struggle to detect tiny objects compared to segmentation neural networks, resulting in weaker performance when detecting small targets. To reduce the number of false alarms while maintaining a high detection rate, we introduce an $\textit{a contrario}$ decision criterion into the training of a YOLO detector. The latter takes advantage of the $\textit{unexpectedness}$ of small targets to discriminate them from complex backgrounds. Adding this statistical criterion to a YOLOv7-tiny bridges the performance gap between state-of-the-art segmentation methods for infrared small target detection and object detection networks. It also significantly increases the robustness of YOLO towards few-shot settings.</li>
</ul>

<h3>Title: SemPool: Simple, robust, and interpretable KG pooling for enhancing  language models</h3>
<ul>
<li><strong>Authors: </strong>Costas Mavromatis, Petros Karypis, George Karypis</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02289">https://arxiv.org/abs/2402.02289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02289">https://arxiv.org/pdf/2402.02289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02289]] SemPool: Simple, robust, and interpretable KG pooling for enhancing  language models(https://arxiv.org/abs/2402.02289)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Knowledge Graph (KG) powered question answering (QA) performs complex reasoning over language semantics as well as knowledge facts. Graph Neural Networks (GNNs) learn to aggregate information from the underlying KG, which is combined with Language Models (LMs) for effective reasoning with the given question. However, GNN-based methods for QA rely on the graph information of the candidate answer nodes, which limits their effectiveness in more challenging settings where critical answer information is not included in the KG. We propose a simple graph pooling approach that learns useful semantics of the KG that can aid the LM's reasoning and that its effectiveness is robust under graph perturbations. Our method, termed SemPool, represents KG facts with pre-trained LMs, learns to aggregate their semantic information, and fuses it at different layers of the LM. Our experimental results show that SemPool outperforms state-of-the-art GNN-based methods by 2.27% accuracy points on average when answer information is missing from the KG. In addition, SemPool offers interpretability on what type of graph information is fused at different LM layers.</li>
</ul>

<h3>Title: Polyp-DAM: Polyp segmentation via depth anything model</h3>
<ul>
<li><strong>Authors: </strong>Zhuoran Zheng, Chen Wu, Wei Wang, Yeying Jin, Xiuyi Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02298">https://arxiv.org/abs/2402.02298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02298">https://arxiv.org/pdf/2402.02298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02298]] Polyp-DAM: Polyp segmentation via depth anything model(https://arxiv.org/abs/2402.02298)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recently, large models (Segment Anything model) came on the scene to provide a new baseline for polyp segmentation tasks. This demonstrates that large models with a sufficient image level prior can achieve promising performance on a given task. In this paper, we unfold a new perspective on polyp segmentation modeling by leveraging the Depth Anything Model (DAM) to provide depth prior to polyp segmentation models. Specifically, the input polyp image is first passed through a frozen DAM to generate a depth map. The depth map and the input polyp images are then concatenated and fed into a convolutional neural network with multiscale to generate segmented images. Extensive experimental results demonstrate the effectiveness of our method, and in addition, we observe that our method still performs well on images of polyps with noise. The URL of our code is \url{https://github.com/zzr-idam/Polyp-DAM}.</li>
</ul>

<h3>Title: A Review and Comparison of AI Enhanced Side Channel Analysis</h3>
<ul>
<li><strong>Authors: </strong>Max Panoff, Honggang Yu, Haoqi Shan, Yier Jin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02299">https://arxiv.org/abs/2402.02299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02299">https://arxiv.org/pdf/2402.02299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02299]] A Review and Comparison of AI Enhanced Side Channel Analysis(https://arxiv.org/abs/2402.02299)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack</a></li>
<li><strong>Abstract: </strong>Side Channel Analysis (SCA) presents a clear threat to privacy and security in modern computing systems. The vast majority of communications are secured through cryptographic algorithms. These algorithms are often provably-secure from a cryptographical perspective, but their implementation on real hardware introduces vulnerabilities. Adversaries can exploit these vulnerabilities to conduct SCA and recover confidential information, such as secret keys or internal states. The threat of SCA has greatly increased as machine learning, and in particular deep learning, enhanced attacks become more common. In this work, we will examine the latest state-of-the-art deep learning techniques for side channel analysis, the theory behind them, and how they are conducted. Our focus will be on profiling attacks using deep learning techniques, but we will also examine some new and emerging methodologies enhanced by deep learning techniques, such as non-profiled attacks, artificial trace generation, and others. Finally, different deep learning enhanced SCA schemes attempted against the ANSSI SCA Database (ASCAD) and their relative performance will be evaluated and compared. This will lead to new research directions to secure cryptographic implementations against the latest SCA attacks.</li>
</ul>

<h3>Title: Jailbreaking Attack against Multimodal Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Zhenxing Niu, Haodong Ren, Xinbo Gao, Gang Hua, Rong Jin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02309">https://arxiv.org/abs/2402.02309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02309">https://arxiv.org/pdf/2402.02309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02309]] Jailbreaking Attack against Multimodal Large Language Model(https://arxiv.org/abs/2402.02309)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>This paper focuses on jailbreaking attacks against multi-modal large language models (MLLMs), seeking to elicit MLLMs to generate objectionable responses to harmful user queries. A maximum likelihood-based algorithm is proposed to find an \emph{image Jailbreaking Prompt} (imgJP), enabling jailbreaks against MLLMs across multiple unseen prompts and images (i.e., data-universal property). Our approach exhibits strong model-transferability, as the generated imgJP can be transferred to jailbreak various models, including MiniGPT-v2, LLaVA, InstructBLIP, and mPLUG-Owl2, in a black-box manner. Moreover, we reveal a connection between MLLM-jailbreaks and LLM-jailbreaks. As a result, we introduce a construction-based method to harness our approach for LLM-jailbreaks, demonstrating greater efficiency than current state-of-the-art methods. The code is available here. \textbf{Warning: some content generated by language models may be offensive to some readers.}</li>
</ul>

<h3>Title: Selecting Large Language Model to Fine-tune via Rectified Scaling Law</h3>
<ul>
<li><strong>Authors: </strong>Haowei Lin, Baizhou Huang, Haotian Ye, Qinyu Chen, Zihao Wang, Sujian Li, Jianzhu Ma, Xiaojun Wan, James Zou, Yitao Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02314">https://arxiv.org/abs/2402.02314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02314">https://arxiv.org/pdf/2402.02314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02314]] Selecting Large Language Model to Fine-tune via Rectified Scaling Law(https://arxiv.org/abs/2402.02314)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The ever-growing ecosystem of LLMs has posed a challenge in selecting the most appropriate pre-trained model to fine-tune amidst a sea of options. Given constrained resources, fine-tuning all models and making selections afterward is unrealistic. In this work, we formulate this resource-constrained selection task into predicting fine-tuning performance and illustrate its natural connection with scaling laws. Unlike pre-training, We find that the fine-tuning scaling curve includes not just the well-known "power phase" but also the previously unobserved "pre-power phase". We also explain why existing scaling laws fail to capture this phase transition phenomenon both theoretically and empirically. To address this, we introduce the concept of "pre-learned data size" into our rectified scaling law, which overcomes theoretical limitations and fits experimental results much better. By leveraging our law, we propose a novel LLM selection algorithm that selects the near-optimal model with hundreds of times less resource consumption, while other methods may provide negatively correlated selection.</li>
</ul>

<h3>Title: A Survey of Large Language Models in Finance (FinLLMs)</h3>
<ul>
<li><strong>Authors: </strong>Jean Lee, Nicholas Stevens, Soyeon Caren Han, Minseok Song</a></li>
<li><strong>Subjects: </strong>cs.CL, q-fin.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02315">https://arxiv.org/abs/2402.02315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02315">https://arxiv.org/pdf/2402.02315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02315]] A Survey of Large Language Models in Finance (FinLLMs)(https://arxiv.org/abs/2402.02315)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable capabilities across a wide variety of Natural Language Processing (NLP) tasks and have attracted attention from multiple domains, including financial services. Despite the extensive research into general-domain LLMs, and their immense potential in finance, Financial LLM (FinLLM) research remains limited. This survey provides a comprehensive overview of FinLLMs, including their history, techniques, performance, and opportunities and challenges. Firstly, we present a chronological overview of general-domain Pre-trained Language Models (PLMs) through to current FinLLMs, including the GPT-series, selected open-source LLMs, and financial LMs. Secondly, we compare five techniques used across financial PLMs and FinLLMs, including training methods, training data, and fine-tuning methods. Thirdly, we summarize the performance evaluations of six benchmark tasks and datasets. In addition, we provide eight advanced financial NLP tasks and datasets for developing more sophisticated FinLLMs. Finally, we discuss the opportunities and the challenges facing FinLLMs, such as hallucination, privacy, and efficiency. To support AI research in finance, we compile a collection of accessible datasets and evaluation benchmarks on GitHub.</li>
</ul>

<h3>Title: Your Diffusion Model is Secretly a Certifiably Robust Classifier</h3>
<ul>
<li><strong>Authors: </strong>Huanran Chen, Yinpeng Dong, Shitong Shao, Zhongkai Hao, Xiao Yang, Hang Su, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02316">https://arxiv.org/abs/2402.02316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02316">https://arxiv.org/pdf/2402.02316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02316]] Your Diffusion Model is Secretly a Certifiably Robust Classifier(https://arxiv.org/abs/2402.02316)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models are recently employed as generative classifiers for robust classification. However, a comprehensive theoretical understanding of the robustness of diffusion classifiers is still lacking, leading us to question whether they will be vulnerable to future stronger attacks. In this study, we propose a new family of diffusion classifiers, named Noised Diffusion Classifiers~(NDCs), that possess state-of-the-art certified robustness. Specifically, we generalize the diffusion classifiers to classify Gaussian-corrupted data by deriving the evidence lower bounds (ELBOs) for these distributions, approximating the likelihood using the ELBO, and calculating classification probabilities via Bayes' theorem. We integrate these generalized diffusion classifiers with randomized smoothing to construct smoothed classifiers possessing non-constant Lipschitzness. Experimental results demonstrate the superior certified robustness of our proposed NDCs. Notably, we are the first to achieve 80\%+ and 70\%+ certified robustness on CIFAR-10 under adversarial perturbations with $\ell_2$ norm less than 0.25 and 0.5, respectively, using a single off-the-shelf diffusion model without any additional data.</li>
</ul>

<h3>Title: INViT: A Generalizable Routing Problem Solver with Invariant Nested View  Transformer</h3>
<ul>
<li><strong>Authors: </strong>Han Fang, Zhihao Song, Paul Weng, Yutong Ban</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02317">https://arxiv.org/abs/2402.02317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02317">https://arxiv.org/pdf/2402.02317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02317]] INViT: A Generalizable Routing Problem Solver with Invariant Nested View  Transformer(https://arxiv.org/abs/2402.02317)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recently, deep reinforcement learning has shown promising results for learning fast heuristics to solve routing problems. Meanwhile, most of the solvers suffer from generalizing to an unseen distribution or distributions with different scales. To address this issue, we propose a novel architecture, called Invariant Nested View Transformer (INViT), which is designed to enforce a nested design together with invariant views inside the encoders to promote the generalizability of the learned solver. It applies a modified policy gradient algorithm enhanced with data augmentations. We demonstrate that the proposed INViT achieves a dominant generalization performance on both TSP and CVRP problems with various distributions and different problem scales.</li>
</ul>

<h3>Title: Diversity Measurement and Subset Selection for Instruction Tuning  Datasets</h3>
<ul>
<li><strong>Authors: </strong>Peiqi Wang, Yikang Shen, Zhen Guo, Matthew Stallone, Yoon Kim, Polina Golland, Rameswar Panda</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02318">https://arxiv.org/abs/2402.02318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02318">https://arxiv.org/pdf/2402.02318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02318]] Diversity Measurement and Subset Selection for Instruction Tuning  Datasets(https://arxiv.org/abs/2402.02318)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We aim to select data subsets for the fine-tuning of large language models to more effectively follow instructions. Prior work has emphasized the importance of diversity in dataset curation but relied on heuristics such as the number of tasks. In this paper, we use determinantal point processes to capture the diversity and quality of instruction tuning datasets for subset selection. We propose to measure dataset diversity with log determinant distance that is the distance between the dataset of interest and a maximally diverse reference dataset. Our experiments demonstrate that the proposed diversity measure in the normalized weight gradient space is correlated with downstream instruction-following performance. Consequently, it can be used to inform when data selection is the most helpful and to analyze dataset curation strategies. We demonstrate the utility of our approach on various instruction tuning datasets.</li>
</ul>

<h3>Title: Spin: An Efficient Secure Computation Framework with GPU Acceleration</h3>
<ul>
<li><strong>Authors: </strong>Wuxuan Jiang, Xiangjun Song, Shenbai Hong, Haijun Zhang, Wenxin Liu, Bo Zhao, Wei Xu, Yi Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02320">https://arxiv.org/abs/2402.02320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02320">https://arxiv.org/pdf/2402.02320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02320]] Spin: An Efficient Secure Computation Framework with GPU Acceleration(https://arxiv.org/abs/2402.02320)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, transformer</a></li>
<li><strong>Abstract: </strong>Accuracy and efficiency remain challenges for multi-party computation (MPC) frameworks. Spin is a GPU-accelerated MPC framework that supports multiple computation parties and a dishonest majority adversarial setup. We propose optimized protocols for non-linear functions that are critical for machine learning, as well as several novel optimizations specific to attention that is the fundamental unit of Transformer models, allowing Spin to perform non-trivial CNNs training and Transformer inference without sacrificing security. At the backend level, Spin leverages GPU, CPU, and RDMA-enabled smart network cards for acceleration. Comprehensive evaluations demonstrate that Spin can be up to $2\times$ faster than the state-of-the-art for deep neural network training. For inference on a Transformer model with 18.9 million parameters, our attention-specific optimizations enable Spin to achieve better efficiency, less communication, and better accuracy.</li>
</ul>

<h3>Title: Active Learning for Graphs with Noisy Structures</h3>
<ul>
<li><strong>Authors: </strong>Hongliang Chi, Cong Qi, Suhang Wang, Yao Ma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02321">https://arxiv.org/abs/2402.02321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02321">https://arxiv.org/pdf/2402.02321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02321]] Active Learning for Graphs with Noisy Structures(https://arxiv.org/abs/2402.02321)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have seen significant success in tasks such as node classification, largely contingent upon the availability of sufficient labeled nodes. Yet, the excessive cost of labeling large-scale graphs led to a focus on active learning on graphs, which aims for effective data selection to maximize downstream model performance. Notably, most existing methods assume reliable graph topology, while real-world scenarios often present noisy graphs. Given this, designing a successful active learning framework for noisy graphs is highly needed but challenging, as selecting data for labeling and obtaining a clean graph are two tasks naturally interdependent: selecting high-quality data requires clean graph structure while cleaning noisy graph structure requires sufficient labeled data. Considering the complexity mentioned above, we propose an active learning framework, GALClean, which has been specifically designed to adopt an iterative approach for conducting both data selection and graph purification simultaneously with best information learned from the prior iteration. Importantly, we summarize GALClean as an instance of the Expectation-Maximization algorithm, which provides a theoretical understanding of its design and mechanisms. This theory naturally leads to an enhanced version, GALClean+. Extensive experiments have demonstrated the effectiveness and robustness of our proposed method across various types and levels of noisy graphs.</li>
</ul>

<h3>Title: Dynamic Incremental Optimization for Best Subset Selection</h3>
<ul>
<li><strong>Authors: </strong>Shaogang Ren, Xiaoning Qian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02322">https://arxiv.org/abs/2402.02322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02322">https://arxiv.org/pdf/2402.02322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02322]] Dynamic Incremental Optimization for Best Subset Selection(https://arxiv.org/abs/2402.02322)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Best subset selection is considered the `gold standard' for many sparse learning problems. A variety of optimization techniques have been proposed to attack this non-smooth non-convex problem. In this paper, we investigate the dual forms of a family of $\ell_0$-regularized problems. An efficient primal-dual algorithm is developed based on the primal and dual problem structures. By leveraging the dual range estimation along with the incremental strategy, our algorithm potentially reduces redundant computation and improves the solutions of best subset selection. Theoretical analysis and experiments on synthetic and real-world datasets validate the efficiency and statistical properties of the proposed solutions.</li>
</ul>

<h3>Title: Bootstrapping Audio-Visual Segmentation by Strengthening Audio Cues</h3>
<ul>
<li><strong>Authors: </strong>Tianxiang Chen, Zhentao Tan, Tao Gong, Qi Chu, Yue Wu, Bin Liu, Le Lu, Jieping Ye, Nenghai Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02327">https://arxiv.org/abs/2402.02327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02327">https://arxiv.org/pdf/2402.02327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02327]] Bootstrapping Audio-Visual Segmentation by Strengthening Audio Cues(https://arxiv.org/abs/2402.02327)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>How to effectively interact audio with vision has garnered considerable interest within the multi-modality research field. Recently, a novel audio-visual segmentation (AVS) task has been proposed, aiming to segment the sounding objects in video frames under the guidance of audio cues. However, most existing AVS methods are hindered by a modality imbalance where the visual features tend to dominate those of the audio modality, due to a unidirectional and insufficient integration of audio cues. This imbalance skews the feature representation towards the visual aspect, impeding the learning of joint audio-visual representations and potentially causing segmentation inaccuracies. To address this issue, we propose AVSAC. Our approach features a Bidirectional Audio-Visual Decoder (BAVD) with integrated bidirectional bridges, enhancing audio cues and fostering continuous interplay between audio and visual modalities. This bidirectional interaction narrows the modality imbalance, facilitating more effective learning of integrated audio-visual representations. Additionally, we present a strategy for audio-visual frame-wise synchrony as fine-grained guidance of BAVD. This strategy enhances the share of auditory components in visual features, contributing to a more balanced audio-visual representation learning. Extensive experiments show that our method attains new benchmarks in AVS performance.</li>
</ul>

<h3>Title: Minusformer: Improving Time Series Forecasting by Progressively Learning  Residuals</h3>
<ul>
<li><strong>Authors: </strong>Daojun Liang, Haixia Zhang, Dongfeng Yuan, Bingzheng Zhang, Minggao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02332">https://arxiv.org/abs/2402.02332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02332">https://arxiv.org/pdf/2402.02332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02332]] Minusformer: Improving Time Series Forecasting by Progressively Learning  Residuals(https://arxiv.org/abs/2402.02332)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we find that ubiquitous time series (TS) forecasting models are prone to severe overfitting. To cope with this problem, we embrace a de-redundancy approach to progressively reinstate the intrinsic values of TS for future intervals. Specifically, we renovate the vanilla Transformer by reorienting the information aggregation mechanism from addition to subtraction. Then, we incorporate an auxiliary output branch into each block of the original model to construct a highway leading to the ultimate prediction. The output of subsequent modules in this branch will subtract the previously learned results, enabling the model to learn the residuals of the supervision signal, layer by layer. This designing facilitates the learning-driven implicit progressive decomposition of the input and output streams, empowering the model with heightened versatility, interpretability, and resilience against overfitting. Since all aggregations in the model are minus signs, which is called Minusformer. Extensive experiments demonstrate the proposed method outperform existing state-of-the-art methods, yielding an average performance improvement of 11.9% across various datasets.</li>
</ul>

<h3>Title: Copyright Protection in Generative AI: A Technical Perspective</h3>
<ul>
<li><strong>Authors: </strong>Jie Ren, Han Xu, Pengfei He, Yingqian Cui, Shenglai Zeng, Jiankun Zhang, Hongzhi Wen, Jiayuan Ding, Hui Liu, Yi Chang, Jiliang Tang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02333">https://arxiv.org/abs/2402.02333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02333">https://arxiv.org/pdf/2402.02333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02333]] Copyright Protection in Generative AI: A Technical Perspective(https://arxiv.org/abs/2402.02333)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, generative</a></li>
<li><strong>Abstract: </strong>Generative AI has witnessed rapid advancement in recent years, expanding their capabilities to create synthesized content such as text, images, audio, and code. The high fidelity and authenticity of contents generated by these Deep Generative Models (DGMs) have sparked significant copyright concerns. There have been various legal debates on how to effectively safeguard copyrights in DGMs. This work delves into this issue by providing a comprehensive overview of copyright protection from a technical perspective. We examine from two distinct viewpoints: the copyrights pertaining to the source data held by the data owners and those of the generative models maintained by the model builders. For data copyright, we delve into methods data owners can protect their content and DGMs can be utilized without infringing upon these rights. For model copyright, our discussion extends to strategies for preventing model theft and identifying outputs generated by specific models. Finally, we highlight the limitations of existing techniques and identify areas that remain unexplored. Furthermore, we discuss prospective directions for the future of copyright protection, underscoring its importance for the sustainable and ethical development of Generative AI.</li>
</ul>

<h3>Title: Arithmetic Feature Interaction Is Necessary for Deep Tabular Learning</h3>
<ul>
<li><strong>Authors: </strong>Yi Cheng, Renjun Hu, Haochao Ying, Xing Shi, Jian Wu, Wei Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02334">https://arxiv.org/abs/2402.02334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02334">https://arxiv.org/pdf/2402.02334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02334]] Arithmetic Feature Interaction Is Necessary for Deep Tabular Learning(https://arxiv.org/abs/2402.02334)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Until recently, the question of the effective inductive bias of deep models on tabular data has remained unanswered. This paper investigates the hypothesis that arithmetic feature interaction is necessary for deep tabular learning. To test this point, we create a synthetic tabular dataset with a mild feature interaction assumption and examine a modified transformer architecture enabling arithmetical feature interactions, referred to as AMFormer. Results show that AMFormer outperforms strong counterparts in fine-grained tabular data modeling, data efficiency in training, and generalization. This is attributed to its parallel additive and multiplicative attention operators and prompt-based optimization, which facilitate the separation of tabular samples in an extended space with arithmetically-engineered features. Our extensive experiments on real-world data also validate the consistent effectiveness, efficiency, and rationale of AMFormer, suggesting it has established a strong inductive bias for deep learning on tabular data. Code is available at https://github.com/aigc-apps/AMFormer.</li>
</ul>

<h3>Title: Learning Semantic Proxies from Visual Prompts for Parameter-Efficient  Fine-Tuning in Deep Metric Learning</h3>
<ul>
<li><strong>Authors: </strong>Li Ren, Chen Chen, Liqiang Wang, Kien Hua</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02340">https://arxiv.org/abs/2402.02340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02340">https://arxiv.org/pdf/2402.02340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02340]] Learning Semantic Proxies from Visual Prompts for Parameter-Efficient  Fine-Tuning in Deep Metric Learning(https://arxiv.org/abs/2402.02340)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep Metric Learning (DML) has long attracted the attention of the machine learning community as a key objective. Existing solutions concentrate on fine-tuning the pre-trained models on conventional image datasets. As a result of the success of recent pre-trained models trained from larger-scale datasets, it is challenging to adapt the model to the DML tasks in the local data domain while retaining the previously gained knowledge. In this paper, we investigate parameter-efficient methods for fine-tuning the pre-trained model for DML tasks. In particular, we propose a novel and effective framework based on learning Visual Prompts (VPT) in the pre-trained Vision Transformers (ViT). Based on the conventional proxy-based DML paradigm, we augment the proxy by incorporating the semantic information from the input image and the ViT, in which we optimize the visual prompts for each class. We demonstrate that our new approximations with semantic information are superior to representative capabilities, thereby improving metric learning performance. We conduct extensive experiments to demonstrate that our proposed framework is effective and efficient by evaluating popular DML benchmarks. In particular, we demonstrate that our fine-tuning method achieves comparable or even better performance than recent state-of-the-art full fine-tuning works of DML while tuning only a small percentage of total parameters.</li>
</ul>

<h3>Title: Closed-Loop Unsupervised Representation Disentanglement with $$-VAE  Distillation and Diffusion Probabilistic Feedback</h3>
<ul>
<li><strong>Authors: </strong>Xin Jin, Bohan Li, BAAO Xie, Wenyao Zhang, Jinming Liu, Ziqiang Li, Tao Yang, Wenjun Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02346">https://arxiv.org/abs/2402.02346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02346">https://arxiv.org/pdf/2402.02346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02346]] Closed-Loop Unsupervised Representation Disentanglement with $$-VAE  Distillation and Diffusion Probabilistic Feedback(https://arxiv.org/abs/2402.02346)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Representation disentanglement may help AI fundamentally understand the real world and thus benefit both discrimination and generation tasks. It currently has at least three unresolved core issues: (i) heavy reliance on label annotation and synthetic data -- causing poor generalization on natural scenarios; (ii) heuristic/hand-craft disentangling constraints make it hard to adaptively achieve an optimal training trade-off; (iii) lacking reasonable evaluation metric, especially for the real label-free data. To address these challenges, we propose a \textbf{C}losed-\textbf{L}oop unsupervised representation \textbf{Dis}entanglement approach dubbed \textbf{CL-Dis}. Specifically, we use diffusion-based autoencoder (Diff-AE) as a backbone while resorting to $\beta$-VAE as a co-pilot to extract semantically disentangled representations. The strong generation ability of diffusion model and the good disentanglement ability of VAE model are complementary. To strengthen disentangling, VAE-latent distillation and diffusion-wise feedback are interconnected in a closed-loop system for a further mutual promotion. Then, a self-supervised \textbf{Navigation} strategy is introduced to identify interpretable semantic directions in the disentangled latent space. Finally, a new metric based on content tracking is designed to evaluate the disentanglement effect. Experiments demonstrate the superiority of CL-Dis on applications like real image manipulation and visual analysis.</li>
</ul>

<h3>Title: Riemannian Preconditioned LoRA for Fine-Tuning Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Fangzhao Zhang, Mert Pilanci</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02347">https://arxiv.org/abs/2402.02347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02347">https://arxiv.org/pdf/2402.02347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02347]] Riemannian Preconditioned LoRA for Fine-Tuning Foundation Models(https://arxiv.org/abs/2402.02347)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>In this work we study the enhancement of Low Rank Adaptation (LoRA) fine-tuning procedure by introducing a Riemannian preconditioner in its optimization step. Specifically, we introduce an $r\times r$ preconditioner in each gradient step where $r$ is the LoRA rank. This preconditioner requires a small change to existing optimizer code and creates virtually minuscule storage and runtime overhead. Our experimental results with both large language models and text-to-image diffusion models show that with our preconditioner, the convergence and reliability of SGD and AdamW can be significantly enhanced. Moreover, the training process becomes much more robust to hyperparameter choices such as learning rate. Theoretically, we show that fine-tuning a two-layer ReLU network in the convex paramaterization with our preconditioner has convergence rate independent of condition number of the data matrix. This new Riemannian preconditioner, previously explored in classic low-rank matrix recovery, is introduced to deep learning tasks for the first time in our work. We release our code at https://github.com/pilancilab/Riemannian_Preconditioned_LoRA.</li>
</ul>

<h3>Title: Vision Transformer-based Multimodal Feature Fusion Network for Lymphoma  Segmentation on PET/CT Images</h3>
<ul>
<li><strong>Authors: </strong>Huan Huang, Liheng Qiu, Shenmiao Yang, Longxi Li, Jiaofen Nan, Yanting Li, Chuang Han, Fubao Zhu, Chen Zhao, Weihua Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02349">https://arxiv.org/abs/2402.02349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02349">https://arxiv.org/pdf/2402.02349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02349]] Vision Transformer-based Multimodal Feature Fusion Network for Lymphoma  Segmentation on PET/CT Images(https://arxiv.org/abs/2402.02349)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Background: Diffuse large B-cell lymphoma (DLBCL) segmentation is a challenge in medical image analysis. Traditional segmentation methods for lymphoma struggle with the complex patterns and the presence of DLBCL lesions. Objective: We aim to develop an accurate method for lymphoma segmentation with 18F-Fluorodeoxyglucose positron emission tomography (PET) and computed tomography (CT) images. Methods: Our lymphoma segmentation approach combines a vision transformer with dual encoders, adeptly fusing PET and CT data via multimodal cross-attention fusion (MMCAF) module. In this study, PET and CT data from 165 DLBCL patients were analyzed. A 5-fold cross-validation was employed to evaluate the performance and generalization ability of our method. Ground truths were annotated by experienced nuclear medicine experts. We calculated the total metabolic tumor volume (TMTV) and performed a statistical analysis on our results. Results: The proposed method exhibited accurate performance in DLBCL lesion segmentation, achieving a Dice similarity coefficient of 0.9173$\pm$0.0071, a Hausdorff distance of 2.71$\pm$0.25mm, a sensitivity of 0.9462$\pm$0.0223, and a specificity of 0.9986$\pm$0.0008. Additionally, a Pearson correlation coefficient of 0.9030$\pm$0.0179 and an R-square of 0.8586$\pm$0.0173 were observed in TMTV when measured on manual annotation compared to our segmentation results. Conclusion: This study highlights the advantages of MMCAF and vision transformer for lymphoma segmentation using PET and CT, offering great promise for computer-aided lymphoma diagnosis and treatment.</li>
</ul>

<h3>Title: Region-Based Representations Revisited</h3>
<ul>
<li><strong>Authors: </strong>Michal Shlapentokh-Rothman, Ansel Blume, Yao Xiao, Yuqun Wu, Sethuraman T V, Heyi Tao, Jae Yong Lee, Wilfredo Torres, Yu-Xiong Wang, Derek Hoiem</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02352">https://arxiv.org/abs/2402.02352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02352">https://arxiv.org/pdf/2402.02352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02352]] Region-Based Representations Revisited(https://arxiv.org/abs/2402.02352)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We investigate whether region-based representations are effective for recognition. Regions were once a mainstay in recognition approaches, but pixel and patch-based features are now used almost exclusively. We show that recent class-agnostic segmenters like SAM can be effectively combined with strong unsupervised representations like DINOv2 and used for a wide variety of tasks, including semantic segmentation, object-based image retrieval, and multi-image analysis. Once the masks and features are extracted, these representations, even with linear decoders, enable competitive performance, making them well suited to applications that require custom queries. The compactness of the representation also makes it well-suited to video analysis and other problems requiring inference across many images.</li>
</ul>

<h3>Title: Symbol: Generating Flexible Black-Box Optimizers through Symbolic  Equation Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Chen, Zeyuan Ma, Hongshu Guo, Yining Ma, Jie Zhang, Yue-jiao Gong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02355">https://arxiv.org/abs/2402.02355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02355">https://arxiv.org/pdf/2402.02355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02355]] Symbol: Generating Flexible Black-Box Optimizers through Symbolic  Equation Learning(https://arxiv.org/abs/2402.02355)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Recent Meta-learning for Black-Box Optimization (MetaBBO) methods harness neural networks to meta-learn configurations of traditional black-box optimizers. Despite their success, they are inevitably restricted by the limitations of predefined hand-crafted optimizers. In this paper, we present \textsc{Symbol}, a novel framework that promotes the automated discovery of black-box optimizers through symbolic equation learning. Specifically, we propose a Symbolic Equation Generator (SEG) that allows closed-form optimization rules to be dynamically generated for specific tasks and optimization steps. Within \textsc{Symbol}, we then develop three distinct strategies based on reinforcement learning, so as to meta-learn the SEG efficiently. Extensive experiments reveal that the optimizers generated by \textsc{Symbol} not only surpass the state-of-the-art BBO and MetaBBO baselines, but also exhibit exceptional zero-shot generalization abilities across entirely unseen tasks with different problem dimensions, population sizes, and optimization horizons. Furthermore, we conduct in-depth analyses of our \textsc{Symbol} framework and the optimization rules that it generates, underscoring its desirable flexibility and interpretability.</li>
</ul>

<h3>Title: Pruner: An Efficient Cross-Platform Tensor Compiler with Dual Awareness</h3>
<ul>
<li><strong>Authors: </strong>Liang Qiao, Jun Shi, Xiaoyu Hao, Xi Fang, Minfan Zhao, Ziqi Zhu, Junshi Chen, Hong An, Bing Li, Honghui Yuan, Xinyang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02361">https://arxiv.org/abs/2402.02361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02361">https://arxiv.org/pdf/2402.02361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02361]] Pruner: An Efficient Cross-Platform Tensor Compiler with Dual Awareness(https://arxiv.org/abs/2402.02361)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Tensor program optimization on Deep Learning Accelerators (DLAs) is critical for efficient model deployment. Although search-based Deep Learning Compilers (DLCs) have achieved significant performance gains compared to manual methods, they still suffer from the persistent challenges of low search efficiency and poor cross-platform adaptability. In this paper, we propose $\textbf{Pruner}$, following hardware/software co-design principles to hierarchically boost tensor program optimization. Pruner comprises two primary components: a Parameterized Static Analyzer ($\textbf{PSA}$) and a Pattern-aware Cost Model ($\textbf{PaCM}$). The former serves as a hardware-aware and formulaic performance analysis tool, guiding the pruning of the search space, while the latter enables the performance prediction of tensor programs according to the critical data-flow patterns. Furthermore, to ensure effective cross-platform adaptation, we design a Momentum Transfer Learning ($\textbf{MTL}$) strategy using a Siamese network, which establishes a bidirectional feedback mechanism to improve the robustness of the pre-trained cost model. The extensive experimental results demonstrate the effectiveness and advancement of the proposed Pruner in various tensor program tuning tasks across both online and offline scenarios, with low resource overhead. The code is available at https://github.com/qiaolian9/Pruner.</li>
</ul>

<h3>Title: Unification of Symmetries Inside Neural Networks: Transformer,  Feedforward and Neural ODE</h3>
<ul>
<li><strong>Authors: </strong>Koji Hashimoto, Yuji Hirono, Akiyoshi Sannai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, hep-th, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02362">https://arxiv.org/abs/2402.02362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02362">https://arxiv.org/pdf/2402.02362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02362]] Unification of Symmetries Inside Neural Networks: Transformer,  Feedforward and Neural ODE(https://arxiv.org/abs/2402.02362)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding the inner workings of neural networks, including transformers, remains one of the most challenging puzzles in machine learning. This study introduces a novel approach by applying the principles of gauge symmetries, a key concept in physics, to neural network architectures. By regarding model functions as physical observables, we find that parametric redundancies of various machine learning models can be interpreted as gauge symmetries. We mathematically formulate the parametric redundancies in neural ODEs, and find that their gauge symmetries are given by spacetime diffeomorphisms, which play a fundamental role in Einstein's theory of gravity. Viewing neural ODEs as a continuum version of feedforward neural networks, we show that the parametric redundancies in feedforward neural networks are indeed lifted to diffeomorphisms in neural ODEs. We further extend our analysis to transformer models, finding natural correspondences with neural ODEs and their gauge symmetries. The concept of gauge symmetries sheds light on the complex behavior of deep learning models through physics and provides us with a unifying perspective for analyzing various machine learning architectures.</li>
</ul>

<h3>Title: The Developmental Landscape of In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Jesse Hoogland, George Wang, Matthew Farrugia-Roberts, Liam Carroll, Susan Wei, Daniel Murfet</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02364">https://arxiv.org/abs/2402.02364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02364">https://arxiv.org/pdf/2402.02364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02364]] The Developmental Landscape of In-Context Learning(https://arxiv.org/abs/2402.02364)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We show that in-context learning emerges in transformers in discrete developmental stages, when they are trained on either language modeling or linear regression tasks. We introduce two methods for detecting the milestones that separate these stages, by probing the geometry of the population loss in both parameter space and function space. We study the stages revealed by these new methods using a range of behavioral and structural metrics to establish their validity.</li>
</ul>

<h3>Title: Transolver: A Fast Transformer Solver for PDEs on General Geometries</h3>
<ul>
<li><strong>Authors: </strong>Haixu Wu, Huakun Luo, Haowen Wang, Jianmin Wang, Mingsheng Long</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02366">https://arxiv.org/abs/2402.02366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02366">https://arxiv.org/pdf/2402.02366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02366]] Transolver: A Fast Transformer Solver for PDEs on General Geometries(https://arxiv.org/abs/2402.02366)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have empowered many milestones across various fields and have recently been applied to solve partial differential equations (PDEs). However, since PDEs are typically discretized into large-scale meshes with complex geometries, it is challenging for Transformers to capture intricate physical correlations directly from massive individual points. Going beyond superficial and unwieldy meshes, we present Transolver based on a more foundational idea, which is learning intrinsic physical states hidden behind discretized geometries. Specifically, we propose a new Physics-Attention to adaptively split the discretized domain into a series of learnable slices of flexible shapes, where mesh points under similar physical states will be ascribed to the same slice. By calculating attention to physics-aware tokens encoded from slices, Transovler can effectively capture intricate physical correlations under complex geometrics, which also empowers the solver with endogenetic geometry-general modeling capacity and can be efficiently computed in linear complexity. Transolver achieves consistent state-of-the-art with 22\% relative gain across six standard benchmarks and also excels in large-scale industrial simulations, including car and airfoil designs.</li>
</ul>

<h3>Title: Exploring Intrinsic Properties of Medical Images for Self-Supervised  Binary Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Pranav Singh, Jacopo Cirrone</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02367">https://arxiv.org/abs/2402.02367</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02367">https://arxiv.org/pdf/2402.02367</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02367]] Exploring Intrinsic Properties of Medical Images for Self-Supervised  Binary Semantic Segmentation(https://arxiv.org/abs/2402.02367)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in self-supervised learning have unlocked the potential to harness unlabeled data for auxiliary tasks, facilitating the learning of beneficial priors. This has been particularly advantageous in fields like medical image analysis, where labeled data are scarce. Although effective for classification tasks, this methodology has shown limitations in more complex applications, such as medical image segmentation. In this paper, we introduce Medical imaging Enhanced with Dynamic Self-Adaptive Semantic Segmentation (MedSASS), a dedicated self-supervised framework tailored for medical image segmentation. We evaluate MedSASS against existing state- of-the-art methods across four diverse medical datasets, showcasing its superiority. MedSASS outperforms existing CNN-based self-supervised methods by 3.83% and matches the performance of ViT-based methods. Furthermore, when MedSASS is trained end-to-end, covering both encoder and decoder, it demonstrates significant improvements of 14.4% for CNNs and 6% for ViT-based architectures compared to existing state-of-the-art self-supervised strategies.</li>
</ul>

<h3>Title: Timer: Transformers for Time Series Analysis at Scale</h3>
<ul>
<li><strong>Authors: </strong>Yong Liu, Haoran Zhang, Chenyu Li, Xiangdong Huang, Jianmin Wang, Mingsheng Long</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02368">https://arxiv.org/abs/2402.02368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02368">https://arxiv.org/pdf/2402.02368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02368]] Timer: Transformers for Time Series Analysis at Scale(https://arxiv.org/abs/2402.02368)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Deep learning has contributed remarkably to the advancement of time series analysis. Still, deep models can encounter performance bottlenecks in real-world small-sample scenarios, which can be concealed due to the performance saturation with small models on current benchmarks. Meanwhile, large models have demonstrated great powers in these scenarios through large-scale pre-training. Continuous progresses have been achieved as the emergence of large language models, exhibiting unprecedented ability in few-shot generalization, scalability, and task generality, which is however absent in time series models. To change the current practices of training small models on specific datasets from scratch, this paper aims at an early development of large time series models (LTSM). During pre-training, we curate large-scale datasets with up to 1 billion time points, unify heterogeneous time series into single-series sequence (S3) format, and develop the GPT-style architecture toward LTSMs. To meet diverse application needs, we convert forecasting, imputation, and anomaly detection of time series into a unified generative task. The outcome of this study is a Time Series Transformer (Timer), that is pre-trained by autoregressive next token prediction on large multi-domain datasets, and is fine-tuned to downstream scenarios with promising abilities as an LTSM.</li>
</ul>

<h3>Title: M$^3$Face: A Unified Multi-Modal Multilingual Framework for Human Face  Generation and Editing</h3>
<ul>
<li><strong>Authors: </strong>Mohammadreza Mofayezi, Reza Alipour, Mohammad Ali Kakavand, Ehsaneddin Asgari</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02369">https://arxiv.org/abs/2402.02369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02369">https://arxiv.org/pdf/2402.02369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02369]] M$^3$Face: A Unified Multi-Modal Multilingual Framework for Human Face  Generation and Editing(https://arxiv.org/abs/2402.02369)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Human face generation and editing represent an essential task in the era of computer vision and the digital world. Recent studies have shown remarkable progress in multi-modal face generation and editing, for instance, using face segmentation to guide image generation. However, it may be challenging for some users to create these conditioning modalities manually. Thus, we introduce M3Face, a unified multi-modal multilingual framework for controllable face generation and editing. This framework enables users to utilize only text input to generate controlling modalities automatically, for instance, semantic segmentation or facial landmarks, and subsequently generate face images. We conduct extensive qualitative and quantitative experiments to showcase our frameworks face generation and editing capabilities. Additionally, we propose the M3CelebA Dataset, a large-scale multi-modal and multilingual face dataset containing high-quality images, semantic segmentations, facial landmarks, and different captions for each image in multiple languages. The code and the dataset will be released upon publication.</li>
</ul>

<h3>Title: AutoTimes: Autoregressive Time Series Forecasters via Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Yong Liu, Guo Qin, Xiangdong Huang, Jianmin Wang, Mingsheng Long</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02370">https://arxiv.org/abs/2402.02370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02370">https://arxiv.org/pdf/2402.02370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02370]] AutoTimes: Autoregressive Time Series Forecasters via Large Language  Models(https://arxiv.org/abs/2402.02370)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Foundation models of time series have not been fully developed due to the limited availability of large-scale time series and the underexploration of scalable pre-training. Based on the similar sequential structure of time series and natural language, increasing research demonstrates the feasibility of leveraging large language models (LLM) for time series. Nevertheless, prior methods may overlook the consistency in aligning time series and natural language, resulting in insufficient utilization of the LLM potentials. To fully exploit the general-purpose token transitions learned from language modeling, we propose AutoTimes to repurpose LLMs as Autoregressive Time series forecasters, which is consistent with the acquisition and utilization of LLMs without updating the parameters. The consequent forecasters can handle flexible series lengths and achieve competitive performance as prevalent models. Further, we present token-wise prompting that utilizes corresponding timestamps to make our method applicable to multimodal scenarios. Analysis demonstrates our forecasters inherit zero-shot and in-context learning capabilities of LLMs. Empirically, AutoTimes exhibits notable method generality and achieves enhanced performance by basing on larger LLMs, additional texts, or time series as instructions.</li>
</ul>

<h3>Title: PromptRR: Diffusion Models as Prompt Generators for Single Image  Reflection Removal</h3>
<ul>
<li><strong>Authors: </strong>Tao Wang, Wanglong Lu, Kaihao Zhang, Wenhan Luo, Tae-Kyun Kim, Tong Lu, Hongdong Li, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02374">https://arxiv.org/abs/2402.02374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02374">https://arxiv.org/pdf/2402.02374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02374]] PromptRR: Diffusion Models as Prompt Generators for Single Image  Reflection Removal(https://arxiv.org/abs/2402.02374)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Existing single image reflection removal (SIRR) methods using deep learning tend to miss key low-frequency (LF) and high-frequency (HF) differences in images, affecting their effectiveness in removing reflections. To address this problem, this paper proposes a novel prompt-guided reflection removal (PromptRR) framework that uses frequency information as new visual prompts for better reflection performance. Specifically, the proposed framework decouples the reflection removal process into the prompt generation and subsequent prompt-guided restoration. For the prompt generation, we first propose a prompt pre-training strategy to train a frequency prompt encoder that encodes the ground-truth image into LF and HF prompts. Then, we adopt diffusion models (DMs) as prompt generators to generate the LF and HF prompts estimated by the pre-trained frequency prompt encoder. For the prompt-guided restoration, we integrate specially generated prompts into the PromptFormer network, employing a novel Transformer-based prompt block to effectively steer the model toward enhanced reflection removal. The results on commonly used benchmarks show that our method outperforms state-of-the-art approaches. The codes and models are available at https://github.com/TaoWangzj/PromptRR.</li>
</ul>

<h3>Title: NOAH: Learning Pairwise Object Category Attentions for Image  Classification</h3>
<ul>
<li><strong>Authors: </strong>Chao Li, Aojun Zhou, Anbang Yao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02377">https://arxiv.org/abs/2402.02377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02377">https://arxiv.org/pdf/2402.02377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02377]] NOAH: Learning Pairwise Object Category Attentions for Image  Classification(https://arxiv.org/abs/2402.02377)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>A modern deep neural network (DNN) for image classification tasks typically consists of two parts: a backbone for feature extraction, and a head for feature encoding and class predication. We observe that the head structures of mainstream DNNs adopt a similar feature encoding pipeline, exploiting global feature dependencies while disregarding local ones. In this paper, we revisit the feature encoding problem, and propose Non-glObal Attentive Head (NOAH) that relies on a new form of dot-product attention called pairwise object category attention (POCA), efficiently exploiting spatially dense category-specific attentions to augment classification performance. NOAH introduces a neat combination of feature split, transform and merge operations to learn POCAs at local to global scales. As a drop-in design, NOAH can be easily used to replace existing heads of various types of DNNs, improving classification performance while maintaining similar model efficiency. We validate the effectiveness of NOAH on ImageNet classification benchmark with 25 DNN architectures spanning convolutional neural networks, vision transformers and multi-layer perceptrons. In general, NOAH is able to significantly improve the performance of lightweight DNNs, e.g., showing 3.14\%|5.3\%|1.9\% top-1 accuracy improvement to MobileNetV2 (0.5x)|Deit-Tiny (0.5x)|gMLP-Tiny (0.5x). NOAH also generalizes well when applied to medium-size and large-size DNNs. We further show that NOAH retains its efficacy on other popular multi-class and multi-label image classification benchmarks as well as in different training regimes, e.g., showing 3.6\%|1.1\% mAP improvement to large ResNet101|ViT-Large on MS-COCO dataset. Project page: https://github.com/OSVAI/NOAH.</li>
</ul>

<h3>Title: Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an  Entity-Centric Perspective</h3>
<ul>
<li><strong>Authors: </strong>Chong Zhang, Yixi Zhao, Chenshu Yuan, Yi Tu, Ya Guo, Qi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02379">https://arxiv.org/abs/2402.02379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02379">https://arxiv.org/pdf/2402.02379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02379]] Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an  Entity-Centric Perspective(https://arxiv.org/abs/2402.02379)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Recently developed pre-trained text-and-layout models (PTLMs) have shown remarkable success in multiple information extraction tasks on visually-rich documents. However, the prevailing evaluation pipeline may not be sufficiently robust for assessing the information extraction ability of PTLMs, due to inadequate annotations within the benchmarks. Therefore, we claim the necessary standards for an ideal benchmark to evaluate the information extraction ability of PTLMs. We then introduce EC-FUNSD, an entity-centric benckmark designed for the evaluation of semantic entity recognition and entity linking on visually-rich documents. This dataset contains diverse formats of document layouts and annotations of semantic-driven entities and their relations. Moreover, this dataset disentangles the falsely coupled annotation of segment and entity that arises from the block-level annotation of FUNSD. Experiment results demonstrate that state-of-the-art PTLMs exhibit overfitting tendencies on the prevailing benchmarks, as their performance sharply decrease when the dataset bias is removed.</li>
</ul>

<h3>Title: Evaluating Large Language Models in Analysing Classroom Dialogue</h3>
<ul>
<li><strong>Authors: </strong>Yun Long, Haifeng Luo, Yu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02380">https://arxiv.org/abs/2402.02380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02380">https://arxiv.org/pdf/2402.02380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02380]] Evaluating Large Language Models in Analysing Classroom Dialogue(https://arxiv.org/abs/2402.02380)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study explores the application of Large Language Models (LLMs), specifically GPT-4, in the analysis of classroom dialogue, a crucial research task for both teaching diagnosis and quality improvement. Recognizing the knowledge-intensive and labor-intensive nature of traditional qualitative methods in educational research, this study investigates the potential of LLM to streamline and enhance the analysis process. The study involves datasets from a middle school, encompassing classroom dialogues across mathematics and Chinese classes. These dialogues were manually coded by educational experts and then analyzed using a customised GPT-4 model. This study focuses on comparing manual annotations with the outputs of GPT-4 to evaluate its efficacy in analyzing educational dialogues. Time efficiency, inter-coder agreement, and inter-coder reliability between human coders and GPT-4 are evaluated. Results indicate substantial time savings with GPT-4, and a high degree of consistency in coding between the model and human coders, with some discrepancies in specific codes. These findings highlight the strong potential of LLM in teaching evaluation and facilitation.</li>
</ul>

<h3>Title: Revisiting the Power of Prompt for Visual Tuning</h3>
<ul>
<li><strong>Authors: </strong>Yuzhu Wang, Lechao Cheng, Chaowei Fang, Dingwen Zhang, Manni Duan, Meng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02382">https://arxiv.org/abs/2402.02382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02382">https://arxiv.org/pdf/2402.02382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02382]] Revisiting the Power of Prompt for Visual Tuning(https://arxiv.org/abs/2402.02382)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual prompt tuning (VPT) is a promising solution incorporating learnable prompt tokens to customize pre-trained models for downstream tasks. However, VPT and its variants often encounter challenges like prompt initialization, prompt length, and subpar performance in self-supervised pretraining, hindering successful contextual adaptation. This study commences by exploring the correlation evolvement between prompts and patch tokens during proficient training. Inspired by the observation that the prompt tokens tend to share high mutual information with patch tokens, we propose initializing prompts with downstream token prototypes. The strategic initialization, a stand-in for the previous initialization, substantially improves performance in fine-tuning. To refine further, we optimize token construction with a streamlined pipeline that maintains excellent performance with almost no increase in computational expenses compared to VPT. Exhaustive experiments show our proposed approach outperforms existing methods by a remarkable margin. For instance, it surpasses full fine-tuning in 19 out of 24 tasks, using less than 0.4% of learnable parameters on the FGVC and VTAB-1K benchmarks. Notably, our method significantly advances the adaptation for self-supervised pretraining, achieving impressive task performance gains of at least 10% to 30%. Besides, the experimental results demonstrate the proposed SPT is robust to prompt lengths and scales well with model capacity and training data size. We finally provide an insightful exploration into the amount of target data facilitating the adaptation of pre-trained models to downstream tasks.</li>
</ul>

<h3>Title: Solution-oriented Agent-based Models Generation with Verifier-assisted  Iterative In-context Learning</h3>
<ul>
<li><strong>Authors: </strong>Tong Niu, Weihao Zhang, Rong Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02388">https://arxiv.org/abs/2402.02388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02388">https://arxiv.org/pdf/2402.02388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02388]] Solution-oriented Agent-based Models Generation with Verifier-assisted  Iterative In-context Learning(https://arxiv.org/abs/2402.02388)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Agent-based models (ABMs) stand as an essential paradigm for proposing and validating hypothetical solutions or policies aimed at addressing challenges posed by complex systems and achieving various objectives. This process demands labor-intensive endeavors and multidisciplinary expertise. Large language models (LLMs) encapsulating cross-domain knowledge and programming proficiency could potentially alleviate the difficulty of this process. However, LLMs excel in handling sequential information, making it challenging for analyzing the intricate interactions and nonlinear dynamics inherent in ABMs. Additionally, due to the lack of self-evaluation capability of LLMs, relying solely on LLMs is insufficient to effectively accomplish this process. In this paper, we present SAGE, a general solution-oriented ABM generation framework designed for automatic modeling and generating solutions for targeted problems. Unlike approaches reliant on expert handcrafting or resource-intensive neural network training, SAGE establishes a verifier-assisted iterative in-context learning process employing large language models (LLMs) to leverages their inherent cross-domain knowledge for tackling intricate demands from diverse domain scenarios. In SAGE, we introduce an semi-structured conceptual representation expliciting the intricate structures of ABMs and an objective representation to guide LLMs in modeling scenarios and proposing hypothetical solutions through in-context learning. To ensure the model executability and solution feasibility, SAGE devises a two-level verifier with chain-of-thought prompting tailored to the complex interactions and non-linear dynamics of ABMs, driving the iterative generation optimization. Moreover, we construct an evaluation dataset of solution-oriented ABMs from open sources.It contains practical models across various domains.</li>
</ul>

<h3>Title: KICGPT: Large Language Model with Knowledge in Context for Knowledge  Graph Completion</h3>
<ul>
<li><strong>Authors: </strong>Yanbin Wei, Qiushi Huang, James T. Kwok, Yu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02389">https://arxiv.org/abs/2402.02389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02389">https://arxiv.org/pdf/2402.02389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02389]] KICGPT: Large Language Model with Knowledge in Context for Knowledge  Graph Completion(https://arxiv.org/abs/2402.02389)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph incompleteness and supporting downstream applications. Many models have been proposed for KGC. They can be categorized into two main classes: triple-based and text-based approaches. Triple-based methods struggle with long-tail entities due to limited structural information and imbalanced entity distributions. Text-based methods alleviate this issue but require costly training for language models and specific finetuning for knowledge graphs, which limits their efficiency. To alleviate these limitations, in this paper, we propose KICGPT, a framework that integrates a large language model (LLM) and a triple-based KGC retriever. It alleviates the long-tail problem without incurring additional training overhead. KICGPT uses an in-context learning strategy called Knowledge Prompt, which encodes structural knowledge into demonstrations to guide the LLM. Empirical results on benchmark datasets demonstrate the effectiveness of KICGPT with smaller training overhead and no finetuning.</li>
</ul>

<h3>Title: FreDF: Learning to Forecast in Frequency Domain</h3>
<ul>
<li><strong>Authors: </strong>Hao Wang, Licheng Pan, Zhichao Chen, Degui Yang, Sen Zhang, Yifei Yang, Xinggao Liu, Haoxuan Li, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02399">https://arxiv.org/abs/2402.02399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02399">https://arxiv.org/pdf/2402.02399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02399]] FreDF: Learning to Forecast in Frequency Domain(https://arxiv.org/abs/2402.02399)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Time series modeling is uniquely challenged by the presence of autocorrelation in both historical and label sequences. Current research predominantly focuses on handling autocorrelation within the historical sequence but often neglects its presence in the label sequence. Specifically, emerging forecast models mainly conform to the direct forecast (DF) paradigm, generating multi-step forecasts under the assumption of conditional independence within the label sequence. This assumption disregards the inherent autocorrelation in the label sequence, thereby limiting the performance of DF-based models. In response to this gap, we introduce the Frequency-enhanced Direct Forecast (FreDF), which bypasses the complexity of label autocorrelation by learning to forecast in the frequency domain. Our experiments demonstrate that FreDF substantially outperforms existing state-of-the-art methods including iTransformer and is compatible with a variety of forecast models.</li>
</ul>

<h3>Title: GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large  Language Model</h3>
<ul>
<li><strong>Authors: </strong>Xuanchang Zhang, Zhuosheng Zhang, Hai Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02408">https://arxiv.org/abs/2402.02408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02408">https://arxiv.org/pdf/2402.02408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02408]] GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large  Language Model(https://arxiv.org/abs/2402.02408)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the rapid progress of large language models (LLMs), their task performance remains sensitive to prompt design. Recent studies have explored leveraging the LLM itself as an optimizer to identify optimal prompts that maximize task accuracy. However, when evaluating prompts, such approaches heavily rely on elusive manually annotated gold labels to calculate task accuracy for each candidate prompt, which hinders the widespread implementation and generality. To overcome the limitation, this work proposes a gold label-agnostic prompt evaluation (GLaPE) to alleviate dependence on gold labels. Motivated by the observed correlation between self-consistency and the accuracy of the answer, we adopt self-consistency as the initial evaluation score. Subsequently, we refine the scores of prompts producing identical answers to be mutually consistent. Experimental results show that GLaPE provides reliable evaluations uniform with accuracy, even in the absence of gold labels. Moreover, on six popular reasoning tasks, our GLaPE-based prompt optimization yields effective prompts comparable to accuracy-based ones. The code is publicly available at https://github.com/thunderous77/GLaPE.</li>
</ul>

<h3>Title: Aligner: Achieving Efficient Alignment through Weak-to-Strong Correction</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Ji, Boyuan Chen, Hantao Lou, Donghai Hong, Borong Zhang, Xuehai Pan, Juntao Dai, Yaodong Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02416">https://arxiv.org/abs/2402.02416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02416">https://arxiv.org/pdf/2402.02416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02416]] Aligner: Achieving Efficient Alignment through Weak-to-Strong Correction(https://arxiv.org/abs/2402.02416)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Efforts to align Large Language Models (LLMs) are mainly conducted via Reinforcement Learning from Human Feedback (RLHF) methods. However, RLHF encounters major challenges including training reward models, actor-critic engineering, and importantly, it requires access to LLM parameters. Here we introduce Aligner, a new efficient alignment paradigm that bypasses the whole RLHF process by learning the correctional residuals between the aligned and the unaligned answers. Our Aligner offers several key advantages. Firstly, it is an autoregressive seq2seq model that is trained on the query-answer-correction dataset via supervised learning; this offers a parameter-efficient alignment solution with minimal resources. Secondly, the Aligner facilitates weak-to-strong generalization; finetuning large pretrained models by Aligner's supervisory signals demonstrates strong performance boost. Thirdly, Aligner functions as a model-agnostic plug-and-play module, allowing for its direct application on different open-source and API-based models. Remarkably, Aligner-7B improves 11 different LLMs by 18% in helpfulness and 23% in harmlessness on average (GPT-4 by 26.9% and 17.5%). When finetuning (strong) Llama2-70B with (weak) Aligner-7B's supervision, we can improve Llama2 by 8.2% in helpfulness and 61.6% in harmlessness. See our dataset and code at \url{https://aligner2024.github.io}.</li>
</ul>

<h3>Title: Factuality of Large Language Models in the Year 2024</h3>
<ul>
<li><strong>Authors: </strong>Yuxia Wang, Minghan Wang, Muhammad Arslan Manzoor, Georgi Georgiev, Rocktim Jyoti Das, Preslav Nakov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02420">https://arxiv.org/abs/2402.02420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02420">https://arxiv.org/pdf/2402.02420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02420]] Factuality of Large Language Models in the Year 2024(https://arxiv.org/abs/2402.02420)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), especially when instruction-tuned for chat, have become part of our daily lives, freeing people from the process of searching, extracting, and integrating information from multiple sources by offering a straightforward answer to a variety of questions in a single place. Unfortunately, in many cases, LLM responses are factually incorrect, which limits their applicability in real-world scenarios. As a result, research on evaluating and improving the factuality of LLMs has attracted a lot of research attention recently. In this survey, we critically analyze existing work with the aim to identify the major challenges and their associated causes, pointing out to potential solutions for improving the factuality of LLMs, and analyzing the obstacles to automated factuality evaluation for open-ended text generation. We further offer an outlook on where future research should go.</li>
</ul>

<h3>Title: Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement  Learning with Diverse Human Feedback</h3>
<ul>
<li><strong>Authors: </strong>Yifu Yuan, Jianye Hao, Yi Ma, Zibin Dong, Hebin Liang, Jinyi Liu, Zhixin Feng, Kai Zhao, Yan Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02423">https://arxiv.org/abs/2402.02423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02423">https://arxiv.org/pdf/2402.02423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02423]] Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement  Learning with Diverse Human Feedback(https://arxiv.org/abs/2402.02423)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning with Human Feedback (RLHF) has received significant attention for performing tasks without the need for costly manual reward design by aligning human preferences. It is crucial to consider diverse human feedback types and various learning methods in different environments. However, quantifying progress in RLHF with diverse feedback is challenging due to the lack of standardized annotation platforms and widely used unified benchmarks. To bridge this gap, we introduce Uni-RLHF, a comprehensive system implementation tailored for RLHF. It aims to provide a complete workflow from real human feedback, fostering progress in the development of practical problems. Uni-RLHF contains three packages: 1) a universal multi-feedback annotation platform, 2) large-scale crowdsourced feedback datasets, and 3) modular offline RLHF baseline implementations. Uni-RLHF develops a user-friendly annotation interface tailored to various feedback types, compatible with a wide range of mainstream RL environments. We then establish a systematic pipeline of crowdsourced annotations, resulting in large-scale annotated datasets comprising more than 15 million steps across 30+ popular tasks. Through extensive experiments, the results in the collected datasets demonstrate competitive performance compared to those from well-designed manual rewards. We evaluate various design choices and offer insights into their strengths and potential areas of improvement. We wish to build valuable open-source platforms, datasets, and baselines to facilitate the development of more robust and reliable RLHF solutions based on realistic human feedback. The website is available at https://uni-rlhf.github.io/.</li>
</ul>

<h3>Title: Exploiting Low-level Representations for Ultra-Fast Road Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Huan Zhou, Feng Xue, Yucong Li, Shi Gong, Yiqun Li, Yu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02430">https://arxiv.org/abs/2402.02430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02430">https://arxiv.org/pdf/2402.02430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02430]] Exploiting Low-level Representations for Ultra-Fast Road Segmentation(https://arxiv.org/abs/2402.02430)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Achieving real-time and accuracy on embedded platforms has always been the pursuit of road segmentation methods. To this end, they have proposed many lightweight networks. However, they ignore the fact that roads are "stuff" (background or environmental elements) rather than "things" (specific identifiable objects), which inspires us to explore the feasibility of representing roads with low-level instead of high-level features. Surprisingly, we find that the primary stage of mainstream network models is sufficient to represent most pixels of the road for segmentation. Motivated by this, we propose a Low-level Feature Dominated Road Segmentation network (LFD-RoadSeg). Specifically, LFD-RoadSeg employs a bilateral structure. The spatial detail branch is firstly designed to extract low-level feature representation for the road by the first stage of ResNet-18. To suppress texture-less regions mistaken as the road in the low-level feature, the context semantic branch is then designed to extract the context feature in a fast manner. To this end, in the second branch, we asymmetrically downsample the input image and design an aggregation module to achieve comparable receptive fields to the third stage of ResNet-18 but with less time consumption. Finally, to segment the road from the low-level feature, a selective fusion module is proposed to calculate pixel-wise attention between the low-level representation and context feature, and suppress the non-road low-level response by this attention. On KITTI-Road, LFD-RoadSeg achieves a maximum F1-measure (MaxF) of 95.21% and an average precision of 93.71%, while reaching 238 FPS on a single TITAN Xp and 54 FPS on a Jetson TX2, all with a compact model size of just 936k parameters. The source code is available at https://github.com/zhouhuan-hust/LFD-RoadSeg.</li>
</ul>

<h3>Title: Learning Mutual Excitation for Hand-to-Hand and Human-to-Human  Interaction Recognition</h3>
<ul>
<li><strong>Authors: </strong>Mengyuan Liu, Chen Chen, Songtao Wu, Fanyang Meng, Hong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02431">https://arxiv.org/abs/2402.02431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02431">https://arxiv.org/pdf/2402.02431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02431]] Learning Mutual Excitation for Hand-to-Hand and Human-to-Human  Interaction Recognition(https://arxiv.org/abs/2402.02431)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recognizing interactive actions, including hand-to-hand interaction and human-to-human interaction, has attracted increasing attention for various applications in the field of video analysis and human-robot interaction. Considering the success of graph convolution in modeling topology-aware features from skeleton data, recent methods commonly operate graph convolution on separate entities and use late fusion for interactive action recognition, which can barely model the mutual semantic relationships between pairwise entities. To this end, we propose a mutual excitation graph convolutional network (me-GCN) by stacking mutual excitation graph convolution (me-GC) layers. Specifically, me-GC uses a mutual topology excitation module to firstly extract adjacency matrices from individual entities and then adaptively model the mutual constraints between them. Moreover, me-GC extends the above idea and further uses a mutual feature excitation module to extract and merge deep features from pairwise entities. Compared with graph convolution, our proposed me-GC gradually learns mutual information in each layer and each stage of graph convolution operations. Extensive experiments on a challenging hand-to-hand interaction dataset, i.e., the Assembely101 dataset, and two large-scale human-to-human interaction datasets, i.e., NTU60-Interaction and NTU120-Interaction consistently verify the superiority of our proposed method, which outperforms the state-of-the-art GCN-based and Transformer-based methods.</li>
</ul>

<h3>Title: Fast and interpretable Support Vector Classification based on the  truncated ANOVA decomposition</h3>
<ul>
<li><strong>Authors: </strong>Kseniya Akhalaya, Franziska Nestler, Daniel Potts</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02438">https://arxiv.org/abs/2402.02438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02438">https://arxiv.org/pdf/2402.02438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02438]] Fast and interpretable Support Vector Classification based on the  truncated ANOVA decomposition(https://arxiv.org/abs/2402.02438)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Support Vector Machines (SVMs) are an important tool for performing classification on scattered data, where one usually has to deal with many data points in high-dimensional spaces. We propose solving SVMs in primal form using feature maps based on trigonometric functions or wavelets. In small dimensional settings the Fast Fourier Transform (FFT) and related methods are a powerful tool in order to deal with the considered basis functions. For growing dimensions the classical FFT-based methods become inefficient due to the curse of dimensionality. Therefore, we restrict ourselves to multivariate basis functions, each one of them depends only on a small number of dimensions. This is motivated by the well-known sparsity of effects and recent results regarding the reconstruction of functions from scattered data in terms of truncated analysis of variance (ANOVA) decomposition, which makes the resulting model even interpretable in terms of importance of the features as well as their couplings. The usage of small superposition dimensions has the consequence that the computational effort no longer grows exponentially but only polynomially with respect to the dimension. In order to enforce sparsity regarding the basis coefficients, we use the frequently applied $\ell_2$-norm and, in addition, $\ell_1$-norm regularization. The found classifying function, which is the linear combination of basis functions, and its variance can then be analyzed in terms of the classical ANOVA decomposition of functions. Based on numerical examples we show that we are able to recover the signum of a function that perfectly fits our model assumptions. We obtain better results with $\ell_1$-norm regularization, both in terms of accuracy and clarity of interpretability.</li>
</ul>

<h3>Title: DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based  Trajectory Stitching</h3>
<ul>
<li><strong>Authors: </strong>Guanghe Li, Yixiang Shan, Zhengbang Zhu, Ting Long, Weinan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02439">https://arxiv.org/abs/2402.02439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02439">https://arxiv.org/pdf/2402.02439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02439]] DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based  Trajectory Stitching(https://arxiv.org/abs/2402.02439)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In offline reinforcement learning (RL), the performance of the learned policy highly depends on the quality of offline datasets. However, in many cases, the offline dataset contains very limited optimal trajectories, which poses a challenge for offline RL algorithms as agents must acquire the ability to transit to high-reward regions. To address this issue, we introduce Diffusion-based Trajectory Stitching (DiffStitch), a novel diffusion-based data augmentation pipeline that systematically generates stitching transitions between trajectories. DiffStitch effectively connects low-reward trajectories with high-reward trajectories, forming globally optimal trajectories to address the challenges faced by offline RL algorithms. Empirical experiments conducted on D4RL datasets demonstrate the effectiveness of DiffStitch across RL methodologies. Notably, DiffStitch demonstrates substantial enhancements in the performance of one-step methods (IQL), imitation learning methods (TD3+BC), and trajectory optimization methods (DT).</li>
</ul>

<h3>Title: LQER: Low-Rank Quantization Error Reconstruction for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Cheng Zhang, Jianyi Cheng, George A. Constantinides, Yiren Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02446">https://arxiv.org/abs/2402.02446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02446">https://arxiv.org/pdf/2402.02446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02446]] LQER: Low-Rank Quantization Error Reconstruction for LLMs(https://arxiv.org/abs/2402.02446)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Post-training quantization of Large Language Models (LLMs) is challenging. In this work, we introduce Low-rank Quantization Error Reduction (LQER), which combines quantization and low-rank approximation to recover the model capability. LQER leverages an activation-induced scale matrix to drive the singular value distribution of quantization error towards a desirable distribution, which enables nearly-lossless W4A8 quantization on various LLMs and downstream tasks without the need for knowledge distillation, grid search, or gradient-base iterative optimization. Unlike existing methods, the computation pattern of LQER eliminates the need for specialized Scatter and Gather processes to collect high-precision weights from irregular memory locations. Our W4A8 LLMs achieve near-lossless performance on six popular downstream tasks, while using 1.36$\times$ fewer hardware resources than the leading state-of-the-art method. We will open-source our framework once the paper is accepted.</li>
</ul>

<h3>Title: AI Art Neural Constellation: Revealing the Collective and Contrastive  State of AI-Generated and Human Art</h3>
<ul>
<li><strong>Authors: </strong>Faizan Farooq Khan, Diana Kim, Divyansh Jha, Youssef Mohamed, Hanna H Chang, Ahmed Elgammal, Luba Elliott, Mohamed Elhoseiny</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02453">https://arxiv.org/abs/2402.02453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02453">https://arxiv.org/pdf/2402.02453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02453]] AI Art Neural Constellation: Revealing the Collective and Contrastive  State of AI-Generated and Human Art(https://arxiv.org/abs/2402.02453)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Discovering the creative potentials of a random signal to various artistic expressions in aesthetic and conceptual richness is a ground for the recent success of generative machine learning as a way of art creation. To understand the new artistic medium better, we conduct a comprehensive analysis to position AI-generated art within the context of human art heritage. Our comparative analysis is based on an extensive dataset, dubbed ``ArtConstellation,'' consisting of annotations about art principles, likability, and emotions for 6,000 WikiArt and 3,200 AI-generated artworks. After training various state-of-the-art generative models, art samples are produced and compared with WikiArt data on the last hidden layer of a deep-CNN trained for style classification. We actively examined the various art principles to interpret the neural representations and used them to drive the comparative knowledge about human and AI-generated art. A key finding in the semantic analysis is that AI-generated artworks are visually related to the principle concepts for modern period art made in 1800-2000. In addition, through Out-Of-Distribution (OOD) and In-Distribution (ID) detection in CLIP space, we find that AI-generated artworks are ID to human art when they depict landscapes and geometric abstract figures, while detected as OOD when the machine art consists of deformed and twisted figures. We observe that machine-generated art is uniquely characterized by incomplete and reduced figuration. Lastly, we conducted a human survey about emotional experience. Color composition and familiar subjects are the key factors of likability and emotions in art appreciation. We propose our whole methodologies and collected dataset as our analytical framework to contrast human and AI-generated art, which we refer to as ``ArtNeuralConstellation''. Code is available at: https://github.com/faixan-khan/ArtNeuralConstellation</li>
</ul>

<h3>Title: A Survey on Decentralized Identifiers and Verifiable Credentials</h3>
<ul>
<li><strong>Authors: </strong>Carlo Mazzocca, Abbas Acar, Selcuk Uluagac, Rebecca Montanari, Paolo Bellavista, Mauro Conti</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02455">https://arxiv.org/abs/2402.02455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02455">https://arxiv.org/pdf/2402.02455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02455]] A Survey on Decentralized Identifiers and Verifiable Credentials(https://arxiv.org/abs/2402.02455)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Digital identity has always been considered the keystone for implementing secure and trustworthy communications among parties. The ever-evolving digital landscape has gone through many technological transformations that have also affected the way entities are digitally identified. During this digital evolution, identity management has shifted from centralized to decentralized approaches. The last era of this journey is represented by the emerging Self-Sovereign Identity (SSI), which gives users full control over their data. SSI leverages decentralized identifiers (DIDs) and verifiable credentials (VCs), which have been recently standardized by the World Wide Web Community (W3C). These technologies have the potential to build more secure and decentralized digital identity systems, remarkably contributing to strengthening the security of communications that typically involve many distributed participants. It is worth noting that the scope of DIDs and VCs extends beyond individuals, encompassing a broad range of entities including cloud, edge, and Internet of Things (IoT) resources. However, due to their novelty, existing literature lacks a comprehensive survey on how DIDs and VCs have been employed in different application domains, which go beyond SSI systems. This paper provides readers with a comprehensive overview of such technologies from different perspectives. Specifically, we first provide the background on DIDs and VCs. Then, we analyze available implementations and offer an in-depth review of how these technologies have been employed across different use-case scenarios. Furthermore, we examine recent regulations and initiatives that have been emerging worldwide. Finally, we present some challenges that hinder their adoption in real-world scenarios and future research directions.</li>
</ul>

<h3>Title: Discovering More Effective Tensor Network Structure Search Algorithms  via Large Language Models (LLMs)</h3>
<ul>
<li><strong>Authors: </strong>Junhua Zeng, Guoxu Zhou, Chao Li, Zhun Sun, Qibin Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02456">https://arxiv.org/abs/2402.02456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02456">https://arxiv.org/pdf/2402.02456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02456]] Discovering More Effective Tensor Network Structure Search Algorithms  via Large Language Models (LLMs)(https://arxiv.org/abs/2402.02456)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Tensor network structure search (TN-SS), aiming at searching for suitable tensor network (TN) structures in representing high-dimensional problems, largely promotes the efficacy of TN in various machine learning applications. Nonetheless, finding a satisfactory TN structure using existing algorithms remains challenging. To develop more effective algorithms and avoid the human labor-intensive development process, we explore the knowledge embedded in large language models (LLMs) for the automatic design of TN-SS algorithms. Our approach, dubbed GPTN-SS, leverages an elaborate crafting LLM-based prompting system that operates in an evolutionary-like manner. The experimental results, derived from real-world data, demonstrate that GPTN-SS can effectively leverage the insights gained from existing methods to develop novel TN-SS algorithms that achieve a better balance between exploration and exploitation. These algorithms exhibit superior performance in searching the high-quality TN structures for natural image compression and model parameters compression while also demonstrating generalizability in their performance.</li>
</ul>

<h3>Title: A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zhangyang Gao, Daize Dong, Cheng Tan, Jun Xia, Bozhen Hu, Stan Z. Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02464">https://arxiv.org/abs/2402.02464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02464">https://arxiv.org/pdf/2402.02464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02464]] A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer(https://arxiv.org/abs/2402.02464)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Can we model non-Euclidean graphs as pure language or even Euclidean vectors while retaining their inherent information? The non-Euclidean property have posed a long term challenge in graph modeling. Despite recent GNN and Graphformer efforts encoding graphs as Euclidean vectors, recovering original graph from the vectors remains a challenge. We introduce GraphsGPT, featuring a Graph2Seq encoder that transforms non-Euclidean graphs into learnable graph words in a Euclidean space, along with a GraphGPT decoder that reconstructs the original graph from graph words to ensure information equivalence. We pretrain GraphsGPT on 100M molecules and yield some interesting findings: (1) Pretrained Graph2Seq excels in graph representation learning, achieving state-of-the-art results on 8/9 graph classification and regression tasks. (2) Pretrained GraphGPT serves as a strong graph generator, demonstrated by its ability to perform both unconditional and conditional graph generation. (3) Graph2Seq+GraphGPT enables effective graph mixup in the Euclidean space, overcoming previously known non-Euclidean challenge. (4) Our proposed novel edge-centric GPT pretraining task is effective in graph fields, underscoring its success in both representation and generation.</li>
</ul>

<h3>Title: Deep Spectral Improvement for Unsupervised Image Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Farnoosh Arefi, Amir M. Mansourian, Shohreh Kasaei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02474">https://arxiv.org/abs/2402.02474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02474">https://arxiv.org/pdf/2402.02474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02474]] Deep Spectral Improvement for Unsupervised Image Instance Segmentation(https://arxiv.org/abs/2402.02474)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Deep spectral methods reframe the image decomposition process as a graph partitioning task by extracting features using self-supervised learning and utilizing the Laplacian of the affinity matrix to obtain eigensegments. However, instance segmentation has received less attention compared to other tasks within the context of deep spectral methods. This paper addresses the fact that not all channels of the feature map extracted from a self-supervised backbone contain sufficient information for instance segmentation purposes. In fact, Some channels are noisy and hinder the accuracy of the task. To overcome this issue, this paper proposes two channel reduction modules: Noise Channel Reduction (NCR) and Deviation-based Channel Reduction (DCR). The NCR retains channels with lower entropy, as they are less likely to be noisy, while DCR prunes channels with low standard deviation, as they lack sufficient information for effective instance segmentation. Furthermore, the paper demonstrates that the dot product, commonly used in deep spectral methods, is not suitable for instance segmentation due to its sensitivity to feature map values, potentially leading to incorrect instance segments. A new similarity metric called Bray-Curtis over Chebyshev (BoC) is proposed to address this issue. It takes into account the distribution of features in addition to their values, providing a more robust similarity measure for instance segmentation. Quantitative and qualitative results on the Youtube-VIS2019 dataset highlight the improvements achieved by the proposed channel reduction methods and the use of BoC instead of the conventional dot product for creating the affinity matrix. These improvements are observed in terms of mean Intersection over Union and extracted instance segments, demonstrating enhanced instance segmentation performance. The code is available on: https://github.com/farnooshar/SpecUnIIS</li>
</ul>

<h3>Title: VM-UNet: Vision Mamba UNet for Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Ruan, Suncheng Xiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02491">https://arxiv.org/abs/2402.02491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02491">https://arxiv.org/pdf/2402.02491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02491]] VM-UNet: Vision Mamba UNet for Medical Image Segmentation(https://arxiv.org/abs/2402.02491)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In the realm of medical image segmentation, both CNN-based and Transformer-based models have been extensively explored. However, CNNs exhibit limitations in long-range modeling capabilities, whereas Transformers are hampered by their quadratic computational complexity. Recently, State Space Models (SSMs), exemplified by Mamba, have emerged as a promising approach. They not only excel in modeling long-range interactions but also maintain a linear computational complexity. In this paper, leveraging state space models, we propose a U-shape architecture model for medical image segmentation, named Vision Mamba UNet (VM-UNet). Specifically, the Visual State Space (VSS) block is introduced as the foundation block to capture extensive contextual information, and an asymmetrical encoder-decoder structure is constructed. We conduct comprehensive experiments on the ISIC17, ISIC18, and Synapse datasets, and the results indicate that VM-UNet performs competitively in medical image segmentation tasks. To our best knowledge, this is the first medical image segmentation model constructed based on the pure SSM-based model. We aim to establish a baseline and provide valuable insights for the future development of more efficient and effective SSM-based segmentation systems. Our code is available at https://github.com/JCruan519/VM-UNet.</li>
</ul>

<h3>Title: GeReA: Question-Aware Prompt Captions for Knowledge-based Visual  Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Ma, Shutao Li, Bin Sun, Jianfei Cai, Zuxiang Long, Fuyan Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02503">https://arxiv.org/abs/2402.02503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02503">https://arxiv.org/pdf/2402.02503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02503]] GeReA: Question-Aware Prompt Captions for Knowledge-based Visual  Question Answering(https://arxiv.org/abs/2402.02503)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge-based visual question answering (VQA) requires world knowledge beyond the image for accurate answer. Recently, instead of extra knowledge bases, a large language model (LLM) like GPT-3 is activated as an implicit knowledge engine to jointly acquire and reason the necessary knowledge for answering by converting images into textual information (e.g., captions and answer candidates). However, such conversion may introduce irrelevant information, which causes the LLM to misinterpret images and ignore visual details crucial for accurate knowledge. We argue that multimodal large language model (MLLM) is a better implicit knowledge engine than the LLM for its superior capability of visual understanding. Despite this, how to activate the capacity of MLLM as the implicit knowledge engine has not been explored yet. Therefore, we propose GeReA, a generate-reason framework that prompts a MLLM like InstructBLIP with question relevant vision and language information to generate knowledge-relevant descriptions and reasons those descriptions for knowledge-based VQA. Specifically, the question-relevant image regions and question-specific manual prompts are encoded in the MLLM to generate the knowledge relevant descriptions, referred to as question-aware prompt captions. After that, the question-aware prompt captions, image-question pair, and similar samples are sent into the multi-modal reasoning model to learn a joint knowledge-image-question representation for answer prediction. GeReA unlocks the use of MLLM as the implicit knowledge engine, surpassing all previous state-of-the-art methods on OK-VQA and A-OKVQA datasets, with test accuracies of 66.5% and 63.3% respectively. Our code will be released at https://github.com/Upper9527/GeReA.</li>
</ul>

<h3>Title: Deep Supervision by Gaussian Pseudo-label-based Morphological Attention  for Abdominal Aorta Segmentation in Non-Contrast CTs</h3>
<ul>
<li><strong>Authors: </strong>Qixiang Ma, Antoine Lucas, Adrien Kaladji, Pascal Haigron</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02514">https://arxiv.org/abs/2402.02514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02514">https://arxiv.org/pdf/2402.02514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02514]] Deep Supervision by Gaussian Pseudo-label-based Morphological Attention  for Abdominal Aorta Segmentation in Non-Contrast CTs(https://arxiv.org/abs/2402.02514)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The segmentation of the abdominal aorta in non-contrast CT images is a non-trivial task for computer-assisted endovascular navigation, particularly in scenarios where contrast agents are unsuitable. While state-of-the-art deep learning segmentation models have been proposed recently for this task, they are trained on manually annotated strong labels. However, the inherent ambiguity in the boundary of the aorta in non-contrast CT may undermine the reliability of strong labels, leading to potential overfitting risks. This paper introduces a Gaussian-based pseudo label, integrated into conventional deep learning models through deep supervision, to achieve Morphological Attention (MA) enhancement. As the Gaussian pseudo label retains the morphological features of the aorta without explicitly representing its boundary distribution, we suggest that it preserves aortic morphology during training while mitigating the negative impact of ambiguous boundaries, reducing the risk of overfitting. It is introduced in various 2D/3D deep learning models and validated on our local data set of 30 non-contrast CT volumes comprising 5749 CT slices. The results underscore the effectiveness of MA in preserving the morphological characteristics of the aorta and addressing overfitting concerns, thereby enhancing the performance of the models.</li>
</ul>

<h3>Title: Adaptive scheduling for adaptive sampling in POS taggers construction</h3>
<ul>
<li><strong>Authors: </strong>Manuel Vilares Ferro, Victor M. Darriba Bilbao, Jess Vilares Ferro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02516">https://arxiv.org/abs/2402.02516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02516">https://arxiv.org/pdf/2402.02516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02516]] Adaptive scheduling for adaptive sampling in POS taggers construction(https://arxiv.org/abs/2402.02516)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce an adaptive scheduling for adaptive sampling as a novel way of machine learning in the construction of part-of-speech taggers. The goal is to speed up the training on large data sets, without significant loss of performance with regard to an optimal configuration. In contrast to previous methods using a random, fixed or regularly rising spacing between the instances, ours analyzes the shape of the learning curve geometrically in conjunction with a functional model to increase or decrease it at any time. The algorithm proves to be formally correct regarding our working hypotheses. Namely, given a case, the following one is the nearest ensuring a net gain of learning ability from the former, it being possible to modulate the level of requirement for this condition. We also improve the robustness of sampling by paying greater attention to those regions of the training data base subject to a temporary inflation in performance, thus preventing the learning from stopping prematurely. The proposal has been evaluated on the basis of its reliability to identify the convergence of models, corroborating our expectations. While a concrete halting condition is used for testing, users can choose any condition whatsoever to suit their own specific needs.</li>
</ul>

<h3>Title: Latent Graph Diffusion: A Unified Framework for Generation and  Prediction on Graphs</h3>
<ul>
<li><strong>Authors: </strong>Zhou Cai, Xiyuan Wang, Muhan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02518">https://arxiv.org/abs/2402.02518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02518">https://arxiv.org/pdf/2402.02518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02518]] Latent Graph Diffusion: A Unified Framework for Generation and  Prediction on Graphs(https://arxiv.org/abs/2402.02518)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we propose the first framework that enables solving graph learning tasks of all levels (node, edge and graph) and all types (generation, regression and classification) with one model. We first propose Latent Graph Diffusion (LGD), a generative model that can generate node, edge, and graph-level features of all categories simultaneously. We achieve this goal by embedding the graph structures and features into a latent space leveraging a powerful encoder which can also be decoded, then training a diffusion model in the latent space. LGD is also capable of conditional generation through a specifically designed cross-attention mechanism. Then we formulate prediction tasks including regression and classification as (conditional) generation, which enables our LGD to solve tasks of all levels and all types with provable guarantees. We verify the effectiveness of our framework with extensive experiments, where our models achieve state-of-the-art or highly competitive results across generation and regression tasks.</li>
</ul>

<h3>Title: Absolute convergence and error thresholds in non-active adaptive  sampling</h3>
<ul>
<li><strong>Authors: </strong>Manuel Vilares Ferro, Victor M. Darriba Bilbao, Jess Vilares Ferro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02522">https://arxiv.org/abs/2402.02522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02522">https://arxiv.org/pdf/2402.02522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02522]] Absolute convergence and error thresholds in non-active adaptive  sampling(https://arxiv.org/abs/2402.02522)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Non-active adaptive sampling is a way of building machine learning models from a training data base which are supposed to dynamically and automatically derive guaranteed sample size. In this context and regardless of the strategy used in both scheduling and generating of weak predictors, a proposal for calculating absolute convergence and error thresholds is described. We not only make it possible to establish when the quality of the model no longer increases, but also supplies a proximity condition to estimate in absolute terms how close it is to achieving such a goal, thus supporting decision making for fine-tuning learning parameters in model selection. The technique proves its correctness and completeness with respect to our working hypotheses, in addition to strengthening the robustness of the sampling scheme. Tests meet our expectations and illustrate the proposal in the domain of natural language processing, taking the generation of part-of-speech taggers as case study.</li>
</ul>

<h3>Title: CompeteSMoE - Effective Training of Sparse Mixture of Experts via  Competition</h3>
<ul>
<li><strong>Authors: </strong>Quang Pham, Giang Do, Huy Nguyen, TrungTin Nguyen, Chenghao Liu, Mina Sartipi, Binh T. Nguyen, Savitha Ramasamy, Xiaoli Li, Steven Hoi, Nhat Ho</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02526">https://arxiv.org/abs/2402.02526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02526">https://arxiv.org/pdf/2402.02526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02526]] CompeteSMoE - Effective Training of Sparse Mixture of Experts via  Competition(https://arxiv.org/abs/2402.02526)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Sparse mixture of experts (SMoE) offers an appealing solution to scale up the model complexity beyond the mean of increasing the network's depth or width. However, effective training of SMoE has proven to be challenging due to the representation collapse issue, which causes parameter redundancy and limited representation potentials. In this work, we propose a competition mechanism to address this fundamental challenge of representation collapse. By routing inputs only to experts with the highest neural response, we show that, under mild assumptions, competition enjoys the same convergence rate as the optimal estimator. We further propose CompeteSMoE, an effective and efficient algorithm to train large language models by deploying a simple router that predicts the competition outcomes. Consequently, CompeteSMoE enjoys strong performance gains from the competition routing policy while having low computation overheads. Our extensive empirical evaluations on two transformer architectures and a wide range of tasks demonstrate the efficacy, robustness, and scalability of CompeteSMoE compared to state-of-the-art SMoE strategies.</li>
</ul>

<h3>Title: Embedding Non-Distortive Cancelable Face Template Generation</h3>
<ul>
<li><strong>Authors: </strong>Dmytro Zakharov, Oleksandr Kuznetsov, Emanuele Frontoni, Natalia Kryvinska</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02540">https://arxiv.org/abs/2402.02540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02540">https://arxiv.org/pdf/2402.02540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02540]] Embedding Non-Distortive Cancelable Face Template Generation(https://arxiv.org/abs/2402.02540)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, biometric</a></li>
<li><strong>Abstract: </strong>Biometric authentication systems are crucial for security, but developing them involves various complexities, including privacy, security, and achieving high accuracy without directly storing pure biometric data in storage. We introduce an innovative image distortion technique that makes facial images unrecognizable to the eye but still identifiable by any custom embedding neural network model. Using the proposed approach, we test the reliability of biometric recognition networks by determining the maximum image distortion that does not change the predicted identity. Through experiments on MNIST and LFW datasets, we assess its effectiveness and compare it based on the traditional comparison metrics.</li>
</ul>

<h3>Title: Knowledge Generation for Zero-shot Knowledge-based VQA</h3>
<ul>
<li><strong>Authors: </strong>Rui Cao, Jing Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02541">https://arxiv.org/abs/2402.02541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02541">https://arxiv.org/pdf/2402.02541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02541]] Knowledge Generation for Zero-shot Knowledge-based VQA(https://arxiv.org/abs/2402.02541)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Previous solutions to knowledge-based visual question answering~(K-VQA) retrieve knowledge from external knowledge bases and use supervised learning to train the K-VQA model. Recently pre-trained LLMs have been used as both a knowledge source and a zero-shot QA model for K-VQA and demonstrated promising results. However, these recent methods do not explicitly show the knowledge needed to answer the questions and thus lack interpretability. Inspired by recent work on knowledge generation from LLMs for text-based QA, in this work we propose and test a similar knowledge-generation-based K-VQA method, which first generates knowledge from an LLM and then incorporates the generated knowledge for K-VQA in a zero-shot manner. We evaluate our method on two K-VQA benchmarks and found that our method performs better than previous zero-shot K-VQA methods and our generated knowledge is generally relevant and helpful.</li>
</ul>

<h3>Title: LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal  Language Model</h3>
<ul>
<li><strong>Authors: </strong>Dilxat Muhtar, Zhenshi Li, Feng Gu, Xueliang Zhang, Pengfeng Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02544">https://arxiv.org/abs/2402.02544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02544">https://arxiv.org/pdf/2402.02544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02544]] LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal  Language Model(https://arxiv.org/abs/2402.02544)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The revolutionary capabilities of large language models (LLMs) have paved the way for multimodal large language models (MLLMs) and fostered diverse applications across various specialized domains. In the remote sensing (RS) field, however, the diverse geographical landscapes and varied objects in RS imagery are not adequately considered in recent MLLM endeavors. To bridge this gap, we construct a large-scale RS image-text dataset, LHRS-Align, and an informative RS-specific instruction dataset, LHRS-Instruct, leveraging the extensive volunteered geographic information (VGI) and globally available RS images. Building on this foundation, we introduce LHRS-Bot, an MLLM tailored for RS image understanding through a novel multi-level vision-language alignment strategy and a curriculum learning method. Comprehensive experiments demonstrate that LHRS-Bot exhibits a profound understanding of RS images and the ability to perform nuanced reasoning within the RS domain.</li>
</ul>

<h3>Title: "What's my model inside of?": Exploring the role of environments for  grounded natural language understanding</h3>
<ul>
<li><strong>Authors: </strong>Ronen Tamari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02548">https://arxiv.org/abs/2402.02548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02548">https://arxiv.org/pdf/2402.02548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02548]] "What's my model inside of?": Exploring the role of environments for  grounded natural language understanding(https://arxiv.org/abs/2402.02548)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>In contrast to classical cognitive science which studied brains in isolation, ecological approaches focused on the role of the body and environment in shaping cognition. Similarly, in this thesis we adopt an ecological approach to grounded natural language understanding (NLU) research. Grounded language understanding studies language understanding systems situated in the context of events, actions and precepts in naturalistic/simulated virtual environments. Where classic research tends to focus on designing new models and optimization methods while treating environments as given, we explore the potential of environment design for improving data collection and model development. We developed novel training and annotation approaches for procedural text understanding based on text-based game environments. We also drew upon embodied cognitive linguistics literature to propose a roadmap for grounded NLP research, and to inform the development of a new benchmark for measuring the progress of large language models on challenging commonsense reasoning tasks. We leveraged the richer supervision provided by text-based game environments to develop Breakpoint Transformers, a novel approach to modeling intermediate semantic information in long narrative or procedural texts. Finally, we integrated theories on the role of environments in collective human intelligence to propose a design for AI-augmented "social thinking environments" for knowledge workers like scientists.</li>
</ul>

<h3>Title: Are Large Language Models Table-based Fact-Checkers?</h3>
<ul>
<li><strong>Authors: </strong>Hangwen Zhang, Qingyi Si, Peng Fu, Zheng Lin, Weiping Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02549">https://arxiv.org/abs/2402.02549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02549">https://arxiv.org/pdf/2402.02549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02549]] Are Large Language Models Table-based Fact-Checkers?(https://arxiv.org/abs/2402.02549)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Table-based Fact Verification (TFV) aims to extract the entailment relation between statements and structured tables. Existing TFV methods based on small-scaled models suffer from insufficient labeled data and weak zero-shot ability. Recently, the appearance of Large Language Models (LLMs) has gained lots of attraction in research fields. They have shown powerful zero-shot and in-context learning abilities on several NLP tasks, but their potential on TFV is still unknown. In this work, we implement a preliminary study about whether LLMs are table-based fact-checkers. In detail, we design diverse prompts to explore how the in-context learning can help LLMs in TFV, i.e., zero-shot and few-shot TFV capability. Besides, we carefully design and construct TFV instructions to study the performance gain brought by the instruction tuning of LLMs. Experimental results demonstrate that LLMs can achieve acceptable results on zero-shot and few-shot TFV with prompt engineering, while instruction-tuning can stimulate the TFV capability significantly. We also make some valuable findings about the format of zero-shot prompts and the number of in-context examples. Finally, we analyze some possible directions to promote the accuracy of TFV via LLMs, which is beneficial to further research of table reasoning.</li>
</ul>

<h3>Title: DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms  in Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Oryan Yehezkel, Alon Zolfi, Amit Baras, Yuval Elovici, Asaf Shabtai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02554">https://arxiv.org/abs/2402.02554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02554">https://arxiv.org/pdf/2402.02554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02554]] DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms  in Vision Transformers(https://arxiv.org/abs/2402.02554)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, transformer</a></li>
<li><strong>Abstract: </strong>Vision transformers have contributed greatly to advancements in the computer vision domain, demonstrating state-of-the-art performance in diverse tasks (e.g., image classification, object detection). However, their high computational requirements grow quadratically with the number of tokens used. Token sparsification techniques have been proposed to address this issue. These techniques employ an input-dependent strategy, in which uninformative tokens are discarded from the computation pipeline, improving the model's efficiency. However, their dynamism and average-case assumption makes them vulnerable to a new threat vector - carefully crafted adversarial examples capable of fooling the sparsification mechanism, resulting in worst-case performance. In this paper, we present DeSparsify, an attack targeting the availability of vision transformers that use token sparsification mechanisms. The attack aims to exhaust the operating system's resources, while maintaining its stealthiness. Our evaluation demonstrates the attack's effectiveness on three token sparsification techniques and examines the attack's transferability between them and its effect on the GPU resources. To mitigate the impact of the attack, we propose various countermeasures.</li>
</ul>

<h3>Title: Generalizable Entity Grounding via Assistance of Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Lu Qi, Yi-Wen Chen, Lehan Yang, Tiancheng Shen, Xiangtai Li, Weidong Guo, Yu Xu, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02555">https://arxiv.org/abs/2402.02555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02555">https://arxiv.org/pdf/2402.02555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02555]] Generalizable Entity Grounding via Assistance of Large Language Model(https://arxiv.org/abs/2402.02555)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>In this work, we propose a novel approach to densely ground visual entities from a long caption. We leverage a large multimodal model (LMM) to extract semantic nouns, a class-agnostic segmentation model to generate entity-level segmentation, and the proposed multi-modal feature fusion module to associate each semantic noun with its corresponding segmentation mask. Additionally, we introduce a strategy of encoding entity segmentation masks into a colormap, enabling the preservation of fine-grained predictions from features of high-resolution masks. This approach allows us to extract visual features from low-resolution images using the CLIP vision encoder in the LMM, which is more computationally efficient than existing approaches that use an additional encoder for high-resolution images. Our comprehensive experiments demonstrate the superiority of our method, outperforming state-of-the-art techniques on three tasks, including panoptic narrative grounding, referring expression segmentation, and panoptic segmentation.</li>
</ul>

<h3>Title: Enhancing Robustness in Biomedical NLI Models: A Probing Approach for  Clinical Trials</h3>
<ul>
<li><strong>Authors: </strong>Ata Mustafa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02558">https://arxiv.org/abs/2402.02558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02558">https://arxiv.org/pdf/2402.02558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02558]] Enhancing Robustness in Biomedical NLI Models: A Probing Approach for  Clinical Trials(https://arxiv.org/abs/2402.02558)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have revolutionized various fields and industries, such as Conversational AI, Content Generation, Information Retrieval, Business Intelligence, and Medical, to name a few. One major application in the field of medical is to analyze and investigate clinical trials for entailment tasks.However, It has been observed that Large Language Models are susceptible to shortcut learning, factual inconsistency, and performance degradation with little variation in context. Adversarial and robust testing is performed to ensure the integrity of models output. But, ambiguity still persists. In order to ensure the integrity of the reasoning performed and investigate the model has correct syntactic and semantic understanding probing is used. Here, I used mnestic probing to investigate the Sci-five model, trained on clinical trial. I investigated the model for feature learnt with respect to natural logic. To achieve the target, I trained task specific probes. Used these probes to investigate the final layers of trained model. Then, fine tuned the trained model using iterative null projection. The results shows that model accuracy improved. During experimentation, I observed that size of the probe has affect on the fine tuning process.</li>
</ul>

<h3>Title: NavHint: Vision and Language Navigation Agent with a Hint Generator</h3>
<ul>
<li><strong>Authors: </strong>Yue Zhang, Quan Guo, Parisa Kordjamshidi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02559">https://arxiv.org/abs/2402.02559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02559">https://arxiv.org/pdf/2402.02559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02559]] NavHint: Vision and Language Navigation Agent with a Hint Generator(https://arxiv.org/abs/2402.02559)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Existing work on vision and language navigation mainly relies on navigation-related losses to establish the connection between vision and language modalities, neglecting aspects of helping the navigation agent build a deep understanding of the visual environment. In our work, we provide indirect supervision to the navigation agent through a hint generator that provides detailed visual descriptions. The hint generator assists the navigation agent in developing a global understanding of the visual environment. It directs the agent's attention toward related navigation details, including the relevant sub-instruction, potential challenges in recognition and ambiguities in grounding, and the targeted viewpoint description. To train the hint generator, we construct a synthetic dataset based on landmarks in the instructions and visible and distinctive objects in the visual environment. We evaluate our method on the R2R and R4R datasets and achieve state-of-the-art on several metrics. The experimental results demonstrate that generating hints not only enhances the navigation performance but also helps improve the interpretability of the agent's actions.</li>
</ul>

<h3>Title: Foundation Model Makes Clustering a Better Initialization for Active  Learning</h3>
<ul>
<li><strong>Authors: </strong>Han Yuan, Chuan Hong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02561">https://arxiv.org/abs/2402.02561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02561">https://arxiv.org/pdf/2402.02561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02561]] Foundation Model Makes Clustering a Better Initialization for Active  Learning(https://arxiv.org/abs/2402.02561)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Active learning selects the most informative samples from the unlabeled dataset to annotate in the context of a limited annotation budget. While numerous methods have been proposed for subsequent sample selection based on an initialized model, scant attention has been paid to the indispensable phase of active learning: selecting samples for model initialization. Most of the previous studies resort to random sampling or naive clustering. However, random sampling is prone to fluctuation, and naive clustering suffers from convergence speed, particularly when dealing with high-dimensional data such as imaging data. In this work, we propose to integrate foundation models with clustering methods to select samples for active learning initialization. Foundation models refer to those trained on massive datasets by the self-supervised paradigm and capable of generating informative and compacted embeddings for various downstream tasks. Leveraging these embeddings to replace raw features such as pixel values, clustering quickly converges and identifies better initial samples. For a comprehensive comparison, we included a classic ImageNet-supervised model to acquire embeddings. Experiments on two clinical tasks of image classification and segmentation demonstrated that foundation model-based clustering efficiently pinpointed informative initial samples, leading to models showcasing enhanced performance than the baseline methods. We envisage that this study provides an effective paradigm for future active learning.</li>
</ul>

<h3>Title: DefInt: A Default-interventionist Framework for Efficient Reasoning with  Hybrid Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yu Shang, Yu Li, Fengli Xu, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02563">https://arxiv.org/abs/2402.02563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02563">https://arxiv.org/pdf/2402.02563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02563]] DefInt: A Default-interventionist Framework for Efficient Reasoning with  Hybrid Large Language Models(https://arxiv.org/abs/2402.02563)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown impressive emergent abilities in a wide range of tasks, but still face challenges in handling complex reasoning problems. Previous works like chain-of-thought (CoT) and tree-of-thoughts(ToT) have predominately focused on enhancing accuracy, but overlook the rapidly increasing token cost, which could be particularly problematic for open-ended real-world tasks with huge solution spaces. Motivated by the dual process theory of human cognition, we propose a Default-Interventionist framework (DefInt) to unleash the synergistic potential of hybrid LLMs. By default, DefInt uses smaller-scale language models to generate low-cost reasoning thoughts, which resembles the fast intuitions produced by System 1. If the intuitions are considered with low confidence, DefInt will invoke the reflective reasoning of scaled-up language models as the intervention of System 2, which can override the default thoughts and rectify the reasoning process. Experiments on five representative reasoning tasks show that DefInt consistently achieves state-of-the-art reasoning accuracy and solution diversity. More importantly, it substantially reduces the token cost by 49%-79% compared to the second accurate baselines. Specifically, the open-ended tasks have an average 75% token cost reduction. Code repo with all prompts will be released upon publication.</li>
</ul>

<h3>Title: A Truly Joint Neural Architecture for Segmentation and Parsing</h3>
<ul>
<li><strong>Authors: </strong>Danit Yshaayahu Levi, Reut Tsarfaty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02564">https://arxiv.org/abs/2402.02564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02564">https://arxiv.org/pdf/2402.02564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02564]] A Truly Joint Neural Architecture for Segmentation and Parsing(https://arxiv.org/abs/2402.02564)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the joint morpho-syntactic hypothesis, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline. In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art performance on parsing, tagging and segmentation of the Hebrew section of UD, using a single model. This proposed architecture is LLM-based and language agnostic, providing a solid foundation for MRLs to obtain further performance improvements and bridge the gap with other languages.</li>
</ul>

<h3>Title: A Quantitative Discourse Analysis of Asian Workers in the US Historical  Newspapers</h3>
<ul>
<li><strong>Authors: </strong>Jaihyun Park, Ryan Cordell</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02572">https://arxiv.org/abs/2402.02572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02572">https://arxiv.org/pdf/2402.02572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02572]] A Quantitative Discourse Analysis of Asian Workers in the US Historical  Newspapers(https://arxiv.org/abs/2402.02572)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Warning: This paper contains examples of offensive language targetting marginalized population. The digitization of historical texts invites researchers to explore the large-scale corpus of historical texts with computational methods. In this study, we present computational text analysis on a relatively understudied topic of how Asian workers are represented in historical newspapers in the United States. We found that the word "coolie" was semantically different in some States (e.g., Massachusetts, Rhode Island, Wyoming, Oklahoma, and Arkansas) with the different discourses around coolie. We also found that then-Confederate newspapers and then-Union newspapers formed distinctive discourses by measuring over-represented words. Newspapers from then-Confederate States associated coolie with slavery-related words. In addition, we found Asians were perceived to be inferior to European immigrants and subjected to the target of racism. This study contributes to supplementing the qualitative analysis of racism in the United States with quantitative discourse analysis.</li>
</ul>

<h3>Title: Spatio-temporal Prompting Network for Robust Video Feature Extraction</h3>
<ul>
<li><strong>Authors: </strong>Guanxiong Sun, Chi Wang, Zhaoyu Zhang, Jiankang Deng, Stefanos Zafeiriou, Yang Hua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02574">https://arxiv.org/abs/2402.02574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02574">https://arxiv.org/pdf/2402.02574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02574]] Spatio-temporal Prompting Network for Robust Video Feature Extraction(https://arxiv.org/abs/2402.02574)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Frame quality deterioration is one of the main challenges in the field of video understanding. To compensate for the information loss caused by deteriorated frames, recent approaches exploit transformer-based integration modules to obtain spatio-temporal information. However, these integration modules are heavy and complex. Furthermore, each integration module is specifically tailored for its target task, making it difficult to generalise to multiple tasks. In this paper, we present a neat and unified framework, called Spatio-Temporal Prompting Network (STPN). It can efficiently extract robust and accurate video features by dynamically adjusting the input features in the backbone network. Specifically, STPN predicts several video prompts containing spatio-temporal information of neighbour frames. Then, these video prompts are prepended to the patch embeddings of the current frame as the updated input for video feature extraction. Moreover, STPN is easy to generalise to various video tasks because it does not contain task-specific modules. Without bells and whistles, STPN achieves state-of-the-art performance on three widely-used datasets for different video understanding tasks, i.e., ImageNetVID for video object detection, YouTubeVIS for video instance segmentation, and GOT-10k for visual object tracking. Code is available at https://github.com/guanxiongsun/vfe.pytorch.</li>
</ul>

<h3>Title: DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image  Editing</h3>
<ul>
<li><strong>Authors: </strong>Chong Mou, Xintao Wang, Jiechong Song, Ying Shan, Jian Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02583">https://arxiv.org/abs/2402.02583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02583">https://arxiv.org/pdf/2402.02583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02583]] DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image  Editing(https://arxiv.org/abs/2402.02583)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Large-scale Text-to-Image (T2I) diffusion models have revolutionized image generation over the last few years. Although owning diverse and high-quality generation capabilities, translating these abilities to fine-grained image editing remains challenging. In this paper, we propose DiffEditor to rectify two weaknesses in existing diffusion-based image editing: (1) in complex scenarios, editing results often lack editing accuracy and exhibit unexpected artifacts; (2) lack of flexibility to harmonize editing operations, e.g., imagine new content. In our solution, we introduce image prompts in fine-grained image editing, cooperating with the text prompt to better describe the editing content. To increase the flexibility while maintaining content consistency, we locally combine stochastic differential equation (SDE) into the ordinary differential equation (ODE) sampling. In addition, we incorporate regional score-based gradient guidance and a time travel strategy into the diffusion sampling, further improving the editing quality. Extensive experiments demonstrate that our method can efficiently achieve state-of-the-art performance on various fine-grained image editing tasks, including editing within a single image (e.g., object moving, resizing, and content dragging) and across images (e.g., appearance replacing and object pasting). Our source code is released at https://github.com/MC-E/DragonDiffusion.</li>
</ul>

<h3>Title: ClipFormer: Key-Value Clipping of Transformers on Memristive Crossbars  for Write Noise Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Abhiroop Bhattacharjee, Abhishek Moitra, Priyadarshini Panda</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02586">https://arxiv.org/abs/2402.02586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02586">https://arxiv.org/pdf/2402.02586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02586]] ClipFormer: Key-Value Clipping of Transformers on Memristive Crossbars  for Write Noise Mitigation(https://arxiv.org/abs/2402.02586)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have revolutionized various real-world applications from natural language processing to computer vision. However, traditional von-Neumann computing paradigm faces memory and bandwidth limitations in accelerating transformers owing to their massive model sizes. To this end, In-memory Computing (IMC) crossbars based on Non-volatile Memories (NVMs), due to their ability to perform highly parallelized Matrix-Vector-Multiplications (MVMs) with high energy-efficiencies, have emerged as a promising solution for accelerating transformers. However, analog MVM operations in crossbars introduce non-idealities, such as stochastic read & write noise, which affect the inference accuracy of the deployed transformers. Specifically, we find pre-trained Vision Transformers (ViTs) to be vulnerable on crossbars due to the impact of write noise on the dynamically-generated Key (K) and Value (V) matrices in the attention layers, an effect not accounted for in prior studies. We, thus, propose ClipFormer, a transformation on the K and V matrices during inference, to boost the non-ideal accuracies of pre-trained ViT models. ClipFormer requires no additional hardware and training overhead and is amenable to transformers deployed on any memristive crossbar platform. Our experiments on Imagenet-1k dataset using pre-trained DeiT-S transformers, subjected to standard training and variation-aware-training, show >10-40% higher non-ideal accuracies at the high write noise regime by applying ClipFormer.</li>
</ul>

<h3>Title: Unified Training of Universal Time Series Forecasting Transformers</h3>
<ul>
<li><strong>Authors: </strong>Gerald Woo, Chenghao Liu, Akshat Kumar, Caiming Xiong, Silvio Savarese, Doyen Sahoo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02592">https://arxiv.org/abs/2402.02592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02592">https://arxiv.org/pdf/2402.02592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02592]] Unified Training of Universal Time Series Forecasting Transformers(https://arxiv.org/abs/2402.02592)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep learning for time series forecasting has traditionally operated within a one-model-per-dataset framework, limiting its potential to leverage the game-changing impact of large pre-trained models. The concept of universal forecasting, emerging from pre-training on a vast collection of time series datasets, envisions a single Large Time Series Model capable of addressing diverse downstream forecasting tasks. However, constructing such a model poses unique challenges specific to time series data: i) cross-frequency learning, ii) accommodating an arbitrary number of variates for multivariate time series, and iii) addressing the varying distributional properties inherent in large-scale data. To address these challenges, we present novel enhancements to the conventional time series Transformer architecture, resulting in our proposed Masked Encoder-based Universal Time Series Forecasting Transformer (Moirai). Trained on our newly introduced Large-scale Open Time Series Archive (LOTSA) featuring over 27B observations across nine domains, Moirai achieves competitive or superior performance as a zero-shot forecaster when compared to full-shot models. Code, model weights, and data will be released.</li>
</ul>

<h3>Title: Leveraging Continuously Differentiable Activation Functions for Learning  in Quantized Noisy Environments</h3>
<ul>
<li><strong>Authors: </strong>Vivswan Shah, Nathan Youngblood</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02593">https://arxiv.org/abs/2402.02593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02593">https://arxiv.org/pdf/2402.02593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02593]] Leveraging Continuously Differentiable Activation Functions for Learning  in Quantized Noisy Environments(https://arxiv.org/abs/2402.02593)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Real-world analog systems intrinsically suffer from noise that can impede model convergence and accuracy on a variety of deep learning models. We demonstrate that differentiable activations like GELU and SiLU enable robust propagation of gradients which help to mitigate analog quantization error that is ubiquitous to all analog systems. We perform analysis and training of convolutional, linear, and transformer networks in the presence of quantized noise. Here, we are able to demonstrate that continuously differentiable activation functions are significantly more noise resilient over conventional rectified activations. As in the case of ReLU, the error in gradients are 100x higher than those in GELU near zero. Our findings provide guidance for selecting appropriate activations to realize performant and reliable hardware implementations across several machine learning domains such as computer vision, signal processing, and beyond.</li>
</ul>

<h3>Title: Evading Deep Learning-Based Malware Detectors via Obfuscation: A Deep  Reinforcement Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Brian Etter, James Lee Hu, Mohammedreza Ebrahimi, Weifeng Li, Xin Li, Hsinchun Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02600">https://arxiv.org/abs/2402.02600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02600">https://arxiv.org/pdf/2402.02600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02600]] Evading Deep Learning-Based Malware Detectors via Obfuscation: A Deep  Reinforcement Learning Approach(https://arxiv.org/abs/2402.02600)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense</a></li>
<li><strong>Abstract: </strong>Adversarial Malware Generation (AMG), the gen- eration of adversarial malware variants to strengthen Deep Learning (DL)-based malware detectors has emerged as a crucial tool in the development of proactive cyberdefense. However, the majority of extant works offer subtle perturbations or additions to executable files and do not explore full-file obfuscation. In this study, we show that an open-source encryption tool coupled with a Reinforcement Learning (RL) framework can successfully obfuscate malware to evade state-of-the-art malware detection engines and outperform techniques that use advanced modification methods. Our results show that the proposed method improves the evasion rate from 27%-49% compared to widely- used state-of-the-art reinforcement learning-based methods.</li>
</ul>

<h3>Title: Flexible Non-interactive Short-term Implicit Certificate Generation for  VANETs</h3>
<ul>
<li><strong>Authors: </strong>Rui Liu, Yun Lu, Jianping Pan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02607">https://arxiv.org/abs/2402.02607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02607">https://arxiv.org/pdf/2402.02607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02607]] Flexible Non-interactive Short-term Implicit Certificate Generation for  VANETs(https://arxiv.org/abs/2402.02607)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate</a></li>
<li><strong>Abstract: </strong>A leading industry standard for secure and trusted communication in vehicular ad-hoc networks (VANETs) is the Security Credential Management System (SCMS). It uses anonymous certificates, functioning as pseudonyms, to preserve the privacy of vehicles. With the rapid development of advanced applications in VANETs, such as crowdsensing and federated learning, vehicles need to communicate with each other or infrastructures more frequently, leading to a higher demand for pseudonyms. However, the current approach of certificate provisioning in SCMS is not able to fully support pseudonyms, due to storage limitation, cost of connectivity establishment, and communication overhead of certificate downloading. To tackle this challenge, we propose a non-interactive approach for SCMS, allowing vehicles themselves to generate short-term key pairs and anonymous implicit certificates. Our evaluation and comparison with previous work show that our solution not only effectively reduces the communication cost, but also grants vehicles greater flexibility in certificate generation and use. On the technical side, to the best of our knowledge, this is the first work which (1) applies sanitizable signature for non-interactive anonymous certificate generation, and (2) is specifically designed for SCMS, which opens up possibilities for extensions and applications in industry.</li>
</ul>

<h3>Title: Increasing Trust in Language Models through the Reuse of Verified  Circuits</h3>
<ul>
<li><strong>Authors: </strong>Philip Quirke, Clement Neo, Fazl Barez</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02619">https://arxiv.org/abs/2402.02619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02619">https://arxiv.org/pdf/2402.02619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02619]] Increasing Trust in Language Models through the Reuse of Verified  Circuits(https://arxiv.org/abs/2402.02619)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Language Models (LMs) are increasingly used for a wide range of prediction tasks, but their training can often neglect rare edge cases, reducing their reliability. Here, we define a stringent standard of trustworthiness whereby the task algorithm and circuit implementation must be verified, accounting for edge cases, with no known failure modes. We show that a transformer model can be trained to meet this standard if built using mathematically and logically specified frameworks. In this paper, we fully verify a model for n-digit integer addition. To exhibit the reusability of verified modules, we insert the trained integer addition model into an untrained model and train the combined model to perform both addition and subtraction. We find extensive reuse of the addition circuits for both tasks, easing verification of the more complex subtractor model. We discuss how inserting verified task modules into LMs can leverage model reuse to improve verifiability and trustworthiness of language models built using them. The reuse of verified circuits reduces the effort to verify more complex composite models which we believe to be a significant step towards safety of language models.</li>
</ul>

<h3>Title: DenseFormer: Enhancing Information Flow in Transformers via Depth  Weighted Averaging</h3>
<ul>
<li><strong>Authors: </strong>Matteo Pagliardini, Amirkeivan Mohtashami, Francois Fleuret, Martin Jaggi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02622">https://arxiv.org/abs/2402.02622</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02622">https://arxiv.org/pdf/2402.02622</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02622]] DenseFormer: Enhancing Information Flow in Transformers via Depth  Weighted Averaging(https://arxiv.org/abs/2402.02622)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The transformer architecture from Vaswani et al. (2017) is now ubiquitous across application domains, from natural language processing to speech processing and image understanding. We propose DenseFormer, a simple modification to the standard architecture that improves the perplexity of the model without increasing its size -- adding a few thousand parameters for large-scale models in the 100B parameters range. Our approach relies on an additional averaging step after each transformer block, which computes a weighted average of current and past representations -- we refer to this operation as Depth-Weighted-Average (DWA). The learned DWA weights exhibit coherent patterns of information flow, revealing the strong and structured reuse of activations from distant layers. Experiments demonstrate that DenseFormer is more data efficient, reaching the same perplexity of much deeper transformer models, and that for the same perplexity, these new models outperform transformer baselines in terms of memory efficiency and inference time.</li>
</ul>

<h3>Title: Enhancing Transformer RNNs with Multiple Temporal Perspectives</h3>
<ul>
<li><strong>Authors: </strong>Razvan-Gabriel Dumitru, Darius Peteleaza, Mihai Surdeanu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02625">https://arxiv.org/abs/2402.02625</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02625">https://arxiv.org/pdf/2402.02625</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02625]] Enhancing Transformer RNNs with Multiple Temporal Perspectives(https://arxiv.org/abs/2402.02625)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce the concept of multiple temporal perspectives, a novel approach applicable to Recurrent Neural Network (RNN) architectures for enhancing their understanding of sequential data. This method involves maintaining diverse temporal views of previously encountered text, significantly enriching the language models' capacity to interpret context. To show the efficacy of this approach, we incorporate it into the Receptance Weighted Key Value (RWKV) architecture, addressing its inherent challenge of retaining all historical information within a single hidden state. Notably, this improvement is achieved with a minimal increase in the number of parameters --even as little as $0.04\%$ of the original number of parameters. Further, the additional parameters necessary for the multiple temporal perspectives are fine-tuned with minimal computational overhead, avoiding the need for a full pre-training. The resulting model maintains linear computational complexity during prompt inference, ensuring consistent efficiency across various sequence lengths. The empirical results and ablation studies included in our research validate the effectiveness of our approach, showcasing improved performance across multiple benchmarks. The code, model weights and datasets are open-sourced at: https://github.com/RazvanDu/TemporalRNNs.</li>
</ul>

<h3>Title: Stability Analysis of Various Symbolic Rule Extraction Methods from  Recurrent Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Neisarg Dave, Daniel Kifer, C. Lee Giles, Ankur Mali</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02627">https://arxiv.org/abs/2402.02627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02627">https://arxiv.org/pdf/2402.02627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02627]] Stability Analysis of Various Symbolic Rule Extraction Methods from  Recurrent Neural Network(https://arxiv.org/abs/2402.02627)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper analyzes two competing rule extraction methodologies: quantization and equivalence query. We trained $3600$ RNN models, extracting $18000$ DFA with a quantization approach (k-means and SOM) and $3600$ DFA by equivalence query($L^{*}$) methods across $10$ initialization seeds. We sampled the datasets from $7$ Tomita and $4$ Dyck grammars and trained them on $4$ RNN cells: LSTM, GRU, O2RNN, and MIRNN. The observations from our experiments establish the superior performance of O2RNN and quantization-based rule extraction over others. $L^{*}$, primarily proposed for regular grammars, performs similarly to quantization methods for Tomita languages when neural networks are perfectly trained. However, for partially trained RNNs, $L^{*}$ shows instability in the number of states in DFA, e.g., for Tomita 5 and Tomita 6 languages, $L^{*}$ produced more than $100$ states. In contrast, quantization methods result in rules with number of states very close to ground truth DFA. Among RNN cells, O2RNN produces stable DFA consistently compared to other cells. For Dyck Languages, we observe that although GRU outperforms other RNNs in network performance, the DFA extracted by O2RNN has higher performance and better stability. The stability is computed as the standard deviation of accuracy on test sets on networks trained across $10$ seeds. On Dyck Languages, quantization methods outperformed $L^{*}$ with better stability in accuracy and the number of states. $L^{*}$ often showed instability in accuracy in the order of $16\% - 22\%$ for GRU and MIRNN while deviation for quantization methods varied in $5\% - 15\%$. In many instances with LSTM and GRU, DFA's extracted by $L^{*}$ even failed to beat chance accuracy ($50\%$), while those extracted by quantization method had standard deviation in the $7\%-17\%$ range. For O2RNN, both rule extraction methods had deviation in the $0.5\% - 3\%$ range.</li>
</ul>

<h3>Title: PROSAC: Provably Safe Certification for Machine Learning Models under  Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Ziquan Liu, Zhuo Zhi, Ilija Bogunovic, Carsten Gerner-Beuerle, Miguel Rodrigues</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02629">https://arxiv.org/abs/2402.02629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02629">https://arxiv.org/pdf/2402.02629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02629]] PROSAC: Provably Safe Certification for Machine Learning Models under  Adversarial Attacks(https://arxiv.org/abs/2402.02629)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>It is widely known that state-of-the-art machine learning models, including vision and language models, can be seriously compromised by adversarial perturbations. It is therefore increasingly relevant to develop capabilities to certify their performance in the presence of the most effective adversarial attacks. Our paper offers a new approach to certify the performance of machine learning models in the presence of adversarial attacks with population level risk guarantees. In particular, we introduce the notion of $(\alpha,\zeta)$ machine learning model safety. We propose a hypothesis testing procedure, based on the availability of a calibration set, to derive statistical guarantees providing that the probability of declaring that the adversarial (population) risk of a machine learning model is less than $\alpha$ (i.e. the model is safe), while the model is in fact unsafe (i.e. the model adversarial population risk is higher than $\alpha$), is less than $\zeta$. We also propose Bayesian optimization algorithms to determine efficiently whether a machine learning model is $(\alpha,\zeta)$-safe in the presence of an adversarial attack, along with statistical guarantees. We apply our framework to a range of machine learning models including various sizes of vision Transformer (ViT) and ResNet models impaired by a variety of adversarial attacks, such as AutoAttack, SquareAttack and natural evolution strategy attack, to illustrate the operation of our approach. Importantly, we show that ViT's are generally more robust to adversarial attacks than ResNets, and ViT-large is more robust than smaller models. Our approach goes beyond existing empirical adversarial risk-based certification guarantees. It formulates rigorous (and provable) performance guarantees that can be used to satisfy regulatory requirements mandating the use of state-of-the-art technical tools.</li>
</ul>

<h3>Title: Cryptographically Assured Information Flow: Assured Remote Execution</h3>
<ul>
<li><strong>Authors: </strong>Scott L. Dyer, Christian A. Femrite, Joshua D. Guttman, Julian P. Lanson, Moses D. Liskov</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02630">https://arxiv.org/abs/2402.02630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02630">https://arxiv.org/pdf/2402.02630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02630]] Cryptographically Assured Information Flow: Assured Remote Execution(https://arxiv.org/abs/2402.02630)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Assured Remote Execution on a device is the ability of suitably authorized parties to construct secure channels with known processes -- i.e. processes executing known code -- running on it. Assured Remote Execution requires a hardware basis including cryptographic primitives. In this paper, we show that a simple hardware-level mechanism called Cryptographically Assured Information Flow (CAIF) enables Assured Remote Execution. CAIF is akin to some operations in existing Trusted Execution Environments, but securely implements an ideal functionality defined in terms of logging and confidential escrow. We show how to achieve Assured Remote Execution for a wide variety of processes on a CAIF device. Cryptographic protocol analysis demonstrates our security goals are achieved even against a strong adversary that may modify our programs and execute unauthorized programs on the device. Assured Remote Execution enables useful functionality such as trustworthy remote attestation, and provides some of the support needed for secure remote reprogramming. Acknowledgment. We are grateful to the MITRE Independent Research and Development Program for support.</li>
</ul>

<h3>Title: Learning to Understand: Identifying Interactions via the Mobius  Transform</h3>
<ul>
<li><strong>Authors: </strong>Justin S. Kang, Yigit E. Erginbas, Landon Butler, Ramtin Pedarsani, Kannan Ramchandran</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02631">https://arxiv.org/abs/2402.02631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02631">https://arxiv.org/pdf/2402.02631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02631]] Learning to Understand: Identifying Interactions via the Mobius  Transform(https://arxiv.org/abs/2402.02631)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>One of the most fundamental problems in machine learning is finding interpretable representations of the functions we learn. The Mobius transform is a useful tool for this because its coefficients correspond to unique importance scores on sets of input variables. The Mobius Transform is strongly related (and in some cases equivalent) to the concept of Shapley value, which is a widely used game-theoretic notion of importance. This work focuses on the (typical) regime where the fraction of non-zero Mobius coefficients (and thus interactions between inputs) is small compared to the set of all $2^n$ possible interactions between $n$ inputs. When there are $K = O(2^{n \delta})$ with $\delta \leq \frac{1}{3}$ non-zero coefficients chosen uniformly at random, our algorithm exactly recovers the Mobius transform in $O(Kn)$ samples and $O(Kn^2)$ time with vanishing error as $K \rightarrow \infty$, the first non-adaptive algorithm to do so. We also uncover a surprising connection between group testing and the Mobius transform. In the case where all interactions are between at most $t = \Theta(n^{\alpha})$ inputs, for $\alpha < 0.409$, we are able to leverage results from group testing to provide the first algorithm that computes the Mobius transform in $O(Kt\log n)$ sample complexity and $O(K\mathrm{poly}(n))$ time with vanishing error as $K \rightarrow \infty$. Finally, we present a robust version of this algorithm that achieves the same sample and time complexity under some assumptions, but with a factor depending on noise variance. Our work is deeply interdisciplinary, drawing from tools spanning across signal processing, algebra, information theory, learning theory and group testing to address this important problem at the forefront of machine learning.</li>
</ul>

<h3>Title: Predicting Machine Translation Performance on Low-Resource Languages:  The Role of Domain Similarity</h3>
<ul>
<li><strong>Authors: </strong>Eric Khiu, Hasti Toossi, David Anugraha, Jinyu Liu, Jiaxu Li, Juan Armando Parra Flores, Leandro Acros Roman, A. Seza Doruz, En-Shiun Annie Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02633">https://arxiv.org/abs/2402.02633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02633">https://arxiv.org/pdf/2402.02633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02633]] Predicting Machine Translation Performance on Low-Resource Languages:  The Role of Domain Similarity(https://arxiv.org/abs/2402.02633)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning and testing a multilingual large language model is expensive and challenging for low-resource languages (LRLs). While previous studies have predicted the performance of natural language processing (NLP) tasks using machine learning methods, they primarily focus on high-resource languages, overlooking LRLs and shifts across domains. Focusing on LRLs, we investigate three factors: the size of the fine-tuning corpus, the domain similarity between fine-tuning and testing corpora, and the language similarity between source and target languages. We employ classical regression models to assess how these factors impact the model's performance. Our results indicate that domain similarity has the most critical impact on predicting the performance of Machine Translation models.</li>
</ul>

<h3>Title: Key-Graph Transformer for Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Bin Ren, Yawei Li, Jingyun Liang, Rakesh Ranjan, Mengyuan Liu, Rita Cucchiara, Luc Van Gool, Nicu Sebe</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02634">https://arxiv.org/abs/2402.02634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02634">https://arxiv.org/pdf/2402.02634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02634]] Key-Graph Transformer for Image Restoration(https://arxiv.org/abs/2402.02634)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While it is crucial to capture global information for effective image restoration (IR), integrating such cues into transformer-based methods becomes computationally expensive, especially with high input resolution. Furthermore, the self-attention mechanism in transformers is prone to considering unnecessary global cues from unrelated objects or regions, introducing computational inefficiencies. In response to these challenges, we introduce the Key-Graph Transformer (KGT) in this paper. Specifically, KGT views patch features as graph nodes. The proposed Key-Graph Constructor efficiently forms a sparse yet representative Key-Graph by selectively connecting essential nodes instead of all the nodes. Then the proposed Key-Graph Attention is conducted under the guidance of the Key-Graph only among selected nodes with linear computational complexity within each window. Extensive experiments across 6 IR tasks confirm the proposed KGT's state-of-the-art performance, showcasing advancements both quantitatively and qualitatively.</li>
</ul>

<h3>Title: Towards Principled Risk Scores for Space Cyber Risk Management</h3>
<ul>
<li><strong>Authors: </strong>Ekzhin Ear, Brandon Bailey, Shouhuai Xu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02635">https://arxiv.org/abs/2402.02635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02635">https://arxiv.org/pdf/2402.02635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02635]] Towards Principled Risk Scores for Space Cyber Risk Management(https://arxiv.org/abs/2402.02635)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Space is an emerging domain critical to humankind. Correspondingly, space cybersecurity is an emerging field with much research to be done. To help space cybersecurity practitioners better manage cyber risks, The Aerospace Corporation proposed Notional Risk Scores (NRS) within their Space Attack Research and Tactic Analysis (SPARTA) framework, which can be applied to quantify the cyber risks associated with space infrastructures and systems. While intended for adoption by practitioners, NRS has not been analyzed with real-world scenarios, putting its effectiveness into question. In this paper we analyze NRS via a real-world cyber attack scenario against a satellite, and characterize the strengths, weaknesses, and applicability of NRS. The characterization prompts us to propose a set of desired properties to guide the design of future NRS. As a first step along this direction, we further propose a formalism to serve as a baseline for designing future NRS with those desired properties.</li>
</ul>

<h3>Title: Can Large Language Models Learn Independent Causal Mechanisms?</h3>
<ul>
<li><strong>Authors: </strong>Gal Gendron, Bao Trung Nguyen, Alex Yuxuan Peng, Michael Witbrock, Gillian Dobbie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IT, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02636">https://arxiv.org/abs/2402.02636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02636">https://arxiv.org/pdf/2402.02636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02636]] Can Large Language Models Learn Independent Causal Mechanisms?(https://arxiv.org/abs/2402.02636)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Despite impressive performance on language modelling and complex reasoning tasks, Large Language Models (LLMs) fall short on the same tasks in uncommon settings or with distribution shifts, exhibiting some lack of generalisation ability. This issue has usually been alleviated by feeding more training data into the LLM. However, this method is brittle, as the scope of tasks may not be readily predictable or may evolve, and updating the model with new data generally requires extensive additional training. By contrast, systems, such as causal models, that learn abstract variables and causal relationships can demonstrate increased robustness against changes in the distribution. One reason for this success is the existence and use of Independent Causal Mechanisms (ICMs) representing high-level concepts that only sparsely interact. In this work, we apply two concepts from causality to learn ICMs within LLMs. We develop a new LLM architecture composed of multiple sparsely interacting language modelling modules. We introduce a routing scheme to induce specialisation of the network into domain-specific modules. We also present a Mutual Information minimisation objective that trains a separate module to learn abstraction and domain-invariant mechanisms. We show that such causal constraints can improve out-of-distribution performance on abstract and causal reasoning tasks.</li>
</ul>

<h3>Title: Chain-of-Feedback: Mitigating the Effects of Inconsistency in Responses</h3>
<ul>
<li><strong>Authors: </strong>Jinwoo Ahn</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02648">https://arxiv.org/abs/2402.02648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02648">https://arxiv.org/pdf/2402.02648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02648]] Chain-of-Feedback: Mitigating the Effects of Inconsistency in Responses(https://arxiv.org/abs/2402.02648)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) frequently suffer from knowledge-intensive questions, often being inconsistent by providing different outputs despite given the same input. The response quality worsens when the user expresses a firm opposing stance which causes the LLMs to adjust its response despite the correct initial one. These behaviors decrease the reliability and validity of the responses provided by these models. In this paper, we attempt to 1) raise awareness of the inherent risks that follow from overly relying on AI agents like ChatGPT by showing how Chain-of-Feedback (CoF) triggers LLMs to deviate more from the actual answer and 2) suggest a novel prompting method, Recursive Chain of Feedback (R-CoF), that we are conducting further study. The CoF system takes in an open-ended multi-step question. Then, we repetitively provide meaningless feedback requesting another attempt. Our preliminary experiments show that such feedback only decreases the quality of the response. On the other hand, to mitigate the effects of the aforementioned inconsistencies, we present a novel method of recursively revising the initial incorrect reasoning provided by the LLM by repetitively breaking down each incorrect step into smaller individual problems.</li>
</ul>

<h3>Title: Densely Decoded Networks with Adaptive Deep Supervision for Medical  Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Suraj Mishra</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02649">https://arxiv.org/abs/2402.02649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02649">https://arxiv.org/pdf/2402.02649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02649]] Densely Decoded Networks with Adaptive Deep Supervision for Medical  Image Segmentation(https://arxiv.org/abs/2402.02649)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation using deep neural networks has been highly successful. However, the effectiveness of these networks is often limited by inadequate dense prediction and inability to extract robust features. To achieve refined dense prediction, we propose densely decoded networks (ddn), by selectively introducing 'crutch' network connections. Such 'crutch' connections in each upsampling stage of the network decoder (1) enhance target localization by incorporating high resolution features from the encoder, and (2) improve segmentation by facilitating multi-stage contextual information flow. Further, we present a training strategy based on adaptive deep supervision (ads), which exploits and adapts specific attributes of input dataset, for robust feature extraction. In particular, ads strategically locates and deploys auxiliary supervision, by matching the average input object size with the layer-wise effective receptive fields (lerf) of a network, resulting in a class of ddns. Such inclusion of 'companion objective' from a specific hidden layer, helps the model pay close attention to some distinct input-dependent features, which the network might otherwise 'ignore' during training. Our new networks and training strategy are validated on 4 diverse datasets of different modalities, demonstrating their effectiveness.</li>
</ul>

<h3>Title: RACER: An LLM-powered Methodology for Scalable Analysis of  Semi-structured Mental Health Interviews</h3>
<ul>
<li><strong>Authors: </strong>Satpreet Harcharan Singh, Kevin Jiang, Kanchan Bhasin, Ashutosh Sabharwal, Nidal Moukaddam, Ankit B Patel</a></li>
<li><strong>Subjects: </strong>cs.CL, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02656">https://arxiv.org/abs/2402.02656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02656">https://arxiv.org/pdf/2402.02656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02656]] RACER: An LLM-powered Methodology for Scalable Analysis of  Semi-structured Mental Health Interviews(https://arxiv.org/abs/2402.02656)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Semi-structured interviews (SSIs) are a commonly employed data-collection method in healthcare research, offering in-depth qualitative insights into subject experiences. Despite their value, the manual analysis of SSIs is notoriously time-consuming and labor-intensive, in part due to the difficulty of extracting and categorizing emotional responses, and challenges in scaling human evaluation for large populations. In this study, we develop RACER, a Large Language Model (LLM) based expert-guided automated pipeline that efficiently converts raw interview transcripts into insightful domain-relevant themes and sub-themes. We used RACER to analyze SSIs conducted with 93 healthcare professionals and trainees to assess the broad personal and professional mental health impacts of the COVID-19 crisis. RACER achieves moderately high agreement with two human evaluators (72%), which approaches the human inter-rater agreement (77%). Interestingly, LLMs and humans struggle with similar content involving nuanced emotional, ambivalent/dialectical, and psychological statements. Our study highlights the opportunities and challenges in using LLMs to improve research efficiency and opens new avenues for scalable analysis of SSIs in healthcare research.</li>
</ul>

<h3>Title: Image-Caption Encoding for Improving Zero-Shot Generalization</h3>
<ul>
<li><strong>Authors: </strong>Eric Yang Yu, Christopher Liao, Sathvik Ravi, Theodoros Tsiligkaridis, Brian Kulis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02662">https://arxiv.org/abs/2402.02662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02662">https://arxiv.org/pdf/2402.02662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02662]] Image-Caption Encoding for Improving Zero-Shot Generalization(https://arxiv.org/abs/2402.02662)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advances in vision-language models have combined contrastive approaches with generative methods to achieve state-of-the-art (SOTA) on downstream inference tasks like zero-shot image classification. However, a persistent issue of these models for image classification is their out-of-distribution (OOD) generalization capabilities. We first show that when an OOD data point is misclassified, the correct class can be typically found in the Top-K predicted classes. In order to steer the model prediction toward the correct class within the top predicted classes, we propose the Image-Caption Encoding (ICE) method, a straightforward approach that directly enforces consistency between the image-conditioned and caption-conditioned predictions at evaluation time only. Intuitively, we take advantage of unique properties of the generated captions to guide our local search for the correct class label within the Top-K predicted classes. We show that our method can be easily combined with other SOTA methods to enhance Top-1 OOD accuracies by 0.5% on average and up to 3% on challenging datasets. Our code: https://github.com/Chris210634/ice</li>
</ul>

<h3>Title: Counterfactual Fairness Is Not Demographic Parity, and Other  Observations</h3>
<ul>
<li><strong>Authors: </strong>Ricardo Silva</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02663">https://arxiv.org/abs/2402.02663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02663">https://arxiv.org/pdf/2402.02663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02663]] Counterfactual Fairness Is Not Demographic Parity, and Other  Observations(https://arxiv.org/abs/2402.02663)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Blanket statements of equivalence between causal concepts and purely probabilistic concepts should be approached with care. In this short note, I examine a recent claim that counterfactual fairness is equivalent to demographic parity. The claim fails to hold up upon closer examination. I will take the opportunity to address some broader misunderstandings about counterfactual fairness.</li>
</ul>

<h3>Title: Verifiable evaluations of machine learning models using zkSNARKs</h3>
<ul>
<li><strong>Authors: </strong>Tobin South, Alexander Camuto, Shrey Jain, Shayla Nguyen, Robert Mahari, Christian Paquin, Jason Morton, Alex 'Sandy' Pentland</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02675">https://arxiv.org/abs/2402.02675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02675">https://arxiv.org/pdf/2402.02675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02675]] Verifiable evaluations of machine learning models using zkSNARKs(https://arxiv.org/abs/2402.02675)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>In a world of increasing closed-source commercial machine learning models, model evaluations from developers must be taken at face value. These benchmark results, whether over task accuracy, bias evaluations, or safety checks, are traditionally impossible to verify by a model end-user without the costly or impossible process of re-performing the benchmark on black-box model outputs. This work presents a method of verifiable model evaluation using model inference through zkSNARKs. The resulting zero-knowledge computational proofs of model outputs over datasets can be packaged into verifiable evaluation attestations showing that models with fixed private weights achieve stated performance or fairness metrics over public inputs. These verifiable attestations can be performed on any standard neural network model with varying compute requirements. For the first time, we demonstrate this across a sample of real-world models and highlight key challenges and design solutions. This presents a new transparency paradigm in the verifiable evaluation of private models.</li>
</ul>

<h3>Title: Large Language Models are Geographically Biased</h3>
<ul>
<li><strong>Authors: </strong>Rohin Manvi, Samar Khanna, Marshall Burke, David Lobell, Stefano Ermon</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02680">https://arxiv.org/abs/2402.02680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02680">https://arxiv.org/pdf/2402.02680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02680]] Large Language Models are Geographically Biased(https://arxiv.org/abs/2402.02680)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) inherently carry the biases contained in their training corpora, which can lead to the perpetuation of societal harm. As the impact of these foundation models grows, understanding and evaluating their biases becomes crucial to achieving fairness and accuracy. We propose to study what LLMs know about the world we live in through the lens of geography. This approach is particularly powerful as there is ground truth for the numerous aspects of human life that are meaningfully projected onto geographic space such as culture, race, language, politics, and religion. We show various problematic geographic biases, which we define as systemic errors in geospatial predictions. Initially, we demonstrate that LLMs are capable of making accurate zero-shot geospatial predictions in the form of ratings that show strong monotonic correlation with ground truth (Spearman's $\rho$ of up to 0.89). We then show that LLMs exhibit common biases across a range of objective and subjective topics. In particular, LLMs are clearly biased against locations with lower socioeconomic conditions (e.g. most of Africa) on a variety of sensitive subjective topics such as attractiveness, morality, and intelligence (Spearman's $\rho$ of up to 0.70). Finally, we introduce a bias score to quantify this and find that there is significant variation in the magnitude of bias across existing LLMs.</li>
</ul>

<h3>Title: Poisson Process for Bayesian Optimization</h3>
<ul>
<li><strong>Authors: </strong>Xiaoxing Wang, Jiaxing Li, Chao Xue, Wei Liu, Weifeng Liu, Xiaokang Yang, Junchi Yan, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02687">https://arxiv.org/abs/2402.02687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02687">https://arxiv.org/pdf/2402.02687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02687]] Poisson Process for Bayesian Optimization(https://arxiv.org/abs/2402.02687)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>BayesianOptimization(BO) is a sample-efficient black-box optimizer, and extensive methods have been proposed to build the absolute function response of the black-box function through a probabilistic surrogate model, including Tree-structured Parzen Estimator (TPE), random forest (SMAC), and Gaussian process (GP). However, few methods have been explored to estimate the relative rankings of candidates, which can be more robust to noise and have better practicality than absolute function responses, especially when the function responses are intractable but preferences can be acquired. To this end, we propose a novel ranking-based surrogate model based on the Poisson process and introduce an efficient BO framework, namely Poisson Process Bayesian Optimization (PoPBO). Two tailored acquisition functions are further derived from classic LCB and EI to accommodate it. Compared to the classic GP-BO method, our PoPBO has lower computation costs and better robustness to noise, which is verified by abundant experiments. The results on both simulated and real-world benchmarks, including hyperparameter optimization (HPO) and neural architecture search (NAS), show the effectiveness of PoPBO.</li>
</ul>

<h3>Title: Exploiting Class Probabilities for Black-box Sentence-level Attacks</h3>
<ul>
<li><strong>Authors: </strong>Raha Moraffah, Huan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02695">https://arxiv.org/abs/2402.02695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02695">https://arxiv.org/pdf/2402.02695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02695]] Exploiting Class Probabilities for Black-box Sentence-level Attacks(https://arxiv.org/abs/2402.02695)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Sentence-level attacks craft adversarial sentences that are synonymous with correctly-classified sentences but are misclassified by the text classifiers. Under the black-box setting, classifiers are only accessible through their feedback to queried inputs, which is predominately available in the form of class probabilities. Even though utilizing class probabilities results in stronger attacks, due to the challenges of using them for sentence-level attacks, existing attacks use either no feedback or only the class labels. Overcoming the challenges, we develop a novel algorithm that uses class probabilities for black-box sentence-level attacks, investigate the effectiveness of using class probabilities on the attack's success, and examine the question if it is worthy or practical to use class probabilities by black-box sentence-level attacks. We conduct extensive evaluations of the proposed attack comparing with the baselines across various classifiers and benchmark datasets.</li>
</ul>

<h3>Title: Causal Feature Selection for Responsible Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Raha Moraffah, Paras Sheth, Saketh Vishnubhatla, Huan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02696">https://arxiv.org/abs/2402.02696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02696">https://arxiv.org/pdf/2402.02696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02696]] Causal Feature Selection for Responsible Machine Learning(https://arxiv.org/abs/2402.02696)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, interpretability</a></li>
<li><strong>Abstract: </strong>Machine Learning (ML) has become an integral aspect of many real-world applications. As a result, the need for responsible machine learning has emerged, focusing on aligning ML models to ethical and social values, while enhancing their reliability and trustworthiness. Responsible ML involves many issues. This survey addresses four main issues: interpretability, fairness, adversarial robustness, and domain generalization. Feature selection plays a pivotal role in the responsible ML tasks. However, building upon statistical correlations between variables can lead to spurious patterns with biases and compromised performance. This survey focuses on the current study of causal feature selection: what it is and how it can reinforce the four aspects of responsible ML. By identifying features with causal impacts on outcomes and distinguishing causality from correlation, causal feature selection is posited as a unique approach to ensuring ML models to be ethically and socially responsible in high-stakes applications.</li>
</ul>

<h3>Title: Position Paper: What Can Large Language Models Tell Us about Time Series  Analysis</h3>
<ul>
<li><strong>Authors: </strong>Ming Jin, Yifan Zhang, Wei Chen, Kexin Zhang, Yuxuan Liang, Bin Yang, Jindong Wang, Shirui Pan, Qingsong Wen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02713">https://arxiv.org/abs/2402.02713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02713">https://arxiv.org/pdf/2402.02713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02713]] Position Paper: What Can Large Language Models Tell Us about Time Series  Analysis(https://arxiv.org/abs/2402.02713)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Time series analysis is essential for comprehending the complexities inherent in various real-world systems and applications. Although large language models (LLMs) have recently made significant strides, the development of artificial general intelligence (AGI) equipped with time series analysis capabilities remains in its nascent phase. Most existing time series models heavily rely on domain knowledge and extensive model tuning, predominantly focusing on prediction tasks. In this paper, we argue that current LLMs have the potential to revolutionize time series analysis, thereby promoting efficient decision-making and advancing towards a more universal form of time series analytical intelligence. Such advancement could unlock a wide range of possibilities, including modality switching and time series question answering. We encourage researchers and practitioners to recognize the potential of LLMs in advancing time series analysis and emphasize the need for trust in these related efforts. Furthermore, we detail the seamless integration of time series analysis with existing LLM technologies and outline promising avenues for future research.</li>
</ul>

<h3>Title: Discounted Adaptive Online Prediction</h3>
<ul>
<li><strong>Authors: </strong>Zhiyu Zhang, David Bombara, Heng Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02720">https://arxiv.org/abs/2402.02720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02720">https://arxiv.org/pdf/2402.02720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02720]] Discounted Adaptive Online Prediction(https://arxiv.org/abs/2402.02720)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Online learning is not always about memorizing everything. Since the future can be statistically very different from the past, a critical challenge is to gracefully forget the history while new data comes in. To formalize this intuition, we revisit the classical notion of discounted regret using recently developed techniques in adaptive online learning. Our main result is a new algorithm that adapts to the complexity of both the loss sequence and the comparator, improving the widespread non-adaptive algorithm - gradient descent with a constant learning rate. In particular, our theoretical guarantee does not require any structural assumption beyond convexity, and the algorithm is provably robust to suboptimal hyperparameter tuning. We further demonstrate such benefits through online conformal prediction, a downstream online learning task with set-membership decisions.</li>
</ul>

<h3>Title: FDNet: Frequency Domain Denoising Network For Cell Segmentation in  Astrocytes Derived From Induced Pluripotent Stem Cells</h3>
<ul>
<li><strong>Authors: </strong>Haoran Li, Jiahua Shi, Huaming Chen, Bo Du, Simon Maksour, Gabrielle Phillips, Mirella Dottori, Jun Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02724">https://arxiv.org/abs/2402.02724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02724">https://arxiv.org/pdf/2402.02724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02724]] FDNet: Frequency Domain Denoising Network For Cell Segmentation in  Astrocytes Derived From Induced Pluripotent Stem Cells(https://arxiv.org/abs/2402.02724)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Artificially generated induced pluripotent stem cells (iPSCs) from somatic cells play an important role for disease modeling and drug screening of neurodegenerative diseases. Astrocytes differentiated from iPSCs are important targets to investigate neuronal metabolism. The astrocyte differentiation progress can be monitored through the variations of morphology observed from microscopy images at different differentiation stages, then determined by molecular biology techniques upon maturation. However, the astrocytes usually ``perfectly'' blend into the background and some of them are covered by interference information (i.e., dead cells, media sediments, and cell debris), which makes astrocytes difficult to observe. Due to the lack of annotated datasets, the existing state-of-the-art deep learning approaches cannot be used to address this issue. In this paper, we introduce a new task named astrocyte segmentation with a novel dataset, called IAI704, which contains 704 images and their corresponding pixel-level annotation masks. Moreover, a novel frequency domain denoising network, named FDNet, is proposed for astrocyte segmentation. In detail, our FDNet consists of a contextual information fusion module (CIF), an attention block (AB), and a Fourier transform block (FTB). CIF and AB fuse multi-scale feature embeddings to localize the astrocytes. FTB transforms feature embeddings into the frequency domain and conducts a high-pass filter to eliminate interference information. Experimental results demonstrate the superiority of our proposed FDNet over the state-of-the-art substitutes in astrocyte segmentation, shedding insights for iPSC differentiation progress prediction.</li>
</ul>

<h3>Title: Innovative Cybersickness Detection: Exploring Head Movement Patterns in  Virtual Reality</h3>
<ul>
<li><strong>Authors: </strong>Masoud Salehi, Nikoo Javadpour, Brietta Beisner, Mohammadamin Sanaei, Stephen B. Gilbert</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02725">https://arxiv.org/abs/2402.02725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02725">https://arxiv.org/pdf/2402.02725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02725]] Innovative Cybersickness Detection: Exploring Head Movement Patterns in  Virtual Reality(https://arxiv.org/abs/2402.02725)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Despite the widespread adoption of Virtual Reality (VR) technology, cybersickness remains a barrier for some users. This research investigates head movement patterns as a novel physiological marker for cybersickness detection. Unlike traditional markers, head movements provide a continuous, non-invasive measure that can be easily captured through the sensors embedded in all commercial VR headsets. We used a publicly available dataset from a VR experiment involving 75 participants and analyzed head movements across six axes. An extensive feature extraction process was then performed on the head movement dataset and its derivatives, including velocity, acceleration, and jerk. Three categories of features were extracted, encompassing statistical, temporal, and spectral features. Subsequently, we employed the Recursive Feature Elimination method to select the most important and effective features. In a series of experiments, we trained a variety of machine learning algorithms. The results demonstrate a 76% accuracy and 83% precision in predicting cybersickness in the subjects based on the head movements. This study contribution to the cybersickness literature lies in offering a preliminary analysis of a new source of data and providing insight into the relationship of head movements and cybersickness.</li>
</ul>

<h3>Title: A Generative Approach to Surrogate-based Black-box Attacks</h3>
<ul>
<li><strong>Authors: </strong>Raha Moraffah, Huan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02732">https://arxiv.org/abs/2402.02732</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02732">https://arxiv.org/pdf/2402.02732</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02732]] A Generative Approach to Surrogate-based Black-box Attacks(https://arxiv.org/abs/2402.02732)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, generative</a></li>
<li><strong>Abstract: </strong>Surrogate-based black-box attacks have exposed the heightened vulnerability of DNNs. These attacks are designed to craft adversarial examples for any samples with black-box target feedback for only a given set of samples. State-of-the-art surrogate-based attacks involve training a discriminative surrogate that mimics the target's outputs. The goal is to learn the decision boundaries of the target. The surrogate is then attacked by white-box attacks to craft adversarial examples similar to the original samples but belong to other classes. With limited samples, the discriminative surrogate fails to accurately learn the target's decision boundaries, and these surrogate-based attacks suffer from low success rates. Different from the discriminative approach, we propose a generative surrogate that learns the distribution of samples residing on or close to the target's decision boundaries. The distribution learned by the generative surrogate can be used to craft adversarial examples that have imperceptible differences from the original samples but belong to other classes. The proposed generative approach results in attacks with remarkably high attack success rates on various targets and datasets.</li>
</ul>

<h3>Title: ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer</h3>
<ul>
<li><strong>Authors: </strong>Bumsoo Kim, Abdul Muqeet, Kyuchul Lee, Sanghyun Seo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02733">https://arxiv.org/abs/2402.02733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02733">https://arxiv.org/pdf/2402.02733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02733]] ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer(https://arxiv.org/abs/2402.02733)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Face re-aging is a prominent field in computer vision and graphics, with significant applications in photorealistic domains such as movies, advertising, and live streaming. Recently, the need to apply face re-aging to non-photorealistic images, like comics, illustrations, and animations, has emerged as an extension in various entertainment sectors. However, the absence of a network capable of seamlessly editing the apparent age on NPR images means that these tasks have been confined to a naive approach, applying each task sequentially. This often results in unpleasant artifacts and a loss of facial attributes due to domain discrepancies. In this paper, we introduce a novel one-stage method for face re-aging combined with portrait style transfer, executed in a single generative step. We leverage existing face re-aging and style transfer networks, both trained within the same PR domain. Our method uniquely fuses distinct latent vectors, each responsible for managing aging-related attributes and NPR appearance. Adopting an exemplar-based approach, our method offers greater flexibility than domain-level fine-tuning approaches, which typically require separate training or fine-tuning for each domain. This effectively addresses the limitation of requiring paired datasets for re-aging and domain-level, data-driven approaches for stylization. Our experiments show that our model can effortlessly generate re-aged images while simultaneously transferring the style of examples, maintaining both natural appearance and controllability.</li>
</ul>

<h3>Title: Improving Robustness of LiDAR-Camera Fusion Model against Weather  Corruption from Fusion Strategy Perspective</h3>
<ul>
<li><strong>Authors: </strong>Yihao Huang, Kaiyuan Yu, Qing Guo, Felix Juefei-Xu, Xiaojun Jia, Tianlin Li, Geguang Pu, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02738">https://arxiv.org/abs/2402.02738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02738">https://arxiv.org/pdf/2402.02738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02738]] Improving Robustness of LiDAR-Camera Fusion Model against Weather  Corruption from Fusion Strategy Perspective(https://arxiv.org/abs/2402.02738)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, LiDAR-camera fusion models have markedly advanced 3D object detection tasks in autonomous driving. However, their robustness against common weather corruption such as fog, rain, snow, and sunlight in the intricate physical world remains underexplored. In this paper, we evaluate the robustness of fusion models from the perspective of fusion strategies on the corrupted dataset. Based on the evaluation, we further propose a concise yet practical fusion strategy to enhance the robustness of the fusion models, namely flexibly weighted fusing features from LiDAR and camera sources to adapt to varying weather scenarios. Experiments conducted on four types of fusion models, each with two distinct lightweight implementations, confirm the broad applicability and effectiveness of the approach.</li>
</ul>

<h3>Title: DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yang Sui, Huy Phan, Jinqi Xiao, Tianfang Zhang, Zijie Tang, Cong Shi, Yan Wang, Yingying Chen, Bo Yuan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02739">https://arxiv.org/abs/2402.02739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02739">https://arxiv.org/pdf/2402.02739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02739]] DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models(https://arxiv.org/abs/2402.02739)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal, diffusion, generative</a></li>
<li><strong>Abstract: </strong>In the exciting generative AI era, the diffusion model has emerged as a very powerful and widely adopted content generation and editing tool for various data modalities, making the study of their potential security risks very necessary and critical. Very recently, some pioneering works have shown the vulnerability of the diffusion model against backdoor attacks, calling for in-depth analysis and investigation of the security challenges of this popular and fundamental AI technique. In this paper, for the first time, we systematically explore the detectability of the poisoned noise input for the backdoored diffusion models, an important performance metric yet little explored in the existing works. Starting from the perspective of a defender, we first analyze the properties of the trigger pattern in the existing diffusion backdoor attacks, discovering the important role of distribution discrepancy in Trojan detection. Based on this finding, we propose a low-cost trigger detection mechanism that can effectively identify the poisoned input noise. We then take a further step to study the same problem from the attack side, proposing a backdoor attack strategy that can learn the unnoticeable trigger to evade our proposed detection scheme. Empirical evaluations across various diffusion models and datasets demonstrate the effectiveness of the proposed trigger detection and detection-evading attack strategy. For trigger detection, our distribution discrepancy-based solution can achieve a 100\% detection rate for the Trojan triggers used in the existing works. For evading trigger detection, our proposed stealthy trigger design approach performs end-to-end learning to make the distribution of poisoned noise input approach that of benign noise, enabling nearly 100\% detection pass rate with very high attack and benign performance for the backdoored diffusion models.</li>
</ul>

<h3>Title: Standard Gaussian Process is All You Need for High-Dimensional Bayesian  Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zhitong Xu, Shandian Zhe</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02746">https://arxiv.org/abs/2402.02746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02746">https://arxiv.org/pdf/2402.02746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02746]] Standard Gaussian Process is All You Need for High-Dimensional Bayesian  Optimization(https://arxiv.org/abs/2402.02746)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>There has been a long-standing and widespread belief that Bayesian Optimization (BO) with standard Gaussian process (GP), referred to as standard BO, is ineffective in high-dimensional optimization problems. This perception may partly stem from the intuition that GPs struggle with high-dimensional inputs for covariance modeling and function estimation. While these concerns seem reasonable, empirical evidence supporting this belief is lacking. In this paper, we systematically investigated BO with standard GP regression across a variety of synthetic and real-world benchmark problems for high-dimensional optimization. Surprisingly, the performance with standard GP consistently ranks among the best, often outperforming existing BO methods specifically designed for high-dimensional optimization by a large margin. Contrary to the stereotype, we found that standard GP can serve as a capable surrogate for learning high-dimensional target functions. Without strong structural assumptions, BO with standard GP not only excels in high-dimensional optimization but also proves robust in accommodating various structures within the target functions. Furthermore, with standard GP, achieving promising optimization performance is possible by only using maximum likelihood estimation, eliminating the need for expensive Markov-Chain Monte Carlo (MCMC) sampling that might be required by more complex surrogate models. We thus advocate for a re-evaluation and in-depth study of the potential of standard BO in addressing high-dimensional problems.</li>
</ul>

<h3>Title: KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache</h3>
<ul>
<li><strong>Authors: </strong>Zirui Liu, Jiayi Yuan, Hongye Jin, Shaochen Zhong, Zhaozhuo Xu, Vladimir Braverman, Beidi Chen, Xia Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02750">https://arxiv.org/abs/2402.02750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02750">https://arxiv.org/pdf/2402.02750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02750]] KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache(https://arxiv.org/abs/2402.02750)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Efficiently serving large language models (LLMs) requires batching many requests together to reduce the cost per request. Yet, the key-value (KV) cache, which stores attention keys and values to avoid re-computations, significantly increases memory demands and becomes the new bottleneck in speed and memory usage. This memory demand increases with larger batch sizes and longer context lengths. Additionally, the inference speed is limited by the size of KV cache, as the GPU's SRAM must load the entire KV cache from the main GPU memory for each token generated, causing the computational core to be idle during this process. A straightforward and effective solution to reduce KV cache size is quantization, which decreases the total bytes taken by KV cache. However, there is a lack of in-depth studies that explore the element distribution of KV cache to understand the hardness and limitation of KV cache quantization. To fill the gap, we conducted a comprehensive study on the element distribution in KV cache of popular LLMs. Our findings indicate that the key cache should be quantized per-channel, i.e., group elements along the channel dimension and quantize them together. In contrast, the value cache should be quantized per-token. From this analysis, we developed a tuning-free 2bit KV cache quantization algorithm, named KIVI. With the hardware-friendly implementation, KIVI can enable Llama (Llama-2), Falcon, and Mistral models to maintain almost the same quality while using $\mathbf{2.6\times}$ less peak memory usage (including the model weight). This reduction in memory usage enables up to $\mathbf{4\times}$ larger batch size, bringing $\mathbf{2.35\times \sim 3.47\times}$ throughput on real LLM inference workload. The source code is available at https://github.com/jy-yuan/KIVI.</li>
</ul>

<h3>Title: Transmission Line Detection Based on Improved Hough Transform</h3>
<ul>
<li><strong>Authors: </strong>Wei Song, Pei Li, Man Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02761">https://arxiv.org/abs/2402.02761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02761">https://arxiv.org/pdf/2402.02761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02761]] Transmission Line Detection Based on Improved Hough Transform(https://arxiv.org/abs/2402.02761)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>To address the challenges of low detection accuracy and high false positive rates of transmission lines in UAV (Unmanned Aerial Vehicle) images, we explore the linear features and spatial distribution. We introduce an enhanced stochastic Hough transform technique tailored for detecting transmission lines in complex backgrounds. By employing the Hessian matrix for initial preprocessing of transmission lines, and utilizing boundary search and pixel row segmentation, our approach distinguishes transmission line areas from the background. We significantly reduce both false positives and missed detections, thereby improving the accuracy of transmission line identification. Experiments demonstrate that our method not only processes images more rapidly, but also yields superior detection results compared to conventional and random Hough transform methods.</li>
</ul>

<h3>Title: Contrastive Diffuser: Planning Towards High Return States via  Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Yixiang Shan, Zhengbang Zhu, Ting Long, Qifan Liang, Yi Chang, Weinan Zhang, Liang Yin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02772">https://arxiv.org/abs/2402.02772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02772">https://arxiv.org/pdf/2402.02772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02772]] Contrastive Diffuser: Planning Towards High Return States via  Contrastive Learning(https://arxiv.org/abs/2402.02772)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Applying diffusion models in reinforcement learning for long-term planning has gained much attention recently. Several diffusion-based methods have successfully leveraged the modeling capabilities of diffusion for arbitrary distributions. These methods generate subsequent trajectories for planning and have demonstrated significant improvement. However, these methods are limited by their plain base distributions and their overlooking of the diversity of samples, in which different states have different returns. They simply leverage diffusion to learn the distribution of offline dataset, generate the trajectories whose states share the same distribution with the offline dataset. As a result, the probability of these models reaching the high-return states is largely dependent on the dataset distribution. Even equipped with the guidance model, the performance is still suppressed. To address these limitations, in this paper, we propose a novel method called CDiffuser, which devises a return contrast mechanism to pull the states in generated trajectories towards high-return states while pushing them away from low-return states to improve the base distribution. Experiments on 14 commonly used D4RL benchmarks demonstrate the effectiveness of our proposed method. Our code is publicly available at https://anonymous.4open.science/r/ContrastiveDiffuser.</li>
</ul>

<h3>Title: From Partial to Strictly Incremental Constituent Parsing</h3>
<ul>
<li><strong>Authors: </strong>Ana Ezquerro, Carlos Gmez-Rodrguez, David Vilares</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02782">https://arxiv.org/abs/2402.02782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02782">https://arxiv.org/pdf/2402.02782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02782]] From Partial to Strictly Incremental Constituent Parsing(https://arxiv.org/abs/2402.02782)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We study incremental constituent parsers to assess their capacity to output trees based on prefix representations alone. Guided by strictly left-to-right generative language models and tree-decoding modules, we build parsers that adhere to a strong definition of incrementality across languages. This builds upon work that asserted incrementality, but that mostly only enforced it on either the encoder or the decoder. Finally, we conduct an analysis against non-incremental and partially incremental models.</li>
</ul>

<h3>Title: Stable and Robust Deep Learning By Hyperbolic Tangent Exponential Linear  Unit (TeLU)</h3>
<ul>
<li><strong>Authors: </strong>Alfredo Fernandez, Ankur Mali</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02790">https://arxiv.org/abs/2402.02790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02790">https://arxiv.org/pdf/2402.02790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02790]] Stable and Robust Deep Learning By Hyperbolic Tangent Exponential Linear  Unit (TeLU)(https://arxiv.org/abs/2402.02790)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce the Hyperbolic Tangent Exponential Linear Unit (TeLU), a novel neural network activation function, represented as $f(x) = x{\cdot}tanh(e^x)$. TeLU is designed to overcome the limitations of conventional activation functions like ReLU, GELU, and Mish by addressing the vanishing and, to an extent, the exploding gradient problems. Our theoretical analysis and empirical assessments reveal that TeLU outperforms existing activation functions in stability and robustness, effectively adjusting activation outputs' mean towards zero for enhanced training stability and convergence. Extensive evaluations against popular activation functions (ReLU, GELU, SiLU, Mish, Logish, Smish) across advanced architectures, including Resnet-50, demonstrate TeLU's lower variance and superior performance, even under hyperparameter conditions optimized for other functions. In large-scale tests with challenging datasets like CIFAR-10, CIFAR-100, and TinyImageNet, encompassing 860 scenarios, TeLU consistently showcased its effectiveness, positioning itself as a potential new standard for neural network activation functions, boosting stability and performance in diverse deep learning applications.</li>
</ul>

<h3>Title: Rethinking Optimization and Architecture for Tiny Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yehui Tang, Fangcheng Liu, Yunsheng Ni, Yuchuan Tian, Zheyuan Bai, Yi-Qi Hu, Sichao Liu, Shangling Jui, Kai Han, Yunhe Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02791">https://arxiv.org/abs/2402.02791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02791">https://arxiv.org/pdf/2402.02791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02791]] Rethinking Optimization and Architecture for Tiny Language Models(https://arxiv.org/abs/2402.02791)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The power of large language models (LLMs) has been demonstrated through numerous data and computing resources. However, the application of language models on mobile devices is facing huge challenge on the computation and memory costs, that is, tiny language models with high performance are urgently required. Limited by the highly complex training process, there are many details for optimizing language models that are seldom studied carefully. In this study, based on a tiny language model with 1B parameters, we carefully design a series of empirical study to analyze the effect of each component. Three perspectives are mainly discussed, i.e., neural architecture, parameter initialization, and optimization strategy. Several design formulas are empirically proved especially effective for tiny language models, including tokenizer compression, architecture tweaking, parameter inheritance and multiple-round training. Then we train PanGu-$\pi$-1B Pro and PanGu-$\pi$-1.5B Pro on 1.6T multilingual corpora, following the established formulas. Experimental results demonstrate the improved optimization and architecture yield a notable average improvement of 8.87 on benchmark evaluation sets for PanGu-$\pi$-1B Pro. Besides, PanGu-$\pi$-1.5B Pro surpasses a range of SOTA models with larger model sizes, validating its superior performance. The code will be released soon (https://github.com/YuchuanTian/RethinkTinyLM).</li>
</ul>

<h3>Title: Extreme Two-View Geometry From Object Poses with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yujing Sun, Caiyi Sun, Yuan Liu, Yuexin Ma, Siu Ming Yiu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02800">https://arxiv.org/abs/2402.02800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02800">https://arxiv.org/pdf/2402.02800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02800]] Extreme Two-View Geometry From Object Poses with Diffusion Models(https://arxiv.org/abs/2402.02800)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Human has an incredible ability to effortlessly perceive the viewpoint difference between two images containing the same object, even when the viewpoint change is astonishingly vast with no co-visible regions in the images. This remarkable skill, however, has proven to be a challenge for existing camera pose estimation methods, which often fail when faced with large viewpoint differences due to the lack of overlapping local features for matching. In this paper, we aim to effectively harness the power of object priors to accurately determine two-view geometry in the face of extreme viewpoint changes. In our method, we first mathematically transform the relative camera pose estimation problem to an object pose estimation problem. Then, to estimate the object pose, we utilize the object priors learned from a diffusion model Zero123 to synthesize novel-view images of the object. The novel-view images are matched to determine the object pose and thus the two-view camera pose. In experiments, our method has demonstrated extraordinary robustness and resilience to large viewpoint changes, consistently estimating two-view poses with exceptional generalization ability across both synthetic and real-world datasets. Code will be available at https://github.com/scy639/Extreme-Two-View-Geometry-From-Object-Poses-with-Diffusion-Models.</li>
</ul>

<h3>Title: Evading Data Contamination Detection for Language Models is (too) Easy</h3>
<ul>
<li><strong>Authors: </strong>Jasper Dekoninck, Mark Niklas Mller, Maximilian Baader, Marc Fischer, Martin Vechev</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02823">https://arxiv.org/abs/2402.02823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02823">https://arxiv.org/pdf/2402.02823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02823]] Evading Data Contamination Detection for Language Models is (too) Easy(https://arxiv.org/abs/2402.02823)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are widespread, with their performance on benchmarks frequently guiding user preferences for one model over another. However, the vast amount of data these models are trained on can inadvertently lead to contamination with public benchmarks, thus compromising performance measurements. While recently developed contamination detection methods try to address this issue, they overlook the possibility of deliberate contamination by malicious model providers aiming to evade detection. We argue that this setting is of crucial importance as it casts doubt on the reliability of public benchmarks. To more rigorously study this issue, we propose a categorization of both model providers and contamination detection methods. This reveals vulnerabilities in existing methods that we exploit with EAL, a simple yet effective contamination technique that significantly inflates benchmark performance while completely evading current detection methods.</li>
</ul>

<h3>Title: SynthVision - Harnessing Minimal Input for Maximal Output in Computer  Vision Models using Synthetic Image data</h3>
<ul>
<li><strong>Authors: </strong>Yudara Kularathne, Prathapa Janitha, Sithira Ambepitiya, Thanveer Ahamed, Dinuka Wijesundara, Prarththanan Sothyrajah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02826">https://arxiv.org/abs/2402.02826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02826">https://arxiv.org/pdf/2402.02826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02826]] SynthVision - Harnessing Minimal Input for Maximal Output in Computer  Vision Models using Synthetic Image data(https://arxiv.org/abs/2402.02826)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Rapid development of disease detection computer vision models is vital in response to urgent medical crises like epidemics or events of bioterrorism. However, traditional data gathering methods are too slow for these scenarios necessitating innovative approaches to generate reliable models quickly from minimal data. We demonstrate our new approach by building a comprehensive computer vision model for detecting Human Papilloma Virus Genital warts using only synthetic data. In our study, we employed a two phase experimental design using diffusion models. In the first phase diffusion models were utilized to generate a large number of diverse synthetic images from 10 HPV guide images explicitly focusing on accurately depicting genital warts. The second phase involved the training and testing vision model using this synthetic dataset. This method aimed to assess the effectiveness of diffusion models in rapidly generating high quality training data and the subsequent impact on the vision model performance in medical image recognition. The study findings revealed significant insights into the performance of the vision model trained on synthetic images generated through diffusion models. The vision model showed exceptional performance in accurately identifying cases of genital warts. It achieved an accuracy rate of 96% underscoring its effectiveness in medical image classification. For HPV cases the model demonstrated a high precision of 99% and a recall of 94%. In normal cases the precision was 95% with an impressive recall of 99%. These metrics indicate the model capability to correctly identify true positive cases and minimize false positives. The model achieved an F1 Score of 96% for HPV cases and 97% for normal cases. The high F1 Score across both categories highlights the balanced nature of the model precision and recall ensuring reliability and robustness in its predictions.</li>
</ul>

<h3>Title: PowerGraph: A power grid benchmark dataset for graph neural networks</h3>
<ul>
<li><strong>Authors: </strong>Anna Varbella, Kenza Amara, Blazhe Gjorgiev, Giovanni Sansavini</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02827">https://arxiv.org/abs/2402.02827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02827">https://arxiv.org/pdf/2402.02827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02827]] PowerGraph: A power grid benchmark dataset for graph neural networks(https://arxiv.org/abs/2402.02827)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Public Graph Neural Networks (GNN) benchmark datasets facilitate the use of GNN and enhance GNN applicability to diverse disciplines. The community currently lacks public datasets of electrical power grids for GNN applications. Indeed, GNNs can potentially capture complex power grid phenomena over alternative machine learning techniques. Power grids are complex engineered networks that are naturally amenable to graph representations. Therefore, GNN have the potential for capturing the behavior of power grids over alternative machine learning techniques. To this aim, we develop a graph dataset for cascading failure events, which are the major cause of blackouts in electric power grids. Historical blackout datasets are scarce and incomplete. The assessment of vulnerability and the identification of critical components are usually conducted via computationally expensive offline simulations of cascading failures. Instead, we propose using machine learning models for the online detection of cascading failures leveraging the knowledge of the system state at the onset of the cascade. We develop PowerGraph, a graph dataset modeling cascading failures in power grids, designed for two purposes, namely, i) training GNN models for different graph-level tasks including multi-class classification, binary classification, and regression, and ii) explaining GNN models. The dataset generated via a physics-based cascading failure model ensures the generality of the operating and environmental conditions by spanning diverse failure scenarios. In addition, we foster the use of the dataset to benchmark GNN explainability methods by assigning ground-truth edge-level explanations. PowerGraph helps the development of better GNN models for graph-level tasks and explainability, critical in many domains ranging from chemistry to biology, where the systems and processes can be described as graphs.</li>
</ul>

<h3>Title: Shortened LLaMA: A Simple Depth Pruning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Bo-Kyeong Kim, Geonmin Kim, Tae-Ho Kim, Thibault Castells, Shinkook Choi, Junho Shin, Hyoung-Kyu Song</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02834">https://arxiv.org/abs/2402.02834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02834">https://arxiv.org/pdf/2402.02834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02834]] Shortened LLaMA: A Simple Depth Pruning for Large Language Models(https://arxiv.org/abs/2402.02834)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Structured pruning of modern large language models (LLMs) has emerged as a way of decreasing their high computational needs. Width pruning reduces the size of projection weight matrices (e.g., by removing attention heads) while maintaining the number of layers. Depth pruning, in contrast, removes entire layers or blocks, while keeping the size of the remaining weights unchanged. Most current research focuses on either width-only or a blend of width and depth pruning, with little comparative analysis between the two units (width vs. depth) concerning their impact on LLM inference efficiency. In this work, we show that a simple depth pruning approach can compete with recent width pruning methods in terms of zero-shot task performance. Our pruning method boosts inference speeds, especially under memory-constrained conditions that require limited batch sizes for running LLMs, where width pruning is ineffective. We hope this work can help deploy LLMs on local and edge devices.</li>
</ul>

<h3>Title: With a Little Help from my (Linguistic) Friends: Topic Segmentation of  Multi-party Casual Conversations</h3>
<ul>
<li><strong>Authors: </strong>Amandine Decker (LORIA, UL, CNRS, SEMAGRAMME, GU), Maxime Amblard (SEMAGRAMME, LORIA)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02837">https://arxiv.org/abs/2402.02837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02837">https://arxiv.org/pdf/2402.02837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02837]] With a Little Help from my (Linguistic) Friends: Topic Segmentation of  Multi-party Casual Conversations(https://arxiv.org/abs/2402.02837)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Topics play an important role in the global organisation of a conversation as what is currently discussed constrains the possible contributions of the participant. Understanding the way topics are organised in interaction would provide insight on the structure of dialogue beyond the sequence of utterances. However, studying this high-level structure is a complex task that we try to approach by first segmenting dialogues into smaller topically coherent sets of utterances. Understanding the interactions between these segments would then enable us to propose a model of topic organisation at a dialogue level. In this paper we work with open-domain conversations and try to reach a comparable level of accuracy as recent machine learning based topic segmentation models but with a formal approach. The features we identify as meaningful for this task help us understand better the topical structure of a conversation.</li>
</ul>

<h3>Title: How do Large Language Models Learn In-Context? Query and Key Matrices of  In-Context Heads are Two Towers for Metric Learning</h3>
<ul>
<li><strong>Authors: </strong>Zeping Yu, Sophia Ananiadou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02872">https://arxiv.org/abs/2402.02872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02872">https://arxiv.org/pdf/2402.02872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02872]] How do Large Language Models Learn In-Context? Query and Key Matrices of  In-Context Heads are Two Towers for Metric Learning(https://arxiv.org/abs/2402.02872)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We explore the mechanism of in-context learning and propose a hypothesis using locate-and-project method. In shallow layers, the features of demonstrations are merged into their corresponding labels, and the features of the input text are aggregated into the last token. In deep layers, in-context heads make great contributions. In each in-context head, the value-output matrix extracts the labels' features. Query and key matrices compute the attention weights between the input text and each demonstration. The larger the attention weight is, the more label information is transferred into the last token for predicting the next word. Query and key matrices can be regarded as two towers for learning the similarity metric between the input text and each demonstration. Based on this hypothesis, we explain why imbalanced labels and demonstration order affect predictions. We conduct experiments on GPT2 large, Llama 7B, 13B and 30B. The results can support our analysis. Overall, our study provides a new method and a reasonable hypothesis for understanding the mechanism of in-context learning. Our code will be released on github.</li>
</ul>

<h3>Title: Feedback to the European Data Protection Board's Guidelines 2/2023 on  Technical Scope of Art. 5(3) of ePrivacy Directive</h3>
<ul>
<li><strong>Authors: </strong>Cristiana Santos, Nataliia Bielova (PRIVATICS), Vincent Roca (PRIVATICS), Mathieu Cunche (PRIVATICS), Gilles Mertens (PRIVATICS), Karel Kubicek (ETHZ), Hamed Haddadi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02877">https://arxiv.org/abs/2402.02877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02877">https://arxiv.org/pdf/2402.02877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02877]] Feedback to the European Data Protection Board's Guidelines 2/2023 on  Technical Scope of Art. 5(3) of ePrivacy Directive(https://arxiv.org/abs/2402.02877)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>We very much welcome the EDPB's Guidelines. Please find hereunder our feedback to the Guidelines 2/2023 on Technical Scope of Art. 5(3) of ePrivacy Directive. Our comments are presented after a quotation from the proposed text by the EDPB in a box.</li>
</ul>

<h3>Title: Approximate Attributions for Off-the-Shelf Siamese Transformers</h3>
<ul>
<li><strong>Authors: </strong>Lucas Mller, Dmitry Nikolaev, Sebastian Pad</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02883">https://arxiv.org/abs/2402.02883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02883">https://arxiv.org/pdf/2402.02883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02883]] Approximate Attributions for Off-the-Shelf Siamese Transformers(https://arxiv.org/abs/2402.02883)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Siamese encoders such as sentence transformers are among the least understood deep models. Established attribution methods cannot tackle this model class since it compares two inputs rather than processing a single one. To address this gap, we have recently proposed an attribution method specifically for Siamese encoders (M\"oller et al., 2023). However, it requires models to be adjusted and fine-tuned and therefore cannot be directly applied to off-the-shelf models. In this work, we reassess these restrictions and propose (i) a model with exact attribution ability that retains the original model's predictive performance and (ii) a way to compute approximate attributions for off-the-shelf models. We extensively compare approximate and exact attributions and use them to analyze the models' attendance to different linguistic aspects. We gain insights into which syntactic roles Siamese transformers attend to, confirm that they mostly ignore negation, explore how they judge semantically opposite adjectives, and find that they exhibit lexical bias.</li>
</ul>

<h3>Title: Time-Distributed Backdoor Attacks on Federated Spiking Learning</h3>
<ul>
<li><strong>Authors: </strong>Gorka Abad, Stjepan Picek, Aitor Urbieta</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02886">https://arxiv.org/abs/2402.02886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02886">https://arxiv.org/pdf/2402.02886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02886]] Time-Distributed Backdoor Attacks on Federated Spiking Learning(https://arxiv.org/abs/2402.02886)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, defense, attack, robust, steal, federate</a></li>
<li><strong>Abstract: </strong>This paper investigates the vulnerability of spiking neural networks (SNNs) and federated learning (FL) to backdoor attacks using neuromorphic data. Despite the efficiency of SNNs and the privacy advantages of FL, particularly in low-powered devices, we demonstrate that these systems are susceptible to such attacks. We first assess the viability of using FL with SNNs using neuromorphic data, showing its potential usage. Then, we evaluate the transferability of known FL attack methods to SNNs, finding that these lead to suboptimal attack performance. Therefore, we explore backdoor attacks involving single and multiple attackers to improve the attack performance. Our primary contribution is developing a novel attack strategy tailored to SNNs and FL, which distributes the backdoor trigger temporally and across malicious devices, enhancing the attack's effectiveness and stealthiness. In the best case, we achieve a 100 attack success rate, 0.13 MSE, and 98.9 SSIM. Moreover, we adapt and evaluate an existing defense against backdoor attacks, revealing its inadequacy in protecting SNNs. This study underscores the need for robust security measures in deploying SNNs and FL, particularly in the context of backdoor attacks.</li>
</ul>

<h3>Title: Time-, Memory- and Parameter-Efficient Visual Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Otniel-Bogdan Mercea, Alexey Gritsenko, Cordelia Schmid, Anurag Arnab</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02887">https://arxiv.org/abs/2402.02887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02887">https://arxiv.org/pdf/2402.02887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02887]] Time-, Memory- and Parameter-Efficient Visual Adaptation(https://arxiv.org/abs/2402.02887)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>As foundation models become more popular, there is a growing need to efficiently finetune them for downstream tasks. Although numerous adaptation methods have been proposed, they are designed to be efficient only in terms of how many parameters are trained. They, however, typically still require backpropagating gradients throughout the model, meaning that their training-time and -memory cost does not reduce as significantly. We propose an adaptation method which does not backpropagate gradients through the backbone. We achieve this by designing a lightweight network in parallel that operates on features from the frozen, pretrained backbone. As a result, our method is efficient not only in terms of parameters, but also in training-time and memory usage. Our approach achieves state-of-the-art accuracy-parameter trade-offs on the popular VTAB benchmark, and we further show how we outperform prior works with respect to training-time and -memory usage too. We further demonstrate the training efficiency and scalability of our method by adapting a vision transformer backbone of 4 billion parameters for the computationally demanding task of video classification, without any intricate model parallelism. Here, we outperform a prior adaptor-based method which could only scale to a 1 billion parameter backbone, or fully-finetuning a smaller backbone, with the same GPU and less training time.</li>
</ul>

<h3>Title: Black-Box Approximation and Optimization with Hierarchical Tucker  Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Gleb Ryzhakov, Andrei Chertkov, Artem Basharin, Ivan Oseledets</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02890">https://arxiv.org/abs/2402.02890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02890">https://arxiv.org/pdf/2402.02890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02890]] Black-Box Approximation and Optimization with Hierarchical Tucker  Decomposition(https://arxiv.org/abs/2402.02890)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We develop a new method HTBB for the multidimensional black-box approximation and gradient-free optimization, which is based on the low-rank hierarchical Tucker decomposition with the use of the MaxVol indices selection procedure. Numerical experiments for 14 complex model problems demonstrate the robustness of the proposed method for dimensions up to 1000, while it shows significantly more accurate results than classical gradient-free optimization methods, as well as approximation and optimization methods based on the popular tensor train decomposition, which represents a simpler case of a tensor network.</li>
</ul>

<h3>Title: LLM Agents in Interaction: Measuring Personality Consistency and  Linguistic Alignment in Interacting Populations of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ivar Frisch, Mario Giulianelli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02896">https://arxiv.org/abs/2402.02896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02896">https://arxiv.org/pdf/2402.02896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02896]] LLM Agents in Interaction: Measuring Personality Consistency and  Linguistic Alignment in Interacting Populations of Large Language Models(https://arxiv.org/abs/2402.02896)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>While both agent interaction and personalisation are vibrant topics in research on large language models (LLMs), there has been limited focus on the effect of language interaction on the behaviour of persona-conditioned LLM agents. Such an endeavour is important to ensure that agents remain consistent to their assigned traits yet are able to engage in open, naturalistic dialogues. In our experiments, we condition GPT-3.5 on personality profiles through prompting and create a two-group population of LLM agents using a simple variability-inducing sampling algorithm. We then administer personality tests and submit the agents to a collaborative writing task, finding that different profiles exhibit different degrees of personality consistency and linguistic alignment to their conversational partners. Our study seeks to lay the groundwork for better understanding of dialogue-based interaction between LLMs and highlights the need for new approaches to crafting robust, more human-like LLM personas for interactive environments.</li>
</ul>

<h3>Title: ViewFusion: Learning Composable Diffusion Models for Novel View  Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Bernard Spiegl, Andrea Perin, Stphane Deny, Alexander Ilin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02906">https://arxiv.org/abs/2402.02906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02906">https://arxiv.org/pdf/2402.02906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02906]] ViewFusion: Learning Composable Diffusion Models for Novel View  Synthesis(https://arxiv.org/abs/2402.02906)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Deep learning is providing a wealth of new approaches to the old problem of novel view synthesis, from Neural Radiance Field (NeRF) based approaches to end-to-end style architectures. Each approach offers specific strengths but also comes with specific limitations in their applicability. This work introduces ViewFusion, a state-of-the-art end-to-end generative approach to novel view synthesis with unparalleled flexibility. ViewFusion consists in simultaneously applying a diffusion denoising step to any number of input views of a scene, then combining the noise gradients obtained for each view with an (inferred) pixel-weighting mask, ensuring that for each region of the target scene only the most informative input views are taken into account. Our approach resolves several limitations of previous approaches by (1) being trainable and generalizing across multiple scenes and object classes, (2) adaptively taking in a variable number of pose-free views at both train and test time, (3) generating plausible views even in severely undetermined conditions (thanks to its generative nature) -- all while generating views of quality on par or even better than state-of-the-art methods. Limitations include not generating a 3D embedding of the scene, resulting in a relatively slow inference speed, and our method only being tested on the relatively small dataset NMR. Code is available.</li>
</ul>

<h3>Title: DS-MS-TCN: Otago Exercises Recognition with a Dual-Scale Multi-Stage  Temporal Convolutional Network</h3>
<ul>
<li><strong>Authors: </strong>Meng Shang, Lenore Dedeyne, Jolan Dupont, Laura Vercauteren, Nadjia Amini, Laurence Lapauw, Evelien Gielen, Sabine Verschueren, Carolina Varon, Walter De Raedt, Bart Vanrumste</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02910">https://arxiv.org/abs/2402.02910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02910">https://arxiv.org/pdf/2402.02910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02910]] DS-MS-TCN: Otago Exercises Recognition with a Dual-Scale Multi-Stage  Temporal Convolutional Network(https://arxiv.org/abs/2402.02910)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The Otago Exercise Program (OEP) represents a crucial rehabilitation initiative tailored for older adults, aimed at enhancing balance and strength. Despite previous efforts utilizing wearable sensors for OEP recognition, existing studies have exhibited limitations in terms of accuracy and robustness. This study addresses these limitations by employing a single waist-mounted Inertial Measurement Unit (IMU) to recognize OEP exercises among community-dwelling older adults in their daily lives. A cohort of 36 older adults participated in laboratory settings, supplemented by an additional 7 older adults recruited for at-home assessments. The study proposes a Dual-Scale Multi-Stage Temporal Convolutional Network (DS-MS-TCN) designed for two-level sequence-to-sequence classification, incorporating them in one loss function. In the first stage, the model focuses on recognizing each repetition of the exercises (micro labels). Subsequent stages extend the recognition to encompass the complete range of exercises (macro labels). The DS-MS-TCN model surpasses existing state-of-the-art deep learning models, achieving f1-scores exceeding 80% and Intersection over Union (IoU) f1-scores surpassing 60% for all four exercises evaluated. Notably, the model outperforms the prior study utilizing the sliding window technique, eliminating the need for post-processing stages and window size tuning. To our knowledge, we are the first to present a novel perspective on enhancing Human Activity Recognition (HAR) systems through the recognition of each repetition of activities.</li>
</ul>

<h3>Title: Automated Cognate Detection as a Supervised Link Prediction Task with  Cognate Transformer</h3>
<ul>
<li><strong>Authors: </strong>V.S.D.S.Mahesh Akavarapu, Arnab Bhattacharya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02926">https://arxiv.org/abs/2402.02926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02926">https://arxiv.org/pdf/2402.02926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02926]] Automated Cognate Detection as a Supervised Link Prediction Task with  Cognate Transformer(https://arxiv.org/abs/2402.02926)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Identification of cognates across related languages is one of the primary problems in historical linguistics. Automated cognate identification is helpful for several downstream tasks including identifying sound correspondences, proto-language reconstruction, phylogenetic classification, etc. Previous state-of-the-art methods for cognate identification are mostly based on distributions of phonemes computed across multilingual wordlists and make little use of the cognacy labels that define links among cognate clusters. In this paper, we present a transformer-based architecture inspired by computational biology for the task of automated cognate detection. Beyond a certain amount of supervision, this method performs better than the existing methods, and shows steady improvement with further increase in supervision, thereby proving the efficacy of utilizing the labeled information. We also demonstrate that accepting multiple sequence alignments as input and having an end-to-end architecture with link prediction head saves much computation time while simultaneously yielding superior performance.</li>
</ul>

<h3>Title: Instance Segmentation XXL-CT Challenge of a Historic Airplane</h3>
<ul>
<li><strong>Authors: </strong>Roland Gruber, Johann Christopher Engster, Markus Michen, Nele Blum, Maik Stille, Stefan Gerth, Thomas Wittenberg</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02928">https://arxiv.org/abs/2402.02928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02928">https://arxiv.org/pdf/2402.02928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02928]] Instance Segmentation XXL-CT Challenge of a Historic Airplane(https://arxiv.org/abs/2402.02928)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Instance segmentation of compound objects in XXL-CT imagery poses a unique challenge in non-destructive testing. This complexity arises from the lack of known reference segmentation labels, limited applicable segmentation tools, as well as partially degraded image quality. To asses recent advancements in the field of machine learning-based image segmentation, the "Instance Segmentation XXL-CT Challenge of a Historic Airplane" was conducted. The challenge aimed to explore automatic or interactive instance segmentation methods for an efficient delineation of the different aircraft components, such as screws, rivets, metal sheets or pressure tubes. We report the organization and outcome of this challenge and describe the capabilities and limitations of the submitted segmentation methods.</li>
</ul>

<h3>Title: InterpretCC: Conditional Computation for Inherently Interpretable Neural  Networks</h3>
<ul>
<li><strong>Authors: </strong>Vinitra Swamy, Julian Blackwell, Jibril Frej, Martin Jaggi, Tanja Kser</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02933">https://arxiv.org/abs/2402.02933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02933">https://arxiv.org/pdf/2402.02933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02933]] InterpretCC: Conditional Computation for Inherently Interpretable Neural  Networks(https://arxiv.org/abs/2402.02933)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Real-world interpretability for neural networks is a tradeoff between three concerns: 1) it requires humans to trust the explanation approximation (e.g. post-hoc approaches), 2) it compromises the understandability of the explanation (e.g. automatically identified feature masks), and 3) it compromises the model performance (e.g. decision trees). These shortcomings are unacceptable for human-facing domains, like education, healthcare, or natural language, which require trustworthy explanations, actionable interpretations, and accurate predictions. In this work, we present InterpretCC (interpretable conditional computation), a family of interpretable-by-design neural networks that guarantee human-centric interpretability while maintaining comparable performance to state-of-the-art models by adaptively and sparsely activating features before prediction. We extend this idea into an interpretable mixture-of-experts model, that allows humans to specify topics of interest, discretely separates the feature space for each data point into topical subnetworks, and adaptively and sparsely activates these topical subnetworks. We demonstrate variations of the InterpretCC architecture for text and tabular data across several real-world benchmarks: six online education courses, news classification, breast cancer diagnosis, and review sentiment.</li>
</ul>

<h3>Title: Exploring the Synergies of Hybrid CNNs and ViTs Architectures for  Computer Vision: A survey</h3>
<ul>
<li><strong>Authors: </strong>Haruna Yunusa, Shiyin Qin, Abdulrahman Hamman Adama Chukkol, Abdulganiyu Abdu Yusuf, Isah Bello, Adamu Lawan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02941">https://arxiv.org/abs/2402.02941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02941">https://arxiv.org/pdf/2402.02941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02941]] Exploring the Synergies of Hybrid CNNs and ViTs Architectures for  Computer Vision: A survey(https://arxiv.org/abs/2402.02941)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The hybrid of Convolutional Neural Network (CNN) and Vision Transformers (ViT) architectures has emerged as a groundbreaking approach, pushing the boundaries of computer vision (CV). This comprehensive review provides a thorough examination of the literature on state-of-the-art hybrid CNN-ViT architectures, exploring the synergies between these two approaches. The main content of this survey includes: (1) a background on the vanilla CNN and ViT, (2) systematic review of various taxonomic hybrid designs to explore the synergy achieved through merging CNNs and ViTs models, (3) comparative analysis and application task-specific synergy between different hybrid architectures, (4) challenges and future directions for hybrid models, (5) lastly, the survey concludes with a summary of key findings and recommendations. Through this exploration of hybrid CV architectures, the survey aims to serve as a guiding resource, fostering a deeper understanding of the intricate dynamics between CNNs and ViTs and their collective impact on shaping the future of CV architectures.</li>
</ul>

<h3>Title: HoughToRadon Transform: New Neural Network Layer for Features  Improvement in Projection Space</h3>
<ul>
<li><strong>Authors: </strong>Alexandra Zhabitskaya, Alexander Sheshkus, Vladimir L. Arlazarov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02946">https://arxiv.org/abs/2402.02946</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02946">https://arxiv.org/pdf/2402.02946</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02946]] HoughToRadon Transform: New Neural Network Layer for Features  Improvement in Projection Space(https://arxiv.org/abs/2402.02946)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce HoughToRadon Transform layer, a novel layer designed to improve the speed of neural networks incorporated with Hough Transform to solve semantic image segmentation problems. By placing it after a Hough Transform layer, "inner" convolutions receive modified feature maps with new beneficial properties, such as a smaller area of processed images and parameter space linearity by angle and shift. These properties were not presented in Hough Transform alone. Furthermore, HoughToRadon Transform layer allows us to adjust the size of intermediate feature maps using two new parameters, thus allowing us to balance the speed and quality of the resulting neural network. Our experiments on the open MIDV-500 dataset show that this new approach leads to time savings in document segmentation tasks and achieves state-of-the-art 97.7% accuracy, outperforming HoughEncoder with larger computational complexity.</li>
</ul>

<h3>Title: Semantic Entropy Can Simultaneously Benefit Transmission Efficiency and  Channel Security of Wireless Semantic Communications</h3>
<ul>
<li><strong>Authors: </strong>Yankai Rong, Guoshun Nan, Minwei Zhang, Sihan Chen, Songtao Wang, Xuefei Zhang, Nan Ma, Shixun Gong, Zhaohui Yang, Qimei Cui, Xiaofeng Tao, Tony Q.S. Quek</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02950">https://arxiv.org/abs/2402.02950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02950">https://arxiv.org/pdf/2402.02950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02950]] Semantic Entropy Can Simultaneously Benefit Transmission Efficiency and  Channel Security of Wireless Semantic Communications(https://arxiv.org/abs/2402.02950)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Recently proliferated deep learning-based semantic communications (DLSC) focus on how transmitted symbols efficiently convey a desired meaning to the destination. However, the sensitivity of neural models and the openness of wireless channels cause the DLSC system to be extremely fragile to various malicious attacks. This inspires us to ask a question: ``Can we further exploit the advantages of transmission efficiency in wireless semantic communications while also alleviating its security disadvantages?''. Keeping this in mind, we propose SemEntropy, a novel method that answers the above question by exploring the semantics of data for both adaptive transmission and physical layer encryption. Specifically, we first introduce semantic entropy, which indicates the expectation of various semantic scores regarding the transmission goal of the DLSC. Equipped with such semantic entropy, we can dynamically assign informative semantics to Orthogonal Frequency Division Multiplexing (OFDM) subcarriers with better channel conditions in a fine-grained manner. We also use the entropy to guide semantic key generation to safeguard communications over open wireless channels. By doing so, both transmission efficiency and channel security can be simultaneously improved. Extensive experiments over various benchmarks show the effectiveness of the proposed SemEntropy. We discuss the reason why our proposed method benefits secure transmission of DLSC, and also give some interesting findings, e.g., SemEntropy can keep the semantic accuracy remain 95\% with 60\% less transmission.</li>
</ul>

<h3>Title: Dynamic Byzantine-Robust Learning: Adapting to Switching Byzantine  Workers</h3>
<ul>
<li><strong>Authors: </strong>Ron Dorfman, Naseem Yehya, Kfir Y. Levy</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02951">https://arxiv.org/abs/2402.02951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02951">https://arxiv.org/pdf/2402.02951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02951]] Dynamic Byzantine-Robust Learning: Adapting to Switching Byzantine  Workers(https://arxiv.org/abs/2402.02951)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Byzantine-robust learning has emerged as a prominent fault-tolerant distributed machine learning framework. However, most techniques consider the static setting, wherein the identity of Byzantine machines remains fixed during the learning process. This assumption does not capture real-world dynamic Byzantine behaviors, which may include transient malfunctions or targeted temporal attacks. Addressing this limitation, we propose $\textsf{DynaBRO}$ -- a new method capable of withstanding $\mathcal{O}(\sqrt{T})$ rounds of Byzantine identity alterations (where $T$ is the total number of training rounds), while matching the asymptotic convergence rate of the static setting. Our method combines a multi-level Monte Carlo (MLMC) gradient estimation technique with robust aggregation of worker updates and incorporates a fail-safe filter to limit bias from dynamic Byzantine strategies. Additionally, by leveraging an adaptive learning rate, our approach eliminates the need for knowing the percentage of Byzantine workers.</li>
</ul>

<h3>Title: Unraveling the Key of Machine Learning Solutions for Android Malware  Detection</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Liu, Jun Zeng, Fabio Pierazzi, Lorenzo Cavallaro, Zhenkai Liang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02953">https://arxiv.org/abs/2402.02953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02953">https://arxiv.org/pdf/2402.02953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02953]] Unraveling the Key of Machine Learning Solutions for Android Malware  Detection(https://arxiv.org/abs/2402.02953)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Android malware detection serves as the front line against malicious apps. With the rapid advancement of machine learning (ML), ML-based Android malware detection has attracted increasing attention due to its capability of automatically capturing malicious patterns from Android APKs. These learning-driven methods have reported promising results in detecting malware. However, the absence of an in-depth analysis of current research progress makes it difficult to gain a holistic picture of the state of the art in this area. This paper presents a comprehensive investigation to date into ML-based Android malware detection with empirical and quantitative analysis. We first survey the literature, categorizing contributions into a taxonomy based on the Android feature engineering and ML modeling pipeline. Then, we design a general-propose framework for ML-based Android malware detection, re-implement 12 representative approaches from different research communities, and evaluate them from three primary dimensions, i.e., effectiveness, robustness, and efficiency. The evaluation reveals that ML-based approaches still face open challenges and provides insightful findings like more powerful ML models are not the silver bullet for designing better malware detectors. We further summarize our findings and put forth recommendations to guide future research.</li>
</ul>

<h3>Title: AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a  Single High-Resolution Image</h3>
<ul>
<li><strong>Authors: </strong>Hamed Amini Amirkolaee, Miaojing Shi, Lianghua He, Mark Mulligan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02956">https://arxiv.org/abs/2402.02956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02956">https://arxiv.org/pdf/2402.02956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02956]] AdaTreeFormer: Few Shot Domain Adaptation for Tree Counting from a  Single High-Resolution Image(https://arxiv.org/abs/2402.02956)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>The process of estimating and counting tree density using only a single aerial or satellite image is a difficult task in the fields of photogrammetry and remote sensing. However, it plays a crucial role in the management of forests. The huge variety of trees in varied topography severely hinders tree counting models to perform well. The purpose of this paper is to propose a framework that is learnt from the source domain with sufficient labeled trees and is adapted to the target domain with only a limited number of labeled trees. Our method, termed as AdaTreeFormer, contains one shared encoder with a hierarchical feature extraction scheme to extract robust features from the source and target domains. It also consists of three subnets: two for extracting self-domain attention maps from source and target domains respectively and one for extracting cross-domain attention maps. For the latter, an attention-to-adapt mechanism is introduced to distill relevant information from different domains while generating tree density maps; a hierarchical cross-domain feature alignment scheme is proposed that progressively aligns the features from the source and target domains. We also adopt adversarial learning into the framework to further reduce the gap between source and target domains. Our AdaTreeFormer is evaluated on six designed domain adaptation tasks using three tree counting datasets, ie Jiangsu, Yosemite, and London; and outperforms the state of the art methods significantly.</li>
</ul>

<h3>Title: Delving into Multi-modal Multi-task Foundation Models for Road Scene  Understanding: From Learning Paradigm Perspectives</h3>
<ul>
<li><strong>Authors: </strong>Sheng Luo, Wei Chen, Wanxin Tian, Rui Liu, Luanxuan Hou, Xiubao Zhang, Haifeng Shen, Ruiqi Wu, Shuyi Geng, Yi Zhou, Ling Shao, Yi Yang, Bojun Gao, Qun Li, Guobin Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02968">https://arxiv.org/abs/2402.02968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02968">https://arxiv.org/pdf/2402.02968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02968]] Delving into Multi-modal Multi-task Foundation Models for Road Scene  Understanding: From Learning Paradigm Perspectives(https://arxiv.org/abs/2402.02968)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Foundation models have indeed made a profound impact on various fields, emerging as pivotal components that significantly shape the capabilities of intelligent systems. In the context of intelligent vehicles, leveraging the power of foundation models has proven to be transformative, offering notable advancements in visual understanding. Equipped with multi-modal and multi-task learning capabilities, multi-modal multi-task visual understanding foundation models (MM-VUFMs) effectively process and fuse data from diverse modalities and simultaneously handle various driving-related tasks with powerful adaptability, contributing to a more holistic understanding of the surrounding scene. In this survey, we present a systematic analysis of MM-VUFMs specifically designed for road scenes. Our objective is not only to provide a comprehensive overview of common practices, referring to task-specific models, unified multi-modal models, unified multi-task models, and foundation model prompting techniques, but also to highlight their advanced capabilities in diverse learning paradigms. These paradigms include open-world understanding, efficient transfer for road scenes, continual learning, interactive and generative capability. Moreover, we provide insights into key challenges and future trends, such as closed-loop driving systems, interpretability, embodied driving agents, and world models. To facilitate researchers in staying abreast of the latest developments in MM-VUFMs for road scenes, we have established a continuously updated repository at https://github.com/rolsheng/MM-VUFM4DS</li>
</ul>

<h3>Title: Retrieval-Augmented Score Distillation for Text-to-3D Generation</h3>
<ul>
<li><strong>Authors: </strong>Junyoung Seo, Susung Hong, Wooseok Jang, Ins Hyeonsu Kim, Minseop Kwak, Doyup Lee, Seungryong Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02972">https://arxiv.org/abs/2402.02972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02972">https://arxiv.org/pdf/2402.02972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02972]] Retrieval-Augmented Score Distillation for Text-to-3D Generation(https://arxiv.org/abs/2402.02972)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-3D generation has achieved significant success by incorporating powerful 2D diffusion models, but insufficient 3D prior knowledge also leads to the inconsistency of 3D geometry. Recently, since large-scale multi-view datasets have been released, fine-tuning the diffusion model on the multi-view datasets becomes a mainstream to solve the 3D inconsistency problem. However, it has confronted with fundamental difficulties regarding the limited quality and diversity of 3D data, compared with 2D data. To sidestep these trade-offs, we explore a retrieval-augmented approach tailored for score distillation, dubbed RetDream. We postulate that both expressiveness of 2D diffusion models and geometric consistency of 3D assets can be fully leveraged by employing the semantically relevant assets directly within the optimization process. To this end, we introduce novel framework for retrieval-based quality enhancement in text-to-3D generation. We leverage the retrieved asset to incorporate its geometric prior in the variational objective and adapt the diffusion model's 2D prior toward view consistency, achieving drastic improvements in both geometry and fidelity of generated scenes. We conduct extensive experiments to demonstrate that RetDream exhibits superior quality with increased geometric consistency. Project page is available at https://ku-cvlab.github.io/RetDream/.</li>
</ul>

<h3>Title: Putting Context in Context: the Impact of Discussion Structure on Text  Classification</h3>
<ul>
<li><strong>Authors: </strong>Nicol Penzo, Antonio Longa, Bruno Lepri, Sara Tonelli, Marco Guerini</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02975">https://arxiv.org/abs/2402.02975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02975">https://arxiv.org/pdf/2402.02975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02975]] Putting Context in Context: the Impact of Discussion Structure on Text  Classification(https://arxiv.org/abs/2402.02975)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, transformer</a></li>
<li><strong>Abstract: </strong>Current text classification approaches usually focus on the content to be classified. Contextual aspects (both linguistic and extra-linguistic) are usually neglected, even in tasks based on online discussions. Still in many cases the multi-party and multi-turn nature of the context from which these elements are selected can be fruitfully exploited. In this work, we propose a series of experiments on a large dataset for stance detection in English, in which we evaluate the contribution of different types of contextual information, i.e. linguistic, structural and temporal, by feeding them as natural language input into a transformer-based model. We also experiment with different amounts of training data and analyse the topology of local discussion networks in a privacy-compliant way. Results show that structural information can be highly beneficial to text classification but only under certain circumstances (e.g. depending on the amount of training data and on discussion chain complexity). Indeed, we show that contextual information on smaller datasets from other classification tasks does not yield significant improvements. Our framework, based on local discussion networks, allows the integration of structural information, while minimising user profiling, thus preserving their privacy.</li>
</ul>

<h3>Title: Variational Flow Models: Flowing in Your Style</h3>
<ul>
<li><strong>Authors: </strong>Kien Do, Duc Kieu, Toan Nguyen, Dang Nguyen, Hung Le, Dung Nguyen, Thin Nguyen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02977">https://arxiv.org/abs/2402.02977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02977">https://arxiv.org/pdf/2402.02977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02977]] Variational Flow Models: Flowing in Your Style(https://arxiv.org/abs/2402.02977)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce a variational inference interpretation for models of "posterior flows" - generalizations of "probability flows" to a broader class of stochastic processes not necessarily diffusion processes. We coin the resulting models as "Variational Flow Models". Additionally, we propose a systematic training-free method to transform the posterior flow of a "linear" stochastic process characterized by the equation Xt = at * X0 + st * X1 into a straight constant-speed (SC) flow, reminiscent of Rectified Flow. This transformation facilitates fast sampling along the original posterior flow without training a new model of the SC flow. The flexibility of our approach allows us to extend our transformation to inter-convert two posterior flows from distinct "linear" stochastic processes. Moreover, we can easily integrate high-order numerical solvers into the transformed SC flow, further enhancing sampling accuracy and efficiency. Rigorous theoretical analysis and extensive experimental results substantiate the advantages of our framework.</li>
</ul>

<h3>Title: Unsupervised semantic segmentation of high-resolution UAV imagery for  road scene parsing</h3>
<ul>
<li><strong>Authors: </strong>Zihan Ma, Yongshang Li, Ronggui Ma, Chen Liang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02985">https://arxiv.org/abs/2402.02985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02985">https://arxiv.org/pdf/2402.02985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02985]] Unsupervised semantic segmentation of high-resolution UAV imagery for  road scene parsing(https://arxiv.org/abs/2402.02985)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Two challenges are presented when parsing road scenes in UAV images. First, the high resolution of UAV images makes processing difficult. Second, supervised deep learning methods require a large amount of manual annotations to train robust and accurate models. In this paper, an unsupervised road parsing framework that leverages recent advances in vision language models and fundamental computer vision model is introduced.Initially, a vision language model is employed to efficiently process ultra-large resolution UAV images to quickly detect road regions of interest in the images. Subsequently, the vision foundation model SAM is utilized to generate masks for the road regions without category information. Following that, a self-supervised representation learning network extracts feature representations from all masked regions. Finally, an unsupervised clustering algorithm is applied to cluster these feature representations and assign IDs to each cluster. The masked regions are combined with the corresponding IDs to generate initial pseudo-labels, which initiate an iterative self-training process for regular semantic segmentation. The proposed method achieves an impressive 89.96% mIoU on the development dataset without relying on any manual annotation. Particularly noteworthy is the extraordinary flexibility of the proposed method, which even goes beyond the limitations of human-defined categories and is able to acquire knowledge of new categories from the dataset itself.</li>
</ul>

<h3>Title: Conversation Reconstruction Attack Against GPT Models</h3>
<ul>
<li><strong>Authors: </strong>Junjie Chu, Zeyang Sha, Michael Backes, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02987">https://arxiv.org/abs/2402.02987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02987">https://arxiv.org/pdf/2402.02987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02987]] Conversation Reconstruction Attack Against GPT Models(https://arxiv.org/abs/2402.02987)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>In recent times, significant advancements have been made in the field of large language models (LLMs), represented by GPT series models. To optimize task execution, users often engage in multi-round conversations with GPT models hosted in cloud environments. These multi-round conversations, potentially replete with private information, require transmission and storage within the cloud. However, this operational paradigm introduces additional attack surfaces. In this paper, we first introduce a specific Conversation Reconstruction Attack targeting GPT models. Our introduced Conversation Reconstruction Attack is composed of two steps: hijacking a session and reconstructing the conversations. Subsequently, we offer an exhaustive evaluation of the privacy risks inherent in conversations when GPT models are subjected to the proposed attack. However, GPT-4 demonstrates certain robustness to the proposed attacks. We then introduce two advanced attacks aimed at better reconstructing previous conversations, specifically the UNR attack and the PBU attack. Our experimental findings indicate that the PBU attack yields substantial performance across all models, achieving semantic similarity scores exceeding 0.60, while the UNR attack is effective solely on GPT-3.5. Our results reveal the concern about privacy risks associated with conversations involving GPT models and aim to draw the community's attention to prevent the potential misuse of these models' remarkable capabilities. We will responsibly disclose our findings to the suppliers of related large language models.</li>
</ul>

<h3>Title: Text-Guided Image Clustering</h3>
<ul>
<li><strong>Authors: </strong>Andreas Stephan, Lukas Miklautz, Kevin Sidak, Jan Philip Wahle, Bela Gipp, Claudia Plant, Benjamin Roth</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02996">https://arxiv.org/abs/2402.02996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02996">https://arxiv.org/pdf/2402.02996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02996]] Text-Guided Image Clustering(https://arxiv.org/abs/2402.02996)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Image clustering divides a collection of images into meaningful groups, typically interpreted post-hoc via human-given annotations. Those are usually in the form of text, begging the question of using text as an abstraction for image clustering. Current image clustering methods, however, neglect the use of generated textual descriptions. We, therefore, propose Text-Guided Image Clustering, i.e., generating text using image captioning and visual question-answering (VQA) models and subsequently clustering the generated text. Further, we introduce a novel approach to inject task- or domain knowledge for clustering by prompting VQA models. Across eight diverse image clustering datasets, our results show that the obtained text representations often outperform image features. Additionally, we propose a counting-based cluster explainability method. Our evaluations show that the derived keyword-based explanations describe clusters better than the respective cluster accuracy suggests. Overall, this research challenges traditional approaches and paves the way for a paradigm shift in image clustering, using generated text.</li>
</ul>

<h3>Title: Careful with that Scalpel: Improving Gradient Surgery with an EMA</h3>
<ul>
<li><strong>Authors: </strong>Yu-Guan Hsieh, James Thornton, Eugene Ndiaye, Michal Klein, Marco Cuturi, Pierre Ablin</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.02998">https://arxiv.org/abs/2402.02998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.02998">https://arxiv.org/pdf/2402.02998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.02998]] Careful with that Scalpel: Improving Gradient Surgery with an EMA(https://arxiv.org/abs/2402.02998)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Beyond minimizing a single training loss, many deep learning estimation pipelines rely on an auxiliary objective to quantify and encourage desirable properties of the model (e.g. performance on another dataset, robustness, agreement with a prior). Although the simplest approach to incorporating an auxiliary loss is to sum it with the training loss as a regularizer, recent works have shown that one can improve performance by blending the gradients beyond a simple sum; this is known as gradient surgery. We cast the problem as a constrained minimization problem where the auxiliary objective is minimized among the set of minimizers of the training loss. To solve this bilevel problem, we follow a parameter update direction that combines the training loss gradient and the orthogonal projection of the auxiliary gradient to the training gradient. In a setting where gradients come from mini-batches, we explain how, using a moving average of the training loss gradients, we can carefully maintain this critical orthogonality property. We demonstrate that our method, Bloop, can lead to much better performances on NLP and vision experiments than other gradient surgery methods without EMA.</li>
</ul>

<h3>Title: UniMem: Towards a Unified View of Long-Context Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Junjie Fang, Likai Tang, Hongzhe Bi, Yujia Qin, Si Sun, Zhenyu Li, Haolun Li, Yongjian Li, Xin Cong, Yukun Yan, Xiaodong Shi, Sen Song, Yankai Lin, Zhiyuan Liu, Maosong Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03009">https://arxiv.org/abs/2402.03009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03009">https://arxiv.org/pdf/2402.03009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03009]] UniMem: Towards a Unified View of Long-Context Large Language Models(https://arxiv.org/abs/2402.03009)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Long-context processing is a critical ability that constrains the applicability of large language models. Although there exist various methods devoted to enhancing the long-context processing ability of large language models (LLMs), they are developed in an isolated manner and lack systematic analysis and integration of their strengths, hindering further developments. In this paper, we introduce UniMem, a unified framework that reformulates existing long-context methods from the view of memory augmentation of LLMs. UniMem is characterized by four key dimensions: Memory Management, Memory Writing, Memory Reading, and Memory Injection, providing a systematic theory for understanding various long-context methods. We reformulate 16 existing methods based on UniMem and analyze four representative methods: Transformer-XL, Memorizing Transformer, RMT, and Longformer into equivalent UniMem forms to reveal their design principles and strengths. Based on these analyses, we propose UniMix, an innovative approach that integrates the strengths of these algorithms. Experimental results show that UniMix achieves superior performance in handling long contexts with significantly lower perplexity than baselines.</li>
</ul>

<h3>Title: On the Impact of Output Perturbation on Fairness in Binary Linear  Classification</h3>
<ul>
<li><strong>Authors: </strong>Vitalii Emelianov, Michal Perrot</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03011">https://arxiv.org/abs/2402.03011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03011">https://arxiv.org/pdf/2402.03011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03011]] On the Impact of Output Perturbation on Fairness in Binary Linear  Classification(https://arxiv.org/abs/2402.03011)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>We theoretically study how differential privacy interacts with both individual and group fairness in binary linear classification. More precisely, we focus on the output perturbation mechanism, a classic approach in privacy-preserving machine learning. We derive high-probability bounds on the level of individual and group fairness that the perturbed models can achieve compared to the original model. Hence, for individual fairness, we prove that the impact of output perturbation on the level of fairness is bounded but grows with the dimension of the model. For group fairness, we show that this impact is determined by the distribution of so-called angular margins, that is signed margins of the non-private model re-scaled by the norm of each example.</li>
</ul>

<h3>Title: Taylor Videos for Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Lei Wang, Xiuyuan Yuan, Tom Gedeon, Liang Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03019">https://arxiv.org/abs/2402.03019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03019">https://arxiv.org/pdf/2402.03019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03019]] Taylor Videos for Action Recognition(https://arxiv.org/abs/2402.03019)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Effectively extracting motions from video is a critical and long-standing problem for action recognition. This problem is very challenging because motions (i) do not have an explicit form, (ii) have various concepts such as displacement, velocity, and acceleration, and (iii) often contain noise caused by unstable pixels. Addressing these challenges, we propose the Taylor video, a new video format that highlights the dominate motions (e.g., a waving hand) in each of its frames named the Taylor frame. Taylor video is named after Taylor series, which approximates a function at a given point using important terms. In the scenario of videos, we define an implicit motion-extraction function which aims to extract motions from video temporal block. In this block, using the frames, the difference frames, and higher-order difference frames, we perform Taylor expansion to approximate this function at the starting frame. We show the summation of the higher-order terms in the Taylor series gives us dominant motion patterns, where static objects, small and unstable motions are removed. Experimentally we show that Taylor videos are effective inputs to popular architectures including 2D CNNs, 3D CNNs, and transformers. When used individually, Taylor videos yield competitive action recognition accuracy compared to RGB videos and optical flow. When fused with RGB or optical flow videos, further accuracy improvement is achieved.</li>
</ul>

<h3>Title: InteractiveVideo: User-Centric Controllable Video Generation with  Synergistic Multimodal Instructions</h3>
<ul>
<li><strong>Authors: </strong>Yiyuan Zhang, Yuhao Kang, Zhixin Zhang, Xiaohan Ding, Sanyuan Zhao, Xiangyu Yue</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03040">https://arxiv.org/abs/2402.03040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03040">https://arxiv.org/pdf/2402.03040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03040]] InteractiveVideo: User-Centric Controllable Video Generation with  Synergistic Multimodal Instructions(https://arxiv.org/abs/2402.03040)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce $\textit{InteractiveVideo}$, a user-centric framework for video generation. Different from traditional generative approaches that operate based on user-provided images or text, our framework is designed for dynamic interaction, allowing users to instruct the generative model through various intuitive mechanisms during the whole generation process, e.g. text and image prompts, painting, drag-and-drop, etc. We propose a Synergistic Multimodal Instruction mechanism, designed to seamlessly integrate users' multimodal instructions into generative models, thus facilitating a cooperative and responsive interaction between user inputs and the generative process. This approach enables iterative and fine-grained refinement of the generation result through precise and effective user instructions. With $\textit{InteractiveVideo}$, users are given the flexibility to meticulously tailor key aspects of a video. They can paint the reference image, edit semantics, and adjust video motions until their requirements are fully met. Code, models, and demo are available at https://github.com/invictus717/InteractiveVideo</li>
</ul>

<h3>Title: SIDU-TXT: An XAI Algorithm for NLP with a Holistic Assessment Approach</h3>
<ul>
<li><strong>Authors: </strong>Mohammad N.S. Jahromi, Satya. M. Muddamsetty, Asta Sofie Stage Jarlner, Anna Murphy Hgenhaug, Thomas Gammeltoft-Hansen, Thomas B. Moeslund</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03043">https://arxiv.org/abs/2402.03043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03043">https://arxiv.org/pdf/2402.03043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03043]] SIDU-TXT: An XAI Algorithm for NLP with a Holistic Assessment Approach(https://arxiv.org/abs/2402.03043)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Explainable AI (XAI) aids in deciphering 'black-box' models. While several methods have been proposed and evaluated primarily in the image domain, the exploration of explainability in the text domain remains a growing research area. In this paper, we delve into the applicability of XAI methods for the text domain. In this context, the 'Similarity Difference and Uniqueness' (SIDU) XAI method, recognized for its superior capability in localizing entire salient regions in image-based classification is extended to textual data. The extended method, SIDU-TXT, utilizes feature activation maps from 'black-box' models to generate heatmaps at a granular, word-based level, thereby providing explanations that highlight contextually significant textual elements crucial for model predictions. Given the absence of a unified standard for assessing XAI methods, this study applies a holistic three-tiered comprehensive evaluation framework: Functionally-Grounded, Human-Grounded and Application-Grounded, to assess the effectiveness of the proposed SIDU-TXT across various experiments. We find that, in sentiment analysis task of a movie review dataset, SIDU-TXT excels in both functionally and human-grounded evaluations, demonstrating superior performance through quantitative and qualitative analyses compared to benchmarks like Grad-CAM and LIME. In the application-grounded evaluation within the sensitive and complex legal domain of asylum decision-making, SIDU-TXT and Grad-CAM demonstrate comparable performances, each with its own set of strengths and weaknesses. However, both methods fall short of entirely fulfilling the sophisticated criteria of expert expectations, highlighting the imperative need for additional research in XAI methods suitable for such domains.</li>
</ul>

<h3>Title: PFDM: Parser-Free Virtual Try-on via Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Yunfang Niu, Dong Yi, Lingxiang Wu, Zhiwei Liu, Pengxiang Cai, Jinqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03047">https://arxiv.org/abs/2402.03047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03047">https://arxiv.org/pdf/2402.03047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03047]] PFDM: Parser-Free Virtual Try-on via Diffusion Model(https://arxiv.org/abs/2402.03047)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Virtual try-on can significantly improve the garment shopping experiences in both online and in-store scenarios, attracting broad interest in computer vision. However, to achieve high-fidelity try-on performance, most state-of-the-art methods still rely on accurate segmentation masks, which are often produced by near-perfect parsers or manual labeling. To overcome the bottleneck, we propose a parser-free virtual try-on method based on the diffusion model (PFDM). Given two images, PFDM can "wear" garments on the target person seamlessly by implicitly warping without any other information. To learn the model effectively, we synthesize many pseudo-images and construct sample pairs by wearing various garments on persons. Supervised by the large-scale expanded dataset, we fuse the person and garment features using a proposed Garment Fusion Attention (GFA) mechanism. Experiments demonstrate that our proposed PFDM can successfully handle complex cases, synthesize high-fidelity images, and outperform both state-of-the-art parser-free and parser-based models.</li>
</ul>

<h3>Title: EasyInstruct: An Easy-to-use Instruction Processing Framework for Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yixin Ou, Ningyu Zhang, Honghao Gui, Ziwen Xu, Shuofei Qiao, Zhen Bi, Huajun Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03049">https://arxiv.org/abs/2402.03049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03049">https://arxiv.org/pdf/2402.03049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03049]] EasyInstruct: An Easy-to-use Instruction Processing Framework for Large  Language Models(https://arxiv.org/abs/2402.03049)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along with a running demo App at https://huggingface.co/spaces/zjunlp/EasyInstruct for quick-start, calling for broader research centered on instruction data.</li>
</ul>

<h3>Title: Multi-Lingual Malaysian Embedding: Leveraging Large Language Models for  Semantic Representations</h3>
<ul>
<li><strong>Authors: </strong>Husein Zolkepli, Aisyah Razak, Kamarul Adha, Ariff Nazhan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03053">https://arxiv.org/abs/2402.03053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03053">https://arxiv.org/pdf/2402.03053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03053]] Multi-Lingual Malaysian Embedding: Leveraging Large Language Models for  Semantic Representations(https://arxiv.org/abs/2402.03053)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we present a comprehensive exploration of finetuning Malaysian language models, specifically Llama2 and Mistral, on embedding tasks involving negative and positive pairs. We release two distinct models tailored for Semantic Similarity and Retrieval-Augmented Generation (RAG). For Semantic Similarity, our 600 million parameter Llama2 model outperforms OpenAI text-embedding-ada-002 across all recall@k metrics for b.cari.com.my, c.cari.com.my, Malay news, and Malaysian Twitter test sets. In the realm of RAG models, our approach proves competitive with OpenAI text-embedding-ada-002 in the Malaysian context. Notably, our 2 billion parameter Llama2 model achieves superior Recall@5, Recall@10 for the "Melayu" keyword research papers dataset and excels in Recall@3, Recall@5, and Recall@10 for the lom.agc.gov.my dataset. These findings underscore the effectiveness of our finetuning strategy and highlight the performance gains in both Semantic Similarity and RAG tasks. All models released at https://huggingface.co/collections/mesolitica/malaysian-embedding-6523612bfe5881ad35f81b99</li>
</ul>

<h3>Title: UniHENN: Designing More Versatile Homomorphic Encryption-based CNNs  without im2col</h3>
<ul>
<li><strong>Authors: </strong>Hyunmin Choi, Jihun Kim, Seungho Kim, Seonhye Park, Jeongyong Park, Wonbin Choi, Hyoungshick Kim</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03060">https://arxiv.org/abs/2402.03060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03060">https://arxiv.org/pdf/2402.03060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03060]] UniHENN: Designing More Versatile Homomorphic Encryption-based CNNs  without im2col(https://arxiv.org/abs/2402.03060)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Homomorphic encryption enables computations on encrypted data without decryption, which is crucial for privacy-preserving cloud services. However, deploying convolutional neural networks (CNNs) with homomorphic encryption encounters significant challenges, particularly in converting input data into a two-dimensional matrix for convolution, typically achieved using the im2col technique. While efficient, this method limits the variety of deployable CNN models due to compatibility constraints with the encrypted data structure. UniHENN, a homomorphic encryption-based CNN architecture, eliminates the need for im2col, ensuring compatibility with a diverse range of CNN models using homomorphic encryption. Our experiments demonstrate that UniHENN surpasses the leading 2D CNN inference architecture, PyCrCNN, in inference time, as evidenced by its performance on the LeNet-1 dataset, where it averages 30.090 seconds--significantly faster than PyCrCNN's 794.064 seconds. Furthermore, UniHENN outperforms TenSEAL, which employs im2col, in processing concurrent images, an essential feature for high-demand cloud applications. The versatility of UniHENN is proven across various CNN architectures, including 1D and six different 2D CNNs, highlighting its flexibility and efficiency. These qualities establish UniHENN as a promising solution for privacy-preserving, cloud-based CNN services, addressing the increasing demand for scalable, secure, and efficient deep learning in cloud computing environments.</li>
</ul>

<h3>Title: Multilingual transformer and BERTopic for short text topic modeling: The  case of Serbian</h3>
<ul>
<li><strong>Authors: </strong>Darija Medvecki, Bojana Baaragin, Adela Ljaji, Nikola Miloevi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03067">https://arxiv.org/abs/2402.03067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03067">https://arxiv.org/pdf/2402.03067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03067]] Multilingual transformer and BERTopic for short text topic modeling: The  case of Serbian(https://arxiv.org/abs/2402.03067)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents the results of the first application of BERTopic, a state-of-the-art topic modeling technique, to short text written in a morphologi-cally rich language. We applied BERTopic with three multilingual embed-ding models on two levels of text preprocessing (partial and full) to evalu-ate its performance on partially preprocessed short text in Serbian. We also compared it to LDA and NMF on fully preprocessed text. The experiments were conducted on a dataset of tweets expressing hesitancy toward COVID-19 vaccination. Our results show that with adequate parameter setting, BERTopic can yield informative topics even when applied to partially pre-processed short text. When the same parameters are applied in both prepro-cessing scenarios, the performance drop on partially preprocessed text is minimal. Compared to LDA and NMF, judging by the keywords, BERTopic offers more informative topics and gives novel insights when the number of topics is not limited. The findings of this paper can be significant for re-searchers working with other morphologically rich low-resource languages and short text.</li>
</ul>

<h3>Title: Visual Text Meets Low-level Vision: A Comprehensive Survey on Visual  Text Processing</h3>
<ul>
<li><strong>Authors: </strong>Yan Shu, Weichao Zeng, Zhenhang Li, Fangmin Zhao, Yu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03082">https://arxiv.org/abs/2402.03082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03082">https://arxiv.org/pdf/2402.03082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03082]] Visual Text Meets Low-level Vision: A Comprehensive Survey on Visual  Text Processing(https://arxiv.org/abs/2402.03082)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Visual text, a pivotal element in both document and scene images, speaks volumes and attracts significant attention in the computer vision domain. Beyond visual text detection and recognition, the field of visual text processing has experienced a surge in research, driven by the advent of fundamental generative models. However, challenges persist due to the unique properties and features that distinguish text from general objects. Effectively leveraging these unique textual characteristics is crucial in visual text processing, as observed in our study. In this survey, we present a comprehensive, multi-perspective analysis of recent advancements in this field. Initially, we introduce a hierarchical taxonomy encompassing areas ranging from text image enhancement and restoration to text image manipulation, followed by different learning paradigms. Subsequently, we conduct an in-depth discussion of how specific textual features such as structure, stroke, semantics, style, and spatial context are seamlessly integrated into various tasks. Furthermore, we explore available public datasets and benchmark the reviewed methods on several widely-used datasets. Finally, we identify principal challenges and potential avenues for future research. Our aim is to establish this survey as a fundamental resource, fostering continued exploration and innovation in the dynamic area of visual text processing.</li>
</ul>

<h3>Title: Cross-Domain Few-Shot Object Detection via Enhanced Open-Set Object  Detector</h3>
<ul>
<li><strong>Authors: </strong>Yuqian Fu, Yu Wang, Yixuan Pan, Lian Huai, Xingyu Qiu, Zeyu Shangguan, Tong Liu, Lingjie Kong, Yanwei Fu, Luc Van Gool, Xingqun Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03094">https://arxiv.org/abs/2402.03094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03094">https://arxiv.org/pdf/2402.03094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03094]] Cross-Domain Few-Shot Object Detection via Enhanced Open-Set Object  Detector(https://arxiv.org/abs/2402.03094)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper addresses the challenge of cross-domain few-shot object detection (CD-FSOD), aiming to develop an accurate object detector for novel domains with minimal labeled examples. While transformer-based open-set detectors e.g., DE-ViT~\cite{zhang2023detect} have excelled in both open-vocabulary object detection and traditional few-shot object detection, detecting categories beyond those seen during training, we thus naturally raise two key questions: 1) can such open-set detection methods easily generalize to CD-FSOD? 2) If no, how to enhance the results of open-set methods when faced with significant domain gaps? To address the first question, we introduce several metrics to quantify domain variances and establish a new CD-FSOD benchmark with diverse domain metric values. Some State-Of-The-Art (SOTA) open-set object detection methods are evaluated on this benchmark, with evident performance degradation observed across out-of-domain datasets. This indicates the failure of adopting open-set detectors directly for CD-FSOD. Sequentially, to overcome the performance degradation issue and also to answer the second proposed question, we endeavor to enhance the vanilla DE-ViT. With several novel components including finetuning, a learnable prototype module, and a lightweight attention module, we present an improved Cross-Domain Vision Transformer for CD-FSOD (CD-ViTO). Experiments show that our CD-ViTO achieves impressive results on both out-of-domain and in-domain target datasets, establishing new SOTAs for both CD-FSOD and FSOD. All the datasets, codes, and models will be released to the community.</li>
</ul>

<h3>Title: Transcending Adversarial Perturbations: Manifold-Aided Adversarial  Examples with Legitimate Semantics</h3>
<ul>
<li><strong>Authors: </strong>Shuai Li, Xiaoyu Jiang, Xiaoguang Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03095">https://arxiv.org/abs/2402.03095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03095">https://arxiv.org/pdf/2402.03095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03095]] Transcending Adversarial Perturbations: Manifold-Aided Adversarial  Examples with Legitimate Semantics(https://arxiv.org/abs/2402.03095)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, interpretability, generative</a></li>
<li><strong>Abstract: </strong>Deep neural networks were significantly vulnerable to adversarial examples manipulated by malicious tiny perturbations. Although most conventional adversarial attacks ensured the visual imperceptibility between adversarial examples and corresponding raw images by minimizing their geometric distance, these constraints on geometric distance led to limited attack transferability, inferior visual quality, and human-imperceptible interpretability. In this paper, we proposed a supervised semantic-transformation generative model to generate adversarial examples with real and legitimate semantics, wherein an unrestricted adversarial manifold containing continuous semantic variations was constructed for the first time to realize a legitimate transition from non-adversarial examples to adversarial ones. Comprehensive experiments on MNIST and industrial defect datasets showed that our adversarial examples not only exhibited better visual quality but also achieved superior attack transferability and more effective explanations for model vulnerabilities, indicating their great potential as generic adversarial examples. The code and pre-trained models were available at https://github.com/shuaili1027/MAELS.git.</li>
</ul>

<h3>Title: Intent-based Prompt Calibration: Enhancing prompt optimization with  synthetic boundary cases</h3>
<ul>
<li><strong>Authors: </strong>Elad Levi, Eli Brosh, Matan Friedmann</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03099">https://arxiv.org/abs/2402.03099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03099">https://arxiv.org/pdf/2402.03099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03099]] Intent-based Prompt Calibration: Enhancing prompt optimization with  synthetic boundary cases(https://arxiv.org/abs/2402.03099)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prompt engineering is a challenging and important task due to the high sensitivity of Large Language Models (LLMs) to the given prompt and the inherent ambiguity of a textual task instruction. Automatic prompt engineering is essential to achieve optimized performance from LLMs. Recent studies have demonstrated the capabilities of LLMs to automatically conduct prompt engineering by employing a meta-prompt that incorporates the outcomes of the last trials and proposes an improved prompt. However, this requires a high-quality benchmark to compare different prompts, which is difficult and expensive to acquire in many real-world use cases. In this work, we introduce a new method for automatic prompt engineering, using a calibration process that iteratively refines the prompt to the user intent. During the optimization process, the system jointly generates synthetic data of boundary use cases and optimizes the prompt according to the generated dataset. We demonstrate the effectiveness of our method with respect to strong proprietary models on real-world tasks such as moderation and generation. Our method outperforms state-of-the-art methods with a limited number of annotated samples. Furthermore, we validate the advantages of each one of the system's key components. Our system is built in a modular way, facilitating easy adaptation to other tasks. The code is available $\href{https://github.com/Eladlev/AutoPrompt}{here}$.</li>
</ul>

<h3>Title: Infrared Spectra Prediction for Diazo Groups Utilizing a Machine  Learning Approach with Structural Attention Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Chengchun Liu, Fanyang Mo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.chem-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03112">https://arxiv.org/abs/2402.03112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03112">https://arxiv.org/pdf/2402.03112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03112]] Infrared Spectra Prediction for Diazo Groups Utilizing a Machine  Learning Approach with Structural Attention Mechanism(https://arxiv.org/abs/2402.03112)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Infrared (IR) spectroscopy is a pivotal technique in chemical research for elucidating molecular structures and dynamics through vibrational and rotational transitions. However, the intricate molecular fingerprints characterized by unique vibrational and rotational patterns present substantial analytical challenges. Here, we present a machine learning approach employing a Structural Attention Mechanism tailored to enhance the prediction and interpretation of infrared spectra, particularly for diazo compounds. Our model distinguishes itself by honing in on chemical information proximal to functional groups, thereby significantly bolstering the accuracy, robustness, and interpretability of spectral predictions. This method not only demystifies the correlations between infrared spectral features and molecular structures but also offers a scalable and efficient paradigm for dissecting complex molecular interactions.</li>
</ul>

<h3>Title: Augmenting Security and Privacy in the Virtual Realm: An Analysis of  Extended Reality Devices</h3>
<ul>
<li><strong>Authors: </strong>Derin Cayir, Abbas Acar, Riccardo Lazzeretti, Marco Angelini, Mauro Conti, Selcuk Uluagac</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03114">https://arxiv.org/abs/2402.03114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03114">https://arxiv.org/pdf/2402.03114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03114]] Augmenting Security and Privacy in the Virtual Realm: An Analysis of  Extended Reality Devices(https://arxiv.org/abs/2402.03114)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>In this work, we present a device-centric analysis of security and privacy attacks and defenses on Extended Reality (XR) devices, highlighting the need for robust and privacy-aware security mechanisms. Based on our analysis, we present future research directions and propose design considerations to help ensure the security and privacy of XR devices.</li>
</ul>

<h3>Title: Good Teachers Explain: Explanation-Enhanced Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Amin Parchami-Araghi, Moritz Bhle, Sukrut Rao, Bernt Schiele</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03119">https://arxiv.org/abs/2402.03119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03119">https://arxiv.org/pdf/2402.03119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03119]] Good Teachers Explain: Explanation-Enhanced Knowledge Distillation(https://arxiv.org/abs/2402.03119)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Knowledge Distillation (KD) has proven effective for compressing large teacher models into smaller student models. While it is well known that student models can achieve similar accuracies as the teachers, it has also been shown that they nonetheless often do not learn the same function. It is, however, often highly desirable that the student's and teacher's functions share similar properties such as basing the prediction on the same input features, as this ensures that students learn the 'right features' from the teachers. In this work, we explore whether this can be achieved by not only optimizing the classic KD loss but also the similarity of the explanations generated by the teacher and the student. Despite the idea being simple and intuitive, we find that our proposed 'explanation-enhanced' KD (e$^2$KD) (1) consistently provides large gains in terms of accuracy and student-teacher agreement, (2) ensures that the student learns from the teacher to be right for the right reasons and to give similar explanations, and (3) is robust with respect to the model architectures, the amount of training data, and even works with 'approximate', pre-computed explanations.</li>
</ul>

<h3>Title: Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yanbo Wang, Jian Liang, Ran He</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03124">https://arxiv.org/abs/2402.03124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03124">https://arxiv.org/pdf/2402.03124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03124]] Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks(https://arxiv.org/abs/2402.03124)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, federate</a></li>
<li><strong>Abstract: </strong>Gradient inversion attacks aim to reconstruct local training data from intermediate gradients exposed in the federated learning framework. Despite successful attacks, all previous methods, starting from reconstructing a single data point and then relaxing the single-image limit to batch level, are only tested under hard label constraints. Even for single-image reconstruction, we still lack an analysis-based algorithm to recover augmented soft labels. In this work, we change the focus from enlarging batchsize to investigating the hard label constraints, considering a more realistic circumstance where label smoothing and mixup techniques are used in the training process. In particular, we are the first to initiate a novel algorithm to simultaneously recover the ground-truth augmented label and the input feature of the last fully-connected layer from single-input gradients, and provide a necessary condition for any analytical-based label recovery methods. Extensive experiments testify to the label recovery accuracy, as well as the benefits to the following image reconstruction. We believe soft labels in classification tasks are worth further attention in gradient inversion attacks.</li>
</ul>

<h3>Title: Constrained Decoding for Cross-lingual Label Projection</h3>
<ul>
<li><strong>Authors: </strong>Duong Minh Le, Yang Chen, Alan Ritter, Wei Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03131">https://arxiv.org/abs/2402.03131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03131">https://arxiv.org/pdf/2402.03131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03131]] Constrained Decoding for Cross-lingual Label Projection(https://arxiv.org/abs/2402.03131)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Zero-shot cross-lingual transfer utilizing multilingual LLMs has become a popular learning paradigm for low-resource languages with no labeled training data. However, for NLP tasks that involve fine-grained predictions on words and phrases, the performance of zero-shot cross-lingual transfer learning lags far behind supervised fine-tuning methods. Therefore, it is common to exploit translation and label projection to further improve the performance by (1) translating training data that is available in a high-resource language (e.g., English) together with the gold labels into low-resource languages, and/or (2) translating test data in low-resource languages to a high-source language to run inference on, then projecting the predicted span-level labels back onto the original test data. However, state-of-the-art marker-based label projection methods suffer from translation quality degradation due to the extra label markers injected in the input to the translation model. In this work, we explore a new direction that leverages constrained decoding for label projection to overcome the aforementioned issues. Our new method not only can preserve the quality of translated texts but also has the versatility of being applicable to both translating training and translating test data strategies. This versatility is crucial as our experiments reveal that translating test data can lead to a considerable boost in performance compared to translating only training data. We evaluate on two cross-lingual transfer tasks, namely Named Entity Recognition and Event Argument Extraction, spanning 20 languages. The results demonstrate that our approach outperforms the state-of-the-art marker-based method by a large margin and also shows better performance than other label projection methods that rely on external word alignment.</li>
</ul>

<h3>Title: Sociolinguistically Informed Interpretability: A Case Study on Hinglish  Emotion Classification</h3>
<ul>
<li><strong>Authors: </strong>Kushal Tatariya, Heather Lent, Johannes Bjerva, Miryam de Lhoneux</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03137">https://arxiv.org/abs/2402.03137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03137">https://arxiv.org/pdf/2402.03137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03137]] Sociolinguistically Informed Interpretability: A Case Study on Hinglish  Emotion Classification(https://arxiv.org/abs/2402.03137)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression, especially with code-mixed data. Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages. Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions. To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset. Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression. Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce. We also conclude from the misclassifications that the models may overgeneralise this heuristic to other infrequent examples where this sociolinguistic phenomenon does not apply.</li>
</ul>

<h3>Title: Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Michele Mastromattei, Fabio Massimo Zanzotto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03142">https://arxiv.org/abs/2402.03142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03142">https://arxiv.org/pdf/2402.03142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03142]] Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for  Large Language Models(https://arxiv.org/abs/2402.03142)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Neural network pruning has become increasingly crucial due to the complexity of neural network models and their widespread use in various fields. Existing pruning algorithms often suffer from limitations such as architecture specificity, excessive complexity and reliance on complex calculations, rendering them impractical for real-world applications. In this paper, we propose KEN: a straightforward, universal and unstructured pruning algorithm based on Kernel Density Estimation (KDE). KEN aims to construct optimized transformer models by selectively preserving the most significant parameters while restoring others to their pre-training state. This approach maintains model performance while allowing storage of only the optimized subnetwork, leading to significant memory savings. Extensive evaluations on seven transformer models demonstrate that KEN achieves equal or better performance than the original models with a minimum parameter reduction of 25%. In-depth comparisons against other pruning and PEFT algorithms confirm KEN effectiveness. Furthermore, we introduce KEN_viz, an explainable tool that visualizes the optimized model composition and the subnetwork selected by KEN.</li>
</ul>

<h3>Title: A Multi-step Loss Function for Robust Learning of the Dynamics in  Model-based Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Abdelhakim Benechehab, Albert Thomas, Giuseppe Paolo, Maurizio Filippone, Balzs Kgl</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03146">https://arxiv.org/abs/2402.03146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03146">https://arxiv.org/pdf/2402.03146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03146]] A Multi-step Loss Function for Robust Learning of the Dynamics in  Model-based Reinforcement Learning(https://arxiv.org/abs/2402.03146)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In model-based reinforcement learning, most algorithms rely on simulating trajectories from one-step models of the dynamics learned on data. A critical challenge of this approach is the compounding of one-step prediction errors as the length of the trajectory grows. In this paper we tackle this issue by using a multi-step objective to train one-step models. Our objective is a weighted sum of the mean squared error (MSE) loss at various future horizons. We find that this new loss is particularly useful when the data is noisy (additive Gaussian noise in the observations), which is often the case in real-life environments. To support the multi-step loss, first we study its properties in two tractable cases: i) uni-dimensional linear system, and ii) two-parameter non-linear system. Second, we show in a variety of tasks (environments or datasets) that the models learned with this loss achieve a significant improvement in terms of the averaged R2-score on future prediction horizons. Finally, in the pure batch reinforcement learning setting, we demonstrate that one-step models serve as strong baselines when dynamics are deterministic, while multi-step models would be more advantageous in the presence of noise, highlighting the potential of our approach in real-world applications.</li>
</ul>

<h3>Title: Detecting Scams Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Liming Jiang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03147">https://arxiv.org/abs/2402.03147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03147">https://arxiv.org/pdf/2402.03147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03147]] Detecting Scams Using Large Language Models(https://arxiv.org/abs/2402.03147)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have gained prominence in various applications, including security. This paper explores the utility of LLMs in scam detection, a critical aspect of cybersecurity. Unlike traditional applications, we propose a novel use case for LLMs to identify scams, such as phishing, advance fee fraud, and romance scams. We present notable security applications of LLMs and discuss the unique challenges posed by scams. Specifically, we outline the key steps involved in building an effective scam detector using LLMs, emphasizing data collection, preprocessing, model selection, training, and integration into target systems. Additionally, we conduct a preliminary evaluation using GPT-3.5 and GPT-4 on a duplicated email, highlighting their proficiency in identifying common signs of phishing or scam emails. The results demonstrate the models' effectiveness in recognizing suspicious elements, but we emphasize the need for a comprehensive assessment across various language tasks. The paper concludes by underlining the importance of ongoing refinement and collaboration with cybersecurity experts to adapt to evolving threats.</li>
</ul>

<h3>Title: Video-LaVIT: Unified Video-Language Pre-training with Decoupled  Visual-Motional Tokenization</h3>
<ul>
<li><strong>Authors: </strong>Yang Jin, Zhicheng Sun, Kun Xu, Kun Xu, Liwei Chen, Hao Jiang, Quzhe Huang, Chengru Song, Yuliang Liu, Di Zhang, Yang Song, Kun Gai, Yadong Mu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03161">https://arxiv.org/abs/2402.03161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03161">https://arxiv.org/pdf/2402.03161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03161]] Video-LaVIT: Unified Video-Language Pre-training with Decoupled  Visual-Motional Tokenization(https://arxiv.org/abs/2402.03161)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In light of recent advances in multimodal Large Language Models (LLMs), there is increasing attention to scaling them from image-text data to more informative real-world videos. Compared to static images, video poses unique challenges for effective large-scale pre-training due to the modeling of its spatiotemporal dynamics. In this paper, we address such limitations in video-language pre-training with an efficient video decomposition that represents each video as keyframes and temporal motions. These are then adapted to an LLM using well-designed tokenizers that discretize visual and temporal information as a few tokens, thus enabling unified generative pre-training of videos, images, and text. At inference, the generated tokens from the LLM are carefully recovered to the original continuous pixel space to create various video content. Our proposed framework is both capable of comprehending and generating image and video content, as demonstrated by its competitive performance across 13 multimodal benchmarks in image and video understanding and generation. Our code and models will be available at https://video-lavit.github.io.</li>
</ul>

<h3>Title: Direct-a-Video: Customized Video Generation with User-Directed Camera  Movement and Object Motion</h3>
<ul>
<li><strong>Authors: </strong>Shiyuan Yang, Liang Hou, Haibin Huang, Chongyang Ma, Pengfei Wan, Di Zhang, Xiaodong Chen, Jing Liao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03162">https://arxiv.org/abs/2402.03162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03162">https://arxiv.org/pdf/2402.03162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03162]] Direct-a-Video: Customized Video Generation with User-Directed Camera  Movement and Object Motion(https://arxiv.org/abs/2402.03162)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent text-to-video diffusion models have achieved impressive progress. In practice, users often desire the ability to control object motion and camera movement independently for customized video creation. However, current methods lack the focus on separately controlling object motion and camera movement in a decoupled manner, which limits the controllability and flexibility of text-to-video models. In this paper, we introduce Direct-a-Video, a system that allows users to independently specify motions for one or multiple objects and/or camera movements, as if directing a video. We propose a simple yet effective strategy for the decoupled control of object motion and camera movement. Object motion is controlled through spatial cross-attention modulation using the model's inherent priors, requiring no additional optimization. For camera movement, we introduce new temporal cross-attention layers to interpret quantitative camera movement parameters. We further employ an augmentation-based approach to train these layers in a self-supervised manner on a small-scale dataset, eliminating the need for explicit motion annotation. Both components operate independently, allowing individual or combined control, and can generalize to open-domain scenarios. Extensive experiments demonstrate the superiority and effectiveness of our method. Project page: https://direct-a-video.github.io/.</li>
</ul>

<h3>Title: RRWNet: Recursive Refinement Network for Effective Retinal Artery/Vein  Segmentation and Classification</h3>
<ul>
<li><strong>Authors: </strong>Jos Morano, Guilherme Aresta, Hrvoje Bogunovi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03166">https://arxiv.org/abs/2402.03166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03166">https://arxiv.org/pdf/2402.03166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03166]] RRWNet: Recursive Refinement Network for Effective Retinal Artery/Vein  Segmentation and Classification(https://arxiv.org/abs/2402.03166)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The caliber and configuration of retinal blood vessels serve as important biomarkers for various diseases and medical conditions. A thorough analysis of the retinal vasculature requires the segmentation of blood vessels and their classification into arteries and veins, which is typically performed on color fundus images obtained by retinography, a widely used imaging technique. Nonetheless, manually performing these tasks is labor-intensive and prone to human error. Various automated methods have been proposed to address this problem. However, the current state of art in artery/vein segmentation and classification faces challenges due to manifest classification errors that affect the topological consistency of segmentation maps. This study presents an innovative end-to-end framework, RRWNet, designed to recursively refine semantic segmentation maps and correct manifest classification errors. The framework consists of a fully convolutional neural network with a Base subnetwork that generates base segmentation maps from input images, and a Recursive Refinement subnetwork that iteratively and recursively improves these maps. Evaluation on public datasets demonstrates the state-of-the-art performance of the proposed method, yielding more topologically consistent segmentation maps with fewer manifest classification errors than existing approaches. In addition, the Recursive Refinement module proves effective in post-processing segmentation maps from other methods, automatically correcting classification errors and improving topological consistency. The model code, weights, and predictions are publicly available at https://github.com/j-morano/rrwnet.</li>
</ul>

<h3>Title: Is Mamba Capable of In-Context Learning?</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Grazzi, Julien Siems, Simon Schrodi, Thomas Brox, Frank Hutter</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03170">https://arxiv.org/abs/2402.03170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03170">https://arxiv.org/pdf/2402.03170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03170]] Is Mamba Capable of In-Context Learning?(https://arxiv.org/abs/2402.03170)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This work provides empirical evidence that Mamba, a newly proposed selective structured state space model, has similar in-context learning (ICL) capabilities as transformers. We evaluated Mamba on tasks involving simple function approximation as well as more complex natural language processing problems. Our results demonstrate that across both categories of tasks, Mamba matches the performance of transformer models for ICL. Further analysis reveals that like transformers, Mamba appears to solve ICL problems by incrementally optimizing its internal representations. Overall, our work suggests that Mamba can be an efficient alternative to transformers for ICL tasks involving longer input sequences.</li>
</ul>

<h3>Title: Homograph Attacks on Maghreb Sentiment Analyzers</h3>
<ul>
<li><strong>Authors: </strong>Fatima Zahra Qachfar, Rakesh M. Verma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03171">https://arxiv.org/abs/2402.03171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03171">https://arxiv.org/pdf/2402.03171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03171]] Homograph Attacks on Maghreb Sentiment Analyzers(https://arxiv.org/abs/2402.03171)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>We examine the impact of homograph attacks on the Sentiment Analysis (SA) task of different Arabic dialects from the Maghreb North-African countries. Homograph attacks result in a 65.3% decrease in transformer classification from an F1-score of 0.95 to 0.33 when data is written in "Arabizi". The goal of this study is to highlight LLMs weaknesses' and to prioritize ethical and responsible Machine Learning.</li>
</ul>

<h3>Title: Accurate and Well-Calibrated ICD Code Assignment Through Attention Over  Diverse Label Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Gonalo Gomes, Isabel Coutinho, Bruno Martins</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03172">https://arxiv.org/abs/2402.03172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03172">https://arxiv.org/pdf/2402.03172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03172]] Accurate and Well-Calibrated ICD Code Assignment Through Attention Over  Diverse Label Embeddings(https://arxiv.org/abs/2402.03172)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Although the International Classification of Diseases (ICD) has been adopted worldwide, manually assigning ICD codes to clinical text is time-consuming, error-prone, and expensive, motivating the development of automated approaches. This paper describes a novel approach for automated ICD coding, combining several ideas from previous related work. We specifically employ a strong Transformer-based model as a text encoder and, to handle lengthy clinical narratives, we explored either (a) adapting the base encoder model into a Longformer, or (b) dividing the text into chunks and processing each chunk independently. The representations produced by the encoder are combined with a label embedding mechanism that explores diverse ICD code synonyms. Experiments with different splits of the MIMIC-III dataset show that the proposed approach outperforms the current state-of-the-art models in ICD coding, with the label embeddings significantly contributing to the good performance. Our approach also leads to properly calibrated classification results, which can effectively inform downstream tasks such as quantification.</li>
</ul>

<h3>Title: Multi: Multimodal Understanding Leaderboard with Text and Images</h3>
<ul>
<li><strong>Authors: </strong>Zichen Zhu, Yang Xu, Lu Chen, Jingkai Yang, Yichuan Ma, Yiming Sun, Hailin Wen, Jiaqi Liu, Jinyu Cai, Yingzi Ma, Situo Zhang, Zihan Zhao, Liangtai Sun, Kai Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03173">https://arxiv.org/abs/2402.03173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03173">https://arxiv.org/pdf/2402.03173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03173]] Multi: Multimodal Understanding Leaderboard with Text and Images(https://arxiv.org/abs/2402.03173)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Rapid progress in multimodal large language models (MLLMs) highlights the need to introduce challenging yet realistic benchmarks to the academic community. Existing benchmarks primarily focus on simple natural image understanding, but Multi emerges as a cutting-edge benchmark for MLLMs, offering a comprehensive dataset for evaluating MLLMs against understanding complex figures and tables, and scientific questions. This benchmark, reflecting current realistic examination styles, provides multimodal inputs and requires responses that are either precise or open-ended, similar to real-life school tests. It challenges MLLMs with a variety of tasks, ranging from formula derivation to image detail analysis, and cross-modality reasoning. Multi includes over 18,000 questions, with a focus on science-based QA in diverse formats. We also introduce Multi-Elite, a 500-question subset for testing the extremities of MLLMs, and Multi-Extend, which enhances In-Context Learning research with more than 4,500 knowledge pieces. Our evaluation indicates significant potential for MLLM advancement, with GPT-4V achieving a 63.7% accuracy rate on Multi, in contrast to other MLLMs scoring between 31.3% and 53.7%. Multi serves not only as a robust evaluation platform but also paves the way for the development of expert-level AI.</li>
</ul>

<h3>Title: The Matrix: A Bayesian learning model for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Siddhartha Dalal, Vishal Misra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03175">https://arxiv.org/abs/2402.03175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03175">https://arxiv.org/pdf/2402.03175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03175]] The Matrix: A Bayesian learning model for LLMs(https://arxiv.org/abs/2402.03175)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce a Bayesian learning model to understand the behavior of Large Language Models (LLMs). We explore the optimization metric of LLMs, which is based on predicting the next token, and develop a novel model grounded in this principle. Our approach involves constructing an ideal generative text model represented by a multinomial transition probability matrix with a prior, and we examine how LLMs approximate this matrix. We discuss the continuity of the mapping between embeddings and multinomial distributions, and present the Dirichlet approximation theorem to approximate any prior. Additionally, we demonstrate how text generation by LLMs aligns with Bayesian learning principles and delve into the implications for in-context learning, specifically explaining why in-context learning emerges in larger models where prompts are considered as samples to be updated. Our findings indicate that the behavior of LLMs is consistent with Bayesian Learning, offering new insights into their functioning and potential applications.</li>
</ul>

<h3>Title: CIDAR: Culturally Relevant Instruction Dataset For Arabic</h3>
<ul>
<li><strong>Authors: </strong>Zaid Alyafeai, Khalid Almubarak, Ahmed Ashraf, Deema Alnuhait, Saied Alshahrani, Gubran A. Q. Abdulrahman, Gamil Ahmed, Qais Gawah, Zead Saleh, Mustafa Ghaleb, Yousef Ali, Maged S. Al-Shaibani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03177">https://arxiv.org/abs/2402.03177</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03177">https://arxiv.org/pdf/2402.03177</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03177]] CIDAR: Culturally Relevant Instruction Dataset For Arabic(https://arxiv.org/abs/2402.03177)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning has emerged as a prominent methodology for teaching Large Language Models (LLMs) to follow instructions. However, current instruction datasets predominantly cater to English or are derived from English-dominated LLMs, resulting in inherent biases toward Western culture. This bias significantly impacts the linguistic structures of non-English languages such as Arabic, which has a distinct grammar reflective of the diverse cultures across the Arab region. This paper addresses this limitation by introducing CIDAR: https://hf.co/datasets/arbml/CIDAR, the first open Arabic instruction-tuning dataset culturally-aligned by human reviewers. CIDAR contains 10,000 instruction and output pairs that represent the Arab region. We discuss the cultural relevance of CIDAR via the analysis and comparison to other models fine-tuned on other datasets. Our experiments show that CIDAR can help enrich research efforts in aligning LLMs with the Arabic culture. All the code is available at https://github.com/ARBML/CIDAR.</li>
</ul>

<h3>Title: Empowering Time Series Analysis with Large Language Models: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Yushan Jiang, Zijie Pan, Xikun Zhang, Sahil Garg, Anderson Schneider, Yuriy Nevmyvaka, Dongjin Song</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03182">https://arxiv.org/abs/2402.03182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03182">https://arxiv.org/pdf/2402.03182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03182]] Empowering Time Series Analysis with Large Language Models: A Survey(https://arxiv.org/abs/2402.03182)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, remarkable progress has been made over large language models (LLMs), demonstrating their unprecedented capability in varieties of natural language tasks. However, completely training a large general-purpose model from the scratch is challenging for time series analysis, due to the large volumes and varieties of time series data, as well as the non-stationarity that leads to concept drift impeding continuous model adaptation and re-training. Recent advances have shown that pre-trained LLMs can be exploited to capture complex dependencies in time series data and facilitate various applications. In this survey, we provide a systematic overview of existing methods that leverage LLMs for time series analysis. Specifically, we first state the challenges and motivations of applying language models in the context of time series as well as brief preliminaries of LLMs. Next, we summarize the general pipeline for LLM-based time series analysis, categorize existing methods into different groups (i.e., direct query, tokenization, prompt design, fine-tune, and model integration), and highlight the key ideas within each group. We also discuss the applications of LLMs for both general and spatial-temporal time series data, tailored to specific domains. Finally, we thoroughly discuss future research opportunities to empower time series analysis with LLMs.</li>
</ul>

<h3>Title: Towards mitigating uncann(eye)ness in face swaps via gaze-centric loss  terms</h3>
<ul>
<li><strong>Authors: </strong>Ethan Wilson, Frederick Shic, Sophie Jrg, Eakta Jain</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03188">https://arxiv.org/abs/2402.03188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03188">https://arxiv.org/pdf/2402.03188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03188]] Towards mitigating uncann(eye)ness in face swaps via gaze-centric loss  terms(https://arxiv.org/abs/2402.03188)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Advances in face swapping have enabled the automatic generation of highly realistic faces. Yet face swaps are perceived differently than when looking at real faces, with key differences in viewer behavior surrounding the eyes. Face swapping algorithms generally place no emphasis on the eyes, relying on pixel or feature matching losses that consider the entire face to guide the training process. We further investigate viewer perception of face swaps, focusing our analysis on the presence of an uncanny valley effect. We additionally propose a novel loss equation for the training of face swapping models, leveraging a pretrained gaze estimation network to directly improve representation of the eyes. We confirm that viewed face swaps do elicit uncanny responses from viewers. Our proposed improvements significant reduce viewing angle errors between face swaps and their source material. Our method additionally reduces the prevalence of the eyes as a deciding factor when viewers perform deepfake detection tasks. Our findings have implications on face swapping for special effects, as digital avatars, as privacy mechanisms, and more; negative responses from users could limit effectiveness in said applications. Our gaze improvements are a first step towards alleviating negative viewer perceptions via a targeted approach.</li>
</ul>

<h3>Title: Unified Hallucination Detection for Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiang Chen, Chenxi Wang, Yida Xue, Ningyu Zhang, Xiaoyan Yang, Qiang Li, Yue Shen, Jinjie Gu, Huajun Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03190">https://arxiv.org/abs/2402.03190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03190">https://arxiv.org/pdf/2402.03190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03190]] Unified Hallucination Detection for Multimodal Large Language Models(https://arxiv.org/abs/2402.03190)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical application deployment. Prior research in this domain has been constrained by a narrow focus on singular tasks, an inadequate range of hallucination categories addressed, and a lack of detailed granularity. In response to these challenges, our work expands the investigative horizons of hallucination detection. We present a novel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate the evaluation of advancements in hallucination detection methods. Additionally, we unveil a novel unified multimodal hallucination detection framework, UNIHD, which leverages a suite of auxiliary tools to validate the occurrence of hallucinations robustly. We demonstrate the effectiveness of UNIHD through meticulous evaluation and comprehensive analysis. We also provide strategic insights on the application of specific tools for addressing various categories of hallucinations.</li>
</ul>

<h3>Title: Lightweight Masking Against Static Power Side-Channel Attacks</h3>
<ul>
<li><strong>Authors: </strong>Jitendra Bhandari, Mohammed Nabeel, Likhitha Mankali, Ozgur Sinanoglu, Ramesh Karri, Johann Knechtel</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03196">https://arxiv.org/abs/2402.03196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03196">https://arxiv.org/pdf/2402.03196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03196]] Lightweight Masking Against Static Power Side-Channel Attacks(https://arxiv.org/abs/2402.03196)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>This paper presents a novel defense strategy against static power side-channel attacks (PSCAs), a critical threat to cryptographic security. Our method is based on (1) carefully tuning high-Vth versus low-Vth cell selection during synthesis, accounting for both security and timing impact, and (2), at runtime, randomly switching the operation between these cells. This approach serves to significantly obscure static power patterns, which are at the heart of static PSCAs. Our experimental results on a commercial 28nm node show a drastic increase in the effort required for a successful attack, namely up to 96 times more traces. When compared to prior countermeasures, ours incurs little cost, making it a lightweight defense.</li>
</ul>

<h3>Title: SOAP: A Social Authentication Protocol</h3>
<ul>
<li><strong>Authors: </strong>Felix Linker, David Basin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03199">https://arxiv.org/abs/2402.03199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03199">https://arxiv.org/pdf/2402.03199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03199]] SOAP: A Social Authentication Protocol(https://arxiv.org/abs/2402.03199)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Social authentication has been suggested as a usable authentication ceremony to replace manual key authentication in messaging applications. Using social authentication, chat partners authenticate their peers using digital identities managed by identity providers. In this paper, we formally define social authentication, present a protocol called SOAP that largely automates social authentication, formally prove SOAP's security, and demonstrate SOAP's practicality in two prototypes. One prototype is web-based, and the other is implemented in the open-source Signal messaging application. Using SOAP, users can significantly raise the bar for compromising their messaging accounts. In contrast to the default security provided by messaging applications such as Signal and WhatsApp, attackers must compromise both the messaging account and all identity provider-managed identities to attack a victim. In addition to its security and automation, SOAP is straightforward to adopt as it is built on top of the well-established OpenID Connect protocol.</li>
</ul>

<h3>Title: Guidance with Spherical Gaussian Constraint for Conditional Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Lingxiao Yang, Shutong Ding, Yifan Cai, Jingyi Yu, Jingya Wang, Ye Shi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03201">https://arxiv.org/abs/2402.03201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03201">https://arxiv.org/pdf/2402.03201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03201]] Guidance with Spherical Gaussian Constraint for Conditional Diffusion(https://arxiv.org/abs/2402.03201)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion models attempt to handle conditional generative tasks by utilizing a differentiable loss function for guidance without the need for additional training. While these methods achieved certain success, they often compromise on sample quality and require small guidance step sizes, leading to longer sampling processes. This paper reveals that the fundamental issue lies in the manifold deviation during the sampling process when loss guidance is employed. We theoretically show the existence of manifold deviation by establishing a certain lower bound for the estimation error of the loss guidance. To mitigate this problem, we propose Diffusion with Spherical Gaussian constraint (DSG), drawing inspiration from the concentration phenomenon in high-dimensional Gaussian distributions. DSG effectively constrains the guidance step within the intermediate data manifold through optimization and enables the use of larger guidance steps. Furthermore, we present a closed-form solution for DSG denoising with the Spherical Gaussian constraint. Notably, DSG can seamlessly integrate as a plugin module within existing training-free conditional diffusion methods. Implementing DSG merely involves a few lines of additional code with almost no extra computational overhead, yet it leads to significant performance improvements. Comprehensive experimental results in various conditional generation tasks validate the superiority and adaptability of DSG in terms of both sample quality and time efficiency.</li>
</ul>

<h3>Title: Light and Optimal Schrdinger Bridge Matching</h3>
<ul>
<li><strong>Authors: </strong>Nikita Gushchin, Sergei Kholkin, Evgeny Burnaev, Alexander Korotin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03207">https://arxiv.org/abs/2402.03207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03207">https://arxiv.org/pdf/2402.03207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03207]] Light and Optimal Schrdinger Bridge Matching(https://arxiv.org/abs/2402.03207)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Schr\"odinger Bridges (SB) have recently gained the attention of the ML community as a promising extension of classic diffusion models which is also interconnected to the Entropic Optimal Transport (EOT). Recent solvers for SB exploit the pervasive bridge matching procedures. Such procedures aim to recover a stochastic process transporting the mass between distributions given only a transport plan between them. In particular, given the EOT plan, these procedures can be adapted to solve SB. This fact is heavily exploited by recent works giving rives to matching-based SB solvers. The cornerstone here is recovering the EOT plan: recent works either use heuristical approximations (e.g., the minibatch OT) or establish iterative matching procedures which by the design accumulate the error during the training. We address these limitations and propose a novel procedure to learn SB which we call the \textbf{optimal Schr\"odinger bridge matching}. It exploits the optimal parameterization of the diffusion process and provably recovers the SB process \textbf{(a)} with a single bridge matching step and \textbf{(b)} with arbitrary transport plan as the input. Furthermore, we show that the optimal bridge matching objective coincides with the recently discovered energy-based modeling (EBM) objectives to learn EOT/SB. Inspired by this observation, we develop a light solver (which we call LightSB-M) to implement optimal matching in practice using the Gaussian mixture parameterization of the Schr\"odinger potential. We experimentally showcase the performance of our solver in a range of practical tasks. The code for the LightSB-M solver can be found at \url{https://github.com/SKholkin/LightSB-Matching}.</li>
</ul>

<h3>Title: Organic or Diffused: Can We Distinguish Human Art from AI-generated  Images?</h3>
<ul>
<li><strong>Authors: </strong>Anna Yoo Jeong Ha, Josephine Passananti, Ronik Bhaskar, Shawn Shan, Reid Southen, Haitao Zheng, Ben Y. Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03214">https://arxiv.org/abs/2402.03214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03214">https://arxiv.org/pdf/2402.03214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03214]] Organic or Diffused: Can We Distinguish Human Art from AI-generated  Images?(https://arxiv.org/abs/2402.03214)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The advent of generative AI images has completely disrupted the art world. Identifying AI generated images from human art is a challenging problem whose impact is growing over time. The failure to address this problem allows bad actors to defraud individuals paying a premium for human art, and companies whose stated policies forbid AI imagery. This is also critical for AI model trainers, who need to filter training data to avoid potential model collapse. There are several different approaches to distinguishing human art from AI images, including classifiers trained by supervised learning, research tools targeting diffusion models, and identification by professional artists using their knowledge of artistic techniques. In this paper, we seek to understand how well these approaches can perform against today's modern generative models in both benign and adversarial settings. We curate real human art across 7 styles, generate matching images from 5 generative models, and apply 8 detectors (5 automated detectors and 3 different human groups including 180 crowdworkers, 4000+ professional artists, and 13 expert artists experienced at detecting AI). Both Hive and expert artists do very well, but make mistakes in different ways (Hive is weaker against adversarial perturbations while Expert artists produce higher false positives). We believe these weaknesses will remain as models continue to evolve, and use our data to demonstrate why a combined team of human and automated detectors provides the best combination of accuracy and robustness.</li>
</ul>

<h3>Title: English Prompts are Better for NLI-based Zero-Shot Emotion  Classification than Target-Language Prompts</h3>
<ul>
<li><strong>Authors: </strong>Patrick Barrei, Roman Klinger, Jeremy Barnes</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03223">https://arxiv.org/abs/2402.03223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03223">https://arxiv.org/pdf/2402.03223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03223]] English Prompts are Better for NLI-based Zero-Shot Emotion  Classification than Target-Language Prompts(https://arxiv.org/abs/2402.03223)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Emotion classification in text is a challenging and subjective task, due to the involved cognitive inference processes that are required to interpret a textual stimulus. In addition, the set of emotion categories is highly domain-specific. For instance, literature analysis might require the use of aesthetic emotions (e.g., finding something beautiful), and social media analysis could benefit from fine-grained sets (e.g., separating anger from annoyance) in contrast to basic emotion categories. This renders the task an interesting field for zero-shot classifications, in which the label set is not known at model development time. Unfortunately, most resources for emotion analysis are English, and therefore, most studies on emotion analysis have been performed in English, including those that involve prompting language models for text labels. This leaves us with a research gap that we address in this paper: In which language should we prompt for emotion labels on non-English texts? This is particularly of interest when we have access to a multilingual large language model, because we could request labels with English prompts even for non-English data. Our experiments with natural language inference-based language models show that it is consistently better to use English prompts even if the data is in a different language.</li>
</ul>

<h3>Title: FuseMoE: Mixture-of-Experts Transformers for Fleximodal Fusion</h3>
<ul>
<li><strong>Authors: </strong>Xing Han, Huy Nguyen, Carl Harris, Nhat Ho, Suchi Saria</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03226">https://arxiv.org/abs/2402.03226</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03226">https://arxiv.org/pdf/2402.03226</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03226]] FuseMoE: Mixture-of-Experts Transformers for Fleximodal Fusion(https://arxiv.org/abs/2402.03226)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>As machine learning models in critical fields increasingly grapple with multimodal data, they face the dual challenges of handling a wide array of modalities, often incomplete due to missing elements, and the temporal irregularity and sparsity of collected samples. Successfully leveraging this complex data, while overcoming the scarcity of high-quality training samples, is key to improving these models' predictive performance. We introduce ``FuseMoE'', a mixture-of-experts framework incorporated with an innovative gating function. Designed to integrate a diverse number of modalities, FuseMoE is effective in managing scenarios with missing modalities and irregularly sampled data trajectories. Theoretically, our unique gating function contributes to enhanced convergence rates, leading to better performance in multiple downstream tasks. The practical utility of FuseMoE in real world is validated by a challenging set of clinical risk prediction tasks.</li>
</ul>

<h3>Title: CT-based Anatomical Segmentation for Thoracic Surgical Planning: A  Benchmark Study for 3D U-shaped Deep Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Arash Harirpoush, Amirhossein Rasoulian, Marta Kersten-Oertel, Yiming Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03230">https://arxiv.org/abs/2402.03230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03230">https://arxiv.org/pdf/2402.03230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03230]] CT-based Anatomical Segmentation for Thoracic Surgical Planning: A  Benchmark Study for 3D U-shaped Deep Learning Models(https://arxiv.org/abs/2402.03230)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Recent rising interests in patient-specific thoracic surgical planning and simulation require efficient and robust creation of digital anatomical models from automatic medical image segmentation algorithms. Deep learning (DL) is now state-of-the-art in various radiological tasks, and U-shaped DL models have particularly excelled in medical image segmentation since the inception of the 2D UNet. To date, many variants of U-shaped models have been proposed by the integration of different attention mechanisms and network configurations. Leveraging the recent development of large multi-label databases, systematic benchmark studies for these models can provide valuable insights for clinical deployment and future model designs, but such studies are still rare. We conduct the first benchmark study for variants of 3D U-shaped models (3DUNet, STUNet, AttentionUNet, SwinUNETR, FocalSegNet, and a novel 3D SwinUnet with four variants) with a focus on CT-based anatomical segmentation for thoracic surgery. Our study systematically examines the impact of different attention mechanisms, number of resolution stages, and network configurations on segmentation accuracy and computational complexity. To allow cross-reference with other recent benchmarking studies, we also included a performance assessment of the BTCV abdominal structural segmentation. With the STUNet ranking at the top, our study demonstrated the value of CNN-based U-shaped models for the investigated tasks and the benefit of residual blocks in network configuration designs to boost segmentation performance.</li>
</ul>

<h3>Title: FROSTER: Frozen CLIP Is A Strong Teacher for Open-Vocabulary Action  Recognition</h3>
<ul>
<li><strong>Authors: </strong>Xiaohu Huang, Hao Zhou, Kun Yao, Kai Han</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03241">https://arxiv.org/abs/2402.03241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03241">https://arxiv.org/pdf/2402.03241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03241]] FROSTER: Frozen CLIP Is A Strong Teacher for Open-Vocabulary Action  Recognition(https://arxiv.org/abs/2402.03241)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce FROSTER, an effective framework for open-vocabulary action recognition. The CLIP model has achieved remarkable success in a range of image-based tasks, benefiting from its strong generalization capability stemming from pretaining on massive image-text pairs. However, applying CLIP directly to the open-vocabulary action recognition task is challenging due to the absence of temporal information in CLIP's pretraining. Further, fine-tuning CLIP on action recognition datasets may lead to overfitting and hinder its generalizability, resulting in unsatisfactory results when dealing with unseen actions. To address these issues, FROSTER employs a residual feature distillation approach to ensure that CLIP retains its generalization capability while effectively adapting to the action recognition task. Specifically, the residual feature distillation treats the frozen CLIP model as a teacher to maintain the generalizability exhibited by the original CLIP and supervises the feature learning for the extraction of video-specific features to bridge the gap between images and videos. Meanwhile, it uses a residual sub-network for feature distillation to reach a balance between the two distinct objectives of learning generalizable and video-specific features. We extensively evaluate FROSTER on open-vocabulary action recognition benchmarks under both base-to-novel and cross-dataset settings. FROSTER consistently achieves state-of-the-art performance on all datasets across the board. Project page: https://visual-ai.github.io/froster.</li>
</ul>

<h3>Title: JOBSKAPE: A Framework for Generating Synthetic Job Postings to Enhance  Skill Matching</h3>
<ul>
<li><strong>Authors: </strong>Antoine Magron, Anna Dai, Mike Zhang, Syrielle Montariol, Antoine Bosselut</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03242">https://arxiv.org/abs/2402.03242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03242">https://arxiv.org/pdf/2402.03242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03242]] JOBSKAPE: A Framework for Generating Synthetic Job Postings to Enhance  Skill Matching(https://arxiv.org/abs/2402.03242)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Recent approaches in skill matching, employing synthetic training data for classification or similarity model training, have shown promising results, reducing the need for time-consuming and expensive annotations. However, previous synthetic datasets have limitations, such as featuring only one skill per sentence and generally comprising short sentences. In this paper, we introduce JobSkape, a framework to generate synthetic data that tackles these limitations, specifically designed to enhance skill-to-taxonomy matching. Within this framework, we create SkillSkape, a comprehensive open-source synthetic dataset of job postings tailored for skill-matching tasks. We introduce several offline metrics that show that our dataset resembles real-world data. Additionally, we present a multi-step pipeline for skill extraction and matching tasks using large language models (LLMs), benchmarking against known supervised methodologies. We outline that the downstream evaluation results on real-world data can beat baselines, underscoring its efficacy and adaptability.</li>
</ul>

<h3>Title: Skill Set Optimization: Reinforcing Language Model Behavior via  Transferable Skills</h3>
<ul>
<li><strong>Authors: </strong>Kolby Nottingham, Bodhisattwa Prasad Majumder, Bhavana Dalvi Mishra, Sameer Singh, Peter Clark, Roy Fox</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03244">https://arxiv.org/abs/2402.03244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03244">https://arxiv.org/pdf/2402.03244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03244]] Skill Set Optimization: Reinforcing Language Model Behavior via  Transferable Skills(https://arxiv.org/abs/2402.03244)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have recently been used for sequential decision making in interactive environments. However, leveraging environment reward signals for continual LLM actor improvement is not straightforward. We propose Skill Set Optimization (SSO) for improving LLM actor performance through constructing and refining sets of transferable skills. SSO constructs skills by extracting common subtrajectories with high rewards and generating subgoals and instructions to represent each skill. These skills are provided to the LLM actor in-context to reinforce behaviors with high rewards. Then, SSO further refines the skill set by pruning skills that do not continue to result in high rewards. We evaluate our method in the classic videogame NetHack and the text environment ScienceWorld to demonstrate SSO's ability to optimize a set of skills and perform in-context policy improvement. SSO outperforms baselines by 40% in our custom NetHack task and outperforms the previous state-of-the-art in ScienceWorld by 35%.</li>
</ul>

<h3>Title: SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM</h3>
<ul>
<li><strong>Authors: </strong>Mingrui Li, Shuhong Liu, Heng Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03246">https://arxiv.org/abs/2402.03246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03246">https://arxiv.org/pdf/2402.03246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03246]] SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM(https://arxiv.org/abs/2402.03246)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM), facilitating comprehensive scene interpretation. Recent advancements that integrate Gaus- sian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings through the use of explicit 3D Gaussian representations. Building on this progress, we propose SGS-SLAM, the first semantic dense visual SLAM system grounded in 3D Gaussians, which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation, outperforming existing methods meanwhile preserving real-time rendering ability.</li>
</ul>

<h3>Title: Fair Active Ranking from Pairwise Preferences</h3>
<ul>
<li><strong>Authors: </strong>Sruthi Gorantla, Sara Ahmadian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03252">https://arxiv.org/abs/2402.03252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03252">https://arxiv.org/pdf/2402.03252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03252]] Fair Active Ranking from Pairwise Preferences(https://arxiv.org/abs/2402.03252)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We investigate the problem of probably approximately correct and fair (PACF) ranking of items by adaptively evoking pairwise comparisons. Given a set of $n$ items that belong to disjoint groups, our goal is to find an $(\epsilon, \delta)$-PACF-Ranking according to a fair objective function that we propose. We assume access to an oracle, wherein, for each query, the learner can choose a pair of items and receive stochastic winner feedback from the oracle. Our proposed objective function asks to minimize the $\ell_q$ norm of the error of the groups, where the error of a group is the $\ell_p$ norm of the error of all the items within that group, for $p, q \geq 1$. This generalizes the objective function of $\epsilon$-Best-Ranking, proposed by Saha & Gopalan (2019). By adopting our objective function, we gain the flexibility to explore fundamental fairness concepts like equal or proportionate errors within a unified framework. Adjusting parameters $p$ and $q$ allows tailoring to specific fairness preferences. We present both group-blind and group-aware algorithms and analyze their sample complexity. We provide matching lower bounds up to certain logarithmic factors for group-blind algorithms. For a restricted class of group-aware algorithms, we show that we can get reasonable lower bounds. We conduct comprehensive experiments on both real-world and synthetic datasets to complement our theoretical findings.</li>
</ul>

<h3>Title: MobilityGPT: Enhanced Human Mobility Modeling with a GPT model</h3>
<ul>
<li><strong>Authors: </strong>Ammar Haydari, Dongjie Chen, Zhengfeng Lai, Chen-Nee Chuah</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03264">https://arxiv.org/abs/2402.03264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03264">https://arxiv.org/pdf/2402.03264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03264]] MobilityGPT: Enhanced Human Mobility Modeling with a GPT model(https://arxiv.org/abs/2402.03264)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Generative models have shown promising results in capturing human mobility characteristics and generating synthetic trajectories. However, it remains challenging to ensure that the generated geospatial mobility data is semantically realistic, including consistent location sequences, and reflects real-world characteristics, such as constraining on geospatial limits. To address these issues, we reformat human mobility modeling as an autoregressive generation task, leveraging Generative Pre-trained Transformer (GPT). To ensure its controllable generation to alleviate the above challenges, we propose a geospatially-aware generative model, MobilityGPT. We propose a gravity-based sampling method to train a transformer for semantic sequence similarity. Then, we constrained the training process via a road connectivity matrix that provides the connectivity of sequences in trajectory generation, thereby keeping generated trajectories in geospatial limits. Lastly, we constructed a Reinforcement Learning from Trajectory Feedback (RLTF) to minimize the travel distance between training and the synthetically generated trajectories. Our experiments on real-world datasets demonstrate that MobilityGPT outperforms state-of-the-art methods in generating high-quality mobility trajectories that are closest to real data in terms of origin-destination similarity, trip length, travel radius, link, and gravity distributions.</li>
</ul>

<h3>Title: Multiclass Classification Procedure for Detecting Attacks on MQTT-IoT  Protocol</h3>
<ul>
<li><strong>Authors: </strong>Hector Alaiz-Moreton (1), Jose Aveleira-Mata (2), Jorge Ondicol-Garcia (2), Angel Luis Muoz-Castaeda (2), Isaas Garca (1), Carmen Benavides (1) ((1) Escuela de Ingenieras, Universidad de Len, (2) Research Institute of Applied Sciences in Cybersecurity, Universidad de Len)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03270">https://arxiv.org/abs/2402.03270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03270">https://arxiv.org/pdf/2402.03270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03270]] Multiclass Classification Procedure for Detecting Attacks on MQTT-IoT  Protocol(https://arxiv.org/abs/2402.03270)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>The large number of sensors and actuators that make up the Internet of Things obliges these systems to use diverse technologies and protocols. This means that IoT networks are more heterogeneous than traditional networks. This gives rise to new challenges in cybersecurity to protect these systems and devices which are characterized by being connected continuously to the Internet. Intrusion detection systems (IDS) are used to protect IoT systems from the various anomalies and attacks at the network level. Intrusion Detection Systems (IDS) can be improved through machine learning techniques. Our work focuses on creating classification models that can feed an IDS using a dataset containing frames under attacks of an IoT system that uses the MQTT protocol. We have addressed two types of method for classifying the attacks, ensemble methods and deep learning models, more specifically recurrent networks with very satisfactory results.</li>
</ul>

<h3>Title: Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information  Seeking in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Hu, Chumin Liu, Xidong Feng, Yilun Zhao, See-Kiong Ng, Anh Tuan Luu, Junxian He, Pang Wei Koh, Bryan Hooi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03271">https://arxiv.org/abs/2402.03271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03271">https://arxiv.org/pdf/2402.03271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03271]] Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information  Seeking in Large Language Models(https://arxiv.org/abs/2402.03271)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the face of uncertainty, the ability to seek information is of fundamental importance. In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to be actively sought by asking follow-up questions (for example, a doctor asking a patient for more details about their symptoms). In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to augment large language models with the ability to actively seek information by asking effective questions. UoT combines 1) an uncertainty-aware simulation approach which enables the model to simulate possible future scenarios and how likely they are to occur, 2) uncertainty-based rewards motivated by information gain which incentivizes the model to seek information, and 3) a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward. In experiments on medical diagnosis, troubleshooting and the '20 Questions' game, UoT achieves an average performance improvement of 57.8% in the rate of successful task completion across multiple LLMs compared with direct prompting, and also improves efficiency (i.e., the number of questions needed to complete the task).</li>
</ul>

<h3>Title: Deal, or no deal (or who knows)? Forecasting Uncertainty in  Conversations using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anthony Sicilia, Hyunwoo Kim, Khyathi Raghavi Chandu, Malihe Alikhani, Jack Hessel</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03284">https://arxiv.org/abs/2402.03284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03284">https://arxiv.org/pdf/2402.03284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03284]] Deal, or no deal (or who knows)? Forecasting Uncertainty in  Conversations using Large Language Models(https://arxiv.org/abs/2402.03284)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Effective interlocutors account for the uncertain goals, beliefs, and emotions of others. But even the best human conversationalist cannot perfectly anticipate the trajectory of a dialogue. How well can language models represent inherent uncertainty in conversations? We propose FortUne Dial, an expansion of the long-standing "conversation forecasting" task: instead of just accuracy, evaluation is conducted with uncertainty-aware metrics, effectively enabling abstention on individual instances. We study two ways in which language models potentially represent outcome uncertainty (internally, using scores and directly, using tokens) and propose fine-tuning strategies to improve calibration of both representations. Experiments on eight difficult negotiation corpora demonstrate that our proposed fine-tuning strategies (a traditional supervision strategy and an off-policy reinforcement learning strategy) can calibrate smaller open-source models to compete with pre-trained models 10x their size.</li>
</ul>

<h3>Title: Make Every Move Count: LLM-based High-Quality RTL Code Generation Using  MCTS</h3>
<ul>
<li><strong>Authors: </strong>Matthew DeLorenzo, Animesh Basak Chowdhury, Vasudev Gohil, Shailja Thakur, Ramesh Karri, Siddharth Garg, Jeyavijayan Rajendran</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03289">https://arxiv.org/abs/2402.03289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03289">https://arxiv.org/pdf/2402.03289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03289]] Make Every Move Count: LLM-based High-Quality RTL Code Generation Using  MCTS(https://arxiv.org/abs/2402.03289)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Existing large language models (LLMs) for register transfer level code generation face challenges like compilation failures and suboptimal power, performance, and area (PPA) efficiency. This is due to the lack of PPA awareness in conventional transformer decoding algorithms. In response, we present an automated transformer decoding algorithm that integrates Monte Carlo tree-search for lookahead, guiding the transformer to produce compilable, functionally correct, and PPA-optimized code. Empirical evaluation with a fine-tuned language model on RTL codesets shows that our proposed technique consistently generates functionally correct code compared to prompting-only methods and effectively addresses the PPA-unawareness drawback of naive large language models. For the largest design generated by the state-of-the-art LLM (16-bit adder), our technique can achieve a 31.8% improvement in the area-delay product.</li>
</ul>

<h3>Title: InstanceDiffusion: Instance-level Control for Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Xudong Wang, Trevor Darrell, Sai Saketh Rambhatla, Rohit Girdhar, Ishan Misra</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03290">https://arxiv.org/abs/2402.03290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03290">https://arxiv.org/pdf/2402.03290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03290]] InstanceDiffusion: Instance-level Control for Image Generation(https://arxiv.org/abs/2402.03290)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models produce high quality images but do not offer control over individual instances in the image. We introduce InstanceDiffusion that adds precise instance-level control to text-to-image diffusion models. InstanceDiffusion supports free-form language conditions per instance and allows flexible ways to specify instance locations such as simple single points, scribbles, bounding boxes or intricate instance segmentation masks, and combinations thereof. We propose three major changes to text-to-image models that enable precise instance-level control. Our UniFusion block enables instance-level conditions for text-to-image models, the ScaleU block improves image fidelity, and our Multi-instance Sampler improves generations for multiple instances. InstanceDiffusion significantly surpasses specialized state-of-the-art models for each location condition. Notably, on the COCO dataset, we outperform previous state-of-the-art by 20.4% AP$_{50}^\text{box}$ for box inputs, and 25.4% IoU for mask inputs.</li>
</ul>

<h3>Title: Zero-shot Object-Level OOD Detection with Context-Aware Inpainting</h3>
<ul>
<li><strong>Authors: </strong>Quang-Huy Nguyen, Jin Peng Zhou, Zhenzhen Liu, Khanh-Huyen Bui, Kilian Q. Weinberger, Dung D. Le</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03292">https://arxiv.org/abs/2402.03292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03292">https://arxiv.org/pdf/2402.03292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03292]] Zero-shot Object-Level OOD Detection with Context-Aware Inpainting(https://arxiv.org/abs/2402.03292)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Machine learning algorithms are increasingly provided as black-box cloud services or pre-trained models, without access to their training data. This motivates the problem of zero-shot out-of-distribution (OOD) detection. Concretely, we aim to detect OOD objects that do not belong to the classifier's label set but are erroneously classified as in-distribution (ID) objects. Our approach, RONIN, uses an off-the-shelf diffusion model to replace detected objects with inpainting. RONIN conditions the inpainting process with the predicted ID label, drawing the input object closer to the in-distribution domain. As a result, the reconstructed object is very close to the original in the ID cases and far in the OOD cases, allowing RONIN to effectively distinguish ID and OOD samples. Throughout extensive experiments, we demonstrate that RONIN achieves competitive results compared to previous approaches across several datasets, both in zero-shot and non-zero-shot settings.</li>
</ul>

<h3>Title: GUARD: Role-playing to Generate Natural-language Jailbreakings to Test  Guideline Adherence of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haibo Jin, Ruoxi Chen, Andy Zhou, Jinyin Chen, Yang Zhang, Haohan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03299">https://arxiv.org/abs/2402.03299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03299">https://arxiv.org/pdf/2402.03299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03299]] GUARD: Role-playing to Generate Natural-language Jailbreakings to Test  Guideline Adherence of Large Language Models(https://arxiv.org/abs/2402.03299)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The discovery of "jailbreaks" to bypass safety filters of Large Language Models (LLMs) and harmful responses have encouraged the community to implement safety measures. One major safety measure is to proactively test the LLMs with jailbreaks prior to the release. Therefore, such testing will require a method that can generate jailbreaks massively and efficiently. In this paper, we follow a novel yet intuitive strategy to generate jailbreaks in the style of the human generation. We propose a role-playing system that assigns four different roles to the user LLMs to collaborate on new jailbreaks. Furthermore, we collect existing jailbreaks and split them into different independent characteristics using clustering frequency and semantic patterns sentence by sentence. We organize these characteristics into a knowledge graph, making them more accessible and easier to retrieve. Our system of different roles will leverage this knowledge graph to generate new jailbreaks, which have proved effective in inducing LLMs to generate unethical or guideline-violating responses. In addition, we also pioneer a setting in our system that will automatically follow the government-issued guidelines to generate jailbreaks to test whether LLMs follow the guidelines accordingly. We refer to our system as GUARD (Guideline Upholding through Adaptive Role-play Diagnostics). We have empirically validated the effectiveness of GUARD on three cutting-edge open-sourced LLMs (Vicuna-13B, LongChat-7B, and Llama-2-7B), as well as a widely-utilized commercial LLM (ChatGPT). Moreover, our work extends to the realm of vision language models (MiniGPT-v2 and Gemini Vision Pro), showcasing GUARD's versatility and contributing valuable insights for the development of safer, more reliable LLM-based applications across diverse modalities.</li>
</ul>

<h3>Title: Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining</h3>
<ul>
<li><strong>Authors: </strong>Jiarun Liu, Hao Yang, Hong-Yu Zhou, Yan Xi, Lequan Yu, Yizhou Yu, Yong Liang, Guangming Shi, Shaoting Zhang, Hairong Zheng, Shanshan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03302">https://arxiv.org/abs/2402.03302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03302">https://arxiv.org/pdf/2402.03302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03302]] Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining(https://arxiv.org/abs/2402.03302)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate medical image segmentation demands the integration of multi-scale information, spanning from local features to global dependencies. However, it is challenging for existing methods to model long-range global information, where convolutional neural networks (CNNs) are constrained by their local receptive fields, and vision transformers (ViTs) suffer from high quadratic complexity of their attention mechanism. Recently, Mamba-based models have gained great attention for their impressive ability in long sequence modeling. Several studies have demonstrated that these models can outperform popular vision models in various tasks, offering higher accuracy, lower memory consumption, and less computational burden. However, existing Mamba-based models are mostly trained from scratch and do not explore the power of pretraining, which has been proven to be quite effective for data-efficient medical image analysis. This paper introduces a novel Mamba-based model, Swin-UMamba, designed specifically for medical image segmentation tasks, leveraging the advantages of ImageNet-based pretraining. Our experimental results reveal the vital role of ImageNet-based training in enhancing the performance of Mamba-based models. Swin-UMamba demonstrates superior performance with a large margin compared to CNNs, ViTs, and latest Mamba-based models. Notably, on AbdomenMRI, Encoscopy, and Microscopy datasets, Swin-UMamba outperforms its closest counterpart U-Mamba by an average score of 3.58%. The code and models of Swin-UMamba are publicly available at: https://github.com/JiarunLiu/Swin-UMamba</li>
</ul>

<h3>Title: Nevermind: Instruction Override and Moderation in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Edward Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03303">https://arxiv.org/abs/2402.03303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03303">https://arxiv.org/pdf/2402.03303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03303]] Nevermind: Instruction Override and Moderation in Large Language Models(https://arxiv.org/abs/2402.03303)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Given the impressive capabilities of recent Large Language Models (LLMs), we investigate and benchmark the most popular proprietary and different sized open source models on the task of explicit instruction following in conflicting situations, e.g. overrides. These include the ability of the model to override the knowledge within the weights of the model, the ability to override (or moderate) extracted knowledge in the prompt, and lastly the ability to perform a full jailbreak. Experimentation performed suggest several key findings to improve instruction following - larger models perform the best in following instructions that override internal and contextual instructions, and are obedient, even to a fault. When scaling to longer contexts via rope scaling, a significant buffer needs to be maintained from the edge of the perplexity cliff in order to maintain instruction following capabilities. Finally, we observe improving instruction following, and subsequently instruction overrides/jailbreaks, is fundamentally at odds with the ability of a language model to follow given safety filters or guidelines. Thus, we postulate the most effective approach for safe, trustworthy AI should be dealt external to the LLM itself.</li>
</ul>

<h3>Title: Do Diffusion Models Learn Semantically Meaningful and Efficient  Representations?</h3>
<ul>
<li><strong>Authors: </strong>Qiyao Liang, Ziming Liu, Ila Fiete</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03305">https://arxiv.org/abs/2402.03305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03305">https://arxiv.org/pdf/2402.03305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03305]] Do Diffusion Models Learn Semantically Meaningful and Efficient  Representations?(https://arxiv.org/abs/2402.03305)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models are capable of impressive feats of image generation with uncommon juxtapositions such as astronauts riding horses on the moon with properly placed shadows. These outputs indicate the ability to perform compositional generalization, but how do the models do so? We perform controlled experiments on conditional DDPMs learning to generate 2D spherical Gaussian bumps centered at specified $x$- and $y$-positions. Our results show that the emergence of semantically meaningful latent representations is key to achieving high performance. En route to successful performance over learning, the model traverses three distinct phases of latent representations: (phase A) no latent structure, (phase B) a 2D manifold of disordered states, and (phase C) a 2D ordered manifold. Corresponding to each of these phases, we identify qualitatively different generation behaviors: 1) multiple bumps are generated, 2) one bump is generated but at inaccurate $x$ and $y$ locations, 3) a bump is generated at the correct $x$ and y location. Furthermore, we show that even under imbalanced datasets where features ($x$- versus $y$-positions) are represented with skewed frequencies, the learning process for $x$ and $y$ is coupled rather than factorized, demonstrating that simple vanilla-flavored diffusion models cannot learn efficient representations in which localization in $x$ and $y$ are factorized into separate 1D tasks. These findings suggest the need for future work to find inductive biases that will push generative models to discover and exploit factorizable independent structures in their inputs, which will be required to vault these models into more data-efficient regimes.</li>
</ul>

<h3>Title: AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion</h3>
<ul>
<li><strong>Authors: </strong>Mohamad Qadri, Kevin Zhang, Akshay Hinduja, Michael Kaess, Adithya Pediredla, Christopher A. Metzler</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03309">https://arxiv.org/abs/2402.03309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03309">https://arxiv.org/pdf/2402.03309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03309]] AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion(https://arxiv.org/abs/2402.03309)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Underwater perception and 3D surface reconstruction are challenging problems with broad applications in construction, security, marine archaeology, and environmental monitoring. Treacherous operating conditions, fragile surroundings, and limited navigation control often dictate that submersibles restrict their range of motion and, thus, the baseline over which they can capture measurements. In the context of 3D scene reconstruction, it is well-known that smaller baselines make reconstruction more challenging. Our work develops a physics-based multimodal acoustic-optical neural surface reconstruction framework (AONeuS) capable of effectively integrating high-resolution RGB measurements with low-resolution depth-resolved imaging sonar measurements. By fusing these complementary modalities, our framework can reconstruct accurate high-resolution 3D surfaces from measurements captured over heavily-restricted baselines. Through extensive simulations and in-lab experiments, we demonstrate that AONeuS dramatically outperforms recent RGB-only and sonar-only inverse-differentiable-rendering--based surface reconstruction methods. A website visualizing the results of our paper is located at this address: https://aoneus.github.io/</li>
</ul>

<h3>Title: HASSOD: Hierarchical Adaptive Self-Supervised Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Shengcao Cao, Dhiraj Joshi, Liang-Yan Gui, Yu-Xiong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03311">https://arxiv.org/abs/2402.03311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03311">https://arxiv.org/pdf/2402.03311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03311]] HASSOD: Hierarchical Adaptive Self-Supervised Object Detection(https://arxiv.org/abs/2402.03311)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The human visual perception system demonstrates exceptional capabilities in learning without explicit supervision and understanding the part-to-whole composition of objects. Drawing inspiration from these two abilities, we propose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), a novel approach that learns to detect objects and understand their compositions without human supervision. HASSOD employs a hierarchical adaptive clustering strategy to group regions into object masks based on self-supervised visual representations, adaptively determining the number of objects per image. Furthermore, HASSOD identifies the hierarchical levels of objects in terms of composition, by analyzing coverage relations between masks and constructing tree structures. This additional self-supervised learning task leads to improved detection performance and enhanced interpretability. Lastly, we abandon the inefficient multi-round self-training process utilized in prior methods and instead adapt the Mean Teacher framework from semi-supervised learning, which leads to a smoother and more efficient training process. Through extensive experiments on prevalent image datasets, we demonstrate the superiority of HASSOD over existing methods, thereby advancing the state of the art in self-supervised object detection. Notably, we improve Mask AR from 20.2 to 22.5 on LVIS, and from 17.0 to 26.0 on SA-1B. Project page: https://HASSOD-NeurIPS23.github.io.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
