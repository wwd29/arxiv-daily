<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-04-29</h1>
<h3>Title: Leaf-Based Plant Disease Detection and Explainable AI</h3>
<ul>
<li><strong>Authors: </strong>Saurav Sagar, Mohammed Javed, David S Doermann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16833">https://arxiv.org/abs/2404.16833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16833">https://arxiv.org/pdf/2404.16833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16833]] Leaf-Based Plant Disease Detection and Explainable AI(https://arxiv.org/abs/2404.16833)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The agricultural sector plays an essential role in the economic growth of a country. Specifically, in an Indian context, it is the critical source of livelihood for millions of people living in rural areas. Plant Disease is one of the significant factors affecting the agricultural sector. Plants get infected with diseases for various reasons, including synthetic fertilizers, archaic practices, environmental conditions, etc., which impact the farm yield and subsequently hinder the economy. To address this issue, researchers have explored many applications based on AI and Machine Learning techniques to detect plant diseases. This research survey provides a comprehensive understanding of common plant leaf diseases, evaluates traditional and deep learning techniques for disease detection, and summarizes available datasets. It also explores Explainable AI (XAI) to enhance the interpretability of deep learning models' decisions for end-users. By consolidating this knowledge, the survey offers valuable insights to researchers, practitioners, and stakeholders in the agricultural sector, fostering the development of efficient and transparent solutions for combating plant diseases and promoting sustainable agricultural practices.</li>
</ul>

<h3>Title: The Security Performance Analysis of Blockchain System Based on  Post-Quantum Cryptography -- A Case Study of Cryptocurrency Exchanges</h3>
<ul>
<li><strong>Authors: </strong>Abel C. H. Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16837">https://arxiv.org/abs/2404.16837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16837">https://arxiv.org/pdf/2404.16837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16837]] The Security Performance Analysis of Blockchain System Based on  Post-Quantum Cryptography -- A Case Study of Cryptocurrency Exchanges(https://arxiv.org/abs/2404.16837)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The current blockchain system for cryptocurrency exchanges primarily employs elliptic curve cryptography (ECC) for generating key pairs in wallets, and elliptic curve digital signature algorithms (ECDSA) for generating signatures in transactions. Consequently, with the maturation of quantum computing technology, the current blockchain system faces the risk of quantum computing attacks. Quantum computers may potentially counterfeit signatures produced by ECDSA. Therefore, this study analyzes the vulnerabilities of the current blockchain system to quantum computing attacks and proposes a post-quantum cryptography (PQC)-based blockchain system to enhance security by addressing and improving each identified weakness. Furthermore, this study proposes PQC-based wallets and PQC-based transactions, utilizing PQC digital signature algorithms to generate PQC-based signatures for the inputs in PQC-based transactions, thereby preventing signatures from being counterfeited by quantum computing. Experimental results demonstrate that the efficiency of the Dilithium algorithm, a PQC digital signature algorithm, in producing wallets, generating signatures, and verifying signatures surpasses that of ECDSA in the current blockchain system. Furthermore, the Dilithium algorithm also exhibits a higher security level.</li>
</ul>

<h3>Title: Predicting SSH keys in Open SSH Memory dumps</h3>
<ul>
<li><strong>Authors: </strong>Florian Rascoussier</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16838">https://arxiv.org/abs/2404.16838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16838">https://arxiv.org/pdf/2404.16838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16838]] Predicting SSH keys in Open SSH Memory dumps(https://arxiv.org/abs/2404.16838)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect</a></li>
<li><strong>Abstract: </strong>As the digital landscape evolves, cybersecurity has become an indispensable focus of IT systems. Its ever-escalating challenges have amplified the importance of digital forensics, particularly in the analysis of heap dumps from main memory. In this context, the Secure Shell protocol (SSH) designed for encrypted communications, serves as both a safeguard and a potential veil for malicious activities. This research project focuses on predicting SSH keys in OpenSSH memory dumps, aiming to enhance protective measures against illicit access and enable the development of advanced security frameworks or tools like honeypots. This Masterarbeit is situated within the broader SmartVMI project, and seeks to build upon existing research on key prediction in OpenSSH heap dumps. Utilizing machine learning (ML) and deep learning models, the study aims to refine features for embedding techniques and explore innovative methods for effective key detection based on recent advancements in Knowledge Graph and ML. The objective is to accurately predict the presence and location of SSH keys within memory dumps. This work builds upon, and aims to enhance, the foundations laid by SSHkex and SmartKex, enriching both the methodology and the results of the original research while exploring the untapped potential of newly proposed approaches. The current thesis dives into memory graph modelization from raw binary heap dump files. Each memory graph can support a range of embeddings that can be used directly for model training, through the use of classic ML models and graph neural network. It offers an in-depth discussion on the current state-of-the-art in key prediction for OpenSSH memory dumps, research questions, experimental setups, programs development, results as well as discussing potential future directions.</li>
</ul>

<h3>Title: Immersed in Reality Secured by Design -- A Comprehensive Analysis of  Security Measures in AR/VR Environments</h3>
<ul>
<li><strong>Authors: </strong>Sameer Chauhan, Luv Sachdeva</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16839">https://arxiv.org/abs/2404.16839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16839">https://arxiv.org/pdf/2404.16839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16839]] Immersed in Reality Secured by Design -- A Comprehensive Analysis of  Security Measures in AR/VR Environments(https://arxiv.org/abs/2404.16839)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Virtual reality and related technologies such as mixed and augmented reality have received extensive coverage in both mainstream and fringe media outlets. When the subject goes to a new AR headset, another AR device, or AR glasses, the talk swiftly shifts to the technical and design details. Unfortunately, no one seemed to care about security. Data theft and other forms of cyberattack pose serious threats to virtual reality systems. Virtual reality goggles are just specialist versions of computers or Internet of Things devices, whereas virtual reality experiences are software packages. As a result, AR systems are just as vulnerable as any other Internet of Things (IoT) device we use on a daily basis, such as computers, tablets, and phones. Preventing and responding to common cybersecurity threats and assaults is crucial. Cybercriminals can exploit virtual reality headsets just like any other computer system. This paper analysis the data breach induced by these assaults could result in a variety of concerns, including but not limited to identity theft, the unauthorized acquisition of personal information or network credentials, damage to hardware and software, and so on. Augmented reality (AR) allows for real-time monitoring and visualization of network activity, system logs, and security alerts. This allows security professionals to immediately identify threats, monitor suspicious activities, and fix any issues that develop. This data can be displayed in an aesthetically pleasing and intuitively structured format using augmented reality interfaces, enabling for faster analysis and decision-making.</li>
</ul>

<h3>Title: Biometrics Employing Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Sajjad Bhuiyan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16840">https://arxiv.org/abs/2404.16840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16840">https://arxiv.org/pdf/2404.16840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16840]] Biometrics Employing Neural Network(https://arxiv.org/abs/2404.16840)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, biometric</a></li>
<li><strong>Abstract: </strong>Biometrics involves using unique human traits, both physical and behavioral, for the digital identification of individuals to provide access to systems, devices, or information. Within the field of computer science, it acts as a method for identifying and verifying individuals and controlling access. While the conventional method for personal authentication involves passwords, the vulnerability arises when passwords are compromised, allowing unauthorized access to sensitive actions. Biometric authentication presents a viable answer to this problem and is the most secure and user-friendly authentication method. Today, fingerprints, iris and retina patterns, facial recognition, hand shapes, palm prints, and voice recognition are frequently used forms of biometrics. Despite the diverse nature of these biometric identifiers, the core objective remains consistent ensuring security, recognizing authorized users, and rejecting impostors. Hence, it is crucial to determine accurately whether the characteristics belong to the rightful person. For systems to be effective and widely accepted, the error rate in recognition and verification must approach zero. It is acknowledged that current biometric techniques, while advanced, are not infallible and require continuous improvement. A more refined classifier is deemed necessary to classify patterns accurately. Artificial Neural Networks, which simulate the human brain's operations, present themselves as a promising approach. The survey presented herein explores various biometric techniques based on neural networks, emphasizing the ongoing quest for enhanced accuracy and reliability. It concludes that The utilization of neural networks along with biometric features not only enhances accuracy but also contributes to overall better security.</li>
</ul>

<h3>Title: Machine Unlearning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kongyang Chen, Zixin Wang, Bing Mi, Waixi Liu, Shaowei Wang, Xiaojun Ren, Jiaxing Shen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16841">https://arxiv.org/abs/2404.16841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16841">https://arxiv.org/pdf/2404.16841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16841]] Machine Unlearning in Large Language Models(https://arxiv.org/abs/2404.16841)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, large language model</a></li>
<li><strong>Abstract: </strong>Recently, large language models (LLMs) have emerged as a notable field, attracting significant attention for its ability to automatically generate intelligent contents for various application domains. However, LLMs still suffer from significant security and privacy issues. For example, LLMs might expose user privacy from hacking attacks or targeted prompts. To address this problem, this paper introduces a novel machine unlearning framework into LLMs. Our objectives are to make LLMs not produce harmful, hallucinatory, or privacy-compromising responses, while retaining their standard output capabilities. To accomplish this, we use an evaluative model to pinpoint dialogues needing unlearning. We also establish a distance loss to function as the model's negative loss, diverting it from previous undesirable outputs. Furthermore, we determine the expected output's cluster mean to formulate a positive loss, directing the model's outputs toward preferable outcomes without compromising its reasoning abilities and performance. Experimental results show that our approach effectively meets unlearning objectives without substantially compromising model performance.</li>
</ul>

<h3>Title: Cybersecurity Threat Analysis And Attack Simulations For Unmanned Aerial  Vehicle Networks</h3>
<ul>
<li><strong>Authors: </strong>Charles Abdulrazak</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16842">https://arxiv.org/abs/2404.16842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16842">https://arxiv.org/pdf/2404.16842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16842]] Cybersecurity Threat Analysis And Attack Simulations For Unmanned Aerial  Vehicle Networks(https://arxiv.org/abs/2404.16842)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Drones, also known as unmanned air vehicles (UAVs), have revolutionised various industries, from farming to national security. (Wexler., Lesley. 2016) However, their broad use has revealed a severe weakness in cybersecurity. (Jean-Paul Yaacoub 2020) The urgent necessity to defend UAV networks from new cyber threats is explored in-depth in this research, making it a crucial subject for both technological development and national security. The two essential areas of our study are assault simulation and threat analysis in cybersecurity. This work demonstrates how easy it is to hack a drone mid-flight using only a Raspberry Pi3 and open-source online tools. This work illustrates the ability to penetrate a DJI drone currently used by the mercenary soldiers in the Ukraine war. (Greg Myre March, 2023) This research examines strategies used to attack UAV networks, such as the de-authentic attack and the man-in-the-middle attack. This work investigates the weaknesses in these networks' sophisticated attack simulations with a Raspberry PI 3 and the Alpha network adaptor from Amazon, showing that basic tools are needed to perform cyberattacks on drones. This research proposes creative solutions and preventative methods for protecting UAV operations and highlights the seriousness of the problem. As drones become more prevalent daily, maintaining their security becomes crucial. This work provides a compelling perspective on protecting vital infrastructure and preserving our skies by bridging the gap between the latest technologies and cybersecurity.</li>
</ul>

<h3>Title: Enhancing Data Security through Rainbow Antimagic Graph Coloring for  Secret-Share Distribution and Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Raul M. Falcon, K. Abirami, N. Mohanapriya, Dafik</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16843">https://arxiv.org/abs/2404.16843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16843">https://arxiv.org/pdf/2404.16843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16843]] Enhancing Data Security through Rainbow Antimagic Graph Coloring for  Secret-Share Distribution and Reconstruction(https://arxiv.org/abs/2404.16843)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Now-a-days, ensuring data security has become an increasingly formidable challenge in safeguarding individuals' sensitive information. Secret-sharing scheme has evolved as a most successful cryptographic technique that allows a secret to be divided or distributed among a group of participants in such a way that only a subset of those participants can reconstruct the original secret. This provides a safe level of security and redundancy, ensuring that no single individual possesses the complete secret. The implementation of Rainbow Antimagic coloring within these schemes not only safeguards the data but also ensures an advanced level of information security among multi-participant groups. Additionally, the retrieved data is reconstructed and can be disseminated to all group participants via multiple rounds of communication.</li>
</ul>

<h3>Title: HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring  Unconstrained Photo Collections</h3>
<ul>
<li><strong>Authors: </strong>Chen Dudai, Morris Alper, Hana Bezalel, Rana Hanocka, Itai Lang, Hadar Averbuch-Elor</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16845">https://arxiv.org/abs/2404.16845</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16845">https://arxiv.org/pdf/2404.16845</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16845]] HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring  Unconstrained Photo Collections(https://arxiv.org/abs/2404.16845)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Internet image collections containing photos captured by crowds of photographers show promise for enabling digital exploration of large-scale tourist landmarks. However, prior works focus primarily on geometric reconstruction and visualization, neglecting the key role of language in providing a semantic interface for navigation and fine-grained understanding. In constrained 3D domains, recent methods have leveraged vision-and-language models as a strong prior of 2D visual semantics. While these models display an excellent understanding of broad visual semantics, they struggle with unconstrained photo collections depicting such tourist landmarks, as they lack expert knowledge of the architectural domain. In this work, we present a localization system that connects neural representations of scenes depicting large-scale landmarks with text describing a semantic region within the scene, by harnessing the power of SOTA vision-and-language models with adaptations for understanding landmark scene semantics. To bolster such models with fine-grained knowledge, we leverage large-scale Internet data containing images of similar landmarks along with weakly-related textual information. Our approach is built upon the premise that images physically grounded in space can provide a powerful supervision signal for localizing new concepts, whose semantics may be unlocked from Internet textual metadata with large language models. We use correspondences between views of scenes to bootstrap spatial understanding of these semantics, providing guidance for 3D-compatible segmentation that ultimately lifts to a volumetric scene representation. Our results show that HaLo-NeRF can accurately localize a variety of semantic concepts related to architectural landmarks, surpassing the results of other 3D models as well as strong 2D segmentation baselines. Our project page is at https://tau-vailab.github.io/HaLo-NeRF/.</li>
</ul>

<h3>Title: Securing Bluetooth Low Energy: A Literature Review</h3>
<ul>
<li><strong>Authors: </strong>Zhe Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16846">https://arxiv.org/abs/2404.16846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16846">https://arxiv.org/pdf/2404.16846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16846]] Securing Bluetooth Low Energy: A Literature Review(https://arxiv.org/abs/2404.16846)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Bluetooth Low Energy (BLE) technology, operating within the widely used 2.4 GHz ISM band, stands as a cornerstone in modern wireless communication frameworks alongside its classic Bluetooth counterpart. This paper delves into the foundational aspects of BLE, excluding niche components, to explore its core functionalities and pivotal role in diverse connectivity needs. BLE's specialization in catering to low-power devices ensures optimal energy utilization, making it indispensable in IoT applications where energy efficiency is paramount. Its versatility finds applications across consumer electronics, industrial automation, and healthcare, ensuring reliability and efficiency in safety-critical systems and enhancing user convenience through remote control capabilities. However, the wireless nature of BLE interfaces exposes them to cybersecurity threats, necessitating robust security measures for mitigating risks such as sniffing, DoS attacks, and message injection. Continuous research and development efforts are essential to stay ahead of emerging threats and safeguard BLE-enabled systems and data.</li>
</ul>

<h3>Title: State-of-the-Art Approaches to Enhancing Privacy Preservation of Machine  Learning Datasets: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Chaoyu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16847">https://arxiv.org/abs/2404.16847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16847">https://arxiv.org/pdf/2404.16847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16847]] State-of-the-Art Approaches to Enhancing Privacy Preservation of Machine  Learning Datasets: A Survey(https://arxiv.org/abs/2404.16847)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect</a></li>
<li><strong>Abstract: </strong>This paper examines the evolving landscape of machine learning (ML) and its profound impact across various sectors, with a special focus on the emerging field of Privacy-preserving Machine Learning (PPML). As ML applications become increasingly integral to industries like telecommunications, financial technology, and surveillance, they raise significant privacy concerns, necessitating the development of PPML strategies. The paper highlights the unique challenges in safeguarding privacy within ML frameworks, which stem from the diverse capabilities of potential adversaries, including their ability to infer sensitive information from model outputs or training data. We delve into the spectrum of threat models that characterize adversarial intentions, ranging from membership and attribute inference to data reconstruction. The paper emphasizes the importance of maintaining the confidentiality and integrity of training data, outlining current research efforts that focus on refining training data to minimize privacy-sensitive information and enhancing data processing techniques to uphold privacy. Through a comprehensive analysis of privacy leakage risks and countermeasures in both centralized and collaborative learning settings, this paper aims to provide a thorough understanding of effective strategies for protecting ML training data against privacy intrusions. It explores the balance between data privacy and model utility, shedding light on privacy-preserving techniques that leverage cryptographic methods, Differential Privacy, and Trusted Execution Environments. The discussion extends to the application of these techniques in sensitive domains, underscoring the critical role of PPML in ensuring the privacy and security of ML systems.</li>
</ul>

<h3>Title: Cyber Security issues and Blockchain-Deep Learning based solutions for  UAV and Internet of Drones (FANETs)</h3>
<ul>
<li><strong>Authors: </strong>Partha Protim Datta</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16848">https://arxiv.org/abs/2404.16848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16848">https://arxiv.org/pdf/2404.16848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16848]] Cyber Security issues and Blockchain-Deep Learning based solutions for  UAV and Internet of Drones (FANETs)(https://arxiv.org/abs/2404.16848)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Safety-critical systems such as automated embedded or industrial systems have a strong dependency on the trustworthiness of data collection. As sensors are the critical component for those systems, it is imperative to address the attack resilience of sensors</li>
</ul>

<h3>Title: Smart Grids Secured By Dynamic Watermarking: How Secure?</h3>
<ul>
<li><strong>Authors: </strong>Kate Davis, Laszlo B. Kish, Chanan Singh</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16849">https://arxiv.org/abs/2404.16849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16849">https://arxiv.org/pdf/2404.16849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16849]] Smart Grids Secured By Dynamic Watermarking: How Secure?(https://arxiv.org/abs/2404.16849)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, watermark</a></li>
<li><strong>Abstract: </strong>Unconditional security for smart grids is defined. Cryptanalyses of the watermarked security of smart grids indicate that watermarking cannot guarantee unconditional security unless the communication within the grid system is unconditionally secure. The successful attack against the dynamically watermarked smart grid remains valid even with the presence of internal noise from the grid. An open question arises: if unconditionally authenticated secure communications within the grid, together with tamper resistance of the critical elements, are satisfactory conditions to provide unconditional security for the grid operation.</li>
</ul>

<h3>Title: Membership Information Leakage in Federated Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Kongyang Chen, Wenfeng Wang, Zixin Wang, Wangjun Zhang, Zhipeng Li, Yao Huang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16850">https://arxiv.org/abs/2404.16850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16850">https://arxiv.org/pdf/2404.16850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16850]] Membership Information Leakage in Federated Contrastive Learning(https://arxiv.org/abs/2404.16850)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, membership infer, federate</a></li>
<li><strong>Abstract: </strong>Federated Contrastive Learning (FCL) represents a burgeoning approach for learning from decentralized unlabeled data while upholding data privacy. In FCL, participant clients collaborate in learning a global encoder using unlabeled data, which can serve as a versatile feature extractor for diverse downstream tasks. Nonetheless, FCL is susceptible to privacy risks, such as membership information leakage, stemming from its distributed nature, an aspect often overlooked in current solutions. This study delves into the feasibility of executing a membership inference attack on FCL and proposes a robust attack methodology. The attacker's objective is to determine if the data signifies training member data by accessing the model's inference output. Specifically, we concentrate on attackers situated within a client framework, lacking the capability to manipulate server-side aggregation methods or discern the training status of other clients. We introduce two membership inference attacks tailored for FCL: the \textit{passive membership inference attack} and the \textit{active membership inference attack}, contingent on the attacker's involvement in local model training. Experimental findings across diverse datasets validate the effectiveness of our attacks and underscore the inherent privacy risks associated with the federated contrastive learning paradigm.</li>
</ul>

<h3>Title: EdgeLeakage: Membership Information Leakage in Distributed Edge  Intelligence Systems</h3>
<ul>
<li><strong>Authors: </strong>Kongyang Chen, Yi Lin, Hui Luo, Bing Mi, Yatie Xiao, Chao Ma, Jorge Sá Silva</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16851">https://arxiv.org/abs/2404.16851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16851">https://arxiv.org/pdf/2404.16851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16851]] EdgeLeakage: Membership Information Leakage in Distributed Edge  Intelligence Systems(https://arxiv.org/abs/2404.16851)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, membership infer</a></li>
<li><strong>Abstract: </strong>In contemporary edge computing systems, decentralized edge nodes aggregate unprocessed data and facilitate data analytics to uphold low transmission latency and real-time data processing capabilities. Recently, these edge nodes have evolved to facilitate the implementation of distributed machine learning models, utilizing their computational resources to enable intelligent decision-making, thereby giving rise to an emerging domain referred to as edge intelligence. However, within the realm of edge intelligence, susceptibility to numerous security and privacy threats against machine learning models becomes evident. This paper addresses the issue of membership inference leakage in distributed edge intelligence systems. Specifically, our focus is on an autonomous scenario wherein edge nodes collaboratively generate a global model. The utilization of membership inference attacks serves to elucidate the potential data leakage in this particular context. Furthermore, we delve into the examination of several defense mechanisms aimed at mitigating the aforementioned data leakage problem. Experimental results affirm that our approach is effective in detecting data leakage within edge intelligence systems, and the implementation of our defense methods proves instrumental in alleviating this security threat. Consequently, our findings contribute to safeguarding data privacy in the context of edge intelligence systems.</li>
</ul>

<h3>Title: Expectation Entropy as a Password Strength Metric</h3>
<ul>
<li><strong>Authors: </strong>Khan Reaz, Gerhard Wunder</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16853">https://arxiv.org/abs/2404.16853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16853">https://arxiv.org/pdf/2404.16853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16853]] Expectation Entropy as a Password Strength Metric(https://arxiv.org/abs/2404.16853)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The classical combinatorics-based password strength formula provides a result in tens of bits, whereas the NIST Entropy Estimation Suite give a result between 0 and 1 for Min-entropy. In this work, we present a newly developed metric -- Expectation entropy that can be applied to estimate the strength of any random or random-like password. Expectation entropy provides the strength of a password on the same scale as an entropy estimation tool. Having an 'Expectation entropy' of a certain value, for example, 0.4 means that an attacker has to exhaustively search at least 40\% of the total number of guesses to find the password.</li>
</ul>

<h3>Title: Dynamic Vulnerability Criticality Calculator for Industrial Control  Systems</h3>
<ul>
<li><strong>Authors: </strong>Pavlos Cheimonidis, Kontantinos Rantos</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16854">https://arxiv.org/abs/2404.16854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16854">https://arxiv.org/pdf/2404.16854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16854]] Dynamic Vulnerability Criticality Calculator for Industrial Control  Systems(https://arxiv.org/abs/2404.16854)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The convergence of information and communication technologies has introduced new and advanced capabilities to Industrial Control Systems. However, concurrently, it has heightened their vulnerability to cyber attacks. Consequently, the imperative for new security methods has emerged as a critical need for these organizations to effectively identify and mitigate potential threats. This paper introduces an innovative approach by proposing a dynamic vulnerability criticality calculator. Our methodology encompasses the analysis of environmental topology and the effectiveness of deployed security mechanisms, coupled with the utilization of the Common Vulnerability Scoring System framework to adjust detected vulnerabilities based on the specific environment. Moreover, it evaluates the quantity of vulnerabilities and their interdependencies within each asset. Additionally, our approach integrates these factors into a comprehensive Fuzzy Cognitive Map model, incorporating attack paths to holistically assess the overall vulnerability score. To validate the efficacy of our proposed method, we present a relative case study alongside several modified scenarios, demonstrating its effectiveness in practical applications.</li>
</ul>

<h3>Title: HookChain: A new perspective for Bypassing EDR Solutions</h3>
<ul>
<li><strong>Authors: </strong>Helvio Carvalho Junior</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI, cs.OS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16856">https://arxiv.org/abs/2404.16856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16856">https://arxiv.org/pdf/2404.16856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16856]] HookChain: A new perspective for Bypassing EDR Solutions(https://arxiv.org/abs/2404.16856)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>In the current digital security ecosystem, where threats evolve rapidly and with complexity, companies developing Endpoint Detection and Response (EDR) solutions are in constant search for innovations that not only keep up but also anticipate emerging attack vectors. In this context, this article introduces the HookChain, a look from another perspective at widely known techniques, which when combined, provide an additional layer of sophisticated evasion against traditional EDR systems. Through a precise combination of IAT Hooking techniques, dynamic SSN resolution, and indirect system calls, HookChain redirects the execution flow of Windows subsystems in a way that remains invisible to the vigilant eyes of EDRs that only act on Ntdll.dll, without requiring changes to the source code of the applications and malwares involved. This work not only challenges current conventions in cybersecurity but also sheds light on a promising path for future protection strategies, leveraging the understanding that continuous evolution is key to the effectiveness of digital security. By developing and exploring the HookChain technique, this study significantly contributes to the body of knowledge in endpoint security, stimulating the development of more robust and adaptive solutions that can effectively address the ever-changing dynamics of digital threats. This work aspires to inspire deep reflection and advancement in the research and development of security technologies that are always several steps ahead of adversaries.</li>
</ul>

<h3>Title: Implementation of Entropically Secure Encryption: Securing Personal  Health Data</h3>
<ul>
<li><strong>Authors: </strong>Mehmet Hüseyin Temel, Boris Skoric, Idelfonso Tafur Monroy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16857">https://arxiv.org/abs/2404.16857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16857">https://arxiv.org/pdf/2404.16857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16857]] Implementation of Entropically Secure Encryption: Securing Personal  Health Data(https://arxiv.org/abs/2404.16857)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect</a></li>
<li><strong>Abstract: </strong>Entropically Secure Encryption (ESE) offers unconditional security with shorter keys compared to the One-Time Pad. In this paper, we present the first implementation of ESE for bulk encryption. The main computational bottleneck for bulk ESE is a multiplication in a very large finite field. This involves multiplication of polynomials followed by modular reduction. We have implemented polynomial multiplication based on the gf2x library, with some modifications that avoid inputs of vastly different length, thus improving speed. Additionally, we have implemented a recently proposed efficient reduction algorithm that works for any polynomial degree. We investigate two use cases: X-ray images of patients and human genome data. We conduct entropy estimation using compression methods whose results determine the key lengths required for ESE. We report running times for all steps of the encryption. We discuss the potential of ESE to be used in conjunction with Quantum Key Distribution (QKD), in order to achieve full information-theoretic security of QKD-protected links for these use cases.</li>
</ul>

<h3>Title: Rumour Evaluation with Very Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dahlia Shehata, Robin Cohen, Charles Clarke</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16859">https://arxiv.org/abs/2404.16859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16859">https://arxiv.org/pdf/2404.16859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16859]] Rumour Evaluation with Very Large Language Models(https://arxiv.org/abs/2404.16859)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Conversational prompt-engineering-based large language models (LLMs) have enabled targeted control over the output creation, enhancing versatility, adaptability and adhoc retrieval. From another perspective, digital misinformation has reached alarming levels. The anonymity, availability and reach of social media offer fertile ground for rumours to propagate. This work proposes to leverage the advancement of prompting-dependent LLMs to combat misinformation by extending the research efforts of the RumourEval task on its Twitter dataset. To the end, we employ two prompting-based LLM variants (GPT-3.5-turbo and GPT-4) to extend the two RumourEval subtasks: (1) veracity prediction, and (2) stance classification. For veracity prediction, three classifications schemes are experimented per GPT variant. Each scheme is tested in zero-, one- and few-shot settings. Our best results outperform the precedent ones by a substantial margin. For stance classification, prompting-based-approaches show comparable performance to prior results, with no improvement over finetuning methods. Rumour stance subtask is also extended beyond the original setting to allow multiclass classification. All of the generated predictions for both subtasks are equipped with confidence scores determining their trustworthiness degree according to the LLM, and post-hoc justifications for explainability and interpretability purposes. Our primary aim is AI for social good.</li>
</ul>

<h3>Title: To what extent are multiple pendulum systems viable in pseudo-random  number generation?</h3>
<ul>
<li><strong>Authors: </strong>Matthew Sigit</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16860">https://arxiv.org/abs/2404.16860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16860">https://arxiv.org/pdf/2404.16860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16860]] To what extent are multiple pendulum systems viable in pseudo-random  number generation?(https://arxiv.org/abs/2404.16860)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>This paper explores the development and viability of an alternative pseudorandom number generator (PRNG) that leverages the chaotic dynamics of multiple pendulum systems. Some traditional PRNGs, notably the one implemented in the Java.Random class, suffer from predictability which gives rise to exploitability. This study identifies these vulnerabilities and proposes a novel PRNG designed using ordinary differential equations, physics modeling, and chaos theory. The performance of the new PRNG is then tested against Java's standard PRNGs using the NIST Statistical Test Suite, which evaluates randomness through comprehensive statistical testing. Results indicate that the multiple pendulum-based PRNG not only offers enhanced security by generating less predictable number sequences but also demonstrates potential for efficiency improvements in applications requiring high levels of entropy. The findings suggest that integrating chaotic physics-based systems into PRNGs, such as the double-pendulum system tested in this study, could strengthen cryptographic practices and security protocols for applications that do not require the level of security created by true random number generators, which is useful in fields such as gaming.</li>
</ul>

<h3>Title: Improving Privacy-Preserving Techniques for Smart Grid using  Lattice-based Cryptography</h3>
<ul>
<li><strong>Authors: </strong>Saleh Darzi, Bahareh Akhbari, Hassan Khodaiemehr</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16865">https://arxiv.org/abs/2404.16865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16865">https://arxiv.org/pdf/2404.16865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16865]] Improving Privacy-Preserving Techniques for Smart Grid using  Lattice-based Cryptography(https://arxiv.org/abs/2404.16865)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack</a></li>
<li><strong>Abstract: </strong>Advancements in communication and information tech birthed the Smart Grid, optimizing energy and data transmission. Yet, user privacy is at risk due to frequent data collection. Existing privacy schemes face vulnerability with quantum machines. To tackle this, the LPM2DA scheme is introduced, utilizing lattice-based encryption and signatures for secure data aggregation. It ensures privacy, integrity, and authentication, enabling statistical analysis while preserving user privacy. Traditional aggregation schemes suffer from weak network models and centralization issues. Enter SPDBlock, a blockchain-based solution ensuring privacy, integrity, and resistance to attacks. It detects and prosecutes malicious entities while efficiently handling multi-dimensional data transmission. Through distributed decryption and secret sharing, only valid data can be decrypted with minimal involvement from smart meters. Performance tests reveal SPDBlock's superiority in communication and computational efficiency over traditional schemes.</li>
</ul>

<h3>Title: LEMDA: A Novel Feature Engineering Method for Intrusion Detection in IoT  Systems</h3>
<ul>
<li><strong>Authors: </strong>Ali Ghubaish, Zebo Yang, Aiman Erbad, Raj Jain</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16870">https://arxiv.org/abs/2404.16870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16870">https://arxiv.org/pdf/2404.16870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16870]] LEMDA: A Novel Feature Engineering Method for Intrusion Detection in IoT  Systems(https://arxiv.org/abs/2404.16870)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, interpretability</a></li>
<li><strong>Abstract: </strong>Intrusion detection systems (IDS) for the Internet of Things (IoT) systems can use AI-based models to ensure secure communications. IoT systems tend to have many connected devices producing massive amounts of data with high dimensionality, which requires complex models. Complex models have notorious problems such as overfitting, low interpretability, and high computational complexity. Adding model complexity penalty (i.e., regularization) can ease overfitting, but it barely helps interpretability and computational efficiency. Feature engineering can solve these issues; hence, it has become critical for IDS in large-scale IoT systems to reduce the size and dimensionality of data, resulting in less complex models with excellent performance, smaller data storage, and fast detection. This paper proposes a new feature engineering method called LEMDA (Light feature Engineering based on the Mean Decrease in Accuracy). LEMDA applies exponential decay and an optional sensitivity factor to select and create the most informative features. The proposed method has been evaluated and compared to other feature engineering methods using three IoT datasets and four AI/ML models. The results show that LEMDA improves the F1 score performance of all the IDS models by an average of 34% and reduces the average training and detection times in most cases.</li>
</ul>

<h3>Title: Mitigating Data Sharing in Public Cloud using Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Pratik Patil, Prerna Tulsiani, Dr. Sunil Mane</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16872">https://arxiv.org/abs/2404.16872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16872">https://arxiv.org/pdf/2404.16872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16872]] Mitigating Data Sharing in Public Cloud using Blockchain(https://arxiv.org/abs/2404.16872)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect</a></li>
<li><strong>Abstract: </strong>Public Cloud Computing has become a fundamental part of modern IT infrastructure as its adoption has transformed the way businesses operate. However, cloud security concerns introduce new risks and challenges related to data protection, sharing, and access control. A synergistic integration of blockchain with the cloud holds immense potential. Blockchain's distributed ledger ensures transparency, immutability, and efficiency as it reduces the reliance on centralized authorities. Motivated by this, our framework proposes a secure data ecosystem in the cloud with the key aspects being Data Rights, Data Sharing, and Data Validation. Also, this approach aims to increase its interoperability and scalability by eliminating the need for data migration. This will ensure that existing public cloud-based systems can easily deploy blockchain enhancing trustworthiness and non-repudiation of cloud data.</li>
</ul>

<h3>Title: AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Anselm Paulus, Arman Zharmagambetov, Chuan Guo, Brandon Amos, Yuandong Tian</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16873">https://arxiv.org/abs/2404.16873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16873">https://arxiv.org/pdf/2404.16873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16873]] AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs(https://arxiv.org/abs/2404.16873)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>While recently Large Language Models (LLMs) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content. Manual red-teaming requires finding adversarial prompts that cause such jailbreaking, e.g. by appending a suffix to a given instruction, which is inefficient and time-consuming. On the other hand, automatic adversarial prompt generation often leads to semantically meaningless attacks that can easily be detected by perplexity-based filters, may require gradient information from the TargetLLM, or do not scale well due to time-consuming discrete optimization processes over the token space. In this paper, we present a novel method that uses another LLM, called the AdvPrompter, to generate human-readable adversarial prompts in seconds, $\sim800\times$ faster than existing optimization-based approaches. We train the AdvPrompter using a novel algorithm that does not require access to the gradients of the TargetLLM. This process alternates between two steps: (1) generating high-quality target adversarial suffixes by optimizing the AdvPrompter predictions, and (2) low-rank fine-tuning of the AdvPrompter with the generated adversarial suffixes. The trained AdvPrompter generates suffixes that veil the input instruction without changing its meaning, such that the TargetLLM is lured to give a harmful response. Experimental results on popular open source TargetLLMs show state-of-the-art results on the AdvBench dataset, that also transfer to closed-source black-box LLM APIs. Further, we demonstrate that by fine-tuning on a synthetic dataset generated by AdvPrompter, LLMs can be made more robust against jailbreaking attacks while maintaining performance, i.e. high MMLU scores.</li>
</ul>

<h3>Title: ThermoPore: Predicting Part Porosity Based on Thermal Images Using Deep  Learning</h3>
<ul>
<li><strong>Authors: </strong>Peter Myung-Won Pak, Francis Ogoke, Andrew Polonsky, Anthony Garland, Dan S. Bolintineanu, Dan R. Moser, Michael J. Heiden, Amir Barati Farimani</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16882">https://arxiv.org/abs/2404.16882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16882">https://arxiv.org/pdf/2404.16882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16882]] ThermoPore: Predicting Part Porosity Based on Thermal Images Using Deep  Learning(https://arxiv.org/abs/2404.16882)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a deep learning approach for quantifying and localizing ex-situ porosity within Laser Powder Bed Fusion fabricated samples utilizing in-situ thermal image monitoring data. Our goal is to build the real time porosity map of parts based on thermal images acquired during the build. The quantification task builds upon the established Convolutional Neural Network model architecture to predict pore count and the localization task leverages the spatial and temporal attention mechanisms of the novel Video Vision Transformer model to indicate areas of expected porosity. Our model for porosity quantification achieved a $R^2$ score of 0.57 and our model for porosity localization produced an average IoU score of 0.32 and a maximum of 1.0. This work is setting the foundations of part porosity "Digital Twins" based on additive manufacturing monitoring data and can be applied downstream to reduce time-intensive post-inspection and testing activities during part qualification and certification. In addition, we seek to accelerate the acquisition of crucial insights normally only available through ex-situ part evaluation by means of machine learning analysis of in-situ process monitoring data.</li>
</ul>

<h3>Title: Aligning Knowledge Graphs Provided by Humans and Generated from Neural  Networks in Specific Tasks</h3>
<ul>
<li><strong>Authors: </strong>Tangrui Li, Jun Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16884">https://arxiv.org/abs/2404.16884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16884">https://arxiv.org/pdf/2404.16884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16884]] Aligning Knowledge Graphs Provided by Humans and Generated from Neural  Networks in Specific Tasks(https://arxiv.org/abs/2404.16884)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This paper develops an innovative method that enables neural networks to generate and utilize knowledge graphs, which describe their concept-level knowledge and optimize network parameters through alignment with human-provided knowledge. This research addresses a gap where traditionally, network-generated knowledge has been limited to applications in downstream symbolic analysis or enhancing network transparency. By integrating a novel autoencoder design with the Vector Symbolic Architecture (VSA), we have introduced auxiliary tasks that support end-to-end training. Our approach eschews traditional dependencies on ontologies or word embedding models, mining concepts from neural networks and directly aligning them with human knowledge. Experiments show that our method consistently captures network-generated concepts that align closely with human knowledge and can even uncover new, useful concepts not previously identified by humans. This plug-and-play strategy not only enhances the interpretability of neural networks but also facilitates the integration of symbolic logical reasoning within these systems.</li>
</ul>

<h3>Title: Adapting an Artificial Intelligence Sexually Transmitted Diseases  Symptom Checker Tool for Mpox Detection: The HeHealth Experience</h3>
<ul>
<li><strong>Authors: </strong>Rayner Kay Jin Tan, Dilruk Perera, Salomi Arasaratnam, Yudara Kularathne</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16885">https://arxiv.org/abs/2404.16885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16885">https://arxiv.org/pdf/2404.16885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16885]] Adapting an Artificial Intelligence Sexually Transmitted Diseases  Symptom Checker Tool for Mpox Detection: The HeHealth Experience(https://arxiv.org/abs/2404.16885)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence applications have shown promise in the management of pandemics and have been widely used to assist the identification, classification, and diagnosis of medical images. In response to the global outbreak of Monkeypox (Mpox), the HeHealth.ai team leveraged an existing tool to screen for sexually transmitted diseases to develop a digital screening test for symptomatic Mpox through AI approaches. Prior to the global outbreak of Mpox, the team developed a smartphone app, where app users can use their own smartphone cameras to take pictures of their own penises to screen for symptomatic STD. The AI model was initially developed using 5000 cases and use a modified convolutional neural network to output prediction scores across visually diagnosable penis pathologies including Syphilis, Herpes Simplex Virus, and Human Papilloma Virus. From June 2022 to October 2022, a total of about 22,000 users downloaded the HeHealth app, and about 21,000 images have been analyzed using HeHealth AI technology. We then engaged in formative research, stakeholder engagement, rapid consolidation images, a validation study, and implementation of the tool from July 2022. From July 2022 to October 2022, a total of 1000 Mpox related images had been used to train the Mpox symptom checker tool. Our digital symptom checker tool showed accuracy of 87% to rule in Mpox and 90% to rule out symptomatic Mpox. Several hurdles identified included issues of data privacy and security for app users, initial lack of data to train the AI tool, and the potential generalizability of input data. We offer several suggestions to help others get started on similar projects in emergency situations, including engaging a wide range of stakeholders, having a multidisciplinary team, prioritizing pragmatism, as well as the concept that big data in fact is made up of small data.</li>
</ul>

<h3>Title: Review of Data-centric Time Series Analysis from Sample, Feature, and  Period</h3>
<ul>
<li><strong>Authors: </strong>Chenxi Sun, Hongyan Li, Yaliang Li, Shenda Hong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16886">https://arxiv.org/abs/2404.16886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16886">https://arxiv.org/pdf/2404.16886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16886]] Review of Data-centric Time Series Analysis from Sample, Feature, and  Period(https://arxiv.org/abs/2404.16886)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Data is essential to performing time series analysis utilizing machine learning approaches, whether for classic models or today's large language models. A good time-series dataset is advantageous for the model's accuracy, robustness, and convergence, as well as task outcomes and costs. The emergence of data-centric AI represents a shift in the landscape from model refinement to prioritizing data quality. Even though time-series data processing methods frequently come up in a wide range of research fields, it hasn't been well investigated as a specific topic. To fill the gap, in this paper, we systematically review different data-centric methods in time series analysis, covering a wide range of research topics. Based on the time-series data characteristics at sample, feature, and period, we propose a taxonomy for the reviewed data selection methods. In addition to discussing and summarizing their characteristics, benefits, and drawbacks targeting time-series data, we also introduce the challenges and opportunities by proposing recommendations, open problems, and possible research topics.</li>
</ul>

<h3>Title: Attacks on Third-Party APIs of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wanru Zhao, Vidit Khazanchi, Haodi Xing, Xuanli He, Qiongkai Xu, Nicholas Donald Lane</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16891">https://arxiv.org/abs/2404.16891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16891">https://arxiv.org/pdf/2404.16891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16891]] Attacks on Third-Party APIs of Large Language Models(https://arxiv.org/abs/2404.16891)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) services have recently begun offering a plugin ecosystem to interact with third-party API services. This innovation enhances the capabilities of LLMs, but it also introduces risks, as these plugins developed by various third parties cannot be easily trusted. This paper proposes a new attacking framework to examine security and safety vulnerabilities within LLM platforms that incorporate third-party services. Applying our framework specifically to widely used LLMs, we identify real-world malicious attacks across various domains on third-party APIs that can imperceptibly modify LLM outputs. The paper discusses the unique challenges posed by third-party API integration and offers strategic possibilities to improve the security and safety of LLM ecosystems moving forward. Our code is released at https://github.com/vk0812/Third-Party-Attacks-on-LLMs.</li>
</ul>

<h3>Title: Automatic AI controller that can drive with confidence: steering vehicle  with uncertainty knowledge</h3>
<ul>
<li><strong>Authors: </strong>Neha Kumari, Sumit Kumar. Sneha Priya, Ayush Kumar, Akash Fogla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16893">https://arxiv.org/abs/2404.16893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16893">https://arxiv.org/pdf/2404.16893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16893]] Automatic AI controller that can drive with confidence: steering vehicle  with uncertainty knowledge(https://arxiv.org/abs/2404.16893)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>In safety-critical systems that interface with the real world, the role of uncertainty in decision-making is pivotal, particularly in the context of machine learning models. For the secure functioning of Cyber-Physical Systems (CPS), it is imperative to manage such uncertainty adeptly. In this research, we focus on the development of a vehicle's lateral control system using a machine learning framework. Specifically, we employ a Bayesian Neural Network (BNN), a probabilistic learning model, to address uncertainty quantification. This capability allows us to gauge the level of confidence or uncertainty in the model's predictions. The BNN based controller is trained using simulated data gathered from the vehicle traversing a single track and subsequently tested on various other tracks. We want to share two significant results: firstly, the trained model demonstrates the ability to adapt and effectively control the vehicle on multiple similar tracks. Secondly, the quantification of prediction confidence integrated into the controller serves as an early-warning system, signaling when the algorithm lacks confidence in its predictions and is therefore susceptible to failure. By establishing a confidence threshold, we can trigger manual intervention, ensuring that control is relinquished from the algorithm when it operates outside of safe parameters.</li>
</ul>

<h3>Title: On TinyML and Cybersecurity: Electric Vehicle Charging Infrastructure  Use Case</h3>
<ul>
<li><strong>Authors: </strong>Fatemeh Dehrouyeh, Li Yang, Firouz Badrkhani Ajaei, Abdallah Shami</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16894">https://arxiv.org/abs/2404.16894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16894">https://arxiv.org/pdf/2404.16894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16894]] On TinyML and Cybersecurity: Electric Vehicle Charging Infrastructure  Use Case(https://arxiv.org/abs/2404.16894)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>As technology advances, the use of Machine Learning (ML) in cybersecurity is becoming increasingly crucial to tackle the growing complexity of cyber threats. While traditional ML models can enhance cybersecurity, their high energy and resource demands limit their applications, leading to the emergence of Tiny Machine Learning (TinyML) as a more suitable solution for resource-constrained environments. TinyML is widely applied in areas such as smart homes, healthcare, and industrial automation. TinyML focuses on optimizing ML algorithms for small, low-power devices, enabling intelligent data processing directly on edge devices. This paper provides a comprehensive review of common challenges of TinyML techniques, such as power consumption, limited memory, and computational constraints; it also explores potential solutions to these challenges, such as energy harvesting, computational optimization techniques, and transfer learning for privacy preservation. On the other hand, this paper discusses TinyML's applications in advancing cybersecurity for Electric Vehicle Charging Infrastructures (EVCIs) as a representative use case. It presents an experimental case study that enhances cybersecurity in EVCI using TinyML, evaluated against traditional ML in terms of reduced delay and memory usage, with a slight trade-off in accuracy. Additionally, the study includes a practical setup using the ESP32 microcontroller in the PlatformIO environment, which provides a hands-on assessment of TinyML's application in cybersecurity for EVCI.</li>
</ul>

<h3>Title: How to Parameterize Asymmetric Quantization Ranges for  Quantization-Aware Training</h3>
<ul>
<li><strong>Authors: </strong>Jaeseong You, Minseop Park, Kyunggeun Lee, Seokjun An, Chirag Patel, Markus Nage</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16898">https://arxiv.org/abs/2404.16898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16898">https://arxiv.org/pdf/2404.16898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16898]] How to Parameterize Asymmetric Quantization Ranges for  Quantization-Aware Training(https://arxiv.org/abs/2404.16898)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates three different parameterizations of asymmetric uniform quantization for quantization-aware training: (1) scale and offset, (2) minimum and maximum, and (3) beta and gamma. We perform a comprehensive comparative analysis of these parameterizations' influence on quantization-aware training, using both controlled experiments and real-world large language models. Our particular focus is on their changing behavior in response to critical training hyperparameters, bit width and learning rate. Based on our investigation, we propose best practices to stabilize and accelerate quantization-aware training with learnable asymmetric quantization ranges.</li>
</ul>

<h3>Title: mlr3summary: Concise and interpretable summaries for machine learning  models</h3>
<ul>
<li><strong>Authors: </strong>Susanne Dandl, Marc Becker, Bernd Bischl, Giuseppe Casalicchio, Ludwig Bothmann</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16899">https://arxiv.org/abs/2404.16899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16899">https://arxiv.org/pdf/2404.16899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16899]] mlr3summary: Concise and interpretable summaries for machine learning  models(https://arxiv.org/abs/2404.16899)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This work introduces a novel R package for concise, informative summaries of machine learning models. We take inspiration from the summary function for (generalized) linear models in R, but extend it in several directions: First, our summary function is model-agnostic and provides a unified summary output also for non-parametric machine learning models; Second, the summary output is more extensive and customizable -- it comprises information on the dataset, model performance, model complexity, model's estimated feature importances, feature effects, and fairness metrics; Third, models are evaluated based on resampling strategies for unbiased estimates of model performances, feature importances, etc. Overall, the clear, structured output should help to enhance and expedite the model selection process, making it a helpful tool for practitioners and researchers alike.</li>
</ul>

<h3>Title: Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage  framework for Emotion-Cause Pair Extraction in Conversations</h3>
<ul>
<li><strong>Authors: </strong>Shen Zhang, Haojie Zhang, Jing Zhang, Xudong Zhang, Yimeng Zhuang, Jinting Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16905">https://arxiv.org/abs/2404.16905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16905">https://arxiv.org/pdf/2404.16905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16905]] Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage  framework for Emotion-Cause Pair Extraction in Conversations(https://arxiv.org/abs/2404.16905)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In human-computer interaction, it is crucial for agents to respond to human by understanding their emotions. Unraveling the causes of emotions is more challenging. A new task named Multimodal Emotion-Cause Pair Extraction in Conversations is responsible for recognizing emotion and identifying causal expressions. In this study, we propose a multi-stage framework to generate emotion and extract the emotion causal pairs given the target emotion. In the first stage, Llama-2-based InstructERC is utilized to extract the emotion category of each utterance in a conversation. After emotion recognition, a two-stream attention model is employed to extract the emotion causal pairs given the target emotion for subtask 2 while MuTEC is employed to extract causal span for subtask 1. Our approach achieved first place for both of the two subtasks in the competition.</li>
</ul>

<h3>Title: DE-CGAN: Boosting rTMS Treatment Prediction with Diversity Enhancing  Conditional Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Matthew Squires, Xiaohui Tao, Soman Elangovan, Raj Gururajan, Haoran Xie, Xujuan Zhou, Yuefeng Li, U Rajendra Acharya</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16913">https://arxiv.org/abs/2404.16913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16913">https://arxiv.org/pdf/2404.16913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16913]] DE-CGAN: Boosting rTMS Treatment Prediction with Diversity Enhancing  Conditional Generative Adversarial Networks(https://arxiv.org/abs/2404.16913)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Repetitive Transcranial Magnetic Stimulation (rTMS) is a well-supported, evidence-based treatment for depression. However, patterns of response to this treatment are inconsistent. Emerging evidence suggests that artificial intelligence can predict rTMS treatment outcomes for most patients using fMRI connectivity features. While these models can reliably predict treatment outcomes for many patients for some underrepresented fMRI connectivity measures DNN models are unable to reliably predict treatment outcomes. As such we propose a novel method, Diversity Enhancing Conditional General Adversarial Network (DE-CGAN) for oversampling these underrepresented examples. DE-CGAN creates synthetic examples in difficult-to-classify regions by first identifying these data points and then creating conditioned synthetic examples to enhance data diversity. Through empirical experiments we show that a classification model trained using a diversity enhanced training set outperforms traditional data augmentation techniques and existing benchmark results. This work shows that increasing the diversity of a training dataset can improve classification model performance. Furthermore, this work provides evidence for the utility of synthetic patients providing larger more robust datasets for both AI researchers and psychiatrists to explore variable relationships.</li>
</ul>

<h3>Title: Prediction Is All MoE Needs: Expert Load Distribution Goes from  Fluctuating to Stabilizing</h3>
<ul>
<li><strong>Authors: </strong>Peizhuang Cong, Aomufei Yuan, Shimao Chen, Yuxuan Tian, Bowen Ye, Tong Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16914">https://arxiv.org/abs/2404.16914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16914">https://arxiv.org/pdf/2404.16914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16914]] Prediction Is All MoE Needs: Expert Load Distribution Goes from  Fluctuating to Stabilizing(https://arxiv.org/abs/2404.16914)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>MoE facilitates the development of large models by making the computational complexity of the model no longer scale linearly with increasing parameters. The learning sparse gating network selects a set of experts for each token to be processed; however, this may lead to differences in the number of tokens processed by each expert over several successive iterations, i.e., the expert load fluctuations, which reduces computational parallelization and resource utilization. To this end, we traced and analyzed loads of each expert in the training iterations for several large language models in this work, and defined the transient state with "obvious load fluctuation" and the stable state with "temporal locality". Moreover, given the characteristics of these two states and the computational overhead, we deployed three classical prediction algorithms that achieve accurate expert load prediction results. For the GPT3 350M model, the average error rates for predicting the expert load proportion over the next 1,000 and 2,000 steps are approximately 1.3% and 1.8%, respectively. This work can provide valuable guidance for expert placement or resource allocation for MoE model training. Based on this work, we will propose an expert placement scheme for transient and stable states in our coming work.</li>
</ul>

<h3>Title: Grad Queue : A probabilistic framework to reinforce sparse gradients</h3>
<ul>
<li><strong>Authors: </strong>Irfan Mohammad Al Hasib</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16917">https://arxiv.org/abs/2404.16917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16917">https://arxiv.org/pdf/2404.16917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16917]] Grad Queue : A probabilistic framework to reinforce sparse gradients(https://arxiv.org/abs/2404.16917)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Informative gradients are often lost in large batch updates. We propose a robust mechanism to reinforce the sparse components within a random batch of data points. A finite queue of online gradients is used to determine their expected instantaneous statistics. We propose a function to measure the scarcity of incoming gradients using these statistics and establish the theoretical ground of this mechanism. To minimize conflicting components within large mini-batches, samples are grouped with aligned objectives by clustering based on inherent feature space. Sparsity is measured for each centroid and weighted accordingly. A strong intuitive criterion to squeeze out redundant information from each cluster is the backbone of the system. It makes rare information indifferent to aggressive momentum also exhibits superior performance with larger mini-batch horizon. The effective length of the queue kept variable to follow the local loss pattern. The contribution of our method is to restore intra-mini-batch diversity at the same time widening the optimal batch boundary. Both of these collectively drive it deeper towards the minima. Our method has shown superior performance for CIFAR10, MNIST, and Reuters News category dataset compared to mini-batch gradient descent.</li>
</ul>

<h3>Title: A Short Survey of Human Mobility Prediction in Epidemic Modeling from  Transformers to LLMs</h3>
<ul>
<li><strong>Authors: </strong>Christian N. Mayemba, D'Jeff K. Nkashama, Jean Marie Tshimula, Maximilien V. Dialufuma, Jean Tshibangu Muabila, Mbuyi Mukendi Didier, Hugues Kanda, René Manassé Galekwa, Heber Dibwe Fita, Serge Mundele, Kalonji Kalala, Aristarque Ilunga, Lambert Mukendi Ntobo, Dominique Muteba, Aaron Aruna Abedi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16921">https://arxiv.org/abs/2404.16921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16921">https://arxiv.org/pdf/2404.16921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16921]] A Short Survey of Human Mobility Prediction in Epidemic Modeling from  Transformers to LLMs(https://arxiv.org/abs/2404.16921)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This paper provides a comprehensive survey of recent advancements in leveraging machine learning techniques, particularly Transformer models, for predicting human mobility patterns during epidemics. Understanding how people move during epidemics is essential for modeling the spread of diseases and devising effective response strategies. Forecasting population movement is crucial for informing epidemiological models and facilitating effective response planning in public health emergencies. Predicting mobility patterns can enable authorities to better anticipate the geographical and temporal spread of diseases, allocate resources more efficiently, and implement targeted interventions. We review a range of approaches utilizing both pretrained language models like BERT and Large Language Models (LLMs) tailored specifically for mobility prediction tasks. These models have demonstrated significant potential in capturing complex spatio-temporal dependencies and contextual patterns in textual data.</li>
</ul>

<h3>Title: Taming False Positives in Out-of-Distribution Detection with Human  Feedback</h3>
<ul>
<li><strong>Authors: </strong>Harit Vishwakarma, Heguang Lin, Ramya Korlakai Vinayak</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16954">https://arxiv.org/abs/2404.16954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16954">https://arxiv.org/pdf/2404.16954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16954]] Taming False Positives in Out-of-Distribution Detection with Human  Feedback(https://arxiv.org/abs/2404.16954)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robustness to out-of-distribution (OOD) samples is crucial for safely deploying machine learning models in the open world. Recent works have focused on designing scoring functions to quantify OOD uncertainty. Setting appropriate thresholds for these scoring functions for OOD detection is challenging as OOD samples are often unavailable up front. Typically, thresholds are set to achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can lead to very high false positive rates (FPR), ranging from 60 to 96\%, as observed in the Open-OOD benchmark. In safety-critical real-life applications, e.g., medical diagnosis, controlling the FPR is essential when dealing with various OOD samples dynamically. To address these challenges, we propose a mathematically grounded OOD detection framework that leverages expert feedback to \emph{safely} update the threshold on the fly. We provide theoretical results showing that it is guaranteed to meet the FPR constraint at all times while minimizing the use of human feedback. Another key feature of our framework is that it can work with any scoring function for OOD uncertainty quantification. Empirical evaluation of our system on synthetic and benchmark OOD datasets shows that our method can maintain FPR at most $5\%$ while maximizing TPR.</li>
</ul>

<h3>Title: Examining the robustness of LLM evaluation to the distributional  assumptions of benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Melissa Ailem, Katerina Marazopoulou, Charlotte Siska, James Bono</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16966">https://arxiv.org/abs/2404.16966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16966">https://arxiv.org/pdf/2404.16966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16966]] Examining the robustness of LLM evaluation to the distributional  assumptions of benchmarks(https://arxiv.org/abs/2404.16966)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Benchmarks have emerged as the central approach for evaluating Large Language Models (LLMs). The research community often relies on a model's average performance across the test prompts of a benchmark to evaluate the model's performance. This is consistent with the assumption that the test prompts within a benchmark represent a random sample from a real-world distribution of interest. We note that this is generally not the case; instead, we hold that the distribution of interest varies according to the specific use case. We find that (1) the correlation in model performance across test prompts is non-random, (2) accounting for correlations across test prompts can change model rankings on major benchmarks, (3) explanatory factors for these correlations include semantic similarity and common LLM failure points.</li>
</ul>

<h3>Title: IDIL: Imitation Learning of Intent-Driven Expert Behavior</h3>
<ul>
<li><strong>Authors: </strong>Sangwon Seo, Vaibhav Unhelkar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.16989">https://arxiv.org/abs/2404.16989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.16989">https://arxiv.org/pdf/2404.16989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.16989]] IDIL: Imitation Learning of Intent-Driven Expert Behavior(https://arxiv.org/abs/2404.16989)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>When faced with accomplishing a task, human experts exhibit intentional behavior. Their unique intents shape their plans and decisions, resulting in experts demonstrating diverse behaviors to accomplish the same task. Due to the uncertainties encountered in the real world and their bounded rationality, experts sometimes adjust their intents, which in turn influences their behaviors during task execution. This paper introduces IDIL, a novel imitation learning algorithm to mimic these diverse intent-driven behaviors of experts. Iteratively, our approach estimates expert intent from heterogeneous demonstrations and then uses it to learn an intent-aware model of their behavior. Unlike contemporary approaches, IDIL is capable of addressing sequential tasks with high-dimensional state representations, while sidestepping the complexities and drawbacks associated with adversarial training (a mainstay of related techniques). Our empirical results suggest that the models generated by IDIL either match or surpass those produced by recent imitation learning benchmarks in metrics of task performance. Moreover, as it creates a generative model, IDIL demonstrates superior performance in intent inference metrics, crucial for human-agent interactions, and aptly captures a broad spectrum of expert behaviors.</li>
</ul>

<h3>Title: Evaluating Class Membership Relations in Knowledge Graphs using Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Bradley P. Allen, Paul T. Groth</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17000">https://arxiv.org/abs/2404.17000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17000">https://arxiv.org/pdf/2404.17000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17000]] Evaluating Class Membership Relations in Knowledge Graphs using Large  Language Models(https://arxiv.org/abs/2404.17000)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A backbone of knowledge graphs are their class membership relations, which assign entities to a given class. As part of the knowledge engineering process, we propose a new method for evaluating the quality of these relations by processing descriptions of a given entity and class using a zero-shot chain-of-thought classifier that uses a natural language intensional definition of a class. We evaluate the method using two publicly available knowledge graphs, Wikidata and CaLiGraph, and 7 large language models. Using the gpt-4-0125-preview large language model, the method's classification performance achieves a macro-averaged F1-score of 0.830 on data from Wikidata and 0.893 on data from CaLiGraph. Moreover, a manual analysis of the classification errors shows that 40.9% of errors were due to the knowledge graphs, with 16.0% due to missing relations and 24.9% due to incorrectly asserted relations. These results show how large language models can assist knowledge engineers in the process of knowledge graph refinement. The code and data are available on Github.</li>
</ul>

<h3>Title: Türkçe Dil Modellerinin Performans  Karşılaştırması Performance Comparison of Turkish Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Eren Dogan, M. Egemen Uzun, Atahan Uz, H. Emre Seyrek, Ahmed Zeer, Ezgi Sevi, H. Toprak Kesgin, M. Kaan Yuce, M. Fatih Amasyali</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17010">https://arxiv.org/abs/2404.17010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17010">https://arxiv.org/pdf/2404.17010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17010]] Türkçe Dil Modellerinin Performans  Karşılaştırması Performance Comparison of Turkish Language  Models(https://arxiv.org/abs/2404.17010)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The developments that language models have provided in fulfilling almost all kinds of tasks have attracted the attention of not only researchers but also the society and have enabled them to become products. There are commercially successful language models available. However, users may prefer open-source language models due to cost, data privacy, or regulations. Yet, despite the increasing number of these models, there is no comprehensive comparison of their performance for Turkish. This study aims to fill this gap in the literature. A comparison is made among seven selected language models based on their contextual learning and question-answering abilities. Turkish datasets for contextual learning and question-answering were prepared, and both automatic and human evaluations were conducted. The results show that for question-answering, continuing pretraining before fine-tuning with instructional datasets is more successful in adapting multilingual models to Turkish and that in-context learning performances do not much related to question-answering performances.</li>
</ul>

<h3>Title: Player-Driven Emergence in LLM-Driven Game Narrative</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Peng, Jessica Quaye, Weijia Xu, Chris Brockett, Bill Dolan, Nebojsa Jojic, Gabriel DesGarennes, Ken Lobb, Michael Xu, Jorge Leandro, Claire Jin, Sudha Rao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17027">https://arxiv.org/abs/2404.17027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17027">https://arxiv.org/pdf/2404.17027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17027]] Player-Driven Emergence in LLM-Driven Game Narrative(https://arxiv.org/abs/2404.17027)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We explore how interaction with large language models (LLMs) can give rise to emergent behaviors, empowering players to participate in the evolution of game narratives. Our testbed is a text-adventure game in which players attempt to solve a mystery under a fixed narrative premise, but can freely interact with non-player characters generated by GPT-4, a large language model. We recruit 28 gamers to play the game and use GPT-4 to automatically convert the game logs into a node-graph representing the narrative in the player's gameplay. We find that through their interactions with the non-deterministic behavior of the LLM, players are able to discover interesting new emergent nodes that were not a part of the original narrative but have potential for being fun and engaging. Players that created the most emergent nodes tended to be those that often enjoy games that facilitate discovery, exploration and experimentation.</li>
</ul>

<h3>Title: Dr-SAM: An End-to-End Framework for Vascular Segmentation, Diameter  Estimation, and Anomaly Detection on Angiography Images</h3>
<ul>
<li><strong>Authors: </strong>Vazgen Zohranyan, Vagner Navasardyan, Hayk Navasardyan, Jan Borggrefe, Shant Navasardyan</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17029">https://arxiv.org/abs/2404.17029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17029">https://arxiv.org/pdf/2404.17029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17029]] Dr-SAM: An End-to-End Framework for Vascular Segmentation, Diameter  Estimation, and Anomaly Detection on Angiography Images(https://arxiv.org/abs/2404.17029)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in AI have significantly transformed medical imaging, particularly in angiography, by enhancing diagnostic precision and patient care. However existing works are limited in analyzing the aorta and iliac arteries, above all for vascular anomaly detection and characterization. To close this gap, we propose Dr-SAM, a comprehensive multi-stage framework for vessel segmentation, diameter estimation, and anomaly analysis aiming to examine the peripheral vessels through angiography images. For segmentation we introduce a customized positive/negative point selection mechanism applied on top of the Segment Anything Model (SAM), specifically for medical (Angiography) images. Then we propose a morphological approach to determine the vessel diameters followed by our histogram-driven anomaly detection approach. Moreover, we introduce a new benchmark dataset for the comprehensive analysis of peripheral vessel angiography images which we hope can boost the upcoming research in this direction leading to enhanced diagnostic precision and ultimately better health outcomes for individuals facing vascular issues.</li>
</ul>

<h3>Title: Motor Focus: Ego-Motion Prediction with All-Pixel Matching</h3>
<ul>
<li><strong>Authors: </strong>Hao Wang, Jiayou Qin, Xiwen Chen, Ashish Bastola, John Suchanek, Zihao Gong, Abolfazl Razi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17031">https://arxiv.org/abs/2404.17031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17031">https://arxiv.org/pdf/2404.17031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17031]] Motor Focus: Ego-Motion Prediction with All-Pixel Matching(https://arxiv.org/abs/2404.17031)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Motion analysis plays a critical role in various applications, from virtual reality and augmented reality to assistive visual navigation. Traditional self-driving technologies, while advanced, typically do not translate directly to pedestrian applications due to their reliance on extensive sensor arrays and non-feasible computational frameworks. This highlights a significant gap in applying these solutions to human users since human navigation introduces unique challenges, including the unpredictable nature of human movement, limited processing capabilities of portable devices, and the need for directional responsiveness due to the limited perception range of humans. In this project, we introduce an image-only method that applies motion analysis using optical flow with ego-motion compensation to predict Motor Focus-where and how humans or machines focus their movement intentions. Meanwhile, this paper addresses the camera shaking issue in handheld and body-mounted devices which can severely degrade performance and accuracy, by applying a Gaussian aggregation to stabilize the predicted motor focus area and enhance the prediction accuracy of movement direction. This also provides a robust, real-time solution that adapts to the user's immediate environment. Furthermore, in the experiments part, we show the qualitative analysis of motor focus estimation between the conventional dense optical flow-based method and the proposed method. In quantitative tests, we show the performance of the proposed method on a collected small dataset that is specialized for motor focus estimation tasks.</li>
</ul>

<h3>Title: Auto-Generating Weak Labels for Real & Synthetic Data to Improve  Label-Scarce Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Tanvi Deshpande, Eva Prakash, Elsie Gyang Ross, Curtis Langlotz, Andrew Ng, Jeya Maria Jose Valanarasu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17033">https://arxiv.org/abs/2404.17033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17033">https://arxiv.org/pdf/2404.17033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17033]] Auto-Generating Weak Labels for Real & Synthetic Data to Improve  Label-Scarce Medical Image Segmentation(https://arxiv.org/abs/2404.17033)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The high cost of creating pixel-by-pixel gold-standard labels, limited expert availability, and presence of diverse tasks make it challenging to generate segmentation labels to train deep learning models for medical imaging tasks. In this work, we present a new approach to overcome the hurdle of costly medical image labeling by leveraging foundation models like Segment Anything Model (SAM) and its medical alternate MedSAM. Our pipeline has the ability to generate weak labels for any unlabeled medical image and subsequently use it to augment label-scarce datasets. We perform this by leveraging a model trained on a few gold-standard labels and using it to intelligently prompt MedSAM for weak label generation. This automation eliminates the manual prompting step in MedSAM, creating a streamlined process for generating labels for both real and synthetic images, regardless of quantity. We conduct experiments on label-scarce settings for multiple tasks pertaining to modalities ranging from ultrasound, dermatology, and X-rays to demonstrate the usefulness of our pipeline. The code is available at https://github.com/stanfordmlgroup/Auto-Generate-WLs/.</li>
</ul>

<h3>Title: Near to Mid-term Risks and Opportunities of Open Source Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Francisco Eiras, Aleksandar Petrov, Bertie Vidgen, Christian Schroeder de Witt, Fabio Pizzati, Katherine Elkins, Supratik Mukhopadhyay, Adel Bibi, Botos Csaba, Fabro Steibel, Fazl Barez, Genevieve Smith, Gianluca Guadagni, Jon Chun, Jordi Cabot, Joseph Marvin Imperial, Juan A. Nolazco-Flores, Lori Landay, Matthew Jackson, Paul Röttger, Philip H.S. Torr, Trevor Darrell, Yong Suk Lee, Jakob Foerster</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17047">https://arxiv.org/abs/2404.17047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17047">https://arxiv.org/pdf/2404.17047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17047]] Near to Mid-term Risks and Opportunities of Open Source Generative AI(https://arxiv.org/abs/2404.17047)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In the next few years, applications of Generative AI are expected to revolutionize a number of different areas, ranging from science & medicine to education. The potential for these seismic changes has triggered a lively debate about potential risks and resulted in calls for tighter regulation, in particular from some of the major tech companies who are leading in AI development. This regulation is likely to put at risk the budding field of open source Generative AI. We argue for the responsible open sourcing of generative AI models in the near and medium term. To set the stage, we first introduce an AI openness taxonomy system and apply it to 40 current large language models. We then outline differential benefits and risks of open versus closed source AI and present potential risk mitigation, ranging from best practices to calls for technical and scientific contributions. We hope that this report will add a much needed missing voice to the current public discourse on near to mid-term AI safety and other societal impact.</li>
</ul>

<h3>Title: Defending Spiking Neural Networks against Adversarial Attacks through  Image Purification</h3>
<ul>
<li><strong>Authors: </strong>Weiran Chen, Qi Sun, Qi Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17092">https://arxiv.org/abs/2404.17092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17092">https://arxiv.org/pdf/2404.17092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17092]] Defending Spiking Neural Networks against Adversarial Attacks through  Image Purification(https://arxiv.org/abs/2404.17092)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>Spiking Neural Networks (SNNs) aim to bridge the gap between neuroscience and machine learning by emulating the structure of the human nervous system. However, like convolutional neural networks, SNNs are vulnerable to adversarial attacks. To tackle the challenge, we propose a biologically inspired methodology to enhance the robustness of SNNs, drawing insights from the visual masking effect and filtering theory. First, an end-to-end SNN-based image purification model is proposed to defend against adversarial attacks, including a noise extraction network and a non-blind denoising network. The former network extracts noise features from noisy images, while the latter component employs a residual U-Net structure to reconstruct high-quality noisy images and generate clean images. Simultaneously, a multi-level firing SNN based on Squeeze-and-Excitation Network is introduced to improve the robustness of the classifier. Crucially, the proposed image purification network serves as a pre-processing module, avoiding modifications to classifiers. Unlike adversarial training, our method is highly flexible and can be seamlessly integrated with other defense strategies. Experimental results on various datasets demonstrate that the proposed methodology outperforms state-of-the-art baselines in terms of defense effectiveness, training time, and resource consumption.</li>
</ul>

<h3>Title: Unleashing the Potential of Fractional Calculus in Graph Neural Networks  with FROND</h3>
<ul>
<li><strong>Authors: </strong>Qiyu Kang, Kai Zhao, Qinxu Ding, Feng Ji, Xuhao Li, Wenfei Liang, Yang Song, Wee Peng Tay</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17099">https://arxiv.org/abs/2404.17099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17099">https://arxiv.org/pdf/2404.17099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17099]] Unleashing the Potential of Fractional Calculus in Graph Neural Networks  with FROND(https://arxiv.org/abs/2404.17099)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce the FRactional-Order graph Neural Dynamical network (FROND), a new continuous graph neural network (GNN) framework. Unlike traditional continuous GNNs that rely on integer-order differential equations, FROND employs the Caputo fractional derivative to leverage the non-local properties of fractional calculus. This approach enables the capture of long-term dependencies in feature updates, moving beyond the Markovian update mechanisms in conventional integer-order models and offering enhanced capabilities in graph representation learning. We offer an interpretation of the node feature updating process in FROND from a non-Markovian random walk perspective when the feature updating is particularly governed by a diffusion process. We demonstrate analytically that oversmoothing can be mitigated in this setting. Experimentally, we validate the FROND framework by comparing the fractional adaptations of various established integer-order continuous GNNs, demonstrating their consistently improved performance and underscoring the framework's potential as an effective extension to enhance traditional continuous GNNs. The code is available at \url{https://github.com/zknus/ICLR2024-FROND}.</li>
</ul>

<h3>Title: Synthesizing Iris Images using Generative Adversarial Networks: Survey  and Comparative Analysis</h3>
<ul>
<li><strong>Authors: </strong>Shivangi Yadav, Arun Ross</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17105">https://arxiv.org/abs/2404.17105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17105">https://arxiv.org/pdf/2404.17105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17105]] Synthesizing Iris Images using Generative Adversarial Networks: Survey  and Comparative Analysis(https://arxiv.org/abs/2404.17105)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, biometric, generative</a></li>
<li><strong>Abstract: </strong>Biometric systems based on iris recognition are currently being used in border control applications and mobile devices. However, research in iris recognition is stymied by various factors such as limited datasets of bonafide irides and presentation attack instruments; restricted intra-class variations; and privacy concerns. Some of these issues can be mitigated by the use of synthetic iris data. In this paper, we present a comprehensive review of state-of-the-art GAN-based synthetic iris image generation techniques, evaluating their strengths and limitations in producing realistic and useful iris images that can be used for both training and testing iris recognition systems and presentation attack detectors. In this regard, we first survey the various methods that have been used for synthetic iris generation and specifically consider generators based on StyleGAN, RaSGAN, CIT-GAN, iWarpGAN, StarGAN, etc. We then analyze the images generated by these models for realism, uniqueness, and biometric utility. This comprehensive analysis highlights the pros and cons of various GANs in the context of developing robust iris matchers and presentation attack detectors.</li>
</ul>

<h3>Title: MER 2024: Semi-Supervised Learning, Noise Robustness, and  Open-Vocabulary Multimodal Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Zheng Lian, Haiyang Sun, Licai Sun, Zhuofan Wen, Siyuan Zhang, Shun Chen, Hao Gu, Jinming Zhao, Ziyang Ma, Xie Chen, Jiangyan Yi, Rui Liu, Kele Xu, Bin Liu, Erik Cambria, Guoying Zhao, Björn W. Schuller, Jianhua Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17113">https://arxiv.org/abs/2404.17113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17113">https://arxiv.org/pdf/2404.17113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17113]] MER 2024: Semi-Supervised Learning, Noise Robustness, and  Open-Vocabulary Multimodal Emotion Recognition(https://arxiv.org/abs/2404.17113)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multimodal emotion recognition is an important research topic in artificial intelligence. Over the past few decades, researchers have made remarkable progress by increasing dataset size and building more effective architectures. However, due to various reasons (such as complex environments and inaccurate labels), current systems still cannot meet the demands of practical applications. Therefore, we plan to organize a series of challenges around emotion recognition to further promote the development of this field. Last year, we launched MER2023, focusing on three topics: multi-label learning, noise robustness, and semi-supervised learning. This year, we continue to organize MER2024. In addition to expanding the dataset size, we introduce a new track around open-vocabulary emotion recognition. The main consideration for this track is that existing datasets often fix the label space and use majority voting to enhance annotator consistency, but this process may limit the model's ability to describe subtle emotions. In this track, we encourage participants to generate any number of labels in any category, aiming to describe the character's emotional state as accurately as possible. Our baseline is based on MERTools and the code is available at: https://github.com/zeroQiaoba/MERTools/tree/master/MER2024.</li>
</ul>

<h3>Title: Talking Nonsense: Probing Large Language Models' Understanding of  Adversarial Gibberish Inputs</h3>
<ul>
<li><strong>Authors: </strong>Valeriia Cherepanova, James Zou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17120">https://arxiv.org/abs/2404.17120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17120">https://arxiv.org/pdf/2404.17120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17120]] Talking Nonsense: Probing Large Language Models' Understanding of  Adversarial Gibberish Inputs(https://arxiv.org/abs/2404.17120)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit excellent ability to understand human languages, but do they also understand their own language that appears gibberish to us? In this work we delve into this question, aiming to uncover the mechanisms underlying such behavior in LLMs. We employ the Greedy Coordinate Gradient optimizer to craft prompts that compel LLMs to generate coherent responses from seemingly nonsensical inputs. We call these inputs LM Babel and this work systematically studies the behavior of LLMs manipulated by these prompts. We find that the manipulation efficiency depends on the target text's length and perplexity, with the Babel prompts often located in lower loss minima compared to natural prompts. We further examine the structure of the Babel prompts and evaluate their robustness. Notably, we find that guiding the model to generate harmful texts is not more difficult than into generating benign texts, suggesting lack of alignment for out-of-distribution prompts.</li>
</ul>

<h3>Title: Deep Evidential Learning for Dose Prediction</h3>
<ul>
<li><strong>Authors: </strong>Hai Siong Tan, Kuancheng Wang, Rafe Mcbeth</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.IV, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17126">https://arxiv.org/abs/2404.17126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17126">https://arxiv.org/pdf/2404.17126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17126]] Deep Evidential Learning for Dose Prediction(https://arxiv.org/abs/2404.17126)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this work, we present a novel application of an uncertainty-quantification framework called Deep Evidential Learning in the domain of radiotherapy dose prediction. Using medical images of the Open Knowledge-Based Planning Challenge dataset, we found that this model can be effectively harnessed to yield uncertainty estimates that inherited correlations with prediction errors upon completion of network training. This was achieved only after reformulating the original loss function for a stable implementation. We found that (i)epistemic uncertainty was highly correlated with prediction errors, with various association indices comparable or stronger than those for Monte-Carlo Dropout and Deep Ensemble methods, (ii)the median error varied with uncertainty threshold much more linearly for epistemic uncertainty in Deep Evidential Learning relative to these other two conventional frameworks, indicative of a more uniformly calibrated sensitivity to model errors, (iii)relative to epistemic uncertainty, aleatoric uncertainty demonstrated a more significant shift in its distribution in response to Gaussian noise added to CT intensity, compatible with its interpretation as reflecting data noise. Collectively, our results suggest that Deep Evidential Learning is a promising approach that can endow deep-learning models in radiotherapy dose prediction with statistical robustness. Towards enhancing its clinical relevance, we demonstrate how we can use such a model to construct the predicted Dose-Volume-Histograms' confidence intervals.</li>
</ul>

<h3>Title: Small Language Models Need Strong Verifiers to Self-Correct Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yunxiang Zhang, Muhammad Khalifa, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, Lu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17140">https://arxiv.org/abs/2404.17140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17140">https://arxiv.org/pdf/2404.17140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17140]] Small Language Models Need Strong Verifiers to Self-Correct Reasoning(https://arxiv.org/abs/2404.17140)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether smaller-size (<= 13B) language models (LMs) have the ability of self-correction on reasoning tasks with minimal inputs from stronger LMs. We propose a novel pipeline that prompts smaller LMs to collect self-correction data that supports the training of self-refinement abilities. First, we leverage correct solutions to guide the model in critiquing their incorrect responses. Second, the generated critiques, after filtering, are used for supervised fine-tuning of the self-correcting reasoner through solution refinement. Our experimental results show improved self-correction abilities of two models on five datasets spanning math and commonsense reasoning, with notable performance gains when paired with a strong GPT-4-based verifier, though limitations are identified when using a weak self-verifier for determining when to correct.</li>
</ul>

<h3>Title: Quantifying Memorization of Domain-Specific Pre-trained Language Models  using Japanese Newspaper and Paywalls</h3>
<ul>
<li><strong>Authors: </strong>Shotaro Ishihara</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17143">https://arxiv.org/abs/2404.17143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17143">https://arxiv.org/pdf/2404.17143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17143]] Quantifying Memorization of Domain-Specific Pre-trained Language Models  using Japanese Newspaper and Paywalls(https://arxiv.org/abs/2404.17143)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Dominant pre-trained language models (PLMs) have been successful in high-quality natural language generation. However, the analysis of their generation is not mature: do they acquire generalizable linguistic abstractions, or do they simply memorize and recover substrings of the training data? Especially, few studies focus on domain-specific PLM. In this study, we pre-trained domain-specific GPT-2 models using a limited corpus of Japanese newspaper articles and quantified memorization of training data by comparing them with general Japanese GPT-2 models. Our experiments revealed that domain-specific PLMs sometimes "copy and paste" on a large scale. Furthermore, we replicated the empirical finding that memorization is related to duplication, model size, and prompt length, in Japanese the same as in previous English studies. Our evaluations are relieved from data contamination concerns by focusing on newspaper paywalls, which prevent their use as training data. We hope that our paper encourages a sound discussion such as the security and copyright of PLMs.</li>
</ul>

<h3>Title: Sensor Response-Time Reduction using Long-Short Term Memory Network  Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Simon J. Ward, Muhamed Baljevic, Sharon M. Weiss</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17144">https://arxiv.org/abs/2404.17144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17144">https://arxiv.org/pdf/2404.17144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17144]] Sensor Response-Time Reduction using Long-Short Term Memory Network  Forecasting(https://arxiv.org/abs/2404.17144)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The response time of a biosensor is a crucial metric in safety-critical applications such as medical diagnostics where an earlier diagnosis can markedly improve patient outcomes. However, the speed at which a biosensor reaches a final equilibrium state can be limited by poor mass transport and long molecular diffusion times that increase the time it takes target molecules to reach the active sensing region of a biosensor. While optimization of system and sensor design can promote molecules reaching the sensing element faster, a simpler and complementary approach for response time reduction that is widely applicable across all sensor platforms is to use time-series forecasting to predict the ultimate steady-state sensor response. In this work, we show that ensembles of long short-term memory (LSTM) networks can accurately predict equilibrium biosensor response from a small quantity of initial time-dependent biosensor measurements, allowing for significant reduction in response time by a mean and median factor of improvement of 18.6 and 5.1, respectively. The ensemble of models also provides simultaneous estimation of uncertainty, which is vital to provide confidence in the predictions and subsequent safety-related decisions that are made. This approach is demonstrated on real-time experimental data collected by exposing porous silicon biosensors to buffered protein solutions using a multi-channel fluidic cell that enables the automated measurement of 100 porous silicon biosensors in parallel. The dramatic improvement in sensor response time achieved using LSTM network ensembles and associated uncertainty quantification opens the door to trustworthy and faster responding biosensors, enabling more rapid medical diagnostics for improved patient outcomes and healthcare access, as well as quicker identification of toxins in food and the environment.</li>
</ul>

<h3>Title: On the Federated Learning Framework for Cooperative Perception</h3>
<ul>
<li><strong>Authors: </strong>Zhenrong Zhang, Jianan Liu, Xi Zhou, Tao Huang, Qing-Long Han, Jingxin Liu, Hongbin Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17147">https://arxiv.org/abs/2404.17147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17147">https://arxiv.org/pdf/2404.17147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17147]] On the Federated Learning Framework for Cooperative Perception(https://arxiv.org/abs/2404.17147)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate, transformer</a></li>
<li><strong>Abstract: </strong>Cooperative perception is essential to enhance the efficiency and safety of future transportation systems, requiring extensive data sharing among vehicles on the road, which raises significant privacy concerns. Federated learning offers a promising solution by enabling data privacy-preserving collaborative enhancements in perception, decision-making, and planning among connected and autonomous vehicles (CAVs). However, federated learning is impeded by significant challenges arising from data heterogeneity across diverse clients, potentially diminishing model accuracy and prolonging convergence periods. This study introduces a specialized federated learning framework for CP, termed the federated dynamic weighted aggregation (FedDWA) algorithm, facilitated by dynamic adjusting loss (DALoss) function. This framework employs dynamic client weighting to direct model convergence and integrates a novel loss function that utilizes Kullback-Leibler divergence (KLD) to counteract the detrimental effects of non-independently and identically distributed (Non-IID) and unbalanced data. Utilizing the BEV transformer as the primary model, our rigorous testing on the OpenV2V dataset, augmented with FedBEVT data, demonstrates significant improvements in the average intersection over union (IoU). These results highlight the substantial potential of our federated learning framework to address data heterogeneity challenges in CP, thereby enhancing the accuracy of environmental perception models and facilitating more robust and efficient collaborative learning solutions in the transportation sector.</li>
</ul>

<h3>Title: Neuro-Symbolic Embedding for Short and Effective Feature Selection via  Autoregressive Generation</h3>
<ul>
<li><strong>Authors: </strong>Nanxu Gong, Wangyang Ying, Dongjie Wang, Yanjie Fu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17157">https://arxiv.org/abs/2404.17157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17157">https://arxiv.org/pdf/2404.17157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17157]] Neuro-Symbolic Embedding for Short and Effective Feature Selection via  Autoregressive Generation(https://arxiv.org/abs/2404.17157)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Feature selection aims to identify the optimal feature subset for enhancing downstream models. Effective feature selection can remove redundant features, save computational resources, accelerate the model learning process, and improve the model overall performance. However, existing works are often time-intensive to identify the effective feature subset within high-dimensional feature spaces. Meanwhile, these methods mainly utilize a single downstream task performance as the selection criterion, leading to the selected subsets that are not only redundant but also lack generalizability. To bridge these gaps, we reformulate feature selection through a neuro-symbolic lens and introduce a novel generative framework aimed at identifying short and effective feature subsets. More specifically, we found that feature ID tokens of the selected subset can be formulated as symbols to reflect the intricate correlations among features. Thus, in this framework, we first create a data collector to automatically collect numerous feature selection samples consisting of feature ID tokens, model performance, and the measurement of feature subset redundancy. Building on the collected data, an encoder-decoder-evaluator learning paradigm is developed to preserve the intelligence of feature selection into a continuous embedding space for efficient search. Within the learned embedding space, we leverage a multi-gradient search algorithm to find more robust and generalized embeddings with the objective of improving model performance and reducing feature subset redundancy. These embeddings are then utilized to reconstruct the feature ID tokens for executing the final feature selection. Ultimately, comprehensive experiments and case studies are conducted to validate the effectiveness of the proposed framework.</li>
</ul>

<h3>Title: Phase-aggregated Dual-branch Network for Efficient Fingerprint Dense  Registration</h3>
<ul>
<li><strong>Authors: </strong>Xiongjun Guan, Jianjiang Feng, Jie Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17159">https://arxiv.org/abs/2404.17159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17159">https://arxiv.org/pdf/2404.17159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17159]] Phase-aggregated Dual-branch Network for Efficient Fingerprint Dense  Registration(https://arxiv.org/abs/2404.17159)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fingerprint dense registration aims to finely align fingerprint pairs at the pixel level, thereby reducing intra-class differences caused by distortion. Unfortunately, traditional methods exhibited subpar performance when dealing with low-quality fingerprints while suffering from slow inference speed. Although deep learning based approaches shows significant improvement in these aspects, their registration accuracy is still unsatisfactory. In this paper, we propose a Phase-aggregated Dual-branch Registration Network (PDRNet) to aggregate the advantages of both types of methods. A dual-branch structure with multi-stage interactions is introduced between correlation information at high resolution and texture feature at low resolution, to perceive local fine differences while ensuring global stability. Extensive experiments are conducted on more comprehensive databases compared to previous works. Experimental results demonstrate that our method reaches the state-of-the-art registration performance in terms of accuracy and robustness, while maintaining considerable competitiveness in efficiency.</li>
</ul>

<h3>Title: DPGAN: A Dual-Path Generative Adversarial Network for Missing Data  Imputation in Graphs</h3>
<ul>
<li><strong>Authors: </strong>Xindi Zheng, Yuwei Wu, Yu Pan, Wanyu Lin, Lei Ma, Jianjun Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17164">https://arxiv.org/abs/2404.17164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17164">https://arxiv.org/pdf/2404.17164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17164]] DPGAN: A Dual-Path Generative Adversarial Network for Missing Data  Imputation in Graphs(https://arxiv.org/abs/2404.17164)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Missing data imputation poses a paramount challenge when dealing with graph data. Prior works typically are based on feature propagation or graph autoencoders to address this issue. However, these methods usually encounter the over-smoothing issue when dealing with missing data, as the graph neural network (GNN) modules are not explicitly designed for handling missing data. This paper proposes a novel framework, called Dual-Path Generative Adversarial Network (DPGAN), that can deal simultaneously with missing data and avoid over-smoothing problems. The crux of our work is that it admits both global and local representations of the input graph signal, which can capture the long-range dependencies. It is realized via our proposed generator, consisting of two key components, i.e., MLPUNet++ and GraphUNet++. Our generator is trained with a designated discriminator via an adversarial process. In particular, to avoid assessing the entire graph as did in the literature, our discriminator focuses on the local subgraph fidelity, thereby boosting the quality of the local imputation. The subgraph size is adjustable, allowing for control over the intensity of adversarial regularization. Comprehensive experiments across various benchmark datasets substantiate that DPGAN consistently rivals, if not outperforms, existing state-of-the-art imputation algorithms. The code is provided at \url{https://github.com/momoxia/DPGAN}.</li>
</ul>

<h3>Title: FairGT: A Fairness-aware Graph Transformer</h3>
<ul>
<li><strong>Authors: </strong>Renqiang Luo, Huafei Huang, Shuo Yu, Xiuzhen Zhang, Feng Xia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17169">https://arxiv.org/abs/2404.17169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17169">https://arxiv.org/pdf/2404.17169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17169]] FairGT: A Fairness-aware Graph Transformer(https://arxiv.org/abs/2404.17169)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, transformer</a></li>
<li><strong>Abstract: </strong>The design of Graph Transformers (GTs) generally neglects considerations for fairness, resulting in biased outcomes against certain sensitive subgroups. Since GTs encode graph information without relying on message-passing mechanisms, conventional fairness-aware graph learning methods cannot be directly applicable to address these issues. To tackle this challenge, we propose FairGT, a Fairness-aware Graph Transformer explicitly crafted to mitigate fairness concerns inherent in GTs. FairGT incorporates a meticulous structural feature selection strategy and a multi-hop node feature integration method, ensuring independence of sensitive features and bolstering fairness considerations. These fairness-aware graph information encodings seamlessly integrate into the Transformer framework for downstream tasks. We also prove that the proposed fair structural topology encoding with adjacency matrix eigenvector selection and multi-hop integration are theoretically effective. Empirical evaluations conducted across five real-world datasets demonstrate FairGT's superiority in fairness metrics over existing graph transformers, graph neural networks, and state-of-the-art fairness-aware graph learning approaches.</li>
</ul>

<h3>Title: S-IQA Image Quality Assessment With Compressive Sampling</h3>
<ul>
<li><strong>Authors: </strong>Ronghua Liao, Chen Hui, Lang Yuan, Feng Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17170">https://arxiv.org/abs/2404.17170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17170">https://arxiv.org/pdf/2404.17170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17170]] S-IQA Image Quality Assessment With Compressive Sampling(https://arxiv.org/abs/2404.17170)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>No-Reference Image Quality Assessment (IQA) aims at estimating image quality in accordance with subjective human perception. However, most existing NR-IQA methods focus on exploring increasingly complex networks or components to improve the final performance. Such practice imposes great limitations and complexity on IQA methods, especially when they are applied to high-resolution (HR) images in the real world. Actually, most images own high spatial redundancy, especially for those HR data. To further exploit the characteristic and alleviate the issue above, we propose a new framework for Image Quality Assessment with compressive Sampling (dubbed S-IQA), which consists of three components: (1) The Flexible Sampling Module (FSM) samples the image to obtain measurements at an arbitrary ratio. (2) Vision Transformer with the Adaptive Embedding Module (AEM) makes measurements of uniform size and extracts deep features (3) Dual Branch (DB) allocates weight for every patch and predicts the final quality score. Experiments show that our proposed S-IQA achieves state-of-the-art result on various datasets with less data usage.</li>
</ul>

<h3>Title: Optimizing Cycle Life Prediction of Lithium-ion Batteries via a  Physics-Informed Model</h3>
<ul>
<li><strong>Authors: </strong>Constantin-Daniel Nicolae, Sara Sameer, Nathan Sun, Karena Yan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17174">https://arxiv.org/abs/2404.17174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17174">https://arxiv.org/pdf/2404.17174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17174]] Optimizing Cycle Life Prediction of Lithium-ion Batteries via a  Physics-Informed Model(https://arxiv.org/abs/2404.17174)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Accurately measuring the cycle lifetime of commercial lithium-ion batteries is crucial for performance and technology development. We introduce a novel hybrid approach combining a physics-based equation with a self-attention model to predict the cycle lifetimes of commercial lithium iron phosphate graphite cells via early-cycle data. After fitting capacity loss curves to this physics-based equation, we then use a self-attention layer to reconstruct entire battery capacity loss curves. Our model exhibits comparable performances to existing models while predicting more information: the entire capacity loss curve instead of cycle life. This provides more robustness and interpretability: our model does not need to be retrained for a different notion of end-of-life and is backed by physical intuition.</li>
</ul>

<h3>Title: MovieChat+: Question-aware Sparse Memory for Long Video Question  Answering</h3>
<ul>
<li><strong>Authors: </strong>Enxin Song, Wenhao Chai, Tian Ye, Jenq-Neng Hwang, Xi Li, Gaoang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17176">https://arxiv.org/abs/2404.17176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17176">https://arxiv.org/pdf/2404.17176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17176]] MovieChat+: Question-aware Sparse Memory for Long Video Question  Answering(https://arxiv.org/abs/2404.17176)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recently, integrating video foundation models and large language models to build a video understanding system can overcome the limitations of specific pre-defined vision tasks. Yet, existing methods either employ complex spatial-temporal modules or rely heavily on additional perception models to extract temporal features for video understanding, and they only perform well on short videos. For long videos, the computational complexity and memory costs associated with long-term temporal connections are significantly increased, posing additional challenges.Taking advantage of the Atkinson-Shiffrin memory model, with tokens in Transformers being employed as the carriers of memory in combination with our specially designed memory mechanism, we propose MovieChat to overcome these challenges. We lift pre-trained multi-modal large language models for understanding long videos without incorporating additional trainable temporal modules, employing a zero-shot approach. MovieChat achieves state-of-the-art performance in long video understanding, along with the released MovieChat-1K benchmark with 1K long video, 2K temporal grounding labels, and 14K manual annotations for validation of the effectiveness of our method. The code along with the dataset can be accessed via the following https://github.com/rese1f/MovieChat.</li>
</ul>

<h3>Title: RE-RFME: Real-Estate RFME Model for customer segmentation</h3>
<ul>
<li><strong>Authors: </strong>Anurag Kumar Pandey, Anil Goyal, Nikhil Sikka</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17177">https://arxiv.org/abs/2404.17177</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17177">https://arxiv.org/pdf/2404.17177</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17177]] RE-RFME: Real-Estate RFME Model for customer segmentation(https://arxiv.org/abs/2404.17177)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Marketing is one of the high-cost activities for any online platform. With the increase in the number of customers, it is crucial to understand customers based on their dynamic behaviors to design effective marketing strategies. Customer segmentation is a widely used approach to group customers into different categories and design the marketing strategy targeting each group individually. Therefore, in this paper, we propose an end-to-end pipeline RE-RFME for segmenting customers into 4 groups: high value, promising, need attention, and need activation. Concretely, we propose a novel RFME (Recency, Frequency, Monetary and Engagement) model to track behavioral features of customers and segment them into different categories. Finally, we train the K-means clustering algorithm to cluster the user into one of the 4 categories. We show the effectiveness of the proposed approach on real-world Housing.com datasets for both website and mobile application users.</li>
</ul>

<h3>Title: Low-Rank Knowledge Decomposition for Medical Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Zhou, Haolin Li, Siyuan Du, Jiangchao Yao, Ya Zhang, Yanfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17184">https://arxiv.org/abs/2404.17184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17184">https://arxiv.org/pdf/2404.17184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17184]] Low-Rank Knowledge Decomposition for Medical Foundation Models(https://arxiv.org/abs/2404.17184)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The popularity of large-scale pre-training has promoted the development of medical foundation models. However, some studies have shown that although foundation models exhibit strong general feature extraction capabilities, their performance on specific tasks is still inferior to task-specific methods. In this paper, we explore a new perspective called ``Knowledge Decomposition'' to improve the performance on specific medical tasks, which deconstruct the foundation model into multiple lightweight expert models, each dedicated to a particular task, with the goal of improving specialization while concurrently mitigating resource expenditure. To accomplish the above objective, we design a novel framework named Low-Rank Knowledge Decomposition (LoRKD), which explicitly separates graidents by incorporating low-rank expert modules and the efficient knowledge separation convolution. Extensive experimental results demonstrate that the decomposed models perform well in terms of performance and transferability, even surpassing the original foundation models.</li>
</ul>

<h3>Title: MCSDNet: Mesoscale Convective System Detection Network via Multi-scale  Spatiotemporal Information</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Liang, Baoquan Zhang, Yunming Ye, Xutao Li, Chuyao Luo, Xukai Fu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17186">https://arxiv.org/abs/2404.17186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17186">https://arxiv.org/pdf/2404.17186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17186]] MCSDNet: Mesoscale Convective System Detection Network via Multi-scale  Spatiotemporal Information(https://arxiv.org/abs/2404.17186)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The accurate detection of Mesoscale Convective Systems (MCS) is crucial for meteorological monitoring due to their potential to cause significant destruction through severe weather phenomena such as hail, thunderstorms, and heavy rainfall. However, the existing methods for MCS detection mostly targets on single-frame detection, which just considers the static characteristics and ignores the temporal evolution in the life cycle of MCS. In this paper, we propose a novel encoder-decoder neural network for MCS detection(MCSDNet). MCSDNet has a simple architecture and is easy to expand. Different from the previous models, MCSDNet targets on multi-frames detection and leverages multi-scale spatiotemporal information for the detection of MCS regions in remote sensing imagery(RSI). As far as we know, it is the first work to utilize multi-scale spatiotemporal information to detect MCS regions. Firstly, we design a multi-scale spatiotemporal information module to extract multi-level semantic from different encoder levels, which makes our models can extract more detail spatiotemporal features. Secondly, a Spatiotemporal Mix Unit(STMU) is introduced to MCSDNet to capture both intra-frame features and inter-frame correlations, which is a scalable module and can be replaced by other spatiotemporal module, e.g., CNN, RNN, Transformer and our proposed Dual Spatiotemporal Attention(DSTA). This means that the future works about spatiotemporal modules can be easily integrated to our model. Finally, we present MCSRSI, the first publicly available dataset for multi-frames MCS detection based on visible channel images from the FY-4A satellite. We also conduct several experiments on MCSRSI and find that our proposed MCSDNet achieve the best performance on MCS detection task when comparing to other baseline methods.</li>
</ul>

<h3>Title: An Explainable Deep Reinforcement Learning Model for Warfarin  Maintenance Dosing Using Policy Distillation and Action Forging</h3>
<ul>
<li><strong>Authors: </strong>Sadjad Anzabi Zadeh, W. Nick Street, Barrett W. Thomas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17187">https://arxiv.org/abs/2404.17187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17187">https://arxiv.org/pdf/2404.17187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17187]] An Explainable Deep Reinforcement Learning Model for Warfarin  Maintenance Dosing Using Policy Distillation and Action Forging(https://arxiv.org/abs/2404.17187)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Deep Reinforcement Learning is an effective tool for drug dosing for chronic condition management. However, the final protocol is generally a black box without any justification for its prescribed doses. This paper addresses this issue by proposing an explainable dosing protocol for warfarin using a Proximal Policy Optimization method combined with Policy Distillation. We introduce Action Forging as an effective tool to achieve explainability. Our focus is on the maintenance dosing protocol. Results show that the final model is as easy to understand and deploy as the current dosing protocols and outperforms the baseline dosing algorithms.</li>
</ul>

<h3>Title: Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered  Applications</h3>
<ul>
<li><strong>Authors: </strong>Quan Zhang, Binqi Zeng, Chijin Zhou, Gwihwan Go, Heyuan Shi, Yu Jiang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17196">https://arxiv.org/abs/2404.17196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17196">https://arxiv.org/pdf/2404.17196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17196]] Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered  Applications(https://arxiv.org/abs/2404.17196)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Presently, with the assistance of advanced LLM application development frameworks, more and more LLM-powered applications can effortlessly augment the LLMs' knowledge with external content using the retrieval augmented generation (RAG) technique. However, these frameworks' designs do not have sufficient consideration of the risk of external content, thereby allowing attackers to undermine the applications developed with these frameworks. In this paper, we reveal a new threat to LLM-powered applications, termed retrieval poisoning, where attackers can guide the application to yield malicious responses during the RAG process. Specifically, through the analysis of LLM application frameworks, attackers can craft documents visually indistinguishable from benign ones. Despite the documents providing correct information, once they are used as reference sources for RAG, the application is misled into generating incorrect responses. Our preliminary experiments indicate that attackers can mislead LLMs with an 88.33\% success rate, and achieve a 66.67\% success rate in the real-world application, demonstrating the potential impact of retrieval poisoning.</li>
</ul>

<h3>Title: Few-shot Calligraphy Style Learning</h3>
<ul>
<li><strong>Authors: </strong>Fangda Chen, Jiacheng Nie, Lichuan Jiang, Zhuoer Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17199">https://arxiv.org/abs/2404.17199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17199">https://arxiv.org/pdf/2404.17199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17199]] Few-shot Calligraphy Style Learning(https://arxiv.org/abs/2404.17199)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduced "Presidifussion," a novel approach to learning and replicating the unique style of calligraphy of President Xu, using a pretrained diffusion model adapted through a two-stage training process. Initially, our model is pretrained on a diverse dataset containing works from various calligraphers. This is followed by fine-tuning on a smaller, specialized dataset of President Xu's calligraphy, comprising just under 200 images. Our method introduces innovative techniques of font image conditioning and stroke information conditioning, enabling the model to capture the intricate structural elements of Chinese characters. The effectiveness of our approach is demonstrated through a comparison with traditional methods like zi2zi and CalliGAN, with our model achieving comparable performance using significantly smaller datasets and reduced computational resources. This work not only presents a breakthrough in the digital preservation of calligraphic art but also sets a new standard for data-efficient generative modeling in the domain of cultural heritage digitization.</li>
</ul>

<h3>Title: Self-supervised visual learning in the low-data regime: a comparative  evaluation</h3>
<ul>
<li><strong>Authors: </strong>Sotirios Konstantakos, Despina Ioanna Chalkiadaki, Ioannis Mademlis, Yuki M. Asano, Efstratios Gavves, Georgios Th. Papadopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17202">https://arxiv.org/abs/2404.17202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17202">https://arxiv.org/pdf/2404.17202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17202]] Self-supervised visual learning in the low-data regime: a comparative  evaluation(https://arxiv.org/abs/2404.17202)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Self-Supervised Learning (SSL) is a valuable and robust training methodology for contemporary Deep Neural Networks (DNNs), enabling unsupervised pretraining on a `pretext task' that does not require ground-truth labels/annotation. This allows efficient representation learning from massive amounts of unlabeled training data, which in turn leads to increased accuracy in a `downstream task' by exploiting supervised transfer learning. Despite the relatively straightforward conceptualization and applicability of SSL, it is not always feasible to collect and/or to utilize very large pretraining datasets, especially when it comes to real-world application settings. In particular, in cases of specialized and domain-specific application scenarios, it may not be achievable or practical to assemble a relevant image pretraining dataset in the order of millions of instances or it could be computationally infeasible to pretrain at this scale. This motivates an investigation on the effectiveness of common SSL pretext tasks, when the pretraining dataset is of relatively limited/constrained size. In this context, this work introduces a taxonomy of modern visual SSL methods, accompanied by detailed explanations and insights regarding the main categories of approaches, and, subsequently, conducts a thorough comparative experimental evaluation in the low-data regime, targeting to identify: a) what is learnt via low-data SSL pretraining, and b) how do different SSL categories behave in such training scenarios. Interestingly, for domain-specific downstream tasks, in-domain low-data SSL pretraining outperforms the common approach of large-scale pretraining on general datasets. Grounded on the obtained results, valuable insights are highlighted regarding the performance of each category of SSL methods, which in turn suggest straightforward future research directions in the field.</li>
</ul>

<h3>Title: Two in One Go: Single-stage Emotion Recognition with Decoupled  Subject-context Transformer</h3>
<ul>
<li><strong>Authors: </strong>Xinpeng Li, Teng Wang, Jian Zhao, Shuyi Mao, Jinbao Wang, Feng Zheng, Xiaojiang Peng, Xuelong Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17205">https://arxiv.org/abs/2404.17205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17205">https://arxiv.org/pdf/2404.17205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17205]] Two in One Go: Single-stage Emotion Recognition with Decoupled  Subject-context Transformer(https://arxiv.org/abs/2404.17205)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Emotion recognition aims to discern the emotional state of subjects within an image, relying on subject-centric and contextual visual cues. Current approaches typically follow a two-stage pipeline: first localize subjects by off-the-shelf detectors, then perform emotion classification through the late fusion of subject and context features. However, the complicated paradigm suffers from disjoint training stages and limited interaction between fine-grained subject-context elements. To address the challenge, we present a single-stage emotion recognition approach, employing a Decoupled Subject-Context Transformer (DSCT), for simultaneous subject localization and emotion classification. Rather than compartmentalizing training stages, we jointly leverage box and emotion signals as supervision to enrich subject-centric feature learning. Furthermore, we introduce DSCT to facilitate interactions between fine-grained subject-context cues in a decouple-then-fuse manner. The decoupled query token--subject queries and context queries--gradually intertwine across layers within DSCT, during which spatial and semantic relations are exploited and aggregated. We evaluate our single-stage framework on two widely used context-aware emotion recognition datasets, CAER-S and EMOTIC. Our approach surpasses two-stage alternatives with fewer parameter numbers, achieving a 3.39% accuracy improvement and a 6.46% average precision gain on CAER-S and EMOTIC datasets, respectively.</li>
</ul>

<h3>Title: SAGHOG: Self-Supervised Autoencoder for Generating HOG Features for  Writer Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Marco Peer, Florian Kleber, Robert Sablatnig</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17221">https://arxiv.org/abs/2404.17221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17221">https://arxiv.org/pdf/2404.17221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17221]] SAGHOG: Self-Supervised Autoencoder for Generating HOG Features for  Writer Retrieval(https://arxiv.org/abs/2404.17221)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces SAGHOG, a self-supervised pretraining strategy for writer retrieval using HOG features of the binarized input image. Our preprocessing involves the application of the Segment Anything technique to extract handwriting from various datasets, ending up with about 24k documents, followed by training a vision transformer on reconstructing masked patches of the handwriting. SAGHOG is then finetuned by appending NetRVLAD as an encoding layer to the pretrained encoder. Evaluation of our approach on three historical datasets, Historical-WI, HisFrag20, and GRK-Papyri, demonstrates the effectiveness of SAGHOG for writer retrieval. Additionally, we provide ablation studies on our architecture and evaluate un- and supervised finetuning. Notably, on HisFrag20, SAGHOG outperforms related work with a mAP of 57.2 % - a margin of 11.6 % to the current state of the art, showcasing its robustness on challenging data, and is competitive on even small datasets, e.g. GRK-Papyri, where we achieve a Top-1 accuracy of 58.0%.</li>
</ul>

<h3>Title: Enhancing Privacy and Security of Autonomous UAV Navigation</h3>
<ul>
<li><strong>Authors: </strong>Vatsal Aggarwal, Arjun Ramesh Kaushik, Charanjit Jutla, Nalini Ratha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17225">https://arxiv.org/abs/2404.17225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17225">https://arxiv.org/pdf/2404.17225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17225]] Enhancing Privacy and Security of Autonomous UAV Navigation(https://arxiv.org/abs/2404.17225)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, defense, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Autonomous Unmanned Aerial Vehicles (UAVs) have become essential tools in defense, law enforcement, disaster response, and product delivery. These autonomous navigation systems require a wireless communication network, and of late are deep learning based. In critical scenarios such as border protection or disaster response, ensuring the secure navigation of autonomous UAVs is paramount. But, these autonomous UAVs are susceptible to adversarial attacks through the communication network or the deep learning models - eavesdropping / man-in-the-middle / membership inference / reconstruction. To address this susceptibility, we propose an innovative approach that combines Reinforcement Learning (RL) and Fully Homomorphic Encryption (FHE) for secure autonomous UAV navigation. This end-to-end secure framework is designed for real-time video feeds captured by UAV cameras and utilizes FHE to perform inference on encrypted input images. While FHE allows computations on encrypted data, certain computational operators are yet to be implemented. Convolutional neural networks, fully connected neural networks, activation functions and OpenAI Gym Library are meticulously adapted to the FHE domain to enable encrypted data processing. We demonstrate the efficacy of our proposed approach through extensive experimentation. Our proposed approach ensures security and privacy in autonomous UAV navigation with negligible loss in performance.</li>
</ul>

<h3>Title: ObjectAdd: Adding Objects into Image via a Training-Free Diffusion  Modification Fashion</h3>
<ul>
<li><strong>Authors: </strong>Ziyue Zhang, Mingbao Lin, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17230">https://arxiv.org/abs/2404.17230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17230">https://arxiv.org/pdf/2404.17230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17230]] ObjectAdd: Adding Objects into Image via a Training-Free Diffusion  Modification Fashion(https://arxiv.org/abs/2404.17230)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce ObjectAdd, a training-free diffusion modification method to add user-expected objects into user-specified area. The motive of ObjectAdd stems from: first, describing everything in one prompt can be difficult, and second, users often need to add objects into the generated image. To accommodate with real world, our ObjectAdd maintains accurate image consistency after adding objects with technical innovations in: (1) embedding-level concatenation to ensure correct text embedding coalesce; (2) object-driven layout control with latent and attention injection to ensure objects accessing user-specified area; (3) prompted image inpainting in an attention refocusing & object expansion fashion to ensure rest of the image stays the same. With a text-prompted image, our ObjectAdd allows users to specify a box and an object, and achieves: (1) adding object inside the box area; (2) exact content outside the box area; (3) flawless fusion between the two areas</li>
</ul>

<h3>Title: Binarizing Documents by Leveraging both Space and Frequency</h3>
<ul>
<li><strong>Authors: </strong>Fabio Quattrini, Vittorio Pippi, Silvia Cascianelli, Rita Cucchiara</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17243">https://arxiv.org/abs/2404.17243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17243">https://arxiv.org/pdf/2404.17243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17243]] Binarizing Documents by Leveraging both Space and Frequency(https://arxiv.org/abs/2404.17243)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Document Image Binarization is a well-known problem in Document Analysis and Computer Vision, although it is far from being solved. One of the main challenges of this task is that documents generally exhibit degradations and acquisition artifacts that can greatly vary throughout the page. Nonetheless, even when dealing with a local patch of the document, taking into account the overall appearance of a wide portion of the page can ease the prediction by enriching it with semantic information on the ink and background conditions. In this respect, approaches able to model both local and global information have been proven suitable for this task. In particular, recent applications of Vision Transformer (ViT)-based models, able to model short and long-range dependencies via the attention mechanism, have demonstrated their superiority over standard Convolution-based models, which instead struggle to model global dependencies. In this work, we propose an alternative solution based on the recently introduced Fast Fourier Convolutions, which overcomes the limitation of standard convolutions in modeling global information while requiring fewer parameters than ViTs. We validate the effectiveness of our approach via extensive experimental analysis considering different types of degradations.</li>
</ul>

<h3>Title: Parameter Efficient Fine-tuning of Self-supervised ViTs without  Catastrophic Forgetting</h3>
<ul>
<li><strong>Authors: </strong>Reza Akbarian Bafghi, Nidhin Harilal, Claire Monteleoni, Maziar Raissi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17245">https://arxiv.org/abs/2404.17245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17245">https://arxiv.org/pdf/2404.17245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17245]] Parameter Efficient Fine-tuning of Self-supervised ViTs without  Catastrophic Forgetting(https://arxiv.org/abs/2404.17245)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Artificial neural networks often suffer from catastrophic forgetting, where learning new concepts leads to a complete loss of previously acquired knowledge. We observe that this issue is particularly magnified in vision transformers (ViTs), where post-pre-training and fine-tuning on new tasks can significantly degrade the model's original general abilities. For instance, a DINO ViT-Base/16 pre-trained on ImageNet-1k loses over 70% accuracy on ImageNet-1k after just 10 iterations of fine-tuning on CIFAR-100. Overcoming this stability-plasticity dilemma is crucial for enabling ViTs to continuously learn and adapt to new domains while preserving their initial knowledge. In this work, we study two new parameter-efficient fine-tuning strategies: (1)~Block Expansion, and (2) Low-rank adaptation (LoRA). Our experiments reveal that using either Block Expansion or LoRA on self-supervised pre-trained ViTs surpass fully fine-tuned ViTs in new domains while offering significantly greater parameter efficiency. Notably, we find that Block Expansion experiences only a minimal performance drop in the pre-training domain, thereby effectively mitigating catastrophic forgetting in pre-trained ViTs.</li>
</ul>

<h3>Title: Weakly Supervised Training for Hologram Verification in Identity  Documents</h3>
<ul>
<li><strong>Authors: </strong>Glen Pouliquen (1 and 2), Guillaume Chiron (1), Joseph Chazalon (2), Thierry Géraud (2), Ahmad Montaser Awal (1) ((1) IDnow AI & ML Center of Excellence, France, (2) EPITA Research Lab. (LRE), EPITA, France)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17253">https://arxiv.org/abs/2404.17253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17253">https://arxiv.org/pdf/2404.17253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17253]] Weakly Supervised Training for Hologram Verification in Identity  Documents(https://arxiv.org/abs/2404.17253)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>We propose a method to remotely verify the authenticity of Optically Variable Devices (OVDs), often referred to as ``holograms'', in identity documents. Our method processes video clips captured with smartphones under common lighting conditions, and is evaluated on two public datasets: MIDV-HOLO and MIDV-2020. Thanks to a weakly-supervised training, we optimize a feature extraction and decision pipeline which achieves a new leading performance on MIDV-HOLO, while maintaining a high recall on documents from MIDV-2020 used as attack samples. It is also the first method, to date, to effectively address the photo replacement attack task, and can be trained on either genuine samples, attack samples, or both for increased performance. By enabling to verify OVD shapes and dynamics with very little supervision, this work opens the way towards the use of massive amounts of unlabeled data to build robust remote identity document verification systems on commodity smartphones. Code is available at https://github.com/EPITAResearchLab/pouliquen.24.icdar</li>
</ul>

<h3>Title: Trinity Detector:text-assisted and attention mechanisms based spectral  fusion for diffusion generation image detection</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Song, Dengpan Ye, Yunming Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17254">https://arxiv.org/abs/2404.17254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17254">https://arxiv.org/pdf/2404.17254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17254]] Trinity Detector:text-assisted and attention mechanisms based spectral  fusion for diffusion generation image detection(https://arxiv.org/abs/2404.17254)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence Generated Content (AIGC) techniques, represented by text-to-image generation, have led to a malicious use of deep forgeries, raising concerns about the trustworthiness of multimedia content. Adapting traditional forgery detection methods to diffusion models proves challenging. Thus, this paper proposes a forgery detection method explicitly designed for diffusion models called Trinity Detector. Trinity Detector incorporates coarse-grained text features through a CLIP encoder, coherently integrating them with fine-grained artifacts in the pixel domain for comprehensive multimodal detection. To heighten sensitivity to diffusion-generated image features, a Multi-spectral Channel Attention Fusion Unit (MCAF) is designed, extracting spectral inconsistencies through adaptive fusion of diverse frequency bands and further integrating spatial co-occurrence of the two modalities. Extensive experimentation validates that our Trinity Detector method outperforms several state-of-the-art methods, our performance is competitive across all datasets and up to 17.6\% improvement in transferability in the diffusion datasets.</li>
</ul>

<h3>Title: SDFD: Building a Versatile Synthetic Face Image Dataset with Diverse  Attributes</h3>
<ul>
<li><strong>Authors: </strong>Georgia Baltsou, Ioannis Sarridis, Christos Koutlis, Symeon Papadopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17255">https://arxiv.org/abs/2404.17255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17255">https://arxiv.org/pdf/2404.17255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17255]] SDFD: Building a Versatile Synthetic Face Image Dataset with Diverse  Attributes(https://arxiv.org/abs/2404.17255)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric</a></li>
<li><strong>Abstract: </strong>AI systems rely on extensive training on large datasets to address various tasks. However, image-based systems, particularly those used for demographic attribute prediction, face significant challenges. Many current face image datasets primarily focus on demographic factors such as age, gender, and skin tone, overlooking other crucial facial attributes like hairstyle and accessories. This narrow focus limits the diversity of the data and consequently the robustness of AI systems trained on them. This work aims to address this limitation by proposing a methodology for generating synthetic face image datasets that capture a broader spectrum of facial diversity. Specifically, our approach integrates a systematic prompt formulation strategy, encompassing not only demographics and biometrics but also non-permanent traits like make-up, hairstyle, and accessories. These prompts guide a state-of-the-art text-to-image model in generating a comprehensive dataset of high-quality realistic images and can be used as an evaluation set in face analysis systems. Compared to existing datasets, our proposed dataset proves equally or more challenging in image classification tasks while being much smaller in size.</li>
</ul>

<h3>Title: 3SHNet: Boosting Image-Sentence Retrieval via Visual Semantic-Spatial  Self-Highlighting</h3>
<ul>
<li><strong>Authors: </strong>Xuri Ge, Songpei Xu, Fuhai Chen, Jie Wang, Guoxin Wang, Shan An, Joemon M. Jose</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17273">https://arxiv.org/abs/2404.17273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17273">https://arxiv.org/pdf/2404.17273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17273]] 3SHNet: Boosting Image-Sentence Retrieval via Visual Semantic-Spatial  Self-Highlighting(https://arxiv.org/abs/2404.17273)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a novel visual Semantic-Spatial Self-Highlighting Network (termed 3SHNet) for high-precision, high-efficiency and high-generalization image-sentence retrieval. 3SHNet highlights the salient identification of prominent objects and their spatial locations within the visual modality, thus allowing the integration of visual semantics-spatial interactions and maintaining independence between two modalities. This integration effectively combines object regions with the corresponding semantic and position layouts derived from segmentation to enhance the visual representation. And the modality-independence guarantees efficiency and generalization. Additionally, 3SHNet utilizes the structured contextual visual scene information from segmentation to conduct the local (region-based) or global (grid-based) guidance and achieve accurate hybrid-level retrieval. Extensive experiments conducted on MS-COCO and Flickr30K benchmarks substantiate the superior performances, inference efficiency and generalization of the proposed 3SHNet when juxtaposed with contemporary state-of-the-art methodologies. Specifically, on the larger MS-COCO 5K test set, we achieve 16.3%, 24.8%, and 18.3% improvements in terms of rSum score, respectively, compared with the state-of-the-art methods using different image representations, while maintaining optimal retrieval efficiency. Moreover, our performance on cross-dataset generalization improves by 18.6%. Data and code are available at https://github.com/XuriGe1995/3SHNet.</li>
</ul>

<h3>Title: Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact  Checking News Claims with Black-Box LLM</h3>
<ul>
<li><strong>Authors: </strong>Xuan Zhang, Wei Gao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17283">https://arxiv.org/abs/2404.17283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17283">https://arxiv.org/pdf/2404.17283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17283]] Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact  Checking News Claims with Black-Box LLM(https://arxiv.org/abs/2404.17283)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented language models have exhibited promising performance across various areas of natural language processing (NLP), including fact-critical tasks. However, due to the black-box nature of advanced large language models (LLMs) and the non-retrieval-oriented supervision signal of specific tasks, the training of retrieval model faces significant challenges under the setting of black-box LLM. We propose an approach leveraging Fine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance fact-checking on news claims by using black-box LLM. FFRR adopts a two-level strategy to gather fine-grained feedback from the LLM, which serves as a reward for optimizing the retrieval policy, by rating the retrieved documents based on the non-retrieval ground truth of the task. We evaluate our model on two public datasets for real-world news claim verification, and the results demonstrate that FFRR achieves significant improvements over strong LLM-enabled and non-LLM baselines.</li>
</ul>

<h3>Title: When to Trust LLMs: Aligning Confidence with Response Quality</h3>
<ul>
<li><strong>Authors: </strong>Shuchang Tao, Liuyi Yao, Hanxing Ding, Yuexiang Xie, Qi Cao, Fei Sun, Jinyang Gao, Huawei Shen, Bolin Ding</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17287">https://arxiv.org/abs/2404.17287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17287">https://arxiv.org/pdf/2404.17287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17287]] When to Trust LLMs: Aligning Confidence with Response Quality(https://arxiv.org/abs/2404.17287)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the success of large language models (LLMs) in natural language generation, much evidence shows that LLMs may produce incorrect or nonsensical text. This limitation highlights the importance of discerning when to trust LLMs, especially in safety-critical domains. Existing methods, which rely on verbalizing confidence to tell the reliability by inducing top-k responses and sampling-aggregating multiple responses, often fail, due to the lack of objective guidance of confidence. To address this, we propose CONfidence-Quality-ORDerpreserving alignment approach (CONQORD), leveraging reinforcement learning with a tailored dual-component reward function. This function encompasses quality reward and orderpreserving alignment reward functions. Specifically, the order-preserving reward incentivizes the model to verbalize greater confidence for responses of higher quality to align the order of confidence and quality. Experiments demonstrate that our CONQORD significantly improves the alignment performance between confidence levels and response accuracy, without causing the model to become over-cautious. Furthermore, the aligned confidence provided by CONQORD informs when to trust LLMs, and acts as a determinant for initiating the retrieval process of external knowledge. Aligning confidence with response quality ensures more transparent and reliable responses, providing better trustworthiness.</li>
</ul>

<h3>Title: Lazy Data Practices Harm Fairness Research</h3>
<ul>
<li><strong>Authors: </strong>Jan Simson, Alessandro Fabris, Christoph Kern</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17293">https://arxiv.org/abs/2404.17293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17293">https://arxiv.org/pdf/2404.17293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17293]] Lazy Data Practices Harm Fairness Research(https://arxiv.org/abs/2404.17293)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, fair</a></li>
<li><strong>Abstract: </strong>Data practices shape research and practice on fairness in machine learning (fair ML). Critical data studies offer important reflections and critiques for the responsible advancement of the field by highlighting shortcomings and proposing recommendations for improvement. In this work, we present a comprehensive analysis of fair ML datasets, demonstrating how unreflective yet common practices hinder the reach and reliability of algorithmic fairness findings. We systematically study protected information encoded in tabular datasets and their usage in 280 experiments across 142 publications. Our analyses identify three main areas of concern: (1) a \textbf{lack of representation for certain protected attributes} in both data and evaluations; (2) the widespread \textbf{exclusion of minorities} during data preprocessing; and (3) \textbf{opaque data processing} threatening the generalization of fairness research. By conducting exemplary analyses on the utilization of prominent datasets, we demonstrate how unreflective data decisions disproportionately affect minority groups, fairness metrics, and resultant model comparisons. Additionally, we identify supplementary factors such as limitations in publicly available data, privacy considerations, and a general lack of awareness, which exacerbate these challenges. To address these issues, we propose a set of recommendations for data usage in fairness research centered on transparency and responsible inclusion. This study underscores the need for a critical reevaluation of data practices in fair ML and offers directions to improve both the sourcing and usage of datasets.</li>
</ul>

<h3>Title: A Novel Spike Transformer Network for Depth Estimation from Event  Cameras via Cross-modality Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Xin Zhang, Liangxiu Han, Tam Sobeih, Lianghao Han, Darren Dancey</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17335">https://arxiv.org/abs/2404.17335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17335">https://arxiv.org/pdf/2404.17335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17335]] A Novel Spike Transformer Network for Depth Estimation from Event  Cameras via Cross-modality Knowledge Distillation(https://arxiv.org/abs/2404.17335)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Depth estimation is crucial for interpreting complex environments, especially in areas such as autonomous vehicle navigation and robotics. Nonetheless, obtaining accurate depth readings from event camera data remains a formidable challenge. Event cameras operate differently from traditional digital cameras, continuously capturing data and generating asynchronous binary spikes that encode time, location, and light intensity. Yet, the unique sampling mechanisms of event cameras render standard image based algorithms inadequate for processing spike data. This necessitates the development of innovative, spike-aware algorithms tailored for event cameras, a task compounded by the irregularity, continuity, noise, and spatial and temporal characteristics inherent in spiking data.Harnessing the strong generalization capabilities of transformer neural networks for spatiotemporal data, we propose a purely spike-driven spike transformer network for depth estimation from spiking camera data. To address performance limitations with Spiking Neural Networks (SNN), we introduce a novel single-stage cross-modality knowledge transfer framework leveraging knowledge from a large vision foundational model of artificial neural networks (ANN) (DINOv2) to enhance the performance of SNNs with limited data. Our experimental results on both synthetic and real datasets show substantial improvements over existing models, with notable gains in Absolute Relative and Square Relative errors (49% and 39.77% improvements over the benchmark model Spike-T, respectively). Besides accuracy, the proposed model also demonstrates reduced power consumptions, a critical factor for practical applications.</li>
</ul>

<h3>Title: Metronome: tracing variation in poetic meters via local sequence  alignment</h3>
<ul>
<li><strong>Authors: </strong>Ben Nagy, Artjoms Šeļa, Mirella De Sisto, Petr Plecháč</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17337">https://arxiv.org/abs/2404.17337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17337">https://arxiv.org/pdf/2404.17337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17337]] Metronome: tracing variation in poetic meters via local sequence  alignment(https://arxiv.org/abs/2404.17337)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>All poetic forms come from somewhere. Prosodic templates can be copied for generations, altered by individuals, imported from foreign traditions, or fundamentally changed under the pressures of language evolution. Yet these relationships are notoriously difficult to trace across languages and times. This paper introduces an unsupervised method for detecting structural similarities in poems using local sequence alignment. The method relies on encoding poetic texts as strings of prosodic features using a four-letter alphabet; these sequences are then aligned to derive a distance measure based on weighted symbol (mis)matches. Local alignment allows poems to be clustered according to emergent properties of their underlying prosodic patterns. We evaluate method performance on a meter recognition tasks against strong baselines and show its potential for cross-lingual and historical research using three short case studies: 1) mutations in quantitative meter in classical Latin, 2) European diffusion of the Renaissance hendecasyllable, and 3) comparative alignment of modern meters in 18--19th century Czech, German and Russian. We release an implementation of the algorithm as a Python package with an open license.</li>
</ul>

<h3>Title: Adversarial Consistency and the Uniqueness of the Adversarial Bayes  Classifier</h3>
<ul>
<li><strong>Authors: </strong>Natalie S. Frank</a></li>
<li><strong>Subjects: </strong>cs.LG, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17358">https://arxiv.org/abs/2404.17358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17358">https://arxiv.org/pdf/2404.17358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17358]] Adversarial Consistency and the Uniqueness of the Adversarial Bayes  Classifier(https://arxiv.org/abs/2404.17358)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Adversarial training is a common technique for learning robust classifiers. Prior work showed that convex surrogate losses are not statistically consistent in the adversarial context -- or in other words, a minimizing sequence of the adversarial surrogate risk will not necessarily minimize the adversarial classification error. We connect the consistency of adversarial surrogate losses to properties of minimizers to the adversarial classification risk, known as \emph{adversarial Bayes classifiers}. Specifically, under reasonable distributional assumptions, a convex loss is statistically consistent for adversarial learning iff the adversarial Bayes classifier satisfies a certain notion of uniqueness.</li>
</ul>

<h3>Title: UniRGB-IR: A Unified Framework for Visible-Infrared Downstream Tasks via  Adapter Tuning</h3>
<ul>
<li><strong>Authors: </strong>Maoxun Yuan, Bo Cui, Tianyi Zhao, Xingxing Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17360">https://arxiv.org/abs/2404.17360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17360">https://arxiv.org/pdf/2404.17360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17360]] UniRGB-IR: A Unified Framework for Visible-Infrared Downstream Tasks via  Adapter Tuning(https://arxiv.org/abs/2404.17360)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Semantic analysis on visible (RGB) and infrared (IR) images has gained attention for its ability to be more accurate and robust under low-illumination and complex weather conditions. Due to the lack of pre-trained foundation models on the large-scale infrared image datasets, existing methods prefer to design task-specific frameworks and directly fine-tune them with pre-trained foundation models on their RGB-IR semantic relevance datasets, which results in poor scalability and limited generalization. In this work, we propose a scalable and efficient framework called UniRGB-IR to unify RGB-IR downstream tasks, in which a novel adapter is developed to efficiently introduce richer RGB-IR features into the pre-trained RGB-based foundation model. Specifically, our framework consists of a vision transformer (ViT) foundation model, a Multi-modal Feature Pool (MFP) module and a Supplementary Feature Injector (SFI) module. The MFP and SFI modules cooperate with each other as an adpater to effectively complement the ViT features with the contextual multi-scale features. During training process, we freeze the entire foundation model to inherit prior knowledge and only optimize the MFP and SFI modules. Furthermore, to verify the effectiveness of our framework, we utilize the ViT-Base as the pre-trained foundation model to perform extensive experiments. Experimental results on various RGB-IR downstream tasks demonstrate that our method can achieve state-of-the-art performance. The source code and results are available at https://github.com/PoTsui99/UniRGB-IR.git.</li>
</ul>

<h3>Title: MV-VTON: Multi-View Virtual Try-On with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Haoyu Wang, Zhilu Zhang, Donglin Di, Shiliang Zhang, Wangmeng Zuo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17364">https://arxiv.org/abs/2404.17364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17364">https://arxiv.org/pdf/2404.17364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17364]] MV-VTON: Multi-View Virtual Try-On with Diffusion Models(https://arxiv.org/abs/2404.17364)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>The goal of image-based virtual try-on is to generate an image of the target person naturally wearing the given clothing. However, most existing methods solely focus on the frontal try-on using the frontal clothing. When the views of the clothing and person are significantly inconsistent, particularly when the person's view is non-frontal, the results are unsatisfactory. To address this challenge, we introduce Multi-View Virtual Try-ON (MV-VTON), which aims to reconstruct the dressing results of a person from multiple views using the given clothes. On the one hand, given that single-view clothes provide insufficient information for MV-VTON, we instead employ two images, i.e., the frontal and back views of the clothing, to encompass the complete view as much as possible. On the other hand, the diffusion models that have demonstrated superior abilities are adopted to perform our MV-VTON. In particular, we propose a view-adaptive selection method where hard-selection and soft-selection are applied to the global and local clothing feature extraction, respectively. This ensures that the clothing features are roughly fit to the person's view. Subsequently, we suggest a joint attention block to align and fuse clothing features with person features. Additionally, we collect a MV-VTON dataset, i.e., Multi-View Garment (MVG), in which each person has multiple photos with diverse views and poses. Experiments show that the proposed method not only achieves state-of-the-art results on MV-VTON task using our MVG dataset, but also has superiority on frontal-view virtual try-on task using VITON-HD and DressCode datasets. Codes and datasets will be publicly released at https://github.com/hywang2002/MV-VTON .</li>
</ul>

<h3>Title: Estimating the Robustness Radius for Randomized Smoothing with  100$\times$ Sample Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Emmanouil Seferis, Stefanos Kollias, Chih-Hong Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17371">https://arxiv.org/abs/2404.17371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17371">https://arxiv.org/pdf/2404.17371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17371]] Estimating the Robustness Radius for Randomized Smoothing with  100$\times$ Sample Efficiency(https://arxiv.org/abs/2404.17371)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Randomized smoothing (RS) has successfully been used to improve the robustness of predictions for deep neural networks (DNNs) by adding random noise to create multiple variations of an input, followed by deciding the consensus. To understand if an RS-enabled DNN is effective in the sampled input domains, it is mandatory to sample data points within the operational design domain, acquire the point-wise certificate regarding robustness radius, and compare it with pre-defined acceptance criteria. Consequently, ensuring that a point-wise robustness certificate for any given data point is obtained relatively cost-effectively is crucial. This work demonstrates that reducing the number of samples by one or two orders of magnitude can still enable the computation of a slightly smaller robustness radius (commonly ~20% radius reduction) with the same confidence. We provide the mathematical foundation for explaining the phenomenon while experimentally showing promising results on the standard CIFAR-10 and ImageNet datasets.</li>
</ul>

<h3>Title: Child Speech Recognition in Human-Robot Interaction: Problem Solved?</h3>
<ul>
<li><strong>Authors: </strong>Ruben Janssens, Eva Verhelst, Giulio Antonio Abbo, Qiaoqiao Ren, Maria Jose Pinto Bernal, Tony Belpaeme</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17394">https://arxiv.org/abs/2404.17394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17394">https://arxiv.org/pdf/2404.17394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17394]] Child Speech Recognition in Human-Robot Interaction: Problem Solved?(https://arxiv.org/abs/2404.17394)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Automated Speech Recognition shows superhuman performance for adult English speech on a range of benchmarks, but disappoints when fed children's speech. This has long sat in the way of child-robot interaction. Recent evolutions in data-driven speech recognition, including the availability of Transformer architectures and unprecedented volumes of training data, might mean a breakthrough for child speech recognition and social robot applications aimed at children. We revisit a study on child speech recognition from 2017 and show that indeed performance has increased, with newcomer OpenAI Whisper doing markedly better than leading commercial cloud services. While transcription is not perfect yet, the best model recognises 60.3% of sentences correctly barring small grammatical differences, with sub-second transcription time running on a local GPU, showing potential for usable autonomous child-robot speech interactions.</li>
</ul>

<h3>Title: Evaluations of Machine Learning Privacy Defenses are Misleading</h3>
<ul>
<li><strong>Authors: </strong>Michael Aerni, Jie Zhang, Florian Tramèr</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17399">https://arxiv.org/abs/2404.17399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17399">https://arxiv.org/pdf/2404.17399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17399]] Evaluations of Machine Learning Privacy Defenses are Misleading(https://arxiv.org/abs/2404.17399)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Empirical defenses for machine learning privacy forgo the provable guarantees of differential privacy in the hope of achieving higher utility while resisting realistic adversaries. We identify severe pitfalls in existing empirical privacy evaluations (based on membership inference attacks) that result in misleading conclusions. In particular, we show that prior evaluations fail to characterize the privacy leakage of the most vulnerable samples, use weak attacks, and avoid comparisons with practical differential privacy baselines. In 5 case studies of empirical privacy defenses, we find that prior evaluations underestimate privacy leakage by an order of magnitude. Under our stronger evaluation, none of the empirical defenses we study are competitive with a properly tuned, high-utility DP-SGD baseline (with vacuous provable guarantees).</li>
</ul>

<h3>Title: Spatial-frequency Dual-Domain Feature Fusion Network for Low-Light  Remote Sensing Image Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Zishu Yao, Guodong Fan, Jinfu Fan, Min Gan, C.L. Philip Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17400">https://arxiv.org/abs/2404.17400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17400">https://arxiv.org/pdf/2404.17400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17400]] Spatial-frequency Dual-Domain Feature Fusion Network for Low-Light  Remote Sensing Image Enhancement(https://arxiv.org/abs/2404.17400)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Low-light remote sensing images generally feature high resolution and high spatial complexity, with continuously distributed surface features in space. This continuity in scenes leads to extensive long-range correlations in spatial domains within remote sensing images. Convolutional Neural Networks, which rely on local correlations for long-distance modeling, struggle to establish long-range correlations in such images. On the other hand, transformer-based methods that focus on global information face high computational complexities when processing high-resolution remote sensing images. From another perspective, Fourier transform can compute global information without introducing a large number of parameters, enabling the network to more efficiently capture the overall image structure and establish long-range correlations. Therefore, we propose a Dual-Domain Feature Fusion Network (DFFN) for low-light remote sensing image enhancement. Specifically, this challenging task of low-light enhancement is divided into two more manageable sub-tasks: the first phase learns amplitude information to restore image brightness, and the second phase learns phase information to refine details. To facilitate information exchange between the two phases, we designed an information fusion affine block that combines data from different phases and scales. Additionally, we have constructed two dark light remote sensing datasets to address the current lack of datasets in dark light remote sensing image enhancement. Extensive evaluations show that our method outperforms existing state-of-the-art methods. The code is available at https://github.com/iijjlk/DFFN.</li>
</ul>

<h3>Title: Multi-view Image Prompted Multi-view Diffusion for Improved 3D  Generation</h3>
<ul>
<li><strong>Authors: </strong>Seungwook Kim, Yichun Shi, Kejie Li, Minsu Cho, Peng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17419">https://arxiv.org/abs/2404.17419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17419">https://arxiv.org/pdf/2404.17419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17419]] Multi-view Image Prompted Multi-view Diffusion for Improved 3D  Generation(https://arxiv.org/abs/2404.17419)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Using image as prompts for 3D generation demonstrate particularly strong performances compared to using text prompts alone, for images provide a more intuitive guidance for the 3D generation process. In this work, we delve into the potential of using multiple image prompts, instead of a single image prompt, for 3D generation. Specifically, we build on ImageDream, a novel image-prompt multi-view diffusion model, to support multi-view images as the input prompt. Our method, dubbed MultiImageDream, reveals that transitioning from a single-image prompt to multiple-image prompts enhances the performance of multi-view and 3D object generation according to various quantitative evaluation metrics and qualitative assessments. This advancement is achieved without the necessity of fine-tuning the pre-trained ImageDream multi-view diffusion model.</li>
</ul>

<h3>Title: PromptCIR: Blind Compressed Image Restoration with Prompt Learning</h3>
<ul>
<li><strong>Authors: </strong>Bingchen Li, Xin Li, Yiting Lu, Ruoyu Feng, Mengxi Guo, Shijie Zhao, Li Zhang, Zhibo Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17433">https://arxiv.org/abs/2404.17433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17433">https://arxiv.org/pdf/2404.17433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17433]] PromptCIR: Blind Compressed Image Restoration with Prompt Learning(https://arxiv.org/abs/2404.17433)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Blind Compressed Image Restoration (CIR) has garnered significant attention due to its practical applications. It aims to mitigate compression artifacts caused by unknown quality factors, particularly with JPEG codecs. Existing works on blind CIR often seek assistance from a quality factor prediction network to facilitate their network to restore compressed images. However, the predicted numerical quality factor lacks spatial information, preventing network adaptability toward image contents. Recent studies in prompt-learning-based image restoration have showcased the potential of prompts to generalize across varied degradation types and degrees. This motivated us to design a prompt-learning-based compressed image restoration network, dubbed PromptCIR, which can effectively restore images from various compress levels. Specifically, PromptCIR exploits prompts to encode compression information implicitly, where prompts directly interact with soft weights generated from image features, thus providing dynamic content-aware and distortion-aware guidance for the restoration process. The light-weight prompts enable our method to adapt to different compression levels, while introducing minimal parameter overhead. Overall, PromptCIR leverages the powerful transformer-based backbone with the dynamic prompt module to proficiently handle blind CIR tasks, winning first place in the NTIRE 2024 challenge of blind compressed image enhancement track. Extensive experiments have validated the effectiveness of our proposed PromptCIR. The code is available at https://github.com/lbc12345/PromptCIR-NTIRE24.</li>
</ul>

<h3>Title: Domain Adaptive and Fine-grained Anomaly Detection for Single-cell  Sequencing Data and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Kaichen Xu, Yueyang Ding, Suyang Hou, Weiqiang Zhan, Nisang Chen, Jun Wang, Xiaobo Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17454">https://arxiv.org/abs/2404.17454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17454">https://arxiv.org/pdf/2404.17454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17454]] Domain Adaptive and Fine-grained Anomaly Detection for Single-cell  Sequencing Data and Beyond(https://arxiv.org/abs/2404.17454)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Fined-grained anomalous cell detection from affected tissues is critical for clinical diagnosis and pathological research. Single-cell sequencing data provide unprecedented opportunities for this task. However, current anomaly detection methods struggle to handle domain shifts prevalent in multi-sample and multi-domain single-cell sequencing data, leading to suboptimal performance. Moreover, these methods fall short of distinguishing anomalous cells into pathologically distinct subtypes. In response, we propose ACSleuth, a novel, reconstruction deviation-guided generative framework that integrates the detection, domain adaptation, and fine-grained annotating of anomalous cells into a methodologically cohesive workflow. Notably, we present the first theoretical analysis of using reconstruction deviations output by generative models for anomaly detection in lieu of domain shifts. This analysis informs us to develop a novel and superior maximum mean discrepancy-based anomaly scorer in ACSleuth. Extensive benchmarks over various single-cell data and other types of tabular data demonstrate ACSleuth's superiority over the state-of-the-art methods in identifying and subtyping anomalies in multi-sample and multi-domain contexts. Our code is available at https://github.com/Catchxu/ACsleuth.</li>
</ul>

<h3>Title: Ruffle&Riley: Insights from Designing and Evaluating a Large Language  Model-Based Conversational Tutoring System</h3>
<ul>
<li><strong>Authors: </strong>Robin Schmucker, Meng Xia, Amos Azaria, Tom Mitchell</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17460">https://arxiv.org/abs/2404.17460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17460">https://arxiv.org/pdf/2404.17460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17460]] Ruffle&Riley: Insights from Designing and Evaluating a Large Language  Model-Based Conversational Tutoring System(https://arxiv.org/abs/2404.17460)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conversational tutoring systems (CTSs) offer learning experiences through interactions based on natural language. They are recognized for promoting cognitive engagement and improving learning outcomes, especially in reasoning tasks. Nonetheless, the cost associated with authoring CTS content is a major obstacle to widespread adoption and to research on effective instructional design. In this paper, we discuss and evaluate a novel type of CTS that leverages recent advances in large language models (LLMs) in two ways: First, the system enables AI-assisted content authoring by inducing an easily editable tutoring script automatically from a lesson text. Second, the system automates the script orchestration in a learning-by-teaching format via two LLM-based agents (Ruffle&Riley) acting as a student and a professor. The system allows for free-form conversations that follow the ITS-typical inner and outer loop structure. We evaluate Ruffle&Riley's ability to support biology lessons in two between-subject online user studies (N = 200) comparing the system to simpler QA chatbots and reading activity. Analyzing system usage patterns, pre/post-test scores and user experience surveys, we find that Ruffle&Riley users report high levels of engagement, understanding and perceive the offered support as helpful. Even though Ruffle&Riley users require more time to complete the activity, we did not find significant differences in short-term learning gains over the reading activity. Our system architecture and user study provide various insights for designers of future CTSs. We further open-source our system to support ongoing research on effective instructional design of LLM-based learning technologies.</li>
</ul>

<h3>Title: TextGaze: Gaze-Controllable Face Generation with Natural Language</h3>
<ul>
<li><strong>Authors: </strong>Hengfei Wang, Zhongqun Zhang, Yihua Cheng, Hyung Jin Chang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17486">https://arxiv.org/abs/2404.17486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17486">https://arxiv.org/pdf/2404.17486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17486]] TextGaze: Gaze-Controllable Face Generation with Natural Language(https://arxiv.org/abs/2404.17486)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Generating face image with specific gaze information has attracted considerable attention. Existing approaches typically input gaze values directly for face generation, which is unnatural and requires annotated gaze datasets for training, thereby limiting its application. In this paper, we present a novel gaze-controllable face generation task. Our approach inputs textual descriptions that describe human gaze and head behavior and generates corresponding face images. Our work first introduces a text-of-gaze dataset containing over 90k text descriptions spanning a dense distribution of gaze and head poses. We further propose a gaze-controllable text-to-face method. Our method contains a sketch-conditioned face diffusion module and a model-based sketch diffusion module. We define a face sketch based on facial landmarks and eye segmentation map. The face diffusion module generates face images from the face sketch, and the sketch diffusion module employs a 3D face model to generate face sketch from text description. Experiments on the FFHQ dataset show the effectiveness of our method. We will release our dataset and code for future research.</li>
</ul>

<h3>Title: Merchants of Vulnerabilities: How Bug Bounty Programs Benefit Software  Vendors</h3>
<ul>
<li><strong>Authors: </strong>Esther Gal-Or, Muhammad Zia Hydari, Rahul Telang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.GT, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17497">https://arxiv.org/abs/2404.17497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17497">https://arxiv.org/pdf/2404.17497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17497]] Merchants of Vulnerabilities: How Bug Bounty Programs Benefit Software  Vendors(https://arxiv.org/abs/2404.17497)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Software vulnerabilities enable exploitation by malicious hackers, compromising systems and data security. This paper examines bug bounty programs (BBPs) that incentivize ethical hackers to discover and responsibly disclose vulnerabilities to software vendors. Using game-theoretic models, we capture the strategic interactions between software vendors, ethical hackers, and malicious hackers. First, our analysis shows that software vendors can increase expected profits by participating in BBPs, explaining their growing adoption and the success of BBP platforms. Second, we find that vendors with BBPs will release software earlier, albeit with more potential vulnerabilities, as BBPs enable coordinated vulnerability disclosure and mitigation. Third, the optimal number of ethical hackers to invite to a BBP depends solely on the expected number of malicious hackers seeking exploitation. This optimal number of ethical hackers is lower than but increases with the expected malicious hacker count. Finally, higher bounties incentivize ethical hackers to exert more effort, thereby increasing the probability that they will discover severe vulnerabilities first while reducing the success probability of malicious hackers. These findings highlight BBPs' potential benefits for vendors beyond profitability. Earlier software releases are enabled by managing risks through coordinated disclosure. As cybersecurity threats evolve, BBP adoption will likely gain momentum, providing vendors with a valuable tool for enhancing security posture and stakeholder trust. Moreover, BBPs envelop vulnerability identification and disclosure into new market relationships and transactions, impacting software vendors' incentives regarding product security choices like release timing.</li>
</ul>

<h3>Title: Inhomogeneous illuminated image enhancement under extremely low  visibility condition</h3>
<ul>
<li><strong>Authors: </strong>Libang Chen, Yikun Liu, Jianying Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.optics</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17503">https://arxiv.org/abs/2404.17503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17503">https://arxiv.org/pdf/2404.17503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17503]] Inhomogeneous illuminated image enhancement under extremely low  visibility condition(https://arxiv.org/abs/2404.17503)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Imaging through fog significantly impacts fields such as object detection and recognition. In conditions of extremely low visibility, essential image information can be obscured, rendering standard extraction methods ineffective. Traditional digital processing techniques, such as histogram stretching, aim to mitigate fog effects by enhancing object light contrast diminished by atmospheric scattering. However, these methods often experience reduce effectiveness under inhomogeneous illumination. This paper introduces a novel approach that adaptively filters background illumination under extremely low visibility and preserve only the essential signal information. Additionally, we employ a visual optimization strategy based on image gradients to eliminate grayscale banding. Finally, the image is transformed to achieve high contrast and maintain fidelity to the original information through maximum histogram equalization. Our proposed method significantly enhances signal clarity in conditions of extremely low visibility and outperforms existing algorithms.</li>
</ul>

<h3>Title: Bridging the Fairness Divide: Achieving Group and Individual Fairness in  Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Duna Zhan, Dongliang Guo, Pengsheng Ji, Sheng Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17511">https://arxiv.org/abs/2404.17511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17511">https://arxiv.org/pdf/2404.17511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17511]] Bridging the Fairness Divide: Achieving Group and Individual Fairness in  Graph Neural Networks(https://arxiv.org/abs/2404.17511)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) have emerged as a powerful tool for analyzing and learning from complex data structured as graphs, demonstrating remarkable effectiveness in various applications, such as social network analysis, recommendation systems, and drug discovery. However, despite their impressive performance, the fairness problem has increasingly gained attention as a crucial aspect to consider. Existing research in graph learning focuses on either group fairness or individual fairness. However, since each concept provides unique insights into fairness from distinct perspectives, integrating them into a fair graph neural network system is crucial. To the best of our knowledge, no study has yet to comprehensively tackle both individual and group fairness simultaneously. In this paper, we propose a new concept of individual fairness within groups and a novel framework named Fairness for Group and Individual (FairGI), which considers both group fairness and individual fairness within groups in the context of graph learning. FairGI employs the similarity matrix of individuals to achieve individual fairness within groups, while leveraging adversarial learning to address group fairness in terms of both Equal Opportunity and Statistical Parity. The experimental results demonstrate that our approach not only outperforms other state-of-the-art models in terms of group fairness and individual fairness within groups, but also exhibits excellent performance in population-level individual fairness, while maintaining comparable prediction accuracy.</li>
</ul>

<h3>Title: A Comprehensive Evaluation on Event Reasoning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhengwei Tao, Zhi Jin, Yifan Zhang, Xiancai Chen, Xiaoying Bai, Yue Fang, Haiyan Zhao, Jia Li, Chongyang Tao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17513">https://arxiv.org/abs/2404.17513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17513">https://arxiv.org/pdf/2404.17513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17513]] A Comprehensive Evaluation on Event Reasoning of Large Language Models(https://arxiv.org/abs/2404.17513)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Event reasoning is a fundamental ability that underlies many applications. It requires event schema knowledge to perform global reasoning and needs to deal with the diversity of the inter-event relations and the reasoning paradigms. How well LLMs accomplish event reasoning on various relations and reasoning paradigms remains unknown. To mitigate this disparity, we comprehensively evaluate the abilities of event reasoning of LLMs. We introduce a novel benchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of evaluation of schema and instance and is comprehensive in relations and reasoning paradigms. We conduct extensive experiments on EV2. We find that LLMs have abilities to accomplish event reasoning but their performances are far from satisfactory. We also notice the imbalance of event reasoning abilities in LLMs. Besides, LLMs have event schema knowledge, however, they're not aligned with humans on how to utilize the knowledge. Based on these findings, we introduce two methods to guide the LLMs to utilize the event schema knowledge. Both methods achieve improvements.</li>
</ul>

<h3>Title: Large Language Model Agent as a Mechanical Designer</h3>
<ul>
<li><strong>Authors: </strong>Yayati Jadhav, Amir Barati Farimani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17525">https://arxiv.org/abs/2404.17525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17525">https://arxiv.org/pdf/2404.17525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17525]] Large Language Model Agent as a Mechanical Designer(https://arxiv.org/abs/2404.17525)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conventional mechanical design paradigms rely on experts systematically refining concepts through experience-guided modification and FEA to meet specific requirements. However, this approach can be time-consuming and heavily dependent on prior knowledge and experience. While numerous machine learning models have been developed to streamline this intensive and expert-driven iterative process, these methods typically demand extensive training data and considerable computational resources. Furthermore, methods based on deep learning are usually restricted to the specific domains and tasks for which they were trained, limiting their applicability across different tasks. This creates a trade-off between the efficiency of automation and the demand for resources. In this study, we present a novel approach that integrates pre-trained LLMs with a FEM module. The FEM module evaluates each design and provides essential feedback, guiding the LLMs to continuously learn, plan, generate, and optimize designs without the need for domain-specific training. We demonstrate the effectiveness of our proposed framework in managing the iterative optimization of truss structures, showcasing its capability to reason about and refine designs according to structured feedback and criteria. Our results reveal that these LLM-based agents can successfully generate truss designs that comply with natural language specifications with a success rate of up to 90%, which varies according to the applied constraints. By employing prompt-based optimization techniques we show that LLM based agents exhibit optimization behavior when provided with solution-score pairs to iteratively refine designs to meet specifications. This ability of LLM agents to produce viable designs and optimize them based on their inherent reasoning capabilities highlights their potential to develop and implement effective design strategies autonomously.</li>
</ul>

<h3>Title: Exploring the Distinctiveness and Fidelity of the Descriptions Generated  by Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Huang, Zihan Wu, Chongyang Gao, Jiawei Peng, Xu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17534">https://arxiv.org/abs/2404.17534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17534">https://arxiv.org/pdf/2404.17534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17534]] Exploring the Distinctiveness and Fidelity of the Descriptions Generated  by Large Vision-Language Models(https://arxiv.org/abs/2404.17534)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) are gaining traction for their remarkable ability to process and integrate visual and textual data. Despite their popularity, the capacity of LVLMs to generate precise, fine-grained textual descriptions has not been fully explored. This study addresses this gap by focusing on \textit{distinctiveness} and \textit{fidelity}, assessing how models like Open-Flamingo, IDEFICS, and MiniGPT-4 can distinguish between similar objects and accurately describe visual features. We proposed the Textual Retrieval-Augmented Classification (TRAC) framework, which, by leveraging its generative capabilities, allows us to delve deeper into analyzing fine-grained visual description generation. This research provides valuable insights into the generation quality of LVLMs, enhancing the understanding of multimodal language models. Notably, MiniGPT-4 stands out for its better ability to generate fine-grained descriptions, outperforming the other two models in this aspect. The code is provided at \url{https://anonymous.4open.science/r/Explore_FGVDs-E277}.</li>
</ul>

<h3>Title: Probabilistic Inference in Language Models via Twisted Sequential Monte  Carlo</h3>
<ul>
<li><strong>Authors: </strong>Stephen Zhao, Rob Brekelmans, Alireza Makhzani, Roger Grosse</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17546">https://arxiv.org/abs/2404.17546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17546">https://arxiv.org/pdf/2404.17546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17546]] Probabilistic Inference in Language Models via Twisted Sequential Monte  Carlo(https://arxiv.org/abs/2404.17546)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Numerous capability and safety techniques of Large Language Models (LLMs), including RLHF, automated red-teaming, prompt engineering, and infilling, can be cast as sampling from an unnormalized target distribution defined by a given reward or potential function over the full sequence. In this work, we leverage the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic inference problems. In particular, we use learned twist functions to estimate the expected future value of the potential at each timestep, which enables us to focus inference-time computation on promising partial sequences. We propose a novel contrastive method for learning the twist functions, and establish connections with the rich literature of soft reinforcement learning. As a complementary application of our twisted SMC framework, we present methods for evaluating the accuracy of language model inference techniques using novel bidirectional SMC bounds on the log partition function. These bounds can be used to estimate the KL divergence between the inference and target distributions in both directions. We apply our inference evaluation techniques to show that twisted SMC is effective for sampling undesirable outputs from a pretrained model (a useful component of harmlessness training and automated red-teaming), generating reviews with varied sentiment, and performing infilling tasks.</li>
</ul>

<h3>Title: ChangeBind: A Hybrid Change Encoder for Remote Sensing Change Detection</h3>
<ul>
<li><strong>Authors: </strong>Mubashir Noman, Mustansar Fiaz, Hisham Cholakkal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17565">https://arxiv.org/abs/2404.17565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17565">https://arxiv.org/pdf/2404.17565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17565]] ChangeBind: A Hybrid Change Encoder for Remote Sensing Change Detection(https://arxiv.org/abs/2404.17565)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Change detection (CD) is a fundamental task in remote sensing (RS) which aims to detect the semantic changes between the same geographical regions at different time stamps. Existing convolutional neural networks (CNNs) based approaches often struggle to capture long-range dependencies. Whereas recent transformer-based methods are prone to the dominant global representation and may limit their capabilities to capture the subtle change regions due to the complexity of the objects in the scene. To address these limitations, we propose an effective Siamese-based framework to encode the semantic changes occurring in the bi-temporal RS images. The main focus of our design is to introduce a change encoder that leverages local and global feature representations to capture both subtle and large change feature information from multi-scale features to precisely estimate the change regions. Our experimental study on two challenging CD datasets reveals the merits of our approach and obtains state-of-the-art performance.</li>
</ul>

<h3>Title: MaPa: Text-driven Photorealistic Material Painting for 3D Shapes</h3>
<ul>
<li><strong>Authors: </strong>Shangzhan Zhang, Sida Peng, Tao Xu, Yuanbo Yang, Tianrun Chen, Nan Xue, Yujun Shen, Hujun Bao, Ruizhen Hu, Xiaowei Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17569">https://arxiv.org/abs/2404.17569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17569">https://arxiv.org/pdf/2404.17569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17569]] MaPa: Text-driven Photorealistic Material Painting for 3D Shapes(https://arxiv.org/abs/2404.17569)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper aims to generate materials for 3D meshes from text descriptions. Unlike existing methods that synthesize texture maps, we propose to generate segment-wise procedural material graphs as the appearance representation, which supports high-quality rendering and provides substantial flexibility in editing. Instead of relying on extensive paired data, i.e., 3D meshes with material graphs and corresponding text descriptions, to train a material graph generative model, we propose to leverage the pre-trained 2D diffusion model as a bridge to connect the text and material graphs. Specifically, our approach decomposes a shape into a set of segments and designs a segment-controlled diffusion model to synthesize 2D images that are aligned with mesh parts. Based on generated images, we initialize parameters of material graphs and fine-tune them through the differentiable rendering module to produce materials in accordance with the textual description. Extensive experiments demonstrate the superior performance of our framework in photorealism, resolution, and editability over existing methods. Project page: https://zhanghe3z.github.io/MaPa/</li>
</ul>

<h3>Title: Tunnel Try-on: Excavating Spatial-temporal Tunnels for High-quality  Virtual Try-on in Videos</h3>
<ul>
<li><strong>Authors: </strong>Zhengze Xu, Mengting Chen, Zhao Wang, Linyu Xing, Zhonghua Zhai, Nong Sang, Jinsong Lan, Shuai Xiao, Changxin Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2404.17571">https://arxiv.org/abs/2404.17571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2404.17571">https://arxiv.org/pdf/2404.17571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2404.17571]] Tunnel Try-on: Excavating Spatial-temporal Tunnels for High-quality  Virtual Try-on in Videos(https://arxiv.org/abs/2404.17571)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Video try-on is a challenging task and has not been well tackled in previous works. The main obstacle lies in preserving the details of the clothing and modeling the coherent motions simultaneously. Faced with those difficulties, we address video try-on by proposing a diffusion-based framework named "Tunnel Try-on." The core idea is excavating a "focus tunnel" in the input video that gives close-up shots around the clothing regions. We zoom in on the region in the tunnel to better preserve the fine details of the clothing. To generate coherent motions, we first leverage the Kalman filter to construct smooth crops in the focus tunnel and inject the position embedding of the tunnel into attention layers to improve the continuity of the generated videos. In addition, we develop an environment encoder to extract the context information outside the tunnels as supplementary cues. Equipped with these techniques, Tunnel Try-on keeps the fine details of the clothing and synthesizes stable and smooth videos. Demonstrating significant advancements, Tunnel Try-on could be regarded as the first attempt toward the commercial-level application of virtual try-on in videos.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
