<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: ZK-IMG: Attested Images via Zero-Knowledge Proofs to Fight Disinformation. (arXiv:2211.04775v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04775">http://arxiv.org/abs/2211.04775</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04775] ZK-IMG: Attested Images via Zero-Knowledge Proofs to Fight Disinformation](http://arxiv.org/abs/2211.04775)</code></li>
<li>Summary: <p>Over the past few years, AI methods of generating images have been increasing
in capabilities, with recent breakthroughs enabling high-resolution,
photorealistic "deepfakes" (artificially generated images with the purpose of
misinformation or harm). The rise of deepfakes has potential for social
disruption. Recent work has proposed using ZK-SNARKs (zero-knowledge succinct
non-interactive argument of knowledge) and attested cameras to verify that
images were taken by a camera. ZK-SNARKs allow verification of image
transformations non-interactively (i.e., post-hoc) with only standard
cryptographic hardness assumptions. Unfortunately, this work does not preserve
input privacy, is impractically slow (working only on 128$\times$128 images),
and/or requires custom cryptographic arguments.
</p></li>
</ul>

<p>To address these issues, we present zk-img, a library for attesting to image
transformations while hiding the pre-transformed image. zk-img allows
application developers to specify high level image transformations. Then,
zk-img will transparently compile these specifications to ZK-SNARKs. To hide
the input or output images, zk-img will compute the hash of the images inside
the ZK-SNARK. We further propose methods of chaining image transformations
securely and privately, which allows for arbitrarily many transformations. By
combining these optimizations, zk-img is the first system to be able to
transform HD images on commodity hardware, securely and privately.
</p>

<h3>Title: A Capability-based Distributed Authorization System to Enforce Context-aware Permission Sequences. (arXiv:2211.04980v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04980">http://arxiv.org/abs/2211.04980</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04980] A Capability-based Distributed Authorization System to Enforce Context-aware Permission Sequences](http://arxiv.org/abs/2211.04980)</code></li>
<li>Summary: <p>Controlled sharing is fundamental to distributed systems. We consider a
capability-based distributed authorization system where a client receives
capabilities (access tokens) from an authorization server to access the
resources of resource servers. Capability-based authorization systems have been
widely used on the Web, in mobile applications and other distributed systems.
</p></li>
</ul>

<p>A common requirement of such systems is that the user uses tokens of multiple
servers in a particular order. A related requirement is the token may be used
if certain environmental conditions hold. We introduce a secure
capability-based system that supports "permission sequence" and "context". This
allows a finite sequence of permissions to be enforced, each with their own
specific context. We prove the safety property of this system for these
conditions and integrate the system into OAuth 2.0 with proof-of-possession
tokens. We evaluate our implementation and compare it with plain OAuth with
respect to the average time for obtaining an authorization token and acquiring
access to the resource.
</p>

<h2>security</h2>
<h3>Title: Building Resilience in Cybersecurity -- An Artificial Lab Approach. (arXiv:2211.04762v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04762">http://arxiv.org/abs/2211.04762</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04762] Building Resilience in Cybersecurity -- An Artificial Lab Approach](http://arxiv.org/abs/2211.04762)</code></li>
<li>Summary: <p>Based on classical contagion models we introduce an artificial cyber lab: the
digital twin of a complex cyber system in which possible cyber resilience
measures may be implemented and tested. Using the lab, in numerical case
studies, we identify two classes of measures to control systemic cyber risks:
security- and topology-based interventions. We discuss the implications of our
findings on selected real-world cybersecurity measures currently applied in the
insurance and regulation practice or under discussion for future cyber risk
control. To this end, we provide a brief overview of the current cybersecurity
regulation and emphasize the role of insurance companies as private regulators.
Moreover, from an insurance point of view, we provide first attempts to design
systemic cyber risk obligations and to measure the systemic risk contribution
of individual policyholders.
</p></li>
</ul>

<h3>Title: DSCOT: An NFT-Based Blockchain Architecture for the Authentication of IoT-Enabled Smart Devices in Smart Cities. (arXiv:2211.04803v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04803">http://arxiv.org/abs/2211.04803</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04803] DSCOT: An NFT-Based Blockchain Architecture for the Authentication of IoT-Enabled Smart Devices in Smart Cities](http://arxiv.org/abs/2211.04803)</code></li>
<li>Summary: <p>Smart city architecture brings all the underlying architectures, i.e.,
Internet of Things (IoT), Cyber-Physical Systems (CPSs), Internet of
Cyber-Physical Things (IoCPT), and Internet of Everything (IoE), together to
work as a system under its umbrella. The goal of smart city architecture is to
come up with a solution that may integrate all the real-time response
applications. However, the cyber-physical space poses threats that can
jeopardize the working of a smart city where all the data belonging to people,
systems, and processes will be at risk. Various architectures based on
centralized and distributed mechanisms support smart cities; however, the
security concerns regarding traceability, scalability, security services,
platform assistance, and resource management persist. In this paper, private
blockchain-based architecture Decentralized Smart City of Things (DSCoT) is
proposed. It actively utilizes fog computing for all the users and smart
devices connected to a fog node in a particular management system in a smart
city, i.e., a smart house or hospital, etc. Non-fungible tokens (NFTs) have
been utilized for representation to define smart device attributes. NFTs in the
proposed DSCoT architecture provide devices and user authentication (IoT)
functionality. DSCoT has been designed to provide a smart city solution that
ensures robust security features such as Confidentiality, Integrity,
Availability (CIA), and authorization by defining new attributes and functions
for Owner, User, Fog, and IoT devices authentication. The evaluation of the
proposed functions and components in terms of Gas consumption and time
complexity has shown promising results. Comparatively, the Gas consumption for
minting DSCoT NFT showed approximately 27%, and a DSCoT approve() was
approximately 11% more efficient than the PUF-based NFT solution.
</p></li>
</ul>

<h3>Title: Detection of Sparse Anomalies in High-Dimensional Network Telescope Signals. (arXiv:2211.04918v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04918">http://arxiv.org/abs/2211.04918</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04918] Detection of Sparse Anomalies in High-Dimensional Network Telescope Signals](http://arxiv.org/abs/2211.04918)</code></li>
<li>Summary: <p>Network operators and system administrators are increasingly overwhelmed with
incessant cyber-security threats ranging from malicious network reconnaissance
to attacks such as distributed denial of service and data breaches. A large
number of these attacks could be prevented if the network operators were better
equipped with threat intelligence information that would allow them to block or
throttle nefarious scanning activities. Network telescopes or "darknets" offer
a unique window into observing Internet-wide scanners and other malicious
entities, and they could offer early warning signals to operators that would be
critical for infrastructure protection and/or attack mitigation. A network
telescope consists of unused or "dark" IP spaces that serve no users, and
solely passively observes any Internet traffic destined to the "telescope
sensor" in an attempt to record ubiquitous network scanners, malware that
forage for vulnerable devices, and other dubious activities. Hence, monitoring
network telescopes for timely detection of coordinated and heavy scanning
activities is an important, albeit challenging, task. The challenges mainly
arise due to the non-stationarity and the dynamic nature of Internet traffic
and, more importantly, the fact that one needs to monitor high-dimensional
signals (e.g., all TCP/UDP ports) to search for "sparse" anomalies. We propose
statistical methods to address both challenges in an efficient and "online"
manner; our work is validated both with synthetic data as well as real-world
data from a large network telescope.
</p></li>
</ul>

<h3>Title: Supporting AI/ML Security Workers through an Adversarial Techniques, Tools, and Common Knowledge (AI/ML ATT&amp;CK) Framework. (arXiv:2211.05075v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.05075">http://arxiv.org/abs/2211.05075</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.05075] Supporting AI/ML Security Workers through an Adversarial Techniques, Tools, and Common Knowledge (AI/ML ATT&amp;CK) Framework](http://arxiv.org/abs/2211.05075)</code></li>
<li>Summary: <p>This paper focuses on supporting AI/ML Security Workers -- professionals
involved in the development and deployment of secure AI-enabled software
systems. It presents AI/ML Adversarial Techniques, Tools, and Common Knowledge
(AI/ML ATT&amp;CK) framework to enable AI/ML Security Workers intuitively to
explore offensive and defensive tactics.
</p></li>
</ul>

<h3>Title: Interpretable Deep Reinforcement Learning for Green Security Games with Real-Time Information. (arXiv:2211.04987v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04987">http://arxiv.org/abs/2211.04987</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04987] Interpretable Deep Reinforcement Learning for Green Security Games with Real-Time Information](http://arxiv.org/abs/2211.04987)</code></li>
<li>Summary: <p>Green Security Games with real-time information (GSG-I) add the real-time
information about the agents' movement to the typical GSG formulation. Prior
works on GSG-I have used deep reinforcement learning (DRL) to learn the best
policy for the agent in such an environment without any need to store the huge
number of state representations for GSG-I. However, the decision-making process
of DRL methods is largely opaque, which results in a lack of trust in their
predictions. To tackle this issue, we present an interpretable DRL method for
GSG-I that generates visualization to explain the decisions taken by the DRL
algorithm. We also show that this approach performs better and works well with
a simpler training regimen compared to the existing method.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Domain-incremental Cardiac Image Segmentation with Style-oriented Replay and Domain-sensitive Feature Whitening. (arXiv:2211.04862v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04862">http://arxiv.org/abs/2211.04862</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04862] Domain-incremental Cardiac Image Segmentation with Style-oriented Replay and Domain-sensitive Feature Whitening](http://arxiv.org/abs/2211.04862)</code></li>
<li>Summary: <p>Contemporary methods have shown promising results on cardiac image
segmentation, but merely in static learning, i.e., optimizing the network once
for all, ignoring potential needs for model updating. In real-world scenarios,
new data continues to be gathered from multiple institutions over time and new
demands keep growing to pursue more satisfying performance. The desired model
should incrementally learn from each incoming dataset and progressively update
with improved functionality as time goes by. As the datasets sequentially
delivered from multiple sites are normally heterogenous with domain
discrepancy, each updated model should not catastrophically forget previously
learned domains while well generalizing to currently arrived domains or even
unseen domains. In medical scenarios, this is particularly challenging as
accessing or storing past data is commonly not allowed due to data privacy. To
this end, we propose a novel domain-incremental learning framework to recover
past domain inputs first and then regularly replay them during model
optimization. Particularly, we first present a style-oriented replay module to
enable structure-realistic and memory-efficient reproduction of past data, and
then incorporate the replayed past data to jointly optimize the model with
current data to alleviate catastrophic forgetting. During optimization, we
additionally perform domain-sensitive feature whitening to suppress model's
dependency on features that are sensitive to domain changes (e.g.,
domain-distinctive style features) to assist domain-invariant feature
exploration and gradually improve the generalization performance of the
network. We have extensively evaluated our approach with the M&amp;Ms Dataset in
single-domain and compound-domain incremental learning settings with improved
performance over other comparison approaches.
</p></li>
</ul>

<h3>Title: Accountable and Explainable Methods for Complex Reasoning over Text. (arXiv:2211.04946v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04946">http://arxiv.org/abs/2211.04946</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04946] Accountable and Explainable Methods for Complex Reasoning over Text](http://arxiv.org/abs/2211.04946)</code></li>
<li>Summary: <p>A major concern of Machine Learning (ML) models is their opacity. They are
deployed in an increasing number of applications where they often operate as
black boxes that do not provide explanations for their predictions. Among
others, the potential harms associated with the lack of understanding of the
models' rationales include privacy violations, adversarial manipulations, and
unfair discrimination. As a result, the accountability and transparency of ML
models have been posed as critical desiderata by works in policy and law,
philosophy, and computer science.
</p></li>
</ul>

<p>In computer science, the decision-making process of ML models has been
studied by developing accountability and transparency methods. Accountability
methods, such as adversarial attacks and diagnostic datasets, expose
vulnerabilities of ML models that could lead to malicious manipulations or
systematic faults in their predictions. Transparency methods explain the
rationales behind models' predictions gaining the trust of relevant
stakeholders and potentially uncovering mistakes and unfairness in models'
decisions. To this end, transparency methods have to meet accountability
requirements as well, e.g., being robust and faithful to the underlying
rationales of a model.
</p>
<p>This thesis presents my research that expands our collective knowledge in the
areas of accountability and transparency of ML models developed for complex
reasoning tasks over text.
</p>

<h3>Title: Directional Privacy for Deep Learning. (arXiv:2211.04686v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04686">http://arxiv.org/abs/2211.04686</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04686] Directional Privacy for Deep Learning](http://arxiv.org/abs/2211.04686)</code></li>
<li>Summary: <p>Differentially Private Stochastic Gradient Descent (DP-SGD) is a key method
for applying privacy in the training of deep learning models. This applies
isotropic Gaussian noise to gradients during training, which can perturb these
gradients in any direction, damaging utility. Metric DP, however, can provide
alternative mechanisms based on arbitrary metrics that might be more suitable.
In this paper we apply \textit{directional privacy}, via a mechanism based on
the von Mises-Fisher (VMF) distribution, to perturb gradients in terms of
\textit{angular distance} so that gradient direction is broadly preserved. We
show that this provides $\epsilon d$-privacy for deep learning training, rather
than the $(\epsilon, \delta)$-privacy of the Gaussian mechanism; and that
experimentally, on key datasets, the VMF mechanism can outperform the Gaussian
in the utility-privacy trade-off.
</p></li>
</ul>

<h3>Title: Harpocrates: Privacy-Preserving and Immutable Audit Log for Sensitive Data Operations. (arXiv:2211.04741v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04741">http://arxiv.org/abs/2211.04741</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04741] Harpocrates: Privacy-Preserving and Immutable Audit Log for Sensitive Data Operations](http://arxiv.org/abs/2211.04741)</code></li>
<li>Summary: <p>The audit log is a crucial component to monitor fine-grained operations over
sensitive data (e.g., personal, health) for security inspection and assurance.
Since such data operations can be highly sensitive, it is vital to ensure that
the audit log achieves not only validity and immutability, but also
confidentiality against active threats to standard data regulations (e.g.,
HIPAA) compliance. Despite its critical needs, state-of-the-art
privacy-preserving audit log schemes (e.g., Ghostor (NSDI '20), Calypso (VLDB
'19)) do not fully obtain a high level of privacy, integrity, and immutability
simultaneously, in which certain information (e.g., user identities) is still
leaked in the log.
</p></li>
</ul>

<p>In this paper, we propose Harpocrates, a new privacy-preserving and immutable
audit log scheme. Harpocrates permits data store, share, and access operations
to be recorded in the audit log without leaking sensitive information (e.g.,
data identifier, user identity), while permitting the validity of data
operations to be publicly verifiable. Harpocrates makes use of blockchain
techniques to achieve immutability and avoid a single point of failure, while
cryptographic zero-knowledge proofs are harnessed for confidentiality and
public verifiability. We analyze the security of our proposed technique and
prove that it achieves non-malleability and indistinguishability. We fully
implemented Harpocrates and evaluated its performance on a real blockchain
system (i.e., Hyperledger Fabric) deployed on a commodity platform (i.e.,
Amazon EC2). Experimental results demonstrated that Harpocrates is highly
scalable and achieves practical performance.
</p>

<h3>Title: Almost Tight Error Bounds on Differentially Private Continual Counting. (arXiv:2211.05006v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.05006">http://arxiv.org/abs/2211.05006</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.05006] Almost Tight Error Bounds on Differentially Private Continual Counting](http://arxiv.org/abs/2211.05006)</code></li>
<li>Summary: <p>The first large-scale deployment of private federated learning uses
differentially private counting in the continual release model as a subroutine
(Google AI blog titled "Federated Learning with Formal Differential Privacy
Guarantees"). In this case, a concrete bound on the error is very relevant to
reduce the privacy parameter. The standard mechanism for continual counting is
the binary mechanism. We present a novel mechanism and show that its mean
squared error is both asymptotically optimal and a factor 10 smaller than the
error of the binary mechanism. We also show that the constants in our analysis
are almost tight by giving non-asymptotic lower and upper bounds that differ
only in the constants of lower-order terms. Our algorithm is a matrix mechanism
for the counting matrix and takes constant time per release. We also use our
explicit factorization of the counting matrix to give an upper bound on the
excess risk of the private learning algorithm of Denisov et al. (NeurIPS 2022).
Our lower bound for any continual counting mechanism is the first tight lower
bound on continual counting under approximate differential privacy. It is
achieved using a new lower bound on a certain factorization norm, denoted by
$\gamma_F(\cdot)$, in terms of the singular values of the matrix. In
particular, we show that for any complex matrix, $A \in \mathbb{C}^{m \times
n}$, [ \gamma_F(A) \geq \frac{1}{\sqrt{m}}\|A\|_1, ] where $\|\cdot \|$
denotes the Schatten-1 norm.
</p></li>
</ul>

<p>We believe this technique will be useful in proving lower bounds for a larger
class of linear queries. To illustrate the power of this technique, we show the
first lower bound on the mean squared error for answering parity queries.
</p>

<h2>protect</h2>
<h3>Title: Composite Fixed-Length Ordered Features for Palmprint Template Protection with Diminished Performance Loss. (arXiv:2211.04884v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04884">http://arxiv.org/abs/2211.04884</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04884] Composite Fixed-Length Ordered Features for Palmprint Template Protection with Diminished Performance Loss](http://arxiv.org/abs/2211.04884)</code></li>
<li>Summary: <p>Palmprint recognition has become more and more popular due to its advantages
over other biometric modalities such as fingerprint, in that it is larger in
area, richer in information and able to work at a distance. However, the issue
of palmprint privacy and security (especially palmprint template protection)
remains under-studied. Among the very few research works, most of them only use
the directional and orientation features of the palmprint with transformation
processing, yielding unsatisfactory protection and identification performance.
Thus, this paper proposes a palmprint template protection-oriented operator
that has a fixed length and is ordered in nature, by fusing point features and
orientation features. Firstly, double orientations are extracted with more
accuracy based on MFRAT. Then key points of SURF are extracted and converted to
be fixed-length and ordered features. Finally, composite features that fuse up
the double orientations and SURF points are transformed using the irreversible
transformation of IOM to generate the revocable palmprint template. Experiments
show that the EER after irreversible transformation on the PolyU and CASIA
databases are 0.17% and 0.19% respectively, and the absolute precision loss is
0.08% and 0.07%, respectively, which proves the advantage of our method.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h2>robust</h2>
<h3>Title: Soft Augmentation for Image Classification. (arXiv:2211.04625v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04625">http://arxiv.org/abs/2211.04625</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04625] Soft Augmentation for Image Classification](http://arxiv.org/abs/2211.04625)</code></li>
<li>Summary: <p>Modern neural networks are over-parameterized and thus rely on strong
regularization such as data augmentation and weight decay to reduce overfitting
and improve generalization. The dominant form of data augmentation applies
invariant transforms, where the learning target of a sample is invariant to the
transform applied to that sample. We draw inspiration from human visual
classification studies and propose generalizing augmentation with invariant
transforms to soft augmentation where the learning target softens non-linearly
as a function of the degree of the transform applied to the sample: e.g., more
aggressive image crop augmentations produce less confident learning targets. We
demonstrate that soft targets allow for more aggressive data augmentation,
offer more robust performance boosts, work with other augmentation policies,
and interestingly, produce better calibrated models (since they are trained to
be less confident on aggressively cropped/occluded examples). Combined with
existing aggressive augmentation strategies, soft target 1) doubles the top-1
accuracy boost across Cifar-10, Cifar-100, ImageNet-1K, and ImageNet-V2, 2)
improves model occlusion performance by up to $4\times$, and 3) halves the
expected calibration error (ECE). Finally, we show that soft augmentation
generalizes to self-supervised classification tasks.
</p></li>
</ul>

<h3>Title: MEVID: Multi-view Extended Videos with Identities for Video Person Re-Identification. (arXiv:2211.04656v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04656">http://arxiv.org/abs/2211.04656</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04656] MEVID: Multi-view Extended Videos with Identities for Video Person Re-Identification](http://arxiv.org/abs/2211.04656)</code></li>
<li>Summary: <p>In this paper, we present the Multi-view Extended Videos with Identities
(MEVID) dataset for large-scale, video person re-identification (ReID) in the
wild. To our knowledge, MEVID represents the most-varied video person ReID
dataset, spanning an extensive indoor and outdoor environment across nine
unique dates in a 73-day window, various camera viewpoints, and entity clothing
changes. Specifically, we label the identities of 158 unique people wearing 598
outfits taken from 8, 092 tracklets, average length of about 590 frames, seen
in 33 camera views from the very large-scale MEVA person activities dataset.
While other datasets have more unique identities, MEVID emphasizes a richer set
of information about each individual, such as: 4 outfits/identity vs. 2
outfits/identity in CCVID, 33 viewpoints across 17 locations vs. 6 in 5
simulated locations for MTA, and 10 million frames vs. 3 million for LS-VID.
Being based on the MEVA video dataset, we also inherit data that is
intentionally demographically balanced to the continental United States. To
accelerate the annotation process, we developed a semi-automatic annotation
framework and GUI that combines state-of-the-art real-time models for object
detection, pose estimation, person ReID, and multi-object tracking. We evaluate
several state-of-the-art methods on MEVID challenge problems and
comprehensively quantify their robustness in terms of changes of outfit, scale,
and background location. Our quantitative analysis on the realistic, unique
aspects of MEVID shows that there are significant remaining challenges in video
person ReID and indicates important directions for future research.
</p></li>
</ul>

<h3>Title: A Solution for a Fundamental Problem of 3D Inference based on 2D Representations. (arXiv:2211.04691v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04691">http://arxiv.org/abs/2211.04691</a></li>
<li>Code URL: <a href="https://github.com/thienannguyen-cv/2D-representation-experiments/blob/main/experiment-code.ipynb">https://github.com/thienannguyen-cv/2D-representation-experiments/blob/main/experiment-code.ipynb</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04691] A Solution for a Fundamental Problem of 3D Inference based on 2D Representations](http://arxiv.org/abs/2211.04691)</code></li>
<li>Summary: <p>3D inference from monocular vision using neural networks is an important
research area of computer vision. Applications of the research area are various
with many proposed solutions and have shown remarkable performance. Although
many efforts have been invested, there are still unanswered questions, some of
which are fundamental. In this paper, I discuss a problem that I hope will come
to be known as a generalization of the Blind Perspective-n-Point (Blind PnP)
problem for object-driven 3D inference based on 2D representations. The vital
difference between the fundamental problem and the Blind PnP problem is that 3D
inference parameters in the fundamental problem are attached directly to 3D
points and the camera concept will be represented through the sharing of the
parameters of these points. By providing an explainable and robust
gradient-decent solution based on 2D representations for an important special
case of the problem, the paper opens up a new approach for using available
information-based learning methods to solve problems related to 3D object pose
estimation from 2D images.
</p></li>
</ul>

<h3>Title: Robust Point Cloud Registration Framework Based on Deep Graph Matching(TPAMI Version). (arXiv:2211.04696v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04696">http://arxiv.org/abs/2211.04696</a></li>
<li>Code URL: <a href="https://github.com/fukexue/RGM">https://github.com/fukexue/RGM</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04696] Robust Point Cloud Registration Framework Based on Deep Graph Matching(TPAMI Version)](http://arxiv.org/abs/2211.04696)</code></li>
<li>Summary: <p>3D point cloud registration is a fundamental problem in computer vision and
robotics. Recently, learning-based point cloud registration methods have made
great progress. However, these methods are sensitive to outliers, which lead to
more incorrect correspondences. In this paper, we propose a novel deep graph
matching-based framework for point cloud registration. Specifically, we first
transform point clouds into graphs and extract deep features for each point.
Then, we develop a module based on deep graph matching to calculate a soft
correspondence matrix. By using graph matching, not only the local geometry of
each point but also its structure and topology in a larger range are considered
in establishing correspondences, so that more correct correspondences are
found. We train the network with a loss directly defined on the
correspondences, and in the test stage the soft correspondences are transformed
into hard one-to-one correspondences so that registration can be performed by a
correspondence-based solver. Furthermore, we introduce a transformer-based
method to generate edges for graph construction, which further improves the
quality of the correspondences. Extensive experiments on object-level and
scene-level benchmark datasets show that the proposed method achieves
state-of-the-art performance. The code is available at:
\href{https://github.com/fukexue/RGM}{https://github.com/fukexue/RGM}.
</p></li>
</ul>

<h3>Title: Interpretable Explainability in Facial Emotion Recognition and Gamification for Data Collection. (arXiv:2211.04769v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04769">http://arxiv.org/abs/2211.04769</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04769] Interpretable Explainability in Facial Emotion Recognition and Gamification for Data Collection](http://arxiv.org/abs/2211.04769)</code></li>
<li>Summary: <p>Training facial emotion recognition models requires large sets of data and
costly annotation processes. To alleviate this problem, we developed a gamified
method of acquiring annotated facial emotion data without an explicit labeling
effort by humans. The game, which we named Facegame, challenges the players to
imitate a displayed image of a face that portrays a particular basic emotion.
Every round played by the player creates new data that consists of a set of
facial features and landmarks, already annotated with the emotion label of the
target facial expression. Such an approach effectively creates a robust,
sustainable, and continuous machine learning training process. We evaluated
Facegame with an experiment that revealed several contributions to the field of
affective computing. First, the gamified data collection approach allowed us to
access a rich variation of facial expressions of each basic emotion due to the
natural variations in the players' facial expressions and their expressive
abilities. We report improved accuracy when the collected data were used to
enrich well-known in-the-wild facial emotion datasets and consecutively used
for training facial emotion recognition models. Second, the natural language
prescription method used by the Facegame constitutes a novel approach for
interpretable explainability that can be applied to any facial emotion
recognition model. Finally, we observed significant improvements in the facial
emotion perception and expression skills of the players through repeated game
play.
</p></li>
</ul>

<h3>Title: On the Robustness of Explanations of Deep Neural Network Models: A Survey. (arXiv:2211.04780v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04780">http://arxiv.org/abs/2211.04780</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04780] On the Robustness of Explanations of Deep Neural Network Models: A Survey](http://arxiv.org/abs/2211.04780)</code></li>
<li>Summary: <p>Explainability has been widely stated as a cornerstone of the responsible and
trustworthy use of machine learning models. With the ubiquitous use of Deep
Neural Network (DNN) models expanding to risk-sensitive and safety-critical
domains, many methods have been proposed to explain the decisions of these
models. Recent years have also seen concerted efforts that have shown how such
explanations can be distorted (attacked) by minor input perturbations. While
there have been many surveys that review explainability methods themselves,
there has been no effort hitherto to assimilate the different methods and
metrics proposed to study the robustness of explanations of DNN models. In this
work, we present a comprehensive survey of methods that study, understand,
attack, and defend explanations of DNN models. We also present a detailed
review of different metrics used to evaluate explanation methods, as well as
describe attributional attack and defense methods. We conclude with lessons and
take-aways for the community towards ensuring robust explanations of DNN model
predictions.
</p></li>
</ul>

<h3>Title: Disentangling Aesthetic and Technical Effects for Video Quality Assessment of User Generated Content. (arXiv:2211.04894v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04894">http://arxiv.org/abs/2211.04894</a></li>
<li>Code URL: <a href="https://github.com/teowu/dover">https://github.com/teowu/dover</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04894] Disentangling Aesthetic and Technical Effects for Video Quality Assessment of User Generated Content](http://arxiv.org/abs/2211.04894)</code></li>
<li>Summary: <p>User-generated-content (UGC) videos have dominated the Internet during recent
years. While many methods attempt to objectively assess the quality of these
UGC videos, the mechanisms of human quality perception in the UGC-VQA problem
is still yet to be explored. To better explain the quality perception
mechanisms and learn more robust representations, we aim to disentangle the
effects of aesthetic quality issues and technical quality issues risen by the
complicated video generation processes in the UGC-VQA problem. To overcome the
absence of respective supervisions during disentanglement, we propose the
Limited View Biased Supervisions (LVBS) scheme where two separate evaluators
are trained with decomposed views specifically designed for each issue.
Composed of an Aesthetic Quality Evaluator (AQE) and a Technical Quality
Evaluator (TQE) under the LVBS scheme, the proposed Disentangled Objective
Video Quality Evaluator (DOVER) reach excellent performance (0.91 SRCC for
KoNViD-1k, 0.89 SRCC for LSVQ, 0.88 SRCC for YouTube-UGC) in the UGC-VQA
problem. More importantly, our blind subjective studies prove that the separate
evaluators in DOVER can effectively match human perception on respective
disentangled quality issues. Codes and demos are released in
https://github.com/teowu/dover.
</p></li>
</ul>

<h3>Title: SimOn: A Simple Framework for Online Temporal Action Localization. (arXiv:2211.04905v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04905">http://arxiv.org/abs/2211.04905</a></li>
<li>Code URL: <a href="https://github.com/tuantng/simon">https://github.com/tuantng/simon</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04905] SimOn: A Simple Framework for Online Temporal Action Localization](http://arxiv.org/abs/2211.04905)</code></li>
<li>Summary: <p>Online Temporal Action Localization (On-TAL) aims to immediately provide
action instances from untrimmed streaming videos. The model is not allowed to
utilize future frames and any processing techniques to modify past predictions,
making On-TAL much more challenging. In this paper, we propose a simple yet
effective framework, termed SimOn, that learns to predict action instances
using the popular Transformer architecture in an end-to-end manner.
Specifically, the model takes the current frame feature as a query and a set of
past context information as keys and values of the Transformer. Different from
the prior work that uses a set of outputs of the model as past contexts, we
leverage the past visual context and the learnable context embedding for the
current query. Experimental results on the THUMOS14 and ActivityNet1.3 datasets
show that our model remarkably outperforms the previous methods, achieving a
new state-of-the-art On-TAL performance. In addition, the evaluation for Online
Detection of Action Start (ODAS) demonstrates the effectiveness and robustness
of our method in the online setting. The code is available at
https://github.com/TuanTNG/SimOn
</p></li>
</ul>

<h3>Title: The Best of Both Worlds: a Framework for Combining Degradation Prediction with High Performance Super-Resolution Networks. (arXiv:2211.05018v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.05018">http://arxiv.org/abs/2211.05018</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.05018] The Best of Both Worlds: a Framework for Combining Degradation Prediction with High Performance Super-Resolution Networks](http://arxiv.org/abs/2211.05018)</code></li>
<li>Summary: <p>To date, the best-performing blind super-resolution (SR) techniques follow
one of two paradigms: A) generate and train a standard SR network on synthetic
low-resolution - high-resolution (LR - HR) pairs or B) attempt to predict the
degradations an LR image has suffered and use these to inform a customised SR
network. Despite significant progress, subscribers to the former miss out on
useful degradation information that could be used to improve the SR process. On
the other hand, followers of the latter rely on weaker SR networks, which are
significantly outperformed by the latest architectural advancements. In this
work, we present a framework for combining any blind SR prediction mechanism
with any deep SR network, using a metadata insertion block to insert prediction
vectors into SR network feature maps. Through comprehensive testing, we prove
that state-of-the-art contrastive and iterative prediction schemes can be
successfully combined with high-performance SR networks such as RCAN and HAN
within our framework. We show that our hybrid models consistently achieve
stronger SR performance than both their non-blind and blind counterparts.
Furthermore, we demonstrate our framework's robustness by predicting
degradations and super-resolving images from a complex pipeline of blurring,
noise and compression.
</p></li>
</ul>

<h3>Title: Toward a Neural Semantic Parsing System for EHR Question Answering. (arXiv:2211.04569v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04569">http://arxiv.org/abs/2211.04569</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04569] Toward a Neural Semantic Parsing System for EHR Question Answering](http://arxiv.org/abs/2211.04569)</code></li>
<li>Summary: <p>Clinical semantic parsing (SP) is an important step toward identifying the
exact information need (as a machine-understandable logical form) from a
natural language query aimed at retrieving information from electronic health
records (EHRs). Current approaches to clinical SP are largely based on
traditional machine learning and require hand-building a lexicon. The recent
advancements in neural SP show a promise for building a robust and flexible
semantic parser without much human effort. Thus, in this paper, we aim to
systematically assess the performance of two such neural SP models for EHR
question answering (QA). We found that the performance of these advanced neural
models on two clinical SP datasets is promising given their ease of application
and generalizability. Our error analysis surfaces the common types of errors
made by these models and has the potential to inform future research into
improving the performance of neural SP models for EHR QA.
</p></li>
</ul>

<h3>Title: DeepE: a deep neural network for knowledge graph embedding. (arXiv:2211.04620v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04620">http://arxiv.org/abs/2211.04620</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04620] DeepE: a deep neural network for knowledge graph embedding](http://arxiv.org/abs/2211.04620)</code></li>
<li>Summary: <p>Recently, neural network based methods have shown their power in learning
more expressive features on the task of knowledge graph embedding (KGE).
However, the performance of deep methods often falls behind the shallow ones on
simple graphs. One possible reason is that deep models are difficult to train,
while shallow models might suffice for accurately representing the structure of
the simple KGs.
</p></li>
</ul>

<p>In this paper, we propose a neural network based model, named DeepE, to
address the problem, which stacks multiple building blocks to predict the tail
entity based on the head entity and the relation. Each building block is an
addition of a linear and a non-linear function. The stacked building blocks are
equivalent to a group of learning functions with different non-linear depth.
Hence, DeepE allows deep functions to learn deep features, and shallow
functions to learn shallow features. Through extensive experiments, we find
DeepE outperforms other state-of-the-art baseline methods. A major advantage of
DeepE is the robustness. DeepE achieves a Mean Rank (MR) score that is 6%, 30%,
65% lower than the best baseline methods on FB15k-237, WN18RR and YAGO3-10. Our
design makes it possible to train much deeper networks on KGE, e.g. 40 layers
on FB15k-237, and without scarifying precision on simple relations.
</p>

<h3>Title: miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings. (arXiv:2211.04928v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04928">http://arxiv.org/abs/2211.04928</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04928] miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings](http://arxiv.org/abs/2211.04928)</code></li>
<li>Summary: <p>This paper presents miCSE, a mutual information-based Contrastive learning
framework that significantly advances the state-of-the-art in few-shot sentence
embedding. The proposed approach imposes alignment between the attention
pattern of different views during contrastive learning. Learning sentence
embeddings with miCSE entails enforcing the syntactic consistency across
augmented views for every single sentence, making contrastive self-supervised
learning more sample efficient. As a result, the proposed approach shows strong
performance in the few-shot learning domain. While it achieves superior results
compared to state-of-the-art methods on multiple benchmarks in few-shot
learning, it is comparable in the full-shot scenario. The proposed approach is
conceptually simple, easy to implement and optimize, yet empirically powerful.
This study opens up avenues for efficient self-supervised learning methods that
are more robust than current contrastive methods for sentence embedding.
</p></li>
</ul>

<h3>Title: Large Language Models with Controllable Working Memory. (arXiv:2211.05110v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.05110">http://arxiv.org/abs/2211.05110</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.05110] Large Language Models with Controllable Working Memory](http://arxiv.org/abs/2211.05110)</code></li>
<li>Summary: <p>Large language models (LLMs) have led to a series of breakthroughs in natural
language processing (NLP), owing to their excellent understanding and
generation abilities. Remarkably, what further sets these models apart is the
massive amounts of world knowledge they internalize during pretraining. While
many downstream applications provide the model with an informational context to
aid its performance on the underlying task, how the model's world knowledge
interacts with the factual information presented in the context remains under
explored. As a desirable behavior, an LLM should give precedence to the context
whenever it contains task-relevant information that conflicts with the model's
memorized knowledge. This enables model predictions to be grounded in the
context, which can then be used to update or correct specific model predictions
without frequent retraining. By contrast, when the context is irrelevant to the
task, the model should ignore it and fall back on its internal knowledge. In
this paper, we undertake a first joint study of the aforementioned two
properties, namely controllability and robustness, in the context of LLMs. We
demonstrate that state-of-the-art T5 and PaLM (both pretrained and finetuned)
could exhibit poor controllability and robustness, which do not scale with
increasing model size. As a solution, we propose a novel method - Knowledge
Aware FineTuning (KAFT) - to strengthen both controllability and robustness by
incorporating counterfactual and irrelevant contexts to standard supervised
datasets. Our comprehensive evaluation showcases the utility of KAFT across
model architectures and sizes.
</p></li>
</ul>

<h3>Title: ARMOR: A Model-based Framework for Improving Arbitrary Baseline Policies with Offline Data. (arXiv:2211.04538v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04538">http://arxiv.org/abs/2211.04538</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04538] ARMOR: A Model-based Framework for Improving Arbitrary Baseline Policies with Offline Data](http://arxiv.org/abs/2211.04538)</code></li>
<li>Summary: <p>We propose a new model-based offline RL framework, called Adversarial Models
for Offline Reinforcement Learning (ARMOR), which can robustly learn policies
to improve upon an arbitrary baseline policy regardless of data coverage. Based
on the concept of relative pessimism, ARMOR is designed to optimize for the
worst-case relative performance when facing uncertainty. In theory, we prove
that the learned policy of ARMOR never degrades the performance of the baseline
policy with any admissible hyperparameter, and can learn to compete with the
best policy within data coverage when the hyperparameter is well tuned, and the
baseline policy is supported by the data. Such a robust policy improvement
property makes ARMOR especially suitable for building real-world learning
systems, because in practice ensuring no performance degradation is imperative
before considering any benefit learning can bring.
</p></li>
</ul>

<h3>Title: Utilising Bayesian Networks to combine multimodal data and expert opinion for the robust prediction of depression and its symptoms. (arXiv:2211.04924v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04924">http://arxiv.org/abs/2211.04924</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04924] Utilising Bayesian Networks to combine multimodal data and expert opinion for the robust prediction of depression and its symptoms](http://arxiv.org/abs/2211.04924)</code></li>
<li>Summary: <p>Predicting the presence of major depressive disorder (MDD) using behavioural
and cognitive signals is a highly non-trivial task. The heterogeneous clinical
profile of MDD means that any given speech, facial expression and/or observed
cognitive pattern may be associated with a unique combination of depressive
symptoms. Conventional discriminative machine learning models potentially lack
the complexity to robustly model this heterogeneity. Bayesian networks,
however, may instead be well-suited to such a scenario. These networks are
probabilistic graphical models that efficiently describe the joint probability
distribution over a set of random variables by explicitly capturing their
conditional dependencies. This framework provides further advantages over
standard discriminative modelling by offering the possibility to incorporate
expert opinion in the graphical structure of the models, generating explainable
model predictions, informing about the uncertainty of predictions, and
naturally handling missing data. In this study, we apply a Bayesian framework
to capture the relationships between depression, depression symptoms, and
features derived from speech, facial expression and cognitive game data
collected at thymia.
</p></li>
</ul>

<h3>Title: Learning to Price Supply Chain Contracts against a Learning Retailer. (arXiv:2211.04586v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04586">http://arxiv.org/abs/2211.04586</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04586] Learning to Price Supply Chain Contracts against a Learning Retailer](http://arxiv.org/abs/2211.04586)</code></li>
<li>Summary: <p>The rise of big data analytics has automated the decision-making of companies
and increased supply chain agility. In this paper, we study the supply chain
contract design problem faced by a data-driven supplier who needs to respond to
the inventory decisions of the downstream retailer. Both the supplier and the
retailer are uncertain about the market demand and need to learn about it
sequentially. The goal for the supplier is to develop data-driven pricing
policies with sublinear regret bounds under a wide range of possible retailer
inventory policies for a fixed time horizon.
</p></li>
</ul>

<p>To capture the dynamics induced by the retailer's learning policy, we first
make a connection to non-stationary online learning by following the notion of
variation budget. The variation budget quantifies the impact of the retailer's
learning strategy on the supplier's decision-making. We then propose dynamic
pricing policies for the supplier for both discrete and continuous demand. We
also note that our proposed pricing policy only requires access to the support
of the demand distribution, but critically, does not require the supplier to
have any prior knowledge about the retailer's learning policy or the demand
realizations. We examine several well-known data-driven policies for the
retailer, including sample average approximation, distributionally robust
optimization, and parametric approaches, and show that our pricing policies
lead to sublinear regret bounds in all these cases.
</p>
<p>At the managerial level, we answer affirmatively that there is a pricing
policy with a sublinear regret bound under a wide range of retailer's learning
policies, even though she faces a learning retailer and an unknown demand
distribution. Our work also provides a novel perspective in data-driven
operations management where the principal has to learn to react to the learning
policies employed by other agents in the system.
</p>

<h3>Title: Accelerating Adversarial Perturbation by 50% with Semi-backward Propagation. (arXiv:2211.04973v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04973">http://arxiv.org/abs/2211.04973</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04973] Accelerating Adversarial Perturbation by 50% with Semi-backward Propagation](http://arxiv.org/abs/2211.04973)</code></li>
<li>Summary: <p>Adversarial perturbation plays a significant role in the field of adversarial
robustness, which solves a maximization problem over the input data. We show
that the backward propagation of such optimization can accelerate $2\times$
(and thus the overall optimization including the forward propagation can
accelerate $1.5\times$), without any utility drop, if we only compute the
output gradient but not the parameter gradient during the backward propagation.
</p></li>
</ul>

<h3>Title: Hyper-GST: Predict Metro Passenger Flow Incorporating GraphSAGE, Hypergraph, Social-meaningful Edge Weights and Temporal Exploitation. (arXiv:2211.04988v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04988">http://arxiv.org/abs/2211.04988</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04988] Hyper-GST: Predict Metro Passenger Flow Incorporating GraphSAGE, Hypergraph, Social-meaningful Edge Weights and Temporal Exploitation](http://arxiv.org/abs/2211.04988)</code></li>
<li>Summary: <p>Predicting metro passenger flow precisely is of great importance for dynamic
traffic planning. Deep learning algorithms have been widely applied due to
their robust performance in modelling non-linear systems. However, traditional
deep learning algorithms completely discard the inherent graph structure within
the metro system. Graph-based deep learning algorithms could utilise the graph
structure but raise a few challenges, such as how to determine the weights of
the edges and the shallow receptive field caused by the over-smoothing issue.
To further improve these challenges, this study proposes a model based on
GraphSAGE with an edge weights learner applied. The edge weights learner
utilises socially meaningful features to generate edge weights. Hypergraph and
temporal exploitation modules are also constructed as add-ons for better
performance. A comparison study is conducted on the proposed algorithm and
other state-of-art graph neural networks, where the proposed algorithm could
improve the performance.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Novel Chapter Abstractive Summarization using Spinal Tree Aware Sub-Sentential Content Selection. (arXiv:2211.04903v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04903">http://arxiv.org/abs/2211.04903</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04903] Novel Chapter Abstractive Summarization using Spinal Tree Aware Sub-Sentential Content Selection](http://arxiv.org/abs/2211.04903)</code></li>
<li>Summary: <p>Summarizing novel chapters is a difficult task due to the input length and
the fact that sentences that appear in the desired summaries draw content from
multiple places throughout the chapter. We present a pipelined
extractive-abstractive approach where the extractive step filters the content
that is passed to the abstractive component. Extremely lengthy input also
results in a highly skewed dataset towards negative instances for extractive
summarization; we thus adopt a margin ranking loss for extraction to encourage
separation between positive and negative examples. Our extraction component
operates at the constituent level; our approach to this problem enriches the
text with spinal tree information which provides syntactic context (in the form
of constituents) to the extraction model. We show an improvement of 3.71
Rouge-1 points over best results reported in prior work on an existing novel
chapter dataset.
</p></li>
</ul>

<h3>Title: DoSA : A System to Accelerate Annotations on Business Documents with Human-in-the-Loop. (arXiv:2211.04934v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04934">http://arxiv.org/abs/2211.04934</a></li>
<li>Code URL: <a href="https://github.com/neeleshkshukla/dosa">https://github.com/neeleshkshukla/dosa</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04934] DoSA : A System to Accelerate Annotations on Business Documents with Human-in-the-Loop](http://arxiv.org/abs/2211.04934)</code></li>
<li>Summary: <p>Business documents come in a variety of structures, formats and information
needs which makes information extraction a challenging task. Due to these
variations, having a document generic model which can work well across all
types of documents and for all the use cases seems far-fetched. For
document-specific models, we would need customized document-specific labels. We
introduce DoSA (Document Specific Automated Annotations), which helps
annotators in generating initial annotations automatically using our novel
bootstrap approach by leveraging document generic datasets and models. These
initial annotations can further be reviewed by a human for correctness. An
initial document-specific model can be trained and its inference can be used as
feedback for generating more automated annotations. These automated annotations
can be reviewed by human-in-the-loop for the correctness and a new improved
model can be trained using the current model as pre-trained model before going
for the next iteration. In this paper, our scope is limited to Form like
documents due to limited availability of generic annotated datasets, but this
idea can be extended to a variety of other documents as more datasets are
built. An open-source ready-to-use implementation is made available on GitHub
https://github.com/neeleshkshukla/DoSA.
</p></li>
</ul>

<h3>Title: Improving Performance of Automatic Keyword Extraction (AKE) Methods Using PoS-Tagging and Enhanced Semantic-Awareness. (arXiv:2211.05031v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.05031">http://arxiv.org/abs/2211.05031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.05031] Improving Performance of Automatic Keyword Extraction (AKE) Methods Using PoS-Tagging and Enhanced Semantic-Awareness](http://arxiv.org/abs/2211.05031)</code></li>
<li>Summary: <p>Automatic keyword extraction (AKE) has gained more importance with the
increasing amount of digital textual data that modern computing systems
process. It has various applications in information retrieval (IR) and natural
language processing (NLP), including text summarisation, topic analysis and
document indexing. This paper proposes a simple but effective
post-processing-based universal approach to improve the performance of any AKE
methods, via an enhanced level of semantic-awareness supported by PoS-tagging.
To demonstrate the performance of the proposed approach, we considered word
types retrieved from a PoS-tagging step and two representative sources of
semantic information -- specialised terms defined in one or more
context-dependent thesauri, and named entities in Wikipedia. The above three
steps can be simply added to the end of any AKE methods as part of a
post-processor, which simply re-evaluate all candidate keywords following some
context-specific and semantic-aware criteria. For five state-of-the-art (SOTA)
AKE methods, our experimental results with 17 selected datasets showed that the
proposed approach improved their performances both consistently (up to 100\% in
terms of improved cases) and significantly (between 10.2\% and 53.8\%, with an
average of 25.8\%, in terms of F1-score and across all five methods),
especially when all the three enhancement steps are used. Our results have
profound implications considering the ease to apply our proposed approach to
any AKE methods and to further extend it.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Framework Construction of an Adversarial Federated Transfer Learning Classifier. (arXiv:2211.04734v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04734">http://arxiv.org/abs/2211.04734</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04734] Framework Construction of an Adversarial Federated Transfer Learning Classifier](http://arxiv.org/abs/2211.04734)</code></li>
<li>Summary: <p>As the Internet grows in popularity, more and more classification jobs, such
as IoT, finance industry and healthcare field, rely on mobile edge computing to
advance machine learning. In the medical industry, however, good diagnostic
accuracy necessitates the combination of large amounts of labeled data to train
the model, which is difficult and expensive to collect and risks jeopardizing
patients' privacy. In this paper, we offer a novel medical diagnostic framework
that employs a federated learning platform to ensure patient data privacy by
transferring classification algorithms acquired in a labeled domain to a domain
with sparse or missing labeled data. Rather than using a generative adversarial
network, our framework uses a discriminative model to build multiple
classification loss functions with the goal of improving diagnostic accuracy.
It also avoids the difficulty of collecting large amounts of labeled data or
the high cost of generating large amount of sample data. Experiments on
real-world image datasets demonstrates that the suggested adversarial federated
transfer learning method is promising for real-world medical diagnosis
applications that use image classification.
</p></li>
</ul>

<h3>Title: Knowledge Distillation for Federated Learning: a Practical Guide. (arXiv:2211.04742v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04742">http://arxiv.org/abs/2211.04742</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04742] Knowledge Distillation for Federated Learning: a Practical Guide](http://arxiv.org/abs/2211.04742)</code></li>
<li>Summary: <p>Federated Learning (FL) enables the training of Deep Learning models without
centrally collecting possibly sensitive raw data. This paves the way for
stronger privacy guarantees when building predictive models. The most used
algorithms for FL are parameter-averaging based schemes (e.g., Federated
Averaging) that, however, have well known limits: (i) Clients must implement
the same model architecture; (ii) Transmitting model weights and model updates
implies high communication cost, which scales up with the number of model
parameters; (iii) In presence of non-IID data distributions,
parameter-averaging aggregation schemes perform poorly due to client model
drifts. Federated adaptations of regular Knowledge Distillation (KD) can solve
and/or mitigate the weaknesses of parameter-averaging FL algorithms while
possibly introducing other trade-offs. In this article, we provide a review of
KD-based algorithms tailored for specific FL issues.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Discrimination and Class Imbalance Aware Online Naive Bayes. (arXiv:2211.04812v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04812">http://arxiv.org/abs/2211.04812</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04812] Discrimination and Class Imbalance Aware Online Naive Bayes](http://arxiv.org/abs/2211.04812)</code></li>
<li>Summary: <p>Fairness-aware mining of massive data streams is a growing and challenging
concern in the contemporary domain of machine learning. Many stream learning
algorithms are used to replace humans at critical decision-making points e.g.,
hiring staff, assessing credit risk, etc. This calls for handling massive
incoming information with minimum response delay while ensuring fair and high
quality decisions. Recent discrimination-aware learning methods are optimized
based on overall accuracy. However, the overall accuracy is biased in favor of
the majority class; therefore, state-of-the-art methods mainly diminish
discrimination by partially or completely ignoring the minority class. In this
context, we propose a novel adaptation of Na\"ive Bayes to mitigate
discrimination embedded in the streams while maintaining high predictive
performance for both the majority and minority classes. Our proposed algorithm
is simple, fast, and attains multi-objective optimization goals. To handle
class imbalance and concept drifts, a dynamic instance weighting module is
proposed, which gives more importance to recent instances and less importance
to obsolete instances based on their membership in minority or majority class.
We conducted experiments on a range of streaming and static datasets and
deduced that our proposed methodology outperforms existing state-of-the-art
fairness-aware methods in terms of both discrimination score and balanced
accuracy.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Care for the Mind Amid Chronic Diseases: An Interpretable AI Approach Using IoT. (arXiv:2211.04509v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04509">http://arxiv.org/abs/2211.04509</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04509] Care for the Mind Amid Chronic Diseases: An Interpretable AI Approach Using IoT](http://arxiv.org/abs/2211.04509)</code></li>
<li>Summary: <p>Health sensing for chronic disease management creates immense benefits for
social welfare. Existing health sensing studies primarily focus on the
prediction of physical chronic diseases. Depression, a widespread complication
of chronic diseases, is however understudied. We draw on the medical literature
to support depression prediction using motion sensor data. To connect human
expertise in the decision-making, safeguard trust for this high-stake
prediction, and ensure algorithm transparency, we develop an interpretable deep
learning model: Temporal Prototype Network (TempPNet). TempPNet is built upon
the emergent prototype learning models. To accommodate the temporal
characteristic of sensor data and the progressive property of depression,
TempPNet differs from existing prototype learning models in its capability of
capturing the temporal progression of depression. Extensive empirical analyses
using real-world motion sensor data show that TempPNet outperforms
state-of-the-art benchmarks in depression prediction. Moreover, TempPNet
interprets its predictions by visualizing the temporal progression of
depression and its corresponding symptoms detected from sensor data. We further
conduct a user study to demonstrate its superiority over the benchmarks in
interpretability. This study offers an algorithmic solution for impactful
social good - collaborative care of chronic diseases and depression in health
sensing. Methodologically, it contributes to extant literature with a novel
interpretable deep learning model for depression prediction from sensor data.
Patients, doctors, and caregivers can deploy our model on mobile devices to
monitor patients' depression risks in real-time. Our model's interpretability
also allows human experts to participate in the decision-making by reviewing
the interpretation of prediction outcomes and making informed interventions.
</p></li>
</ul>

<h3>Title: Deep Explainable Learning with Graph Based Data Assessing and Rule Reasoning. (arXiv:2211.04693v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.04693">http://arxiv.org/abs/2211.04693</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.04693] Deep Explainable Learning with Graph Based Data Assessing and Rule Reasoning](http://arxiv.org/abs/2211.04693)</code></li>
<li>Summary: <p>Learning an explainable classifier often results in low accuracy model or
ends up with a huge rule set, while learning a deep model is usually more
capable of handling noisy data at scale, but with the cost of hard to explain
the result and weak at generalization. To mitigate this gap, we propose an
end-to-end deep explainable learning approach that combines the advantage of
deep model in noise handling and expert rule-based interpretability.
Specifically, we propose to learn a deep data assessing model which models the
data as a graph to represent the correlations among different observations,
whose output will be used to extract key data features. The key features are
then fed into a rule network constructed following predefined noisy expert
rules with trainable parameters. As these models are correlated, we propose an
end-to-end training framework, utilizing the rule classification loss to
optimize the rule learning model and data assessing model at the same time. As
the rule-based computation is none-differentiable, we propose a gradient
linking search module to carry the gradient information from the rule learning
model to the data assessing model. The proposed method is tested in an industry
production system, showing comparable prediction accuracy, much higher
generalization stability and better interpretability when compared with a
decent deep ensemble baseline, and shows much better fitting power than pure
rule-based approach.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
