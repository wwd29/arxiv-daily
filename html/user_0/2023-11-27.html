<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: A Blockchain Solution for Collaborative Machine Learning over IoT. (arXiv:2311.14136v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14136">http://arxiv.org/abs/2311.14136</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14136]] A Blockchain Solution for Collaborative Machine Learning over IoT(http://arxiv.org/abs/2311.14136)</code></li>
<li>Summary: <p>The rapid growth of Internet of Things (IoT) devices and applications has led
to an increased demand for advanced analytics and machine learning techniques
capable of handling the challenges associated with data privacy, security, and
scalability. Federated learning (FL) and blockchain technologies have emerged
as promising approaches to address these challenges by enabling decentralized,
secure, and privacy-preserving model training on distributed data sources. In
this paper, we present a novel IoT solution that combines the incremental
learning vector quantization algorithm (XuILVQ) with Ethereum blockchain
technology to facilitate secure and efficient data sharing, model training, and
prototype storage in a distributed environment. Our proposed architecture
addresses the shortcomings of existing blockchain-based FL solutions by
reducing computational and communication overheads while maintaining data
privacy and security. We assess the performance of our system through a series
of experiments, showcasing its potential to enhance the accuracy and efficiency
of machine learning tasks in IoT settings.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: A Survey of Blockchain, Artificial Intelligence, and Edge Computing for Web 3.0. (arXiv:2311.13731v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13731">http://arxiv.org/abs/2311.13731</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13731]] A Survey of Blockchain, Artificial Intelligence, and Edge Computing for Web 3(http://arxiv.org/abs/2311.13731)</code></li>
<li>Summary: <p>Web 3.0, as the third generation of the World Wide Web, aims to solve
contemporary problems of trust, centralization, and data ownership. Driven by
the latest advances in cutting-edge technologies, Web 3.0 is moving towards a
more open, decentralized, intelligent, and interconnected network. However,
increasingly widespread data breaches have raised awareness of online privacy
and security of personal data. Additionally, since Web 3.0 is a sophisticated
and complex convergence, the technical details behind it are not as clear as
the characteristics it presents. In this survey, we conduct an in-depth
exploration of Web 3.0 from the perspectives of blockchain, artificial
intelligence, and edge computing. Specifically, we begin with summarizing the
evolution of the Internet and providing an overview of these three key
technological factors. Afterward, we provide a thorough analysis of each
technology separately, including its relevance to Web 3.0, key technology
components, and practical applications. We also propose decentralized storage
and computing solutions by exploring the integration of technologies. Finally,
we highlight the key challenges alongside potential research directions.
Through the combination and mutual complementation of multiple technologies,
Web 3.0 is expected to return more control and ownership of data and digital
assets back to users.
</p></li>
</ul>

<h3>Title: Security and Privacy Challenges in Deep Learning Models. (arXiv:2311.13744v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13744">http://arxiv.org/abs/2311.13744</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13744]] Security and Privacy Challenges in Deep Learning Models(http://arxiv.org/abs/2311.13744)</code></li>
<li>Summary: <p>These days, deep learning models have achieved great success in multiple
fields, from autonomous driving to medical diagnosis. These models have
expanded the abilities of artificial intelligence by offering great solutions
to complex problems that were very difficult to solve earlier. In spite of
their unseen success in various, it has been identified, through research
conducted, that deep learning models can be subjected to various attacks that
compromise model security and data privacy of the Deep Neural Network models.
Deep learning models can be subjected to various attacks at different stages of
their lifecycle. During the testing phase, attackers can exploit
vulnerabilities through different kinds of attacks such as Model Extraction
Attacks, Model Inversion attacks, and Adversarial attacks. Model Extraction
Attacks are aimed at reverse-engineering a trained deep learning model, with
the primary objective of revealing its architecture and parameters. Model
inversion attacks aim to compromise the privacy of the data used in the Deep
learning model. These attacks are done to compromise the confidentiality of the
model by going through the sensitive training data from the model's
predictions. By analyzing the model's responses, attackers aim to reconstruct
sensitive information. In this way, the model's data privacy is compromised.
Adversarial attacks, mainly employed on computer vision models, are made to
corrupt models into confidently making incorrect predictions through malicious
testing data. These attacks subtly alter the input data, making it look normal
but misleading deep learning models to make incorrect decisions. Such attacks
can happen during both the model's evaluation and training phases. Data
Poisoning Attacks add harmful data to the training set, disrupting the learning
process and reducing the reliability of the deep learning mode.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: DPSUR: Accelerating Differentially Private Stochastic Gradient Descent Using Selective Update and Release. (arXiv:2311.14056v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14056">http://arxiv.org/abs/2311.14056</a></li>
<li>Code URL: https://github.com/jefffffffu/dpsur</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14056]] DPSUR: Accelerating Differentially Private Stochastic Gradient Descent Using Selective Update and Release(http://arxiv.org/abs/2311.14056)</code></li>
<li>Summary: <p>Machine learning models are known to memorize private data to reduce their
training loss, which can be inadvertently exploited by privacy attacks such as
model inversion and membership inference. To protect against these attacks,
differential privacy (DP) has become the de facto standard for
privacy-preserving machine learning, particularly those popular training
algorithms using stochastic gradient descent, such as DPSGD. Nonetheless, DPSGD
still suffers from severe utility loss due to its slow convergence. This is
partially caused by the random sampling, which brings bias and variance to the
gradient, and partially by the Gaussian noise, which leads to fluctuation of
gradient updates.
</p>
<p>Our key idea to address these issues is to apply selective updates to the
model training, while discarding those useless or even harmful updates.
Motivated by this, this paper proposes DPSUR, a Differentially Private training
framework based on Selective Updates and Release, where the gradient from each
iteration is evaluated based on a validation test, and only those updates
leading to convergence are applied to the model. As such, DPSUR ensures the
training in the right direction and thus can achieve faster convergence than
DPSGD. The main challenges lie in two aspects -- privacy concerns arising from
gradient evaluation, and gradient selection strategy for model update. To
address the challenges, DPSUR introduces a clipping strategy for update
randomization and a threshold mechanism for gradient selection. Experiments
conducted on MNIST, FMNIST, CIFAR-10, and IMDB datasets show that DPSUR
significantly outperforms previous works in terms of convergence speed and
model utility.
</p></li>
</ul>

<h3>Title: Privacy-Preserving Algorithmic Recourse. (arXiv:2311.14137v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14137">http://arxiv.org/abs/2311.14137</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14137]] Privacy-Preserving Algorithmic Recourse(http://arxiv.org/abs/2311.14137)</code></li>
<li>Summary: <p>When individuals are subject to adverse outcomes from machine learning
models, providing a recourse path to help achieve a positive outcome is
desirable. Recent work has shown that counterfactual explanations - which can
be used as a means of single-step recourse - are vulnerable to privacy issues,
putting an individuals' privacy at risk. Providing a sequential multi-step path
for recourse can amplify this risk. Furthermore, simply adding noise to
recourse paths found from existing methods can impact the realism and
actionability of the path for an end-user. In this work, we address privacy
issues when generating realistic recourse paths based on instance-based
counterfactual explanations, and provide PrivRecourse: an end-to-end privacy
preserving pipeline that can provide realistic recourse paths. PrivRecourse
uses differentially private (DP) clustering to represent non-overlapping
subsets of the private dataset. These DP cluster centers are then used to
generate recourse paths by forming a graph with cluster centers as the nodes,
so that we can generate realistic - feasible and actionable - recourse paths.
We empirically evaluate our approach on finance datasets and compare it to
simply adding noise to data instances, and to using DP synthetic data, to
generate the graph. We observe that PrivRecourse can provide paths that are
private and realistic.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: A Theoretical Insight into Attack and Defense of Gradient Leakage in Transformer. (arXiv:2311.13624v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13624">http://arxiv.org/abs/2311.13624</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13624]] A Theoretical Insight into Attack and Defense of Gradient Leakage in Transformer(http://arxiv.org/abs/2311.13624)</code></li>
<li>Summary: <p>The Deep Leakage from Gradient (DLG) attack has emerged as a prevalent and
highly effective method for extracting sensitive training data by inspecting
exchanged gradients. This approach poses a substantial threat to the privacy of
individuals and organizations alike. This research presents a comprehensive
analysis of the gradient leakage method when applied specifically to
transformer-based models. Through meticulous examination, we showcase the
capability to accurately recover data solely from gradients and rigorously
investigate the conditions under which gradient attacks can be executed,
providing compelling evidence. Furthermore, we reevaluate the approach of
introducing additional noise on gradients as a protective measure against
gradient attacks. To address this, we outline a theoretical proof that analyzes
the associated privacy costs within the framework of differential privacy.
Additionally, we affirm the convergence of the Stochastic Gradient Descent
(SGD) algorithm under perturbed gradients. The primary objective of this study
is to augment the understanding of gradient leakage attack and defense
strategies while actively contributing to the development of privacy-preserving
techniques specifically tailored for transformer-based models. By shedding
light on the vulnerabilities and countermeasures associated with gradient
leakage, this research aims to foster advancements in safeguarding sensitive
data and upholding privacy in the context of transformer-based models.
</p></li>
</ul>

<h3>Title: Adversarial defense based on distribution transfer. (arXiv:2311.13841v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13841">http://arxiv.org/abs/2311.13841</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13841]] Adversarial defense based on distribution transfer(http://arxiv.org/abs/2311.13841)</code></li>
<li>Summary: <p>The presence of adversarial examples poses a significant threat to deep
learning models and their applications. Existing defense methods provide
certain resilience against adversarial examples, but often suffer from
decreased accuracy and generalization performance, making it challenging to
achieve a trade-off between robustness and generalization. To address this, our
paper interprets the adversarial example problem from the perspective of sample
distribution and proposes a defense method based on distribution shift,
leveraging the distribution transfer capability of a diffusion model for
adversarial defense. The core idea is to exploit the discrepancy between normal
and adversarial sample distributions to achieve adversarial defense using a
pretrained diffusion model. Specifically, an adversarial sample undergoes a
forward diffusion process, moving away from the source distribution, followed
by a reverse process guided by the protected model (victim model) output to map
it back to the normal distribution. Experimental evaluations on CIFAR10 and
ImageNet30 datasets are conducted, comparing with adversarial training and
input preprocessing methods. For infinite-norm attacks with 8/255 perturbation,
accuracy rates of 78.1% and 83.5% are achieved, respectively. For 2-norm
attacks with 128/255 perturbation, accuracy rates are 74.3% and 82.5%.
Additional experiments considering perturbation amplitude, diffusion
iterations, and adaptive attacks also validate the effectiveness of the
proposed method. Results demonstrate that even when the attacker has knowledge
of the defense, the proposed distribution-based method effectively withstands
adversarial examples. It fills the gaps of traditional approaches, restoring
high-quality original samples and showcasing superior performance in model
robustness and generalization.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Efficient Trigger Word Insertion. (arXiv:2311.13957v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13957">http://arxiv.org/abs/2311.13957</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13957]] Efficient Trigger Word Insertion(http://arxiv.org/abs/2311.13957)</code></li>
<li>Summary: <p>With the boom in the natural language processing (NLP) field these years,
backdoor attacks pose immense threats against deep neural network models.
However, previous works hardly consider the effect of the poisoning rate. In
this paper, our main objective is to reduce the number of poisoned samples
while still achieving a satisfactory Attack Success Rate (ASR) in text backdoor
attacks. To accomplish this, we propose an efficient trigger word insertion
strategy in terms of trigger word optimization and poisoned sample selection.
Extensive experiments on different datasets and models demonstrate that our
proposed method can significantly improve attack effectiveness in text
classification tasks. Remarkably, our approach achieves an ASR of over 90% with
only 10 poisoned samples in the dirty-label setting and requires merely 1.5% of
the training data in the clean-label setting.
</p></li>
</ul>

<h3>Title: OASIS: Offsetting Active Reconstruction Attacks in Federated Learning. (arXiv:2311.13739v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13739">http://arxiv.org/abs/2311.13739</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13739]] OASIS: Offsetting Active Reconstruction Attacks in Federated Learning(http://arxiv.org/abs/2311.13739)</code></li>
<li>Summary: <p>Federated Learning (FL) has garnered significant attention for its potential
to protect user privacy while enhancing model training efficiency. However,
recent research has demonstrated that FL protocols can be easily compromised by
active reconstruction attacks executed by dishonest servers. These attacks
involve the malicious modification of global model parameters, allowing the
server to obtain a verbatim copy of users' private data by inverting their
gradient updates. Tackling this class of attack remains a crucial challenge due
to the strong threat model. In this paper, we propose OASIS, a defense
mechanism based on image augmentation that effectively counteracts active
reconstruction attacks while preserving model performance. We first uncover the
core principle of gradient inversion that enables these attacks and
theoretically identify the main conditions by which the defense can be robust
regardless of the attack strategies. We then construct OASIS with image
augmentation showing that it can undermine the attack principle. Comprehensive
evaluations demonstrate the efficacy of OASIS highlighting its feasibility as a
solution.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Descriptor and Word Soups: Overcoming the Parameter Efficiency Accuracy Tradeoff for Out-of-Distribution Few-shot Learning. (arXiv:2311.13612v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13612">http://arxiv.org/abs/2311.13612</a></li>
<li>Code URL: https://github.com/chris210634/word_soups</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13612]] Descriptor and Word Soups: Overcoming the Parameter Efficiency Accuracy Tradeoff for Out-of-Distribution Few-shot Learning(http://arxiv.org/abs/2311.13612)</code></li>
<li>Summary: <p>Over the past year, a large body of multimodal research has emerged around
zero-shot evaluation using GPT descriptors. These studies boost the zero-shot
accuracy of pretrained VL models with an ensemble of label-specific text
generated by GPT. A recent study, WaffleCLIP, demonstrated that similar
zero-shot accuracy can be achieved with an ensemble of random descriptors.
However, both zero-shot methods are un-trainable and consequently sub-optimal
when some few-shot out-of-distribution (OOD) training data is available.
Inspired by these prior works, we present two more flexible methods called
descriptor and word soups, which do not require an LLM at test time and can
leverage training data to increase OOD target accuracy. Descriptor soup
greedily selects a small set of textual descriptors using generic few-shot
training data, then calculates robust class embeddings using the selected
descriptors. Word soup greedily assembles a chain of words in a similar manner.
Compared to existing few-shot soft prompt tuning methods, word soup requires
fewer parameters by construction and less GPU memory, since it does not require
backpropagation. Both soups outperform current published few-shot methods, even
when combined with SoTA zero-shot methods, on cross-dataset and domain
generalization benchmarks. Compared with SoTA prompt and descriptor ensembling
methods, such as ProDA and WaffleCLIP, word soup achieves higher OOD accuracy
with fewer ensemble members. Please checkout our code:
github.com/Chris210634/word_soups
</p></li>
</ul>

<h3>Title: Sample as You Infer: Predictive Coding With Langevin Dynamics. (arXiv:2311.13664v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13664">http://arxiv.org/abs/2311.13664</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13664]] Sample as You Infer: Predictive Coding With Langevin Dynamics(http://arxiv.org/abs/2311.13664)</code></li>
<li>Summary: <p>We present a novel algorithm for parameter learning in generic deep
generative models that builds upon the predictive coding (PC) framework of
computational neuroscience. Our approach modifies the standard PC algorithm to
bring performance on-par and exceeding that obtained from standard variational
auto-encoder (VAE) training. By injecting Gaussian noise into the PC inference
procedure we re-envision it as an overdamped Langevin sampling, which
facilitates optimisation with respect to a tight evidence lower bound (ELBO).
We improve the resultant encoder-free training method by incorporating an
encoder network to provide an amortised warm-start to our Langevin sampling and
test three different objectives for doing so. Finally, to increase robustness
to the sampling step size and reduce sensitivity to curvature, we validate a
lightweight and easily computable form of preconditioning, inspired by Riemann
Manifold Langevin and adaptive optimizers from the SGD literature. We compare
against VAEs by training like-for-like generative models using our technique
against those trained with standard reparameterisation-trick-based ELBOs. We
observe our method out-performs or matches performance across a number of
metrics, including sample quality, while converging in a fraction of the number
of SGD training iterations.
</p></li>
</ul>

<h3>Title: A Somewhat Robust Image Watermark against Diffusion-based Editing Models. (arXiv:2311.13713v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13713">http://arxiv.org/abs/2311.13713</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13713]] A Somewhat Robust Image Watermark against Diffusion-based Editing Models(http://arxiv.org/abs/2311.13713)</code></li>
<li>Summary: <p>Recently, diffusion models (DMs) have become the state-of-the-art method for
image synthesis. Editing models based on DMs, known for their high fidelity and
precision, have inadvertently introduced new challenges related to image
copyright infringement and malicious editing. Our work is the first to
formalize and address this issue. After assessing and attempting to enhance
traditional image watermarking techniques, we recognize their limitations in
this emerging context. In response, we develop a novel technique, RIW (Robust
Invisible Watermarking), to embed invisible watermarks leveraging adversarial
example techniques. Our technique ensures a high extraction accuracy of $96\%$
for the invisible watermark after editing, compared to the $0\%$ offered by
conventional methods. We provide access to our code at
https://github.com/BennyTMT/RIW.
</p></li>
</ul>

<h3>Title: GS-Pose: Category-Level Object Pose Estimation via Geometric and Semantic Correspondence. (arXiv:2311.13777v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13777">http://arxiv.org/abs/2311.13777</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13777]] GS-Pose: Category-Level Object Pose Estimation via Geometric and Semantic Correspondence(http://arxiv.org/abs/2311.13777)</code></li>
<li>Summary: <p>Category-level pose estimation is a challenging task with many potential
applications in computer vision and robotics. Recently, deep-learning-based
approaches have made great progress, but are typically hindered by the need for
large datasets of either pose-labelled real images or carefully tuned
photorealistic simulators. This can be avoided by using only geometry inputs
such as depth images to reduce the domain-gap but these approaches suffer from
a lack of semantic information, which can be vital in the pose estimation
problem. To resolve this conflict, we propose to utilize both geometric and
semantic features obtained from a pre-trained foundation model.Our approach
projects 2D features from this foundation model into 3D for a single object
model per category, and then performs matching against this for new single view
observations of unseen object instances with a trained matching network. This
requires significantly less data to train than prior methods since the semantic
features are robust to object texture and appearance. We demonstrate this with
a rich evaluation, showing improved performance over prior methods with a
fraction of the data required.
</p></li>
</ul>

<h3>Title: Evidential Active Recognition: Intelligent and Prudent Open-World Embodied Perception. (arXiv:2311.13793v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13793">http://arxiv.org/abs/2311.13793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13793]] Evidential Active Recognition: Intelligent and Prudent Open-World Embodied Perception(http://arxiv.org/abs/2311.13793)</code></li>
<li>Summary: <p>Active recognition enables robots to intelligently explore novel
observations, thereby acquiring more information while circumventing undesired
viewing conditions. Recent approaches favor learning policies from simulated or
collected data, wherein appropriate actions are more frequently selected when
the recognition is accurate. However, most recognition modules are developed
under the closed-world assumption, which makes them ill-equipped to handle
unexpected inputs, such as the absence of the target object in the current
observation. To address this issue, we propose treating active recognition as a
sequential evidence-gathering process, providing by-step uncertainty
quantification and reliable prediction under the evidence combination theory.
Additionally, the reward function developed in this paper effectively
characterizes the merit of actions when operating in open-world environments.
To evaluate the performance, we collect a dataset from an indoor simulator,
encompassing various recognition challenges such as distance, occlusion levels,
and visibility. Through a series of experiments on recognition and robustness
analysis, we demonstrate the necessity of introducing uncertainties to active
recognition and the superior performance of the proposed method.
</p></li>
</ul>

<h3>Title: Parameter Exchange for Robust Dynamic Domain Generalization. (arXiv:2311.13928v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13928">http://arxiv.org/abs/2311.13928</a></li>
<li>Code URL: https://github.com/metavisionlab/pe</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13928]] Parameter Exchange for Robust Dynamic Domain Generalization(http://arxiv.org/abs/2311.13928)</code></li>
<li>Summary: <p>Agnostic domain shift is the main reason of model degradation on the unknown
target domains, which brings an urgent need to develop Domain Generalization
(DG). Recent advances at DG use dynamic networks to achieve training-free
adaptation on the unknown target domains, termed Dynamic Domain Generalization
(DDG), which compensates for the lack of self-adaptability in static models
with fixed weights. The parameters of dynamic networks can be decoupled into a
static and a dynamic component, which are designed to learn domain-invariant
and domain-specific features, respectively. Based on the existing arts, in this
work, we try to push the limits of DDG by disentangling the static and dynamic
components more thoroughly from an optimization perspective. Our main
consideration is that we can enable the static component to learn
domain-invariant features more comprehensively by augmenting the
domain-specific information. As a result, the more comprehensive
domain-invariant features learned by the static component can then enforce the
dynamic component to focus more on learning adaptive domain-specific features.
To this end, we propose a simple yet effective Parameter Exchange (PE) method
to perturb the combination between the static and dynamic components. We
optimize the model using the gradients from both the perturbed and
non-perturbed feed-forward jointly to implicitly achieve the aforementioned
disentanglement. In this way, the two components can be optimized in a
mutually-beneficial manner, which can resist the agnostic domain shifts and
improve the self-adaptability on the unknown target domain. Extensive
experiments show that PE can be easily plugged into existing dynamic networks
to improve their generalization ability without bells and whistles.
</p></li>
</ul>

<h3>Title: Robustness-Reinforced Knowledge Distillation with Correlation Distance and Network Pruning. (arXiv:2311.13934v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13934">http://arxiv.org/abs/2311.13934</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13934]] Robustness-Reinforced Knowledge Distillation with Correlation Distance and Network Pruning(http://arxiv.org/abs/2311.13934)</code></li>
<li>Summary: <p>The improvement in the performance of efficient and lightweight models (i.e.,
the student model) is achieved through knowledge distillation (KD), which
involves transferring knowledge from more complex models (i.e., the teacher
model). However, most existing KD techniques rely on Kullback-Leibler (KL)
divergence, which has certain limitations. First, if the teacher distribution
has high entropy, the KL divergence's mode-averaging nature hinders the
transfer of sufficient target information. Second, when the teacher
distribution has low entropy, the KL divergence tends to excessively focus on
specific modes, which fails to convey an abundant amount of valuable knowledge
to the student. Consequently, when dealing with datasets that contain numerous
confounding or challenging samples, student models may struggle to acquire
sufficient knowledge, resulting in subpar performance. Furthermore, in previous
KD approaches, we observed that data augmentation, a technique aimed at
enhancing a model's generalization, can have an adverse impact. Therefore, we
propose a Robustness-Reinforced Knowledge Distillation (R2KD) that leverages
correlation distance and network pruning. This approach enables KD to
effectively incorporate data augmentation for performance improvement.
Extensive experiments on various datasets, including CIFAR-100, FGVR,
TinyImagenet, and ImageNet, demonstrate our method's superiority over current
state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Shadow: A Novel Loss Function for Efficient Training in Siamese Networks. (arXiv:2311.14012v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14012">http://arxiv.org/abs/2311.14012</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14012]] Shadow: A Novel Loss Function for Efficient Training in Siamese Networks(http://arxiv.org/abs/2311.14012)</code></li>
<li>Summary: <p>Despite significant recent advances in similarity detection tasks, existing
approaches pose substantial challenges under memory constraints. One of the
primary reasons for this is the use of computationally expensive metric
learning loss functions such as Triplet Loss in Siamese networks. In this
paper, we present a novel loss function called Shadow Loss that compresses the
dimensions of an embedding space during loss calculation without loss of
performance. The distance between the projections of the embeddings is learned
from inputs on a compact projection space where distances directly correspond
to a measure of class similarity. Projecting on a lower-dimension projection
space, our loss function converges faster, and the resulting classified image
clusters have higher inter-class and smaller intra-class distances. Shadow Loss
not only reduces embedding dimensions favoring memory constraint devices but
also consistently performs better than the state-of-the-art Triplet Margin Loss
by an accuracy of 5\%-10\% across diverse datasets. The proposed loss function
is also model agnostic, upholding its performance across several tested models.
Its effectiveness and robustness across balanced, imbalanced, medical, and
non-medical image datasets suggests that it is not specific to a particular
model or dataset but demonstrates superior performance consistently while using
less memory and computation.
</p></li>
</ul>

<h3>Title: Understanding the Vulnerability of CLIP to Image Compression. (arXiv:2311.14029v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14029">http://arxiv.org/abs/2311.14029</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14029]] Understanding the Vulnerability of CLIP to Image Compression(http://arxiv.org/abs/2311.14029)</code></li>
<li>Summary: <p>CLIP is a widely used foundational vision-language model that is used for
zero-shot image recognition and other image-text alignment tasks. We
demonstrate that CLIP is vulnerable to change in image quality under
compression. This surprising result is further analysed using an attribution
method-Integrated Gradients. Using this attribution method, we are able to
better understand both quantitatively and qualitatively exactly the nature in
which the compression affects the zero-shot recognition accuracy of this model.
We evaluate this extensively on CIFAR-10 and STL-10. Our work provides the
basis to understand this vulnerability of CLIP and can help us develop more
effective methods to improve the robustness of CLIP and other vision-language
models.
</p></li>
</ul>

<h3>Title: Hardware Resilience Properties of Text-Guided Image Classifiers. (arXiv:2311.14062v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14062">http://arxiv.org/abs/2311.14062</a></li>
<li>Code URL: https://github.com/talalwasim/textguidedresilience</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14062]] Hardware Resilience Properties of Text-Guided Image Classifiers(http://arxiv.org/abs/2311.14062)</code></li>
<li>Summary: <p>This paper presents a novel method to enhance the reliability of image
classification models during deployment in the face of transient hardware
errors. By utilizing enriched text embeddings derived from GPT-3 with question
prompts per class and CLIP pretrained text encoder, we investigate their impact
as an initialization for the classification layer. Our approach achieves a
remarkable $5.5\times$ average increase in hardware reliability (and up to 14x)
across various architectures in the most critical layer, with minimal accuracy
drop (0.3% on average) compared to baseline PyTorch models. Furthermore, our
method seamlessly integrates with any image classification backbone, showcases
results across various network architectures, decreases parameter and FLOPs
overhead, and follows a consistent training recipe. This research offers a
practical and efficient solution to bolster the robustness of image
classification models against hardware failures, with potential implications
for future studies in this domain. Our code and models are released at
https://github.com/TalalWasim/TextGuidedResilience.
</p></li>
</ul>

<h3>Title: Do VSR Models Generalize Beyond LRS3?. (arXiv:2311.14063v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14063">http://arxiv.org/abs/2311.14063</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14063]] Do VSR Models Generalize Beyond LRS3?(http://arxiv.org/abs/2311.14063)</code></li>
<li>Summary: <p>The Lip Reading Sentences-3 (LRS3) benchmark has primarily been the focus of
intense research in visual speech recognition (VSR) during the last few years.
As a result, there is an increased risk of overfitting to its excessively used
test set, which is only one hour duration. To alleviate this issue, we build a
new VSR test set named WildVSR, by closely following the LRS3 dataset creation
processes. We then evaluate and analyse the extent to which the current VSR
models generalize to the new test data. We evaluate a broad range of publicly
available VSR models and find significant drops in performance on our test set,
compared to their corresponding LRS3 results. Our results suggest that the
increase in word error rates is caused by the models inability to generalize to
slightly harder and in the wild lip sequences than those found in the LRS3 test
set. Our new test benchmark is made public in order to enable future research
towards more robust VSR models.
</p></li>
</ul>

<h3>Title: GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence. (arXiv:2311.14155v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14155">http://arxiv.org/abs/2311.14155</a></li>
<li>Code URL: https://github.com/nv-nguyen/gigapose</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14155]] GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence(http://arxiv.org/abs/2311.14155)</code></li>
<li>Summary: <p>We present GigaPose, a fast, robust, and accurate method for CAD-based novel
object pose estimation in RGB images. GigaPose first leverages discriminative
templates, rendered images of the CAD models, to recover the out-of-plane
rotation and then uses patch correspondences to estimate the four remaining
parameters. Our approach samples templates in only a two-degrees-of-freedom
space instead of the usual three and matches the input image to the templates
using fast nearest neighbor search in feature space, results in a speedup
factor of 38x compared to the state of the art. Moreover, GigaPose is
significantly more robust to segmentation errors. Our extensive evaluation on
the seven core datasets of the BOP challenge demonstrates that it achieves
state-of-the-art accuracy and can be seamlessly integrated with a refinement
method. Additionally, we show the potential of GigaPose with 3D models
predicted by recent work on 3D reconstruction from a single image, relaxing the
need for CAD models and making 6D pose object estimation much more convenient.
Our source code and trained models are publicly available at
https://github.com/nv-nguyen/gigaPose
</p></li>
</ul>

<h3>Title: Optimal Power Flow in Highly Renewable Power System Based on Attention Neural Networks. (arXiv:2311.13949v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13949">http://arxiv.org/abs/2311.13949</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13949]] Optimal Power Flow in Highly Renewable Power System Based on Attention Neural Networks(http://arxiv.org/abs/2311.13949)</code></li>
<li>Summary: <p>The Optimal Power Flow (OPF) problem is pivotal for power system operations,
guiding generator output and power distribution to meet demand at minimized
costs, while adhering to physical and engineering constraints. The integration
of renewable energy sources, like wind and solar, however, poses challenges due
to their inherent variability. This variability, driven largely by changing
weather conditions, demands frequent recalibrations of power settings, thus
necessitating recurrent OPF resolutions. This task is daunting using
traditional numerical methods, particularly for extensive power systems. In
this work, we present a cutting-edge, physics-informed machine learning
methodology, trained using imitation learning and historical European weather
datasets. Our approach directly correlates electricity demand and weather
patterns with power dispatch and generation, circumventing the iterative
requirements of traditional OPF solvers. This offers a more expedient solution
apt for real-time applications. Rigorous evaluations on aggregated European
power systems validate our method's superiority over existing data-driven
techniques in OPF solving. By presenting a quick, robust, and efficient
solution, this research sets a new standard in real-time OPF resolution, paving
the way for more resilient power systems in the era of renewable energy.
</p></li>
</ul>

<h3>Title: MedISure: Towards Assuring Machine Learning-based Medical Image Classifiers using Mixup Boundary Analysis. (arXiv:2311.13978v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13978">http://arxiv.org/abs/2311.13978</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13978]] MedISure: Towards Assuring Machine Learning-based Medical Image Classifiers using Mixup Boundary Analysis(http://arxiv.org/abs/2311.13978)</code></li>
<li>Summary: <p>Machine learning (ML) models are becoming integral in healthcare
technologies, presenting a critical need for formal assurance to validate their
safety, fairness, robustness, and trustworthiness. These models are inherently
prone to errors, potentially posing serious risks to patient health and could
even cause irreparable harm. Traditional software assurance techniques rely on
fixed code and do not directly apply to ML models since these algorithms are
adaptable and learn from curated datasets through a training process. However,
adapting established principles, such as boundary testing using synthetic test
data can effectively bridge this gap. To this end, we present a novel technique
called Mix-Up Boundary Analysis (MUBA) that facilitates evaluating image
classifiers in terms of prediction fairness. We evaluated MUBA for two
important medical imaging tasks -- brain tumour classification and breast
cancer classification -- and achieved promising results. This research aims to
showcase the importance of adapting traditional assurance principles for
assessing ML models to enhance the safety and reliability of healthcare
technologies. To facilitate future research, we plan to publicly release our
code for MUBA.
</p></li>
</ul>

<h3>Title: MINTY: Rule-based Models that Minimize the Need for Imputing Features with Missing Values. (arXiv:2311.14108v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14108">http://arxiv.org/abs/2311.14108</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14108]] MINTY: Rule-based Models that Minimize the Need for Imputing Features with Missing Values(http://arxiv.org/abs/2311.14108)</code></li>
<li>Summary: <p>Rule models are often preferred in prediction tasks with tabular inputs as
they can be easily interpreted using natural language and provide predictive
performance on par with more complex models. However, most rule models'
predictions are undefined or ambiguous when some inputs are missing, forcing
users to rely on statistical imputation models or heuristics like zero
imputation, undermining the interpretability of the models. In this work, we
propose fitting concise yet precise rule models that learn to avoid relying on
features with missing values and, therefore, limit their reliance on imputation
at test time. We develop MINTY, a method that learns rules in the form of
disjunctions between variables that act as replacements for each other when one
or more is missing. This results in a sparse linear rule model, regularized to
have small dependence on features with missing values, that allows a trade-off
between goodness of fit, interpretability, and robustness to missing values at
test time. We demonstrate the value of MINTY in experiments using synthetic and
real-world data sets and find its predictive performance comparable or
favorable to baselines, with smaller reliance on features with missing values.
</p></li>
</ul>

<h3>Title: Byzantine Robustness and Partial Participation Can Be Achieved Simultaneously: Just Clip Gradient Differences. (arXiv:2311.14127v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14127">http://arxiv.org/abs/2311.14127</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14127]] Byzantine Robustness and Partial Participation Can Be Achieved Simultaneously: Just Clip Gradient Differences(http://arxiv.org/abs/2311.14127)</code></li>
<li>Summary: <p>Distributed learning has emerged as a leading paradigm for training large
machine learning models. However, in real-world scenarios, participants may be
unreliable or malicious, posing a significant challenge to the integrity and
accuracy of the trained models. Byzantine fault tolerance mechanisms have been
proposed to address these issues, but they often assume full participation from
all clients, which is not always practical due to the unavailability of some
clients or communication constraints. In our work, we propose the first
distributed method with client sampling and provable tolerance to Byzantine
workers. The key idea behind the developed method is the use of gradient
clipping to control stochastic gradient differences in recursive variance
reduction. This allows us to bound the potential harm caused by Byzantine
workers, even during iterations when all sampled clients are Byzantine.
Furthermore, we incorporate communication compression into the method to
enhance communication efficiency. Under quite general assumptions, we prove
convergence rates for the proposed method that match the existing
state-of-the-art (SOTA) theoretical results.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h3>Title: Steal My Artworks for Fine-tuning? A Watermarking Framework for Detecting Art Theft Mimicry in Text-to-Image Models. (arXiv:2311.13619v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13619">http://arxiv.org/abs/2311.13619</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13619]] Steal My Artworks for Fine-tuning? A Watermarking Framework for Detecting Art Theft Mimicry in Text-to-Image Models(http://arxiv.org/abs/2311.13619)</code></li>
<li>Summary: <p>The advancement in text-to-image models has led to astonishing artistic
performances. However, several studios and websites illegally fine-tune these
models using artists' artworks to mimic their styles for profit, which violates
the copyrights of artists and diminishes their motivation to produce original
works. Currently, there is a notable lack of research focusing on this issue.
In this paper, we propose a novel watermarking framework that detects mimicry
in text-to-image models through fine-tuning. This framework embeds subtle
watermarks into digital artworks to protect their copyrights while still
preserving the artist's visual expression. If someone takes watermarked
artworks as training data to mimic an artist's style, these watermarks can
serve as detectable indicators. By analyzing the distribution of these
watermarks in a series of generated images, acts of fine-tuning mimicry using
stolen victim data will be exposed. In various fine-tune scenarios and against
watermark attack methods, our research confirms that analyzing the distribution
of watermarks in artificially generated images reliably detects unauthorized
mimicry.
</p></li>
</ul>

<h2>extraction</h2>
<h3>Title: Importance of Feature Extraction in the Calculation of Fr\'echet Distance for Medical Imaging. (arXiv:2311.13717v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13717">http://arxiv.org/abs/2311.13717</a></li>
<li>Code URL: https://github.com/mckellwoodland/fid-med-eval</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13717]] Importance of Feature Extraction in the Calculation of Fr\'echet Distance for Medical Imaging(http://arxiv.org/abs/2311.13717)</code></li>
<li>Summary: <p>Fr\'echet Inception Distance is a widely used metric for evaluating synthetic
image quality that utilizes an ImageNet-trained InceptionV3 network as a
feature extractor. However, its application in medical imaging lacks a standard
feature extractor, leading to biased and inconsistent comparisons. This study
aimed to compare state-of-the-art feature extractors for computing Fr\'echet
Distances (FDs) in medical imaging. A StyleGAN2 network was trained with data
augmentation techniques tailored for limited data domains on datasets
comprising three medical imaging modalities and four anatomical locations.
Human evaluation of generative quality (via a visual Turing test) was compared
to FDs calculated using ImageNet-trained InceptionV3, ResNet50, SwAV, DINO, and
Swin Transformer architectures, in addition to an InceptionV3 network trained
on a large medical dataset, RadImageNet. All ImageNet-based extractors were
consistent with each other, but only SwAV was significantly correlated with
medical expert judgment. The RadImageNet-based FD showed volatility and lacked
correlation with human judgment. Caution is advised when using medical
image-trained extraction networks in the FD calculation. These networks should
be rigorously evaluated on the imaging modality under consideration and
publicly released. ImageNet-based extractors, while imperfect, are consistent
and widely understood. Training extraction networks with SwAV is a promising
approach for synthetic medical image evaluation.
</p></li>
</ul>

<h3>Title: EIGEN: Expert-Informed Joint Learning Aggregation for High-Fidelity Information Extraction from Document Images. (arXiv:2311.13993v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13993">http://arxiv.org/abs/2311.13993</a></li>
<li>Code URL: https://github.com/ayushayush591/eigen-high-fidelity-extraction-document-images</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13993]] EIGEN: Expert-Informed Joint Learning Aggregation for High-Fidelity Information Extraction from Document Images(http://arxiv.org/abs/2311.13993)</code></li>
<li>Summary: <p>Information Extraction (IE) from document images is challenging due to the
high variability of layout formats. Deep models such as LayoutLM and BROS have
been proposed to address this problem and have shown promising results.
However, they still require a large amount of field-level annotations for
training these models. Other approaches using rule-based methods have also been
proposed based on the understanding of the layout and semantics of a form such
as geometric position, or type of the fields, etc. In this work, we propose a
novel approach, EIGEN (Expert-Informed Joint Learning aGgrEatioN), which
combines rule-based methods with deep learning models using data programming
approaches to circumvent the requirement of annotation of large amounts of
training data. Specifically, EIGEN consolidates weak labels induced from
multiple heuristics through generative models and use them along with a small
number of annotated labels to jointly train a deep model. In our framework, we
propose the use of labeling functions that include incorporating contextual
information thus capturing the visual and language context of a word for
accurate categorization. We empirically show that our EIGEN framework can
significantly improve the performance of state-of-the-art deep models with the
availability of very few labeled data instances. The source code is available
at
https://github.com/ayushayush591/EIGEN-High-Fidelity-Extraction-Document-Images.
</p></li>
</ul>

<h3>Title: Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case. (arXiv:2311.13729v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13729">http://arxiv.org/abs/2311.13729</a></li>
<li>Code URL: https://github.com/shashank140195/raredis</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13729]] Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case(http://arxiv.org/abs/2311.13729)</code></li>
<li>Summary: <p>End-to-end relation extraction (E2ERE) is an important and realistic
application of natural language processing (NLP) in biomedicine. In this paper,
we aim to compare three prevailing paradigms for E2ERE using a complex dataset
focused on rare diseases involving discontinuous and nested entities. We use
the RareDis information extraction dataset to evaluate three competing
approaches (for E2ERE): NER $\rightarrow$ RE pipelines, joint sequence to
sequence models, and generative pre-trained transformer (GPT) models. We use
comparable state-of-the-art models and best practices for each of these
approaches and conduct error analyses to assess their failure modes. Our
findings reveal that pipeline models are still the best, while
sequence-to-sequence models are not far behind; GPT models with eight times as
many parameters are worse than even sequence-to-sequence models and lose to
pipeline models by over 10 F1 points. Partial matches and discontinuous
entities caused many NER errors contributing to lower overall E2E performances.
We also verify these findings on a second E2ERE dataset for chemical-protein
interactions. Although generative LM-based methods are more suitable for
zero-shot settings, when training data is available, our results show that it
is better to work with more conventional models trained and tailored for E2ERE.
More innovative methods are needed to marry the best of the both worlds from
smaller encoder-decoder pipeline models and the larger GPT models to improve
E2ERE. As of now, we see that well designed pipeline models offer substantial
performance gains at a lower cost and carbon footprint for E2ERE. Our
contribution is also the first to conduct E2ERE for the RareDis dataset.
</p></li>
</ul>

<h3>Title: Question Answering in Natural Language: the Special Case of Temporal Expressions. (arXiv:2311.14087v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14087">http://arxiv.org/abs/2311.14087</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14087]] Question Answering in Natural Language: the Special Case of Temporal Expressions(http://arxiv.org/abs/2311.14087)</code></li>
<li>Summary: <p>Although general question answering has been well explored in recent years,
temporal question answering is a task which has not received as much focus. Our
work aims to leverage a popular approach used for general question answering,
answer extraction, in order to find answers to temporal questions within a
paragraph. To train our model, we propose a new dataset, inspired by SQuAD,
specifically tailored to provide rich temporal information. We chose to adapt
the corpus WikiWars, which contains several documents on history's greatest
conflicts. Our evaluation shows that a deep learning model trained to perform
pattern matching, often used in general question answering, can be adapted to
temporal question answering, if we accept to ask questions whose answers must
be directly present within a text.
</p></li>
</ul>

<h3>Title: Molly: A Verified Compiler for Cryptoprotocol Roles. (arXiv:2311.13692v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13692">http://arxiv.org/abs/2311.13692</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13692]] Molly: A Verified Compiler for Cryptoprotocol Roles(http://arxiv.org/abs/2311.13692)</code></li>
<li>Summary: <p>Molly is a program that compiles cryptographic protocol roles written in a
high-level notation into straight-line programs in an intermediate-level
imperative language, suitable for implementation in a conventional programming
language. We define a denotational semantics for protocol roles based on an
axiomatization of the runtime. A notable feature of our approach is that we
assume that encryption is randomized. Thus, at the runtime level we treat
encryption as a relation rather than a function. Molly is written in Coq, and
generates a machine-checked proof that the procedure it constructs is correct
with respect to the runtime semantics. Using Coq's extraction mechanism, one
can build an efficient functional program for compilation.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Enhancing Intrusion Detection In Internet Of Vehicles Through Federated Learning. (arXiv:2311.13800v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13800">http://arxiv.org/abs/2311.13800</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13800]] Enhancing Intrusion Detection In Internet Of Vehicles Through Federated Learning(http://arxiv.org/abs/2311.13800)</code></li>
<li>Summary: <p>Federated learning is a technique of decentralized machine learning. that
allows multiple parties to collaborate and learn a shared model without sharing
their raw data. Our paper proposes a federated learning framework for intrusion
detection in Internet of Vehicles (IOVs) using the CIC-IDS 2017 dataset. The
proposed framework employs SMOTE for handling class imbalance, outlier
detection for identifying and removing abnormal observations, and
hyperparameter tuning to optimize the model's performance. The authors
evaluated the proposed framework using various performance metrics and
demonstrated its effectiveness in detecting intrusions with other datasets
(KDD-Cup 99 and UNSW- NB-15) and conventional classifiers. Furthermore, the
proposed framework can protect sensitive data while achieving high intrusion
detection performance.
</p></li>
</ul>

<h3>Title: A Joint Gradient and Loss Based Clustered Federated Learning Design. (arXiv:2311.13665v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13665">http://arxiv.org/abs/2311.13665</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13665]] A Joint Gradient and Loss Based Clustered Federated Learning Design(http://arxiv.org/abs/2311.13665)</code></li>
<li>Summary: <p>In this paper, a novel clustered FL framework that enables distributed edge
devices with non-IID data to independently form several clusters in a
distributed manner and implement FL training within each cluster is proposed.
In particular, our designed clustered FL algorithm must overcome two challenges
associated with FL training. First, the server has limited FL training
information (i.e., the parameter server can only obtain the FL model
information of each device) and limited computational power for finding the
differences among a large amount of devices. Second, each device does not have
the data information of other devices for device clustering and can only use
global FL model parameters received from the server and its data information to
determine its cluster identity, which will increase the difficulty of device
clustering. To overcome these two challenges, we propose a joint gradient and
loss based distributed clustering method in which each device determines its
cluster identity considering the gradient similarity and training loss. The
proposed clustering method not only considers how a local FL model of one
device contributes to each cluster but also the direction of gradient descent
thus improving clustering speed. By delegating clustering decisions to edge
devices, each device can fully leverage its private data information to
determine its own cluster identity, thereby reducing clustering overhead and
improving overall clustering performance. Simulation results demonstrate that
our proposed clustered FL algorithm can reduce clustering iterations by up to
99% compared to the existing baseline.
</p></li>
</ul>

<h3>Title: AdapterFL: Adaptive Heterogeneous Federated Learning for Resource-constrained Mobile Computing Systems. (arXiv:2311.14037v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14037">http://arxiv.org/abs/2311.14037</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14037]] AdapterFL: Adaptive Heterogeneous Federated Learning for Resource-constrained Mobile Computing Systems(http://arxiv.org/abs/2311.14037)</code></li>
<li>Summary: <p>Federated Learning (FL) enables collaborative learning of large-scale
distributed clients without data sharing. However, due to the disparity of
computing resources among massive mobile computing devices, the performance of
traditional homogeneous model-based Federated Learning (FL) is seriously
limited. On the one hand, to achieve model training in all the diverse clients,
mobile computing systems can only use small low-performance models for
collaborative learning. On the other hand, devices with high computing
resources cannot train a high-performance large model with their insufficient
raw data. To address the resource-constrained problem in mobile computing
systems, we present a novel heterogeneous FL approach named AdapterFL, which
uses a model reassemble strategy to facilitate collaborative training of
massive heterogeneous mobile devices adaptively. Specifically, we select
multiple candidate heterogeneous models based on the computing performance of
massive mobile devices and then divide each heterogeneous model into two
partitions. By reassembling the partitions, we can generate models with varied
sizes that are combined by the partial parameters of the large model with the
partial parameters of the small model. Using these reassembled models for FL
training, we can train the partial parameters of the large model using
low-performance devices. In this way, we can alleviate performance degradation
in large models due to resource constraints. The experimental results show that
AdapterFL can achieve up to 12\% accuracy improvement compared to the
state-of-the-art heterogeneous federated learning methods in
resource-constrained scenarios.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: A Unified Framework for Fair Spectral Clustering With Effective Graph Learning. (arXiv:2311.13766v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13766">http://arxiv.org/abs/2311.13766</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13766]] A Unified Framework for Fair Spectral Clustering With Effective Graph Learning(http://arxiv.org/abs/2311.13766)</code></li>
<li>Summary: <p>We consider the problem of spectral clustering under group fairness
constraints, where samples from each sensitive group are approximately
proportionally represented in each cluster. Traditional fair spectral
clustering (FSC) methods consist of two consecutive stages, i.e., performing
fair spectral embedding on a given graph and conducting $k$means to obtain
discrete cluster labels. However, in practice, the graph is usually unknown,
and we need to construct the underlying graph from potentially noisy data, the
quality of which inevitably affects subsequent fair clustering performance.
Furthermore, performing FSC through separate steps breaks the connections among
these steps, leading to suboptimal results. To this end, we first theoretically
analyze the effect of the constructed graph on FSC. Motivated by the analysis,
we propose a novel graph construction method with a node-adaptive graph filter
to learn graphs from noisy data. Then, all independent stages of conventional
FSC are integrated into a single objective function, forming an end-to-end
framework that inputs raw data and outputs discrete cluster labels. An
algorithm is developed to jointly and alternately update the variables in each
stage. Finally, we conduct extensive experiments on synthetic, benchmark, and
real data, which show that our model is superior to state-of-the-art fair
clustering methods.
</p></li>
</ul>

<h3>Title: Fairness-Aware Domain Generalization under Covariate and Dependence Shifts. (arXiv:2311.13816v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13816">http://arxiv.org/abs/2311.13816</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13816]] Fairness-Aware Domain Generalization under Covariate and Dependence Shifts(http://arxiv.org/abs/2311.13816)</code></li>
<li>Summary: <p>Achieving the generalization of an invariant classifier from source domains
to shifted target domains while simultaneously considering model fairness is a
substantial and complex challenge in machine learning. Existing domain
generalization research typically attributes domain shifts to concept shift,
which relates to alterations in class labels, and covariate shift, which
pertains to variations in data styles. In this paper, by introducing another
form of distribution shift, known as dependence shift, which involves
variations in fair dependence patterns across domains, we propose a novel
domain generalization approach that addresses domain shifts by considering both
covariate and dependence shifts. We assert the existence of an underlying
transformation model can transform data from one domain to another. By
generating data in synthetic domains through the model, a fairness-aware
invariant classifier is learned that enforces both model accuracy and fairness
in unseen domains. Extensive empirical studies on four benchmark datasets
demonstrate that our approach surpasses state-of-the-art methods.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Unsupervised Learning for Topological Classification of Transportation Networks. (arXiv:2311.13887v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13887">http://arxiv.org/abs/2311.13887</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13887]] Unsupervised Learning for Topological Classification of Transportation Networks(http://arxiv.org/abs/2311.13887)</code></li>
<li>Summary: <p>With increasing urbanization, transportation plays an increasingly critical
role in city development. The number of studies on modeling, optimization,
simulation, and data analysis of transportation systems is on the rise. Many of
these studies utilize transportation test networks to represent real-world
transportation systems in urban areas, examining the efficacy of their proposed
approaches. Each of these networks exhibits unique characteristics in their
topology, making their applications distinct for various study objectives.
Despite their widespread use in research, there is a lack of comprehensive
study addressing the classification of these networks based on their
topological characteristics. This study aims to fill this gap by employing
unsupervised learning methods, particularly clustering. We present a
comprehensive framework for evaluating various topological network
characteristics. Additionally, we employ two dimensionality reduction
techniques, namely Principal Component Analysis (PCA) and Isometric Feature
Mapping (ISOMAP), to reduce overlaps of highly correlated features and enhance
the interpretability of the subsequent classification results. We then utilize
two clustering algorithms, K-means and HDBSCAN, to classify 14 transportation
networks. The PCA method, followed by the K-means clustering approach,
outperforms other alternatives with a Silhouette score of $0.510$, enabling the
classification of transportation networks into five clusters. We also provide a
detailed discussion on the resulting classification.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: You Only Explain Once. (arXiv:2311.14081v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14081">http://arxiv.org/abs/2311.14081</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14081]] You Only Explain Once(http://arxiv.org/abs/2311.14081)</code></li>
<li>Summary: <p>In this paper, we propose a new black-box explainability algorithm and tool,
YO-ReX, for efficient explanation of the outputs of object detectors. The new
algorithm computes explanations for all objects detected in the image
simultaneously. Hence, compared to the baseline, the new algorithm reduces the
number of queries by a factor of 10X for the case of ten detected objects. The
speedup increases further with with the number of objects. Our experimental
results demonstrate that YO-ReX can explain the outputs of YOLO with a
negligible overhead over the running time of YOLO. We also demonstrate similar
results for explaining SSD and Faster R-CNN. The speedup is achieved by
avoiding backtracking by combining aggressive pruning with a causal analysis.
</p></li>
</ul>

<h3>Title: On the Hyperparameter Landscapes of Machine Learning Algorithms. (arXiv:2311.14014v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14014">http://arxiv.org/abs/2311.14014</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14014]] On the Hyperparameter Landscapes of Machine Learning Algorithms(http://arxiv.org/abs/2311.14014)</code></li>
<li>Summary: <p>Despite the recent success in a plethora of hyperparameter optimization (HPO)
methods for machine learning (ML) models, the intricate interplay between model
hyperparameters (HPs) and predictive losses (a.k.a fitness), which is a key
prerequisite for understanding HPO, remain notably underexplored in our
community. This results in limited explainability in the HPO process, rendering
a lack of human trust and difficulties in pinpointing algorithm bottlenecks. In
this paper, we aim to shed light on this black box by conducting large-scale
fitness landscape analysis (FLA) on 1,500 HP loss landscapes of 6 ML models
with more than 11 model configurations, across 67 datasets and different levels
of fidelities. We reveal the first unified, comprehensive portrait of their
topographies in terms of smoothness, neutrality and modality. We also show that
such properties are highly transferable across datasets and fidelities,
providing fundamental evidence for the success of multi-fidelity and transfer
learning methods. These findings are made possible by developing a dedicated
FLA framework that incorporates a combination of visual and quantitative
measures. We further demonstrate the potential of this framework by analyzing
the NAS-Bench-101 landscape, and we believe it is able to faciliate fundamental
understanding of a broader range of AutoML tasks.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Breathing Life Into Sketches Using Text-to-Video Priors. (arXiv:2311.13608v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13608">http://arxiv.org/abs/2311.13608</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13608]] Breathing Life Into Sketches Using Text-to-Video Priors(http://arxiv.org/abs/2311.13608)</code></li>
<li>Summary: <p>A sketch is one of the most intuitive and versatile tools humans use to
convey their ideas visually. An animated sketch opens another dimension to the
expression of ideas and is widely used by designers for a variety of purposes.
Animating sketches is a laborious process, requiring extensive experience and
professional design skills. In this work, we present a method that
automatically adds motion to a single-subject sketch (hence, "breathing life
into it"), merely by providing a text prompt indicating the desired motion. The
output is a short animation provided in vector representation, which can be
easily edited. Our method does not require extensive training, but instead
leverages the motion prior of a large pretrained text-to-video diffusion model
using a score-distillation loss to guide the placement of strokes. To promote
natural and smooth motion and to better preserve the sketch's appearance, we
model the learned motion through two components. The first governs small local
deformations and the second controls global affine transformations.
Surprisingly, we find that even models that struggle to generate sketch videos
on their own can still serve as a useful backbone for animating abstract
representations.
</p></li>
</ul>

<h3>Title: Boosting3D: High-Fidelity Image-to-3D by Boosting 2D Diffusion Prior to 3D Prior with Progressive Learning. (arXiv:2311.13617v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13617">http://arxiv.org/abs/2311.13617</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13617]] Boosting3D: High-Fidelity Image-to-3D by Boosting 2D Diffusion Prior to 3D Prior with Progressive Learning(http://arxiv.org/abs/2311.13617)</code></li>
<li>Summary: <p>We present Boosting3D, a multi-stage single image-to-3D generation method
that can robustly generate reasonable 3D objects in different data domains. The
point of this work is to solve the view consistency problem in single
image-guided 3D generation by modeling a reasonable geometric structure. For
this purpose, we propose to utilize better 3D prior to training the NeRF. More
specifically, we train an object-level LoRA for the target object using
original image and the rendering output of NeRF. And then we train the LoRA and
NeRF using a progressive training strategy. The LoRA and NeRF will boost each
other while training. After the progressive training, the LoRA learns the 3D
information of the generated object and eventually turns to an object-level 3D
prior. In the final stage, we extract the mesh from the trained NeRF and use
the trained LoRA to optimize the structure and appearance of the mesh. The
experiments demonstrate the effectiveness of the proposed method. Boosting3D
learns object-specific 3D prior which is beyond the ability of pre-trained
diffusion priors and achieves state-of-the-art performance in the single
image-to-3d generation task.
</p></li>
</ul>

<h3>Title: The Challenges of Image Generation Models in Generating Multi-Component Images. (arXiv:2311.13620v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13620">http://arxiv.org/abs/2311.13620</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13620]] The Challenges of Image Generation Models in Generating Multi-Component Images(http://arxiv.org/abs/2311.13620)</code></li>
<li>Summary: <p>Recent advances in text-to-image generators have led to substantial
capabilities in image generation. However, the complexity of prompts acts as a
bottleneck in the quality of images generated. A particular under-explored
facet is the ability of generative models to create high-quality images
comprising multiple components given as a prior. In this paper, we propose and
validate a metric called Components Inclusion Score (CIS) to evaluate the
extent to which a model can correctly generate multiple components. Our results
reveal that the evaluated models struggle to incorporate all the visual
elements from prompts with multiple components (8.53% drop in CIS per component
for all evaluated models). We also identify a significant decline in the
quality of the images and context awareness within an image as the number of
components increased (15.91% decrease in inception Score and 9.62% increase in
Frechet Inception Distance). To remedy this issue, we fine-tuned Stable
Diffusion V2 on a custom-created test dataset with multiple components,
outperforming its vanilla counterpart. To conclude, these findings reveal a
critical limitation in existing text-to-image generators, shedding light on the
challenge of generating multiple components within a single image using a
complex prompt.
</p></li>
</ul>

<h3>Title: TDiffDe: A Truncated Diffusion Model for Remote Sensing Hyperspectral Image Denoising. (arXiv:2311.13622v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13622">http://arxiv.org/abs/2311.13622</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13622]] TDiffDe: A Truncated Diffusion Model for Remote Sensing Hyperspectral Image Denoising(http://arxiv.org/abs/2311.13622)</code></li>
<li>Summary: <p>Hyperspectral images play a crucial role in precision agriculture,
environmental monitoring or ecological analysis. However, due to sensor
equipment and the imaging environment, the observed hyperspectral images are
often inevitably corrupted by various noise. In this study, we proposed a
truncated diffusion model, called TDiffDe, to recover the useful information in
hyperspectral images gradually. Rather than starting from a pure noise, the
input data contains image information in hyperspectral image denoising. Thus,
we cut the trained diffusion model from small steps to avoid the destroy of
valid information.
</p></li>
</ul>

<h3>Title: Diffusion models meet image counter-forensics. (arXiv:2311.13629v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13629">http://arxiv.org/abs/2311.13629</a></li>
<li>Code URL: https://github.com/mtailanian/diff-cf</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13629]] Diffusion models meet image counter-forensics(http://arxiv.org/abs/2311.13629)</code></li>
<li>Summary: <p>From its acquisition in the camera sensors to its storage, different
operations are performed to generate the final image. This pipeline imprints
specific traces into the image to form a natural watermark. Tampering with an
image disturbs these traces; these disruptions are clues that are used by most
methods to detect and locate forgeries. In this article, we assess the
capabilities of diffusion models to erase the traces left by forgers and,
therefore, deceive forensics methods. Such an approach has been recently
introduced for adversarial purification, achieving significant performance. We
show that diffusion purification methods are well suited for counter-forensics
tasks. Such approaches outperform already existing counter-forensics techniques
both in deceiving forensics methods and in preserving the natural look of the
purified images. The source code is publicly available at
https://github.com/mtailanian/diff-cf.
</p></li>
</ul>

<h3>Title: Sample-Efficient Training for Diffusion. (arXiv:2311.13745v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13745">http://arxiv.org/abs/2311.13745</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13745]] Sample-Efficient Training for Diffusion(http://arxiv.org/abs/2311.13745)</code></li>
<li>Summary: <p>Score-based diffusion models have become the most popular approach to deep
generative modeling of images, largely due to their empirical performance and
reliability. Recently, a number of theoretical works \citep{chen2022,
Chen2022ImprovedAO, Chenetal23flowode, benton2023linear} have shown that
diffusion models can efficiently sample, assuming $L^2$-accurate score
estimates. The score-matching objective naturally approximates the true score
in $L^2$, but the sample complexity of existing bounds depends
\emph{polynomially} on the data radius and desired Wasserstein accuracy. By
contrast, the time complexity of sampling is only logarithmic in these
parameters. We show that estimating the score in $L^2$ \emph{requires} this
polynomial dependence, but that a number of samples that scales
polylogarithmically in the Wasserstein accuracy actually do suffice for
sampling. We show that with a polylogarithmic number of samples, the ERM of the
score-matching objective is $L^2$ accurate on all but a probability $\delta$
fraction of the true distribution, and that this weaker guarantee is sufficient
for efficient sampling.
</p></li>
</ul>

<h3>Title: Posterior Distillation Sampling. (arXiv:2311.13831v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13831">http://arxiv.org/abs/2311.13831</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13831]] Posterior Distillation Sampling(http://arxiv.org/abs/2311.13831)</code></li>
<li>Summary: <p>We introduce Posterior Distillation Sampling (PDS), a novel optimization
method for parametric image editing based on diffusion models. Existing
optimization-based methods, which leverage the powerful 2D prior of diffusion
models to handle various parametric images, have mainly focused on generation.
Unlike generation, editing requires a balance between conforming to the target
attribute and preserving the identity of the source content. Recent 2D image
editing methods have achieved this balance by leveraging the stochastic latent
encoded in the generative process of diffusion models. To extend the editing
capabilities of diffusion models shown in pixel space to parameter space, we
reformulate the 2D image editing method into an optimization form named PDS.
PDS matches the stochastic latents of the source and the target, enabling the
sampling of targets in diverse parameter spaces that align with a desired
attribute while maintaining the source's identity. We demonstrate that this
optimization resembles running a generative process with the target attribute,
but aligning this process with the trajectory of the source's generative
process. Extensive editing results in Neural Radiance Fields and Scalable
Vector Graphics representations demonstrate that PDS is capable of sampling
targets to fulfill the aforementioned balance across various parameter spaces.
</p></li>
</ul>

<h3>Title: Lego: Learning to Disentangle and Invert Concepts Beyond Object Appearance in Text-to-Image Diffusion Models. (arXiv:2311.13833v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13833">http://arxiv.org/abs/2311.13833</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13833]] Lego: Learning to Disentangle and Invert Concepts Beyond Object Appearance in Text-to-Image Diffusion Models(http://arxiv.org/abs/2311.13833)</code></li>
<li>Summary: <p>Diffusion models have revolutionized generative content creation and
text-to-image (T2I) diffusion models in particular have increased the creative
freedom of users by allowing scene synthesis using natural language. T2I models
excel at synthesizing concepts such as nouns, appearances, and styles. To
enable customized content creation based on a few example images of a concept,
methods such as Textual Inversion and DreamBooth invert the desired concept and
enable synthesizing it in new scenes. However, inverting more general concepts
that go beyond object appearance and style (adjectives and verbs) through
natural language, remains a challenge. Two key characteristics of these
concepts contribute to the limitations of current inversion methods. 1)
Adjectives and verbs are entangled with nouns (subject) and can hinder
appearance-based inversion methods, where the subject appearance leaks into the
concept embedding and 2) describing such concepts often extends beyond single
word embeddings (being frozen in ice, walking on a tightrope, etc.) that
current methods do not handle.
</p>
<p>In this study, we introduce Lego, a textual inversion method designed to
invert subject entangled concepts from a few example images. Lego disentangles
concepts from their associated subjects using a simple yet effective Subject
Separation step and employs a Context Loss that guides the inversion of
single/multi-embedding concepts. In a thorough user study, Lego-generated
concepts were preferred over 70% of the time when compared to the baseline.
Additionally, visual question answering using a large language model suggested
Lego-generated concepts are better aligned with the text description of the
concept.
</p></li>
</ul>

<h3>Title: Continual Learning of Diffusion Models with Generative Distillation. (arXiv:2311.14028v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14028">http://arxiv.org/abs/2311.14028</a></li>
<li>Code URL: https://github.com/atenrev/difussion_continual_learning</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14028]] Continual Learning of Diffusion Models with Generative Distillation(http://arxiv.org/abs/2311.14028)</code></li>
<li>Summary: <p>Diffusion models are powerful generative models that achieve state-of-the-art
performance in tasks such as image synthesis. However, training them demands
substantial amounts of data and computational resources. Continual learning
would allow for incrementally learning new tasks and accumulating knowledge,
thus reusing already trained models would be possible. One potentially suitable
approach is generative replay, where a copy of a generative model trained on
previous tasks produces synthetic data that are interleaved with data from the
current task. However, standard generative replay applied to diffusion models
results in a catastrophic loss in denoising capabilities. In this paper, we
propose generative distillation, an approach that distils the entire reverse
process of a diffusion model. We demonstrate that our approach significantly
improves the continual learning performance of generative replay with only a
moderate increase in the computational costs.
</p></li>
</ul>

<h3>Title: ACT: Adversarial Consistency Models. (arXiv:2311.14097v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14097">http://arxiv.org/abs/2311.14097</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14097]] ACT: Adversarial Consistency Models(http://arxiv.org/abs/2311.14097)</code></li>
<li>Summary: <p>Though diffusion models excel in image generation, their step-by-step
denoising leads to slow generation speeds. Consistency training addresses this
issue with single-step sampling but often produces lower-quality generations
and requires high training costs. In this paper, we show that optimizing
consistency training loss minimizes the Wasserstein distance between target and
generated distributions. As timestep increases, the upper bound accumulates
previous consistency training losses. Therefore, larger batch sizes are needed
to reduce both current and accumulated losses. We propose Adversarial
Consistency Training (ACT), which directly minimizes the Jensen-Shannon (JS)
divergence between distributions at each timestep using a discriminator.
Theoretically, ACT enhances generation quality, and convergence. By
incorporating a discriminator into the consistency training framework, our
method achieves improved FID scores on CIFAR10 and ImageNet 64$\times$64,
retains zero-shot image inpainting capabilities, and uses less than $1/6$ of
the original batch size and fewer than $1/2$ of the model parameters and
training steps compared to the baseline method, this leads to a substantial
reduction in resource consumption.
</p></li>
</ul>

<h3>Title: Touring sampling with pushforward maps. (arXiv:2311.13845v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13845">http://arxiv.org/abs/2311.13845</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13845]] Touring sampling with pushforward maps(http://arxiv.org/abs/2311.13845)</code></li>
<li>Summary: <p>The number of sampling methods could be daunting for a practitioner looking
to cast powerful machine learning methods to their specific problem. This paper
takes a theoretical stance to review and organize many sampling approaches in
the ``generative modeling'' setting, where one wants to generate new data that
are similar to some training examples. By revealing links between existing
methods, it might prove useful to overcome some of the current challenges in
sampling with diffusion models, such as long inference time due to diffusion
simulation, or the lack of diversity in generated samples.
</p></li>
</ul>

<h3>Title: RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation. (arXiv:2311.14077v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14077">http://arxiv.org/abs/2311.14077</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14077]] RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation(http://arxiv.org/abs/2311.14077)</code></li>
<li>Summary: <p>Retrosynthesis poses a fundamental challenge in biopharmaceuticals, aiming to
aid chemists in finding appropriate reactant molecules and synthetic pathways
given determined product molecules. With the reactant and product represented
as 2D graphs, retrosynthesis constitutes a conditional graph-to-graph
generative task. Inspired by the recent advancements in discrete diffusion
models for graph generation, we introduce Retrosynthesis Diffusion (RetroDiff),
a novel diffusion-based method designed to address this problem. However,
integrating a diffusion-based graph-to-graph framework while retaining
essential chemical reaction template information presents a notable challenge.
Our key innovation is to develop a multi-stage diffusion process. In this
method, we decompose the retrosynthesis procedure to first sample external
groups from the dummy distribution given products and then generate the
external bonds to connect the products and generated groups. Interestingly,
such a generation process is exactly the reverse of the widely adapted
semi-template retrosynthesis procedure, i.e. from reaction center
identification to synthon completion, which significantly reduces the error
accumulation. Experimental results on the benchmark have demonstrated the
superiority of our method over all other semi-template methods.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: HEViTPose: High-Efficiency Vision Transformer for Human Pose Estimation. (arXiv:2311.13615v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13615">http://arxiv.org/abs/2311.13615</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13615]] HEViTPose: High-Efficiency Vision Transformer for Human Pose Estimation(http://arxiv.org/abs/2311.13615)</code></li>
<li>Summary: <p>Human pose estimation in complicated situations has always been a challenging
task. Many Transformer-based pose networks have been proposed recently,
achieving encouraging progress in improving performance. However, the
remarkable performance of pose networks is always accompanied by heavy
computation costs and large network scale. In order to deal with this problem,
this paper proposes a High-Efficiency Vision Transformer for Human Pose
Estimation (HEViTPose). In HEViTPose, a Cascaded Group Spatial Reduction
Multi-Head Attention Module (CGSR-MHA) is proposed, which reduces the
computational cost through feature grouping and spatial degradation mechanisms,
while preserving feature diversity through multiple low-dimensional attention
heads. Moreover, a concept of Patch Embedded Overlap Width (PEOW) is defined to
help understand the relationship between the amount of overlap and local
continuity. By optimising PEOW, our model gains improvements in performance,
parameters and GFLOPs.
</p>
<p>Comprehensive experiments on two benchmark datasets (MPII and COCO)
demonstrate that the small and large HEViTPose models are on par with
state-of-the-art models while being more lightweight. Specifically, HEViTPose-B
achieves 90.7 PCK@0.5 on the MPII test set and 72.6 AP on the COCO test-dev2017
set. Compared with HRNet-W32 and Swin-S, our HEViTPose-B significantly reducing
Params ($\downarrow$62.1%,$\downarrow$80.4%,) and GFLOPs
($\downarrow$43.4%,$\downarrow$63.8%,). Code and models are available at
\url{here}.
</p></li>
</ul>

<h3>Title: BenthIQ: a Transformer-Based Benthic Classification Model for Coral Restoration. (arXiv:2311.13661v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13661">http://arxiv.org/abs/2311.13661</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13661]] BenthIQ: a Transformer-Based Benthic Classification Model for Coral Restoration(http://arxiv.org/abs/2311.13661)</code></li>
<li>Summary: <p>Coral reefs are vital for marine biodiversity, coastal protection, and
supporting human livelihoods globally. However, they are increasingly
threatened by mass bleaching events, pollution, and unsustainable practices
with the advent of climate change. Monitoring the health of these ecosystems is
crucial for effective restoration and management. Current methods for creating
benthic composition maps often compromise between spatial coverage and
resolution. In this paper, we introduce BenthIQ, a multi-label semantic
segmentation network designed for high-precision classification of underwater
substrates, including live coral, algae, rock, and sand. Although commonly
deployed CNNs are limited in learning long-range semantic information,
transformer-based models have recently achieved state-of-the-art performance in
vision tasks such as object detection and image classification. We integrate
the hierarchical Swin Transformer as the backbone of a U-shaped encoder-decoder
architecture for local-global semantic feature learning. Using a real-world
case study in French Polynesia, we demonstrate that our approach outperforms
traditional CNN and attention-based models on pixel-wise classification of
shallow reef imagery.
</p></li>
</ul>

<h3>Title: Progressive Learning with Visual Prompt Tuning for Variable-Rate Image Compression. (arXiv:2311.13846v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13846">http://arxiv.org/abs/2311.13846</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13846]] Progressive Learning with Visual Prompt Tuning for Variable-Rate Image Compression(http://arxiv.org/abs/2311.13846)</code></li>
<li>Summary: <p>In this paper, we propose a progressive learning paradigm for
transformer-based variable-rate image compression. Our approach covers a wide
range of compression rates with the assistance of the Layer-adaptive Prompt
Module (LPM). Inspired by visual prompt tuning, we use LPM to extract prompts
for input images and hidden features at the encoder side and decoder side,
respectively, which are fed as additional information into the Swin Transformer
layer of a pre-trained transformer-based image compression model to affect the
allocation of attention region and the bits, which in turn changes the target
compression ratio of the model. To ensure the network is more lightweight, we
involves the integration of prompt networks with less convolutional layers.
Exhaustive experiments show that compared to methods based on multiple models,
which are optimized separately for different target rates, the proposed method
arrives at the same performance with 80% savings in parameter storage and 90%
savings in datasets. Meanwhile, our model outperforms all current variable
bitrate image methods in terms of rate-distortion performance and approaches
the state-of-the-art fixed bitrate image compression methods trained from
scratch.
</p></li>
</ul>

<h3>Title: Learning Saliency From Fixations. (arXiv:2311.14073v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14073">http://arxiv.org/abs/2311.14073</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14073]] Learning Saliency From Fixations(http://arxiv.org/abs/2311.14073)</code></li>
<li>Summary: <p>We present a novel approach for saliency prediction in images, leveraging
parallel decoding in transformers to learn saliency solely from fixation maps.
Models typically rely on continuous saliency maps, to overcome the difficulty
of optimizing for the discrete fixation map. We attempt to replicate the
experimental setup that generates saliency datasets. Our approach treats
saliency prediction as a direct set prediction problem, via a global loss that
enforces unique fixations prediction through bipartite matching and a
transformer encoder-decoder architecture. By utilizing a fixed set of learned
fixation queries, the cross-attention reasons over the image features to
directly output the fixation points, distinguishing it from other modern
saliency predictors. Our approach, named Saliency TRansformer (SalTR), achieves
metric scores on par with state-of-the-art approaches on the Salicon and MIT300
benchmarks.
</p></li>
</ul>

<h3>Title: Efficient Transformer Knowledge Distillation: A Performance Review. (arXiv:2311.13657v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13657">http://arxiv.org/abs/2311.13657</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13657]] Efficient Transformer Knowledge Distillation: A Performance Review(http://arxiv.org/abs/2311.13657)</code></li>
<li>Summary: <p>As pretrained transformer language models continue to achieve
state-of-the-art performance, the Natural Language Processing community has
pushed for advances in model compression and efficient attention mechanisms to
address high computational requirements and limited input sequence length.
Despite these separate efforts, no investigation has been done into the
intersection of these two fields. In this work, we provide an evaluation of
model compression via knowledge distillation on efficient attention
transformers. We provide cost-performance trade-offs for the compression of
state-of-the-art efficient attention architectures and the gains made in
performance in comparison to their full attention counterparts. Furthermore, we
introduce a new long-context Named Entity Recognition dataset, GONERD, to train
and test the performance of NER models on long sequences. We find that
distilled efficient attention transformers can preserve a significant amount of
original model performance, preserving up to 98.6% across short-context tasks
(GLUE, SQUAD, CoNLL-2003), up to 94.6% across long-context
Question-and-Answering tasks (HotpotQA, TriviaQA), and up to 98.8% on
long-context Named Entity Recognition (GONERD), while decreasing inference
times by up to 57.8%. We find that, for most models on most tasks, performing
knowledge distillation is an effective method to yield high-performing
efficient attention models with low costs.
</p></li>
</ul>

<h3>Title: Transformer-based Named Entity Recognition in Construction Supply Chain Risk Management in Australia. (arXiv:2311.13755v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13755">http://arxiv.org/abs/2311.13755</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13755]] Transformer-based Named Entity Recognition in Construction Supply Chain Risk Management in Australia(http://arxiv.org/abs/2311.13755)</code></li>
<li>Summary: <p>The construction industry in Australia is characterized by its intricate
supply chains and vulnerability to myriad risks. As such, effective supply
chain risk management (SCRM) becomes imperative. This paper employs different
transformer models, and train for Named Entity Recognition (NER) in the context
of Australian construction SCRM. Utilizing NER, transformer models identify and
classify specific risk-associated entities in news articles, offering a
detailed insight into supply chain vulnerabilities. By analysing news articles
through different transformer models, we can extract relevant entities and
insights related to specific risk taxonomies local (milieu) to the Australian
construction landscape. This research emphasises the potential of NLP-driven
solutions, like transformer models, in revolutionising SCRM for construction in
geo-media specific contexts.
</p></li>
</ul>

<h3>Title: Beat-Aligned Spectrogram-to-Sequence Generation of Rhythm-Game Charts. (arXiv:2311.13687v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13687">http://arxiv.org/abs/2311.13687</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13687]] Beat-Aligned Spectrogram-to-Sequence Generation of Rhythm-Game Charts(http://arxiv.org/abs/2311.13687)</code></li>
<li>Summary: <p>In the heart of "rhythm games" - games where players must perform actions in
sync with a piece of music - are "charts", the directives to be given to
players. We newly formulate chart generation as a sequence generation task and
train a Transformer using a large dataset. We also introduce tempo-informed
preprocessing and training procedures, some of which are suggested to be
integral for a successful training. Our model is found to outperform the
baselines on a large dataset, and is also found to benefit from pretraining and
finetuning.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Density Distribution-based Learning Framework for Addressing Online Continual Learning Challenges. (arXiv:2311.13623v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13623">http://arxiv.org/abs/2311.13623</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13623]] Density Distribution-based Learning Framework for Addressing Online Continual Learning Challenges(http://arxiv.org/abs/2311.13623)</code></li>
<li>Summary: <p>In this paper, we address the challenges of online Continual Learning (CL) by
introducing a density distribution-based learning framework. CL, especially the
Class Incremental Learning, enables adaptation to new test distributions while
continuously learning from a single-pass training data stream, which is more in
line with the practical application requirements of real-world scenarios.
However, existing CL methods often suffer from catastrophic forgetting and
higher computing costs due to complex algorithm designs, limiting their
practical use. Our proposed framework overcomes these limitations by achieving
superior average accuracy and time-space efficiency, bridging the performance
gap between CL and classical machine learning. Specifically, we adopt an
independent Generative Kernel Density Estimation (GKDE) model for each CL task.
During the testing stage, the GKDEs utilize a self-reported max probability
density value to determine which one is responsible for predicting incoming
test instances. A GKDE-based learning objective can ensure that samples with
the same label are grouped together, while dissimilar instances are pushed
farther apart. Extensive experiments conducted on multiple CL datasets validate
the effectiveness of our proposed framework. Our method outperforms popular CL
approaches by a significant margin, while maintaining competitive time-space
efficiency, making our framework suitable for real-world applications. Code
will be available at https://github.com/xxxx/xxxx.
</p></li>
</ul>

<h3>Title: GAN-Avatar: Controllable Personalized GAN-based Human Head Avatar. (arXiv:2311.13655v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13655">http://arxiv.org/abs/2311.13655</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13655]] GAN-Avatar: Controllable Personalized GAN-based Human Head Avatar(http://arxiv.org/abs/2311.13655)</code></li>
<li>Summary: <p>Digital humans and, especially, 3D facial avatars have raised a lot of
attention in the past years, as they are the backbone of several applications
like immersive telepresence in AR or VR. Despite the progress, facial avatars
reconstructed from commodity hardware are incomplete and miss out on parts of
the side and back of the head, severely limiting the usability of the avatar.
This limitation in prior work stems from their requirement of face tracking,
which fails for profile and back views. To address this issue, we propose to
learn person-specific animatable avatars from images without assuming to have
access to precise facial expression tracking. At the core of our method, we
leverage a 3D-aware generative model that is trained to reproduce the
distribution of facial expressions from the training data. To train this
appearance model, we only assume to have a collection of 2D images with the
corresponding camera parameters. For controlling the model, we learn a mapping
from 3DMM facial expression parameters to the latent space of the generative
model. This mapping can be learned by sampling the latent space of the
appearance model and reconstructing the facial parameters from a normalized
frontal view, where facial expression estimation performs well. With this
scheme, we decouple 3D appearance reconstruction and animation control to
achieve high fidelity in image synthesis. In a series of experiments, we
compare our proposed technique to state-of-the-art monocular methods and show
superior quality while not requiring expression tracking of the training data.
</p></li>
</ul>

<h3>Title: Perceptual Image Compression with Cooperative Cross-Modal Side Information. (arXiv:2311.13847v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13847">http://arxiv.org/abs/2311.13847</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13847]] Perceptual Image Compression with Cooperative Cross-Modal Side Information(http://arxiv.org/abs/2311.13847)</code></li>
<li>Summary: <p>The explosion of data has resulted in more and more associated text being
transmitted along with images. Inspired by from distributed source coding, many
works utilize image side information to enhance image compression. However,
existing methods generally do not consider using text as side information to
enhance perceptual compression of images, even though the benefits of
multimodal synergy have been widely demonstrated in research. This begs the
following question: How can we effectively transfer text-level semantic
dependencies to help image compression, which is only available to the decoder?
In this work, we propose a novel deep image compression method with text-guided
side information to achieve a better rate-perception-distortion tradeoff.
Specifically, we employ the CLIP text encoder and an effective Semantic-Spatial
Aware block to fuse the text and image features. This is done by predicting a
semantic mask to guide the learned text-adaptive affine transformation at the
pixel level. Furthermore, we design a text-conditional generative adversarial
networks to improve the perceptual quality of reconstructed images. Extensive
experiments involving four datasets and ten image quality assessment metrics
demonstrate that the proposed approach achieves superior results in terms of
rate-perception trade-off and semantic distortion.
</p></li>
</ul>

<h3>Title: Video Anomaly Detection using GAN. (arXiv:2311.14095v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14095">http://arxiv.org/abs/2311.14095</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14095]] Video Anomaly Detection using GAN(http://arxiv.org/abs/2311.14095)</code></li>
<li>Summary: <p>Accounting for the increased concern for public safety, automatic abnormal
event detection and recognition in a surveillance scene is crucial. It is a
current open study subject because of its intricacy and utility. The
identification of aberrant events automatically, it's a difficult undertaking
because everyone's idea of abnormality is different. A typical occurrence in
one circumstance could be seen as aberrant in another. Automatic anomaly
identification becomes particularly challenging in the surveillance footage
with a large crowd due to congestion and high occlusion. With the use of
machine learning techniques, this thesis study aims to offer the solution for
this use case so that human resources won't be required to keep an eye out for
any unusual activity in the surveillance system records. We have developed a
novel generative adversarial network (GAN) based anomaly detection model. This
model is trained such that it learns together about constructing a high
dimensional picture space and determining the latent space from the video's
context. The generator uses a residual Autoencoder architecture made up of a
multi-stage channel attention-based decoder and a two-stream, deep
convolutional encoder that can realise both spatial and temporal data. We have
also offered a technique for refining the GAN model that reduces training time
while also generalising the model by utilising transfer learning between
datasets. Using a variety of assessment measures, we compare our model to the
current state-of-the-art techniques on four benchmark datasets. The empirical
findings indicate that, in comparison to existing techniques, our network
performs favourably on all datasets.
</p></li>
</ul>

<h3>Title: Auditing and Mitigating Cultural Bias in LLMs. (arXiv:2311.14096v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14096">http://arxiv.org/abs/2311.14096</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14096]] Auditing and Mitigating Cultural Bias in LLMs(http://arxiv.org/abs/2311.14096)</code></li>
<li>Summary: <p>Culture fundamentally shapes people's reasoning, behavior, and communication.
Generative artificial intelligence (AI) technologies may cause a shift towards
a dominant culture. As people increasingly use AI to expedite and even automate
various professional and personal tasks, cultural values embedded in AI models
may bias authentic expression. We audit large language models for cultural
bias, comparing their responses to nationally representative survey data, and
evaluate country-specific prompting as a mitigation strategy. We find that
GPT-4, 3.5 and 3 exhibit cultural values resembling English-speaking and
Protestant European countries. Our mitigation strategy reduces cultural bias in
recent models but not for all countries/territories. To avoid cultural bias in
generative AI, especially in high-stakes contexts, we suggest using culture
matching and ongoing cultural audits.
</p></li>
</ul>

<h3>Title: A density estimation perspective on learning from pairwise human preferences. (arXiv:2311.14115v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14115">http://arxiv.org/abs/2311.14115</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14115]] A density estimation perspective on learning from pairwise human preferences(http://arxiv.org/abs/2311.14115)</code></li>
<li>Summary: <p>Learning from human feedback (LHF) -- and in particular learning from
pairwise preferences -- has recently become a crucial ingredient in training
large language models (LLMs), and has been the subject of much research. Most
recent works frame it as a reinforcement learning problem, where a reward
function is learned from pairwise preference data and the LLM is treated as a
policy which is adapted to maximize the rewards, often under additional
regularization constraints. We propose an alternative interpretation which
centers on the generative process for pairwise preferences and treats LHF as a
density estimation problem. We provide theoretical and empirical results
showing that for a family of generative processes defined via preference
behavior distribution equations, training a reward function on pairwise
preferences effectively models an annotator's implicit preference distribution.
Finally, we discuss and present findings on "annotator misspecification" --
failure cases where wrong modeling assumptions are made about annotator
behavior, resulting in poorly-adapted models -- suggesting that approaches that
learn from pairwise human preferences could have trouble learning from a
population of annotators with diverse viewpoints.
</p></li>
</ul>

<h3>Title: Multivariate Scenario Generation of Day-Ahead Electricity Prices using Normalizing Flows. (arXiv:2311.14033v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14033">http://arxiv.org/abs/2311.14033</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14033]] Multivariate Scenario Generation of Day-Ahead Electricity Prices using Normalizing Flows(http://arxiv.org/abs/2311.14033)</code></li>
<li>Summary: <p>Trading on electricity markets requires accurate information about the
realization of electricity prices and the uncertainty attached to the
predictions. We present a probabilistic forecasting approach for day-ahead
electricity prices using the fully data-driven deep generative model called
normalizing flows. Our modeling approach generates full-day scenarios of
day-ahead electricity prices based on conditional features such as residual
load forecasts. Furthermore, we propose extended feature sets of prior
realizations and a periodic retraining scheme that allows the normalizing flow
to adapt to the changing conditions of modern electricity markets. In
particular, we investigate the impact of the energy crisis ensuing from the
Russian invasion of Ukraine. Our results highlight that the normalizing flow
generates high-quality scenarios that reproduce the true price distribution and
yield highly accurate forecasts. Additionally, our analysis highlights how our
improvements towards adaptations in changing regimes allow the normalizing flow
to adapt to changing market conditions and enables continued sampling of
high-quality day-ahead price scenarios.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data. (arXiv:2311.13614v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13614">http://arxiv.org/abs/2311.13614</a></li>
<li>Code URL: https://github.com/yuqifan1117/hallucidoctor</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13614]] HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data(http://arxiv.org/abs/2311.13614)</code></li>
<li>Summary: <p>Multi-modal Large Language Models (MLLMs) tuned on machine-generated
instruction-following data have demonstrated remarkable performance in various
multi-modal understanding and generation tasks. However, the hallucinations
inherent in machine-generated data, which could lead to hallucinatory outputs
in MLLMs, remain under-explored. This work aims to investigate various
hallucinations (i.e., object, relation, attribute hallucinations) and mitigate
those hallucinatory toxicities in large-scale machine-generated visual
instruction datasets. Drawing on the human ability to identify factual errors,
we present a novel hallucination detection and elimination framework,
HalluciDoctor, based on the cross-checking paradigm. We use our framework to
identify and eliminate hallucinations in the training data automatically.
Interestingly, HalluciDoctor also indicates that spurious correlations arising
from long-tail object co-occurrences contribute to hallucinations. Based on
that, we execute counterfactual visual instruction expansion to balance data
distribution, thereby enhancing MLLMs' resistance to hallucinations.
Comprehensive experiments on hallucination evaluation benchmarks show that our
method successfully mitigates 44.6% hallucinations relatively and maintains
competitive performance compared to LLaVA.The source code will be released at
\url{https://github.com/Yuqifan1117/HalluciDoctor}.
</p></li>
</ul>

<h3>Title: Vamos: Versatile Action Models for Video Understanding. (arXiv:2311.13627v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13627">http://arxiv.org/abs/2311.13627</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13627]] Vamos: Versatile Action Models for Video Understanding(http://arxiv.org/abs/2311.13627)</code></li>
<li>Summary: <p>What makes good video representations for video understanding, such as
anticipating future activities, or answering video-conditioned questions? While
earlier approaches focus on end-to-end learning directly from video pixels, we
propose to revisit text-based representations, such as discrete action labels,
or free-form video captions, which are interpretable and can be directly
consumed by large language models (LLMs). Intuitively, different video
understanding tasks may require representations that are complementary and at
different granularities. To this end, we propose versatile action models
(Vamos), a learning framework powered by a large language model as the
"reasoner", and can flexibly leverage visual embeddings, action labels, and
free-form descriptions extracted from videos as its input. We evaluate Vamos on
four complementary video understanding benchmarks, Ego4D, Next-QA, IntentQA,
and EgoSchema, on its capability to model temporal dynamics, encode visual
history, and perform reasoning. Surprisingly, we observe that text-based
representations consistently achieve competitive performance on all benchmarks,
and that visual embeddings provide marginal or no performance improvement,
demonstrating the effectiveness of text-based video representation in the LLM
era. We perform extensive ablation study and qualitative analysis to support
our observations, and achieve state-of-the-art performance on three benchmarks.
</p></li>
</ul>

<h3>Title: MAIRA-1: A specialised large multimodal model for radiology report generation. (arXiv:2311.13668v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13668">http://arxiv.org/abs/2311.13668</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13668]] MAIRA-1: A specialised large multimodal model for radiology report generation(http://arxiv.org/abs/2311.13668)</code></li>
<li>Summary: <p>We present a radiology-specific multimodal model for the task for generating
radiological reports from chest X-rays (CXRs). Our work builds on the idea that
large language model(s) can be equipped with multimodal capabilities through
alignment with pre-trained vision encoders. On natural images, this has been
shown to allow multimodal models to gain image understanding and description
capabilities. Our proposed model (MAIRA-1) leverages a CXR-specific image
encoder in conjunction with a fine-tuned large language model based on
Vicuna-7B, and text-based data augmentation, to produce reports with
state-of-the-art quality. In particular, MAIRA-1 significantly improves on the
radiologist-aligned RadCliQ metric and across all lexical metrics considered.
Manual review of model outputs demonstrates promising fluency and accuracy of
generated reports while uncovering failure modes not captured by existing
evaluation practices. More information and resources can be found on the
project website: https://aka.ms/maira.
</p></li>
</ul>

<h3>Title: Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models. (arXiv:2311.13628v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13628">http://arxiv.org/abs/2311.13628</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13628]] Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models(http://arxiv.org/abs/2311.13628)</code></li>
<li>Summary: <p>The recent explosion in the capabilities of large language models has led to
a wave of interest in how best to prompt a model to perform a given task. While
it may be tempting to simply choose a prompt based on average performance on a
validation set, this can lead to a deployment where unexpectedly poor responses
are generated, especially for the worst-off users. To mitigate this prospect,
we propose Prompt Risk Control, a lightweight framework for selecting a prompt
based on rigorous upper bounds on families of informative risk measures. We
offer methods for producing bounds on a diverse set of metrics, including
quantities that measure worst-case responses and disparities in generation
quality across the population of users. In addition, we extend the underlying
statistical bounding techniques to accommodate the possibility of distribution
shifts in deployment. Experiments on applications such as open-ended chat,
medical question summarization, and code generation highlight how such a
framework can foster responsible deployment by reducing the risk of the worst
outcomes.
</p></li>
</ul>

<h3>Title: Surpassing GPT-4 Medical Coding with a Two-Stage Approach. (arXiv:2311.13735v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13735">http://arxiv.org/abs/2311.13735</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13735]] Surpassing GPT-4 Medical Coding with a Two-Stage Approach(http://arxiv.org/abs/2311.13735)</code></li>
<li>Summary: <p>Recent advances in large language models (LLMs) show potential for clinical
applications, such as clinical decision support and trial recommendations.
However, the GPT-4 LLM predicts an excessive number of ICD codes for medical
coding tasks, leading to high recall but low precision. To tackle this
challenge, we introduce LLM-codex, a two-stage approach to predict ICD codes
that first generates evidence proposals using an LLM and then employs an
LSTM-based verification stage. The LSTM learns from both the LLM's high recall
and human expert's high precision, using a custom loss function. Our model is
the only approach that simultaneously achieves state-of-the-art results in
medical coding accuracy, accuracy on rare codes, and sentence-level evidence
identification to support coding decisions without training on human-annotated
evidence according to experiments on the MIMIC dataset.
</p></li>
</ul>

<h3>Title: DaG LLM ver 1.0: Pioneering Instruction-Tuned Language Modeling for Korean NLP. (arXiv:2311.13784v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13784">http://arxiv.org/abs/2311.13784</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13784]] DaG LLM ver 1(http://arxiv.org/abs/2311.13784)</code></li>
<li>Summary: <p>This paper presents the DaG LLM (David and Goliath Large Language Model), a
language model specialized for Korean and fine-tuned through Instruction Tuning
across 41 tasks within 13 distinct categories.
</p></li>
</ul>

<h3>Title: Challenges of Large Language Models for Mental Health Counseling. (arXiv:2311.13857v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13857">http://arxiv.org/abs/2311.13857</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13857]] Challenges of Large Language Models for Mental Health Counseling(http://arxiv.org/abs/2311.13857)</code></li>
<li>Summary: <p>The global mental health crisis is looming with a rapid increase in mental
disorders, limited resources, and the social stigma of seeking treatment. As
the field of artificial intelligence (AI) has witnessed significant
advancements in recent years, large language models (LLMs) capable of
understanding and generating human-like text may be used in supporting or
providing psychological counseling. However, the application of LLMs in the
mental health domain raises concerns regarding the accuracy, effectiveness, and
reliability of the information provided. This paper investigates the major
challenges associated with the development of LLMs for psychological
counseling, including model hallucination, interpretability, bias, privacy, and
clinical effectiveness. We explore potential solutions to these challenges that
are practical and applicable to the current paradigm of AI. From our experience
in developing and deploying LLMs for mental health, AI holds a great promise
for improving mental health care, if we can carefully navigate and overcome
pitfalls of LLMs.
</p></li>
</ul>

<h3>Title: Minimizing Factual Inconsistency and Hallucination in Large Language Models. (arXiv:2311.13878v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13878">http://arxiv.org/abs/2311.13878</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13878]] Minimizing Factual Inconsistency and Hallucination in Large Language Models(http://arxiv.org/abs/2311.13878)</code></li>
<li>Summary: <p>Large Language Models (LLMs) are widely used in critical fields such as
healthcare, education, and finance due to their remarkable proficiency in
various language-related tasks. However, LLMs are prone to generating factually
incorrect responses or "hallucinations," which can lead to a loss of
credibility and trust among users. To address this issue, we propose a
multi-stage framework that generates the rationale first, verifies and refines
incorrect ones, and uses them as supporting references to generate the answer.
The generated rationale enhances the transparency of the answer and our
framework provides insights into how the model arrived at this answer, by using
this rationale and the references to the context. In this paper, we demonstrate
its effectiveness in improving the quality of responses to drug-related
inquiries in the life sciences industry. Our framework improves traditional
Retrieval Augmented Generation (RAG) by enabling OpenAI GPT-3.5-turbo to be
14-25% more faithful and 16-22% more accurate on two datasets. Furthermore,
fine-tuning samples based on our framework improves the accuracy of smaller
open-access LLMs by 33-42% and competes with RAG on commercial models.
</p></li>
</ul>

<h3>Title: Dialogue Quality and Emotion Annotations for Customer Support Conversations. (arXiv:2311.13910v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13910">http://arxiv.org/abs/2311.13910</a></li>
<li>Code URL: https://github.com/johndmendonca/maia-dqe</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13910]] Dialogue Quality and Emotion Annotations for Customer Support Conversations(http://arxiv.org/abs/2311.13910)</code></li>
<li>Summary: <p>Task-oriented conversational datasets often lack topic variability and
linguistic diversity. However, with the advent of Large Language Models (LLMs)
pretrained on extensive, multilingual and diverse text data, these limitations
seem overcome. Nevertheless, their generalisability to different languages and
domains in dialogue applications remains uncertain without benchmarking
datasets. This paper presents a holistic annotation approach for emotion and
conversational quality in the context of bilingual customer support
conversations. By performing annotations that take into consideration the
complete instances that compose a conversation, one can form a broader
perspective of the dialogue as a whole. Furthermore, it provides a unique and
valuable resource for the development of text classification models. To this
end, we present benchmarks for Emotion Recognition and Dialogue Quality
Estimation and show that further research is needed to leverage these models in
a production setting.
</p></li>
</ul>

<h3>Title: MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V. (arXiv:2311.13951v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13951">http://arxiv.org/abs/2311.13951</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13951]] MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V(http://arxiv.org/abs/2311.13951)</code></li>
<li>Summary: <p>In the pursuit of Artificial General Intelligence (AGI), the integration of
vision in language models has marked a significant milestone. The advent of
vision-language models (MLLMs) like GPT-4V have expanded AI applications,
aligning with the multi-modal capabilities of the human brain. However,
evaluating the efficacy of MLLMs poses a substantial challenge due to the
subjective nature of tasks that lack definitive answers. Existing automatic
evaluation methodologies on multi-modal large language models rely on objective
queries that have standard answers, inadequately addressing the nuances of
creative and associative multi-modal tasks. To address this, we introduce
MLLM-Bench, an innovative benchmark inspired by Vicuna, spanning a diverse
array of scenarios, including Perception, Understanding, Applying, Analyzing,
Evaluating, and Creation along with the ethical consideration. MLLM-Bench is
designed to reflect user experience more accurately and provide a more holistic
assessment of model performance. Comparative evaluations indicate a significant
performance gap between existing open-source models and GPT-4V. We posit that
MLLM-Bench will catalyze progress in the open-source community towards
developing user-centric vision-language models that meet a broad spectrum of
real-world applications. See online leaderboard in
\url{https://mllm-bench.llmzoo.com}.
</p></li>
</ul>

<h3>Title: Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions. (arXiv:2311.13982v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13982">http://arxiv.org/abs/2311.13982</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13982]] Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions(http://arxiv.org/abs/2311.13982)</code></li>
<li>Summary: <p>Large language models (LLMs) are capable of answering knowledge-intensive
complex questions with chain-of-thought (CoT) reasoning. However, they tend to
generate factually incorrect reasoning steps when the required knowledge is not
available or up-to-date in models' parameters. Recent works turn to retrieving
external knowledge to augment CoT reasoning. Despite being promising, these
chain-based methods suffer from: 1) Negative retrieval. Unnecessary or
incorrect retrieval may mislead the reasoning; 2) Limited sight. Lacking the
ability to look backward or forward, a local error in one step will propagate
along the chain.
</p>
<p>In this paper, we propose a novel approach: Probabilistic Tree-of-thought
Reasoning (ProbTree). First, LLMs translate a complex question into a query
tree, in which each non-root node denotes a sub-question of its parent node.
Then, probabilistic reasoning is conducted over the tree, by solving questions
from leaf to root considering the confidence of both question decomposing and
answering. During reasoning, for leaf nodes, LLMs choose a more confident
answer from Closed-book QA that employs parametric knowledge and Open-book QA
that employs retrieved external knowledge, thus eliminating the negative
retrieval problem. For non-leaf nodes, with the hierarchical structure, LLMs
have broader sights and are able to globally reason with the information from
child nodes, thus recovering from local errors. The experiments on three
Complex QA datasets under the open-domain setting show that our approach
outperforms SOTA methods significantly, demonstrating the effect of
probabilistic tree-of-thought reasoning.
</p></li>
</ul>

<h3>Title: Towards Auditing Large Language Models: Improving Text-based Stereotype Detection. (arXiv:2311.14126v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14126">http://arxiv.org/abs/2311.14126</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14126]] Towards Auditing Large Language Models: Improving Text-based Stereotype Detection(http://arxiv.org/abs/2311.14126)</code></li>
<li>Summary: <p>Large Language Models (LLM) have made significant advances in the recent past
becoming more mainstream in Artificial Intelligence (AI) enabled human-facing
applications. However, LLMs often generate stereotypical output inherited from
historical data, amplifying societal biases and raising ethical concerns. This
work introduces i) the Multi-Grain Stereotype Dataset, which includes 52,751
instances of gender, race, profession and religion stereotypic text and ii) a
novel stereotype classifier for English text. We design several experiments to
rigorously test the proposed model trained on the novel dataset. Our
experiments show that training the model in a multi-class setting can
outperform the one-vs-all binary counterpart. Consistent feature importance
signals from different eXplainable AI tools demonstrate that the new model
exploits relevant text features. We utilise the newly created model to assess
the stereotypic behaviour of the popular GPT family of models and observe the
reduction of bias over time. In summary, our work establishes a robust and
practical framework for auditing and evaluating the stereotypic bias in LLM.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation Networks for Remote Sensing Imagery. (arXiv:2311.13716v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13716">http://arxiv.org/abs/2311.13716</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13716]] DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation Networks for Remote Sensing Imagery(http://arxiv.org/abs/2311.13716)</code></li>
<li>Summary: <p>Semi-supervised learning is designed to help reduce the cost of the manual
labelling process by exploiting the use of useful features from a large
quantity of unlabelled data during training. Since pixel-level manual labelling
in large-scale remote sensing imagery is expensive, semi-supervised learning
becomes an appropriate solution to this. However, most of the existing
semi-supervised learning methods still lack efficient perturbation methods to
promote diversity of features and the precision of pseudo labels during
training. In order to fill this gap, we propose DiverseNet architectures which
explore multi-head and multi-model semi-supervised learning algorithms by
simultaneously promoting precision and diversity during training. The two
proposed methods of DiverseNet, namely the DiverseHead and DiverseModel,
achieve the highest semantic segmentation performance in four widely utilised
remote sensing imagery data sets compared to state-of-the-art semi-supervised
learning methods. Meanwhile, the proposed DiverseHead architecture is
relatively lightweight in terms of parameter space compared to the
state-of-the-art methods whilst reaching high-performance results for all the
tested data sets.
</p></li>
</ul>

<h3>Title: Towards Transferable Multi-modal Perception Representation Learning for Autonomy: NeRF-Supervised Masked AutoEncoder. (arXiv:2311.13750v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13750">http://arxiv.org/abs/2311.13750</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13750]] Towards Transferable Multi-modal Perception Representation Learning for Autonomy: NeRF-Supervised Masked AutoEncoder(http://arxiv.org/abs/2311.13750)</code></li>
<li>Summary: <p>This work proposes a unified self-supervised pre-training framework for
transferable multi-modal perception representation learning via masked
multi-modal reconstruction in Neural Radiance Field (NeRF), namely
NeRF-Supervised Masked AutoEncoder (NS-MAE). Specifically, conditioned on
certain view directions and locations, multi-modal embeddings extracted from
corrupted multi-modal input signals, i.e., Lidar point clouds and images, are
rendered into projected multi-modal feature maps via neural rendering. Then,
original multi-modal signals serve as reconstruction targets for the rendered
multi-modal feature maps to enable self-supervised representation learning.
Extensive experiments show that the representation learned via NS-MAE shows
promising transferability for diverse multi-modal and single-modal (camera-only
and Lidar-only) perception models on diverse 3D perception downstream tasks (3D
object detection and BEV map segmentation) with diverse amounts of fine-tuning
labeled data. Moreover, we empirically find that NS-MAE enjoys the synergy of
both the mechanism of masked autoencoder and neural radiance field. Our code
shall be released upon acceptance.
</p></li>
</ul>

<h3>Title: Language-guided Few-shot Semantic Segmentation. (arXiv:2311.13865v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13865">http://arxiv.org/abs/2311.13865</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13865]] Language-guided Few-shot Semantic Segmentation(http://arxiv.org/abs/2311.13865)</code></li>
<li>Summary: <p>Few-shot learning is a promising way for reducing the label cost in new
categories adaptation with the guidance of a small, well labeled support set.
But for few-shot semantic segmentation, the pixel-level annotations of support
images are still expensive. In this paper, we propose an innovative solution to
tackle the challenge of few-shot semantic segmentation using only language
information, i.e.image-level text labels. Our approach involves a
vision-language-driven mask distillation scheme, which contains a
vision-language pretraining (VLP) model and a mask refiner, to generate high
quality pseudo-semantic masks from text prompts. We additionally introduce a
distributed prototype supervision method and complementary correlation matching
module to guide the model in digging precise semantic relations among support
and query images. The experiments on two benchmark datasets demonstrate that
our method establishes a new baseline for language-guided few-shot semantic
segmentation and achieves competitive results to recent vision-guided methods.
</p></li>
</ul>

<h3>Title: Low Latency Instance Segmentation by Continuous Clustering for Rotating LiDAR Sensors. (arXiv:2311.13976v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13976">http://arxiv.org/abs/2311.13976</a></li>
<li>Code URL: https://github.com/unibwtas/continuous_clustering</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13976]] Low Latency Instance Segmentation by Continuous Clustering for Rotating LiDAR Sensors(http://arxiv.org/abs/2311.13976)</code></li>
<li>Summary: <p>Low-latency instance segmentation of LiDAR point clouds is crucial in
real-world applications because it serves as an initial and frequently-used
building block in a robot's perception pipeline, where every task adds further
delay. Particularly in dynamic environments, this total delay can result in
significant positional offsets of dynamic objects, as seen in highway
scenarios. To address this issue, we employ continuous clustering of obstacle
points in order to obtain an instance-segmented point cloud. Unlike most
existing approaches, which use a full revolution of the LiDAR sensor, we
process the data stream in a continuous and seamless fashion. More
specifically, each column of a range image is processed as soon it is
available. Obstacle points are clustered to existing instances in real-time and
it is checked at a high-frequency which instances are completed and are ready
to be published. An additional advantage is that no problematic discontinuities
between the points of the start and the end of a scan are observed. In this
work we describe the two-layered data structure and the corresponding algorithm
for continuous clustering, which is able to cluster the incoming data in real
time. We explain the importance of a large perceptive field of view.
Furthermore, we describe and evaluate important architectural design choices,
which could be relevant to design an architecture for deep learning based
low-latency instance segmentation. We are publishing the source code at
https://github.com/UniBwTAS/continuous_clustering.
</p></li>
</ul>

<h3>Title: GRJointNET: Synergistic Completion and Part Segmentation on 3D Incomplete Point Clouds. (arXiv:2311.13997v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13997">http://arxiv.org/abs/2311.13997</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13997]] GRJointNET: Synergistic Completion and Part Segmentation on 3D Incomplete Point Clouds(http://arxiv.org/abs/2311.13997)</code></li>
<li>Summary: <p>Segmentation of three-dimensional (3D) point clouds is an important task for
autonomous systems. However, success of segmentation algorithms depends greatly
on the quality of the underlying point clouds (resolution, completeness etc.).
In particular, incomplete point clouds might reduce a downstream model's
performance. GRNet is proposed as a novel and recent deep learning solution to
complete point clouds, but it is not capable of part segmentation. On the other
hand, our proposed solution, GRJointNet, is an architecture that can perform
joint completion and segmentation on point clouds as a successor of GRNet.
Features extracted for the two tasks are also utilized by each other to
increase the overall performance. We evaluated our proposed network on the
ShapeNet-Part dataset and compared its performance to GRNet. Our results
demonstrate GRJointNet can outperform GRNet on point completion. It should also
be noted that GRNet is not capable of segmentation while GRJointNet is. This
study1, therefore, holds a promise to enhance practicality and utility of point
clouds in 3D vision for autonomous systems.
</p></li>
</ul>

<h3>Title: Class Balanced Dynamic Acquisition for Domain Adaptive Semantic Segmentation using Active Learning. (arXiv:2311.14146v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.14146">http://arxiv.org/abs/2311.14146</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.14146]] Class Balanced Dynamic Acquisition for Domain Adaptive Semantic Segmentation using Active Learning(http://arxiv.org/abs/2311.14146)</code></li>
<li>Summary: <p>Domain adaptive active learning is leading the charge in label-efficient
training of neural networks. For semantic segmentation, state-of-the-art models
jointly use two criteria of uncertainty and diversity to select training
labels, combined with a pixel-wise acquisition strategy. However, we show that
such methods currently suffer from a class imbalance issue which degrades their
performance for larger active learning budgets. We then introduce Class
Balanced Dynamic Acquisition (CBDA), a novel active learning method that
mitigates this issue, especially in high-budget regimes. The more balanced
labels increase minority class performance, which in turn allows the model to
outperform the previous baseline by 0.6, 1.7, and 2.4 mIoU for budgets of 5%,
10%, and 20%, respectively. Additionally, the focus on minority classes leads
to improvements of the minimum class performance of 0.5, 2.9, and 4.6 IoU
respectively. The top-performing model even exceeds the fully supervised
baseline, showing that a more balanced label than the entire ground truth can
be beneficial.
</p></li>
</ul>

<h3>Title: Dynamic Analysis Method for Hidden Dangers in Substation Based on Knowledge Graph. (arXiv:2311.13708v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.13708">http://arxiv.org/abs/2311.13708</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.13708]] Dynamic Analysis Method for Hidden Dangers in Substation Based on Knowledge Graph(http://arxiv.org/abs/2311.13708)</code></li>
<li>Summary: <p>To address the challenge of identifying and understanding hidden dangers in
substations from unstructured text data, a novel dynamic analysis method is
proposed. This approach begins by analyzing and extracting data from the
unstructured text related to hidden dangers. It then leverages a flexible,
distributed data search engine built on Elastic-Search to handle this
information. Following this, the hidden Markov model is employed to train the
data within the engine. The Viterbi algorithm is integrated to decipher the
hidden state sequences, facilitating the segmentation and labeling of entities
related to hidden dangers. The final step involves using the Neo4j graph
database to dynamically create a knowledge map that visualizes hidden dangers
in the substation. This method's effectiveness is demonstrated through an
example analysis using data from a specific substation's hidden dangers.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
