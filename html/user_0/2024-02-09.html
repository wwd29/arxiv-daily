<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-02-09</h1>
<h3>Title: Quantifying Similarity: Text-Mining Approaches to Evaluate ChatGPT and  Google Bard Content in Relation to BioMedical Literature</h3>
<ul>
<li><strong>Authors: </strong>Jakub Klimczak, Ahmed Abdeen Hamed</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05116">https://arxiv.org/abs/2402.05116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05116">https://arxiv.org/pdf/2402.05116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05116]] Quantifying Similarity: Text-Mining Approaches to Evaluate ChatGPT and  Google Bard Content in Relation to BioMedical Literature(https://arxiv.org/abs/2402.05116)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Background: The emergence of generative AI tools, empowered by Large Language Models (LLMs), has shown powerful capabilities in generating content. To date, the assessment of the usefulness of such content, generated by what is known as prompt engineering, has become an interesting research question. Objectives Using the mean of prompt engineering, we assess the similarity and closeness of such contents to real literature produced by scientists. Methods In this exploratory analysis, (1) we prompt-engineer ChatGPT and Google Bard to generate clinical content to be compared with literature counterparts, (2) we assess the similarities of the contents generated by comparing them with counterparts from biomedical literature. Our approach is to use text-mining approaches to compare documents and associated bigrams and to use network analysis to assess the terms' centrality. Results The experiments demonstrated that ChatGPT outperformed Google Bard in cosine document similarity (38% to 34%), Jaccard document similarity (23% to 19%), TF-IDF bigram similarity (47% to 41%), and term network centrality (degree and closeness). We also found new links that emerged in ChatGPT bigram networks that did not exist in literature bigram networks. Conclusions: The obtained similarity results show that ChatGPT outperformed Google Bard in document similarity, bigrams, and degree and closeness centrality. We also observed that ChatGPT offers linkage to terms that are connected in the literature. Such connections could inspire asking interesting questions and generate new hypotheses.</li>
</ul>

<h3>Title: A Closer Look at the Limitations of Instruction Tuning</h3>
<ul>
<li><strong>Authors: </strong>Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Ramaneswaran S, Deepali Aneja, Zeyu Jin, Ramani Duraiswami, Dinesh Manocha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05119">https://arxiv.org/abs/2402.05119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05119">https://arxiv.org/pdf/2402.05119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05119]] A Closer Look at the Limitations of Instruction Tuning(https://arxiv.org/abs/2402.05119)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction Tuning (IT), the process of training large language models (LLMs) using instruction-response pairs, has emerged as the predominant method for transforming base pre-trained LLMs into open-domain conversational agents. While IT has achieved notable success and widespread adoption, its limitations and shortcomings remain underexplored. In this paper, through rigorous experiments and an in-depth analysis of the changes LLMs undergo through IT, we reveal various limitations of IT. In particular, we show that (1) IT fails to enhance knowledge or skills in LLMs. LoRA fine-tuning is limited to learning response initiation and style tokens, and full-parameter fine-tuning leads to knowledge degradation. (2) Copying response patterns from IT datasets derived from knowledgeable sources leads to a decline in response quality. (3) Full-parameter fine-tuning increases hallucination by inaccurately borrowing tokens from conceptually similar instances in the IT dataset for generating responses. (4) Popular methods to improve IT do not lead to performance improvements over a simple LoRA fine-tuned model. Our findings reveal that responses generated solely from pre-trained knowledge consistently outperform responses by models that learn any form of new knowledge from IT on open-source datasets. We hope the insights and challenges revealed inspire future work.</li>
</ul>

<h3>Title: More Agents Is All You Need</h3>
<ul>
<li><strong>Authors: </strong>Junyou Li, Qin Zhang, Yangbin Yu, Qiang Fu, Deheng Ye</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05120">https://arxiv.org/abs/2402.05120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05120">https://arxiv.org/pdf/2402.05120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05120]] More Agents Is All You Need(https://arxiv.org/abs/2402.05120)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of agents instantiated. Also, this method is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence. Our code is publicly available at: \url{https://anonymous.4open.science/r/more_agent_is_all_you_need}.</li>
</ul>

<h3>Title: A Survey on Data Selection for LLM Instruction Tuning</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Wang, Bolin Zhang, Qianlong Du, Jiajun Zhang, Dianhui Chu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05123">https://arxiv.org/abs/2402.05123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05123">https://arxiv.org/pdf/2402.05123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05123]] A Survey on Data Selection for LLM Instruction Tuning(https://arxiv.org/abs/2402.05123)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning is a vital step of training large language models (LLM), so how to enhance the effect of instruction tuning has received increased attention. Existing works indicate that the quality of the dataset is more crucial than the quantity during instruction tuning of LLM. Therefore, recently a lot of studies focus on exploring the methods of selecting high-quality subset from instruction datasets, aiming to reduce training costs and enhance the instruction-following capabilities of LLMs. This paper presents a comprehensive survey on data selection for LLM instruction tuning. Firstly, we introduce the wildly used instruction datasets. Then, we propose a new taxonomy of the data selection methods and provide a detailed introduction of recent advances,and the evaluation strategies and results of data selection methods are also elaborated in detail. Finally, we emphasize the open challenges and present new frontiers of this task.</li>
</ul>

<h3>Title: Zero-Shot Clinical Trial Patient Matching with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Michael Wornow, Alejandro Lozano, Dev Dash, Jenelle Jindal, Kenneth W. Mahaffey, Nigam H. Shah</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05125">https://arxiv.org/abs/2402.05125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05125">https://arxiv.org/pdf/2402.05125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05125]] Zero-Shot Clinical Trial Patient Matching with LLMs(https://arxiv.org/abs/2402.05125)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Matching patients to clinical trials is a key unsolved challenge in bringing new drugs to market. Today, identifying patients who meet a trial's eligibility criteria is highly manual, taking up to 1 hour per patient. Automated screening is challenging, however, as it requires understanding unstructured clinical text. Large language models (LLMs) offer a promising solution. In this work, we explore their application to trial matching. First, we design an LLM-based system which, given a patient's medical history as unstructured clinical text, evaluates whether that patient meets a set of inclusion criteria (also specified as free text). Our zero-shot system achieves state-of-the-art scores on the n2c2 2018 cohort selection benchmark. Second, we improve the data and cost efficiency of our method by identifying a prompting strategy which matches patients an order of magnitude faster and more cheaply than the status quo, and develop a two-stage retrieval pipeline that reduces the number of tokens processed by up to a third while retaining high performance. Third, we evaluate the interpretability of our system by having clinicians evaluate the natural language justifications generated by the LLM for each eligibility decision, and show that it can output coherent explanations for 97% of its correct decisions and 75% of its incorrect ones. Our results establish the feasibility of using LLMs to accelerate clinical trial operations.</li>
</ul>

<h3>Title: Illuminate: A novel approach for depression detection with explainable  analysis and proactive therapy using prompt engineering</h3>
<ul>
<li><strong>Authors: </strong>Aryan Agrawal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05127">https://arxiv.org/abs/2402.05127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05127">https://arxiv.org/pdf/2402.05127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05127]] Illuminate: A novel approach for depression detection with explainable  analysis and proactive therapy using prompt engineering(https://arxiv.org/abs/2402.05127)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel paradigm for depression detection and treatment using advanced Large Language Models (LLMs): Generative Pre-trained Transformer 4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized prompts to diagnose, explain, and suggest therapeutic interventions for depression. A unique few-shot prompting method enhances the models' ability to analyze and explain depressive symptoms based on the DSM-5 criteria. In the interaction phase, the models engage in empathetic dialogue management, drawing from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide, fostering supportive interactions with individuals experiencing major depressive disorders. Additionally, the research introduces the Illuminate Database, enriched with various CBT modules, aiding in personalized therapy recommendations. The study evaluates LLM performance using metrics such as F1 scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) across different test sets, demonstrating their effectiveness. This comprehensive approach blends cutting-edge AI with established psychological methods, offering new possibilities in mental health care and showcasing the potential of LLMs in revolutionizing depression diagnosis and treatment strategies.</li>
</ul>

<h3>Title: Enhancing Textbook Question Answering Task with Large Language Models  and Retrieval Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Hessa Abdulrahman Alawwad, Areej Alhothali, Usman Naseem, Ali Alkhathlan, Amani Jamal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05128">https://arxiv.org/abs/2402.05128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05128">https://arxiv.org/pdf/2402.05128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05128]] Enhancing Textbook Question Answering Task with Large Language Models  and Retrieval Augmented Generation(https://arxiv.org/abs/2402.05128)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Textbook question answering (TQA) is a challenging task in artificial intelligence due to the complex nature of context and multimodal data. Although previous research has significantly improved the task, there are still some limitations including the models' weak reasoning and inability to capture contextual information in the lengthy context. The introduction of large language models (LLMs) has revolutionized the field of AI, however, directly applying LLMs often leads to inaccurate answers. This paper proposes a methodology that handle the out-of-domain scenario in TQA where concepts are spread across different lessons by incorporating the retrieval augmented generation (RAG) technique and utilize transfer learning to handle the long context and enhance reasoning abilities. Through supervised fine-tuning of the LLM model Llama-2 and the incorporation of RAG, our architecture outperforms the baseline, achieving a 4.12% accuracy improvement on validation set and 9.84% on test set for non-diagram multiple-choice questions.</li>
</ul>

<h3>Title: Best Practices for Text Annotation with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Petter Törnberg</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05129">https://arxiv.org/abs/2402.05129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05129">https://arxiv.org/pdf/2402.05129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05129]] Best Practices for Text Annotation with Large Language Models(https://arxiv.org/abs/2402.05129)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have ushered in a new era of text annotation, as their ease-of-use, high accuracy, and relatively low costs have meant that their use has exploded in recent months. However, the rapid growth of the field has meant that LLM-based annotation has become something of an academic Wild West: the lack of established practices and standards has led to concerns about the quality and validity of research. Researchers have warned that the ostensible simplicity of LLMs can be misleading, as they are prone to bias, misunderstandings, and unreliable results. Recognizing the transformative potential of LLMs, this paper proposes a comprehensive set of standards and best practices for their reliable, reproducible, and ethical use. These guidelines span critical areas such as model selection, prompt engineering, structured prompting, prompt stability analysis, rigorous model validation, and the consideration of ethical and legal implications. The paper emphasizes the need for a structured, directed, and formalized approach to using LLMs, aiming to ensure the integrity and robustness of text annotation practices, and advocates for a nuanced and critical engagement with LLMs in social scientific research.</li>
</ul>

<h3>Title: LB-KBQA: Large-language-model and BERT based Knowledge-Based Question  and Answering System</h3>
<ul>
<li><strong>Authors: </strong>Yan Zhao, Zhongyun Li, Jiaxing Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05130">https://arxiv.org/abs/2402.05130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05130">https://arxiv.org/pdf/2402.05130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05130]] LB-KBQA: Large-language-model and BERT based Knowledge-Based Question  and Answering System(https://arxiv.org/abs/2402.05130)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative Artificial Intelligence (AI), because of its emergent abilities, has empowered various fields, one typical of which is large language models (LLMs). One of the typical application fields of Generative AI is large language models (LLMs), and the natural language understanding capability of LLM is dramatically improved when compared with conventional AI-based methods. The natural language understanding capability has always been a barrier to the intent recognition performance of the Knowledge-Based-Question-and-Answer (KBQA) system, which arises from linguistic diversity and the newly appeared intent. Conventional AI-based methods for intent recognition can be divided into semantic parsing-based and model-based approaches. However, both of the methods suffer from limited resources in intent recognition. To address this issue, we propose a novel KBQA system based on a Large Language Model(LLM) and BERT (LB-KBQA). With the help of generative AI, our proposed method could detect newly appeared intent and acquire new knowledge. In experiments on financial domain question answering, our model has demonstrated superior effectiveness.</li>
</ul>

<h3>Title: TexShape: Information Theoretic Sentence Embedding for Language Models</h3>
<ul>
<li><strong>Authors: </strong>H. Kaan Kale, Homa Esfahanizadeh, Noel Elias, Oguzhan Baser, Muriel Medard, Sriram Vishwanath</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05132">https://arxiv.org/abs/2402.05132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05132">https://arxiv.org/pdf/2402.05132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05132]] TexShape: Information Theoretic Sentence Embedding for Language Models(https://arxiv.org/abs/2402.05132)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>With the exponential growth in data volume and the emergence of data-intensive applications, particularly in the field of machine learning, concerns related to resource utilization, privacy, and fairness have become paramount. This paper focuses on the textual domain of data and addresses challenges regarding encoding sentences to their optimized representations through the lens of information-theory. In particular, we use empirical estimates of mutual information, using the Donsker-Varadhan definition of Kullback-Leibler divergence. Our approach leverages this estimation to train an information-theoretic sentence embedding, called TexShape, for (task-based) data compression or for filtering out sensitive information, enhancing privacy and fairness. In this study, we employ a benchmark language model for initial text representation, complemented by neural networks for information-theoretic compression and mutual information estimations. Our experiments demonstrate significant advancements in preserving maximal targeted information and minimal sensitive information over adverse compression ratios, in terms of predictive accuracy of downstream models that are trained using the compressed data.</li>
</ul>

<h3>Title: Personalized Language Modeling from Personalized Human Feedback</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Li, Zachary C. Lipton, Liu Leqi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05133">https://arxiv.org/abs/2402.05133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05133">https://arxiv.org/pdf/2402.05133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05133]] Personalized Language Modeling from Personalized Human Feedback(https://arxiv.org/abs/2402.05133)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) is the current dominating framework to fine-tune large language models to better align with human preferences. However, the underlying premise of algorithms developed under this framework can be problematic when user preferences encoded in human feedback are diverse. In this work, we aim to address this problem by developing methods for building personalized language models. We first formally introduce the task of learning from personalized human feedback and explain why vanilla RLHF can be problematic in this context. We then propose a general Personalized-RLHF (P-RLHF) framework, which requires one to jointly learn a user model and a language (or reward) model. The user model takes in user information and outputs user representations. Its structure encodes our assumptions about user preferences underlying the feedback data. We develop new learning objectives for personalized reward modeling and personalized Direct Preference Optimization. To demonstrate the efficacy of our method, we test it on real-world text summarization data with annotated preferences and annotator information. We fine-tune GPT-J 6B to obtain personalized language (and reward) models, which outperform non-personalized models in terms of aligning with individual preferences.</li>
</ul>

<h3>Title: LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to  256K</h3>
<ul>
<li><strong>Authors: </strong>Tao Yuan, Xuefei Ning, Dong Zhou, Zhijie Yang, Shiyao Li, Minghui Zhuang, Zheyue Tan, Zhuyu Yao, Dahua Lin, Boxun Li, Guohao Dai, Shengen Yan, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05136">https://arxiv.org/abs/2402.05136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05136">https://arxiv.org/pdf/2402.05136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05136]] LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to  256K(https://arxiv.org/abs/2402.05136)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>State-of-the-art large language models (LLMs) are now claiming remarkable supported context lengths of 256k or even more. In contrast, the average context lengths of mainstream benchmarks are insufficient (5k-21k), and they suffer from potential knowledge leakage and inaccurate metrics, resulting in biased evaluation. This paper introduces LV-Eval, a challenging long-context benchmark with five length levels (16k, 32k, 64k, 128k, and 256k) reaching up to 256k words. LV-Eval features two main tasks, single-hop QA and multi-hop QA, comprising 11 bilingual datasets. The design of LV-Eval has incorporated three key techniques, namely confusing facts insertion, keyword and phrase replacement, and keyword-recall-based metric design. The advantages of LV-Eval include controllable evaluation across different context lengths, challenging test instances with confusing facts, mitigated knowledge leakage, and more objective evaluations. We evaluate 10 LLMs on LV-Eval and conduct ablation studies on the techniques used in LV-Eval construction. The results reveal that: (i) Commercial LLMs generally outperform open-source LLMs when evaluated within length levels shorter than their claimed context length. However, their overall performance is surpassed by open-source LLMs with longer context lengths. (ii) Extremely long-context LLMs, such as Yi-6B-200k, exhibit a relatively gentle degradation of performance, but their absolute performances may not necessarily be higher than those of LLMs with shorter context lengths. (iii) LLMs' performances can significantly degrade in the presence of confusing information, especially in the pressure test of "needle in a haystack". (iv) Issues related to knowledge leakage and inaccurate metrics introduce bias in evaluation, and these concerns are alleviated in LV-Eval. All datasets and evaluation codes are released at: https://github.com/infinigence/LVEval.</li>
</ul>

<h3>Title: Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains</h3>
<ul>
<li><strong>Authors: </strong>Junhong Shen, Neil Tenenholtz, James Brian Hall, David Alvarez-Melis, Nicolo Fusi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05140">https://arxiv.org/abs/2402.05140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05140">https://arxiv.org/pdf/2402.05140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05140]] Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains(https://arxiv.org/abs/2402.05140)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable proficiency in understanding and generating natural language. However, their capabilities wane in highly specialized domains underrepresented in the pretraining corpus, such as physical and biomedical sciences. This work explores how to repurpose general LLMs into effective task solvers for specialized domains. We introduce a novel, model-agnostic framework for learning custom input tags, which are parameterized as continuous vectors appended to the LLM's embedding layer, to condition the LLM. We design two types of input tags: domain tags are used to delimit specialized representations (e.g., chemical formulas) and provide domain-relevant context; function tags are used to represent specific functions (e.g., predicting molecular properties) and compress function-solving instructions. We develop a three-stage protocol to learn these tags using auxiliary data and domain knowledge. By explicitly disentangling task domains from task functions, our method enables zero-shot generalization to unseen problems through diverse combinations of the input tags. It also boosts LLM's performance in various specialized domains, such as predicting protein or chemical properties and modeling drug-target interactions, outperforming expert models tailored to these tasks.</li>
</ul>

<h3>Title: Online Learning Approach for Survival Analysis</h3>
<ul>
<li><strong>Authors: </strong>Camila Fernandez (LPSM), Pierre Gaillard (Thoth), Joseph de Vilmarest, Olivier Wintenberger (LPSM (UMR\_8001))</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.data-an, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05145">https://arxiv.org/abs/2402.05145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05145">https://arxiv.org/pdf/2402.05145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05145]] Online Learning Approach for Survival Analysis(https://arxiv.org/abs/2402.05145)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce an online mathematical framework for survival analysis, allowing real time adaptation to dynamic environments and censored data. This framework enables the estimation of event time distributions through an optimal second order online convex optimization algorithm-Online Newton Step (ONS). This approach, previously unexplored, presents substantial advantages, including explicit algorithms with non-asymptotic convergence guarantees. Moreover, we analyze the selection of ONS hyperparameters, which depends on the exp-concavity property and has a significant influence on the regret bound. We propose a stochastic approach that guarantees logarithmic stochastic regret for ONS. Additionally, we introduce an adaptive aggregation method that ensures robustness in hyperparameter selection while maintaining fast regret bounds. The findings of this paper can extend beyond the survival analysis field, and are relevant for any case characterized by poor exp-concavity and unstable ONS. Finally, these assertions are illustrated by simulation experiments.</li>
</ul>

<h3>Title: Compressing Deep Reinforcement Learning Networks with a Dynamic  Structured Pruning Method for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Wensheng Su, Zhenni Li, Minrui Xu, Jiawen Kang, Dusit Niyato, Shengli Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05146">https://arxiv.org/abs/2402.05146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05146">https://arxiv.org/pdf/2402.05146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05146]] Compressing Deep Reinforcement Learning Networks with a Dynamic  Structured Pruning Method for Autonomous Driving(https://arxiv.org/abs/2402.05146)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep reinforcement learning (DRL) has shown remarkable success in complex autonomous driving scenarios. However, DRL models inevitably bring high memory consumption and computation, which hinders their wide deployment in resource-limited autonomous driving devices. Structured Pruning has been recognized as a useful method to compress and accelerate DRL models, but it is still challenging to estimate the contribution of a parameter (i.e., neuron) to DRL models. In this paper, we introduce a novel dynamic structured pruning approach that gradually removes a DRL model's unimportant neurons during the training stage. Our method consists of two steps, i.e. training DRL models with a group sparse regularizer and removing unimportant neurons with a dynamic pruning threshold. To efficiently train the DRL model with a small number of important neurons, we employ a neuron-importance group sparse regularizer. In contrast to conventional regularizers, this regularizer imposes a penalty on redundant groups of neurons that do not significantly influence the output of the DRL model. Furthermore, we design a novel structured pruning strategy to dynamically determine the pruning threshold and gradually remove unimportant neurons with a binary mask. Therefore, our method can remove not only redundant groups of neurons of the DRL model but also achieve high and robust performance. Experimental results show that the proposed method is competitive with existing DRL pruning methods on discrete control environments (i.e., CartPole-v1 and LunarLander-v2) and MuJoCo continuous environments (i.e., Hopper-v3 and Walker2D-v3). Specifically, our method effectively compresses $93\%$ neurons and $96\%$ weights of the DRL model in four challenging DRL environments with slight accuracy degradation.</li>
</ul>

<h3>Title: ApiQ: Finetuning of 2-Bit Quantized Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Baohao Liao, Christof Monz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05147">https://arxiv.org/abs/2402.05147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05147">https://arxiv.org/pdf/2402.05147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05147]] ApiQ: Finetuning of 2-Bit Quantized Large Language Model(https://arxiv.org/abs/2402.05147)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Memory-efficient finetuning of large language models (LLMs) has recently attracted huge attention with the increasing size of LLMs, primarily due to the constraints posed by GPU memory limitations and the comparable results of these methods with full finetuning. Despite the advancements, current strategies for memory-efficient finetuning, such as QLoRA, exhibit inconsistent performance across diverse bit-width quantizations and multifaceted tasks. This inconsistency largely stems from the detrimental impact of the quantization process on preserved knowledge, leading to catastrophic forgetting and undermining the utilization of pretrained models for finetuning purposes. In this work, we introduce a novel quantization framework named ApiQ, designed to restore the lost information from quantization by concurrently initializing LoRA components and quantizing the weights of LLMs. This approach ensures the maintenance of the original LLM's activation precision while mitigating the error propagation from shallower into deeper layers. Through comprehensive evaluations conducted on a spectrum of language tasks with various models, ApiQ demonstrably minimizes activation error during quantization. Consequently, it consistently achieves superior finetuning outcomes across various bit-widths of quantization.</li>
</ul>

<h3>Title: Designing deep neural networks for driver intention recognition</h3>
<ul>
<li><strong>Authors: </strong>Koen Vellenga, H. Joe Steinhauer, Alexander Karlsson, Göran Falkman, Asli Rhodin, Ashok Koppisetty</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05150">https://arxiv.org/abs/2402.05150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05150">https://arxiv.org/pdf/2402.05150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05150]] Designing deep neural networks for driver intention recognition(https://arxiv.org/abs/2402.05150)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Driver intention recognition studies increasingly rely on deep neural networks. Deep neural networks have achieved top performance for many different tasks, but it is not a common practice to explicitly analyse the complexity and performance of the network's architecture. Therefore, this paper applies neural architecture search to investigate the effects of the deep neural network architecture on a real-world safety critical application with limited computational capabilities. We explore a pre-defined search space for three deep neural network layer types that are capable to handle sequential data (a long-short term memory, temporal convolution, and a time-series transformer layer), and the influence of different data fusion strategies on the driver intention recognition performance. A set of eight search strategies are evaluated for two driver intention recognition datasets. For the two datasets, we observed that there is no search strategy clearly sampling better deep neural network architectures. However, performing an architecture search does improve the model performance compared to the original manually designed networks. Furthermore, we observe no relation between increased model complexity and higher driver intention recognition performance. The result indicate that multiple architectures yield similar performance, regardless of the deep neural network layer type or fusion strategy.</li>
</ul>

<h3>Title: Enhancement of Bengali OCR by Specialized Models and Advanced Techniques  for Diverse Document Types</h3>
<ul>
<li><strong>Authors: </strong>AKM Shahariar Azad Rabby, Hasmot Ali, Md. Majedul Islam, Sheikh Abujar, Fuad Rahman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05158">https://arxiv.org/abs/2402.05158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05158">https://arxiv.org/pdf/2402.05158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05158]] Enhancement of Bengali OCR by Specialized Models and Advanced Techniques  for Diverse Document Types(https://arxiv.org/abs/2402.05158)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>This research paper presents a unique Bengali OCR system with some capabilities. The system excels in reconstructing document layouts while preserving structure, alignment, and images. It incorporates advanced image and signature detection for accurate extraction. Specialized models for word segmentation cater to diverse document types, including computer-composed, letterpress, typewriter, and handwritten documents. The system handles static and dynamic handwritten inputs, recognizing various writing styles. Furthermore, it has the ability to recognize compound characters in Bengali. Extensive data collection efforts provide a diverse corpus, while advanced technical components optimize character and word recognition. Additional contributions include image, logo, signature and table recognition, perspective correction, layout reconstruction, and a queuing module for efficient and scalable processing. The system demonstrates outstanding performance in efficient and accurate text extraction and analysis.</li>
</ul>

<h3>Title: Threats and Limitations of Terrestrial Broadcast Attacks</h3>
<ul>
<li><strong>Authors: </strong>Benjamin Michele, Ivan Pena, Pablo Angueira</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05159">https://arxiv.org/abs/2402.05159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05159">https://arxiv.org/pdf/2402.05159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05159]] Threats and Limitations of Terrestrial Broadcast Attacks(https://arxiv.org/abs/2402.05159)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>The DVB standard does not mandate the use of authentication and integrity protection for transport streams. This allows malicious third parties to replace legitimate broadcasts by overpowering terrestrial transmissions. The rogue signal can then deliver a malicious broadcast stream to exploit security vulnerabilities on Smart TVs (STVs) in range. We implemented a proof-of-concept attack based on a malicious Hybrid Broadcast Broadband TV app, able to acquire permanent system-level access to an STV over the air, in less than 10 s. These attacks, however, are severely limited in range due to required co-channel protection ratios (CCPRs), which is in direct contradiction to previous publications. We present evidence for these limitations in form of laboratory experiments, extensive simulations, and field measurements. To this end, we developed an automated, low-cost method for CCPR determination, as well as a method for non-disruptive attack range measurements based on a gap filler and the resulting channel impulse response.</li>
</ul>

<h3>Title: Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank  Modifications</h3>
<ul>
<li><strong>Authors: </strong>Boyi Wei, Kaixuan Huang, Yangsibo Huang, Tinghao Xie, Xiangyu Qi, Mengzhou Xia, Prateek Mittal, Mengdi Wang, Peter Henderson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05162">https://arxiv.org/abs/2402.05162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05162">https://arxiv.org/pdf/2402.05162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05162]] Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank  Modifications(https://arxiv.org/abs/2402.05162)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) show inherent brittleness in their safety mechanisms, as evidenced by their susceptibility to jailbreaking and even non-malicious fine-tuning. This study explores this brittleness of safety alignment by leveraging pruning and low-rank modifications. We develop methods to identify critical regions that are vital for safety guardrails, and that are disentangled from utility-relevant regions at both the neuron and rank levels. Surprisingly, the isolated regions we find are sparse, comprising about $3\%$ at the parameter level and $2.5\%$ at the rank level. Removing these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model's safety mechanisms. Moreover, we show that LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications to the safety-critical regions are restricted. These findings underscore the urgent need for more robust safety strategies in LLMs.</li>
</ul>

<h3>Title: Towards Understanding Inductive Bias in Transformers: A View From  Infinity</h3>
<ul>
<li><strong>Authors: </strong>Itay Lavie, Guy Gur-Ari, Zohar Ringel</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.dis-nn, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05173">https://arxiv.org/abs/2402.05173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05173">https://arxiv.org/pdf/2402.05173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05173]] Towards Understanding Inductive Bias in Transformers: A View From  Infinity(https://arxiv.org/abs/2402.05173)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We study inductive bias in Transformers in the infinitely over-parameterized Gaussian process limit and argue transformers tend to be biased towards more permutation symmetric functions in sequence space. We show that the representation theory of the symmetric group can be used to give quantitative analytical predictions when the dataset is symmetric to permutations between tokens. We present a simplified transformer block and solve the model at the limit, including accurate predictions for the learning curves and network outputs. We show that in common setups, one can derive tight bounds in the form of a scaling law for the learnability as a function of the context length. Finally, we argue WikiText dataset, does indeed possess a degree of permutation symmetry.</li>
</ul>

<h3>Title: $λ$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion  Models by Leveraging CLIP Latent Space</h3>
<ul>
<li><strong>Authors: </strong>Maitreya Patel, Sangmin Jung, Chitta Baral, Yezhou Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05195">https://arxiv.org/abs/2402.05195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05195">https://arxiv.org/pdf/2402.05195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05195]] $λ$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion  Models by Leveraging CLIP Latent Space(https://arxiv.org/abs/2402.05195)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Despite the recent advances in personalized text-to-image (P-T2I) generative models, subject-driven T2I remains challenging. The primary bottlenecks include 1) Intensive training resource requirements, 2) Hyper-parameter sensitivity leading to inconsistent outputs, and 3) Balancing the intricacies of novel visual concept and composition alignment. We start by re-iterating the core philosophy of T2I diffusion models to address the above limitations. Predominantly, contemporary subject-driven T2I approaches hinge on Latent Diffusion Models (LDMs), which facilitate T2I mapping through cross-attention layers. While LDMs offer distinct advantages, P-T2I methods' reliance on the latent space of these diffusion models significantly escalates resource demands, leading to inconsistent results and necessitating numerous iterations for a single desired image. Recently, ECLIPSE has demonstrated a more resource-efficient pathway for training UnCLIP-based T2I models, circumventing the need for diffusion text-to-image priors. Building on this, we introduce $\lambda$-ECLIPSE. Our method illustrates that effective P-T2I does not necessarily depend on the latent space of diffusion models. $\lambda$-ECLIPSE achieves single, multi-subject, and edge-guided T2I personalization with just 34M parameters and is trained on a mere 74 GPU hours using 1.6M image-text interleaved data. Through extensive experiments, we also establish that $\lambda$-ECLIPSE surpasses existing baselines in composition alignment while preserving concept alignment performance, even with significantly lower resource utilization.</li>
</ul>

<h3>Title: The Effect of Sampling Temperature on Problem Solving in Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Matthew Renze, Erhan Guven</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05201">https://arxiv.org/abs/2402.05201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05201">https://arxiv.org/pdf/2402.05201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05201]] The Effect of Sampling Temperature on Problem Solving in Large Language  Models(https://arxiv.org/abs/2402.05201)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this research study, we empirically investigate the effect of sampling temperature on the performance of Large Language Models (LLMs) on various problem-solving tasks. We created a multiple-choice question-and-answer (MCQA) exam by randomly sampling problems from standard LLM benchmarks. Then, we used four popular LLMs with five prompt-engineering techniques to solve the MCQA problems while increasing the sampling temperature from 0.0 to 1.0. Despite anecdotal reports to the contrary, our empirical results indicate that changes in temperature in the range 0.0 to 1.0 do not have a statistically significant impact on LLM performance for problem-solving tasks. In addition, these results appear to hold regardless of the LLM, the prompt-engineering technique, or the problem domain. All code, data, and supplemental materials are available on GitHub at: https://github.com/matthewrenze/jhu-llm-temperature.</li>
</ul>

<h3>Title: QGFN: Controllable Greediness with Action Values</h3>
<ul>
<li><strong>Authors: </strong>Elaine Lau, Stephen Zhewen Lu, Ling Pan, Doina Precup, Emmanuel Bengio</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05234">https://arxiv.org/abs/2402.05234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05234">https://arxiv.org/pdf/2402.05234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05234]] QGFN: Controllable Greediness with Action Values(https://arxiv.org/abs/2402.05234)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Flow Networks (GFlowNets; GFNs) are a family of reward/energy-based generative methods for combinatorial objects, capable of generating diverse and high-utility samples. However, biasing GFNs towards producing high-utility samples is non-trivial. In this work, we leverage connections between GFNs and reinforcement learning (RL) and propose to combine the GFN policy with an action-value estimate, $Q$, to create greedier sampling policies which can be controlled by a mixing parameter. We show that several variants of the proposed method, QGFN, are able to improve on the number of high-reward samples generated in a variety of tasks without sacrificing diversity.</li>
</ul>

<h3>Title: SPAD : Spatially Aware Multiview Diffusers</h3>
<ul>
<li><strong>Authors: </strong>Yash Kant, Ziyi Wu, Michael Vasilkovsky, Guocheng Qian, Jian Ren, Riza Alp Guler, Bernard Ghanem, Sergey Tulyakov, Igor Gilitschenski, Aliaksandr Siarohin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05235">https://arxiv.org/abs/2402.05235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05235">https://arxiv.org/pdf/2402.05235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05235]] SPAD : Spatially Aware Multiview Diffusers(https://arxiv.org/abs/2402.05235)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present SPAD, a novel approach for creating consistent multi-view images from text prompts or single images. To enable multi-view generation, we repurpose a pretrained 2D diffusion model by extending its self-attention layers with cross-view interactions, and fine-tune it on a high quality subset of Objaverse. We find that a naive extension of the self-attention proposed in prior work (e.g. MVDream) leads to content copying between views. Therefore, we explicitly constrain the cross-view attention based on epipolar geometry. To further enhance 3D consistency, we utilize Plucker coordinates derived from camera rays and inject them as positional encoding. This enables SPAD to reason over spatial proximity in 3D well. In contrast to recent works that can only generate views at fixed azimuth and elevation, SPAD offers full camera control and achieves state-of-the-art results in novel view synthesis on unseen objects from the Objaverse and Google Scanned Objects datasets. Finally, we demonstrate that text-to-3D generation using SPAD prevents the multi-face Janus issue. See more details at our webpage: https://yashkant.github.io/spad</li>
</ul>

<h3>Title: Learning Fair Ranking Policies via Differentiable Optimization of  Ordered Weighted Averages</h3>
<ul>
<li><strong>Authors: </strong>My H. Dinh, James Kotary, Ferdinando Fioretto</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05252">https://arxiv.org/abs/2402.05252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05252">https://arxiv.org/pdf/2402.05252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05252]] Learning Fair Ranking Policies via Differentiable Optimization of  Ordered Weighted Averages(https://arxiv.org/abs/2402.05252)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Learning to Rank (LTR) is one of the most widely used machine learning applications. It is a key component in platforms with profound societal impacts, including job search, healthcare information retrieval, and social media content feeds. Conventional LTR models have been shown to produce biases results, stimulating a discourse on how to address the disparities introduced by ranking systems that solely prioritize user relevance. However, while several models of fair learning to rank have been proposed, they suffer from deficiencies either in accuracy or efficiency, thus limiting their applicability to real-world ranking platforms. This paper shows how efficiently-solvable fair ranking models, based on the optimization of Ordered Weighted Average (OWA) functions, can be integrated into the training loop of an LTR model to achieve favorable balances between fairness, user utility, and runtime efficiency. In particular, this paper is the first to show how to backpropagate through constrained optimizations of OWA objectives, enabling their use in integrated prediction and decision models.</li>
</ul>

<h3>Title: AdaBatchGrad: Combining Adaptive Batch Size and Adaptive Step Size</h3>
<ul>
<li><strong>Authors: </strong>Petr Ostroukhov, Aigerim Zhumabayeva, Chulu Xiang, Alexander Gasnikov, Martin Takáč, Dmitry Kamzolov</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05264">https://arxiv.org/abs/2402.05264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05264">https://arxiv.org/pdf/2402.05264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05264]] AdaBatchGrad: Combining Adaptive Batch Size and Adaptive Step Size(https://arxiv.org/abs/2402.05264)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a novel adaptation of the Stochastic Gradient Descent (SGD), termed AdaBatchGrad. This modification seamlessly integrates an adaptive step size with an adjustable batch size. An increase in batch size and a decrease in step size are well-known techniques to tighten the area of convergence of SGD and decrease its variance. A range of studies by R. Byrd and J. Nocedal introduced various testing techniques to assess the quality of mini-batch gradient approximations and choose the appropriate batch sizes at every step. Methods that utilized exact tests were observed to converge within $O(LR^2/\varepsilon)$ iterations. Conversely, inexact test implementations sometimes resulted in non-convergence and erratic performance. To address these challenges, AdaBatchGrad incorporates both adaptive batch and step sizes, enhancing the method's robustness and stability. For exact tests, our approach converges in $O(LR^2/\varepsilon)$ iterations, analogous to standard gradient descent. For inexact tests, it achieves convergence in $O(\max\lbrace LR^2/\varepsilon, \sigma^2 R^2/\varepsilon^2 \rbrace )$ iterations. This makes AdaBatchGrad markedly more robust and computationally efficient relative to prevailing methods. To substantiate the efficacy of our method, we experimentally show, how the introduction of adaptive step size and adaptive batch size gradually improves the performance of regular SGD. The results imply that AdaBatchGrad surpasses alternative methods, especially when applied to inexact tests.</li>
</ul>

<h3>Title: Do Transformer World Models Give Better Policy Gradients?</h3>
<ul>
<li><strong>Authors: </strong>Michel Ma, Tianwei Ni, Clement Gehring, Pierluca D'Oro, Pierre-Luc Bacon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05290">https://arxiv.org/abs/2402.05290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05290">https://arxiv.org/pdf/2402.05290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05290]] Do Transformer World Models Give Better Policy Gradients?(https://arxiv.org/abs/2402.05290)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>A natural approach for reinforcement learning is to predict future rewards by unrolling a neural network world model, and to backpropagate through the resulting computational graph to learn a policy. However, this method often becomes impractical for long horizons since typical world models induce hard-to-optimize loss landscapes. Transformers are known to efficiently propagate gradients overlong horizons: could they be the solution to this problem? Surprisingly, we show that commonly-used transformer world models produce circuitous gradient paths, which can be detrimental to long-range policy gradients. To tackle this challenge, we propose a class of world models called Actions World Models (AWMs), designed to provide more direct routes for gradient propagation. We integrate such AWMs into a policy gradient framework that underscores the relationship between network architectures and the policy gradient updates they inherently represent. We demonstrate that AWMs can generate optimization landscapes that are easier to navigate even when compared to those from the simulator itself. This property allows transformer AWMs to produce better policies than competitive baselines in realistic long-horizon tasks.</li>
</ul>

<h3>Title: A comparative study on feature selection for a risk prediction model for  colorectal cancer</h3>
<ul>
<li><strong>Authors: </strong>N. Cueto-López, M. T. García-Ordás, V. Dávila-Batista, V. Moreno, N. Aragonés, R. Alaiz-Rodríguez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05293">https://arxiv.org/abs/2402.05293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05293">https://arxiv.org/pdf/2402.05293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05293]] A comparative study on feature selection for a risk prediction model for  colorectal cancer(https://arxiv.org/abs/2402.05293)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust</a></li>
<li><strong>Abstract: </strong>Background and objective Risk prediction models aim at identifying people at higher risk of developing a target disease. Feature selection is particularly important to improve the prediction model performance avoiding overfitting and to identify the leading cancer risk (and protective) factors. Assessing the stability of feature selection/ranking algorithms becomes an important issue when the aim is to analyze the features with more prediction power. Methods This work is focused on colorectal cancer, assessing several feature ranking algorithms in terms of performance for a set of risk prediction models (Neural Networks, Support Vector Machines (SVM), Logistic Regression, k-Nearest Neighbors and Boosted Trees). Additionally, their robustness is evaluated following a conventional approach with scalar stability metrics and a visual approach proposed in this work to study both similarity among feature ranking techniques as well as their individual stability. A comparative analysis is carried out between the most relevant features found out in this study and features provided by the experts according to the state-of-the-art knowledge. Results The two best performance results in terms of Area Under the ROC Curve (AUC) are achieved with a SVM classifier using the top-41 features selected by the SVM wrapper approach (AUC=0.693) and Logistic Regression with the top-40 features selected by the Pearson (AUC=0.689). Experiments showed that performing feature selection contributes to classification performance with a 3.9% and 1.9% improvement in AUC for the SVM and Logistic Regression classifier, respectively, with respect to the results using the full feature set. The visual approach proposed in this work allows to see that the Neural Network-based wrapper ranking is the most unstable while the Random Forest is the most stable.</li>
</ul>

<h3>Title: Examining Modality Incongruity in Multimodal Federated Learning for  Medical Vision and Language-based Disease Detection</h3>
<ul>
<li><strong>Authors: </strong>Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05294">https://arxiv.org/abs/2402.05294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05294">https://arxiv.org/pdf/2402.05294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05294]] Examining Modality Incongruity in Multimodal Federated Learning for  Medical Vision and Language-based Disease Detection(https://arxiv.org/abs/2402.05294)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Multimodal Federated Learning (MMFL) utilizes multiple modalities in each client to build a more powerful Federated Learning (FL) model than its unimodal counterpart. However, the impact of missing modality in different clients, also called modality incongruity, has been greatly overlooked. This paper, for the first time, analyses the impact of modality incongruity and reveals its connection with data heterogeneity across participating clients. We particularly inspect whether incongruent MMFL with unimodal and multimodal clients is more beneficial than unimodal FL. Furthermore, we examine three potential routes of addressing this issue. Firstly, we study the effectiveness of various self-attention mechanisms towards incongruity-agnostic information fusion in MMFL. Secondly, we introduce a modality imputation network (MIN) pre-trained in a multimodal client for modality translation in unimodal clients and investigate its potential towards mitigating the missing modality problem. Thirdly, we assess the capability of client-level and server-level regularization techniques towards mitigating modality incongruity effects. Experiments are conducted under several MMFL settings on two publicly available real-world datasets, MIMIC-CXR and Open-I, with Chest X-Ray and radiology reports.</li>
</ul>

<h3>Title: An information theoretic approach to quantify the stability of feature  selection and ranking algorithms</h3>
<ul>
<li><strong>Authors: </strong>Alaiz-Rodriguez, R., Parnell, A. C</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05295">https://arxiv.org/abs/2402.05295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05295">https://arxiv.org/pdf/2402.05295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05295]] An information theoretic approach to quantify the stability of feature  selection and ranking algorithms(https://arxiv.org/abs/2402.05295)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Feature selection is a key step when dealing with high dimensional data. In particular, these techniques simplify the process of knowledge discovery from the data by selecting the most relevant features out of the noisy, redundant and irrelevant features. A problem that arises in many of these practical applications is that the outcome of the feature selection algorithm is not stable. Thus, small variations in the data may yield very different feature rankings. Assessing the stability of these methods becomes an important issue in the previously mentioned situations. We propose an information theoretic approach based on the Jensen Shannon divergence to quantify this robustness. Unlike other stability measures, this metric is suitable for different algorithm outcomes: full ranked lists, feature subsets as well as the lesser studied partial ranked lists. This generalized metric quantifies the difference among a whole set of lists with the same size, following a probabilistic approach and being able to give more importance to the disagreements that appear at the top of the list. Moreover, it possesses desirable properties including correction for change, upper lower bounds and conditions for a deterministic selection. We illustrate the use of this stability metric with data generated in a fully controlled way and compare it with popular metrics including the Spearmans rank correlation and the Kunchevas index on feature ranking and selection outcomes, respectively. Additionally, experimental validation of the proposed approach is carried out on a real-world problem of food quality assessment showing its potential to quantify stability from different perspectives.</li>
</ul>

<h3>Title: Classifying spam emails using agglomerative hierarchical clustering and  a topic-based approach</h3>
<ul>
<li><strong>Authors: </strong>F. Janez-Martino, R. Alaiz-Rodriguez, V. Gonzalez-Castro, E. Fidalgo, E. Alegre</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05296">https://arxiv.org/abs/2402.05296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05296">https://arxiv.org/pdf/2402.05296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05296]] Classifying spam emails using agglomerative hierarchical clustering and  a topic-based approach(https://arxiv.org/abs/2402.05296)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Spam emails are unsolicited, annoying and sometimes harmful messages which may contain malware, phishing or hoaxes. Unlike most studies that address the design of efficient anti-spam filters, we approach the spam email problem from a different and novel perspective. Focusing on the needs of cybersecurity units, we follow a topic-based approach for addressing the classification of spam email into multiple categories. We propose SPEMC-15K-E and SPEMC-15K-S, two novel datasets with approximately 15K emails each in English and Spanish, respectively, and we label them using agglomerative hierarchical clustering into 11 classes. We evaluate 16 pipelines, combining four text representation techniques -Term Frequency-Inverse Document Frequency (TF-IDF), Bag of Words, Word2Vec and BERT- and four classifiers: Support Vector Machine, N\"aive Bayes, Random Forest and Logistic Regression. Experimental results show that the highest performance is achieved with TF-IDF and LR for the English dataset, with a F1 score of 0.953 and an accuracy of 94.6%, and while for the Spanish dataset, TF-IDF with NB yields a F1 score of 0.945 and 98.5% accuracy. Regarding the processing time, TF-IDF with LR leads to the fastest classification, processing an English and Spanish spam email in and on average, respectively.</li>
</ul>

<h3>Title: Knowledge Distillation for Road Detection based on cross-model  Semi-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Wanli Ma, Oktay Karakus, Paul L. Rosin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05305">https://arxiv.org/abs/2402.05305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05305">https://arxiv.org/pdf/2402.05305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05305]] Knowledge Distillation for Road Detection based on cross-model  Semi-Supervised Learning(https://arxiv.org/abs/2402.05305)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>The advancement of knowledge distillation has played a crucial role in enabling the transfer of knowledge from larger teacher models to smaller and more efficient student models, and is particularly beneficial for online and resource-constrained applications. The effectiveness of the student model heavily relies on the quality of the distilled knowledge received from the teacher. Given the accessibility of unlabelled remote sensing data, semi-supervised learning has become a prevalent strategy for enhancing model performance. However, relying solely on semi-supervised learning with smaller models may be insufficient due to their limited capacity for feature extraction. This limitation restricts their ability to exploit training data. To address this issue, we propose an integrated approach that combines knowledge distillation and semi-supervised learning methods. This hybrid approach leverages the robust capabilities of large models to effectively utilise large unlabelled data whilst subsequently providing the small student model with rich and informative features for enhancement. The proposed semi-supervised learning-based knowledge distillation (SSLKD) approach demonstrates a notable improvement in the performance of the student model, in the application of road segmentation, surpassing the effectiveness of traditional semi-supervised learning methods.</li>
</ul>

<h3>Title: Sym-Q: Adaptive Symbolic Regression via Sequential Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Yuan Tian, Wenqi Zhou, Hao Dong, David S. Kammer, Olga Fink</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05306">https://arxiv.org/abs/2402.05306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05306">https://arxiv.org/pdf/2402.05306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05306]] Sym-Q: Adaptive Symbolic Regression via Sequential Decision-Making(https://arxiv.org/abs/2402.05306)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Symbolic regression holds great potential for uncovering underlying mathematical and physical relationships from empirical data. While existing transformer-based models have recently achieved significant success in this domain, they face challenges in terms of generalizability and adaptability. Typically, in cases where the output expressions do not adequately fit experimental data, the models lack efficient mechanisms to adapt or modify the expression. This inflexibility hinders their application in real-world scenarios, particularly in discovering unknown physical or biological relationships. Inspired by how human experts refine and adapt expressions, we introduce Symbolic Q-network (Sym-Q), a novel reinforcement learning-based model that redefines symbolic regression as a sequential decision-making task. Sym-Q leverages supervised demonstrations and refines expressions based on reward signals indicating the quality of fitting precision. Its distinctive ability to manage the complexity of expression trees and perform precise step-wise updates significantly enhances flexibility and efficiency. Our results demonstrate that Sym-Q excels not only in recovering underlying mathematical structures but also uniquely learns to efficiently refine the output expression based on reward signals, thereby discovering underlying expressions. Sym-Q paves the way for more intuitive and impactful discoveries in physical science, marking a substantial advancement in the field of symbolic regression.</li>
</ul>

<h3>Title: Investigating Generalization Behaviours of Generative Flow Networks</h3>
<ul>
<li><strong>Authors: </strong>Lazar Atanackovic, Emmanuel Bengio</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05309">https://arxiv.org/abs/2402.05309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05309">https://arxiv.org/pdf/2402.05309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05309]] Investigating Generalization Behaviours of Generative Flow Networks(https://arxiv.org/abs/2402.05309)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Generative Flow Networks (GFlowNets, GFNs) are a generative framework for learning unnormalized probability mass functions over discrete spaces. Since their inception, GFlowNets have proven to be useful for learning generative models in applications where the majority of the discrete space is unvisited during training. This has inspired some to hypothesize that GFlowNets, when paired with deep neural networks (DNNs), have favourable generalization properties. In this work, we empirically verify some of the hypothesized mechanisms of generalization of GFlowNets. In particular, we find that the functions that GFlowNets learn to approximate have an implicit underlying structure which facilitate generalization. We also find that GFlowNets are sensitive to being trained offline and off-policy; however, the reward implicitly learned by GFlowNets is robust to changes in the training distribution.</li>
</ul>

<h3>Title: Domain-Agnostic Hardware Fingerprinting-Based Device Identifier for  Zero-Trust IoT Security</h3>
<ul>
<li><strong>Authors: </strong>Abdurrahman Elmaghbub, Bechir Hamdaoui</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05332">https://arxiv.org/abs/2402.05332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05332">https://arxiv.org/pdf/2402.05332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05332]] Domain-Agnostic Hardware Fingerprinting-Based Device Identifier for  Zero-Trust IoT Security(https://arxiv.org/abs/2402.05332)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust</a></li>
<li><strong>Abstract: </strong>Next-generation networks aim for comprehensive connectivity, interconnecting humans, machines, devices, and systems seamlessly. This interconnectivity raises concerns about privacy and security, given the potential network-wide impact of a single compromise. To address this challenge, the Zero Trust (ZT) paradigm emerges as a key method for safeguarding network integrity and data confidentiality. This work introduces EPS-CNN, a novel deep-learning-based wireless device identification framework designed to serve as the device authentication layer within the ZT architecture, with a focus on resource-constrained IoT devices. At the core of EPS-CNN, a Convolutional Neural Network (CNN) is utilized to generate the device identity from a unique RF signal representation, known as the Double-Sided Envelope Power Spectrum (EPS), which effectively captures the device-specific hardware characteristics while ignoring device-unrelated information. Experimental evaluations show that the proposed framework achieves over 99%, 93%, and 95% testing accuracy when tested in same-domain (day, location, and channel), cross-day, and cross-location scenarios, respectively. Our findings demonstrate the superiority of the proposed framework in enhancing the accuracy, robustness, and adaptability of deep learning-based methods, thus offering a pioneering solution for enabling ZT IoT device identification.</li>
</ul>

<h3>Title: Descanning: From Scanned to the Original Images with a Color Correction  Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Junghun Cha, Ali Haider, Seoyun Yang, Hoeyeong Jin, Subin Yang, A. F. M. Shahab Uddin, Jaehyoung Kim, Soo Ye Kim, Sung-Ho Bae</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05350">https://arxiv.org/abs/2402.05350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05350">https://arxiv.org/pdf/2402.05350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05350]] Descanning: From Scanned to the Original Images with a Color Correction  Diffusion Model(https://arxiv.org/abs/2402.05350)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>A significant volume of analog information, i.e., documents and images, have been digitized in the form of scanned copies for storing, sharing, and/or analyzing in the digital world. However, the quality of such contents is severely degraded by various distortions caused by printing, storing, and scanning processes in the physical world. Although restoring high-quality content from scanned copies has become an indispensable task for many products, it has not been systematically explored, and to the best of our knowledge, no public datasets are available. In this paper, we define this problem as Descanning and introduce a new high-quality and large-scale dataset named DESCAN-18K. It contains 18K pairs of original and scanned images collected in the wild containing multiple complex degradations. In order to eliminate such complex degradations, we propose a new image restoration model called DescanDiffusion consisting of a color encoder that corrects the global color degradation and a conditional denoising diffusion probabilistic model (DDPM) that removes local degradations. To further improve the generalization ability of DescanDiffusion, we also design a synthetic data generation scheme by reproducing prominent degradations in scanned images. We demonstrate that our DescanDiffusion outperforms other baselines including commercial restoration products, objectively and subjectively, via comprehensive experiments and analyses.</li>
</ul>

<h3>Title: Revisiting Early-Learning Regularization When Federated Learning Meets  Noisy Labels</h3>
<ul>
<li><strong>Authors: </strong>Taehyeon Kim, Donggyu Kim, Se-Young Yun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05353">https://arxiv.org/abs/2402.05353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05353">https://arxiv.org/pdf/2402.05353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05353]] Revisiting Early-Learning Regularization When Federated Learning Meets  Noisy Labels(https://arxiv.org/abs/2402.05353)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>In the evolving landscape of federated learning (FL), addressing label noise presents unique challenges due to the decentralized and diverse nature of data collection across clients. Traditional centralized learning approaches to mitigate label noise are constrained in FL by privacy concerns and the heterogeneity of client data. This paper revisits early-learning regularization, introducing an innovative strategy, Federated Label-mixture Regularization (FLR). FLR adeptly adapts to FL's complexities by generating new pseudo labels, blending local and global model predictions. This method not only enhances the accuracy of the global model in both i.i.d. and non-i.i.d. settings but also effectively counters the memorization of noisy labels. Demonstrating compatibility with existing label noise and FL techniques, FLR paves the way for improved generalization in FL environments fraught with label inaccuracies.</li>
</ul>

<h3>Title: Exploring Learning Complexity for Downstream Data Pruning</h3>
<ul>
<li><strong>Authors: </strong>Wenyu Jiang, Zhenlong Liu, Zejian Xie, Songxin Zhang, Bingyi Jing, Hongxin Wei</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05356">https://arxiv.org/abs/2402.05356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05356">https://arxiv.org/pdf/2402.05356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05356]] Exploring Learning Complexity for Downstream Data Pruning(https://arxiv.org/abs/2402.05356)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The over-parameterized pre-trained models pose a great challenge to fine-tuning with limited computation resources. An intuitive solution is to prune the less informative samples from the fine-tuning dataset. A series of training-based scoring functions are proposed to quantify the informativeness of the data subset but the pruning cost becomes non-negligible due to the heavy parameter updating. For efficient pruning, it is viable to adapt the similarity scoring function of geometric-based methods from training-based to training-free. However, we empirically show that such adaption distorts the original pruning and results in inferior performance on the downstream tasks. In this paper, we propose to treat the learning complexity (LC) as the scoring function for classification and regression tasks. Specifically, the learning complexity is defined as the average predicted confidence of subnets with different capacities, which encapsulates data processing within a converged model. Then we preserve the diverse and easy samples for fine-tuning. Extensive experiments with vision datasets demonstrate the effectiveness and efficiency of the proposed scoring function for classification tasks. For the instruction fine-tuning of large language models, our method achieves state-of-the-art performance with stable convergence, outperforming the full training with only 10\% of the instruction dataset.</li>
</ul>

<h3>Title: Noise Contrastive Alignment of Language Models with Explicit Rewards</h3>
<ul>
<li><strong>Authors: </strong>Huayu Chen, Guande He, Hang Su, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05369">https://arxiv.org/abs/2402.05369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05369">https://arxiv.org/pdf/2402.05369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05369]] Noise Contrastive Alignment of Language Models with Explicit Rewards(https://arxiv.org/abs/2402.05369)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>User intentions are typically formalized as evaluation rewards to be maximized when fine-tuning language models (LMs). Existing alignment methods, such as Direct Preference Optimization (DPO), are mainly tailored for pairwise preference data where rewards are implicitly defined rather than explicitly given. In this paper, we introduce a general framework for LM alignment, leveraging Noise Contrastive Estimation (NCE) to bridge the gap in handling reward datasets explicitly annotated with scalar evaluations. Our framework comprises two parallel algorithms, NCA and InfoNCA, both enabling the direct extraction of an LM policy from reward data as well as preference data. Notably, we show that the DPO loss is a special case of our proposed InfoNCA objective under pairwise preference settings, thereby integrating and extending current alignment theories. By contrasting NCA and InfoNCA, we show that InfoNCA and DPO adjust relative likelihood across different responses to a single instruction, while NCA optimizes absolute likelihood for each response. We apply our methods to align a 7B language model with a GPT-4 annotated reward dataset. Experimental results suggest that InfoNCA surpasses the DPO baseline in GPT-4 evaluations, while NCA enjoys better training stability with competitive performance.</li>
</ul>

<h3>Title: Attention as Robust Representation for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>PeiSong Niu, Tian Zhou, Xue Wang, Liang Sun, Rong Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05370">https://arxiv.org/abs/2402.05370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05370">https://arxiv.org/pdf/2402.05370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05370]] Attention as Robust Representation for Time Series Forecasting(https://arxiv.org/abs/2402.05370)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Time series forecasting is essential for many practical applications, with the adoption of transformer-based models on the rise due to their impressive performance in NLP and CV. Transformers' key feature, the attention mechanism, dynamically fusing embeddings to enhance data representation, often relegating attention weights to a byproduct role. Yet, time series data, characterized by noise and non-stationarity, poses significant forecasting challenges. Our approach elevates attention weights as the primary representation for time series, capitalizing on the temporal relationships among data points to improve forecasting accuracy. Our study shows that an attention map, structured using global landmarks and local windows, acts as a robust kernel representation for data points, withstanding noise and shifts in distribution. Our method outperforms state-of-the-art models, reducing mean squared error (MSE) in multivariate time series forecasting by a notable 3.6% without altering the core neural network architecture. It serves as a versatile component that can readily replace recent patching based embedding schemes in transformer-based models, boosting their performance.</li>
</ul>

<h3>Title: CIC: A framework for Culturally-aware Image Captioning</h3>
<ul>
<li><strong>Authors: </strong>Youngsik Yun, Jihie Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05374">https://arxiv.org/abs/2402.05374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05374">https://arxiv.org/pdf/2402.05374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05374]] CIC: A framework for Culturally-aware Image Captioning(https://arxiv.org/abs/2402.05374)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Image Captioning generates descriptive sentences from images using Vision-Language Pre-trained models (VLPs) such as BLIP, which has improved greatly. However, current methods lack the generation of detailed descriptive captions for the cultural elements depicted in the images, such as the traditional clothing worn by people from Asian cultural groups. In this paper, we propose a new framework, \textbf{Culturally-aware Image Captioning (CIC)}, that generates captions and describes cultural elements extracted from cultural visual elements in images representing cultures. Inspired by methods combining visual modality and Large Language Models (LLMs) through appropriate prompts, our framework (1) generates questions based on cultural categories from images, (2) extracts cultural visual elements from Visual Question Answering (VQA) using generated questions, and (3) generates culturally-aware captions using LLMs with the prompts. Our human evaluation conducted on 45 participants from 4 different cultural groups with a high understanding of the corresponding culture shows that our proposed framework generates more culturally descriptive captions when compared to the image captioning baseline based on VLPs. Our code and dataset will be made publicly available upon acceptance.</li>
</ul>

<h3>Title: Get What You Want, Not What You Don't: Image Content Suppression for  Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Senmao Li, Joost van de Weijer, Taihang Hu, Fahad Shahbaz Khan, Qibin Hou, Yaxing Wang, Jian Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05375">https://arxiv.org/abs/2402.05375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05375">https://arxiv.org/pdf/2402.05375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05375]] Get What You Want, Not What You Don't: Image Content Suppression for  Text-to-Image Diffusion Models(https://arxiv.org/abs/2402.05375)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The success of recent text-to-image diffusion models is largely due to their capacity to be guided by a complex text prompt, which enables users to precisely describe the desired content. However, these models struggle to effectively suppress the generation of undesired content, which is explicitly requested to be omitted from the generated image in the prompt. In this paper, we analyze how to manipulate the text embeddings and remove unwanted content from them. We introduce two contributions, which we refer to as $\textit{soft-weighted regularization}$ and $\textit{inference-time text embedding optimization}$. The first regularizes the text embedding matrix and effectively suppresses the undesired content. The second method aims to further suppress the unwanted content generation of the prompt, and encourages the generation of desired content. We evaluate our method quantitatively and qualitatively on extensive experiments, validating its effectiveness. Furthermore, our method is generalizability to both the pixel-space diffusion models (i.e. DeepFloyd-IF) and the latent-space diffusion models (i.e. Stable Diffusion).</li>
</ul>

<h3>Title: Zero-Shot Chain-of-Thought Reasoning Guided by Evolutionary Algorithms  in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Feihu Jin, Yifan Liu, Ying Tan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05376">https://arxiv.org/abs/2402.05376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05376">https://arxiv.org/pdf/2402.05376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05376]] Zero-Shot Chain-of-Thought Reasoning Guided by Evolutionary Algorithms  in Large Language Models(https://arxiv.org/abs/2402.05376)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable performance across diverse tasks and exhibited impressive reasoning abilities by applying zero-shot Chain-of-Thought (CoT) prompting. However, due to the evolving nature of sentence prefixes during the pre-training phase, existing zero-shot CoT prompting methods that employ identical CoT prompting across all task instances may not be optimal. In this paper, we introduce a novel zero-shot prompting method that leverages evolutionary algorithms to generate diverse promptings for LLMs dynamically. Our approach involves initializing two CoT promptings, performing evolutionary operations based on LLMs to create a varied set, and utilizing the LLMs to select a suitable CoT prompting for a given problem. Additionally, a rewriting operation, guided by the selected CoT prompting, enhances the understanding of the LLMs about the problem. Extensive experiments conducted across ten reasoning datasets demonstrate the superior performance of our proposed method compared to current zero-shot CoT prompting methods on GPT-3.5-turbo and GPT-4. Moreover, in-depth analytical experiments underscore the adaptability and effectiveness of our method in various reasoning tasks.</li>
</ul>

<h3>Title: Task-customized Masked AutoEncoder via Mixture of Cluster-conditional  Experts</h3>
<ul>
<li><strong>Authors: </strong>Zhili Liu, Kai Chen, Jianhua Han, Lanqing Hong, Hang Xu, Zhenguo Li, James T. Kwok</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05382">https://arxiv.org/abs/2402.05382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05382">https://arxiv.org/pdf/2402.05382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05382]] Task-customized Masked AutoEncoder via Mixture of Cluster-conditional  Experts(https://arxiv.org/abs/2402.05382)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Masked Autoencoder~(MAE) is a prevailing self-supervised learning method that achieves promising results in model pre-training. However, when the various downstream tasks have data distributions different from the pre-training data, the semantically irrelevant pre-training information might result in negative transfer, impeding MAE's scalability. To address this issue, we propose a novel MAE-based pre-training paradigm, Mixture of Cluster-conditional Experts (MoCE), which can be trained once but provides customized pre-training models for diverse downstream tasks. Different from the mixture of experts (MoE), our MoCE trains each expert only with semantically relevant images by using cluster-conditional gates. Thus, each downstream task can be allocated to its customized model pre-trained with data most similar to the downstream data. Experiments on a collection of 11 downstream tasks show that MoCE outperforms the vanilla MAE by 2.45\% on average. It also obtains new state-of-the-art self-supervised learning results on detection and segmentation.</li>
</ul>

<h3>Title: Enhancing Zero-shot Counting via Language-guided Exemplar Learning</h3>
<ul>
<li><strong>Authors: </strong>Mingjie Wang, Jun Zhou, Yong Dai, Eric Buys, Minglun Gong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05394">https://arxiv.org/abs/2402.05394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05394">https://arxiv.org/pdf/2402.05394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05394]] Enhancing Zero-shot Counting via Language-guided Exemplar Learning(https://arxiv.org/abs/2402.05394)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, Class-Agnostic Counting (CAC) problem has garnered increasing attention owing to its intriguing generality and superior efficiency compared to Category-Specific Counting (CSC). This paper proposes a novel ExpressCount to enhance zero-shot object counting by delving deeply into language-guided exemplar learning. Specifically, the ExpressCount is comprised of an innovative Language-oriented Exemplar Perceptron and a downstream visual Zero-shot Counting pipeline. Thereinto, the perceptron hammers at exploiting accurate exemplar cues from collaborative language-vision signals by inheriting rich semantic priors from the prevailing pre-trained Large Language Models (LLMs), whereas the counting pipeline excels in mining fine-grained features through dual-branch and cross-attention schemes, contributing to the high-quality similarity learning. Apart from building a bridge between the LLM in vogue and the visual counting tasks, expression-guided exemplar estimation significantly advances zero-shot learning capabilities for counting instances with arbitrary classes. Moreover, devising a FSC-147-Express with annotations of meticulous linguistic expressions pioneers a new venue for developing and validating language-based counting models. Extensive experiments demonstrate the state-of-the-art performance of our ExpressCount, even showcasing the accuracy on par with partial CSC models.</li>
</ul>

<h3>Title: On the Effect of Image Resolution on Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ritambhara Singh, Abhishek Jain, Pietro Perona, Shivani Agarwal, Junfeng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05398">https://arxiv.org/abs/2402.05398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05398">https://arxiv.org/pdf/2402.05398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05398]] On the Effect of Image Resolution on Semantic Segmentation(https://arxiv.org/abs/2402.05398)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>High-resolution semantic segmentation requires substantial computational resources. Traditional approaches in the field typically downscale the input images before processing and then upscale the low-resolution outputs back to their original dimensions. While this strategy effectively identifies broad regions, it often misses finer details. In this study, we demonstrate that a streamlined model capable of directly producing high-resolution segmentations can match the performance of more complex systems that generate lower-resolution results. By simplifying the network architecture, we enable the processing of images at their native resolution. Our approach leverages a bottom-up information propagation technique across various scales, which we have empirically shown to enhance segmentation accuracy. We have rigorously tested our method using leading-edge semantic segmentation datasets. Specifically, for the Cityscapes dataset, we further boost accuracy by applying the Noisy Student Training technique.</li>
</ul>

<h3>Title: Optimizing for ROC Curves on Class-Imbalanced Data by Training over a  Family of Loss Functions</h3>
<ul>
<li><strong>Authors: </strong>Kelsey Lieberman, Shuai Yuan, Swarna Kamlam Ravindran, Carlo Tomasi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05400">https://arxiv.org/abs/2402.05400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05400">https://arxiv.org/pdf/2402.05400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05400]] Optimizing for ROC Curves on Class-Imbalanced Data by Training over a  Family of Loss Functions(https://arxiv.org/abs/2402.05400)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Although binary classification is a well-studied problem in computer vision, training reliable classifiers under severe class imbalance remains a challenging problem. Recent work has proposed techniques that mitigate the effects of training under imbalance by modifying the loss functions or optimization methods. While this work has led to significant improvements in the overall accuracy in the multi-class case, we observe that slight changes in hyperparameter values of these methods can result in highly variable performance in terms of Receiver Operating Characteristic (ROC) curves on binary problems with severe imbalance. To reduce the sensitivity to hyperparameter choices and train more general models, we propose training over a family of loss functions, instead of a single loss function. We develop a method for applying Loss Conditional Training (LCT) to an imbalanced classification problem. Extensive experiment results, on both CIFAR and Kaggle competition datasets, show that our method improves model performance and is more robust to hyperparameter choices. Code will be made available at: https://github.com/klieberman/roc_lct.</li>
</ul>

<h3>Title: Version age-based client scheduling policy for federated learning</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Hu, Nikolaos Pappas, Howard H. Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05407">https://arxiv.org/abs/2402.05407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05407">https://arxiv.org/pdf/2402.05407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05407]] Version age-based client scheduling policy for federated learning(https://arxiv.org/abs/2402.05407)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has emerged as a privacy-preserving machine learning paradigm facilitating collaborative training across multiple clients without sharing local data. Despite advancements in edge device capabilities, communication bottlenecks present challenges in aggregating a large number of clients; only a portion of the clients can update their parameters upon each global aggregation. This phenomenon introduces the critical challenge of stragglers in FL and the profound impact of client scheduling policies on global model convergence and stability. Existing scheduling strategies address staleness but predominantly focus on either timeliness or content. Motivated by this, we introduce the novel concept of Version Age of Information (VAoI) to FL. Unlike traditional Age of Information metrics, VAoI considers both timeliness and content staleness. Each client's version age is updated discretely, indicating the freshness of information. VAoI is incorporated into the client scheduling policy to minimize the average VAoI, mitigating the impact of outdated local updates and enhancing the stability of FL systems.</li>
</ul>

<h3>Title: MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Dewei Zhou, You Li, Fan Ma, Zongxin Yang, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05408">https://arxiv.org/abs/2402.05408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05408">https://arxiv.org/pdf/2402.05408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05408]] MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis(https://arxiv.org/abs/2402.05408)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present a Multi-Instance Generation (MIG) task, simultaneously generating multiple instances with diverse controls in one image. Given a set of predefined coordinates and their corresponding descriptions, the task is to ensure that generated instances are accurately at the designated locations and that all instances' attributes adhere to their corresponding description. This broadens the scope of current research on Single-instance generation, elevating it to a more versatile and practical dimension. Inspired by the idea of divide and conquer, we introduce an innovative approach named Multi-Instance Generation Controller (MIGC) to address the challenges of the MIG task. Initially, we break down the MIG task into several subtasks, each involving the shading of a single instance. To ensure precise shading for each instance, we introduce an instance enhancement attention mechanism. Lastly, we aggregate all the shaded instances to provide the necessary information for accurately generating multiple instances in stable diffusion (SD). To evaluate how well generation models perform on the MIG task, we provide a COCO-MIG benchmark along with an evaluation pipeline. Extensive experiments were conducted on the proposed COCO-MIG benchmark, as well as on various commonly used benchmarks. The evaluation results illustrate the exceptional control capabilities of our model in terms of quantity, position, attribute, and interaction.</li>
</ul>

<h3>Title: Segmentation-free Connectionist Temporal Classification loss based OCR  Model for Text Captcha Classification</h3>
<ul>
<li><strong>Authors: </strong>Vaibhav Khatavkar, Makarand Velankar, Sneha Petkar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05417">https://arxiv.org/abs/2402.05417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05417">https://arxiv.org/pdf/2402.05417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05417]] Segmentation-free Connectionist Temporal Classification loss based OCR  Model for Text Captcha Classification(https://arxiv.org/abs/2402.05417)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, segmentation</a></li>
<li><strong>Abstract: </strong>Captcha are widely used to secure systems from automatic responses by distinguishing computer responses from human responses. Text, audio, video, picture picture-based Optical Character Recognition (OCR) are used for creating captcha. Text-based OCR captcha are the most often used captcha which faces issues namely, complex and distorted contents. There are attempts to build captcha detection and classification-based systems using machine learning and neural networks, which need to be tuned for accuracy. The existing systems face challenges in the recognition of distorted characters, handling variable-length captcha and finding sequential dependencies in captcha. In this work, we propose a segmentation-free OCR model for text captcha classification based on the connectionist temporal classification loss technique. The proposed model is trained and tested on a publicly available captcha dataset. The proposed model gives 99.80\% character level accuracy, while 95\% word level accuracy. The accuracy of the proposed model is compared with the state-of-the-art models and proves to be effective. The variable length complex captcha can be thus processed with the segmentation-free connectionist temporal classification loss technique with dependencies which will be massively used in securing the software systems.</li>
</ul>

<h3>Title: DiffTOP: Differentiable Trajectory Optimization for Deep Reinforcement  and Imitation Learning</h3>
<ul>
<li><strong>Authors: </strong>Weikang Wan, Yufei Wang, Zackory Erickson, David Held</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05421">https://arxiv.org/abs/2402.05421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05421">https://arxiv.org/pdf/2402.05421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05421]] DiffTOP: Differentiable Trajectory Optimization for Deep Reinforcement  and Imitation Learning(https://arxiv.org/abs/2402.05421)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper introduces DiffTOP, which utilizes Differentiable Trajectory OPtimization as the policy representation to generate actions for deep reinforcement and imitation learning. Trajectory optimization is a powerful and widely used algorithm in control, parameterized by a cost and a dynamics function. The key to our approach is to leverage the recent progress in differentiable trajectory optimization, which enables computing the gradients of the loss with respect to the parameters of trajectory optimization. As a result, the cost and dynamics functions of trajectory optimization can be learned end-to-end. DiffTOP addresses the ``objective mismatch'' issue of prior model-based RL algorithms, as the dynamics model in DiffTOP is learned to directly maximize task performance by differentiating the policy gradient loss through the trajectory optimization process. We further benchmark DiffTOP for imitation learning on standard robotic manipulation task suites with high-dimensional sensory observations and compare our method to feed-forward policy classes as well as Energy-Based Models (EBM) and Diffusion. Across 15 model-based RL tasks and 13 imitation learning tasks with high-dimensional image and point cloud inputs, DiffTOP outperforms prior state-of-the-art methods in both domains.</li>
</ul>

<h3>Title: Neural Circuit Diagrams: Robust Diagrams for the Communication,  Implementation, and Analysis of Deep Learning Architectures</h3>
<ul>
<li><strong>Authors: </strong>Vincent Abbott</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05424">https://arxiv.org/abs/2402.05424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05424">https://arxiv.org/pdf/2402.05424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05424]] Neural Circuit Diagrams: Robust Diagrams for the Communication,  Implementation, and Analysis of Deep Learning Architectures(https://arxiv.org/abs/2402.05424)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Diagrams matter. Unfortunately, the deep learning community has no standard method for diagramming architectures. The current combination of linear algebra notation and ad-hoc diagrams fails to offer the necessary precision to understand architectures in all their detail. However, this detail is critical for faithful implementation, mathematical analysis, further innovation, and ethical assurances. I present neural circuit diagrams, a graphical language tailored to the needs of communicating deep learning architectures. Neural circuit diagrams naturally keep track of the changing arrangement of data, precisely show how operations are broadcast over axes, and display the critical parallel behavior of linear operations. A lingering issue with existing diagramming methods is the inability to simultaneously express the detail of axes and the free arrangement of data, which neural circuit diagrams solve. Their compositional structure is analogous to code, creating a close correspondence between diagrams and implementation. In this work, I introduce neural circuit diagrams for an audience of machine learning researchers. After introducing neural circuit diagrams, I cover a host of architectures to show their utility and breed familiarity. This includes the transformer architecture, convolution (and its difficult-to-explain extensions), residual networks, the U-Net, and the vision transformer. I include a Jupyter notebook that provides evidence for the close correspondence between diagrams and code. Finally, I examine backpropagation using neural circuit diagrams. I show their utility in providing mathematical insight and analyzing algorithms' time and space complexities.</li>
</ul>

<h3>Title: GPT-4 Generated Narratives of Life Events using a Structured Narrative  Prompt: A Validation Study</h3>
<ul>
<li><strong>Authors: </strong>Christopher J. Lynch, Erik Jensen, Madison H. Munro, Virginia Zamponi, Joseph Martinez, Kevin O'Brien, Brandon Feldhaus, Katherine Smith, Ann Marie Reinhold, Ross Gore</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05435">https://arxiv.org/abs/2402.05435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05435">https://arxiv.org/pdf/2402.05435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05435]] GPT-4 Generated Narratives of Life Events using a Structured Narrative  Prompt: A Validation Study(https://arxiv.org/abs/2402.05435)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) play a pivotal role in generating vast arrays of narratives, facilitating a systematic exploration of their effectiveness for communicating life events in narrative form. In this study, we employ a zero-shot structured narrative prompt to generate 24,000 narratives using OpenAI's GPT-4. From this dataset, we manually classify 2,880 narratives and evaluate their validity in conveying birth, death, hiring, and firing events. Remarkably, 87.43% of the narratives sufficiently convey the intention of the structured prompt. To automate the identification of valid and invalid narratives, we train and validate nine Machine Learning models on the classified datasets. Leveraging these models, we extend our analysis to predict the classifications of the remaining 21,120 narratives. All the ML models excelled at classifying valid narratives as valid, but experienced challenges at simultaneously classifying invalid narratives as invalid. Our findings not only advance the study of LLM capabilities, limitations, and validity but also offer practical insights for narrative generation and natural language processing applications.</li>
</ul>

<h3>Title: Scalable Wasserstein Gradient Flow for Generative Modeling through  Unbalanced Optimal Transport</h3>
<ul>
<li><strong>Authors: </strong>Jaemoo Choi, Jaewoong Choi, Myungjoo Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05443">https://arxiv.org/abs/2402.05443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05443">https://arxiv.org/pdf/2402.05443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05443]] Scalable Wasserstein Gradient Flow for Generative Modeling through  Unbalanced Optimal Transport(https://arxiv.org/abs/2402.05443)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Wasserstein Gradient Flow (WGF) describes the gradient dynamics of probability density within the Wasserstein space. WGF provides a promising approach for conducting optimization over the probability distributions. Numerically approximating the continuous WGF requires the time discretization method. The most well-known method for this is the JKO scheme. In this regard, previous WGF models employ the JKO scheme and parametrize transport map for each JKO step. However, this approach results in quadratic training complexity $O(K^2)$ with the number of JKO step $K$. This severely limits the scalability of WGF models. In this paper, we introduce a scalable WGF-based generative model, called Semi-dual JKO (S-JKO). Our model is based on the semi-dual form of the JKO step, derived from the equivalence between the JKO step and the Unbalanced Optimal Transport. Our approach reduces the training complexity to $O(K)$. We demonstrate that our model significantly outperforms existing WGF-based generative models, achieving FID scores of 2.62 on CIFAR-10 and 6.19 on CelebA-HQ-256, which are comparable to state-of-the-art image generative models.</li>
</ul>

<h3>Title: Mitigating Privacy Risk in Membership Inference by Convex-Concave Loss</h3>
<ul>
<li><strong>Authors: </strong>Zhenlong Liu, Lei Feng, Huiping Zhuang, Xiaofeng Cao, Hongxin Wei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05453">https://arxiv.org/abs/2402.05453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05453">https://arxiv.org/pdf/2402.05453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05453]] Mitigating Privacy Risk in Membership Inference by Convex-Concave Loss(https://arxiv.org/abs/2402.05453)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Machine learning models are susceptible to membership inference attacks (MIAs), which aim to infer whether a sample is in the training set. Existing work utilizes gradient ascent to enlarge the loss variance of training data, alleviating the privacy risk. However, optimizing toward a reverse direction may cause the model parameters to oscillate near local minima, leading to instability and suboptimal performance. In this work, we propose a novel method -- Convex-Concave Loss, which enables a high variance of training loss distribution by gradient descent. Our method is motivated by the theoretical analysis that convex losses tend to decrease the loss variance during training. Thus, our key idea behind CCL is to reduce the convexity of loss functions with a concave term. Trained with CCL, neural networks produce losses with high variance for training data, reinforcing the defense against MIAs. Extensive experiments demonstrate the superiority of CCL, achieving state-of-the-art balance in the privacy-utility trade-off.</li>
</ul>

<h3>Title: Large Language Models for Psycholinguistic Plausibility Pretesting</h3>
<ul>
<li><strong>Authors: </strong>Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05455">https://arxiv.org/abs/2402.05455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05455">https://arxiv.org/pdf/2402.05455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05455]] Large Language Models for Psycholinguistic Plausibility Pretesting(https://arxiv.org/abs/2402.05455)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In psycholinguistics, the creation of controlled materials is crucial to ensure that research outcomes are solely attributed to the intended manipulations and not influenced by extraneous factors. To achieve this, psycholinguists typically pretest linguistic materials, where a common pretest is to solicit plausibility judgments from human evaluators on specific sentences. In this work, we investigate whether Language Models (LMs) can be used to generate these plausibility judgements. We investigate a wide range of LMs across multiple linguistic structures and evaluate whether their plausibility judgements correlate with human judgements. We find that GPT-4 plausibility judgements highly correlate with human judgements across the structures we examine, whereas other LMs correlate well with humans on commonly used syntactic structures. We then test whether this correlation implies that LMs can be used instead of humans for pretesting. We find that when coarse-grained plausibility judgements are needed, this works well, but when fine-grained judgements are necessary, even GPT-4 does not provide satisfactory discriminative power.</li>
</ul>

<h3>Title: It's Never Too Late: Fusing Acoustic Information into Large Language  Models for Automatic Speech Recognition</h3>
<ul>
<li><strong>Authors: </strong>Chen Chen, Ruizhe Li, Yuchen Hu, Sabato Marco Siniscalchi, Pin-Yu Chen, Ensiong Chng, Chao-Han Huck Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MM, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05457">https://arxiv.org/abs/2402.05457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05457">https://arxiv.org/pdf/2402.05457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05457]] It's Never Too Late: Fusing Acoustic Information into Large Language  Models for Automatic Speech Recognition(https://arxiv.org/abs/2402.05457)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have successfully shown that large language models (LLMs) can be successfully used for generative error correction (GER) on top of the automatic speech recognition (ASR) output. Specifically, an LLM is utilized to carry out a direct mapping from the N-best hypotheses list generated by an ASR system to the predicted output transcription. However, despite its effectiveness, GER introduces extra data uncertainty since the LLM is trained without taking into account acoustic information available in the speech signal. In this work, we aim to overcome such a limitation by infusing acoustic information before generating the predicted transcription through a novel late fusion solution termed Uncertainty-Aware Dynamic Fusion (UADF). UADF is a multimodal fusion approach implemented into an auto-regressive decoding process and works in two stages: (i) It first analyzes and calibrates the token-level LLM decision, and (ii) it then dynamically assimilates the information from the acoustic modality. Experimental evidence collected from various ASR tasks shows that UADF surpasses existing fusion mechanisms in several ways. It yields significant improvements in word error rate (WER) while mitigating data uncertainty issues in LLM and addressing the poor generalization relied with sole modality during fusion. We also demonstrate that UADF seamlessly adapts to audio-visual speech recognition.</li>
</ul>

<h3>Title: Implicit Diffusion: Efficient Optimization through Stochastic Sampling</h3>
<ul>
<li><strong>Authors: </strong>Pierre Marion, Anna Korba, Peter Bartlett, Mathieu Blondel, Valentin De Bortoli, Arnaud Doucet, Felipe Llinares-López, Courtney Paquette, Quentin Berthet</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05468">https://arxiv.org/abs/2402.05468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05468">https://arxiv.org/pdf/2402.05468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05468]] Implicit Diffusion: Efficient Optimization through Stochastic Sampling(https://arxiv.org/abs/2402.05468)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present a new algorithm to optimize distributions defined implicitly by parameterized stochastic diffusions. Doing so allows us to modify the outcome distribution of sampling processes by optimizing over their parameters. We introduce a general framework for first-order optimization of these processes, that performs jointly, in a single loop, optimization and sampling steps. This approach is inspired by recent advances in bilevel optimization and automatic implicit differentiation, leveraging the point of view of sampling as optimization over the space of probability distributions. We provide theoretical guarantees on the performance of our method, as well as experimental results demonstrating its effectiveness in real-world settings.</li>
</ul>

<h3>Title: Question Aware Vision Transformer for Multimodal Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Roy Ganz, Yair Kittenplon, Aviad Aberdam, Elad Ben Avraham, Oren Nuriel, Shai Mazor, Ron Litman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05472">https://arxiv.org/abs/2402.05472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05472">https://arxiv.org/pdf/2402.05472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05472]] Question Aware Vision Transformer for Multimodal Reasoning(https://arxiv.org/abs/2402.05472)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Vision-Language (VL) models have gained significant research focus, enabling remarkable advances in multimodal reasoning. These architectures typically comprise a vision encoder, a Large Language Model (LLM), and a projection module that aligns visual features with the LLM's representation space. Despite their success, a critical limitation persists: the vision encoding process remains decoupled from user queries, often in the form of image-related questions. Consequently, the resulting visual features may not be optimally attuned to the query-specific elements of the image. To address this, we introduce QA-ViT, a Question Aware Vision Transformer approach for multimodal reasoning, which embeds question awareness directly within the vision encoder. This integration results in dynamic visual features focusing on relevant image aspects to the posed question. QA-ViT is model-agnostic and can be incorporated efficiently into any VL architecture. Extensive experiments demonstrate the effectiveness of applying our method to various multimodal architectures, leading to consistent improvement across diverse tasks and showcasing its potential for enhancing visual and scene-text understanding.</li>
</ul>

<h3>Title: Determining the severity of Parkinson's disease in patients using a  multi task neural network</h3>
<ul>
<li><strong>Authors: </strong>María Teresa García-Ordás, José Alberto Benítez-Andrades, Jose Aveleira-Mata, José-Manuel Alija-Pérez, Carmen Benavides</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05491">https://arxiv.org/abs/2402.05491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05491">https://arxiv.org/pdf/2402.05491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05491]] Determining the severity of Parkinson's disease in patients using a  multi task neural network(https://arxiv.org/abs/2402.05491)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Parkinson's disease is easy to diagnose when it is advanced, but it is very difficult to diagnose in its early stages. Early diagnosis is essential to be able to treat the symptoms. It impacts on daily activities and reduces the quality of life of both the patients and their families and it is also the second most prevalent neurodegenerative disorder after Alzheimer in people over the age of 60. Most current studies on the prediction of Parkinson's severity are carried out in advanced stages of the disease. In this work, the study analyzes a set of variables that can be easily extracted from voice analysis, making it a very non-intrusive technique. In this paper, a method based on different deep learning techniques is proposed with two purposes. On the one hand, to find out if a person has severe or non-severe Parkinson's disease, and on the other hand, to determine by means of regression techniques the degree of evolution of the disease in a given patient. The UPDRS (Unified Parkinson's Disease Rating Scale) has been used by taking into account both the motor and total labels, and the best results have been obtained using a mixed multi-layer perceptron (MLP) that classifies and regresses at the same time and the most important features of the data obtained are taken as input, using an autoencoder. A success rate of 99.15% has been achieved in the problem of predicting whether a person suffers from severe Parkinson's disease or non-severe Parkinson's disease. In the degree of disease involvement prediction problem case, a MSE (Mean Squared Error) of 0.15 has been obtained. Using a full deep learning pipeline for data preprocessing and classification has proven to be very promising in the field Parkinson's outperforming the state-of-the-art proposals.</li>
</ul>

<h3>Title: A Solution for Commercializing, Decentralizing and Storing Electronic  Medical Records by Integrating Proxy Re-Encryption, IPFS, and Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Phong Tran, Thong Nguyen, Long Chu, Nhi Tran, Hang Ta</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05498">https://arxiv.org/abs/2402.05498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05498">https://arxiv.org/pdf/2402.05498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05498]] A Solution for Commercializing, Decentralizing and Storing Electronic  Medical Records by Integrating Proxy Re-Encryption, IPFS, and Blockchain(https://arxiv.org/abs/2402.05498)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The rapid expansion of user medical records across global systems presents not only opportunities but also new challenges in maintaining effective application models that ensure user privacy, controllability, and the ability to commercialize patient medical records. Moreover, the proliferation of data analysis models in healthcare institutions necessitates the decentralization and restorability of medical record data. It is imperative that user medical data collected from these systems can be easily analyzed and utilized even years after collection, without the risk of data loss due to numerous factors. Additionally, medical information must be authorized by the data owner, granting patients the right to accept or decline data usage requests from medical research agencies. In response, we propose an innovative solution for implementing a decentralized system utilizing an EVM-compatible blockchain and IPFS for decentralized storage. To ensure privacy and control, we employ Proxy Re-Encryption (PRE), a cryptographic authorized method, within the medical data marketplace. Our proposed architecture significantly reduces costs associated with granting read access to healthcare research agencies by minimizing the encryption and decryption time of stored records. Furthermore, it empowers users with enhanced control over their health data through tamperproof blockchain smart contracts and IPFS, safeguarding the integrity and privacy of their medical records.</li>
</ul>

<h3>Title: GPTs Are Multilingual Annotators for Sequence Generation Tasks</h3>
<ul>
<li><strong>Authors: </strong>Juhwan Choi, Eunju Lee, Kyohoon Jin, YoungBin Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05512">https://arxiv.org/abs/2402.05512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05512">https://arxiv.org/pdf/2402.05512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05512]] GPTs Are Multilingual Annotators for Sequence Generation Tasks(https://arxiv.org/abs/2402.05512)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Data annotation is an essential step for constructing new datasets. However, the conventional approach of data annotation through crowdsourcing is both time-consuming and expensive. In addition, the complexity of this process increases when dealing with low-resource languages owing to the difference in the language pool of crowdworkers. To address these issues, this study proposes an autonomous annotation method by utilizing large language models, which have been recently demonstrated to exhibit remarkable performance. Through our experiments, we demonstrate that the proposed method is not just cost-efficient but also applicable for low-resource language annotation. Additionally, we constructed an image captioning dataset using our approach and are committed to open this dataset for future study. We have opened our source code for further study and reproducibility.</li>
</ul>

<h3>Title: NoisyICL: A Little Noise in Model Parameters Calibrates In-context  Learning</h3>
<ul>
<li><strong>Authors: </strong>Yufeng Zhao, Yoshihiro Sakai, Naoya Inoue</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05515">https://arxiv.org/abs/2402.05515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05515">https://arxiv.org/pdf/2402.05515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05515]] NoisyICL: A Little Noise in Model Parameters Calibrates In-context  Learning(https://arxiv.org/abs/2402.05515)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>In-Context Learning (ICL) is suffering from unsatisfactory performance and under-calibration due to high prior bias and unfaithful confidence. Some previous works fine-tuned language models for better ICL performance with enormous datasets and computing costs. In this paper, we propose NoisyICL, simply perturbing the model parameters by random noises to strive for better performance and calibration. Our experiments on 2 models and 12 downstream datasets show that NoisyICL can help ICL produce more accurate predictions. Our further analysis indicates that NoisyICL enables the model to provide more fair predictions, and also with less unfaithful confidence. Therefore, we believe that NoisyICL is an effective calibration of ICL. Our experimental code is uploaded to Github.</li>
</ul>

<h3>Title: Linearizing Models for Efficient yet Robust Private Inference</h3>
<ul>
<li><strong>Authors: </strong>Sreetama Sarkar, Souvik Kundu, Peter A. Beerel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05521">https://arxiv.org/abs/2402.05521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05521">https://arxiv.org/pdf/2402.05521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05521]] Linearizing Models for Efficient yet Robust Private Inference(https://arxiv.org/abs/2402.05521)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>The growing concern about data privacy has led to the development of private inference (PI) frameworks in client-server applications which protects both data privacy and model IP. However, the cryptographic primitives required yield significant latency overhead which limits its wide-spread application. At the same time, changing environments demand the PI service to be robust against various naturally occurring and gradient-based perturbations. Despite several works focused on the development of latency-efficient models suitable for PI, the impact of these models on robustness has remained unexplored. Towards this goal, this paper presents RLNet, a class of robust linearized networks that can yield latency improvement via reduction of high-latency ReLU operations while improving the model performance on both clean and corrupted images. In particular, RLNet models provide a "triple win ticket" of improved classification accuracy on clean, naturally perturbed, and gradient-based perturbed images using a shared-mask shared-weight architecture with over an order of magnitude fewer ReLUs than baseline models. To demonstrate the efficacy of RLNet, we perform extensive experiments with ResNet and WRN model variants on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets. Our experimental evaluations show that RLNet can yield models with up to 11.14x fewer ReLUs, with accuracy close to the all-ReLU models, on clean, naturally perturbed, and gradient-based perturbed images. Compared with the SoTA non-robust linearized models at similar ReLU budgets, RLNet achieves an improvement in adversarial accuracy of up to ~47%, naturally perturbed accuracy up to ~16.4%, while improving clean image accuracy up to ~1.5%.</li>
</ul>

<h3>Title: Differentially Private Model-Based Offline Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Rio, Merwan Barlier, Igor Colin, Albert Thomas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05525">https://arxiv.org/abs/2402.05525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05525">https://arxiv.org/pdf/2402.05525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05525]] Differentially Private Model-Based Offline Reinforcement Learning(https://arxiv.org/abs/2402.05525)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We address offline reinforcement learning with privacy guarantees, where the goal is to train a policy that is differentially private with respect to individual trajectories in the dataset. To achieve this, we introduce DP-MORL, an MBRL algorithm coming with differential privacy guarantees. A private model of the environment is first learned from offline data using DP-FedAvg, a training method for neural networks that provides differential privacy guarantees at the trajectory level. Then, we use model-based policy optimization to derive a policy from the (penalized) private model, without any further interaction with the system or access to the input data. We empirically show that DP-MORL enables the training of private RL agents from offline data and we furthermore outline the price of privacy in this setting.</li>
</ul>

<h3>Title: Buffer Overflow in Mixture of Experts</h3>
<ul>
<li><strong>Authors: </strong>Jamie Hayes, Ilia Shumailov, Itay Yona</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05526">https://arxiv.org/abs/2402.05526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05526">https://arxiv.org/pdf/2402.05526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05526]] Buffer Overflow in Mixture of Experts(https://arxiv.org/abs/2402.05526)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Mixture of Experts (MoE) has become a key ingredient for scaling large foundation models while keeping inference costs steady. We show that expert routing strategies that have cross-batch dependencies are vulnerable to attacks. Malicious queries can be sent to a model and can affect a model's output on other benign queries if they are grouped in the same batch. We demonstrate this via a proof-of-concept attack in a toy experimental setting.</li>
</ul>

<h3>Title: Asynchronous Diffusion Learning with Agent Subsampling and Local Updates</h3>
<ul>
<li><strong>Authors: </strong>Elsa Rizk, Kun Yuan, Ali H. Sayed</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05529">https://arxiv.org/abs/2402.05529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05529">https://arxiv.org/pdf/2402.05529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05529]] Asynchronous Diffusion Learning with Agent Subsampling and Local Updates(https://arxiv.org/abs/2402.05529)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, diffusion</a></li>
<li><strong>Abstract: </strong>In this work, we examine a network of agents operating asynchronously, aiming to discover an ideal global model that suits individual local datasets. Our assumption is that each agent independently chooses when to participate throughout the algorithm and the specific subset of its neighbourhood with which it will cooperate at any given moment. When an agent chooses to take part, it undergoes multiple local updates before conveying its outcomes to the sub-sampled neighbourhood. Under this setup, we prove that the resulting asynchronous diffusion strategy is stable in the mean-square error sense and provide performance guarantees specifically for the federated learning setting. We illustrate the findings with numerical simulations.</li>
</ul>

<h3>Title: Reinforcement Learning as a Catalyst for Robust and Fair Federated  Learning: Deciphering the Dynamics of Client Contributions</h3>
<ul>
<li><strong>Authors: </strong>Jialuo He, Wei Chen, Xiaojin Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05541">https://arxiv.org/abs/2402.05541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05541">https://arxiv.org/pdf/2402.05541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05541]] Reinforcement Learning as a Catalyst for Robust and Fair Federated  Learning: Deciphering the Dynamics of Client Contributions(https://arxiv.org/abs/2402.05541)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, federate, fair</a></li>
<li><strong>Abstract: </strong>Recent advancements in federated learning (FL) have produced models that retain user privacy by training across multiple decentralized devices or systems holding local data samples. However, these strategies often neglect the inherent challenges of statistical heterogeneity and vulnerability to adversarial attacks, which can degrade model robustness and fairness. Personalized FL strategies offer some respite by adjusting models to fit individual client profiles, yet they tend to neglect server-side aggregation vulnerabilities. To address these issues, we propose Reinforcement Federated Learning (RFL), a novel framework that leverages deep reinforcement learning to adaptively optimize client contribution during aggregation, thereby enhancing both model robustness against malicious clients and fairness across participants under non-identically distributed settings. To achieve this goal, we propose a meticulous approach involving a Deep Deterministic Policy Gradient-based algorithm for continuous control of aggregation weights, an innovative client selection method based on model parameter distances, and a reward mechanism guided by validation set performance. Empirically, extensive experiments demonstrate that, in terms of robustness, RFL outperforms the state-of-the-art methods, while maintaining comparable levels of fairness, offering a promising solution to build resilient and fair federated systems.</li>
</ul>

<h3>Title: Named Entity Recognition for Address Extraction in Speech-to-Text  Transcriptions Using Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Bibiána Lajčinová, Patrik Valábek, Michal Spišiak</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05545">https://arxiv.org/abs/2402.05545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05545">https://arxiv.org/pdf/2402.05545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05545]] Named Entity Recognition for Address Extraction in Speech-to-Text  Transcriptions Using Synthetic Data(https://arxiv.org/abs/2402.05545)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces an approach for building a Named Entity Recognition (NER) model built upon a Bidirectional Encoder Representations from Transformers (BERT) architecture, specifically utilizing the SlovakBERT model. This NER model extracts address parts from data acquired from speech-to-text transcriptions. Due to scarcity of real data, a synthetic dataset using GPT API was generated. The importance of mimicking spoken language variability in this artificial data is emphasized. The performance of our NER model, trained solely on synthetic data, is evaluated using small real test dataset.</li>
</ul>

<h3>Title: Offline Actor-Critic Reinforcement Learning Scales to Large Models</h3>
<ul>
<li><strong>Authors: </strong>Jost Tobias Springenberg, Abbas Abdolmaleki, Jingwei Zhang, Oliver Groth, Michael Bloesch, Thomas Lampe, Philemon Brakel, Sarah Bechtle, Steven Kapturowski, Roland Hafner, Nicolas Heess, Martin Riedmiller</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05546">https://arxiv.org/abs/2402.05546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05546">https://arxiv.org/pdf/2402.05546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05546]] Offline Actor-Critic Reinforcement Learning Scales to Large Models(https://arxiv.org/abs/2402.05546)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We show that offline actor-critic reinforcement learning can scale to large models - such as transformers - and follows similar scaling laws as supervised learning. We find that offline actor-critic algorithms can outperform strong, supervised, behavioral cloning baselines for multi-task training on a large dataset containing both sub-optimal and expert behavior on 132 continuous control tasks. We introduce a Perceiver-based actor-critic model and elucidate the key model features needed to make offline RL work with self- and cross-attention modules. Overall, we find that: i) simple offline actor critic algorithms are a natural choice for gradually moving away from the currently predominant paradigm of behavioral cloning, and ii) via offline RL it is possible to learn multi-task policies that master many domains simultaneously, including real robotics tasks, from sub-optimal demonstrations or self-generated data.</li>
</ul>

<h3>Title: Benchmarking Large Language Models on Communicative Medical Coaching: a  Novel System and Dataset</h3>
<ul>
<li><strong>Authors: </strong>Hengguan Huang, Songtao Wang, Hongfu Liu, Hao Wang, Ye Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05547">https://arxiv.org/abs/2402.05547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05547">https://arxiv.org/pdf/2402.05547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05547]] Benchmarking Large Language Models on Communicative Medical Coaching: a  Novel System and Dataset(https://arxiv.org/abs/2402.05547)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services, enhancing patient interactions and care delivery, such as through medical dialogue systems. However, the potential of NLP to benefit inexperienced doctors, particularly in areas such as communicative medical coaching, remains largely unexplored. We introduce ``ChatCoach,'' an integrated human-AI cooperative framework. Within this framework, both a patient agent and a coaching agent collaboratively support medical learners in practicing their medical communication skills during consultations. Unlike traditional dialogue systems, ChatCoach provides a simulated environment where a human doctor can engage in medical dialogue with a patient agent. Simultaneously, a coaching agent provides real-time feedback to the doctor. To construct the ChatCoach system, we developed a dataset and integrated Large Language Models such as ChatGPT and Llama2, aiming to assess their effectiveness in communicative medical coaching tasks. Our comparative analysis demonstrates that instruction-tuned Llama2 significantly outperforms ChatGPT's prompting-based approaches.</li>
</ul>

<h3>Title: Efficient Expression Neutrality Estimation with Application to Face  Recognition Utility Prediction</h3>
<ul>
<li><strong>Authors: </strong>Marcel Grimmer, Raymond N. J. Veldhuis, Christoph Busch</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05548">https://arxiv.org/abs/2402.05548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05548">https://arxiv.org/pdf/2402.05548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05548]] Efficient Expression Neutrality Estimation with Application to Face  Recognition Utility Prediction(https://arxiv.org/abs/2402.05548)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric</a></li>
<li><strong>Abstract: </strong>The recognition performance of biometric systems strongly depends on the quality of the compared biometric samples. Motivated by the goal of establishing a common understanding of face image quality and enabling system interoperability, the committee draft of ISO/IEC 29794-5 introduces expression neutrality as one of many component quality elements affecting recognition performance. In this study, we train classifiers to assess facial expression neutrality using seven datasets. We conduct extensive performance benchmarking to evaluate their classification and face recognition utility prediction abilities. Our experiments reveal significant differences in how each classifier distinguishes "neutral" from "non-neutral" expressions. While Random Forests and AdaBoost classifiers are most suitable for distinguishing neutral from non-neutral facial expressions with high accuracy, they underperform compared to Support Vector Machines in predicting face recognition utility.</li>
</ul>

<h3>Title: On Convolutional Vision Transformers for Yield Prediction</h3>
<ul>
<li><strong>Authors: </strong>Alvin Inderka, Florian Huber, Volker Steinhage</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05557">https://arxiv.org/abs/2402.05557</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05557">https://arxiv.org/pdf/2402.05557</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05557]] On Convolutional Vision Transformers for Yield Prediction(https://arxiv.org/abs/2402.05557)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While a variety of methods offer good yield prediction on histogrammed remote sensing data, vision Transformers are only sparsely represented in the literature. The Convolution vision Transformer (CvT) is being tested to evaluate vision Transformers that are currently achieving state-of-the-art results in many other vision tasks. CvT combines some of the advantages of convolution with the advantages of dynamic attention and global context fusion of Transformers. It performs worse than widely tested methods such as XGBoost and CNNs, but shows that Transformers have potential to improve yield prediction.</li>
</ul>

<h3>Title: Flashback: Understanding and Mitigating Forgetting in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Aljahdali, Ahmed M. Abdelmoniem, Marco Canini, Samuel Horváth</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05558">https://arxiv.org/abs/2402.05558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05558">https://arxiv.org/pdf/2402.05558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05558]] Flashback: Understanding and Mitigating Forgetting in Federated Learning(https://arxiv.org/abs/2402.05558)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In Federated Learning (FL), forgetting, or the loss of knowledge across rounds, hampers algorithm convergence, particularly in the presence of severe data heterogeneity among clients. This study explores the nuances of this issue, emphasizing the critical role of forgetting in FL's inefficient learning within heterogeneous data contexts. Knowledge loss occurs in both client-local updates and server-side aggregation steps; addressing one without the other fails to mitigate forgetting. We introduce a metric to measure forgetting granularly, ensuring distinct recognition amid new knowledge acquisition. Leveraging these insights, we propose Flashback, an FL algorithm with a dynamic distillation approach that is used to regularize the local models, and effectively aggregate their knowledge. Across different benchmarks, Flashback outperforms other methods, mitigates forgetting, and achieves faster round-to-target-accuracy, by converging in 6 to 16 rounds.</li>
</ul>

<h3>Title: Traditional Machine Learning Models and Bidirectional Encoder  Representations From Transformer (BERT)-Based Automatic Classification of  Tweets About Eating Disorders: Algorithm Development and Validation Study</h3>
<ul>
<li><strong>Authors: </strong>José Alberto Benítez-Andrades, José-Manuel Alija-Pérez, Maria-Esther Vidal, Rafael Pastor-Vargas, María Teresa García-Ordás</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05571">https://arxiv.org/abs/2402.05571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05571">https://arxiv.org/pdf/2402.05571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05571]] Traditional Machine Learning Models and Bidirectional Encoder  Representations From Transformer (BERT)-Based Automatic Classification of  Tweets About Eating Disorders: Algorithm Development and Validation Study(https://arxiv.org/abs/2402.05571)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Background: Eating disorders are increasingly prevalent, and social networks offer valuable information. Objective: Our goal was to identify efficient machine learning models for categorizing tweets related to eating disorders. Methods: Over three months, we collected tweets about eating disorders. A 2,000-tweet subset was labeled for: (1) being written by individuals with eating disorders, (2) promoting eating disorders, (3) informativeness, and (4) scientific content. Both traditional machine learning and deep learning models were employed for classification, assessing accuracy, F1 score, and computational time. Results: From 1,058,957 collected tweets, transformer-based bidirectional encoder representations achieved the highest F1 scores (71.1%-86.4%) across all four categories. Conclusions: Transformer-based models outperform traditional techniques in classifying eating disorder-related tweets, though they require more computational resources.</li>
</ul>

<h3>Title: Simultaneously Achieving Group Exposure Fairness and Within-Group  Meritocracy in Stochastic Bandits</h3>
<ul>
<li><strong>Authors: </strong>Subham Pokhriyal, Shweta Jain, Ganesh Ghalme, Swapnil Dhamal, Sujit Gujar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05575">https://arxiv.org/abs/2402.05575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05575">https://arxiv.org/pdf/2402.05575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05575]] Simultaneously Achieving Group Exposure Fairness and Within-Group  Meritocracy in Stochastic Bandits(https://arxiv.org/abs/2402.05575)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Existing approaches to fairness in stochastic multi-armed bandits (MAB) primarily focus on exposure guarantee to individual arms. When arms are naturally grouped by certain attribute(s), we propose Bi-Level Fairness, which considers two levels of fairness. At the first level, Bi-Level Fairness guarantees a certain minimum exposure to each group. To address the unbalanced allocation of pulls to individual arms within a group, we consider meritocratic fairness at the second level, which ensures that each arm is pulled according to its merit within the group. Our work shows that we can adapt a UCB-based algorithm to achieve a Bi-Level Fairness by providing (i) anytime Group Exposure Fairness guarantees and (ii) ensuring individual-level Meritocratic Fairness within each group. We first show that one can decompose regret bounds into two components: (a) regret due to anytime group exposure fairness and (b) regret due to meritocratic fairness within each group. Our proposed algorithm BF-UCB balances these two regrets optimally to achieve the upper bound of $O(\sqrt{T})$ on regret; $T$ being the stopping time. With the help of simulated experiments, we further show that BF-UCB achieves sub-linear regret; provides better group and individual exposure guarantees compared to existing algorithms; and does not result in a significant drop in reward with respect to UCB algorithm, which does not impose any fairness constraint.</li>
</ul>

<h3>Title: RESMatch: Referring Expression Segmentation in a Semi-Supervised Manner</h3>
<ul>
<li><strong>Authors: </strong>Ying Zang, Chenglong Fu, Runlong Cao, Didi Zhu, Min Zhang, Wenjun Hu, Lanyun Zhu, Tianrun Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05589">https://arxiv.org/abs/2402.05589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05589">https://arxiv.org/pdf/2402.05589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05589]] RESMatch: Referring Expression Segmentation in a Semi-Supervised Manner(https://arxiv.org/abs/2402.05589)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Referring expression segmentation (RES), a task that involves localizing specific instance-level objects based on free-form linguistic descriptions, has emerged as a crucial frontier in human-AI interaction. It demands an intricate understanding of both visual and textual contexts and often requires extensive training data. This paper introduces RESMatch, the first semi-supervised learning (SSL) approach for RES, aimed at reducing reliance on exhaustive data annotation. Extensive validation on multiple RES datasets demonstrates that RESMatch significantly outperforms baseline approaches, establishing a new state-of-the-art. Although existing SSL techniques are effective in image segmentation, we find that they fall short in RES. Facing the challenges including the comprehension of free-form linguistic descriptions and the variability in object attributes, RESMatch introduces a trifecta of adaptations: revised strong perturbation, text augmentation, and adjustments for pseudo-label quality and strong-weak supervision. This pioneering work lays the groundwork for future research in semi-supervised learning for referring expression segmentation.</li>
</ul>

<h3>Title: AttnLRP: Attention-Aware Layer-wise Relevance Propagation for  Transformers</h3>
<ul>
<li><strong>Authors: </strong>Reduan Achtibat, Sayed Mohammad Vakilzadeh Hatefi, Maximilian Dreyer, Aakriti Jain, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05602">https://arxiv.org/abs/2402.05602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05602">https://arxiv.org/pdf/2402.05602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05602]] AttnLRP: Attention-Aware Layer-wise Relevance Propagation for  Transformers(https://arxiv.org/abs/2402.05602)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models are prone to biased predictions and hallucinations, underlining the paramount importance of understanding their model-internal reasoning process. However, achieving faithful attributions for the entirety of a black-box transformer model and maintaining computational efficiency is an unsolved challenge. By extending the Layer-wise Relevance Propagation attribution method to handle attention layers, we address these challenges effectively. While partial solutions exist, our method is the first to faithfully and holistically attribute not only input but also latent representations of transformer models with the computational efficiency similar to a singular backward pass. Through extensive evaluations against existing methods on Llama 2, Flan-T5 and the Vision Transformer architecture, we demonstrate that our proposed approach surpasses alternative methods in terms of faithfulness and enables the understanding of latent representations, opening up the door for concept-based explanations. We provide an open-source implementation on GitHub https://github.com/rachtibat/LRP-for-Transformers.</li>
</ul>

<h3>Title: Scalable Diffusion Models with State Space Backbone</h3>
<ul>
<li><strong>Authors: </strong>Zhengcong Fei, Mingyuan Fan, Changqian Yu, Junshi Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05608">https://arxiv.org/abs/2402.05608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05608">https://arxiv.org/pdf/2402.05608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05608]] Scalable Diffusion Models with State Space Backbone(https://arxiv.org/abs/2402.05608)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>This paper presents a new exploration into a category of diffusion models built upon state space architecture. We endeavor to train diffusion models for image data, wherein the traditional U-Net backbone is supplanted by a state space backbone, functioning on raw patches or latent space. Given its notable efficacy in accommodating long-range dependencies, Diffusion State Space Models (DiS) are distinguished by treating all inputs including time, condition, and noisy image patches as tokens. Our assessment of DiS encompasses both unconditional and class-conditional image generation scenarios, revealing that DiS exhibits comparable, if not superior, performance to CNN-based or Transformer-based U-Net architectures of commensurate size. Furthermore, we analyze the scalability of DiS, gauged by the forward pass complexity quantified in Gflops. DiS models with higher Gflops, achieved through augmentation of depth/width or augmentation of input tokens, consistently demonstrate lower FID. In addition to demonstrating commendable scalability characteristics, DiS-H/2 models in latent space achieve performance levels akin to prior diffusion models on class-conditional ImageNet benchmarks at the resolution of 256$\times$256 and 512$\times$512, while significantly reducing the computational burden. The code and models are available at: https://github.com/feizc/DiS.</li>
</ul>

<h3>Title: Extending 6D Object Pose Estimators for Stereo Vision</h3>
<ul>
<li><strong>Authors: </strong>Thomas Pöllabauer, Jan Emrich, Volker Knauthe, Arjan Kuijper</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05610">https://arxiv.org/abs/2402.05610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05610">https://arxiv.org/pdf/2402.05610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05610]] Extending 6D Object Pose Estimators for Stereo Vision(https://arxiv.org/abs/2402.05610)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Estimating the 6D pose of objects accurately, quickly, and robustly remains a difficult task. However, recent methods for directly regressing poses from RGB images using dense features have achieved state-of-the-art results. Stereo vision, which provides an additional perspective on the object, can help reduce pose ambiguity and occlusion. Moreover, stereo can directly infer the distance of an object, while mono-vision requires internalized knowledge of the object's size. To extend the state-of-the-art in 6D object pose estimation to stereo, we created a BOP compatible stereo version of the YCB-V dataset. Our method outperforms state-of-the-art 6D pose estimation algorithms by utilizing stereo vision and can easily be adopted for other dense feature-based algorithms.</li>
</ul>

<h3>Title: Pretrained Generative Language Models as General Learning Frameworks for  Sequence-Based Tasks</h3>
<ul>
<li><strong>Authors: </strong>Ben Fauber</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05616">https://arxiv.org/abs/2402.05616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05616">https://arxiv.org/pdf/2402.05616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05616]] Pretrained Generative Language Models as General Learning Frameworks for  Sequence-Based Tasks(https://arxiv.org/abs/2402.05616)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We propose that small pretrained foundational generative language models with millions of parameters can be utilized as a general learning framework for sequence-based tasks. Our proposal overcomes the computational resource, skill set, and timeline challenges associated with training neural networks and language models from scratch. Further, our approach focuses on creating small and highly specialized models that can accurately execute a challenging task of which the base model is incapable of performing. We demonstrate that 125M, 350M, and 1.3B parameter pretrained foundational language models can be instruction fine-tuned with 10,000-to-1,000,000 instruction examples to achieve near state-of-the-art results on challenging cheminformatics tasks. We also demonstrate the role of successive language model fine-tuning epochs on improved outcomes, as well as the importance of both data formatting and pretrained foundational language model selection for instruction fine-tuning success.</li>
</ul>

<h3>Title: Deep Learning-based Computational Job Market Analysis: A Survey on Skill  Extraction and Classification from Job Postings</h3>
<ul>
<li><strong>Authors: </strong>Elena Senger, Mike Zhang, Rob van der Goot, Barbara Plank</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05617">https://arxiv.org/abs/2402.05617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05617">https://arxiv.org/pdf/2402.05617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05617]] Deep Learning-based Computational Job Market Analysis: A Survey on Skill  Extraction and Classification from Job Postings(https://arxiv.org/abs/2402.05617)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Recent years have brought significant advances to Natural Language Processing (NLP), which enabled fast progress in the field of computational job market analysis. Core tasks in this application domain are skill extraction and classification from job postings. Because of its quick growth and its interdisciplinary nature, there is no exhaustive assessment of this emerging field. This survey aims to fill this gap by providing a comprehensive overview of deep learning methodologies, datasets, and terminologies specific to NLP-driven skill extraction and classification. Our comprehensive cataloging of publicly available datasets addresses the lack of consolidated information on dataset creation and characteristics. Finally, the focus on terminology addresses the current lack of consistent definitions for important concepts, such as hard and soft skills, and terms relating to skill extraction and classification.</li>
</ul>

<h3>Title: Efficient Models for the Detection of Hate, Abuse and Profanity</h3>
<ul>
<li><strong>Authors: </strong>Christoph Tillmann, Aashka Trivedi, Bishwaranjan Bhattacharjee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05624">https://arxiv.org/abs/2402.05624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05624">https://arxiv.org/pdf/2402.05624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05624]] Efficient Models for the Detection of Hate, Abuse and Profanity(https://arxiv.org/abs/2402.05624)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are the cornerstone for many Natural Language Processing (NLP) tasks like sentiment analysis, document classification, named entity recognition, question answering, summarization, etc. LLMs are often trained on data which originates from the web. This data is prone to having content with Hate, Abuse and Profanity (HAP). For a detailed definition of HAP, please refer to the Appendix. Due to the LLMs being exposed to HAP content during training, the models learn it and may then generate hateful or profane content. For example, when the open-source RoBERTa model (specifically, the RoBERTA base model) from the HuggingFace (HF) Transformers library is prompted to replace the mask token in `I do not know that Persian people are that MASK` it returns the word `stupid` with the highest score. This is unacceptable in civil discourse.The detection of Hate, Abuse and Profanity in text is a vital component of creating civil and unbiased LLMs, which is needed not only for English, but for all languages. In this article, we briefly describe the creation of HAP detectors and various ways of using them to make models civil and acceptable in the output they generate.</li>
</ul>

<h3>Title: RepQuant: Towards Accurate Post-Training Quantization of Large  Transformer Models via Scale Reparameterization</h3>
<ul>
<li><strong>Authors: </strong>Zhikai Li, Xuewen Liu, Jing Zhang, Qingyi Gu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05628">https://arxiv.org/abs/2402.05628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05628">https://arxiv.org/pdf/2402.05628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05628]] RepQuant: Towards Accurate Post-Training Quantization of Large  Transformer Models via Scale Reparameterization(https://arxiv.org/abs/2402.05628)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Large transformer models have demonstrated remarkable success. Post-training quantization (PTQ), which requires only a small dataset for calibration and avoids end-to-end retraining, is a promising solution for compressing these large models. Regrettably, existing PTQ methods typically exhibit non-trivial performance loss. We find that the performance bottleneck stems from over-consideration of hardware compatibility in the quantization process, compelling them to reluctantly employ simple quantizers, albeit at the expense of accuracy. With the above insights, we propose RepQuant, a novel PTQ framework with quantization-inference decoupling paradigm to address the above issues. RepQuant employs complex quantizers in the quantization process and simplified quantizers in the inference process, and performs mathematically equivalent transformations between the two through quantization scale reparameterization, thus ensuring both accurate quantization and efficient inference. More specifically, we focus on two components with extreme distributions: LayerNorm activations and Softmax activations. Initially, we apply channel-wise quantization and log$\sqrt{2}$ quantization, respectively, which are tailored to their distributions. In particular, for the former, we introduce a learnable per-channel dual clipping scheme, which is designed to efficiently identify outliers in the unbalanced activations with fine granularity. Then, we reparameterize the scales to hardware-friendly layer-wise quantization and log2 quantization for inference. Moreover, quantized weight reconstruction is seamlessly integrated into the above procedure to further push the performance limits. Extensive experiments are performed on different large-scale transformer variants on multiple tasks, including vision, language, and multi-modal transformers, and RepQuant encouragingly demonstrates significant performance advantages.</li>
</ul>

<h3>Title: Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature  of Aggregated Factual Claims in Long-Form Generations</h3>
<ul>
<li><strong>Authors: </strong>Cheng-Han Chiang, Hung-yi Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05629">https://arxiv.org/abs/2402.05629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05629">https://arxiv.org/pdf/2402.05629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05629]] Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature  of Aggregated Factual Claims in Long-Form Generations(https://arxiv.org/abs/2402.05629)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-form generations from large language models (LLMs) contains a mix of factual and non-factual claims, making evaluating factuality difficult. To evaluate factual precision of long-form generations in a more fine-grained way, prior works propose to decompose long-form generations into multiple verifiable facts and verify those facts independently. The factuality of the generation is the proportion of verifiable facts among all the facts. Such methods assume that combining factual claims forms a factual paragraph. This paper shows that the assumption can be violated due to entity ambiguity. We show that LLMs can generate paragraphs that contain verifiable facts, but the facts are combined to form a non-factual paragraph due to entity ambiguity. We further reveal that existing factual precision metrics, including FActScore and citation recall, cannot properly evaluate the factuality of these non-factual paragraphs. To address this, we introduce an enhanced metric, D-FActScore, specifically designed for content with ambiguous entities. We evaluate the D-FActScores of people biographies generated with retrieval-augmented generation (RAG). We show that D-FActScore can better assess the factuality of paragraphs with entity ambiguity than FActScore. We also find that four widely used open-source LLMs tend to mix information of distinct entities to form non-factual paragraphs.</li>
</ul>

<h3>Title: Improving Token-Based World Models with Parallel Observation Prediction</h3>
<ul>
<li><strong>Authors: </strong>Lior Cohen, Kaixin Wang, Bingyi Kang, Shie Mannor</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05643">https://arxiv.org/abs/2402.05643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05643">https://arxiv.org/pdf/2402.05643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05643]] Improving Token-Based World Models with Parallel Observation Prediction(https://arxiv.org/abs/2402.05643)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Motivated by the success of Transformers when applied to sequences of discrete symbols, token-based world models (TBWMs) were recently proposed as sample-efficient methods. In TBWMs, the world model consumes agent experience as a language-like sequence of tokens, where each observation constitutes a sub-sequence. However, during imagination, the sequential token-by-token generation of next observations results in a severe bottleneck, leading to long training times, poor GPU utilization, and limited representations. To resolve this bottleneck, we devise a novel Parallel Observation Prediction (POP) mechanism. POP augments a Retentive Network (RetNet) with a novel forward mode tailored to our reinforcement learning setting. We incorporate POP in a novel TBWM agent named REM (Retentive Environment Model), showcasing a 15.4x faster imagination compared to prior TBWMs. REM attains superhuman performance on 12 out of 26 games of the Atari 100K benchmark, while training in less than 12 hours. Our code is available at \url{https://github.com/leor-c/REM}.</li>
</ul>

<h3>Title: Comprehensive Assessment of Jailbreak Attacks Against LLMs</h3>
<ul>
<li><strong>Authors: </strong>Junjie Chu, Yugeng Liu, Ziqing Yang, Xinyue Shen, Michael Backes, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05668">https://arxiv.org/abs/2402.05668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05668">https://arxiv.org/pdf/2402.05668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05668]] Comprehensive Assessment of Jailbreak Attacks Against LLMs(https://arxiv.org/abs/2402.05668)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Misuse of the Large Language Models (LLMs) has raised widespread concern. To address this issue, safeguards have been taken to ensure that LLMs align with social ethics. However, recent findings have revealed an unsettling vulnerability bypassing the safeguards of LLMs, known as jailbreak attacks. By applying techniques, such as employing role-playing scenarios, adversarial examples, or subtle subversion of safety objectives as a prompt, LLMs can produce an inappropriate or even harmful response. While researchers have studied several categories of jailbreak attacks, they have done so in isolation. To fill this gap, we present the first large-scale measurement of various jailbreak attack methods. We concentrate on 13 cutting-edge jailbreak methods from four categories, 160 questions from 16 violation categories, and six popular LLMs. Our extensive experimental results demonstrate that the optimized jailbreak prompts consistently achieve the highest attack success rates, as well as exhibit robustness across different LLMs. Some jailbreak prompt datasets, available from the Internet, can also achieve high attack success rates on many LLMs, such as ChatGLM3, GPT-3.5, and PaLM2. Despite the claims from many organizations regarding the coverage of violation categories in their policies, the attack success rates from these categories remain high, indicating the challenges of effectively aligning LLM policies and the ability to counter jailbreak attacks. We also discuss the trade-off between the attack performance and efficiency, as well as show that the transferability of the jailbreak prompts is still viable, becoming an option for black-box models. Overall, our research highlights the necessity of evaluating different jailbreak methods. We hope our study can provide insights for future research on jailbreak attacks and serve as a benchmark tool for evaluating them for practitioners.</li>
</ul>

<h3>Title: Is Adversarial Training with Compressed Datasets Effective?</h3>
<ul>
<li><strong>Authors: </strong>Tong Chen, Raghavendra Selvan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05675">https://arxiv.org/abs/2402.05675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05675">https://arxiv.org/pdf/2402.05675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05675]] Is Adversarial Training with Compressed Datasets Effective?(https://arxiv.org/abs/2402.05675)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Dataset Condensation (DC) refers to the recent class of dataset compression methods that generate a smaller, synthetic, dataset from a larger dataset. This synthetic dataset retains the essential information of the original dataset, enabling models trained on it to achieve performance levels comparable to those trained on the full dataset. Most current DC methods have mainly concerned with achieving high test performance with limited data budget, and have not directly addressed the question of adversarial robustness. In this work, we investigate the impact of adversarial robustness on models trained with compressed datasets. We show that the compressed datasets obtained from DC methods are not effective in transferring adversarial robustness to models. As a solution to improve dataset compression efficiency and adversarial robustness simultaneously, we propose a novel robustness-aware dataset compression method based on finding the Minimal Finite Covering (MFC) of the dataset. The proposed method is (1) obtained by one-time computation and is applicable for any model, (2) more effective than DC methods when applying adversarial training over MFC, (3) provably robust by minimizing the generalized adversarial loss. Additionally, empirical evaluation on three datasets shows that the proposed method is able to achieve better robustness and performance trade-off compared to DC methods such as distribution matching.</li>
</ul>

<h3>Title: Interpretable classifiers for tabular data via discretization and  feature selection</h3>
<ul>
<li><strong>Authors: </strong>Reijo Jaakkola, Tomi Janhunen, Antti Kuusisto, Masood Feyzbakhsh Rankooh, Miikka Vilander</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05680">https://arxiv.org/abs/2402.05680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05680">https://arxiv.org/pdf/2402.05680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05680]] Interpretable classifiers for tabular data via discretization and  feature selection(https://arxiv.org/abs/2402.05680)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We introduce a method for computing immediately human interpretable yet accurate classifiers from tabular data. The classifiers obtained are short DNF-formulas, computed via first discretizing the original data to Boolean form and then using feature selection coupled with a very fast algorithm for producing the best possible Boolean classifier for the setting. We demonstrate the approach via 14 experiments, obtaining results with accuracies mainly similar to ones obtained via random forests, XGBoost, and existing results for the same datasets in the literature. In several cases, our approach in fact outperforms the reference results in relation to accuracy, even though the main objective of our study is the immediate interpretability of our classifiers. We also prove a new result on the probability that the classifier we obtain from real-life data corresponds to the ideally best classifier with respect to the background distribution the data comes from.</li>
</ul>

<h3>Title: Self-Alignment of Large Language Models via Monopolylogue-based Social  Scene Simulation</h3>
<ul>
<li><strong>Authors: </strong>Xianghe Pang, Shuo Tang, Rui Ye, Yuxin Xiong, Bolun Zhang, Yanfeng Wang, Siheng Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05699">https://arxiv.org/abs/2402.05699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05699">https://arxiv.org/pdf/2402.05699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05699]] Self-Alignment of Large Language Models via Monopolylogue-based Social  Scene Simulation(https://arxiv.org/abs/2402.05699)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that our method outperforms over 10 baselines across 4 benchmarks. As evidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning with human values. Code is available at https://github.com/pangxianghe/MATRIX.</li>
</ul>

<h3>Title: Unified Speech-Text Pretraining for Spoken Dialog Modeling</h3>
<ul>
<li><strong>Authors: </strong>Heeseung Kim, Soonshin Seo, Kyeongseok Jeong, Ohsung Kwon, Jungwhan Kim, Jaehong Lee, Eunwoo Song, Myungwoo Oh, Sungroh Yoon, Kang Min Yoo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05706">https://arxiv.org/abs/2402.05706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05706">https://arxiv.org/pdf/2402.05706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05706]] Unified Speech-Text Pretraining for Spoken Dialog Modeling(https://arxiv.org/abs/2402.05706)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>While recent work shows promising results in expanding the capabilities of large language models (LLM) to directly understand and synthesize speech, an LLM-based strategy for modeling spoken dialogs remains elusive and calls for further investigation. This work proposes an extensive speech-text LLM framework, named the Unified Spoken Dialog Model (USDM), to generate coherent spoken responses with organic prosodic features relevant to the given input speech without relying on automatic speech recognition (ASR) or text-to-speech (TTS) solutions. Our approach employs a multi-step speech-text inference scheme that leverages chain-of-reasoning capabilities exhibited by the underlying LLM. We also propose a generalized speech-text pretraining scheme that helps with capturing cross-modal semantics. Automatic and human evaluations show that the proposed approach is effective in generating natural-sounding spoken responses, outperforming both prior and cascaded baselines. Detailed comparative studies reveal that, despite the cascaded approach being stronger in individual components, the joint speech-text modeling improves robustness against recognition errors and speech quality. Demo is available at https://unifiedsdm.github.io.</li>
</ul>

<h3>Title: DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion  Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Ma, Xiangyu Zhu, Guojun Qi, Chen Qian, Zhaoxiang Zhang, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05712">https://arxiv.org/abs/2402.05712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05712">https://arxiv.org/pdf/2402.05712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05712]] DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion  Transformer(https://arxiv.org/abs/2402.05712)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Speech-driven 3D facial animation is important for many multimedia applications. Recent work has shown promise in using either Diffusion models or Transformer architectures for this task. However, their mere aggregation does not lead to improved performance. We suspect this is due to a shortage of paired audio-4D data, which is crucial for the Transformer to effectively perform as a denoiser within the Diffusion framework. To tackle this issue, we present DiffSpeaker, a Transformer-based network equipped with novel biased conditional attention modules. These modules serve as substitutes for the traditional self/cross-attention in standard Transformers, incorporating thoughtfully designed biases that steer the attention mechanisms to concentrate on both the relevant task-specific and diffusion-related conditions. We also explore the trade-off between accurate lip synchronization and non-verbal facial expressions within the Diffusion paradigm. Experiments show our model not only achieves state-of-the-art performance on existing benchmarks, but also fast inference speed owing to its ability to generate facial motions in parallel.</li>
</ul>

<h3>Title: Hidden in Plain Sight: Undetectable Adversarial Bias Attacks on  Vulnerable Patient Populations</h3>
<ul>
<li><strong>Authors: </strong>Pranav Kulkarni, Andrew Chan, Nithya Navarathna, Skylar Chan, Paul H. Yi, Vishwa S. Parekh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05713">https://arxiv.org/abs/2402.05713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05713">https://arxiv.org/pdf/2402.05713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05713]] Hidden in Plain Sight: Undetectable Adversarial Bias Attacks on  Vulnerable Patient Populations(https://arxiv.org/abs/2402.05713)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The proliferation of artificial intelligence (AI) in radiology has shed light on the risk of deep learning (DL) models exacerbating clinical biases towards vulnerable patient populations. While prior literature has focused on quantifying biases exhibited by trained DL models, demographically targeted adversarial bias attacks on DL models and its implication in the clinical environment remains an underexplored field of research in medical imaging. In this work, we demonstrate that demographically targeted label poisoning attacks can introduce adversarial underdiagnosis bias in DL models and degrade performance on underrepresented groups without impacting overall model performance. Moreover, our results across multiple performance metrics and demographic groups like sex, age, and their intersectional subgroups indicate that a group's vulnerability to undetectable adversarial bias attacks is directly correlated with its representation in the model's training data.</li>
</ul>

<h3>Title: In-Context Learning Can Re-learn Forbidden Tasks</h3>
<ul>
<li><strong>Authors: </strong>Sophie Xhonneux, David Dobre, Jian Tang, Gauthier Gidel, Dhanya Sridhar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05723">https://arxiv.org/abs/2402.05723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05723">https://arxiv.org/pdf/2402.05723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05723]] In-Context Learning Can Re-learn Forbidden Tasks(https://arxiv.org/abs/2402.05723)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Despite significant investment into safety training, large language models (LLMs) deployed in the real world still suffer from numerous vulnerabilities. One perspective on LLM safety training is that it algorithmically forbids the model from answering toxic or harmful queries. To assess the effectiveness of safety training, in this work, we study forbidden tasks, i.e., tasks the model is designed to refuse to answer. Specifically, we investigate whether in-context learning (ICL) can be used to re-learn forbidden tasks despite the explicit fine-tuning of the model to refuse them. We first examine a toy example of refusing sentiment classification to demonstrate the problem. Then, we use ICL on a model fine-tuned to refuse to summarise made-up news articles. Finally, we investigate whether ICL can undo safety training, which could represent a major security risk. For the safety task, we look at Vicuna-7B, Starling-7B, and Llama2-7B. We show that the attack works out-of-the-box on Starling-7B and Vicuna-7B but fails on Llama2-7B. Finally, we propose an ICL attack that uses the chat template tokens like a prompt injection attack to achieve a better attack success rate on Vicuna-7B and Starling-7B. Trigger Warning: the appendix contains LLM-generated text with violence, suicide, and misinformation.</li>
</ul>

<h3>Title: CTGAN: Semantic-guided Conditional Texture Generator for 3D Shapes</h3>
<ul>
<li><strong>Authors: </strong>Yi-Ting Pan, Chai-Rong Lee, Shu-Ho Fan, Jheng-Wei Su, Jia-Bin Huang, Yung-Yu Chuang, Hung-Kuo Chu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05728">https://arxiv.org/abs/2402.05728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05728">https://arxiv.org/pdf/2402.05728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05728]] CTGAN: Semantic-guided Conditional Texture Generator for 3D Shapes(https://arxiv.org/abs/2402.05728)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>The entertainment industry relies on 3D visual content to create immersive experiences, but traditional methods for creating textured 3D models can be time-consuming and subjective. Generative networks such as StyleGAN have advanced image synthesis, but generating 3D objects with high-fidelity textures is still not well explored, and existing methods have limitations. We propose the Semantic-guided Conditional Texture Generator (CTGAN), producing high-quality textures for 3D shapes that are consistent with the viewing angle while respecting shape semantics. CTGAN utilizes the disentangled nature of StyleGAN to finely manipulate the input latent codes, enabling explicit control over both the style and structure of the generated textures. A coarse-to-fine encoder architecture is introduced to enhance control over the structure of the resulting textures via input segmentation. Experimental results show that CTGAN outperforms existing methods on multiple quality metrics and achieves state-of-the-art performance on texture generation in both conditional and unconditional settings.</li>
</ul>

<h3>Title: TimeArena: Shaping Efficient Multitasking Language Agents in a  Time-Aware Simulation</h3>
<ul>
<li><strong>Authors: </strong>Yikai Zhang, Siyu Yuan, Caiyu Hu, Kyle Richardson, Yanghua Xiao, Jiangjie Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05733">https://arxiv.org/abs/2402.05733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05733">https://arxiv.org/pdf/2402.05733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05733]] TimeArena: Shaping Efficient Multitasking Language Agents in a  Time-Aware Simulation(https://arxiv.org/abs/2402.05733)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite remarkable advancements in emulating human-like behavior through Large Language Models (LLMs), current textual simulations do not adequately address the notion of time. To this end, we introduce TimeArena, a novel textual simulated environment that incorporates complex temporal dynamics and constraints that better reflect real-life planning scenarios. In TimeArena, agents are asked to complete multiple tasks as soon as possible, allowing for parallel processing to save time. We implement the dependency between actions, the time duration for each action, and the occupancy of the agent and the objects in the environment. TimeArena grounds to 30 real-world tasks in cooking, household activities, and laboratory work. We conduct extensive experiments with various state-of-the-art LLMs using TimeArena. Our findings reveal that even the most powerful models, e.g., GPT-4, still lag behind humans in effective multitasking, underscoring the need for enhanced temporal awareness in the development of language agents.</li>
</ul>

<h3>Title: Blockchain Based Residential Smart Rent</h3>
<ul>
<li><strong>Authors: </strong>André S. Proença, Tiago R. Dias, Miguel P. Correia</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05737">https://arxiv.org/abs/2402.05737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05737">https://arxiv.org/pdf/2402.05737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05737]] Blockchain Based Residential Smart Rent(https://arxiv.org/abs/2402.05737)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The real estate market includes complex and inefficient mediation processes. Renting a property envolves multiple entities with different responsibilities and interests. Therefore it is imperative to establish a trustful relationship between parties through intermediaries such as notaries, banks or real estate agencies to avoid eventual disputes. Although an intermediary ensures trust, the current process still has some drawbacks concerning efficiency, costs, transparency, bureaucracy and data security. The blockchain technology aims to reduce this issues by providing transparent and secure real estate transactions. We propose a GDPR compliant blockchain-based residential smart rental platform, designed to allow both landlords and tenants to establish rental contracts and make rental payments securely.</li>
</ul>

<h3>Title: Implicit Bias and Fast Convergence Rates for Self-attention</h3>
<ul>
<li><strong>Authors: </strong>Bhavya Vasudeva, Puneesh Deora, Christos Thrampoulidis</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05738">https://arxiv.org/abs/2402.05738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05738">https://arxiv.org/pdf/2402.05738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05738]] Implicit Bias and Fast Convergence Rates for Self-attention(https://arxiv.org/abs/2402.05738)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Self-attention, the core mechanism of transformers, distinguishes them from traditional neural networks and drives their outstanding performance. Towards developing the fundamental optimization principles of self-attention, we investigate the implicit bias of gradient descent (GD) in training a self-attention layer with fixed linear decoder in binary classification. Drawing inspiration from the study of GD in linear logistic regression over separable data, recent work demonstrates that as the number of iterations $t$ approaches infinity, the key-query matrix $W_t$ converges locally (with respect to the initialization direction) to a hard-margin SVM solution $W_{mm}$. Our work enhances this result in four aspects. Firstly, we identify non-trivial data settings for which convergence is provably global, thus shedding light on the optimization landscape. Secondly, we provide the first finite-time convergence rate for $W_t$ to $W_{mm}$, along with quantifying the rate of sparsification in the attention map. Thirdly, through an analysis of normalized GD and Polyak step-size, we demonstrate analytically that adaptive step-size rules can accelerate the convergence of self-attention. Additionally, we remove the restriction of prior work on a fixed linear decoder. Our results reinforce the implicit-bias perspective of self-attention and strengthen its connections to implicit-bias in linear logistic regression, despite the intricate non-convex nature of the former.</li>
</ul>

<h3>Title: Editable Scene Simulation for Autonomous Driving via Collaborative  LLM-Agents</h3>
<ul>
<li><strong>Authors: </strong>Yuxi Wei, Zi Wang, Yifan Lu, Chenxin Xu, Changxing Liu, Hao Zhao, Siheng Chen, Yanfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05746">https://arxiv.org/abs/2402.05746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05746">https://arxiv.org/pdf/2402.05746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05746]] Editable Scene Simulation for Autonomous Driving via Collaborative  LLM-Agents(https://arxiv.org/abs/2402.05746)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scene simulation in autonomous driving has gained significant attention because of its huge potential for generating customized data. However, existing editable scene simulation approaches face limitations in terms of user interaction efficiency, multi-camera photo-realistic rendering and external digital assets integration. To address these challenges, this paper introduces ChatSim, the first system that enables editable photo-realistic 3D driving scene simulations via natural language commands with external digital assets. To enable editing with high command flexibility,~ChatSim leverages a large language model (LLM) agent collaboration framework. To generate photo-realistic outcomes, ChatSim employs a novel multi-camera neural radiance field method. Furthermore, to unleash the potential of extensive high-quality digital assets, ChatSim employs a novel multi-camera lighting estimation method to achieve scene-consistent assets' rendering. Our experiments on Waymo Open Dataset demonstrate that ChatSim can handle complex language commands and generate corresponding photo-realistic scene videos.</li>
</ul>

<h3>Title: Stable Autonomous Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Christopher Iliffe Sprague, Arne Elofsson, Hossein Azizpour</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05774">https://arxiv.org/abs/2402.05774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05774">https://arxiv.org/pdf/2402.05774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05774]] Stable Autonomous Flow Matching(https://arxiv.org/abs/2402.05774)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In contexts where data samples represent a physically stable state, it is often assumed that the data points represent the local minima of an energy landscape. In control theory, it is well-known that energy can serve as an effective Lyapunov function. Despite this, connections between control theory and generative models in the literature are sparse, even though there are several machine learning applications with physically stable data points. In this paper, we focus on such data and a recent class of deep generative models called flow matching. We apply tools of stochastic stability for time-independent systems to flow matching models. In doing so, we characterize the space of flow matching models that are amenable to this treatment, as well as draw connections to other control theory principles. We demonstrate our theoretical results on two examples.</li>
</ul>

<h3>Title: Limits of Transformer Language Models on Algorithmic Learning</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Thomm, Aleksandar Terzic, Geethan Karunaratne, Giacomo Camposampiero, Bernhard Schölkopf, Abbas Rahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05785">https://arxiv.org/abs/2402.05785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05785">https://arxiv.org/pdf/2402.05785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05785]] Limits of Transformer Language Models on Algorithmic Learning(https://arxiv.org/abs/2402.05785)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We analyze the capabilities of Transformer language models on learning discrete algorithms. To this end, we introduce two new tasks demanding the composition of several discrete sub-tasks. On both training LLaMA models from scratch and prompting on GPT-4 and Gemini we measure learning compositions of learned primitives. We observe that the compositional capabilities of state-of-the-art Transformer language models are very limited and sample-wise scale worse than relearning all sub-tasks for a new algorithmic composition. We also present a theorem in complexity theory, showing that gradient descent on memorizing feedforward models can be exponentially data inefficient.</li>
</ul>

<h3>Title: AvatarMMC: 3D Head Avatar Generation and Editing with Multi-Modal  Conditioning</h3>
<ul>
<li><strong>Authors: </strong>Wamiq Reyaz Para, Abdelrahman Eldesokey, Zhenyu Li, Pradyumna Reddy, Jiankang Deng, Peter Wonka</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05803">https://arxiv.org/abs/2402.05803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05803">https://arxiv.org/pdf/2402.05803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05803]] AvatarMMC: 3D Head Avatar Generation and Editing with Multi-Modal  Conditioning(https://arxiv.org/abs/2402.05803)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>We introduce an approach for 3D head avatar generation and editing with multi-modal conditioning based on a 3D Generative Adversarial Network (GAN) and a Latent Diffusion Model (LDM). 3D GANs can generate high-quality head avatars given a single or no condition. However, it is challenging to generate samples that adhere to multiple conditions of different modalities. On the other hand, LDMs excel at learning complex conditional distributions. To this end, we propose to exploit the conditioning capabilities of LDMs to enable multi-modal control over the latent space of a pre-trained 3D GAN. Our method can generate and edit 3D head avatars given a mixture of control signals such as RGB input, segmentation masks, and global attributes. This provides better control over the generation and editing of synthetic avatars both globally and locally. Experiments show that our proposed approach outperforms a solely GAN-based approach both qualitatively and quantitatively on generation and editing tasks. To the best of our knowledge, our approach is the first to introduce multi-modal conditioning to 3D avatar generation and editing. \\href{avatarmmc-sig24.github.io}{Project Page}</li>
</ul>

<h3>Title: Selective Forgetting: Advancing Machine Unlearning Techniques and  Evaluation in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lingzhi Wang, Xingshan Zeng, Jinsong Guo, Kam-Fai Wong, Georg Gottlob</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05813">https://arxiv.org/abs/2402.05813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05813">https://arxiv.org/pdf/2402.05813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05813]] Selective Forgetting: Advancing Machine Unlearning Techniques and  Evaluation in Language Models(https://arxiv.org/abs/2402.05813)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>The aim of this study is to investigate Machine Unlearning (MU), a burgeoning field focused on addressing concerns related to neural models inadvertently retaining personal or sensitive data. Here, a novel approach is introduced to achieve precise and selective forgetting within language models. Unlike previous methodologies that adopt completely opposing training objectives, this approach aims to mitigate adverse effects on language model performance, particularly in generation tasks. Furthermore, two innovative evaluation metrics are proposed: Sensitive Information Extraction Likelihood (S-EL) and Sensitive Information Memory Accuracy (S-MA), designed to gauge the effectiveness of sensitive information elimination. To reinforce the forgetting framework, an effective method for annotating sensitive scopes is presented, involving both online and offline strategies. The online selection mechanism leverages language probability scores to ensure computational efficiency, while the offline annotation entails a robust two-stage process based on Large Language Models (LLMs).</li>
</ul>

<h3>Title: FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework  for Robust Solar Power Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ziqing Ma, Wenwei Wang, Tian Zhou, Chao Chen, Bingqing Peng, Liang Sun, Rong Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05823">https://arxiv.org/abs/2402.05823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05823">https://arxiv.org/pdf/2402.05823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05823]] FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework  for Robust Solar Power Forecasting(https://arxiv.org/abs/2402.05823)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust</a></li>
<li><strong>Abstract: </strong>Accurate solar power forecasting is crucial to integrate photovoltaic plants into the electric grid, schedule and secure the power grid safety. This problem becomes more demanding for those newly installed solar plants which lack sufficient data. Current research predominantly relies on historical solar power data or numerical weather prediction in a single-modality format, ignoring the complementary information provided in different modalities. In this paper, we propose a multi-modality fusion framework to integrate historical power data, numerical weather prediction, and satellite images, significantly improving forecast performance. We introduce a vector quantized framework that aligns modalities with varying information densities, striking a balance between integrating sufficient information and averting model overfitting. Our framework demonstrates strong zero-shot forecasting capability, which is especially useful for those newly installed plants. Moreover, we collect and release a multi-modal solar power (MMSP) dataset from real-world plants to further promote the research of multi-modal solar forecasting algorithms. Our extensive experiments show that our model not only operates with robustness but also boosts accuracy in both zero-shot forecasting and scenarios rich with training data, surpassing leading models. We have incorporated it into our eForecaster platform and deployed it for more than 300 solar plants with a capacity of over 15GW.</li>
</ul>

<h3>Title: Is it Possible to Edit Large Language Models Robustly?</h3>
<ul>
<li><strong>Authors: </strong>Xinbei Ma, Tianjie Ju, Jiyang Qiu, Zhuosheng Zhang, Hai Zhao, Lifeng Liu, Yulong Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05827">https://arxiv.org/abs/2402.05827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05827">https://arxiv.org/pdf/2402.05827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05827]] Is it Possible to Edit Large Language Models Robustly?(https://arxiv.org/abs/2402.05827)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have played a pivotal role in building communicative AI to imitate human behaviors but face the challenge of efficient customization. To tackle this challenge, recent studies have delved into the realm of model editing, which manipulates specific memories of language models and changes the related language generation. However, the robustness of model editing remains an open question. This work seeks to understand the strengths and limitations of editing methods, thus facilitating robust, realistic applications of communicative AI. Concretely, we conduct extensive analysis to address the three key research questions. Q1: Can edited LLMs behave consistently resembling communicative AI in realistic situations? Q2: To what extent does the rephrasing of prompts lead LLMs to deviate from the edited knowledge memory? Q3: Which knowledge features are correlated with the performance and robustness of editing? Our experimental results uncover a substantial disparity between existing editing methods and the practical application of LLMs. On rephrased prompts that are complex and flexible but common in realistic applications, the performance of editing experiences a significant decline. Further analysis shows that more popular knowledge is memorized better, easier to recall, and more challenging to edit effectively.</li>
</ul>

<h3>Title: Sparse-VQ Transformer: An FFN-Free Framework with Vector Quantization  for Enhanced Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Yanjun Zhao, Tian Zhou, Chao Chen, Liang Sun, Yi Qian, Rong Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05830">https://arxiv.org/abs/2402.05830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05830">https://arxiv.org/pdf/2402.05830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05830]] Sparse-VQ Transformer: An FFN-Free Framework with Vector Quantization  for Enhanced Time Series Forecasting(https://arxiv.org/abs/2402.05830)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Time series analysis is vital for numerous applications, and transformers have become increasingly prominent in this domain. Leading methods customize the transformer architecture from NLP and CV, utilizing a patching technique to convert continuous signals into segments. Yet, time series data are uniquely challenging due to significant distribution shifts and intrinsic noise levels. To address these two challenges,we introduce the Sparse Vector Quantized FFN-Free Transformer (Sparse-VQ). Our methodology capitalizes on a sparse vector quantization technique coupled with Reverse Instance Normalization (RevIN) to reduce noise impact and capture sufficient statistics for forecasting, serving as an alternative to the Feed-Forward layer (FFN) in the transformer architecture. Our FFN-free approach trims the parameter count, enhancing computational efficiency and reducing overfitting. Through evaluations across ten benchmark datasets, including the newly introduced CAISO dataset, Sparse-VQ surpasses leading models with a 7.84% and 4.17% decrease in MAE for univariate and multivariate time series forecasting, respectively. Moreover, it can be seamlessly integrated with existing transformer-based models to elevate their performance.</li>
</ul>

<h3>Title: Privacy-Preserving Synthetic Continual Semantic Segmentation for Robotic  Surgery</h3>
<ul>
<li><strong>Authors: </strong>Mengya Xu, Mobarakol Islam, Long Bai, Hongliang Ren</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05860">https://arxiv.org/abs/2402.05860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05860">https://arxiv.org/pdf/2402.05860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05860]] Privacy-Preserving Synthetic Continual Semantic Segmentation for Robotic  Surgery(https://arxiv.org/abs/2402.05860)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, segmentation</a></li>
<li><strong>Abstract: </strong>Deep Neural Networks (DNNs) based semantic segmentation of the robotic instruments and tissues can enhance the precision of surgical activities in robot-assisted surgery. However, in biological learning, DNNs cannot learn incremental tasks over time and exhibit catastrophic forgetting, which refers to the sharp decline in performance on previously learned tasks after learning a new one. Specifically, when data scarcity is the issue, the model shows a rapid drop in performance on previously learned instruments after learning new data with new instruments. The problem becomes worse when it limits releasing the dataset of the old instruments for the old model due to privacy concerns and the unavailability of the data for the new or updated version of the instruments for the continual learning model. For this purpose, we develop a privacy-preserving synthetic continual semantic segmentation framework by blending and harmonizing (i) open-source old instruments foreground to the synthesized background without revealing real patient data in public and (ii) new instruments foreground to extensively augmented real background. To boost the balanced logit distillation from the old model to the continual learning model, we design overlapping class-aware temperature normalization (CAT) by controlling model learning utility. We also introduce multi-scale shifted-feature distillation (SD) to maintain long and short-range spatial relationships among the semantic objects where conventional short-range spatial features with limited information reduce the power of feature distillation. We demonstrate the effectiveness of our framework on the EndoVis 2017 and 2018 instrument segmentation dataset with a generalized continual learning setting. Code is available at~\url{https://github.com/XuMengyaAmy/Synthetic_CAT_SD}.</li>
</ul>

<h3>Title: Memory Consolidation Enables Long-Context Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Ivana Balažević, Yuge Shi, Pinelopi Papalampidi, Rahma Chaabouni, Skanda Koppula, Olivier J. Hénaff</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05861">https://arxiv.org/abs/2402.05861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05861">https://arxiv.org/pdf/2402.05861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05861]] Memory Consolidation Enables Long-Context Video Understanding(https://arxiv.org/abs/2402.05861)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Most transformer-based video encoders are limited to short temporal contexts due to their quadratic complexity. While various attempts have been made to extend this context, this has often come at the cost of both conceptual and computational complexity. We propose to instead re-purpose existing pre-trained video transformers by simply fine-tuning them to attend to memories derived non-parametrically from past activations. By leveraging redundancy reduction, our memory-consolidated vision transformer (MC-ViT) effortlessly extends its context far into the past and exhibits excellent scaling behavior when learning from longer videos. In doing so, MC-ViT sets a new state-of-the-art in long-context video understanding on EgoSchema, Perception Test, and Diving48, outperforming methods that benefit from orders of magnitude more parameters.</li>
</ul>

<h3>Title: Let Your Graph Do the Talking: Encoding Structured Data for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Bryan Perozzi, Bahare Fatemi, Dustin Zelle, Anton Tsitsulin, Mehran Kazemi, Rami Al-Rfou, Jonathan Halcrow</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05862">https://arxiv.org/abs/2402.05862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05862">https://arxiv.org/pdf/2402.05862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05862]] Let Your Graph Do the Talking: Encoding Structured Data for LLMs(https://arxiv.org/abs/2402.05862)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>How can we best encode structured data into sequential form for use in large language models (LLMs)? In this work, we introduce a parameter-efficient method to explicitly represent structured data for LLMs. Our method, GraphToken, learns an encoding function to extend prompts with explicit structured information. Unlike other work which focuses on limited domains (e.g. knowledge graph representation), our work is the first effort focused on the general encoding of structured data to be used for various reasoning tasks. We show that explicitly representing the graph structure allows significant improvements to graph reasoning tasks. Specifically, we see across the board improvements - up to 73% points - on node, edge and, graph-level tasks from the GraphQA benchmark.</li>
</ul>

<h3>Title: Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xuandong Zhao, Lei Li, Yu-Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05864">https://arxiv.org/abs/2402.05864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05864">https://arxiv.org/pdf/2402.05864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05864]] Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs(https://arxiv.org/abs/2402.05864)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a new decoding method called Permute-and-Flip (PF) decoder. It enjoys robustness properties similar to the standard sampling decoder, but is provably up to 2x better in its quality-robustness tradeoff than sampling and never worse than any other decoder. We also design a cryptographic watermarking scheme analogous to Aaronson's Gumbel watermark, but naturally tailored for PF decoder. The watermarking scheme does not change the distribution to sample, while allowing arbitrarily low false positive rate and high recall whenever the generated text has high entropy. Our experiments show that the PF decoder (and its watermarked counterpart) significantly outperform(s) naive sampling (and it's Gumbel watermarked counterpart) in terms of perplexity, while retaining the same robustness (and detectability), hence making it a promising new approach for LLM decoding. The code is available at https://github.com/XuandongZhao/pf-decoding</li>
</ul>

<h3>Title: PromptCrypt: Prompt Encryption for Secure Communication with Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guo Lin, Wenyue Hua, Yongfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05868">https://arxiv.org/abs/2402.05868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05868">https://arxiv.org/pdf/2402.05868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05868]] PromptCrypt: Prompt Encryption for Secure Communication with Large  Language Models(https://arxiv.org/abs/2402.05868)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Cloud-based large language models (LLMs) such as ChatGPT have increasingly become integral to daily operations, serving as vital tools across various applications. While these models offer substantial benefits in terms of accessibility and functionality, they also introduce significant privacy concerns: the transmission and storage of user data in cloud infrastructures pose substantial risks of data breaches and unauthorized access to sensitive information; even if the transmission and storage of data is encrypted, the LLM service provider itself still knows the real contents of the data, preventing individuals or entities from confidently using such LLM services. To address these concerns, this paper proposes a simple yet effective mechanism PromptCrypt to protect user privacy. It uses Emoji to encrypt the user inputs before sending them to LLM, effectively rendering them indecipherable to human or LLM's examination while retaining the original intent of the prompt, thus ensuring the model's performance remains unaffected. We conduct experiments on three tasks, personalized recommendation, sentiment analysis, and tabular data analysis. Experiment results reveal that PromptCrypt can encrypt personal information within prompts in such a manner that not only prevents the discernment of sensitive data by humans or LLM itself, but also maintains or even improves the precision without further tuning, achieving comparable or even better task accuracy than directly prompting the LLM without prompt encryption. These results highlight the practicality of adopting encryption measures that safeguard user privacy without compromising the functional integrity and performance of LLMs. Code and dataset are available at https://github.com/agiresearch/PromptCrypt.</li>
</ul>

<h3>Title: Adaptive Surface Normal Constraint for Geometric Estimation from  Monocular Images</h3>
<ul>
<li><strong>Authors: </strong>Xiaoxiao Long, Yuhang Zheng, Yupeng Zheng, Beiwen Tian, Cheng Lin, Lingjie Liu, Hao Zhao, Guyue Zhou, Wenping Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05869">https://arxiv.org/abs/2402.05869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05869">https://arxiv.org/pdf/2402.05869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05869]] Adaptive Surface Normal Constraint for Geometric Estimation from  Monocular Images(https://arxiv.org/abs/2402.05869)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce a novel approach to learn geometries such as depth and surface normal from images while incorporating geometric context. The difficulty of reliably capturing geometric context in existing methods impedes their ability to accurately enforce the consistency between the different geometric properties, thereby leading to a bottleneck of geometric estimation quality. We therefore propose the Adaptive Surface Normal (ASN) constraint, a simple yet efficient method. Our approach extracts geometric context that encodes the geometric variations present in the input image and correlates depth estimation with geometric constraints. By dynamically determining reliable local geometry from randomly sampled candidates, we establish a surface normal constraint, where the validity of these candidates is evaluated using the geometric context. Furthermore, our normal estimation leverages the geometric context to prioritize regions that exhibit significant geometric variations, which makes the predicted normals accurately capture intricate and detailed geometric information. Through the integration of geometric context, our method unifies depth and surface normal estimations within a cohesive framework, which enables the generation of high-quality 3D geometry from images. We validate the superiority of our approach over state-of-the-art methods through extensive evaluations and comparisons on diverse indoor and outdoor datasets, showcasing its efficiency and robustness.</li>
</ul>

<h3>Title: Federated Offline Reinforcement Learning: Collaborative Single-Policy  Coverage Suffices</h3>
<ul>
<li><strong>Authors: </strong>Jiin Woo, Laixi Shi, Gauri Joshi, Yuejie Chi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05876">https://arxiv.org/abs/2402.05876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05876">https://arxiv.org/pdf/2402.05876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05876]] Federated Offline Reinforcement Learning: Collaborative Single-Policy  Coverage Suffices(https://arxiv.org/abs/2402.05876)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL), which seeks to learn an optimal policy using offline data, has garnered significant interest due to its potential in critical applications where online data collection is infeasible or expensive. This work explores the benefit of federated learning for offline RL, aiming at collaboratively leveraging offline datasets at multiple agents. Focusing on finite-horizon episodic tabular Markov decision processes (MDPs), we design FedLCB-Q, a variant of the popular model-free Q-learning algorithm tailored for federated offline RL. FedLCB-Q updates local Q-functions at agents with novel learning rate schedules and aggregates them at a central server using importance averaging and a carefully designed pessimistic penalty term. Our sample complexity analysis reveals that, with appropriately chosen parameters and synchronization schedules, FedLCB-Q achieves linear speedup in terms of the number of agents without requiring high-quality datasets at individual agents, as long as the local datasets collectively cover the state-action space visited by the optimal policy, highlighting the power of collaboration in the federated setting. In fact, the sample complexity almost matches that of the single-agent counterpart, as if all the data are stored at a central location, up to polynomial factors of the horizon length. Furthermore, FedLCB-Q is communication-efficient, where the number of communication rounds is only linear with respect to the horizon length up to logarithmic factors.</li>
</ul>

<h3>Title: Generative Echo Chamber? Effects of LLM-Powered Search Systems on  Diverse Information Seeking</h3>
<ul>
<li><strong>Authors: </strong>Nikhil Sharma, Q. Vera Liao, Ziang Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05880">https://arxiv.org/abs/2402.05880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05880">https://arxiv.org/pdf/2402.05880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05880]] Generative Echo Chamber? Effects of LLM-Powered Search Systems on  Diverse Information Seeking(https://arxiv.org/abs/2402.05880)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search. However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers -- limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search. We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user's view change the effect. Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias. These results present critical implications for the development of LLMs and conversational search systems, and the policy governing these technologies.</li>
</ul>

<h3>Title: CREMA: Multimodal Compositional Video Reasoning via Efficient Modular  Adaptation and Fusion</h3>
<ul>
<li><strong>Authors: </strong>Shoubin Yu, Jaehong Yoon, Mohit Bansal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05889">https://arxiv.org/abs/2402.05889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05889">https://arxiv.org/pdf/2402.05889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05889]] CREMA: Multimodal Compositional Video Reasoning via Efficient Modular  Adaptation and Fusion(https://arxiv.org/abs/2402.05889)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Despite impressive advancements in multimodal compositional reasoning approaches, they are still limited in their flexibility and efficiency by processing fixed modality inputs while updating a lot of model parameters. This paper tackles these critical challenges and proposes CREMA, an efficient and modular modality-fusion framework for injecting any new modality into video reasoning. We first augment multiple informative modalities (such as optical flow, 3D point cloud, audio) from given videos without extra human annotation by leveraging existing pre-trained models. Next, we introduce a query transformer with multiple parameter-efficient modules associated with each accessible modality. It projects diverse modality features to the LLM token embedding space, allowing the model to integrate different data types for response generation. Furthermore, we propose a fusion module designed to compress multimodal queries, maintaining computational efficiency in the LLM while combining additional modalities. We validate our method on video-3D, video-audio, and video-language reasoning tasks and achieve better/equivalent performance against strong multimodal LLMs, including BLIP-2, 3D-LLM, and SeViLA while using 96% fewer trainable parameters. We provide extensive analyses of CREMA, including the impact of each modality on reasoning domains, the design of the fusion module, and example visualizations.</li>
</ul>

<h3>Title: Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data</h3>
<ul>
<li><strong>Authors: </strong>Shufan Li, Harkanwar Singh, Aditya Grover</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05892">https://arxiv.org/abs/2402.05892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05892">https://arxiv.org/pdf/2402.05892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05892]] Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data(https://arxiv.org/abs/2402.05892)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years, Transformers have become the de-facto architecture for sequence modeling on text and a variety of multi-dimensional data, such as images and video. However, the use of self-attention layers in a Transformer incurs prohibitive compute and memory complexity that scales quadratically w.r.t. the sequence length. A recent architecture, Mamba, based on state space models has been shown to achieve comparable performance for modeling text sequences, while scaling linearly with the sequence length. In this work, we present Mamba-ND, a generalized design extending the Mamba architecture to arbitrary multi-dimensional data. Our design alternatively unravels the input data across different dimensions following row-major orderings. We provide a systematic comparison of Mamba-ND with several other alternatives, based on prior multi-dimensional extensions such as Bi-directional LSTMs and S4ND. Empirically, we show that Mamba-ND demonstrates performance competitive with the state-of-the-art on a variety of multi-dimensional benchmarks, including ImageNet-1K classification, HMDB-51 action recognition, and ERA5 weather forecasting.</li>
</ul>

<h3>Title: ClickSAM: Fine-tuning Segment Anything Model using click prompts for  ultrasound image segmentation</h3>
<ul>
<li><strong>Authors: </strong>Aimee Guo, Gace Fei, Hemanth Pasupuletic, Jing Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05902">https://arxiv.org/abs/2402.05902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05902">https://arxiv.org/pdf/2402.05902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05902]] ClickSAM: Fine-tuning Segment Anything Model using click prompts for  ultrasound image segmentation(https://arxiv.org/abs/2402.05902)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The newly released Segment Anything Model (SAM) is a popular tool used in image processing due to its superior segmentation accuracy, variety of input prompts, training capabilities, and efficient model design. However, its current model is trained on a diverse dataset not tailored to medical images, particularly ultrasound images. Ultrasound images tend to have a lot of noise, making it difficult to segment out important structures. In this project, we developed ClickSAM, which fine-tunes the Segment Anything Model using click prompts for ultrasound images. ClickSAM has two stages of training: the first stage is trained on single-click prompts centered in the ground-truth contours, and the second stage focuses on improving the model performance through additional positive and negative click prompts. By comparing the first stage predictions to the ground-truth masks, true positive, false positive, and false negative segments are calculated. Positive clicks are generated using the true positive and false negative segments, and negative clicks are generated using the false positive segments. The Centroidal Voronoi Tessellation algorithm is then employed to collect positive and negative click prompts in each segment that are used to enhance the model performance during the second stage of training. With click-train methods, ClickSAM exhibits superior performance compared to other existing models for ultrasound image segmentation.</li>
</ul>

<h3>Title: FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Eun Cheol Choi, Emilio Ferrara</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.HC, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05904">https://arxiv.org/abs/2402.05904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05904">https://arxiv.org/pdf/2402.05904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05904]] FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs(https://arxiv.org/abs/2402.05904)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Our society is facing rampant misinformation harming public health and trust. To address the societal challenge, we introduce FACT-GPT, a system leveraging Large Language Models (LLMs) to automate the claim matching stage of fact-checking. FACT-GPT, trained on a synthetic dataset, identifies social media content that aligns with, contradicts, or is irrelevant to previously debunked claims. Our evaluation shows that our specialized LLMs can match the accuracy of larger models in identifying related claims, closely mirroring human judgment. This research provides an automated solution for efficient claim matching, demonstrates the potential of LLMs in supporting fact-checkers, and offers valuable resources for further research in the field.</li>
</ul>

<h3>Title: Efficient Stagewise Pretraining via Progressive Subnetworks</h3>
<ul>
<li><strong>Authors: </strong>Abhishek Panigrahi, Nikunj Saunshi, Kaifeng Lyu, Sobhan Miryoosefi, Sashank Reddi, Satyen Kale, Sanjiv Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05913">https://arxiv.org/abs/2402.05913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05913">https://arxiv.org/pdf/2402.05913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05913]] Efficient Stagewise Pretraining via Progressive Subnetworks(https://arxiv.org/abs/2402.05913)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent developments in large language models have sparked interest in efficient pretraining methods. A recent effective paradigm is to perform stage-wise training, where the size of the model is gradually increased over the course of training (e.g. gradual stacking (Reddi et al., 2023)). While the resource and wall-time savings are appealing, it has limitations, particularly the inability to evaluate the full model during earlier stages, and degradation in model quality due to smaller model capacity in the initial stages. In this work, we propose an alternative framework, progressive subnetwork training, that maintains the full model throughout training, but only trains subnetworks within the model in each step. We focus on a simple instantiation of this framework, Random Path Training (RaPTr) that only trains a sub-path of layers in each step, progressively increasing the path lengths in stages. RaPTr achieves better pre-training loss for BERT and UL2 language models while requiring 20-33% fewer FLOPs compared to standard training, and is competitive or better than other efficient training methods. Furthermore, RaPTr shows better downstream performance on UL2, improving QA tasks and SuperGLUE by 1-5% compared to standard training and stacking. Finally, we provide a theoretical basis for RaPTr to justify (a) the increasing complexity of subnetworks in stages, and (b) the stability in loss across stage transitions due to residual connections and layer norm.</li>
</ul>

<h3>Title: Point-VOS: Pointing Up Video Object Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Idil Esen Zulfikar, Sabarinath Mahadevan, Paul Voigtlaender, Bastian Leibe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05917">https://arxiv.org/abs/2402.05917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05917">https://arxiv.org/pdf/2402.05917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05917]] Point-VOS: Pointing Up Video Object Segmentation(https://arxiv.org/abs/2402.05917)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Current state-of-the-art Video Object Segmentation (VOS) methods rely on dense per-object mask annotations both during training and testing. This requires time-consuming and costly video annotation mechanisms. We propose a novel Point-VOS task with a spatio-temporally sparse point-wise annotation scheme that substantially reduces the annotation effort. We apply our annotation scheme to two large-scale video datasets with text descriptions and annotate over 19M points across 133K objects in 32K videos. Based on our annotations, we propose a new Point-VOS benchmark, and a corresponding point-based training mechanism, which we use to establish strong baseline results. We show that existing VOS methods can easily be adapted to leverage our point annotations during training, and can achieve results close to the fully-supervised performance when trained on pseudo-masks generated from these points. In addition, we show that our data can be used to improve models that connect vision and language, by evaluating it on the Video Narrative Grounding (VNG) task. We will make our code and annotations available at https://pointvos.github.io.</li>
</ul>

<h3>Title: Collaborative Control for Geometry-Conditioned PBR Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Shimon Vainer, Mark Boss, Mathias Parger, Konstantin Kutsy, Dante De Nigris, Ciara Rowles, Nicolas Perony, Simon Donné</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05919">https://arxiv.org/abs/2402.05919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05919">https://arxiv.org/pdf/2402.05919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05919]] Collaborative Control for Geometry-Conditioned PBR Image Generation(https://arxiv.org/abs/2402.05919)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Current 3D content generation builds on generative models that output RGB images. Modern graphics pipelines, however, require physically-based rendering (PBR) material properties. We propose to model the PBR image distribution directly to avoid photometric inaccuracies in RGB generation and the inherent ambiguity in extracting PBR from RGB. Existing paradigms for cross-modal finetuning are not suited for PBR generation due to a lack of data and the high dimensionality of the output modalities: we overcome both challenges by retaining a frozen RGB model and tightly linking a newly trained PBR model using a novel cross-network communication paradigm. As the base RGB model is fully frozen, the proposed method does not risk catastrophic forgetting during finetuning and remains compatible with techniques such as IPAdapter pretrained for the base RGB model. We validate our design choices, robustness to data sparsity, and compare against existing paradigms with an extensive experimental section.</li>
</ul>

<h3>Title: On the Convergence of Zeroth-Order Federated Tuning in Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Zhenqing Ling, Daoyuan Chen, Liuyi Yao, Yaliang Li, Ying Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05926">https://arxiv.org/abs/2402.05926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05926">https://arxiv.org/pdf/2402.05926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05926]] On the Convergence of Zeroth-Order Federated Tuning in Large Language  Models(https://arxiv.org/abs/2402.05926)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>The confluence of Federated Learning (FL) and Large Language Models (LLMs) is ushering in a new era in privacy-preserving natural language processing. However, the intensive memory requirements for fine-tuning LLMs pose significant challenges, especially when deploying on edge devices with limited computational resources. To circumvent this, we explore the novel integration of Memory-efficient Zeroth-Order Optimization within a federated setting, a synergy we denote as FedMeZO. Our study is the first to examine the theoretical underpinnings of FedMeZO in the context of LLMs, tackling key questions regarding the influence of large parameter spaces on optimization behavior, the establishment of convergence properties, and the identification of critical parameters for convergence to inform personalized federated strategies. Our extensive empirical evidence supports the theory, showing that FedMeZO not only converges faster than traditional first-order methods such as SGD but also significantly reduces GPU memory usage during training to levels comparable to those during inference. Moreover, the proposed personalized FL strategy that is built upon the theoretical insights to customize the client-wise learning rate can effectively accelerate loss reduction. We hope our work can help to bridge theoretical and practical aspects of federated fine-tuning for LLMs and facilitate further development and research.</li>
</ul>

<h3>Title: WebLINX: Real-World Website Navigation with Multi-Turn Dialogue</h3>
<ul>
<li><strong>Authors: </strong>Xing Han Lù, Zdeněk Kasner, Siva Reddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05930">https://arxiv.org/abs/2402.05930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05930">https://arxiv.org/pdf/2402.05930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05930]] WebLINX: Real-World Website Navigation with Multi-Turn Dialogue(https://arxiv.org/abs/2402.05930)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose the problem of conversational web navigation, where a digital agent controls a web browser and follows user instructions to solve real-world tasks in a multi-turn dialogue fashion. To support this problem, we introduce WEBLINX - a large-scale benchmark of 100K interactions across 2300 expert demonstrations of conversational web navigation. Our benchmark covers a broad range of patterns on over 150 real-world websites and can be used to train and evaluate agents in diverse scenarios. Due to the magnitude of information present, Large Language Models (LLMs) cannot process entire web pages in real-time. To solve this bottleneck, we design a retrieval-inspired model that efficiently prunes HTML pages by ranking relevant elements. We use the selected elements, along with screenshots and action history, to assess a variety of models for their ability to replicate human behavior when navigating the web. Our experiments span from small text-only to proprietary multimodal LLMs. We find that smaller finetuned decoders surpass the best zero-shot LLMs (including GPT-4V), but also larger finetuned multimodal models which were explicitly pretrained on screenshots. However, all finetuned models struggle to generalize to unseen websites. Our findings highlight the need for large multimodal models that can generalize to novel settings. Our code, data and models are available for research: https://mcgill-nlp.github.io/weblinx</li>
</ul>

<h3>Title: Time Series Diffusion in the Frequency Domain</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Crabbé, Nicolas Huynh, Jan Stanczuk, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05933">https://arxiv.org/abs/2402.05933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05933">https://arxiv.org/pdf/2402.05933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05933]] Time Series Diffusion in the Frequency Domain(https://arxiv.org/abs/2402.05933)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Fourier analysis has been an instrumental tool in the development of signal processing. This leads us to wonder whether this framework could similarly benefit generative modelling. In this paper, we explore this question through the scope of time series diffusion models. More specifically, we analyze whether representing time series in the frequency domain is a useful inductive bias for score-based diffusion models. By starting from the canonical SDE formulation of diffusion in the time domain, we show that a dual diffusion process occurs in the frequency domain with an important nuance: Brownian motions are replaced by what we call mirrored Brownian motions, characterized by mirror symmetries among their components. Building on this insight, we show how to adapt the denoising score matching approach to implement diffusion models in the frequency domain. This results in frequency diffusion models, which we compare to canonical time diffusion models. Our empirical evaluation on real-world datasets, covering various domains like healthcare and finance, shows that frequency diffusion models better capture the training distribution than time diffusion models. We explain this observation by showing that time series from these datasets tend to be more localized in the frequency domain than in the time domain, which makes them easier to model in the former case. All our observations point towards impactful synergies between Fourier analysis and diffusion models.</li>
</ul>

<h3>Title: SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Peng Gao, Renrui Zhang, Chris Liu, Longtian Qiu, Siyuan Huang, Weifeng Lin, Shitian Zhao, Shijie Geng, Ziyi Lin, Peng Jin, Kaipeng Zhang, Wenqi Shao, Chao Xu, Conghui He, Junjun He, Hao Shao, Pan Lu, Hongsheng Li, Yu Qiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05935">https://arxiv.org/abs/2402.05935</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05935">https://arxiv.org/pdf/2402.05935</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05935]] SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large  Language Models(https://arxiv.org/abs/2402.05935)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM) series developed upon SPHINX. To improve the architecture and training efficiency, we modify the SPHINX framework by removing redundant visual encoders, bypassing fully-padded sub-images with skip tokens, and simplifying multi-stage training into a one-stage all-in-one paradigm. To fully unleash the potential of MLLMs, we assemble a comprehensive multi-domain and multimodal dataset covering publicly available resources in language, vision, and vision-language tasks. We further enrich this collection with our curated OCR intensive and Set-of-Mark datasets, extending the diversity and generality. By training over different base LLMs including TinyLlama1.1B, InternLM2-7B, LLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in parameter size and multilingual capabilities. Comprehensive benchmarking reveals a strong correlation between the multi-modal performance with the data and parameter scales. Code and models are released at https://github.com/Alpha-VLLM/LLaMA2-Accessory</li>
</ul>

<h3>Title: InstaGen: Enhancing Object Detection by Training on Synthetic Dataset</h3>
<ul>
<li><strong>Authors: </strong>Chengjian Feng, Yujie Zhong, Zequn Jie, Weidi Xie, Lin Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.05937">https://arxiv.org/abs/2402.05937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.05937">https://arxiv.org/pdf/2402.05937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.05937]] InstaGen: Enhancing Object Detection by Training on Synthetic Dataset(https://arxiv.org/abs/2402.05937)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce a novel paradigm to enhance the ability of object detector, e.g., expanding categories or improving detection performance, by training on synthetic dataset generated from diffusion models. Specifically, we integrate an instance-level grounding head into a pre-trained, generative diffusion model, to augment it with the ability of localising arbitrary instances in the generated images. The grounding head is trained to align the text embedding of category names with the regional visual feature of the diffusion model, using supervision from an off-the-shelf object detector, and a novel self-training scheme on (novel) categories not covered by the detector. This enhanced version of diffusion model, termed as InstaGen, can serve as a data synthesizer for object detection. We conduct thorough experiments to show that, object detector can be enhanced while training on the synthetic dataset from InstaGen, demonstrating superior performance over existing state-of-the-art methods in open-vocabulary (+4.5 AP) and data-sparse (+1.2 to 5.2 AP) scenarios.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
