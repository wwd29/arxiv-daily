<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: ByteStack-ID: Integrated Stacked Model Leveraging Payload Byte Frequency for Grayscale Image-based Network Intrusion Detection. (arXiv:2310.09298v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09298">http://arxiv.org/abs/2310.09298</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09298]] ByteStack-ID: Integrated Stacked Model Leveraging Payload Byte Frequency for Grayscale Image-based Network Intrusion Detection(http://arxiv.org/abs/2310.09298)</code></li>
<li>Summary: <p>In the ever-evolving realm of network security, the swift and accurate
identification of diverse attack classes within network traffic is of paramount
importance. This paper introduces "ByteStack-ID," a pioneering approach
tailored for packet-level intrusion detection. At its core, ByteStack-ID
leverages grayscale images generated from the frequency distributions of
payload data, a groundbreaking technique that greatly enhances the model's
ability to discern intricate data patterns. Notably, our approach is
exclusively grounded in packet-level information, a departure from conventional
Network Intrusion Detection Systems (NIDS) that predominantly rely on
flow-based data. While building upon the fundamental concept of stacking
methodology, ByteStack-ID diverges from traditional stacking approaches. It
seamlessly integrates additional meta learner layers into the concatenated base
learners, creating a highly optimized, unified model. Empirical results
unequivocally confirm the outstanding effectiveness of the ByteStack-ID
framework, consistently outperforming baseline models and state-of-the-art
approaches across pivotal performance metrics, including precision, recall, and
F1-score. Impressively, our proposed approach achieves an exceptional 81\%
macro F1-score in multiclass classification tasks. In a landscape marked by the
continuous evolution of network threats, ByteStack-ID emerges as a robust and
versatile security solution, relying solely on packet-level information
extracted from network traffic data.
</p></li>
</ul>

<h3>Title: Survey on Security Attacks in Connected and Autonomous Vehicular Systems. (arXiv:2310.09510v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09510">http://arxiv.org/abs/2310.09510</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09510]] Survey on Security Attacks in Connected and Autonomous Vehicular Systems(http://arxiv.org/abs/2310.09510)</code></li>
<li>Summary: <p>Connected and autonomous vehicles, also known as CAVs, are a general trend in
the evolution of the automotive industry that can be utilized to make
transportation safer, improve the number of mobility options available, user
costs will go down and new jobs will be created. However, as our society grows
more automated and networked, criminal actors will have additional
opportunities to conduct a variety of attacks, putting CAV security in danger.
By providing a brief review of the state of cyber security in the CAVs
environment, this study aims to draw attention to the issues and concerns
associated with security. The first thing it does is categorize the multiple
cybersecurity threats and weaknesses in the context of CAVs into three groups:
attacks on the vehicles network, attacks on the Internet at large, and other
attacks. This is done in accordance with the various communication networks and
targets under attack. Next, it considers the possibility of cyber attacks to be
an additional form of threat posed by the environment of CAVs. After that, it
details the most uptodate defense tactics for securing CAVs and analyzes how
effective they are. In addition, it draws some conclusions about the various
cyber security and safety requirements of CAVs that are now available, which is
beneficial for the use of CAVs in the real world. At the end, we discussed some
implications on Adversary Attacks on Autonomous Vehicles. In conclusion, a
number of difficulties and unsolved issues for future research are analyzed and
explored.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: An In-Depth Examination of Requirements for Disclosure Risk Assessment. (arXiv:2310.09398v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09398">http://arxiv.org/abs/2310.09398</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09398]] An In-Depth Examination of Requirements for Disclosure Risk Assessment(http://arxiv.org/abs/2310.09398)</code></li>
<li>Summary: <p>The use of formal privacy to protect the confidentiality of responses in the
2020 Decennial Census of Population and Housing has triggered renewed interest
and debate over how to measure the disclosure risks and societal benefits of
the published data products. Following long-established precedent in economics
and statistics, we argue that any proposal for quantifying disclosure risk
should be based on pre-specified, objective criteria. Such criteria should be
used to compare methodologies to identify those with the most desirable
properties. We illustrate this approach, using simple desiderata, to evaluate
the absolute disclosure risk framework, the counterfactual framework underlying
differential privacy, and prior-to-posterior comparisons. We conclude that
satisfying all the desiderata is impossible, but counterfactual comparisons
satisfy the most while absolute disclosure risk satisfies the fewest.
Furthermore, we explain that many of the criticisms levied against differential
privacy would be levied against any technology that is not equivalent to
direct, unrestricted access to confidential data. Thus, more research is
needed, but in the near-term, the counterfactual approach appears best-suited
for privacy-utility analysis.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h2>robust</h2>
<h3>Title: MEMTRACK: A Deep Learning-Based Approach to Microrobot Tracking in Dense and Low-Contrast Environments. (arXiv:2310.09441v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09441">http://arxiv.org/abs/2310.09441</a></li>
<li>Code URL: https://github.com/sawhney-medha/memtrack</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09441]] MEMTRACK: A Deep Learning-Based Approach to Microrobot Tracking in Dense and Low-Contrast Environments(http://arxiv.org/abs/2310.09441)</code></li>
<li>Summary: <p>Tracking microrobots is challenging, considering their minute size and high
speed. As the field progresses towards developing microrobots for biomedical
applications and conducting mechanistic studies in physiologically relevant
media (e.g., collagen), this challenge is exacerbated by the dense surrounding
environments with feature size and shape comparable to microrobots. Herein, we
report Motion Enhanced Multi-level Tracker (MEMTrack), a robust pipeline for
detecting and tracking microrobots using synthetic motion features, deep
learning-based object detection, and a modified Simple Online and Real-time
Tracking (SORT) algorithm with interpolation for tracking. Our object detection
approach combines different models based on the object's motion pattern. We
trained and validated our model using bacterial micro-motors in collagen
(tissue phantom) and tested it in collagen and aqueous media. We demonstrate
that MEMTrack accurately tracks even the most challenging bacteria missed by
skilled human annotators, achieving precision and recall of 77% and 48% in
collagen and 94% and 35% in liquid media, respectively. Moreover, we show that
MEMTrack can quantify average bacteria speed with no statistically significant
difference from the laboriously-produced manual tracking data. MEMTrack
represents a significant contribution to microrobot localization and tracking,
and opens the potential for vision-based deep learning approaches to microrobot
control in dense and low-contrast settings. All source code for training and
testing MEMTrack and reproducing the results of the paper have been made
publicly available https://github.com/sawhney-medha/MEMTrack.
</p></li>
</ul>

<h3>Title: Perception Reinforcement Using Auxiliary Learning Feature Fusion: A Modified Yolov8 for Head Detection. (arXiv:2310.09492v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09492">http://arxiv.org/abs/2310.09492</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09492]] Perception Reinforcement Using Auxiliary Learning Feature Fusion: A Modified Yolov8 for Head Detection(http://arxiv.org/abs/2310.09492)</code></li>
<li>Summary: <p>Head detection provides distribution information of pedestrian, which is
crucial for scene statistical analysis, traffic management, and risk assessment
and early warning. However, scene complexity and large-scale variation in the
real world make accurate detection more difficult. Therefore, we present a
modified Yolov8 which improves head detection performance through reinforcing
target perception. An Auxiliary Learning Feature Fusion (ALFF) module comprised
of LSTM and convolutional blocks is used as the auxiliary task to help the
model perceive targets. In addition, we introduce Noise Calibration into
Distribution Focal Loss to facilitate model fitting and improve the accuracy of
detection. Considering the requirements of high accuracy and speed for the head
detection task, our method is adapted with two kinds of backbone, namely
Yolov8n and Yolov8m. The results demonstrate the superior performance of our
approach in improving detection accuracy and robustness.
</p></li>
</ul>

<h3>Title: Learning In-between Imagery Dynamics via Physical Latent Spaces. (arXiv:2310.09495v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09495">http://arxiv.org/abs/2310.09495</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09495]] Learning In-between Imagery Dynamics via Physical Latent Spaces(http://arxiv.org/abs/2310.09495)</code></li>
<li>Summary: <p>We present a framework designed to learn the underlying dynamics between two
images observed at consecutive time steps. The complex nature of image data and
the lack of temporal information pose significant challenges in capturing the
unique evolving patterns. Our proposed method focuses on estimating the
intermediary stages of image evolution, allowing for interpretability through
latent dynamics while preserving spatial correlations with the image. By
incorporating a latent variable that follows a physical model expressed in
partial differential equations (PDEs), our approach ensures the
interpretability of the learned model and provides insight into corresponding
image dynamics. We demonstrate the robustness and effectiveness of our learning
framework through a series of numerical tests using geoscientific imagery data.
</p></li>
</ul>

<h3>Title: Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust Performance. (arXiv:2310.09507v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09507">http://arxiv.org/abs/2310.09507</a></li>
<li>Code URL: https://github.com/jlianglab/ark</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09507]] Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust Performance(http://arxiv.org/abs/2310.09507)</code></li>
<li>Summary: <p>Deep learning nowadays offers expert-level and sometimes even
super-expert-level performance, but achieving such performance demands massive
annotated data for training (e.g., Google's proprietary CXR Foundation Model
(CXR-FM) was trained on 821,544 labeled and mostly private chest X-rays
(CXRs)). Numerous datasets are publicly available in medical imaging but
individually small and heterogeneous in expert labels. We envision a powerful
and robust foundation model that can be trained by aggregating numerous small
public datasets. To realize this vision, we have developed Ark, a framework
that accrues and reuses knowledge from heterogeneous expert annotations in
various datasets. As a proof of concept, we have trained two Ark models on
335,484 and 704,363 CXRs, respectively, by merging several datasets including
ChestX-ray14, CheXpert, MIMIC-II, and VinDr-CXR, evaluated them on a wide range
of imaging tasks covering both classification and segmentation via fine-tuning,
linear-probing, and gender-bias analysis, and demonstrated our Ark's superior
and robust performance over the SOTA fully/self-supervised baselines and
Google's proprietary CXR-FM. This enhanced performance is attributed to our
simple yet powerful observation that aggregating numerous public datasets
diversifies patient populations and accrues knowledge from diverse experts,
yielding unprecedented performance yet saving annotation cost. With all codes
and pretrained models released at GitHub.com/JLiangLab/Ark, we hope that Ark
exerts an important impact on open science, as accruing and reusing knowledge
from expert annotations in public datasets can potentially surpass the
performance of proprietary models trained on unusually large data, inspiring
many more researchers worldwide to share codes and datasets to build open
foundation models, accelerate open science, and democratize deep learning for
medical imaging.
</p></li>
</ul>

<h3>Title: When are Bandits Robust to Misspecification?. (arXiv:2310.09358v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09358">http://arxiv.org/abs/2310.09358</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09358]] When are Bandits Robust to Misspecification?(http://arxiv.org/abs/2310.09358)</code></li>
<li>Summary: <p>Parametric feature-based reward models are widely employed by algorithms for
decision making settings such as bandits and contextual bandits. The typical
assumption under which they are analysed is realizability, i.e., that the true
rewards of actions are perfectly explained by some parametric model in the
class. We are, however, interested in the situation where the true rewards are
(potentially significantly) misspecified with respect to the model class. For
parameterized bandits and contextual bandits, we identify sufficient
conditions, depending on the problem instance and model class, under which
classic algorithms such as $\epsilon$-greedy and LinUCB enjoy sublinear (in the
time horizon) regret guarantees under even grossly misspecified rewards. This
is in contrast to existing worst-case results for misspecified bandits which
show regret bounds that scale linearly with time, and shows that there can be a
nontrivially large set of bandit instances that are robust to misspecification.
</p></li>
</ul>

<h3>Title: Is Certifying $\ell_p$ Robustness Still Worthwhile?. (arXiv:2310.09361v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09361">http://arxiv.org/abs/2310.09361</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09361]] Is Certifying $\ell_p$ Robustness Still Worthwhile?(http://arxiv.org/abs/2310.09361)</code></li>
<li>Summary: <p>Over the years, researchers have developed myriad attacks that exploit the
ubiquity of adversarial examples, as well as defenses that aim to guard against
the security vulnerabilities posed by such attacks. Of particular interest to
this paper are defenses that provide provable guarantees against the class of
$\ell_p$-bounded attacks. Certified defenses have made significant progress,
taking robustness certification from toy models and datasets to large-scale
problems like ImageNet classification. While this is undoubtedly an interesting
academic problem, as the field has matured, its impact in practice remains
unclear, thus we find it useful to revisit the motivation for continuing this
line of research. There are three layers to this inquiry, which we address in
this paper: (1) why do we care about robustness research? (2) why do we care
about the $\ell_p$-bounded threat model? And (3) why do we care about
certification as opposed to empirical defenses? In brief, we take the position
that local robustness certification indeed confers practical value to the field
of machine learning. We focus especially on the latter two questions from
above. With respect to the first of the two, we argue that the $\ell_p$-bounded
threat model acts as a minimal requirement for safe application of models in
security-critical domains, while at the same time, evidence has mounted
suggesting that local robustness may lead to downstream external benefits not
immediately related to robustness. As for the second, we argue that (i)
certification provides a resolution to the cat-and-mouse game of adversarial
attacks; and furthermore, that (ii) perhaps contrary to popular belief, there
may not exist a fundamental trade-off between accuracy, robustness, and
certifiability, while moreover, certified training techniques constitute a
particularly promising way for learning robust models.
</p></li>
</ul>

<h3>Title: ZeroSwap: Data-driven Optimal Market Making in DeFi. (arXiv:2310.09413v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09413">http://arxiv.org/abs/2310.09413</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09413]] ZeroSwap: Data-driven Optimal Market Making in DeFi(http://arxiv.org/abs/2310.09413)</code></li>
<li>Summary: <p>Automated Market Makers (AMMs) are major centers of matching liquidity supply
and demand in Decentralized Finance. Their functioning relies primarily on the
presence of liquidity providers (LPs) incentivized to invest their assets into
a liquidity pool. However, the prices at which a pooled asset is traded is
often more stale than the prices on centralized and more liquid exchanges. This
leads to the LPs suffering losses to arbitrage. This problem is addressed by
adapting market prices to trader behavior, captured via the classical market
microstructure model of Glosten and Milgrom. In this paper, we propose the
first optimal Bayesian and the first model-free data-driven algorithm to
optimally track the external price of the asset. The notion of optimality that
we use enforces a zero-profit condition on the prices of the market maker,
hence the name ZeroSwap. This ensures that the market maker balances losses to
informed traders with profits from noise traders. The key property of our
approach is the ability to estimate the external market price without the need
for price oracles or loss oracles. Our theoretical guarantees on the
performance of both these algorithms, ensuring the stability and convergence of
their price recommendations, are of independent interest in the theory of
reinforcement learning. We empirically demonstrate the robustness of our
algorithms to changing market conditions.
</p></li>
</ul>

<h3>Title: Learning nonlinear integral operators via Recurrent Neural Networks and its application in solving Integro-Differential Equations. (arXiv:2310.09434v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09434">http://arxiv.org/abs/2310.09434</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09434]] Learning nonlinear integral operators via Recurrent Neural Networks and its application in solving Integro-Differential Equations(http://arxiv.org/abs/2310.09434)</code></li>
<li>Summary: <p>In this paper, we propose using LSTM-RNNs (Long Short-Term Memory-Recurrent
Neural Networks) to learn and represent nonlinear integral operators that
appear in nonlinear integro-differential equations (IDEs). The LSTM-RNN
representation of the nonlinear integral operator allows us to turn a system of
nonlinear integro-differential equations into a system of ordinary differential
equations for which many efficient solvers are available. Furthermore, because
the use of LSTM-RNN representation of the nonlinear integral operator in an IDE
eliminates the need to perform a numerical integration in each numerical time
evolution step, the overall temporal cost of the LSTM-RNN-based IDE solver can
be reduced to $O(n_T)$ from $O(n_T^2)$ if a $n_T$-step trajectory is to be
computed. We illustrate the efficiency and robustness of this LSTM-RNN-based
numerical IDE solver with a model problem. Additionally, we highlight the
generalizability of the learned integral operator by applying it to IDEs driven
by different external forces. As a practical application, we show how this
methodology can effectively solve the Dyson's equation for quantum many-body
systems.
</p></li>
</ul>

<h3>Title: Target Variable Engineering. (arXiv:2310.09440v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09440">http://arxiv.org/abs/2310.09440</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09440]] Target Variable Engineering(http://arxiv.org/abs/2310.09440)</code></li>
<li>Summary: <p>How does the formulation of a target variable affect performance within the
ML pipeline? The experiments in this study examine numeric targets that have
been binarized by comparing against a threshold. We compare the predictive
performance of regression models trained to predict the numeric targets vs.
classifiers trained to predict their binarized counterparts. Specifically, we
make this comparison at every point of a randomized hyperparameter optimization
search to understand the effect of computational resource budget on the
tradeoff between the two. We find that regression requires significantly more
computational effort to converge upon the optimal performance, and is more
sensitive to both randomness and heuristic choices in the training process.
Although classification can and does benefit from systematic hyperparameter
tuning and model selection, the improvements are much less than for regression.
This work comprises the first systematic comparison of regression and
classification within the framework of computational resource requirements. Our
findings contribute to calls for greater replicability and efficiency within
the ML pipeline for the sake of building more sustainable and robust AI
systems.
</p></li>
</ul>

<h3>Title: Mirage: Model-Agnostic Graph Distillation for Graph Classification. (arXiv:2310.09486v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09486">http://arxiv.org/abs/2310.09486</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09486]] Mirage: Model-Agnostic Graph Distillation for Graph Classification(http://arxiv.org/abs/2310.09486)</code></li>
<li>Summary: <p>GNNs, like other deep learning models, are data and computation hungry. There
is a pressing need to scale training of GNNs on large datasets to enable their
usage on low-resource environments. Graph distillation is an effort in that
direction with the aim to construct a smaller synthetic training set from the
original training data without significantly compromising model performance.
While initial efforts are promising, this work is motivated by two key
observations: (1) Existing graph distillation algorithms themselves rely on
training with the full dataset, which undermines the very premise of graph
distillation. (2) The distillation process is specific to the target GNN
architecture and hyper-parameters and thus not robust to changes in the
modeling pipeline. We circumvent these limitations by designing a distillation
algorithm called Mirage for graph classification. Mirage is built on the
insight that a message-passing GNN decomposes the input graph into a multiset
of computation trees. Furthermore, the frequency distribution of computation
trees is often skewed in nature, enabling us to condense this data into a
concise distilled summary. By compressing the computation data itself, as
opposed to emulating gradient flows on the original training set-a prevalent
approach to date-Mirage transforms into an unsupervised and
architecture-agnostic distillation algorithm. Extensive benchmarking on
real-world datasets underscores Mirage's superiority, showcasing enhanced
generalization accuracy, data compression, and distillation efficiency when
compared to state-of-the-art baselines.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks. (arXiv:2310.09436v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09436">http://arxiv.org/abs/2310.09436</a></li>
<li>Code URL: https://github.com/zixuanke/pycontinual</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09436]] Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks(http://arxiv.org/abs/2310.09436)</code></li>
<li>Summary: <p>Continual learning (CL) has two main objectives: preventing catastrophic
forgetting (CF) and encouraging knowledge transfer (KT). The existing
literature mainly focused on overcoming CF. Some work has also been done on KT
when the tasks are similar. To our knowledge, only one method has been proposed
to learn a sequence of mixed tasks. However, these techniques still suffer from
CF and/or limited KT. This paper proposes a new CL method to achieve both. It
overcomes CF by isolating the knowledge of each task via discovering a
subnetwork for it. A soft-masking mechanism is also proposed to preserve the
previous knowledge and to enable the new task to leverage the past knowledge to
achieve KT. Experiments using classification, generation, information
extraction, and their mixture (i.e., heterogeneous tasks) show that the
proposed method consistently outperforms strong baselines.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Tackling Heterogeneity in Medical Federated learning via Vision Transformers. (arXiv:2310.09444v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09444">http://arxiv.org/abs/2310.09444</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09444]] Tackling Heterogeneity in Medical Federated learning via Vision Transformers(http://arxiv.org/abs/2310.09444)</code></li>
<li>Summary: <p>Optimization-based regularization methods have been effective in addressing
the challenges posed by data heterogeneity in medical federated learning,
particularly in improving the performance of underrepresented clients. However,
these methods often lead to lower overall model accuracy and slower convergence
rates. In this paper, we demonstrate that using Vision Transformers can
substantially improve the performance of underrepresented clients without a
significant trade-off in overall accuracy. This improvement is attributed to
the Vision transformer's ability to capture long-range dependencies within the
input data.
</p></li>
</ul>

<h3>Title: Near-optimal Differentially Private Client Selection in Federated Settings. (arXiv:2310.09370v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09370">http://arxiv.org/abs/2310.09370</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09370]] Near-optimal Differentially Private Client Selection in Federated Settings(http://arxiv.org/abs/2310.09370)</code></li>
<li>Summary: <p>We develop an iterative differentially private algorithm for client selection
in federated settings. We consider a federated network wherein clients
coordinate with a central server to complete a task; however, the clients
decide whether to participate or not at a time step based on their preferences
-- local computation and probabilistic intent. The algorithm does not require
client-to-client information exchange. The developed algorithm provides
near-optimal values to the clients over long-term average participation with a
certain differential privacy guarantee. Finally, we present the experimental
results to check the algorithm's efficacy.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h2>explainability</h2>
<h3>Title: Offline Reinforcement Learning for Optimizing Production Bidding Policies. (arXiv:2310.09426v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09426">http://arxiv.org/abs/2310.09426</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09426]] Offline Reinforcement Learning for Optimizing Production Bidding Policies(http://arxiv.org/abs/2310.09426)</code></li>
<li>Summary: <p>The online advertising market, with its thousands of auctions run per second,
presents a daunting challenge for advertisers who wish to optimize their spend
under a budget constraint. Thus, advertising platforms typically provide
automated agents to their customers, which act on their behalf to bid for
impression opportunities in real time at scale. Because these proxy agents are
owned by the platform but use advertiser funds to operate, there is a strong
practical need to balance reliability and explainability of the agent with
optimizing power. We propose a generalizable approach to optimizing bidding
policies in production environments by learning from real data using offline
reinforcement learning. This approach can be used to optimize any
differentiable base policy (practically, a heuristic policy based on principles
which the advertiser can easily understand), and only requires data generated
by the base policy itself. We use a hybrid agent architecture that combines
arbitrary base policies with deep neural networks, where only the optimized
base policy parameters are eventually deployed, and the neural network part is
discarded after training. We demonstrate that such an architecture achieves
statistically significant performance gains in both simulated and at-scale
production bidding environments. Our approach does not incur additional
infrastructure, safety, or explainability costs, as it directly optimizes
parameters of existing production routines without replacing them with black
box-style models like neural networks.
</p></li>
</ul>

<h2>watermark</h2>
<h3>Title: Unified High-binding Watermark for Unconditional Image Generation Models. (arXiv:2310.09479v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09479">http://arxiv.org/abs/2310.09479</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09479]] Unified High-binding Watermark for Unconditional Image Generation Models(http://arxiv.org/abs/2310.09479)</code></li>
<li>Summary: <p>Deep learning techniques have implemented many unconditional image generation
(UIG) models, such as GAN, Diffusion model, etc. The extremely realistic images
(also known as AI-Generated Content, AIGC for short) produced by these models
bring urgent needs for intellectual property protection such as data
traceability and copyright certification. An attacker can steal the output
images of the target model and use them as part of the training data to train a
private surrogate UIG model. The implementation mechanisms of UIG models are
diverse and complex, and there is no unified and effective protection and
verification method at present. To address these issues, we propose a two-stage
unified watermark verification mechanism with high-binding effects for such
models. In the first stage, we use an encoder to invisibly write the watermark
image into the output images of the original AIGC tool, and reversely extract
the watermark image through the corresponding decoder. In the second stage, we
design the decoder fine-tuning process, and the fine-tuned decoder can make
correct judgments on whether the suspicious model steals the original AIGC tool
data. Experiments demonstrate our method can complete the verification work
with almost zero false positive rate under the condition of only using the
model output images. Moreover, the proposed method can achieve data steal
verification across different types of UIG models, which further increases the
practicality of the method.
</p></li>
</ul>

<h2>diffusion</h2>
<h3>Title: PaintHuman: Towards High-fidelity Text-to-3D Human Texturing via Denoised Score Distillation. (arXiv:2310.09458v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09458">http://arxiv.org/abs/2310.09458</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09458]] PaintHuman: Towards High-fidelity Text-to-3D Human Texturing via Denoised Score Distillation(http://arxiv.org/abs/2310.09458)</code></li>
<li>Summary: <p>Recent advances in zero-shot text-to-3D human generation, which employ the
human model prior (eg, SMPL) or Score Distillation Sampling (SDS) with
pre-trained text-to-image diffusion models, have been groundbreaking. However,
SDS may provide inaccurate gradient directions under the weak diffusion
guidance, as it tends to produce over-smoothed results and generate body
textures that are inconsistent with the detailed mesh geometry. Therefore,
directly leverage existing strategies for high-fidelity text-to-3D human
texturing is challenging. In this work, we propose a model called PaintHuman to
addresses the challenges from two aspects. We first propose a novel score
function, Denoised Score Distillation (DSD), which directly modifies the SDS by
introducing negative gradient components to iteratively correct the gradient
direction and generate high-quality textures. In addition, we use the depth map
as a geometric guidance to ensure the texture is semantically aligned to human
mesh surfaces. To guarantee the quality of rendered results, we employ
geometry-aware networks to predict surface materials and render realistic human
textures. Extensive experiments, benchmarked against state-of-the-art methods,
validate the efficacy of our approach.
</p></li>
</ul>

<h3>Title: Towards More Accurate Diffusion Model Acceleration with A Timestep Aligner. (arXiv:2310.09469v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09469">http://arxiv.org/abs/2310.09469</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09469]] Towards More Accurate Diffusion Model Acceleration with A Timestep Aligner(http://arxiv.org/abs/2310.09469)</code></li>
<li>Summary: <p>A diffusion model, which is formulated to produce an image using thousands of
denoising steps, usually suffers from a slow inference speed. Existing
acceleration algorithms simplify the sampling by skipping most steps yet
exhibit considerable performance degradation. By viewing the generation of
diffusion models as a discretized integrating process, we argue that the
quality drop is partly caused by applying an inaccurate integral direction to a
timestep interval. To rectify this issue, we propose a timestep aligner that
helps find a more accurate integral direction for a particular interval at the
minimum cost. Specifically, at each denoising step, we replace the original
parameterization by conditioning the network on a new timestep, which is
obtained by aligning the sampling distribution to the real distribution.
Extensive experiments show that our plug-in design can be trained efficiently
and boost the inference performance of various state-of-the-art acceleration
methods, especially when there are few denoising steps. For example, when using
10 denoising steps on the popular LSUN Bedroom dataset, we improve the FID of
DDIM from 9.65 to 6.07, simply by adopting our method for a more appropriate
set of timesteps. Code will be made publicly available.
</p></li>
</ul>

<h3>Title: Exploring the Design Space of Diffusion Autoencoders for Face Morphing. (arXiv:2310.09484v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09484">http://arxiv.org/abs/2310.09484</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09484]] Exploring the Design Space of Diffusion Autoencoders for Face Morphing(http://arxiv.org/abs/2310.09484)</code></li>
<li>Summary: <p>Face morphs created by Diffusion Autoencoders are a recent innovation and the
design space of such an approach has not been well explored. We explore three
axes of the design space, i.e., 1) sampling algorithms, 2) the reverse DDIM
solver, and 3) partial sampling through small amounts of added noise.
</p></li>
</ul>

<h3>Title: Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task. (arXiv:2310.09336v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09336">http://arxiv.org/abs/2310.09336</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09336]] Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task(http://arxiv.org/abs/2310.09336)</code></li>
<li>Summary: <p>Modern generative models exhibit unprecedented capabilities to generate
extremely realistic data. However, given the inherent compositionality of the
real world, reliable use of these models in practical applications requires
that they exhibit the capability to compose a novel set of concepts to generate
outputs not seen in the training data set. Prior work demonstrates that recent
diffusion models do exhibit intriguing compositional generalization abilities,
but also fail unpredictably. Motivated by this, we perform a controlled study
for understanding compositional generalization in conditional diffusion models
in a synthetic setting, varying different attributes of the training data and
measuring the model's ability to generate samples out-of-distribution. Our
results show: (i) the order in which the ability to generate samples from a
concept and compose them emerges is governed by the structure of the underlying
data-generating process; (ii) performance on compositional tasks exhibits a
sudden ``emergence'' due to multiplicative reliance on the performance of
constituent tasks, partially explaining emergent phenomena seen in generative
models; and (iii) composing concepts with lower frequency in the training data
to generate out-of-distribution samples requires considerably more optimization
steps compared to generating in-distribution samples. Overall, our study lays a
foundation for understanding capabilities and compositionality in generative
models from a data-centric perspective.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Understanding AI Cognition: A Neural Module for Inference Inspired by Human Memory Mechanisms. (arXiv:2310.09297v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09297">http://arxiv.org/abs/2310.09297</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09297]] Understanding AI Cognition: A Neural Module for Inference Inspired by Human Memory Mechanisms(http://arxiv.org/abs/2310.09297)</code></li>
<li>Summary: <p>How humans and machines make sense of current inputs for relation reasoning
and question-answering while putting the perceived information into context of
our past memories, has been a challenging conundrum in cognitive science and
artificial intelligence. Inspired by human brain's memory system and cognitive
architectures, we propose a PMI framework that consists of perception, memory
and inference components. Notably, the memory module comprises working and
long-term memory, with the latter endowed with a higher-order structure to
retain more accumulated knowledge and experiences. Through a differentiable
competitive write access, current perceptions update working memory, which is
later merged with long-term memory via outer product associations, averting
memory overflow and minimizing information conflicts. In the inference module,
relevant information is retrieved from two separate memory origins and
associatively integrated to attain a more comprehensive and precise
interpretation of current perceptions. We exploratively apply our PMI to
improve prevailing Transformers and CNN models on question-answering tasks like
bAbI-20k and Sort-of-CLEVR datasets, as well as relation calculation and image
classification tasks, and in each case, our PMI enhancements consistently
outshine their original counterparts significantly. Visualization analyses
reveal that memory consolidation, along with the interaction and integration of
information from diverse memory sources, substantially contributes to the model
effectiveness on inference tasks.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Efficient Apple Maturity and Damage Assessment: A Lightweight Detection Model with GAN and Attention Mechanism. (arXiv:2310.09347v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09347">http://arxiv.org/abs/2310.09347</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09347]] Efficient Apple Maturity and Damage Assessment: A Lightweight Detection Model with GAN and Attention Mechanism(http://arxiv.org/abs/2310.09347)</code></li>
<li>Summary: <p>This study proposes a method based on lightweight convolutional neural
networks (CNN) and generative adversarial networks (GAN) for apple ripeness and
damage level detection tasks. Initially, a lightweight CNN model is designed by
optimizing the model's depth and width, as well as employing advanced model
compression techniques, successfully reducing the model's parameter and
computational requirements, thus enhancing real-time performance in practical
applications. Simultaneously, attention mechanisms are introduced, dynamically
adjusting the importance of different feature layers to improve the performance
in object detection tasks. To address the issues of sample imbalance and
insufficient sample size, GANs are used to generate realistic apple images,
expanding the training dataset and enhancing the model's recognition capability
when faced with apples of varying ripeness and damage levels. Furthermore, by
applying the object detection network for damage location annotation on damaged
apples, the accuracy of damage level detection is improved, providing a more
precise basis for decision-making. Experimental results show that in apple
ripeness grading detection, the proposed model achieves 95.6\%, 93.8\%, 95.0\%,
and 56.5 in precision, recall, accuracy, and FPS, respectively. In apple damage
level detection, the proposed model reaches 95.3\%, 93.7\%, and 94.5\% in
precision, recall, and mAP, respectively. In both tasks, the proposed method
outperforms other mainstream models, demonstrating the excellent performance
and high practical value of the proposed method in apple ripeness and damage
level detection tasks.
</p></li>
</ul>

<h3>Title: Uncertainty Quantification using Generative Approach. (arXiv:2310.09338v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09338">http://arxiv.org/abs/2310.09338</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09338]] Uncertainty Quantification using Generative Approach(http://arxiv.org/abs/2310.09338)</code></li>
<li>Summary: <p>We present the Incremental Generative Monte Carlo (IGMC) method, designed to
measure uncertainty in deep neural networks using deep generative approaches.
IGMC iteratively trains generative models, adding their output to the dataset,
to compute the posterior distribution of the expectation of a random variable.
We provide a theoretical guarantee of the convergence rate of IGMC relative to
the sample size and sampling depth. Due to its compatibility with deep
generative approaches, IGMC is adaptable to both neural network classification
and regression tasks. We empirically study the behavior of IGMC on the MNIST
digit classification task.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning. (arXiv:2310.09478v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09478">http://arxiv.org/abs/2310.09478</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09478]] MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning(http://arxiv.org/abs/2310.09478)</code></li>
<li>Summary: <p>Large language models have shown their remarkable capabilities as a general
interface for various language-related applications. Motivated by this, we
target to build a unified interface for completing many vision-language tasks
including image description, visual question answering, and visual grounding,
among others. The challenge is to use a single model for performing diverse
vision-language tasks effectively with simple multi-modal instructions. Towards
this objective, we introduce MiniGPT-v2, a model that can be treated as a
unified interface for better handling various vision-language tasks. We propose
using unique identifiers for different tasks when training the model. These
identifiers enable our model to better distinguish each task instruction
effortlessly and also improve the model learning efficiency for each task.
After the three-stage training, the experimental results show that MiniGPT-v2
achieves strong performance on many visual question-answering and visual
grounding benchmarks compared to other vision-language generalist models. Our
model and codes are available at https://minigpt-v2.github.io/
</p></li>
</ul>

<h3>Title: JM3D & JM3D-LLM: Elevating 3D Representation with Joint Multi-modal Cues. (arXiv:2310.09503v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09503">http://arxiv.org/abs/2310.09503</a></li>
<li>Code URL: https://github.com/mr-neko/jm3d</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09503]] JM3D & JM3D-LLM: Elevating 3D Representation with Joint Multi-modal Cues(http://arxiv.org/abs/2310.09503)</code></li>
<li>Summary: <p>The rising importance of 3D representation learning, pivotal in computer
vision, autonomous driving, and robotics, is evident. However, a prevailing
trend, which straightforwardly resorted to transferring 2D alignment strategies
to the 3D domain, encounters three distinct challenges: (1) Information
Degradation: This arises from the alignment of 3D data with mere single-view 2D
images and generic texts, neglecting the need for multi-view images and
detailed subcategory texts. (2) Insufficient Synergy: These strategies align 3D
representations to image and text features individually, hampering the overall
optimization for 3D models. (3) Underutilization: The fine-grained information
inherent in the learned representations is often not fully exploited,
indicating a potential loss in detail. To address these issues, we introduce
JM3D, a comprehensive approach integrating point cloud, text, and image. Key
contributions include the Structured Multimodal Organizer (SMO), enriching
vision-language representation with multiple views and hierarchical text, and
the Joint Multi-modal Alignment (JMA), combining language understanding with
visual representation. Our advanced model, JM3D-LLM, marries 3D representation
with large language models via efficient fine-tuning. Evaluations on ModelNet40
and ScanObjectNN establish JM3D's superiority. The superior performance of
JM3D-LLM further underscores the effectiveness of our representation transfer
approach. Our code and models are available at https://github.com/Mr-Neko/JM3D.
</p></li>
</ul>

<h3>Title: Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents. (arXiv:2310.09343v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09343">http://arxiv.org/abs/2310.09343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09343]] Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents(http://arxiv.org/abs/2310.09343)</code></li>
<li>Summary: <p>Human-like chatbots necessitate the use of commonsense reasoning in order to
effectively comprehend and respond to implicit information present within
conversations. Achieving such coherence and informativeness in responses,
however, is a non-trivial task. Even for large language models (LLMs), the task
of identifying and aggregating key evidence within a single hop presents a
substantial challenge. This complexity arises because such evidence is
scattered across multiple turns in a conversation, thus necessitating
integration over multiple hops. Hence, our focus is to facilitate such
multi-hop reasoning over a dialogue context, namely dialogue chain-of-thought
(CoT) reasoning. To this end, we propose a knowledge distillation framework
that leverages LLMs as unreliable teachers and selectively distills consistent
and helpful rationales via alignment filters. We further present DOCTOR, a
DialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for
response generation. We conduct extensive experiments to show that enhancing
dialogue agents with high-quality rationales from DOCTOR significantly improves
the quality of their responses.
</p></li>
</ul>

<h3>Title: Unsupervised Domain Adaption for Neural Information Retrieval. (arXiv:2310.09350v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09350">http://arxiv.org/abs/2310.09350</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09350]] Unsupervised Domain Adaption for Neural Information Retrieval(http://arxiv.org/abs/2310.09350)</code></li>
<li>Summary: <p>Neural information retrieval requires costly annotated data for each target
domain to be competitive. Synthetic annotation by query generation using Large
Language Models or rule-based string manipulation has been proposed as an
alternative, but their relative merits have not been analysed. In this paper,
we compare both methods head-to-head using the same neural IR architecture. We
focus on the BEIR benchmark, which includes test datasets from several domains
with no training data, and explore two scenarios: zero-shot, where the
supervised system is trained in a large out-of-domain dataset (MS-MARCO); and
unsupervised domain adaptation, where, in addition to MS-MARCO, the system is
fine-tuned in synthetic data from the target domain. Our results indicate that
Large Language Models outperform rule-based methods in all scenarios by a large
margin, and, more importantly, that unsupervised domain adaptation is effective
compared to applying a supervised IR system in a zero-shot fashion. In addition
we explore several sizes of open Large Language Models to generate synthetic
data and find that a medium-sized model suffices. Code and models are publicly
available for reproducibility.
</p></li>
</ul>

<h3>Title: A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks. (arXiv:2310.09430v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09430">http://arxiv.org/abs/2310.09430</a></li>
<li>Code URL: https://github.com/strong-ai-lab/logical-and-abstract-reasoning</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09430]] A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks(http://arxiv.org/abs/2310.09430)</code></li>
<li>Summary: <p>Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly
advanced the performance of artificial systems on various natural language
processing tasks to human-like levels. However, their generalisation and
robustness to perform logical reasoning remain under-evaluated. To probe this
ability, we propose three new logical reasoning datasets named "ReClor-plus",
"LogiQA-plus" and "LogiQAv2-plus", each featuring three subsets: the first with
randomly shuffled options, the second with the correct choices replaced by
"none of the other options are correct", and a combination of the previous two
subsets. We carry out experiments on these datasets with both discriminative
and generative LLMs and show that these simple tricks greatly hinder the
performance of the language models. Despite their superior performance on the
original publicly available datasets, we find that all models struggle to
answer our newly constructed datasets. We show that introducing task variations
by perturbing a sizable training set can markedly improve the model's
generalisation and robustness in logical reasoning tasks. Moreover, applying
logic-driven data augmentation for fine-tuning, combined with prompting can
enhance the generalisation performance of both discriminative large language
models and generative large language models. These results offer insights into
assessing and improving the generalisation and robustness of large language
models for logical reasoning tasks. We make our source code and data publicly
available
\url{https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning}.
</p></li>
</ul>

<h3>Title: One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models. (arXiv:2310.09499v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09499">http://arxiv.org/abs/2310.09499</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09499]] One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models(http://arxiv.org/abs/2310.09499)</code></li>
<li>Summary: <p>Various Large Language Models(LLMs) from the Generative Pretrained
Transformer~(GPT) family have achieved outstanding performances in a wide range
of text generation tasks. However, the enormous model sizes have hindered their
practical use in real-world applications due to high inference latency.
Therefore, improving the efficiencies of LLMs through quantization, pruning,
and other means has been a key issue in LLM studies. In this work, we propose a
method based on Hessian sensitivity-aware mixed sparsity pruning to prune LLMs
to at least 50\% sparsity without the need of any retraining. It allocates
sparsity adaptively based on sensitivity, allowing us to reduce pruning-induced
error while maintaining the overall sparsity level. The advantages of the
proposed method exhibit even more when the sparsity is extremely high.
Furthermore, our method is compatible with quantization, enabling further
compression of LLMs.
</p></li>
</ul>

<h3>Title: Instruction Tuning with Human Curriculum. (arXiv:2310.09518v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09518">http://arxiv.org/abs/2310.09518</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09518]] Instruction Tuning with Human Curriculum(http://arxiv.org/abs/2310.09518)</code></li>
<li>Summary: <p>The dominant paradigm for instruction tuning is the random-shuffled training
of maximally diverse instruction-response pairs. This paper explores the
potential benefits of applying a structured cognitive learning approach to
instruction tuning in contemporary large language models like ChatGPT and
GPT-4. Unlike the previous conventional randomized instruction dataset, we
propose a highly structured synthetic dataset that mimics the progressive and
organized nature of human education. We curate our dataset by aligning it with
educational frameworks, incorporating meta information including its topic and
cognitive rigor level for each sample. Our dataset covers comprehensive
fine-grained topics spanning diverse educational stages (from middle school to
graduate school) with various questions for each topic to enhance conceptual
depth using Bloom's taxonomy-a classification framework distinguishing various
levels of human cognition for each concept. The results demonstrate that this
cognitive rigorous training approach yields significant performance
enhancements - +3.06 on the MMLU benchmark and an additional +1.28 on AI2
Reasoning Challenge (hard set) - compared to conventional randomized training,
all while avoiding additional computational costs. This research highlights the
potential of leveraging human learning principles to enhance the capabilities
of language models in comprehending and responding to complex instructions and
tasks.
</p></li>
</ul>

<h2>segmentation</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
