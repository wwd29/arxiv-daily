<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Fused Classification For Differential Face Morphing Detection. (arXiv:2309.00665v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.00665">http://arxiv.org/abs/2309.00665</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.00665]] Fused Classification For Differential Face Morphing Detection(http://arxiv.org/abs/2309.00665)</code></li>
<li>Summary: <p>Face morphing, a sophisticated presentation attack technique, poses
significant security risks to face recognition systems. Traditional methods
struggle to detect morphing attacks, which involve blending multiple face
images to create a synthetic image that can match different individuals. In
this paper, we focus on the differential detection of face morphing and propose
an extended approach based on fused classification method for no-reference
scenario. We introduce a public face morphing detection benchmark for the
differential scenario and utilize a specific data mining technique to enhance
the performance of our approach. Experimental results demonstrate the
effectiveness of our method in detecting morphing attacks.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: The Use of Synthetic Data to Train AI Models: Opportunities and Risks for Sustainable Development. (arXiv:2309.00652v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.00652">http://arxiv.org/abs/2309.00652</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.00652]] The Use of Synthetic Data to Train AI Models: Opportunities and Risks for Sustainable Development(http://arxiv.org/abs/2309.00652)</code></li>
<li>Summary: <p>In the current data driven era, synthetic data, artificially generated data
that resembles the characteristics of real world data without containing actual
personal information, is gaining prominence. This is due to its potential to
safeguard privacy, increase the availability of data for research, and reduce
bias in machine learning models. This paper investigates the policies governing
the creation, utilization, and dissemination of synthetic data. Synthetic data
can be a powerful instrument for protecting the privacy of individuals, but it
also presents challenges, such as ensuring its quality and authenticity. A well
crafted synthetic data policy must strike a balance between privacy concerns
and the utility of data, ensuring that it can be utilized effectively without
compromising ethical or legal standards. Organizations and institutions must
develop standardized guidelines and best practices in order to capitalize on
the benefits of synthetic data while addressing its inherent challenges.
</p></li>
</ul>

<h3>Title: Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic Learning. (arXiv:2309.00688v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.00688">http://arxiv.org/abs/2309.00688</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.00688]] Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic Learning(http://arxiv.org/abs/2309.00688)</code></li>
<li>Summary: <p>Federated and Continual Learning have emerged as potential paradigms for the
robust and privacy-aware use of Deep Learning in dynamic environments. However,
Client Drift and Catastrophic Forgetting are fundamental obstacles to
guaranteeing consistent performance. Existing work only addresses these
problems separately, which neglects the fact that the root cause behind both
forms of performance deterioration is connected. We propose a unified analysis
framework for building a controlled test environment for Client Drift -- by
perturbing a defined ratio of clients -- and Catastrophic Forgetting -- by
shifting all clients with a particular strength. Our framework further
leverages this new combined analysis by generating a 3D landscape of the
combined performance impact from both. We demonstrate that the performance drop
through Client Drift, caused by a certain share of shifted clients, is
correlated to the drop from Catastrophic Forgetting resulting from a
corresponding shift strength. Correlation tests between both problems for
Computer Vision (CelebA) and Medical Imaging (PESO) support this new
perspective, with an average Pearson rank correlation coefficient of over 0.94.
Our framework's novel ability of combined spatio-temporal shift analysis allows
us to investigate how both forms of distribution shift behave in mixed
scenarios, opening a new pathway for better generalization. We show that a
combination of moderate Client Drift and Catastrophic Forgetting can even
improve the performance of the resulting model (causing a "Generalization
Bump") compared to when only one of the shifts occurs individually. We apply a
simple and commonly used method from Continual Learning in the federated
setting and observe this phenomenon to be reoccurring, leveraging the ability
of our framework to analyze existing and novel methods for Federated and
Continual Learning.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Cross-temporal Detection of Novel Ransomware Campaigns: A Multi-Modal Alert Approach. (arXiv:2309.00700v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.00700">http://arxiv.org/abs/2309.00700</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.00700]] Cross-temporal Detection of Novel Ransomware Campaigns: A Multi-Modal Alert Approach(http://arxiv.org/abs/2309.00700)</code></li>
<li>Summary: <p>We present a novel approach to identify ransomware campaigns derived from
attack timelines representations within victim networks. Malicious activity
profiles developed from multiple alert sources support the construction of
alert graphs. This approach enables an effective and scalable representation of
the attack timelines where individual nodes represent malicious activity
detections with connections describing the potential attack paths. This work
demonstrates adaptability to different attack patterns through implementing a
novel method for parsing and classifying alert graphs while maintaining
efficacy despite potentially low-dimension node features.
</p></li>
</ul>

<h2>robust</h2>
<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: AAN: Attributes-Aware Network for Temporal Action Detection. (arXiv:2309.00696v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.00696">http://arxiv.org/abs/2309.00696</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.00696]] AAN: Attributes-Aware Network for Temporal Action Detection(http://arxiv.org/abs/2309.00696)</code></li>
<li>Summary: <p>The challenge of long-term video understanding remains constrained by the
efficient extraction of object semantics and the modelling of their
relationships for downstream tasks. Although the CLIP visual features exhibit
discriminative properties for various vision tasks, particularly in object
encoding, they are suboptimal for long-term video understanding. To address
this issue, we present the Attributes-Aware Network (AAN), which consists of
two key components: the Attributes Extractor and a Graph Reasoning block. These
components facilitate the extraction of object-centric attributes and the
modelling of their relationships within the video. By leveraging CLIP features,
AAN outperforms state-of-the-art approaches on two popular action detection
datasets: Charades and Toyota Smarthome Untrimmed datasets.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h2>fair</h2>
<h2>interpretability</h2>
<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h2>generative</h2>
<h2>large language model</h2>
<h3>Title: Extracting Mathematical Concepts with Large Language Models. (arXiv:2309.00642v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.00642">http://arxiv.org/abs/2309.00642</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.00642]] Extracting Mathematical Concepts with Large Language Models(http://arxiv.org/abs/2309.00642)</code></li>
<li>Summary: <p>We extract mathematical concepts from mathematical text using generative
large language models (LLMs) like ChatGPT, contributing to the field of
automatic term extraction (ATE) and mathematical text processing, and also to
the study of LLMs themselves. Our work builds on that of others in that we aim
for automatic extraction of terms (keywords) in one mathematical field,
category theory, using as a corpus the 755 abstracts from a snapshot of the
online journal "Theory and Applications of Categories", circa 2020. Where our
study diverges from previous work is in (1) providing a more thorough analysis
of what makes mathematical term extraction a difficult problem to begin with;
(2) paying close attention to inter-annotator disagreements; (3) providing a
set of guidelines which both human and machine annotators could use to
standardize the extraction process; (4) introducing a new annotation tool to
help humans with ATE, applicable to any mathematical field and even beyond
mathematics; (5) using prompts to ChatGPT as part of the extraction process,
and proposing best practices for such prompts; and (6) raising the question of
whether ChatGPT could be used as an annotator on the same level as human
experts. Our overall findings are that the matter of mathematical ATE is an
interesting field which can benefit from participation by LLMs, but LLMs
themselves cannot at this time surpass human performance on it.
</p></li>
</ul>

<h3>Title: GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice. (arXiv:2309.00649v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.00649">http://arxiv.org/abs/2309.00649</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.00649]] GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice(http://arxiv.org/abs/2309.00649)</code></li>
<li>Summary: <p>We assess the ability of GPT -- a large language model -- to serve as a
financial robo-advisor for the masses, by using a financial literacy test.
Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial
literacy test, respectively, compared to a baseline of 33%. However, ChatGPT
based on GPT-4 achieves a near-perfect 99% score, pointing to financial
literacy becoming an emergent ability of state-of-the-art models. We use the
Judge-Advisor System and a savings dilemma to illustrate how researchers might
assess advice-utilization from large language models. We also present a number
of directions for future research.
</p></li>
</ul>

<h3>Title: Contextual Biasing of Named-Entities with Large Language Models. (arXiv:2309.00723v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.00723">http://arxiv.org/abs/2309.00723</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.00723]] Contextual Biasing of Named-Entities with Large Language Models(http://arxiv.org/abs/2309.00723)</code></li>
<li>Summary: <p>This paper studies contextual biasing with Large Language Models (LLMs),
where during second-pass rescoring additional contextual information is
provided to a LLM to boost Automatic Speech Recognition (ASR) performance. We
propose to leverage prompts for a LLM without fine tuning during rescoring
which incorporate a biasing list and few-shot examples to serve as additional
information when calculating the score for the hypothesis. In addition to
few-shot prompt learning, we propose multi-task training of the LLM to predict
both the entity class and the next token. To improve the efficiency for
contextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we
propose dynamic prompting, where we select the most likely class using the
class tag prediction, and only use entities in this class as contexts for next
token prediction. Word Error Rate (WER) evaluation is performed on i) an
internal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli
dataset. Results indicate that biasing lists and few-shot examples can achieve
17.8% and 9.6% relative improvement compared to first pass ASR, and that
multi-task training and dynamic prompting can achieve 20.0% and 11.3% relative
WER improvement, respectively.
</p></li>
</ul>

<h2>segmentation</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
