<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Design and Analysis of Pairing-Friendly Elliptic Curves for Cryptographic Primitives. (arXiv:2307.09610v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09610">http://arxiv.org/abs/2307.09610</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09610] Design and Analysis of Pairing-Friendly Elliptic Curves for Cryptographic Primitives](http://arxiv.org/abs/2307.09610) #secure</code></li>
<li>Summary: <p>Elliptic curve cryptography (ECC) is a remarkable mathematical tool that
offers the same level of security as traditional public-key cryptography (PKC)
with a significantly smaller key size and lower computational requirements. The
use of pairing on elliptic curves has emerged as a vibrant field of research
that provides enhanced security measures for the next generation of
cryptographic systems. This thesis explores using ECC and Pairing-Based
Cryptosystems (PBC) as effective mathematical tools for achieving high-security
levels with minimal key size and computation cost. Specifically, the research
aims to analyze Pairing-Friendly Elliptic Curves (PF-EC) and their practicality
in resource-constrained environments. It proposes solutions to some of the
limitations of existing applications of pairing-based cryptography. The thesis
begins by presenting a comprehensive framework for constructing PF-EC and
evaluating the practical security of several families of pairing-friendly
curves. The study then explores the limitations of Identity-Based Encryption
(IBE), a recognized application of pairing-based cryptography. It proposes
mechanisms to address issues such as key escrow, secure key issuing, user
slandering, and key abusing problems. The proposed solutions include an
Escrow-Free Identity-Based Encryption (EF-IBE) scheme secured against
confidentiality and an Escrow-Free Identity-Based Signature (EF-IBS) scheme
that is forgeable and secure.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Leveraging Visemes for Better Visual Speech Representation and Lip Reading. (arXiv:2307.10157v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10157">http://arxiv.org/abs/2307.10157</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10157] Leveraging Visemes for Better Visual Speech Representation and Lip Reading](http://arxiv.org/abs/2307.10157) #security</code></li>
<li>Summary: <p>Lip reading is a challenging task that has many potential applications in
speech recognition, human-computer interaction, and security systems. However,
existing lip reading systems often suffer from low accuracy due to the
limitations of video features. In this paper, we propose a novel approach that
leverages visemes, which are groups of phonetically similar lip shapes, to
extract more discriminative and robust video features for lip reading. We
evaluate our approach on various tasks, including word-level and sentence-level
lip reading, and audiovisual speech recognition using the Arman-AV dataset, a
largescale Persian corpus. Our experimental results show that our viseme based
approach consistently outperforms the state-of-theart methods in all these
tasks. The proposed method reduces the lip-reading word error rate (WER) by
9.1% relative to the best previous method.
</p></li>
</ul>

<h3>Title: Dead Man's PLC: Towards Viable Cyber Extortion for Operational Technology. (arXiv:2307.09549v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09549">http://arxiv.org/abs/2307.09549</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09549] Dead Man's PLC: Towards Viable Cyber Extortion for Operational Technology](http://arxiv.org/abs/2307.09549) #security</code></li>
<li>Summary: <p>For decades, operational technology (OT) has enjoyed the luxury of being
suitably inaccessible so as to experience directly targeted cyber attacks from
only the most advanced and well-resourced adversaries. However, security via
obscurity cannot last forever, and indeed a shift is happening whereby less
advanced adversaries are showing an appetite for targeting OT. With this shift
in adversary demographics, there will likely also be a shift in attack goals,
from clandestine process degradation and espionage to overt cyber extortion
(Cy-X). The consensus from OT cyber security practitioners suggests that, even
if encryption-based Cy-X techniques were launched against OT assets, typical
recovery practices designed for engineering processes would provide adequate
resilience. In response, this paper introduces Dead Man's PLC (DM-PLC), a
pragmatic step towards viable OT Cy-X that acknowledges and weaponises the
resilience processes typically encountered. Using only existing functionality,
DM-PLC considers an entire environment as the entity under ransom, whereby all
assets constantly poll one another to ensure the attack remains untampered,
treating any deviations as a detonation trigger akin to a Dead Man's switch. A
proof of concept of DM-PLC is implemented and evaluated on an academically peer
reviewed and industry validated OT testbed to demonstrate its malicious
efficacy.
</p></li>
</ul>

<h3>Title: EPUF: A Novel Scheme Based on Entropy Features of Latency-based DRAM PUFs Providing Lightweight Authentication in IoT Networks. (arXiv:2307.09968v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09968">http://arxiv.org/abs/2307.09968</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09968] EPUF: A Novel Scheme Based on Entropy Features of Latency-based DRAM PUFs Providing Lightweight Authentication in IoT Networks](http://arxiv.org/abs/2307.09968) #security</code></li>
<li>Summary: <p>Physical unclonable functions (PUFs) are hardware-oriented primitives that
exploit manufacturing variations to generate a unique identity for a physical
system. Recent advancements showed how DRAM can be exploited to implement PUFs.
DRAM PUFs require no additional circuits for PUF operations and can be used in
most of the applications with resource-constrained nodes such as Internet of
Things (IoT) networks. However, the existing DRAM PUF solutions either require
to interrupt other functions in the host system, or provide unreliable
responses due to their sensitiveness to the environmental conditions.
</p></li>
</ul>

<p>In this paper, we propose EPUF, a novel strategy to extract random and unique
features from DRAM cells to generate reliable PUF responses. In particular, we
use the bitmap images of the binary DRAM values and their entropy features. We
show via real device experiments that EPUF is approximately $1.7$ times faster
than other state of the art solutions, achieves $100\%$ reliability, generates
features with $47.79\%$ uniqueness, and supports a large set of CRP that leads
to new potentials for DRAM PUF-based authentication. We also propose a
lightweight authentication protocol based on EPUF, which not only provides far
better security guarantees but also outperforms the state-of-the-art in terms
of communication overhead and computational cost.
</p>

<h2>privacy</h2>
<h3>Title: TinyTrain: Deep Neural Network Training at the Extreme Edge. (arXiv:2307.09988v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09988">http://arxiv.org/abs/2307.09988</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09988] TinyTrain: Deep Neural Network Training at the Extreme Edge](http://arxiv.org/abs/2307.09988) #privacy</code></li>
<li>Summary: <p>On-device training is essential for user personalisation and privacy. With
the pervasiveness of IoT devices and microcontroller units (MCU), this task
becomes more challenging due to the constrained memory and compute resources,
and the limited availability of labelled user data. Nonetheless, prior works
neglect the data scarcity issue, require excessively long training time (e.g. a
few hours), or induce substantial accuracy loss ($\geq$10\%). We propose
TinyTrain, an on-device training approach that drastically reduces training
time by selectively updating parts of the model and explicitly coping with data
scarcity. TinyTrain introduces a task-adaptive sparse-update method that
dynamically selects the layer/channel based on a multi-objective criterion that
jointly captures user data, the memory, and the compute capabilities of the
target device, leading to high accuracy on unseen tasks with reduced
computation and memory footprint. TinyTrain outperforms vanilla fine-tuning of
the entire network by 3.6-5.0\% in accuracy, while reducing the backward-pass
memory and computation cost by up to 2,286$\times$ and 7.68$\times$,
respectively. Targeting broadly used real-world edge devices, TinyTrain
achieves 9.5$\times$ faster and 3.5$\times$ more energy-efficient training over
status-quo approaches, and 2.8$\times$ smaller memory footprint than SOTA
approaches, while remaining within the 1 MB memory envelope of MCU-grade
platforms.
</p></li>
</ul>

<h3>Title: Privacy Preserving Billing in Local Energy Markets with Imperfect Bid-Offer Fulfillment (Long Version). (arXiv:2307.09618v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09618">http://arxiv.org/abs/2307.09618</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09618] Privacy Preserving Billing in Local Energy Markets with Imperfect Bid-Offer Fulfillment (Long Version)](http://arxiv.org/abs/2307.09618) #privacy</code></li>
<li>Summary: <p>Smart grids are being increasingly deployed worldwide, as they constitute the
electricity grid of the future, providing bidirectional communication between
households. One of their main potential applications is the peer-to-peer (P2P)
energy trading market, which promises users better electricity prices and
higher incentives to produce renewable energy. However, most P2P markets
require users to submit energy bids/offers in advance, which cannot account for
unexpected surpluses of energy consumption/production. Moreover, the
fine-grained metering information used in calculating and settling
bills/rewards is inherently sensitive and must be protected in conformity with
existing privacy regulations.
</p></li>
</ul>

<p>To address these issues, this report proposes a novel privacy-preserving
billing and settlements protocol, PPBSP, for use in local energy markets with
imperfect bid-offer fulfillment, which only uses homomorphically encrypted
versions of the half-hourly user consumption data. PPBSP also supports various
cost-sharing mechanisms among market participants, including two new and
improved methods of proportionally redistributing the cost of maintaining the
balance of the grid in a fair manner. An informal privacy analysis is
performed, highlighting the privacy-enhancing characteristics of the protocol,
which include metering data and bill confidentiality. PPBSP is also evaluated
in terms of computation cost and communication overhead, demonstrating its
efficiency and feasibility for markets with varying sizes.
</p>

<h2>protect</h2>
<h3>Title: Automating Wood Species Detection and Classification in Microscopic Images of Fibrous Materials with Deep Learning. (arXiv:2307.09588v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09588">http://arxiv.org/abs/2307.09588</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09588] Automating Wood Species Detection and Classification in Microscopic Images of Fibrous Materials with Deep Learning](http://arxiv.org/abs/2307.09588) #protect</code></li>
<li>Summary: <p>We have developed a methodology for the systematic generation of a large
image dataset of macerated wood references, which we used to generate image
data for nine hardwood genera. This is the basis for a substantial approach to
automate, for the first time, the identification of hardwood species in
microscopic images of fibrous materials by deep learning. Our methodology
includes a flexible pipeline for easy annotation of vessel elements. We compare
the performance of different neural network architectures and hyperparameters.
Our proposed method performs similarly well to human experts. In the future,
this will improve controls on global wood fiber product flows to protect
forests.
</p></li>
</ul>

<h3>Title: Application of BadNets in Spam Filters. (arXiv:2307.09649v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09649">http://arxiv.org/abs/2307.09649</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09649] Application of BadNets in Spam Filters](http://arxiv.org/abs/2307.09649) #protect</code></li>
<li>Summary: <p>Spam filters are a crucial component of modern email systems, as they help to
protect users from unwanted and potentially harmful emails. However, the
effectiveness of these filters is dependent on the quality of the machine
learning models that power them. In this paper, we design backdoor attacks in
the domain of spam filtering. By demonstrating the potential vulnerabilities in
the machine learning model supply chain, we highlight the need for careful
consideration and evaluation of the models used in spam filters. Our results
show that the backdoor attacks can be effectively used to identify
vulnerabilities in spam filters and suggest the need for ongoing monitoring and
improvement in this area.
</p></li>
</ul>

<h3>Title: Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network. (arXiv:2307.09866v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09866">http://arxiv.org/abs/2307.09866</a></li>
<li>Code URL: <a href="https://github.com/tsinghua-fib-lab/kdd2023-id546-urbaninfra">https://github.com/tsinghua-fib-lab/kdd2023-id546-urbaninfra</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09866] Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network](http://arxiv.org/abs/2307.09866) #protect</code></li>
<li>Summary: <p>Understanding and characterizing the vulnerability of urban infrastructures,
which refers to the engineering facilities essential for the regular running of
cities and that exist naturally in the form of networks, is of great value to
us. Potential applications include protecting fragile facilities and designing
robust topologies, etc. Due to the strong correlation between different
topological characteristics and infrastructure vulnerability and their
complicated evolution mechanisms, some heuristic and machine-assisted analysis
fall short in addressing such a scenario. In this paper, we model the
interdependent network as a heterogeneous graph and propose a system based on
graph neural network with reinforcement learning, which can be trained on
real-world data, to characterize the vulnerability of the city system
accurately. The presented system leverages deep learning techniques to
understand and analyze the heterogeneous graph, which enables us to capture the
risk of cascade failure and discover vulnerable infrastructures of cities.
Extensive experiments with various requests demonstrate not only the expressive
power of our system but also transferring ability and necessity of the specific
components.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots. (arXiv:2307.09579v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09579">http://arxiv.org/abs/2307.09579</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09579] Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots](http://arxiv.org/abs/2307.09579) #defense</code></li>
<li>Summary: <p>Recent advances in natural language processing and machine learning have led
to the development of chatbot models, such as ChatGPT, that can engage in
conversational dialogue with human users. However, the ability of these models
to generate toxic or harmful responses during a non-toxic multi-turn
conversation remains an open research question. Existing research focuses on
single-turn sentence testing, while we find that 82\% of the individual
non-toxic sentences that elicit toxic behaviors in a conversation are
considered safe by existing tools. In this paper, we design a new attack,
\toxicbot, by fine-tuning a chatbot to engage in conversation with a target
open-domain chatbot. The chatbot is fine-tuned with a collection of crafted
conversation sequences. Particularly, each conversation begins with a sentence
from a crafted prompt sentences dataset. Our extensive evaluation shows that
open-domain chatbot models can be triggered to generate toxic responses in a
multi-turn conversation. In the best scenario, \toxicbot achieves a 67\%
activation rate. The conversation sequences in the fine-tuning stage help
trigger the toxicity in a conversation, which allows the attack to bypass two
defense methods. Our findings suggest that further research is needed to
address chatbot toxicity in a dynamic interactive environment. The proposed
\toxicbot can be used by both industry and researchers to develop methods for
detecting and mitigating toxic responses in conversational dialogue and improve
the robustness of chatbots for end users.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Co-Simulation Framework For Network Attack Generation and Monitoring. (arXiv:2307.09633v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09633">http://arxiv.org/abs/2307.09633</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09633] Co-Simulation Framework For Network Attack Generation and Monitoring](http://arxiv.org/abs/2307.09633) #attack</code></li>
<li>Summary: <p>Resilience assessment is a critical requirement of a power grid to maintain
high availability, security, and quality of service. Most grid research work
that is currently pursued does not have the capability to have hardware
testbeds. Additionally, with the integration of distributed energy resources,
the attack surface of the grid is increasing. This increases the need for
reliable and realistic modeling techniques that are usable by the wider
research community. Therefore, simulation testbeds have been used to model a
real-world power grid topology and measure the impact of various perturbations.
</p></li>
</ul>

<p>Existing co-simulation platforms for powergrid focus on a limited components
of the overall system, such as focusing only on the dynamics of the physical
layer. Additionally a significant number of existing platforms need specialized
hardware that may be too expensive for most researchers. Finally, not many
platforms support realistic modeling of the communication layer, which requires
use of Supervisory Control and Data Acquisition communication protocol such as
DNP3 while modeling cybersecurity scenarios.
</p>
<p>We present Network Attack Testbed in [Power] Grid (NATI[P]G), (pronounced
natig), a standalone, containerized, and reusable environment to enable cyber
analysts and researchers to run different cybersecurity and performance
scenarios on powergrid. Our tool combines GridLAB-D, a grid simulator, HELICS,
a co-simulation framework, and NS-3, a network simulator, to create an
end-to-end simulation environment for the power grid. We demonstrate use cases
by generating a library of datasets for several scenarios. These datasets can
be used to detect cyberattacks at the cyber layer, and develop counter measures
to these adverse scenarios.
</p>

<h3>Title: Rethinking Backdoor Attacks. (arXiv:2307.10163v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10163">http://arxiv.org/abs/2307.10163</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10163] Rethinking Backdoor Attacks](http://arxiv.org/abs/2307.10163) #attack</code></li>
<li>Summary: <p>In a backdoor attack, an adversary inserts maliciously constructed backdoor
examples into a training set to make the resulting model vulnerable to
manipulation. Defending against such attacks typically involves viewing these
inserted examples as outliers in the training set and using techniques from
robust statistics to detect and remove them.
</p></li>
</ul>

<p>In this work, we present a different approach to the backdoor attack problem.
Specifically, we show that without structural information about the training
data distribution, backdoor attacks are indistinguishable from
naturally-occurring features in the data--and thus impossible to "detect" in a
general sense. Then, guided by this observation, we revisit existing defenses
against backdoor attacks and characterize the (often latent) assumptions they
make and on which they depend. Finally, we explore an alternative perspective
on backdoor attacks: one that assumes these attacks correspond to the strongest
feature in the training data. Under this assumption (which we make formal) we
develop a new primitive for detecting backdoor attacks. Our primitive naturally
gives rise to a detection algorithm that comes with theoretical guarantees and
is effective in practice.
</p>

<h2>robust</h2>
<h3>Title: Towards Robust Scene Text Image Super-resolution via Explicit Location Enhancement. (arXiv:2307.09749v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09749">http://arxiv.org/abs/2307.09749</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09749] Towards Robust Scene Text Image Super-resolution via Explicit Location Enhancement](http://arxiv.org/abs/2307.09749) #robust</code></li>
<li>Summary: <p>Scene text image super-resolution (STISR), aiming to improve image quality
while boosting downstream scene text recognition accuracy, has recently
achieved great success. However, most existing methods treat the foreground
(character regions) and background (non-character regions) equally in the
forward process, and neglect the disturbance from the complex background, thus
limiting the performance. To address these issues, in this paper, we propose a
novel method LEMMA that explicitly models character regions to produce
high-level text-specific guidance for super-resolution. To model the location
of characters effectively, we propose the location enhancement module to
extract character region features based on the attention map sequence. Besides,
we propose the multi-modal alignment module to perform bidirectional
visual-semantic alignment to generate high-quality prior guidance, which is
then incorporated into the super-resolution branch in an adaptive manner using
the proposed adaptive fusion module. Experiments on TextZoom and four scene
text recognition benchmarks demonstrate the superiority of our method over
other state-of-the-art methods. Code is available at
https://github.com/csguoh/LEMMA.
</p></li>
</ul>

<h3>Title: Towards Building More Robust Models with Frequency Bias. (arXiv:2307.09763v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09763">http://arxiv.org/abs/2307.09763</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09763] Towards Building More Robust Models with Frequency Bias](http://arxiv.org/abs/2307.09763) #robust</code></li>
<li>Summary: <p>The vulnerability of deep neural networks to adversarial samples has been a
major impediment to their broad applications, despite their success in various
fields. Recently, some works suggested that adversarially-trained models
emphasize the importance of low-frequency information to achieve higher
robustness. While several attempts have been made to leverage this frequency
characteristic, they have all faced the issue that applying low-pass filters
directly to input images leads to irreversible loss of discriminative
information and poor generalizability to datasets with distinct frequency
features. This paper presents a plug-and-play module called the Frequency
Preference Control Module that adaptively reconfigures the low- and
high-frequency components of intermediate feature representations, providing
better utilization of frequency in robust learning. Empirical studies show that
our proposed module can be easily incorporated into any adversarial training
framework, further improving model robustness across different architectures
and datasets. Additionally, experiments were conducted to examine how the
frequency bias of robust models impacts the adversarial training process and
its final robustness, revealing interesting insights.
</p></li>
</ul>

<h3>Title: Fix your downsampling ASAP! Be natively more robust via Aliasing and Spectral Artifact free Pooling. (arXiv:2307.09804v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09804">http://arxiv.org/abs/2307.09804</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09804] Fix your downsampling ASAP! Be natively more robust via Aliasing and Spectral Artifact free Pooling](http://arxiv.org/abs/2307.09804) #robust</code></li>
<li>Summary: <p>Convolutional neural networks encode images through a sequence of
convolutions, normalizations and non-linearities as well as downsampling
operations into potentially strong semantic embeddings. Yet, previous work
showed that even slight mistakes during sampling, leading to aliasing, can be
directly attributed to the networks' lack in robustness. To address such issues
and facilitate simpler and faster adversarial training, [12] recently proposed
FLC pooling, a method for provably alias-free downsampling - in theory. In this
work, we conduct a further analysis through the lens of signal processing and
find that such current pooling methods, which address aliasing in the frequency
domain, are still prone to spectral leakage artifacts. Hence, we propose
aliasing and spectral artifact-free pooling, short ASAP. While only introducing
a few modifications to FLC pooling, networks using ASAP as downsampling method
exhibit higher native robustness against common corruptions, a property that
FLC pooling was missing. ASAP also increases native robustness against
adversarial attacks on high and low resolution data while maintaining similar
clean accuracy or even outperforming the baseline.
</p></li>
</ul>

<h3>Title: ProtoCaps: A Fast and Non-Iterative Capsule Network Routing Method. (arXiv:2307.09944v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09944">http://arxiv.org/abs/2307.09944</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09944] ProtoCaps: A Fast and Non-Iterative Capsule Network Routing Method](http://arxiv.org/abs/2307.09944) #robust</code></li>
<li>Summary: <p>Capsule Networks have emerged as a powerful class of deep learning
architectures, known for robust performance with relatively few parameters
compared to Convolutional Neural Networks (CNNs). However, their inherent
efficiency is often overshadowed by their slow, iterative routing mechanisms
which establish connections between Capsule layers, posing computational
challenges resulting in an inability to scale. In this paper, we introduce a
novel, non-iterative routing mechanism, inspired by trainable prototype
clustering. This innovative approach aims to mitigate computational complexity,
while retaining, if not enhancing, performance efficacy. Furthermore, we
harness a shared Capsule subspace, negating the need to project each
lower-level Capsule to each higher-level Capsule, thereby significantly
reducing memory requisites during training. Our approach demonstrates superior
results compared to the current best non-iterative Capsule Network and tests on
the Imagewoof dataset, which is too computationally demanding to handle
efficiently by iterative approaches. Our findings underscore the potential of
our proposed methodology in enhancing the operational efficiency and
performance of Capsule Networks, paving the way for their application in
increasingly complex computational scenarios.
</p></li>
</ul>

<h3>Title: Deteksi Sampah di Permukaan dan Dalam Perairan pada Objek Video dengan Metode Robust and Efficient Post-Processing dan Tubelet-Level Bounding Box Linking. (arXiv:2307.10039v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10039">http://arxiv.org/abs/2307.10039</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10039] Deteksi Sampah di Permukaan dan Dalam Perairan pada Objek Video dengan Metode Robust and Efficient Post-Processing dan Tubelet-Level Bounding Box Linking](http://arxiv.org/abs/2307.10039) #robust</code></li>
<li>Summary: <p>Indonesia, as a maritime country, has a significant portion of its territory
covered by water. Ineffective waste management has resulted in a considerable
amount of trash in Indonesian waters, leading to various issues. The
development of an automated trash-collecting robot can be a solution to address
this problem. The robot requires a system capable of detecting objects in
motion, such as in videos. However, using naive object detection methods in
videos has limitations, particularly when image focus is reduced and the target
object is obstructed by other objects. This paper's contribution provides an
explanation of the methods that can be applied to perform video object
detection in an automated trash-collecting robot. The study utilizes the YOLOv5
model and the Robust &amp; Efficient Post Processing (REPP) method, along with
tubelet-level bounding box linking on the FloW and Roboflow datasets. The
combination of these methods enhances the performance of naive object detection
from YOLOv5 by considering the detection results in adjacent frames. The
results show that the post-processing stage and tubelet-level bounding box
linking can improve the quality of detection, achieving approximately 3% better
performance compared to YOLOv5 alone. The use of these methods has the
potential to detect surface and underwater trash and can be applied to a
real-time image-based trash-collecting robot. Implementing this system is
expected to mitigate the damage caused by trash in the past and improve
Indonesia's waste management system in the future.
</p></li>
</ul>

<h3>Title: DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering. (arXiv:2307.10173v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10173">http://arxiv.org/abs/2307.10173</a></li>
<li>Code URL: <a href="https://github.com/DNA-Rendering/DNA-Rendering">https://github.com/DNA-Rendering/DNA-Rendering</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10173] DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering](http://arxiv.org/abs/2307.10173) #robust</code></li>
<li>Summary: <p>Realistic human-centric rendering plays a key role in both computer vision
and computer graphics. Rapid progress has been made in the algorithm aspect
over the years, yet existing human-centric rendering datasets and benchmarks
are rather impoverished in terms of diversity, which are crucial for rendering
effect. Researchers are usually constrained to explore and evaluate a small set
of rendering problems on current datasets, while real-world applications
require methods to be robust across different scenarios. In this work, we
present DNA-Rendering, a large-scale, high-fidelity repository of human
performance data for neural actor rendering. DNA-Rendering presents several
alluring attributes. First, our dataset contains over 1500 human subjects, 5000
motion sequences, and 67.5M frames' data volume. Second, we provide rich assets
for each subject -- 2D/3D human body keypoints, foreground masks, SMPLX models,
cloth/accessory materials, multi-view images, and videos. These assets boost
the current method's accuracy on downstream rendering tasks. Third, we
construct a professional multi-view system to capture data, which contains 60
synchronous cameras with max 4096 x 3000 resolution, 15 fps speed, and stern
camera calibration steps, ensuring high-quality resources for task training and
evaluation. Along with the dataset, we provide a large-scale and quantitative
benchmark in full-scale, with multiple tasks to evaluate the existing progress
of novel view synthesis, novel pose animation synthesis, and novel identity
rendering methods. In this manuscript, we describe our DNA-Rendering effort as
a revealing of new observations, challenges, and future directions to
human-centric rendering. The dataset, code, and benchmarks will be publicly
available at https://dna-rendering.github.io/
</p></li>
</ul>

<h3>Title: Android in the Wild: A Large-Scale Dataset for Android Device Control. (arXiv:2307.10088v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10088">http://arxiv.org/abs/2307.10088</a></li>
<li>Code URL: <a href="https://github.com/google-research/google-research">https://github.com/google-research/google-research</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10088] Android in the Wild: A Large-Scale Dataset for Android Device Control](http://arxiv.org/abs/2307.10088) #robust</code></li>
<li>Summary: <p>There is a growing interest in device-control systems that can interpret
human natural language instructions and execute them on a digital device by
directly controlling its user interface. We present a dataset for
device-control research, Android in the Wild (AITW), which is orders of
magnitude larger than current datasets. The dataset contains human
demonstrations of device interactions, including the screens and actions, and
corresponding natural language instructions. It consists of 715k episodes
spanning 30k unique instructions, four versions of Android (v10-13),and eight
device types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It
contains multi-step tasks that require semantic understanding of language and
visual context. This dataset poses a new challenge: actions available through
the user interface must be inferred from their visual appearance. And, instead
of simple UI element-based actions, the action space consists of precise
gestures (e.g., horizontal scrolls to operate carousel widgets). We organize
our dataset to encourage robustness analysis of device-control systems, i.e.,
how well a system performs in the presence of new task descriptions, new
applications, or new platform versions. We develop two agents and report
performance across the dataset. The dataset is available at
https://github.com/google-research/google-research/tree/master/android_in_the_wild.
</p></li>
</ul>

<h3>Title: Promoting Exploration in Memory-Augmented Adam using Critical Momenta. (arXiv:2307.09638v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09638">http://arxiv.org/abs/2307.09638</a></li>
<li>Code URL: <a href="https://github.com/chandar-lab/cmoptimizer">https://github.com/chandar-lab/cmoptimizer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09638] Promoting Exploration in Memory-Augmented Adam using Critical Momenta](http://arxiv.org/abs/2307.09638) #robust</code></li>
<li>Summary: <p>Adaptive gradient-based optimizers, particularly Adam, have left their mark
in training large-scale deep learning models. The strength of such optimizers
is that they exhibit fast convergence while being more robust to hyperparameter
choice. However, they often generalize worse than non-adaptive methods. Recent
studies have tied this performance gap to flat minima selection: adaptive
methods tend to find solutions in sharper basins of the loss landscape, which
in turn hurts generalization. To overcome this issue, we propose a new
memory-augmented version of Adam that promotes exploration towards flatter
minima by using a buffer of critical momentum terms during training.
Intuitively, the use of the buffer makes the optimizer overshoot outside the
basin of attraction if it is not wide enough. We empirically show that our
method improves the performance of several variants of Adam on standard
supervised language modelling and image classification tasks.
</p></li>
</ul>

<h3>Title: Contextual Reliability: When Different Features Matter in Different Contexts. (arXiv:2307.10026v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10026">http://arxiv.org/abs/2307.10026</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10026] Contextual Reliability: When Different Features Matter in Different Contexts](http://arxiv.org/abs/2307.10026) #robust</code></li>
<li>Summary: <p>Deep neural networks often fail catastrophically by relying on spurious
correlations. Most prior work assumes a clear dichotomy into spurious and
reliable features; however, this is often unrealistic. For example, most of the
time we do not want an autonomous car to simply copy the speed of surrounding
cars -- we don't want our car to run a red light if a neighboring car does so.
However, we cannot simply enforce invariance to next-lane speed, since it could
provide valuable information about an unobservable pedestrian at a crosswalk.
Thus, universally ignoring features that are sometimes (but not always)
reliable can lead to non-robust performance. We formalize a new setting called
contextual reliability which accounts for the fact that the "right" features to
use may vary depending on the context. We propose and analyze a two-stage
framework called Explicit Non-spurious feature Prediction (ENP) which first
identifies the relevant features to use for a given context, then trains a
model to rely exclusively on these features. Our work theoretically and
empirically demonstrates the advantages of ENP over existing methods and
provides new benchmarks for contextual reliability.
</p></li>
</ul>

<h3>Title: LightPath: Lightweight and Scalable Path Representation Learning. (arXiv:2307.10171v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10171">http://arxiv.org/abs/2307.10171</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10171] LightPath: Lightweight and Scalable Path Representation Learning](http://arxiv.org/abs/2307.10171) #robust</code></li>
<li>Summary: <p>Movement paths are used widely in intelligent transportation and smart city
applications. To serve such applications, path representation learning aims to
provide compact representations of paths that enable efficient and accurate
operations when used for different downstream tasks such as path ranking and
travel cost estimation. In many cases, it is attractive that the path
representation learning is lightweight and scalable; in resource-limited
environments and under green computing limitations, it is essential. Yet,
existing path representation learning studies focus on accuracy and pay at most
secondary attention to resource consumption and scalability.
</p></li>
</ul>

<p>We propose a lightweight and scalable path representation learning framework,
termed LightPath, that aims to reduce resource consumption and achieve
scalability without affecting accuracy, thus enabling broader applicability.
More specifically, we first propose a sparse auto-encoder that ensures that the
framework achieves good scalability with respect to path length. Next, we
propose a relational reasoning framework to enable faster training of more
robust sparse path encoders. We also propose global-local knowledge
distillation to further reduce the size and improve the performance of sparse
path encoders. Finally, we report extensive experiments on two real-world
datasets to offer insight into the efficiency, scalability, and effectiveness
of the proposed framework.
</p>

<h2>biometric</h2>
<h3>Title: Hierarchical Spatio-Temporal Representation Learning for Gait Recognition. (arXiv:2307.09856v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09856">http://arxiv.org/abs/2307.09856</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09856] Hierarchical Spatio-Temporal Representation Learning for Gait Recognition](http://arxiv.org/abs/2307.09856) #biometric</code></li>
<li>Summary: <p>Gait recognition is a biometric technique that identifies individuals by
their unique walking styles, which is suitable for unconstrained environments
and has a wide range of applications. While current methods focus on exploiting
body part-based representations, they often neglect the hierarchical
dependencies between local motion patterns. In this paper, we propose a
hierarchical spatio-temporal representation learning (HSTL) framework for
extracting gait features from coarse to fine. Our framework starts with a
hierarchical clustering analysis to recover multi-level body structures from
the whole body to local details. Next, an adaptive region-based motion
extractor (ARME) is designed to learn region-independent motion features. The
proposed HSTL then stacks multiple ARMEs in a top-down manner, with each ARME
corresponding to a specific partition level of the hierarchy. An adaptive
spatio-temporal pooling (ASTP) module is used to capture gait features at
different levels of detail to perform hierarchical feature mapping. Finally, a
frame-level temporal aggregation (FTA) module is employed to reduce redundant
information in gait sequences through multi-scale temporal downsampling.
Extensive experiments on CASIA-B, OUMVLP, GREW, and Gait3D datasets demonstrate
that our method outperforms the state-of-the-art while maintaining a reasonable
balance between model accuracy and complexity.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Looking deeper into interpretable deep learning in neuroimaging: a comprehensive survey. (arXiv:2307.09615v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09615">http://arxiv.org/abs/2307.09615</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09615] Looking deeper into interpretable deep learning in neuroimaging: a comprehensive survey](http://arxiv.org/abs/2307.09615) #extraction</code></li>
<li>Summary: <p>Deep learning (DL) models have been popular due to their ability to learn
directly from the raw data in an end-to-end paradigm, alleviating the concern
of a separate error-prone feature extraction phase. Recent DL-based
neuroimaging studies have also witnessed a noticeable performance advancement
over traditional machine learning algorithms. But the challenges of deep
learning models still exist because of the lack of transparency in these models
for their successful deployment in real-world applications. In recent years,
Explainable AI (XAI) has undergone a surge of developments mainly to get
intuitions of how the models reached the decisions, which is essential for
safety-critical domains such as healthcare, finance, and law enforcement
agencies. While the interpretability domain is advancing noticeably,
researchers are still unclear about what aspect of model learning a post hoc
method reveals and how to validate its reliability. This paper comprehensively
reviews interpretable deep learning models in the neuroimaging domain. Firstly,
we summarize the current status of interpretability resources in general,
focusing on the progression of methods, associated challenges, and opinions.
Secondly, we discuss how multiple recent neuroimaging studies leveraged model
interpretability to capture anatomical and functional brain alterations most
relevant to model predictions. Finally, we discuss the limitations of the
current practices and offer some valuable insights and guidance on how we can
steer our future research directions to make deep learning models substantially
interpretable and thus advance scientific understanding of brain disorders.
</p></li>
</ul>

<h3>Title: Hierarchical Semantic Perceptual Listener Head Video Generation: A High-performance Pipeline. (arXiv:2307.09821v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09821">http://arxiv.org/abs/2307.09821</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09821] Hierarchical Semantic Perceptual Listener Head Video Generation: A High-performance Pipeline](http://arxiv.org/abs/2307.09821) #extraction</code></li>
<li>Summary: <p>In dyadic speaker-listener interactions, the listener's head reactions along
with the speaker's head movements, constitute an important non-verbal semantic
expression together. The listener Head generation task aims to synthesize
responsive listener's head videos based on audios of the speaker and reference
images of the listener. Compared to the Talking-head generation, it is more
challenging to capture the correlation clues from the speaker's audio and
visual information. Following the ViCo baseline scheme, we propose a
high-performance solution by enhancing the hierarchical semantic extraction
capability of the audio encoder module and improving the decoder part, renderer
and post-processing modules. Our solution gets the first place on the official
leaderboard for the track of listening head generation. This paper is a
technical report of ViCo@2023 Conversational Head Generation Challenge in ACM
Multimedia 2023 conference.
</p></li>
</ul>

<h3>Title: GUIDO: A Hybrid Approach to Guideline Discovery &amp; Ordering from Natural Language Texts. (arXiv:2307.09959v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09959">http://arxiv.org/abs/2307.09959</a></li>
<li>Code URL: <a href="https://github.com/nils-freyer/guido">https://github.com/nils-freyer/guido</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09959] GUIDO: A Hybrid Approach to Guideline Discovery &amp; Ordering from Natural Language Texts](http://arxiv.org/abs/2307.09959) #extraction</code></li>
<li>Summary: <p>Extracting workflow nets from textual descriptions can be used to simplify
guidelines or formalize textual descriptions of formal processes like business
processes and algorithms. The task of manually extracting processes, however,
requires domain expertise and effort. While automatic process model extraction
is desirable, annotating texts with formalized process models is expensive.
Therefore, there are only a few machine-learning-based extraction approaches.
Rule-based approaches, in turn, require domain specificity to work well and can
rarely distinguish relevant and irrelevant information in textual descriptions.
In this paper, we present GUIDO, a hybrid approach to the process model
extraction task that first, classifies sentences regarding their relevance to
the process model, using a BERT-based sentence classifier, and second, extracts
a process model from the sentences classified as relevant, using dependency
parsing. The presented approach achieves significantly better results than a
pure rule-based approach. GUIDO achieves an average behavioral similarity score
of $0.93$. Still, in comparison to purely machine-learning-based approaches,
the annotation costs stay low.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Towards Federated Foundation Models: Scalable Dataset Pipelines for Group-Structured Learning. (arXiv:2307.09619v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09619">http://arxiv.org/abs/2307.09619</a></li>
<li>Code URL: <a href="https://github.com/google-research/dataset_grouper">https://github.com/google-research/dataset_grouper</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09619] Towards Federated Foundation Models: Scalable Dataset Pipelines for Group-Structured Learning](http://arxiv.org/abs/2307.09619) #federate</code></li>
<li>Summary: <p>We introduce a library, Dataset Grouper, to create large-scale
group-structured (e.g., federated) datasets, enabling federated learning
simulation at the scale of foundation models. This library allows the creation
of group-structured versions of existing datasets based on user-specified
partitions, and directly leads to a variety of useful heterogeneous datasets
that can be plugged into existing software frameworks. Dataset Grouper offers
three key advantages. First, it scales to settings where even a single group's
dataset is too large to fit in memory. Second, it provides flexibility, both in
choosing the base (non-partitioned) dataset and in defining partitions.
Finally, it is framework-agnostic. We empirically demonstrate that Dataset
Grouper allows for large-scale federated language modeling simulations on
datasets that are orders of magnitude larger than in previous work. Our
experimental results show that algorithms like FedAvg operate more as
meta-learning methods than as empirical risk minimization methods at this
scale, suggesting their utility in downstream personalization and task-specific
adaptation.
</p></li>
</ul>

<h3>Title: Graph Federated Learning Based on the Decentralized Framework. (arXiv:2307.09801v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09801">http://arxiv.org/abs/2307.09801</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09801] Graph Federated Learning Based on the Decentralized Framework](http://arxiv.org/abs/2307.09801) #federate</code></li>
<li>Summary: <p>Graph learning has a wide range of applications in many scenarios, which
require more need for data privacy. Federated learning is an emerging
distributed machine learning approach that leverages data from individual
devices or data centers to improve the accuracy and generalization of the
model, while also protecting the privacy of user data. Graph-federated learning
is mainly based on the classical federated learning framework i.e., the
Client-Server framework. However, the Client-Server framework faces problems
such as a single point of failure of the central server and poor scalability of
network topology. First, we introduce the decentralized framework to
graph-federated learning. Second, determine the confidence among nodes based on
the similarity of data among nodes, subsequently, the gradient information is
then aggregated by linear weighting based on confidence. Finally, the proposed
method is compared with FedAvg, Fedprox, GCFL, and GCFL+ to verify the
effectiveness of the proposed method. Experiments demonstrate that the proposed
method outperforms other methods.
</p></li>
</ul>

<h3>Title: Learner Referral for Cost-Effective Federated Learning Over Hierarchical IoT Networks. (arXiv:2307.09977v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09977">http://arxiv.org/abs/2307.09977</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09977] Learner Referral for Cost-Effective Federated Learning Over Hierarchical IoT Networks](http://arxiv.org/abs/2307.09977) #federate</code></li>
<li>Summary: <p>The paradigm of federated learning (FL) to address data privacy concerns by
locally training parameters on resource-constrained clients in a distributed
manner has garnered significant attention. Nonetheless, FL is not applicable
when not all clients within the coverage of the FL server are registered with
the FL network. To bridge this gap, this paper proposes joint learner referral
aided federated client selection (LRef-FedCS), along with communications and
computing resource scheduling, and local model accuracy optimization (LMAO)
methods. These methods are designed to minimize the cost incurred by the
worst-case participant and ensure the long-term fairness of FL in hierarchical
Internet of Things (HieIoT) networks. Utilizing the Lyapunov optimization
technique, we reformulate the original problem into a stepwise joint
optimization problem (JOP). Subsequently, to tackle the mixed-integer
non-convex JOP, we separatively and iteratively address LRef-FedCS and LMAO
through the centralized method and self-adaptive global best harmony search
(SGHS) algorithm, respectively. To enhance scalability, we further propose a
distributed LRef-FedCS approach based on a matching game to replace the
centralized method described above. Numerical simulations and experimental
results on the MNIST/CIFAR-10 datasets demonstrate that our proposed LRef-FedCS
approach could achieve a good balance between pursuing high global accuracy and
reducing cost.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Measuring and Modeling Uncertainty Degree for Monocular Depth Estimation. (arXiv:2307.09929v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09929">http://arxiv.org/abs/2307.09929</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09929] Measuring and Modeling Uncertainty Degree for Monocular Depth Estimation](http://arxiv.org/abs/2307.09929) #fair</code></li>
<li>Summary: <p>Effectively measuring and modeling the reliability of a trained model is
essential to the real-world deployment of monocular depth estimation (MDE)
models. However, the intrinsic ill-posedness and ordinal-sensitive nature of
MDE pose major challenges to the estimation of uncertainty degree of the
trained models. On the one hand, utilizing current uncertainty modeling methods
may increase memory consumption and are usually time-consuming. On the other
hand, measuring the uncertainty based on model accuracy can also be
problematic, where uncertainty reliability and prediction accuracy are not well
decoupled. In this paper, we propose to model the uncertainty of MDE models
from the perspective of the inherent probability distributions originating from
the depth probability volume and its extensions, and to assess it more fairly
with more comprehensive metrics. By simply introducing additional training
regularization terms, our model, with surprisingly simple formations and
without requiring extra modules or multiple inferences, can provide uncertainty
estimations with state-of-the-art reliability, and can be further improved when
combined with ensemble or sampling methods. A series of experiments demonstrate
the effectiveness of our methods.
</p></li>
</ul>

<h3>Title: Towards Fair Face Verification: An In-depth Analysis of Demographic Biases. (arXiv:2307.10011v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10011">http://arxiv.org/abs/2307.10011</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10011] Towards Fair Face Verification: An In-depth Analysis of Demographic Biases](http://arxiv.org/abs/2307.10011) #fair</code></li>
<li>Summary: <p>Deep learning-based person identification and verification systems have
remarkably improved in terms of accuracy in recent years; however, such
systems, including widely popular cloud-based solutions, have been found to
exhibit significant biases related to race, age, and gender, a problem that
requires in-depth exploration and solutions. This paper presents an in-depth
analysis, with a particular emphasis on the intersectionality of these
demographic factors. Intersectional bias refers to the performance
discrepancies w.r.t. the different combinations of race, age, and gender
groups, an area relatively unexplored in current literature. Furthermore, the
reliance of most state-of-the-art approaches on accuracy as the principal
evaluation metric often masks significant demographic disparities in
performance. To counter this crucial limitation, we incorporate five additional
metrics in our quantitative analysis, including disparate impact and
mistreatment metrics, which are typically ignored by the relevant
fairness-aware approaches. Results on the Racial Faces in-the-Wild (RFW)
benchmark indicate pervasive biases in face recognition systems, extending
beyond race, with different demographic factors yielding significantly
disparate outcomes. In particular, Africans demonstrate an 11.25% lower True
Positive Rate (TPR) compared to Caucasians, while only a 3.51% accuracy drop is
observed. Even more concerning, the intersections of multiple protected groups,
such as African females over 60 years old, demonstrate a +39.89% disparate
mistreatment rate compared to the highest Caucasians rate. By shedding light on
these biases and their implications, this paper aims to stimulate further
research towards developing fairer, more equitable face recognition and
verification systems.
</p></li>
</ul>

<h3>Title: Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation. (arXiv:2307.09701v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09701">http://arxiv.org/abs/2307.09701</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09701] Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation](http://arxiv.org/abs/2307.09701) #fair</code></li>
<li>Summary: <p>Rising computational demands of modern natural language processing (NLP)
systems have increased the barrier to entry for cutting-edge research while
posing serious environmental concerns. Yet, progress on model efficiency has
been impeded by practical challenges in model evaluation and comparison. For
example, hardware is challenging to control due to disparate levels of
accessibility across different institutions. Moreover, improvements in metrics
such as FLOPs often fail to translate to progress in real-world applications.
In response, we introduce Pentathlon, a benchmark for holistic and realistic
evaluation of model efficiency. Pentathlon focuses on inference, which accounts
for a majority of the compute in a model's lifecycle. It offers a
strictly-controlled hardware platform, and is designed to mirror real-world
applications scenarios. It incorporates a suite of metrics that target
different aspects of efficiency, including latency, throughput, memory
overhead, and energy consumption. Pentathlon also comes with a software library
that can be seamlessly integrated into any codebase and enable evaluation. As a
standardized and centralized evaluation platform, Pentathlon can drastically
reduce the workload to make fair and reproducible efficiency comparisons. While
initially focused on natural language processing (NLP) models, Pentathlon is
designed to allow flexible extension to other fields. We envision Pentathlon
will stimulate algorithmic innovations in building efficient models, and foster
an increased awareness of the social and environmental implications in the
development of future-generation NLP models.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: TbExplain: A Text-based Explanation Method for Scene Classification Models with the Statistical Prediction Correction. (arXiv:2307.10003v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10003">http://arxiv.org/abs/2307.10003</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10003] TbExplain: A Text-based Explanation Method for Scene Classification Models with the Statistical Prediction Correction](http://arxiv.org/abs/2307.10003) #interpretability</code></li>
<li>Summary: <p>The field of Explainable Artificial Intelligence (XAI) aims to improve the
interpretability of black-box machine learning models. Building a heatmap based
on the importance value of input features is a popular method for explaining
the underlying functions of such models in producing their predictions.
Heatmaps are almost understandable to humans, yet they are not without flaws.
Non-expert users, for example, may not fully understand the logic of heatmaps
(the logic in which relevant pixels to the model's prediction are highlighted
with different intensities or colors). Additionally, objects and regions of the
input image that are relevant to the model prediction are frequently not
entirely differentiated by heatmaps. In this paper, we propose a framework
called TbExplain that employs XAI techniques and a pre-trained object detector
to present text-based explanations of scene classification models. Moreover,
TbExplain incorporates a novel method to correct predictions and textually
explain them based on the statistics of objects in the input image when the
initial prediction is unreliable. To assess the trustworthiness and validity of
the text-based explanations, we conducted a qualitative experiment, and the
findings indicated that these explanations are sufficiently reliable.
Furthermore, our quantitative and qualitative experiments on TbExplain with
scene classification datasets reveal an improvement in classification accuracy
over ResNet variants.
</p></li>
</ul>

<h3>Title: TREEMENT: Interpretable Patient-Trial Matching via Personalized Dynamic Tree-Based Memory Network. (arXiv:2307.09942v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09942">http://arxiv.org/abs/2307.09942</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09942] TREEMENT: Interpretable Patient-Trial Matching via Personalized Dynamic Tree-Based Memory Network](http://arxiv.org/abs/2307.09942) #interpretability</code></li>
<li>Summary: <p>Clinical trials are critical for drug development but often suffer from
expensive and inefficient patient recruitment. In recent years, machine
learning models have been proposed for speeding up patient recruitment via
automatically matching patients with clinical trials based on longitudinal
patient electronic health records (EHR) data and eligibility criteria of
clinical trials. However, they either depend on trial-specific expert rules
that cannot expand to other trials or perform matching at a very general level
with a black-box model where the lack of interpretability makes the model
results difficult to be adopted.
</p></li>
</ul>

<p>To provide accurate and interpretable patient trial matching, we introduce a
personalized dynamic tree-based memory network model named TREEMENT. It
utilizes hierarchical clinical ontologies to expand the personalized patient
representation learned from sequential EHR data, and then uses an attentional
beam-search query learned from eligibility criteria embedding to offer a
granular level of alignment for improved performance and interpretability. We
evaluated TREEMENT against existing models on real-world datasets and
demonstrated that TREEMENT outperforms the best baseline by 7% in terms of
error reduction in criteria-level matching and achieves state-of-the-art
results in its trial-level matching ability. Furthermore, we also show TREEMENT
can offer good interpretability to make the model results easier for adoption.
</p>

<h2>explainability</h2>
<h3>Title: A reinforcement learning approach for VQA validation: an application to diabetic macular edema grading. (arXiv:2307.09886v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09886">http://arxiv.org/abs/2307.09886</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09886] A reinforcement learning approach for VQA validation: an application to diabetic macular edema grading](http://arxiv.org/abs/2307.09886) #explainability</code></li>
<li>Summary: <p>Recent advances in machine learning models have greatly increased the
performance of automated methods in medical image analysis. However, the
internal functioning of such models is largely hidden, which hinders their
integration in clinical practice. Explainability and trust are viewed as
important aspects of modern methods, for the latter's widespread use in
clinical communities. As such, validation of machine learning models represents
an important aspect and yet, most methods are only validated in a limited way.
In this work, we focus on providing a richer and more appropriate validation
approach for highly powerful Visual Question Answering (VQA) algorithms. To
better understand the performance of these methods, which answer arbitrary
questions related to images, this work focuses on an automatic visual Turing
test (VTT). That is, we propose an automatic adaptive questioning method, that
aims to expose the reasoning behavior of a VQA algorithm. Specifically, we
introduce a reinforcement learning (RL) agent that observes the history of
previously asked questions, and uses it to select the next question to pose. We
demonstrate our approach in the context of evaluating algorithms that
automatically answer questions related to diabetic macular edema (DME) grading.
The experiments show that such an agent has similar behavior to a clinician,
whereby asking questions that are relevant to key clinical concepts.
</p></li>
</ul>

<h3>Title: Beyond Single-Feature Importance with ICECREAM. (arXiv:2307.09779v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09779">http://arxiv.org/abs/2307.09779</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09779] Beyond Single-Feature Importance with ICECREAM](http://arxiv.org/abs/2307.09779) #explainability</code></li>
<li>Summary: <p>Which set of features was responsible for a certain output of a machine
learning model? Which components caused the failure of a cloud computing
application? These are just two examples of questions we are addressing in this
work by Identifying Coalition-based Explanations for Common and Rare Events in
Any Model (ICECREAM). Specifically, we propose an information-theoretic
quantitative measure for the influence of a coalition of variables on the
distribution of a target variable. This allows us to identify which set of
factors is essential to obtain a certain outcome, as opposed to
well-established explainability and causal contribution analysis methods which
can assign contributions only to individual factors and rank them by their
importance. In experiments with synthetic and real-world data, we show that
ICECREAM outperforms state-of-the-art methods for explainability and root cause
analysis, and achieves impressive accuracy in both tasks.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Text2Layer: Layered Image Generation using Latent Diffusion Model. (arXiv:2307.09781v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09781">http://arxiv.org/abs/2307.09781</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09781] Text2Layer: Layered Image Generation using Latent Diffusion Model](http://arxiv.org/abs/2307.09781) #diffusion</code></li>
<li>Summary: <p>Layer compositing is one of the most popular image editing workflows among
both amateurs and professionals. Motivated by the success of diffusion models,
we explore layer compositing from a layered image generation perspective.
Instead of generating an image, we propose to generate background, foreground,
layer mask, and the composed image simultaneously. To achieve layered image
generation, we train an autoencoder that is able to reconstruct layered images
and train diffusion models on the latent representation. One benefit of the
proposed problem is to enable better compositing workflows in addition to the
high-quality image output. Another benefit is producing higher-quality layer
masks compared to masks produced by a separate step of image segmentation.
Experimental results show that the proposed method is able to generate
high-quality layered images and initiates a benchmark for future work.
</p></li>
</ul>

<h3>Title: A Siamese-based Verification System for Open-set Architecture Attribution of Synthetic Images. (arXiv:2307.09822v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09822">http://arxiv.org/abs/2307.09822</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09822] A Siamese-based Verification System for Open-set Architecture Attribution of Synthetic Images](http://arxiv.org/abs/2307.09822) #diffusion</code></li>
<li>Summary: <p>Despite the wide variety of methods developed for synthetic image
attribution, most of them can only attribute images generated by models or
architectures included in the training set and do not work with unknown
architectures, hindering their applicability in real-world scenarios. In this
paper, we propose a verification framework that relies on a Siamese Network to
address the problem of open-set attribution of synthetic images to the
architecture that generated them. We consider two different settings. In the
first setting, the system determines whether two images have been produced by
the same generative architecture or not. In the second setting, the system
verifies a claim about the architecture used to generate a synthetic image,
utilizing one or multiple reference images generated by the claimed
architecture. The main strength of the proposed system is its ability to
operate in both closed and open-set scenarios so that the input images, either
the query and reference images, can belong to the architectures considered
during training or not. Experimental evaluations encompassing various
generative architectures such as GANs, diffusion models, and transformers,
focusing on synthetic face image generation, confirm the excellent performance
of our method in both closed and open-set settings, as well as its strong
generalization capabilities.
</p></li>
</ul>

<h3>Title: BSDM: Background Suppression Diffusion Model for Hyperspectral Anomaly Detection. (arXiv:2307.09861v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09861">http://arxiv.org/abs/2307.09861</a></li>
<li>Code URL: <a href="https://github.com/majitao-xd/bsdm-had">https://github.com/majitao-xd/bsdm-had</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09861] BSDM: Background Suppression Diffusion Model for Hyperspectral Anomaly Detection](http://arxiv.org/abs/2307.09861) #diffusion</code></li>
<li>Summary: <p>Hyperspectral anomaly detection (HAD) is widely used in Earth observation and
deep space exploration. A major challenge for HAD is the complex background of
the input hyperspectral images (HSIs), resulting in anomalies confused in the
background. On the other hand, the lack of labeled samples for HSIs leads to
poor generalization of existing HAD methods. This paper starts the first
attempt to study a new and generalizable background learning problem without
labeled samples. We present a novel solution BSDM (background suppression
diffusion model) for HAD, which can simultaneously learn latent background
distributions and generalize to different datasets for suppressing complex
background. It is featured in three aspects: (1) For the complex background of
HSIs, we design pseudo background noise and learn the potential background
distribution in it with a diffusion model (DM). (2) For the generalizability
problem, we apply a statistical offset module so that the BSDM adapts to
datasets of different domains without labeling samples. (3) For achieving
background suppression, we innovatively improve the inference process of DM by
feeding the original HSIs into the denoising network, which removes the
background as noise. Our work paves a new background suppression way for HAD
that can improve HAD performance without the prerequisite of manually labeled
data. Assessments and generalization experiments of four HAD methods on several
real HSI datasets demonstrate the above three unique properties of the proposed
method. The code is available at https://github.com/majitao-xd/BSDM-HAD.
</p></li>
</ul>

<h3>Title: FABRIC: Personalizing Diffusion Models with Iterative Feedback. (arXiv:2307.10159v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10159">http://arxiv.org/abs/2307.10159</a></li>
<li>Code URL: <a href="https://github.com/sd-fabric/fabric">https://github.com/sd-fabric/fabric</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10159] FABRIC: Personalizing Diffusion Models with Iterative Feedback](http://arxiv.org/abs/2307.10159) #diffusion</code></li>
<li>Summary: <p>In an era where visual content generation is increasingly driven by machine
learning, the integration of human feedback into generative models presents
significant opportunities for enhancing user experience and output quality.
This study explores strategies for incorporating iterative human feedback into
the generative process of diffusion-based text-to-image models. We propose
FABRIC, a training-free approach applicable to a wide range of popular
diffusion models, which exploits the self-attention layer present in the most
widely used architectures to condition the diffusion process on a set of
feedback images. To ensure a rigorous assessment of our approach, we introduce
a comprehensive evaluation methodology, offering a robust mechanism to quantify
the performance of generative visual models that integrate human feedback. We
show that generation results improve over multiple rounds of iterative feedback
through exhaustive analysis, implicitly optimizing arbitrary user preferences.
The potential applications of these findings extend to fields such as
personalized content creation and customization.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Surgical Action Triplet Detection by Mixed Supervised Learning of Instrument-Tissue Interactions. (arXiv:2307.09548v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09548">http://arxiv.org/abs/2307.09548</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09548] Surgical Action Triplet Detection by Mixed Supervised Learning of Instrument-Tissue Interactions](http://arxiv.org/abs/2307.09548) #transformer</code></li>
<li>Summary: <p>Surgical action triplets describe instrument-tissue interactions as
(instrument, verb, target) combinations, thereby supporting a detailed analysis
of surgical scene activities and workflow. This work focuses on surgical action
triplet detection, which is challenging but more precise than the traditional
triplet recognition task as it consists of joint (1) localization of surgical
instruments and (2) recognition of the surgical action triplet associated with
every localized instrument. Triplet detection is highly complex due to the lack
of spatial triplet annotation. We analyze how the amount of instrument spatial
annotations affects triplet detection and observe that accurate instrument
localization does not guarantee better triplet detection due to the risk of
erroneous associations with the verbs and targets. To solve the two tasks, we
propose MCIT-IG, a two-stage network, that stands for Multi-Class
Instrument-aware Transformer-Interaction Graph. The MCIT stage of our network
models per class embedding of the targets as additional features to reduce the
risk of misassociating triplets. Furthermore, the IG stage constructs a
bipartite dynamic graph to model the interaction between the instruments and
targets, cast as the verbs. We utilize a mixed-supervised learning strategy
that combines weak target presence labels for MCIT and pseudo triplet labels
for IG to train our network. We observed that complementing minimal instrument
spatial annotations with target embeddings results in better triplet detection.
We evaluate our model on the CholecT50 dataset and show improved performance on
both instrument localization and triplet detection, topping the leaderboard of
the CholecTriplet challenge in MICCAI 2022.
</p></li>
</ul>

<h3>Title: Object-aware Gaze Target Detection. (arXiv:2307.09662v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09662">http://arxiv.org/abs/2307.09662</a></li>
<li>Code URL: <a href="https://github.com/francescotonini/object-aware-gaze-target-detection">https://github.com/francescotonini/object-aware-gaze-target-detection</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09662] Object-aware Gaze Target Detection](http://arxiv.org/abs/2307.09662) #transformer</code></li>
<li>Summary: <p>Gaze target detection aims to predict the image location where the person is
looking and the probability that a gaze is out of the scene. Several works have
tackled this task by regressing a gaze heatmap centered on the gaze location,
however, they overlooked decoding the relationship between the people and the
gazed objects. This paper proposes a Transformer-based architecture that
automatically detects objects (including heads) in the scene to build
associations between every head and the gazed-head/object, resulting in a
comprehensive, explainable gaze analysis composed of: gaze target area, gaze
pixel point, the class and the image location of the gazed-object. Upon
evaluation of the in-the-wild benchmarks, our method achieves state-of-the-art
results on all metrics (up to 2.91% gain in AUC, 50% reduction in gaze
distance, and 9% gain in out-of-frame average precision) for gaze target
detection and 11-13% improvement in average precision for the classification
and the localization of the gazed-objects. The code of the proposed method is
available https://github.com/francescotonini/object-aware-gaze-target-detection
</p></li>
</ul>

<h3>Title: DVPT: Dynamic Visual Prompt Tuning of Large Pre-trained Models for Medical Image Analysis. (arXiv:2307.09787v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09787">http://arxiv.org/abs/2307.09787</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09787] DVPT: Dynamic Visual Prompt Tuning of Large Pre-trained Models for Medical Image Analysis](http://arxiv.org/abs/2307.09787) #transformer</code></li>
<li>Summary: <p>Limited labeled data makes it hard to train models from scratch in medical
domain, and an important paradigm is pre-training and then fine-tuning. Large
pre-trained models contain rich representations, which can be adapted to
downstream medical tasks. However, existing methods either tune all the
parameters or the task-specific layers of the pre-trained models, ignoring the
input variations of medical images, and thus they are not efficient or
effective. In this work, we aim to study parameter-efficient fine-tuning (PEFT)
for medical image analysis, and propose a dynamic visual prompt tuning method,
named DVPT. It can extract knowledge beneficial to downstream tasks from large
models with a few trainable parameters. Firstly, the frozen features are
transformed by an lightweight bottleneck layer to learn the domain-specific
distribution of downstream medical tasks, and then a few learnable visual
prompts are used as dynamic queries and then conduct cross-attention with the
transformed features, attempting to acquire sample-specific knowledge that are
suitable for each sample. Finally, the features are projected to original
feature dimension and aggregated with the frozen features. This DVPT module can
be shared between different Transformer layers, further reducing the trainable
parameters. To validate DVPT, we conduct extensive experiments with different
pre-trained models on medical classification and segmentation tasks. We find
such PEFT method can not only efficiently adapt the pre-trained models to the
medical domain, but also brings data efficiency with partial labeled data. For
example, with 0.5\% extra trainable parameters, our method not only outperforms
state-of-the-art PEFT methods, even surpasses the full fine-tuning by more than
2.20\% Kappa score on medical classification task. It can saves up to 60\%
labeled data and 99\% storage cost of ViT-B/16.
</p></li>
</ul>

<h3>Title: Embedded Heterogeneous Attention Transformer for Cross-lingual Image Captioning. (arXiv:2307.09915v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09915">http://arxiv.org/abs/2307.09915</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09915] Embedded Heterogeneous Attention Transformer for Cross-lingual Image Captioning](http://arxiv.org/abs/2307.09915) #transformer</code></li>
<li>Summary: <p>Cross-lingual image captioning is confronted with both cross-lingual and
cross-modal challenges for multimedia analysis. The crucial issue in this task
is to model the global and local matching between the image and different
languages. Existing cross-modal embedding methods based on Transformer
architecture oversight the local matching between the image region and
monolingual words, not to mention in the face of a variety of differentiated
languages. Due to the heterogeneous property of the cross-modal and
cross-lingual task, we utilize the heterogeneous network to establish
cross-domain relationships and the local correspondences between the image and
different languages. In this paper, we propose an Embedded Heterogeneous
Attention Transformer (EHAT) to build reasoning paths bridging cross-domain for
cross-lingual image captioning and integrate into transformer. The proposed
EHAT consists of a Masked Heterogeneous Cross-attention (MHCA), Heterogeneous
Attention Reasoning Network (HARN) and Heterogeneous Co-attention (HCA). HARN
as the core network, models and infers cross-domain relationship anchored by
vision bounding box representation features to connect two languages word
features and learn the heterogeneous maps. MHCA and HCA implement cross-domain
integration in the encoder through the special heterogeneous attention and
enable single model to generate two language captioning. We test on MSCOCO
dataset to generate English and Chinese, which are most widely used and have
obvious difference between their language families. Our experiments show that
our method even achieve better than advanced monolingual methods.
</p></li>
</ul>

<h3>Title: Fine-grained Text-Video Retrieval with Frozen Image Encoders. (arXiv:2307.09972v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09972">http://arxiv.org/abs/2307.09972</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09972] Fine-grained Text-Video Retrieval with Frozen Image Encoders](http://arxiv.org/abs/2307.09972) #transformer</code></li>
<li>Summary: <p>State-of-the-art text-video retrieval (TVR) methods typically utilize CLIP
and cosine similarity for efficient retrieval. Meanwhile, cross attention
methods, which employ a transformer decoder to compute attention between each
text query and all frames in a video, offer a more comprehensive interaction
between text and videos. However, these methods lack important fine-grained
spatial information as they directly compute attention between text and
video-level tokens. To address this issue, we propose CrossTVR, a two-stage
text-video retrieval architecture. In the first stage, we leverage existing TVR
methods with cosine similarity network for efficient text/video candidate
selection. In the second stage, we propose a novel decoupled video text cross
attention module to capture fine-grained multimodal information in spatial and
temporal dimensions. Additionally, we employ the frozen CLIP model strategy in
fine-grained retrieval, enabling scalability to larger pre-trained vision
models like ViT-G, resulting in improved retrieval performance. Experiments on
text video retrieval datasets demonstrate the effectiveness and scalability of
our proposed CrossTVR compared to state-of-the-art approaches.
</p></li>
</ul>

<h3>Title: Divert More Attention to Vision-Language Object Tracking. (arXiv:2307.10046v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10046">http://arxiv.org/abs/2307.10046</a></li>
<li>Code URL: <a href="https://github.com/JudasDie/SOTS">https://github.com/JudasDie/SOTS</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10046] Divert More Attention to Vision-Language Object Tracking](http://arxiv.org/abs/2307.10046) #transformer</code></li>
<li>Summary: <p>Multimodal vision-language (VL) learning has noticeably pushed the tendency
toward generic intelligence owing to emerging large foundation models. However,
tracking, as a fundamental vision problem, surprisingly enjoys less bonus from
recent flourishing VL learning. We argue that the reasons are two-fold: the
lack of large-scale vision-language annotated videos and ineffective
vision-language interaction learning of current works. These nuisances motivate
us to design more effective vision-language representation for tracking,
meanwhile constructing a large database with language annotation for model
learning. Particularly, in this paper, we first propose a general attribute
annotation strategy to decorate videos in six popular tracking benchmarks,
which contributes a large-scale vision-language tracking database with more
than 23,000 videos. We then introduce a novel framework to improve tracking by
learning a unified-adaptive VL representation, where the cores are the proposed
asymmetric architecture search and modality mixer (ModaMixer). To further
improve VL representation, we introduce a contrastive loss to align different
modalities. To thoroughly evidence the effectiveness of our method, we
integrate the proposed framework on three tracking methods with different
designs, i.e., the CNN-based SiamCAR, the Transformer-based OSTrack, and the
hybrid structure TransT. The experiments demonstrate that our framework can
significantly improve all baselines on six benchmarks. Besides empirical
results, we theoretically analyze our approach to show its rationality. By
revealing the potential of VL representation, we expect the community to divert
more attention to VL tracking and hope to open more possibilities for future
tracking with diversified multimodal messages.
</p></li>
</ul>

<h3>Title: Can Model Fusing Help Transformers in Long Document Classification? An Empirical Study. (arXiv:2307.09532v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09532">http://arxiv.org/abs/2307.09532</a></li>
<li>Code URL: <a href="https://github.com/damithdr/legal-classification">https://github.com/damithdr/legal-classification</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09532] Can Model Fusing Help Transformers in Long Document Classification? An Empirical Study](http://arxiv.org/abs/2307.09532) #transformer</code></li>
<li>Summary: <p>Text classification is an area of research which has been studied over the
years in Natural Language Processing (NLP). Adapting NLP to multiple domains
has introduced many new challenges for text classification and one of them is
long document classification. While state-of-the-art transformer models provide
excellent results in text classification, most of them have limitations in the
maximum sequence length of the input sequence. The majority of the transformer
models are limited to 512 tokens, and therefore, they struggle with long
document classification problems. In this research, we explore on employing
Model Fusing for long document classification while comparing the results with
well-known BERT and Longformer architectures.
</p></li>
</ul>

<h3>Title: Gradient Sparsification For Masked Fine-Tuning of Transformers. (arXiv:2307.10098v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10098">http://arxiv.org/abs/2307.10098</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10098] Gradient Sparsification For Masked Fine-Tuning of Transformers](http://arxiv.org/abs/2307.10098) #transformer</code></li>
<li>Summary: <p>Fine-tuning pretrained self-supervised language models is widely adopted for
transfer learning to downstream tasks. Fine-tuning can be achieved by freezing
gradients of the pretrained network and only updating gradients of a newly
added classification layer, or by performing gradient updates on all
parameters. Gradual unfreezing makes a trade-off between the two by gradually
unfreezing gradients of whole layers during training. This has been an
effective strategy to trade-off between storage and training speed with
generalization performance. However, it is not clear whether gradually
unfreezing layers throughout training is optimal, compared to sparse variants
of gradual unfreezing which may improve fine-tuning performance. In this paper,
we propose to stochastically mask gradients to regularize pretrained language
models for improving overall fine-tuned performance. We introduce GradDrop and
variants thereof, a class of gradient sparsification methods that mask
gradients during the backward pass, acting as gradient noise. GradDrop is
sparse and stochastic unlike gradual freezing. Extensive experiments on the
multilingual XGLUE benchmark with XLMR-Large show that GradDrop is competitive
against methods that use additional translated data for intermediate
pretraining and outperforms standard fine-tuning and gradual unfreezing. A
post-analysis shows how GradDrop improves performance with languages it was not
trained on, such as under-resourced languages.
</p></li>
</ul>

<h3>Title: Exploring Transformer Extrapolation. (arXiv:2307.10156v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10156">http://arxiv.org/abs/2307.10156</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10156] Exploring Transformer Extrapolation](http://arxiv.org/abs/2307.10156) #transformer</code></li>
<li>Summary: <p>Length extrapolation has attracted considerable attention recently since it
allows transformers to be tested on longer sequences than those used in
training. Previous research has shown that this property can be attained by
using carefully designed Relative Positional Encodings (RPEs). While these
methods perform well on a variety of corpora, the conditions for length
extrapolation have yet to be investigated. This paper attempts to determine
what types of RPEs allow for length extrapolation through a thorough
mathematical and empirical analysis. We discover that a transformer is certain
to possess this property as long as the series that corresponds to the RPE's
exponential converges. Two practices are derived from the conditions and
examined in language modeling tasks on a variety of corpora. As a bonus from
the conditions, we derive a new Theoretical Receptive Field (TRF) to measure
the receptive field of RPEs without taking any training steps. Extensive
experiments are conducted on the Wikitext-103, Books, Github, and WikiBook
datasets to demonstrate the viability of our discovered conditions. We also
compare TRF to Empirical Receptive Field (ERF) across different models, showing
consistently matched trends on the aforementioned datasets. The code is
available at https://github.com/OpenNLPLab/Rpe.
</p></li>
</ul>

<h3>Title: Anticipating Technical Expertise and Capability Evolution in Research Communities using Dynamic Graph Transformers. (arXiv:2307.09665v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09665">http://arxiv.org/abs/2307.09665</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09665] Anticipating Technical Expertise and Capability Evolution in Research Communities using Dynamic Graph Transformers](http://arxiv.org/abs/2307.09665) #transformer</code></li>
<li>Summary: <p>The ability to anticipate technical expertise and capability evolution trends
globally is essential for national and global security, especially in
safety-critical domains like nuclear nonproliferation (NN) and rapidly emerging
fields like artificial intelligence (AI). In this work, we extend traditional
statistical relational learning approaches (e.g., link prediction in
collaboration networks) and formulate a problem of anticipating technical
expertise and capability evolution using dynamic heterogeneous graph
representations. We develop novel capabilities to forecast collaboration
patterns, authorship behavior, and technical capability evolution at different
granularities (e.g., scientist and institution levels) in two distinct research
fields. We implement a dynamic graph transformer (DGT) neural architecture,
which pushes the state-of-the-art graph neural network models by (a)
forecasting heterogeneous (rather than homogeneous) nodes and edges, and (b)
relying on both discrete -- and continuous -- time inputs. We demonstrate that
our DGT models predict collaboration, partnership, and expertise patterns with
0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and
0.22 for NN domains. DGT model performance exceeds the best-performing static
graph baseline models by 30-80% across AI and NN domains. Our findings
demonstrate that DGT models boost inductive task performance, when previously
unseen nodes appear in the test data, for the domains with emerging
collaboration patterns (e.g., AI). Specifically, models accurately predict
which established scientists will collaborate with early career scientists and
vice-versa in the AI domain.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Conditional 360-degree Image Synthesis for Immersive Indoor Scene Decoration. (arXiv:2307.09621v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09621">http://arxiv.org/abs/2307.09621</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09621] Conditional 360-degree Image Synthesis for Immersive Indoor Scene Decoration](http://arxiv.org/abs/2307.09621) #generative</code></li>
<li>Summary: <p>In this paper, we address the problem of conditional scene decoration for
360-degree images. Our method takes a 360-degree background photograph of an
indoor scene and generates decorated images of the same scene in the panorama
view. To do this, we develop a 360-aware object layout generator that learns
latent object vectors in the 360-degree view to enable a variety of furniture
arrangements for an input 360-degree background image. We use this object
layout to condition a generative adversarial network to synthesize images of an
input scene. To further reinforce the generation capability of our model, we
develop a simple yet effective scene emptier that removes the generated
furniture and produces an emptied scene for our model to learn a cyclic
constraint. We train the model on the Structure3D dataset and show that our
model can generate diverse decorations with controllable object layout. Our
method achieves state-of-the-art performance on the Structure3D dataset and
generalizes well to the Zillow indoor scene dataset. Our user study confirms
the immersive experiences provided by the realistic image quality and furniture
layout in our generation results. Our implementation will be made available.
</p></li>
</ul>

<h3>Title: Generative Prompt Model for Weakly Supervised Object Localization. (arXiv:2307.09756v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09756">http://arxiv.org/abs/2307.09756</a></li>
<li>Code URL: <a href="https://github.com/callsys/genpromp">https://github.com/callsys/genpromp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09756] Generative Prompt Model for Weakly Supervised Object Localization](http://arxiv.org/abs/2307.09756) #generative</code></li>
<li>Summary: <p>Weakly supervised object localization (WSOL) remains challenging when
learning object localization models from image category labels. Conventional
methods that discriminatively train activation models ignore representative yet
less discriminative object parts. In this study, we propose a generative prompt
model (GenPromp), defining the first generative pipeline to localize less
discriminative object parts by formulating WSOL as a conditional image
denoising procedure. During training, GenPromp converts image category labels
to learnable prompt embeddings which are fed to a generative model to
conditionally recover the input image with noise and learn representative
embeddings. During inference, enPromp combines the representative embeddings
with discriminative embeddings (queried from an off-the-shelf vision-language
model) for both representative and discriminative capacity. The combined
embeddings are finally used to generate multi-scale high-quality attention
maps, which facilitate localizing full object extent. Experiments on
CUB-200-2011 and ILSVRC show that GenPromp respectively outperforms the best
discriminative models by 5.2% and 5.6% (Top-1 Loc), setting a solid baseline
for WSOL with the generative model. Code is available at
https://github.com/callsys/GenPromp.
</p></li>
</ul>

<h3>Title: Adversarial Latent Autoencoder with Self-Attention for Structural Image Synthesis. (arXiv:2307.10166v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10166">http://arxiv.org/abs/2307.10166</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10166] Adversarial Latent Autoencoder with Self-Attention for Structural Image Synthesis](http://arxiv.org/abs/2307.10166) #generative</code></li>
<li>Summary: <p>Generative Engineering Design approaches driven by Deep Generative Models
(DGM) have been proposed to facilitate industrial engineering processes. In
such processes, designs often come in the form of images, such as blueprints,
engineering drawings, and CAD models depending on the level of detail. DGMs
have been successfully employed for synthesis of natural images, e.g.,
displaying animals, human faces and landscapes. However, industrial design
images are fundamentally different from natural scenes in that they contain
rich structural patterns and long-range dependencies, which are challenging for
convolution-based DGMs to generate. Moreover, DGM-driven generation process is
typically triggered based on random noisy inputs, which outputs unpredictable
samples and thus cannot perform an efficient industrial design exploration. We
tackle these challenges by proposing a novel model Self-Attention Adversarial
Latent Autoencoder (SA-ALAE), which allows generating feasible design images of
complex engineering parts. With SA-ALAE, users can not only explore novel
variants of an existing design, but also control the generation process by
operating in latent space. The potential of SA-ALAE is shown by generating
engineering blueprints in a real automotive design task.
</p></li>
</ul>

<h3>Title: Sig-Splines: universal approximation and convex calibration of time series generative models. (arXiv:2307.09767v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09767">http://arxiv.org/abs/2307.09767</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09767] Sig-Splines: universal approximation and convex calibration of time series generative models](http://arxiv.org/abs/2307.09767) #generative</code></li>
<li>Summary: <p>We propose a novel generative model for multivariate discrete-time time
series data. Drawing inspiration from the construction of neural spline flows,
our algorithm incorporates linear transformations and the signature transform
as a seamless substitution for traditional neural networks. This approach
enables us to achieve not only the universality property inherent in neural
networks but also introduces convexity in the model's parameters.
</p></li>
</ul>

<h3>Title: Adversarial Likelihood Estimation with One-way Flows. (arXiv:2307.09882v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09882">http://arxiv.org/abs/2307.09882</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09882] Adversarial Likelihood Estimation with One-way Flows](http://arxiv.org/abs/2307.09882) #generative</code></li>
<li>Summary: <p>Generative Adversarial Networks (GANs) can produce high-quality samples, but
do not provide an estimate of the probability density around the samples.
However, it has been noted that maximizing the log-likelihood within an
energy-based setting can lead to an adversarial framework where the
discriminator provides unnormalized density (often called energy). We further
develop this perspective, incorporate importance sampling, and show that 1)
Wasserstein GAN performs a biased estimate of the partition function, and we
propose instead to use an unbiased estimator; 2) when optimizing for
likelihood, one must maximize generator entropy. This is hypothesized to
provide a better mode coverage. Different from previous works, we explicitly
compute the density of the generated samples. This is the key enabler to
designing an unbiased estimator of the partition function and computation of
the generator entropy term. The generator density is obtained via a new type of
flow network, called one-way flow network, that is less constrained in terms of
architecture, as it does not require to have a tractable inverse function. Our
experimental results show that we converge faster, produce comparable sample
quality to GANs with similar architecture, successfully avoid over-fitting to
commonly used datasets and produce smooth low-dimensional latent
representations of the training data.
</p></li>
</ul>

<h3>Title: Symmetric Equilibrium Learning of VAEs. (arXiv:2307.09883v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09883">http://arxiv.org/abs/2307.09883</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09883] Symmetric Equilibrium Learning of VAEs](http://arxiv.org/abs/2307.09883) #generative</code></li>
<li>Summary: <p>We view variational autoencoders (VAE) as decoder-encoder pairs, which map
distributions in the data space to distributions in the latent space and vice
versa. The standard learning approach for VAEs, i.e. maximisation of the
evidence lower bound (ELBO), has an obvious asymmetry in that respect.
Moreover, it requires a closed form a-priori latent distribution. This limits
the applicability of VAEs in more complex scenarios, such as general
semi-supervised learning and employing complex generative models as priors. We
propose a Nash equilibrium learning approach that relaxes these restrictions
and allows learning VAEs in situations where both the data and the latent
distributions are accessible only by sampling. The flexibility and simplicity
of this approach allows its application to a wide range of learning scenarios
and downstream tasks. We show experimentally that the models learned by this
method are comparable to those obtained by ELBO learning and demonstrate its
applicability for tasks that are not accessible by standard VAE learning.
</p></li>
</ul>

<h3>Title: A Dual Formulation for Probabilistic Principal Component Analysis. (arXiv:2307.10078v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10078">http://arxiv.org/abs/2307.10078</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10078] A Dual Formulation for Probabilistic Principal Component Analysis](http://arxiv.org/abs/2307.10078) #generative</code></li>
<li>Summary: <p>In this paper, we characterize Probabilistic Principal Component Analysis in
Hilbert spaces and demonstrate how the optimal solution admits a representation
in dual space. This allows us to develop a generative framework for kernel
methods. Furthermore, we show how it englobes Kernel Principal Component
Analysis and illustrate its working on a toy and a real dataset.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility. (arXiv:2307.09705v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09705">http://arxiv.org/abs/2307.09705</a></li>
<li>Code URL: <a href="https://github.com/x-plug/cvalues">https://github.com/x-plug/cvalues</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09705] CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility](http://arxiv.org/abs/2307.09705) #large language model</code></li>
<li>Summary: <p>With the rapid evolution of large language models (LLMs), there is a growing
concern that they may pose risks or have negative social impacts. Therefore,
evaluation of human values alignment is becoming increasingly important.
Previous work mainly focuses on assessing the performance of LLMs on certain
knowledge and reasoning abilities, while neglecting the alignment to human
values, especially in a Chinese context. In this paper, we present CValues, the
first Chinese human values evaluation benchmark to measure the alignment
ability of LLMs in terms of both safety and responsibility criteria. As a
result, we have manually collected adversarial safety prompts across 10
scenarios and induced responsibility prompts from 8 domains by professional
experts. To provide a comprehensive values evaluation of Chinese LLMs, we not
only conduct human evaluation for reliable comparison, but also construct
multi-choice prompts for automatic evaluation. Our findings suggest that while
most Chinese LLMs perform well in terms of safety, there is considerable room
for improvement in terms of responsibility. Moreover, both the automatic and
human evaluation are important for assessing the human values alignment in
different aspects. The benchmark and code is available on ModelScope and
Github.
</p></li>
</ul>

<h3>Title: ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats. (arXiv:2307.09782v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09782">http://arxiv.org/abs/2307.09782</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09782] ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats](http://arxiv.org/abs/2307.09782) #large language model</code></li>
<li>Summary: <p>In the complex domain of large language models (LLMs), striking a balance
between computational efficiency and maintaining model quality is a formidable
challenge. Navigating the inherent limitations of uniform quantization,
particularly when dealing with outliers, and motivated by the launch of
NVIDIA's H100 hardware, this study delves into the viability of floating-point
(FP) quantization, particularly focusing on FP8 and FP4, as a potential
solution. Our comprehensive investigation reveals that for LLMs, FP8 activation
consistently outshines its integer (INT8) equivalent, with the performance edge
becoming more noticeable in models possessing parameters beyond one billion.
For weight quantization, our findings indicate that FP4 exhibits comparable, if
not superior, performance to INT4, simplifying deployment on FP-supported
hardware like H100. To mitigate the overhead from precision alignment caused by
the disparity between weights and activations, we propose two scaling
constraints for weight quantization that negligibly impact the performance
compared to the standard W4A8 model. We additionally enhance our quantization
methods by integrating the Low Rank Compensation (LoRC) strategy, yielding
improvements especially in smaller models. The results of our investigation
emphasize the immense potential of FP quantization for LLMs, paving the way for
high-efficiency deployment in resource-limited settings.
</p></li>
</ul>

<h3>Title: Large Language Models can accomplish Business Process Management Tasks. (arXiv:2307.09923v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09923">http://arxiv.org/abs/2307.09923</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09923] Large Language Models can accomplish Business Process Management Tasks](http://arxiv.org/abs/2307.09923) #large language model</code></li>
<li>Summary: <p>Business Process Management (BPM) aims to improve organizational activities
and their outcomes by managing the underlying processes. To achieve this, it is
often necessary to consider information from various sources, including
unstructured textual documents. Therefore, researchers have developed several
BPM-specific solutions that extract information from textual documents using
Natural Language Processing techniques. These solutions are specific to their
respective tasks and cannot accomplish multiple process-related problems as a
general-purpose instrument. However, in light of the recent emergence of Large
Language Models (LLMs) with remarkable reasoning capabilities, such a
general-purpose instrument with multiple applications now appears attainable.
In this paper, we illustrate how LLMs can accomplish text-related BPM tasks by
applying a specific LLM to three exemplary tasks: mining imperative process
models from textual descriptions, mining declarative process models from
textual descriptions, and assessing the suitability of process tasks from
textual descriptions for robotic process automation. We show that, without
extensive configuration or prompt engineering, LLMs perform comparably to or
better than existing solutions and discuss implications for future BPM research
as well as practical usage.
</p></li>
</ul>

<h3>Title: Generating Mathematical Derivations with Large Language Models. (arXiv:2307.09998v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09998">http://arxiv.org/abs/2307.09998</a></li>
<li>Code URL: <a href="https://github.com/jmeadows17/deriving-equations-with-llms">https://github.com/jmeadows17/deriving-equations-with-llms</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09998] Generating Mathematical Derivations with Large Language Models](http://arxiv.org/abs/2307.09998) #large language model</code></li>
<li>Summary: <p>The derivation of mathematical results in specialised fields using Large
Language Models (LLMs) is an emerging research direction that can help identify
models' limitations, and potentially support mathematical discovery. In this
paper, we leverage a symbolic engine to generate derivations of equations at
scale, and investigate the capabilities of LLMs when deriving goal equations
from premises. Specifically, we employ in-context learning for GPT and
fine-tune a range of T5 models to compare the robustness and generalisation of
pre-training strategies to specialised models. Empirical results show that
fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and
out-of-distribution test sets in terms of absolute performance. However, an
in-depth analysis reveals that the fine-tuned models are more sensitive to
perturbations involving unseen symbols and (to a lesser extent) changes to
equation structure. In addition, we analyse 1.7K equations and over 200
derivations to highlight common reasoning errors such as the inclusion of
incorrect, irrelevant, and redundant equations, along with the tendency to skip
derivation steps. Finally, we explore the suitability of existing metrics for
evaluating mathematical derivations finding evidence that, while they capture
general properties such as sensitivity to perturbations, they fail to highlight
fine-grained reasoning errors and essential differences between models.
Overall, this work demonstrates that training models on synthetic data can
improve their mathematical capabilities beyond larger architectures.
</p></li>
</ul>

<h3>Title: Challenges and Applications of Large Language Models. (arXiv:2307.10169v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10169">http://arxiv.org/abs/2307.10169</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10169] Challenges and Applications of Large Language Models](http://arxiv.org/abs/2307.10169) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) went from non-existent to ubiquitous in the
machine learning discourse within a few years. Due to the fast pace of the
field, it is difficult to identify the remaining challenges and already
fruitful application areas. In this paper, we aim to establish a systematic set
of open problems and application successes so that ML researchers can
comprehend the field's current state more quickly and become productive.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: DenseMP: Unsupervised Dense Pre-training for Few-shot Medical Image Segmentation. (arXiv:2307.09604v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09604">http://arxiv.org/abs/2307.09604</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09604] DenseMP: Unsupervised Dense Pre-training for Few-shot Medical Image Segmentation](http://arxiv.org/abs/2307.09604) #segmentation</code></li>
<li>Summary: <p>Few-shot medical image semantic segmentation is of paramount importance in
the domain of medical image analysis. However, existing methodologies grapple
with the challenge of data scarcity during the training phase, leading to
over-fitting. To mitigate this issue, we introduce a novel Unsupervised Dense
Few-shot Medical Image Segmentation Model Training Pipeline (DenseMP) that
capitalizes on unsupervised dense pre-training. DenseMP is composed of two
distinct stages: (1) segmentation-aware dense contrastive pre-training, and (2)
few-shot-aware superpixel guided dense pre-training. These stages
collaboratively yield a pre-trained initial model specifically designed for
few-shot medical image segmentation, which can subsequently be fine-tuned on
the target dataset. Our proposed pipeline significantly enhances the
performance of the widely recognized few-shot segmentation model, PA-Net,
achieving state-of-the-art results on the Abd-CT and Abd-MRI datasets. Code
will be released after acceptance.
</p></li>
</ul>

<h3>Title: ClickSeg: 3D Instance Segmentation with Click-Level Weak Annotations. (arXiv:2307.09732v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09732">http://arxiv.org/abs/2307.09732</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09732] ClickSeg: 3D Instance Segmentation with Click-Level Weak Annotations](http://arxiv.org/abs/2307.09732) #segmentation</code></li>
<li>Summary: <p>3D instance segmentation methods often require fully-annotated dense labels
for training, which are costly to obtain. In this paper, we present ClickSeg, a
novel click-level weakly supervised 3D instance segmentation method that
requires one point per instance annotation merely. Such a problem is very
challenging due to the extremely limited labels, which has rarely been solved
before. We first develop a baseline weakly-supervised training method, which
generates pseudo labels for unlabeled data by the model itself. To utilize the
property of click-level annotation setting, we further propose a new training
framework. Instead of directly using the model inference way, i.e., mean-shift
clustering, to generate the pseudo labels, we propose to use k-means with fixed
initial seeds: the annotated points. New similarity metrics are further
designed for clustering. Experiments on ScanNetV2 and S3DIS datasets show that
the proposed ClickSeg surpasses the previous best weakly supervised instance
segmentation result by a large margin (e.g., +9.4% mAP on ScanNetV2). Using
0.02% supervision signals merely, ClickSeg achieves $\sim$90% of the accuracy
of the fully-supervised counterpart. Meanwhile, it also achieves
state-of-the-art semantic segmentation results among weakly supervised methods
that use the same annotation settings.
</p></li>
</ul>

<h3>Title: Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation. (arXiv:2307.09755v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09755">http://arxiv.org/abs/2307.09755</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09755] Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation](http://arxiv.org/abs/2307.09755) #segmentation</code></li>
<li>Summary: <p>Semi-Supervised Semantic Segmentation (S4) aims to train a segmentation model
with limited labeled images and a substantial volume of unlabeled images. To
improve the robustness of representations, powerful methods introduce a
pixel-wise contrastive learning approach in latent space (i.e., representation
space) that aggregates the representations to their prototypes in a fully
supervised manner. However, previous contrastive-based S4 methods merely rely
on the supervision from the model's output (logits) in logit space during
unlabeled training. In contrast, we utilize the outputs in both logit space and
representation space to obtain supervision in a collaborative way. The
supervision from two spaces plays two roles: 1) reduces the risk of
over-fitting to incorrect semantic information in logits with the help of
representations; 2) enhances the knowledge exchange between the two spaces.
Furthermore, unlike previous approaches, we use the similarity between
representations and prototypes as a new indicator to tilt training those
under-performing representations and achieve a more efficient contrastive
learning process. Results on two public benchmarks demonstrate the competitive
performance of our method compared with state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Source-Free Domain Adaptation for Medical Image Segmentation via Prototype-Anchored Feature Alignment and Contrastive Learning. (arXiv:2307.09769v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09769">http://arxiv.org/abs/2307.09769</a></li>
<li>Code URL: <a href="https://github.com/cscyqj/miccai23-protocontra-sfda">https://github.com/cscyqj/miccai23-protocontra-sfda</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09769] Source-Free Domain Adaptation for Medical Image Segmentation via Prototype-Anchored Feature Alignment and Contrastive Learning](http://arxiv.org/abs/2307.09769) #segmentation</code></li>
<li>Summary: <p>Unsupervised domain adaptation (UDA) has increasingly gained interests for
its capacity to transfer the knowledge learned from a labeled source domain to
an unlabeled target domain. However, typical UDA methods require concurrent
access to both the source and target domain data, which largely limits its
application in medical scenarios where source data is often unavailable due to
privacy concern. To tackle the source data-absent problem, we present a novel
two-stage source-free domain adaptation (SFDA) framework for medical image
segmentation, where only a well-trained source segmentation model and unlabeled
target data are available during domain adaptation. Specifically, in the
prototype-anchored feature alignment stage, we first utilize the weights of the
pre-trained pixel-wise classifier as source prototypes, which preserve the
information of source features. Then, we introduce the bi-directional transport
to align the target features with class prototypes by minimizing its expected
cost. On top of that, a contrastive learning stage is further devised to
utilize those pixels with unreliable predictions for a more compact target
feature distribution. Extensive experiments on a cross-modality medical
segmentation task demonstrate the superiority of our method in large domain
discrepancy settings compared with the state-of-the-art SFDA approaches and
even some UDA methods. Code is available at
https://github.com/CSCYQJ/MICCAI23-ProtoContra-SFDA.
</p></li>
</ul>

<h3>Title: U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation. (arXiv:2307.09947v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09947">http://arxiv.org/abs/2307.09947</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09947] U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation](http://arxiv.org/abs/2307.09947) #segmentation</code></li>
<li>Summary: <p>Deep neural networks have shown exceptional performance in various tasks, but
their lack of robustness, reliability, and tendency to be overconfident pose
challenges for their deployment in safety-critical applications like autonomous
driving. In this regard, quantifying the uncertainty inherent to a model's
prediction is a promising endeavour to address these shortcomings. In this
work, we present a novel Uncertainty-aware Cross-Entropy loss (U-CE) that
incorporates dynamic predictive uncertainties into the training process by
pixel-wise weighting of the well-known cross-entropy loss (CE). Through
extensive experimentation, we demonstrate the superiority of U-CE over regular
CE training on two benchmark datasets, Cityscapes and ACDC, using two common
backbone architectures, ResNet-18 and ResNet-101. With U-CE, we manage to train
models that not only improve their segmentation performance but also provide
meaningful uncertainties after training. Consequently, we contribute to the
development of more robust and reliable segmentation models, ultimately
advancing the state-of-the-art in safety-critical applications and beyond.
</p></li>
</ul>

<h3>Title: Source-Free Domain Adaptive Fundus Image Segmentation with Class-Balanced Mean Teacher. (arXiv:2307.09973v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.09973">http://arxiv.org/abs/2307.09973</a></li>
<li>Code URL: <a href="https://github.com/lloongx/sfda-cbmt">https://github.com/lloongx/sfda-cbmt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.09973] Source-Free Domain Adaptive Fundus Image Segmentation with Class-Balanced Mean Teacher](http://arxiv.org/abs/2307.09973) #segmentation</code></li>
<li>Summary: <p>This paper studies source-free domain adaptive fundus image segmentation
which aims to adapt a pretrained fundus segmentation model to a target domain
using unlabeled images. This is a challenging task because it is highly risky
to adapt a model only using unlabeled data. Most existing methods tackle this
task mainly by designing techniques to carefully generate pseudo labels from
the model's predictions and use the pseudo labels to train the model. While
often obtaining positive adaption effects, these methods suffer from two major
issues. First, they tend to be fairly unstable - incorrect pseudo labels
abruptly emerged may cause a catastrophic impact on the model. Second, they
fail to consider the severe class imbalance of fundus images where the
foreground (e.g., cup) region is usually very small. This paper aims to address
these two issues by proposing the Class-Balanced Mean Teacher (CBMT) model.
CBMT addresses the unstable issue by proposing a weak-strong augmented mean
teacher learning scheme where only the teacher model generates pseudo labels
from weakly augmented images to train a student model that takes strongly
augmented images as input. The teacher is updated as the moving average of the
instantly trained student, which could be noisy. This prevents the teacher
model from being abruptly impacted by incorrect pseudo-labels. For the class
imbalance issue, CBMT proposes a novel loss calibration approach to highlight
foreground classes according to global statistics. Experiments show that CBMT
well addresses these two issues and outperforms existing methods on multiple
benchmarks.
</p></li>
</ul>

<h3>Title: Class Attention to Regions of Lesion for Imbalanced Medical Image Recognition. (arXiv:2307.10036v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10036">http://arxiv.org/abs/2307.10036</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10036] Class Attention to Regions of Lesion for Imbalanced Medical Image Recognition](http://arxiv.org/abs/2307.10036) #segmentation</code></li>
<li>Summary: <p>Automated medical image classification is the key component in intelligent
diagnosis systems. However, most medical image datasets contain plenty of
samples of common diseases and just a handful of rare ones, leading to major
class imbalances. Currently, it is an open problem in intelligent diagnosis to
effectively learn from imbalanced training data. In this paper, we propose a
simple yet effective framework, named \textbf{C}lass \textbf{A}ttention to
\textbf{RE}gions of the lesion (CARE), to handle data imbalance issues by
embedding attention into the training process of \textbf{C}onvolutional
\textbf{N}eural \textbf{N}etworks (CNNs). The proposed attention module helps
CNNs attend to lesion regions of rare diseases, therefore helping CNNs to learn
their characteristics more effectively. In addition, this attention module
works only during the training phase and does not change the architecture of
the original network, so it can be directly combined with any existing CNN
architecture. The CARE framework needs bounding boxes to represent the lesion
regions of rare diseases. To alleviate the need for manual annotation, we
further developed variants of CARE by leveraging the traditional saliency
methods or a pretrained segmentation model for bounding box generation. Results
show that the CARE variants with automated bounding box generation are
comparable to the original CARE framework with \textit{manual} bounding box
annotations. A series of experiments on an imbalanced skin image dataset and a
pneumonia dataset indicates that our method can effectively help the network
focus on the lesion regions of rare diseases and remarkably improves the
classification performance of rare diseases.
</p></li>
</ul>

<h3>Title: Boundary-Refined Prototype Generation: A General End-to-End Paradigm for Semi-Supervised Semantic Segmentation. (arXiv:2307.10097v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10097">http://arxiv.org/abs/2307.10097</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10097] Boundary-Refined Prototype Generation: A General End-to-End Paradigm for Semi-Supervised Semantic Segmentation](http://arxiv.org/abs/2307.10097) #segmentation</code></li>
<li>Summary: <p>Prototype-based classification is a classical method in machine learning, and
recently it has achieved remarkable success in semi-supervised semantic
segmentation. However, the current approach isolates the prototype
initialization process from the main training framework, which appears to be
unnecessary. Furthermore, while the direct use of K-Means algorithm for
prototype generation has considered rich intra-class variance, it may not be
the optimal solution for the classification task. To tackle these problems, we
propose a novel boundary-refined prototype generation (BRPG) method, which is
incorporated into the whole training framework. Specifically, our approach
samples and clusters high- and low-confidence features separately based on a
confidence threshold, aiming to generate prototypes closer to the class
boundaries. Moreover, an adaptive prototype optimization strategy is introduced
to make prototype augmentation for categories with scattered feature
distributions. Extensive experiments on the PASCAL VOC 2012 and Cityscapes
datasets demonstrate the superiority and scalability of the proposed method,
outperforming the current state-of-the-art approaches. The code is available at
xxxxxxxxxxxxxx.
</p></li>
</ul>

<h3>Title: Two Approaches to Supervised Image Segmentation. (arXiv:2307.10123v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10123">http://arxiv.org/abs/2307.10123</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10123] Two Approaches to Supervised Image Segmentation](http://arxiv.org/abs/2307.10123) #segmentation</code></li>
<li>Summary: <p>Though performed almost effortlessly by humans, segmenting 2D gray-scale or
color images in terms of their constituent regions of interest
(e.g.~background, objects or portions of objects) constitutes one of the
greatest challenges in science and technology as a consequence of the involved
dimensionality reduction(3D to 2D), noise, reflections, shades, and occlusions,
among many other possible effects. While a large number of interesting
approaches have been respectively suggested along the last decades, it was
mainly with the more recent development of deep learning that more effective
and general solutions have been obtained, currently constituting the basic
comparison reference for this type of operation. Also developed recently, a
multiset-based methodology has been described that is capable of encouraging
performance that combines spatial accuracy, stability, and robustness while
requiring minimal computational resources (hardware and/or training and
recognition time). The interesting features of the latter methodology mostly
follow from the enhanced selectivity and sensitivity, as well as good
robustness to data perturbations and outliers, allowed by the coincidence
similarity index on which the multiset approach to supervised image
segmentation is based. After describing the deep learning and multiset
approaches, the present work develops two comparison experiments between them
which are primarily aimed at illustrating their respective main interesting
features when applied to the adopted specific type of data and parameter
configurations. While the deep learning approach confirmed its potential for
performing image segmentation, the alternative multiset methodology allowed for
encouraging accuracy while requiring little computational resources.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
