<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: PREPRINT: Do OpenSSF Scorecard Practices Contribute to Fewer Vulnerabilities?. (arXiv:2210.14884v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14884">http://arxiv.org/abs/2210.14884</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14884] PREPRINT: Do OpenSSF Scorecard Practices Contribute to Fewer Vulnerabilities?](http://arxiv.org/abs/2210.14884)</code></li>
<li>Summary: <p>Due to the ever-increasing security breaches, practitioners are motivated to
produce more secure software. In the United States, the White House Office
released a memorandum on Executive Order (EO) 14028 that mandates organizations
provide self-attestation of the use of secure software development practices.
The OpenSSF Scorecard project allows practitioners to measure the use of
software security practices automatically. However, little research has been
done to determine whether the use of security practices improves package
security, particularly which security practices have the biggest impact on
security outcomes. The goal of this study is to assist practitioners and
researchers making informed decisions on which security practices to adopt
through the development of models between software security practice scores and
security vulnerability counts.
</p></li>
</ul>

<p>To that end, we developed five supervised machine learning models for npm and
PyPI packages using the OpenSSF Scorecared security practices scores and
aggregate security scores as predictors and the number of externally-reported
vulnerabilities as a target variable. Our models found four security practices
(Maintained, Code Review, Branch Protection, and Security Policy) were the most
important practices influencing vulnerability count. However, we had low R^2
(ranging from 9% to 12%) when we tested the models to predict vulnerability
counts. Additionally, we observed that the number of reported vulnerabilities
increased rather than reduced as the aggregate security score of the packages
increased. Both findings indicate that additional factors may influence the
package vulnerability count. We suggest that vulnerability count and security
score data be refined such that these measures may be used to provide
actionable guidance on security practices.
</p>

<h3>Title: Perfectly Secure Steganography Using Minimum Entropy Coupling. (arXiv:2210.14889v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14889">http://arxiv.org/abs/2210.14889</a></li>
<li>Code URL: <a href="https://github.com/schroederdewitt/perfectly-secure-steganography">https://github.com/schroederdewitt/perfectly-secure-steganography</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14889] Perfectly Secure Steganography Using Minimum Entropy Coupling](http://arxiv.org/abs/2210.14889)</code></li>
<li>Summary: <p>Steganography is the practice of encoding secret information into innocuous
content in such a manner that an adversarial third party would not realize that
there is hidden meaning. While this problem has classically been studied in
security literature, recent advances in generative models have led to a shared
interest among security and machine learning researchers in developing scalable
steganography techniques. In this work, we show that a steganography procedure
is perfectly secure under \citet{cachin_perfect}'s information theoretic-model
of steganography if and only if it is induced by a coupling. Furthermore, we
show that, among perfectly secure procedures, a procedure is maximally
efficient if and only if it is induced by a minimum entropy coupling. These
insights yield what are, to the best of our knowledge, the first steganography
algorithms to achieve perfect security guarantees with non-trivial efficiency;
additionally, these algorithms are highly scalable. To provide empirical
validation, we compare a minimum entropy coupling-based approach to three
modern baselines -- arithmetic coding, Meteor, and adaptive dynamic grouping --
using GPT-2 and WaveRNN as communication channels. We find that the minimum
entropy coupling-based approach yields superior encoding efficiency, despite
its stronger security constraints. In aggregate, these results suggest that it
may be natural to view information-theoretic steganography through the lens of
minimum entropy coupling.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: WebCrack: Dynamic Dictionary Adjustment for Web Weak Password Detection based on Blasting Response Event Discrimination. (arXiv:2210.14582v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14582">http://arxiv.org/abs/2210.14582</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14582] WebCrack: Dynamic Dictionary Adjustment for Web Weak Password Detection based on Blasting Response Event Discrimination](http://arxiv.org/abs/2210.14582)</code></li>
<li>Summary: <p>The feature diversity of different web systems in page elements, submission
contents and return information makes it difficult to detect weak password
automatically. To solve this problem, multi-factor correlation detection method
as integrated in the DBKER algorithm is proposed to achieve automatic detection
of web weak passwords and universal passwords. It generates password
dictionaries based on PCFG algorithm, proposes to judge blasting result via 4
steps with traditional static keyword features and dynamic page feature
information. Then the blasting failure events are discriminated and the
usernames are blasted based on response time. Thereafter the weak password
dictionary is dynamically adjusted according to the hints provided by the
response failure page. Based on the algorithm, this paper implements a
detection system named WebCrack. Experimental results of two blasting tests on
DedeCMS and Discuz! systems as well as a random backend test show that the
proposed method can detect weak passwords and universal passwords of various
web systems with an average accuracy rate of about 93.75%, providing security
advisories for users' password settings with strong practicability.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: TPFNet: A Novel Text In-painting Transformer for Text Removal. (arXiv:2210.14461v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14461">http://arxiv.org/abs/2210.14461</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14461] TPFNet: A Novel Text In-painting Transformer for Text Removal](http://arxiv.org/abs/2210.14461)</code></li>
<li>Summary: <p>Text erasure from an image is helpful for various tasks such as image editing
and privacy preservation. In this paper, we present TPFNet, a novel one-stage
(end-toend) network for text removal from images. Our network has two parts:
feature synthesis and image generation. Since noise can be more effectively
removed from low-resolution images, part 1 operates on low-resolution images.
The output of part 1 is a low-resolution text-free image. Part 2 uses the
features learned in part 1 to predict a high-resolution text-free image. In
part 1, we use "pyramidal vision transformer" (PVT) as the encoder. Further, we
use a novel multi-headed decoder that generates a high-pass filtered image and
a segmentation map, in addition to a text-free image. The segmentation branch
helps locate the text precisely, and the high-pass branch helps in learning the
image structure. To precisely locate the text, TPFNet employs an adversarial
loss that is conditional on the segmentation map rather than the input image.
On Oxford, SCUT, and SCUT-EnsText datasets, our network outperforms recently
proposed networks on nearly all the metrics. For example, on SCUT-EnsText
dataset, TPFNet has a PSNR (higher is better) of 39.0 and text-detection
precision (lower is better) of 21.1, compared to the best previous technique,
which has a PSNR of 32.3 and precision of 53.2. The source code can be obtained
from https://github.com/CandleLabAI/TPFNet
</p></li>
</ul>

<h3>Title: Leveraging Open Data and Task Augmentation to Automated Behavioral Coding of Psychotherapy Conversations in Low-Resource Scenarios. (arXiv:2210.14254v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14254">http://arxiv.org/abs/2210.14254</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14254] Leveraging Open Data and Task Augmentation to Automated Behavioral Coding of Psychotherapy Conversations in Low-Resource Scenarios](http://arxiv.org/abs/2210.14254)</code></li>
<li>Summary: <p>In psychotherapy interactions, the quality of a session is assessed by
codifying the communicative behaviors of participants during the conversation
through manual observation and annotation. Developing computational approaches
for automated behavioral coding can reduce the burden on human coders and
facilitate the objective evaluation of the intervention. In the real world,
however, implementing such algorithms is associated with data sparsity
challenges since privacy concerns lead to limited available in-domain data. In
this paper, we leverage a publicly available conversation-based dataset and
transfer knowledge to the low-resource behavioral coding task by performing an
intermediate language model training via meta-learning. We introduce a task
augmentation method to produce a large number of "analogy tasks" - tasks
similar to the target one - and demonstrate that the proposed framework
predicts target behaviors more accurately than all the other baseline models.
</p></li>
</ul>

<h3>Title: Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe. (arXiv:2210.14348v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14348">http://arxiv.org/abs/2210.14348</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14348] Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe](http://arxiv.org/abs/2210.14348)</code></li>
<li>Summary: <p>Privacy concerns have attracted increasing attention in data-driven products
and services. Existing legislation forbids arbitrary processing of personal
data collected from individuals. Generating synthetic versions of such data
with a formal privacy guarantee such as differential privacy (DP) is considered
to be a solution to address privacy concerns. In this direction, we show a
simple, practical, and effective recipe in the text domain: simply fine-tuning
a generative language model with DP allows us to generate useful synthetic text
while mitigating privacy concerns. Through extensive empirical analyses, we
demonstrate that our method produces synthetic data that is competitive in
terms of utility with its non-private counterpart and meanwhile provides strong
protection against potential privacy leakages.
</p></li>
</ul>

<h3>Title: Streaming Submodular Maximization with Differential Privacy. (arXiv:2210.14315v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14315">http://arxiv.org/abs/2210.14315</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14315] Streaming Submodular Maximization with Differential Privacy](http://arxiv.org/abs/2210.14315)</code></li>
<li>Summary: <p>In this work, we study the problem of privately maximizing a submodular
function in the streaming setting. Extensive work has been done on privately
maximizing submodular functions in the general case when the function depends
upon the private data of individuals. However, when the size of the data stream
drawn from the domain of the objective function is large or arrives very fast,
one must privately optimize the objective within the constraints of the
streaming setting. We establish fundamental differentially private baselines
for this problem and then derive better trade-offs between privacy and utility
for the special case of decomposable submodular functions. A submodular
function is decomposable when it can be written as a sum of submodular
functions; this structure arises naturally when each summand function models
the utility of an individual and the goal is to study the total utility of the
whole population as in the well-known Combinatorial Public Projects Problem.
Finally, we complement our theoretical analysis with experimental
corroboration.
</p></li>
</ul>

<h3>Title: An Attention-based Long Short-Term Memory Framework for Detection of Bitcoin Scams. (arXiv:2210.14408v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14408">http://arxiv.org/abs/2210.14408</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14408] An Attention-based Long Short-Term Memory Framework for Detection of Bitcoin Scams](http://arxiv.org/abs/2210.14408)</code></li>
<li>Summary: <p>Bitcoin is the most common cryptocurrency involved in cyber scams.
Cybercriminals often utilize pseudonymity and privacy protection mechanism
associated with Bitcoin transactions to make their scams virtually untraceable.
The Ponzi scheme has attracted particularly significant attention among Bitcoin
fraudulent activities. This paper considers a multi-class classification
problem to determine whether a transaction is involved in Ponzi schemes or
other cyber scams, or is a non-scam transaction. We design a specifically
designed crawler to collect data and propose a novel Attention-based Long
Short-Term Memory (A-LSTM) method for the classification problem. The
experimental results show that the proposed model has better efficiency and
accuracy than existing approaches, including Random Forest, Extra Trees,
Gradient Boosting, and classical LSTM. With correctly identified scam features,
our proposed A-LSTM achieves an F1-score over 82% for the original data and
outperforms the existing approaches.
</p></li>
</ul>

<h3>Title: Privacy Analysis of Samsung's Crowd-Sourced Bluetooth Location Tracking System. (arXiv:2210.14702v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14702">http://arxiv.org/abs/2210.14702</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14702] Privacy Analysis of Samsung's Crowd-Sourced Bluetooth Location Tracking System](http://arxiv.org/abs/2210.14702)</code></li>
<li>Summary: <p>We present a detailed privacy analysis of Samsung's Offline Finding (OF)
protocol, which is part of Samsung's Find My Mobile (FMM) location tracking
system for locating Samsung mobile devices, such as Samsung smartphones and
Bluetooth trackers (Galaxy SmartTags). The OF protocol uses Bluetooth Low
Energy (BLE) to broadcast a unique beacon for a lost device. This beacon is
then picked up by nearby Samsung phones or tablets (the {\em finder} devices),
which then forward the unique beacon, along with the location it was detected
at, to a Samsung managed server. The owner of a lost device can then query the
server to locate their device. We examine several security and privacy related
properties of the OF protocol and its implementation, from the perspectives of
the owner, the finder and the vendor. These include examining: the possibility
of identifying the owner of a device through the Bluetooth data obtained from
the device, the possibility for a malicious actor to perform unwanted tracking
against a person by exploiting the OF network, the possibility for the vendor
to de-anonymise location reports to determine the locations of the owners or
the finders of lost devices, and the possibility for an attacker to compromise
the integrity of the location reports. Our findings suggest that there are
privacy risks on all accounts, arising from issues in the design and the
implementation of the OF protocol.
</p></li>
</ul>

<h3>Title: Ballot stuffing and participation privacy in pollsite voting. (arXiv:2210.14833v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14833">http://arxiv.org/abs/2210.14833</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14833] Ballot stuffing and participation privacy in pollsite voting](http://arxiv.org/abs/2210.14833)</code></li>
<li>Summary: <p>We study the problem of simultaneously addressing both ballot stuffing and
participation privacy for pollsite voting systems. Ballot stuffing is the
attack where fake ballots (not cast by any eligible voter) are inserted into
the system. Participation privacy is about hiding which eligible voters have
actually cast their vote. So far, the combination of ballot stuffing and
participation privacy has been mostly studied for internet voting, where voters
are assumed to own trusted computing devices. Such approaches are inapplicable
to pollsite voting where voters typically vote bare handed. We present an
eligibility audit protocol to detect ballot stuffing in pollsite voting
protocols. This is done while protecting participation privacy from a remote
observer - one who does not physically observe voters during voting. Our
protocol can be instantiated as an additional layer on top of most existing
pollsite E2E-V voting protocols. To achieve our guarantees, we develop an
efficient zero-knowledge proof (ZKP), that, given a value $v$ and a set $\Phi$
of commitments, proves $v$ is committed by some commitment in $\Phi$, without
revealing which one. We call this a ZKP of reverse set membership because of
its relationship to the popular ZKPs of set membership. This ZKP may be of
independent interest.
</p></li>
</ul>

<h3>Title: A Case for Business Process-Specific Foundation Models. (arXiv:2210.14739v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14739">http://arxiv.org/abs/2210.14739</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14739] A Case for Business Process-Specific Foundation Models](http://arxiv.org/abs/2210.14739)</code></li>
<li>Summary: <p>The inception of large language models has helped advance state-of-the-art
performance on numerous natural language tasks. This has also opened the door
for the development of foundation models for other domains and data modalities
such as images, code, and music. In this paper, we argue that business process
data representations have unique characteristics that warrant the development
of a new class of foundation models to handle tasks like process mining,
optimization, and decision making. These models should also tackle the unique
challenges of applying AI to business processes which include data scarcity,
multi-modal representations, domain specific terminology, and privacy concerns.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Adaptive Test-Time Defense with the Manifold Hypothesis. (arXiv:2210.14404v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14404">http://arxiv.org/abs/2210.14404</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14404] Adaptive Test-Time Defense with the Manifold Hypothesis](http://arxiv.org/abs/2210.14404)</code></li>
<li>Summary: <p>In this work, we formulate a novel framework of adversarial robustness using
the manifold hypothesis. Our framework provides sufficient conditions for
defending against adversarial examples. We develop a test-time defense method
with our formulation and variational inference. The developed approach combines
manifold learning with the Bayesian framework to provide adversarial robustness
without the need for adversarial training. We show that our proposed approach
can provide adversarial robustness even if attackers are aware of existence of
test-time defense. In additions, our approach can also serve as a test-time
defense mechanism for variational autoencoders.
</p></li>
</ul>

<h3>Title: Flexible Android Malware Detection Model based on Generative Adversarial Networks with Code Tensor. (arXiv:2210.14225v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14225">http://arxiv.org/abs/2210.14225</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14225] Flexible Android Malware Detection Model based on Generative Adversarial Networks with Code Tensor](http://arxiv.org/abs/2210.14225)</code></li>
<li>Summary: <p>The behavior of malware threats is gradually increasing, heightened the need
for malware detection. However, existing malware detection methods only target
at the existing malicious samples, the detection of fresh malicious code and
variants of malicious code is limited. In this paper, we propose a novel scheme
that detects malware and its variants efficiently. Based on the idea of the
generative adversarial networks (GANs), we obtain the `true' sample
distribution that satisfies the characteristics of the real malware, use them
to deceive the discriminator, thus achieve the defense against malicious code
attacks and improve malware detection. Firstly, a new Android malware APK to
image texture feature extraction segmentation method is proposed, which is
called segment self-growing texture segmentation algorithm. Secondly, tensor
singular value decomposition (tSVD) based on the low-tubal rank transforms
malicious features with different sizes into a fixed third-order tensor
uniformly, which is entered into the neural network for training and learning.
Finally, a flexible Android malware detection model based on GANs with code
tensor (MTFD-GANs) is proposed. Experiments show that the proposed model can
generally surpass the traditional malware detection model, with a maximum
improvement efficiency of 41.6\%. At the same time, the newly generated samples
of the GANs generator greatly enrich the sample diversity. And retraining
malware detector can effectively improve the detection efficiency and
robustness of traditional models.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Universal Evasion Attacks on Summarization Scoring. (arXiv:2210.14260v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14260">http://arxiv.org/abs/2210.14260</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14260] Universal Evasion Attacks on Summarization Scoring](http://arxiv.org/abs/2210.14260)</code></li>
<li>Summary: <p>The automatic scoring of summaries is important as it guides the development
of summarizers. Scoring is also complex, as it involves multiple aspects such
as fluency, grammar, and even textual entailment with the source text. However,
summary scoring has not been considered a machine learning task to study its
accuracy and robustness. In this study, we place automatic scoring in the
context of regression machine learning tasks and perform evasion attacks to
explore its robustness. Attack systems predict a non-summary string from each
input, and these non-summary strings achieve competitive scores with good
summarizers on the most popular metrics: ROUGE, METEOR, and BERTScore. Attack
systems also "outperform" state-of-the-art summarization methods on ROUGE-1 and
ROUGE-L, and score the second-highest on METEOR. Furthermore, a BERTScore
backdoor is observed: a simple trigger can score higher than any automatic
summarization method. The evasion attacks in this work indicate the low
robustness of current scoring systems at the system level. We hope that our
highlighting of these proposed attacks will facilitate the development of
summary scores.
</p></li>
</ul>

<h3>Title: Similarity between Units of Natural Language: The Transition from Coarse to Fine Estimation. (arXiv:2210.14275v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14275">http://arxiv.org/abs/2210.14275</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14275] Similarity between Units of Natural Language: The Transition from Coarse to Fine Estimation](http://arxiv.org/abs/2210.14275)</code></li>
<li>Summary: <p>Capturing the similarities between human language units is crucial for
explaining how humans associate different objects, and therefore its
computation has received extensive attention, research, and applications. With
the ever-increasing amount of information around us, calculating similarity
becomes increasingly complex, especially in many cases, such as legal or
medical affairs, measuring similarity requires extra care and precision, as
small acts within a language unit can have significant real-world effects. My
research goal in this thesis is to develop regression models that account for
similarities between language units in a more refined way.
</p></li>
</ul>

<p>Computation of similarity has come a long way, but approaches to debugging
the measures are often based on continually fitting human judgment values. To
this end, my goal is to develop an algorithm that precisely catches loopholes
in a similarity calculation. Furthermore, most methods have vague definitions
of the similarities they compute and are often difficult to interpret. The
proposed framework addresses both shortcomings. It constantly improves the
model through catching different loopholes. In addition, every refinement of
the model provides a reasonable explanation. The regression model introduced in
this thesis is called progressively refined similarity computation, which
combines attack testing with adversarial training. The similarity regression
model of this thesis achieves state-of-the-art performance in handling edge
cases.
</p>

<h3>Title: Short Paper: Static and Microarchitectural ML-Based Approaches For Detecting Spectre Vulnerabilities and Attacks. (arXiv:2210.14452v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14452">http://arxiv.org/abs/2210.14452</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14452] Short Paper: Static and Microarchitectural ML-Based Approaches For Detecting Spectre Vulnerabilities and Attacks](http://arxiv.org/abs/2210.14452)</code></li>
<li>Summary: <p>Spectre intrusions exploit speculative execution design vulnerabilities in
modern processors. The attacks violate the principles of isolation in programs
to gain unauthorized private user information. Current state-of-the-art
detection techniques utilize micro-architectural features or vulnerable
speculative code to detect these threats. However, these techniques are
insufficient as Spectre attacks have proven to be more stealthy with recently
discovered variants that bypass current mitigation mechanisms. Side-channels
generate distinct patterns in processor cache, and sensitive information
leakage is dependent on source code vulnerable to Spectre attacks, where an
adversary uses these vulnerabilities, such as branch prediction, which causes a
data breach. Previous studies predominantly approach the detection of Spectre
attacks using the microarchitectural analysis, a reactive approach. Hence, in
this paper, we present the first comprehensive evaluation of static and
microarchitectural analysis-assisted machine learning approaches to detect
Spectre vulnerable code snippets (preventive) and Spectre attacks (reactive).
We evaluate the performance trade-offs in employing classifiers for detecting
Spectre vulnerabilities and attacks.
</p></li>
</ul>

<h3>Title: DEMIS: A Threat Model for Selectively Encrypted Visual Surveillance Data. (arXiv:2210.14622v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14622">http://arxiv.org/abs/2210.14622</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14622] DEMIS: A Threat Model for Selectively Encrypted Visual Surveillance Data](http://arxiv.org/abs/2210.14622)</code></li>
<li>Summary: <p>The monitoring of individuals/objects has become increasingly possible in
recent years due to the convenience of integrated cameras in many devices. Due
to the important moments or activities of people captured by these devices, it
has made it a great asset for attackers to launch attacks against by exploiting
the weaknesses in these devices. Different studies proposed na\"ive/selective
encryption of the captured visual data for safety but despite the encryption,
an attacker can still access or manipulate such data. This paper proposed a
novel threat model, DEMIS which helps analyse the threats against such
encrypted videos. The paper also examines the attack vectors that can be used
for threats and the mitigation that will reduce or prevent the attack. For
experiments, firstly the data set is generated by applying selective encryption
on the Regions-of-interests (ROI) of the tested videos using the image
segmentation technique and Chacha20 cipher. Secondly, different types of
attacks, such as inverse, lowercase, uppercase, random insertion, and
malleability attacks were simulated in experiments to show the effects of the
attacks, the risk matrix, and the severity of these attacks. Our developed data
set with the original, selective encrypted, and attacked videos are available
on git-repository(https://github.com/Ifeoluwapoo/video-datasets) for future
researchers.
</p></li>
</ul>

<h3>Title: Cover Reproducible Steganography via Deep Generative Models. (arXiv:2210.14632v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14632">http://arxiv.org/abs/2210.14632</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14632] Cover Reproducible Steganography via Deep Generative Models](http://arxiv.org/abs/2210.14632)</code></li>
<li>Summary: <p>Whereas cryptography easily arouses attacks by means of encrypting a secret
message into a suspicious form, steganography is advantageous for its
resilience to attacks by concealing the message in an innocent-looking cover
signal. Minimal distortion steganography, one of the mainstream steganography
frameworks, embeds messages while minimizing the distortion caused by the
modification on the cover elements. Due to the unavailability of the original
cover signal for the receiver, message embedding is realized by finding the
coset leader of the syndrome function of steganographic codes migrated from
channel coding, which is complex and has limited performance. Fortunately, deep
generative models and the robust semantic of generated data make it possible
for the receiver to perfectly reproduce the cover signal from the stego signal.
With this advantage, we propose cover-reproducible steganography where the
source coding, e.g., arithmetic coding, serves as the steganographic code.
Specifically, the decoding process of arithmetic coding is used for message
embedding and its encoding process is regarded as message extraction. Taking
text-to-speech and text-to-image synthesis tasks as two examples, we illustrate
the feasibility of cover-reproducible steganography. Steganalysis experiments
and theoretical analysis are conducted to demonstrate that the proposed methods
outperform the existing methods in most cases.
</p></li>
</ul>

<h3>Title: Identifying Threats, Cybercrime and Digital Forensic Opportunities in Smart City Infrastructure via Threat Modeling. (arXiv:2210.14692v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14692">http://arxiv.org/abs/2210.14692</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14692] Identifying Threats, Cybercrime and Digital Forensic Opportunities in Smart City Infrastructure via Threat Modeling](http://arxiv.org/abs/2210.14692)</code></li>
<li>Summary: <p>Technological advances have enabled multiple countries to consider
implementing Smart City Infrastructure to provide in-depth insights into
different data points and enhance the lives of citizens. Unfortunately, these
new technological implementations also entice adversaries and cybercriminals to
execute cyber-attacks and commit criminal acts on these modern infrastructures.
Given the borderless nature of cyber attacks, varying levels of understanding
of smart city infrastructure and ongoing investigation workloads, law
enforcement agencies and investigators would be hard-pressed to respond to
these kinds of cybercrime. Without an investigative capability by
investigators, these smart infrastructures could become new targets favored by
cybercriminals.
</p></li>
</ul>

<p>To address the challenges faced by investigators, we propose a common
definition of smart city infrastructure. Based on the definition, we utilize
the STRIDE threat modeling methodology and the Microsoft Threat Modeling Tool
to identify threats present in the infrastructure and create a threat model
which can be further customized or extended by interested parties. Next, we map
offences, possible evidence sources and types of threats identified to help
investigators understand what crimes could have been committed and what
evidence would be required in their investigation work. Finally, noting that
Smart City Infrastructure investigations would be a global multi-faceted
challenge, we discuss technical and legal opportunities in digital forensics on
Smart City Infrastructure.
</p>

<h2>robust</h2>
<h3>Title: Accelerating Certified Robustness Training via Knowledge Transfer. (arXiv:2210.14283v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14283">http://arxiv.org/abs/2210.14283</a></li>
<li>Code URL: <a href="https://github.com/ethos-lab/crt-neurips22">https://github.com/ethos-lab/crt-neurips22</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14283] Accelerating Certified Robustness Training via Knowledge Transfer](http://arxiv.org/abs/2210.14283)</code></li>
<li>Summary: <p>Training deep neural network classifiers that are certifiably robust against
adversarial attacks is critical to ensuring the security and reliability of
AI-controlled systems. Although numerous state-of-the-art certified training
methods have been developed, they are computationally expensive and scale
poorly with respect to both dataset and network complexity. Widespread usage of
certified training is further hindered by the fact that periodic retraining is
necessary to incorporate new data and network improvements. In this paper, we
propose Certified Robustness Transfer (CRT), a general-purpose framework for
reducing the computational overhead of any certifiably robust training method
through knowledge transfer. Given a robust teacher, our framework uses a novel
training loss to transfer the teacher's robustness to the student. We provide
theoretical and empirical validation of CRT. Our experiments on CIFAR-10 show
that CRT speeds up certified robustness training by $8 \times$ on average
across three different architecture generations while achieving comparable
robustness to state-of-the-art methods. We also show that CRT can scale to
large-scale datasets like ImageNet.
</p></li>
</ul>

<h3>Title: Cross-View Image Sequence Geo-localization. (arXiv:2210.14295v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14295">http://arxiv.org/abs/2210.14295</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14295] Cross-View Image Sequence Geo-localization](http://arxiv.org/abs/2210.14295)</code></li>
<li>Summary: <p>Cross-view geo-localization aims to estimate the GPS location of a query
ground-view image by matching it to images from a reference database of
geo-tagged aerial images. To address this challenging problem, recent
approaches use panoramic ground-view images to increase the range of
visibility. Although appealing, panoramic images are not readily available
compared to the videos of limited Field-Of-View (FOV) images. In this paper, we
present the first cross-view geo-localization method that works on a sequence
of limited FOV images. Our model is trained end-to-end to capture the temporal
structure that lies within the frames using the attention-based temporal
feature aggregation module. To robustly tackle different sequences length and
GPS noises during inference, we propose to use a sequential dropout scheme to
simulate variant length sequences. To evaluate the proposed approach in
realistic settings, we present a new large-scale dataset containing ground-view
sequences along with the corresponding aerial-view images. Extensive
experiments and comparisons demonstrate the superiority of the proposed
approach compared to several competitive baselines.
</p></li>
</ul>

<h3>Title: Adversarially Robust Medical Classification via Attentive Convolutional Neural Networks. (arXiv:2210.14405v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14405">http://arxiv.org/abs/2210.14405</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14405] Adversarially Robust Medical Classification via Attentive Convolutional Neural Networks](http://arxiv.org/abs/2210.14405)</code></li>
<li>Summary: <p>Convolutional neural network-based medical image classifiers have been shown
to be especially susceptible to adversarial examples. Such instabilities are
likely to be unacceptable in the future of automated diagnoses. Though
statistical adversarial example detection methods have proven to be effective
defense mechanisms, additional research is necessary that investigates the
fundamental vulnerabilities of deep-learning-based systems and how best to
build models that jointly maximize traditional and robust accuracy. This paper
presents the inclusion of attention mechanisms in CNN-based medical image
classifiers as a reliable and effective strategy for increasing robust accuracy
without sacrifice. This method is able to increase robust accuracy by up to 16%
in typical adversarial scenarios and up to 2700% in extreme cases.
</p></li>
</ul>

<h3>Title: Improving Adversarial Robustness via Joint Classification and Multiple Explicit Detection Classes. (arXiv:2210.14410v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14410">http://arxiv.org/abs/2210.14410</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14410] Improving Adversarial Robustness via Joint Classification and Multiple Explicit Detection Classes](http://arxiv.org/abs/2210.14410)</code></li>
<li>Summary: <p>This work concerns the development of deep networks that are certifiably
robust to adversarial attacks. Joint robust classification-detection was
recently introduced as a certified defense mechanism, where adversarial
examples are either correctly classified or assigned to the "abstain" class. In
this work, we show that such a provable framework can benefit by extension to
networks with multiple explicit abstain classes, where the adversarial examples
are adaptively assigned to those. We show that naively adding multiple abstain
classes can lead to "model degeneracy", then we propose a regularization
approach and a training method to counter this degeneracy by promoting full use
of the multiple abstain classes. Our experiments demonstrate that the proposed
approach consistently achieves favorable standard vs. robust verified accuracy
tradeoffs, outperforming state-of-the-art algorithms for various choices of
number of abstain classes.
</p></li>
</ul>

<h3>Title: Towards A Robust Deepfake Detector:Common Artifact Deepfake Detection Model. (arXiv:2210.14457v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14457">http://arxiv.org/abs/2210.14457</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14457] Towards A Robust Deepfake Detector:Common Artifact Deepfake Detection Model](http://arxiv.org/abs/2210.14457)</code></li>
<li>Summary: <p>Existing deepfake detection methods perform poorly on face forgeries
generated by unseen face manipulation algorithms. The generalization ability of
previous methods is mainly improved by modeling hand-crafted artifact features.
Such properties, on the other hand, impede their further improvement. In this
paper, we propose a novel deepfake detection method named Common Artifact
Deepfake Detection Model, which aims to learn common artifact features in
different face manipulation algorithms. To this end, we find that the main
obstacle to learning common artifact features is that models are easily misled
by the identity representation feature. We call this phenomenon Implicit
Identity Leakage (IIL). Extensive experimental results demonstrate that, by
learning the binary classifiers with the guidance of the Artifact Detection
Module, our method effectively reduces the influence of IIL and outperforms the
state-of-the-art by a large margin, proving that hand-crafted artifact feature
detectors are not indispensable when tackling deepfake problems.
</p></li>
</ul>

<h3>Title: End-to-End Multimodal Representation Learning for Video Dialog. (arXiv:2210.14512v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14512">http://arxiv.org/abs/2210.14512</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14512] End-to-End Multimodal Representation Learning for Video Dialog](http://arxiv.org/abs/2210.14512)</code></li>
<li>Summary: <p>Video-based dialog task is a challenging multimodal learning task that has
received increasing attention over the past few years with state-of-the-art
obtaining new performance records. This progress is largely powered by the
adaptation of the more powerful transformer-based language encoders. Despite
this progress, existing approaches do not effectively utilize visual features
to help solve tasks. Recent studies show that state-of-the-art models are
biased toward textual information rather than visual cues. In order to better
leverage the available visual information, this study proposes a new framework
that combines 3D-CNN network and transformer-based networks into a single
visual encoder to extract more robust semantic representations from videos. The
visual encoder is jointly trained end-to-end with other input modalities such
as text and audio. Experiments on the AVSD task show significant improvement
over baselines in both generative and retrieval tasks.
</p></li>
</ul>

<h3>Title: Compressing And Debiasing Vision-Language Pre-Trained Models for Visual Question Answering. (arXiv:2210.14558v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14558">http://arxiv.org/abs/2210.14558</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14558] Compressing And Debiasing Vision-Language Pre-Trained Models for Visual Question Answering](http://arxiv.org/abs/2210.14558)</code></li>
<li>Summary: <p>Despite the excellent performance of large-scale vision-language pre-trained
models (VLPs) on conventional visual question answering task, they still suffer
from two problems: First, VLPs tend to rely on language biases in datasets and
fail to generalize to out-of-distribution (OOD) data. Second, they are
inefficient in terms of memory footprint and computation. Although promising
progress has been made in both problems, most existing works tackle them
independently. To facilitate the application of VLP to VQA tasks, it is
imperative to jointly study VLP compression and OOD robustness, which, however,
has not yet been explored. In this paper, we investigate whether a VLP can be
compressed and debiased simultaneously by searching sparse and robust
subnetworks. To this end, we conduct extensive experiments with LXMERT, a
representative VLP, on the OOD dataset VQA-CP v2. We systematically study the
design of a training and compression pipeline to search the subnetworks, as
well as the assignment of sparsity to different modality-specific modules. Our
results show that there indeed exist sparse and robust LXMERT subnetworks,
which significantly outperform the full model (without debiasing) with much
fewer parameters. These subnetworks also exceed the current SoTA debiasing
models with comparable or fewer parameters. We will release the codes on
publication.
</p></li>
</ul>

<h3>Title: Rapid and robust endoscopic content area estimation: A lean GPU-based pipeline and curated benchmark dataset. (arXiv:2210.14771v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14771">http://arxiv.org/abs/2210.14771</a></li>
<li>Code URL: <a href="https://github.com/charliebudd/torch-content-area">https://github.com/charliebudd/torch-content-area</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14771] Rapid and robust endoscopic content area estimation: A lean GPU-based pipeline and curated benchmark dataset](http://arxiv.org/abs/2210.14771)</code></li>
<li>Summary: <p>Endoscopic content area refers to the informative area enclosed by the dark,
non-informative, border regions present in most endoscopic footage. The
estimation of the content area is a common task in endoscopic image processing
and computer vision pipelines. Despite the apparent simplicity of the problem,
several factors make reliable real-time estimation surprisingly challenging.
The lack of rigorous investigation into the topic combined with the lack of a
common benchmark dataset for this task has been a long-lasting issue in the
field. In this paper, we propose two variants of a lean GPU-based computational
pipeline combining edge detection and circle fitting. The two variants differ
by relying on handcrafted features, and learned features respectively to
extract content area edge point candidates. We also present a first-of-its-kind
dataset of manually annotated and pseudo-labelled content areas across a range
of surgical indications. To encourage further developments, the curated
dataset, and an implementation of both algorithms, has been made public
(https://doi.org/10.7303/syn32148000,
https://github.com/charliebudd/torch-content-area). We compare our proposed
algorithm with a state-of-the-art U-Net-based approach and demonstrate
significant improvement in terms of both accuracy (Hausdorff distance: 6.3 px
versus 118.1 px) and computational time (Average runtime per frame: 0.13 ms
versus 11.2 ms).
</p></li>
</ul>

<h3>Title: Learning a Task-specific Descriptor for Robust Matching of 3D Point Clouds. (arXiv:2210.14899v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14899">http://arxiv.org/abs/2210.14899</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14899] Learning a Task-specific Descriptor for Robust Matching of 3D Point Clouds](http://arxiv.org/abs/2210.14899)</code></li>
<li>Summary: <p>Existing learning-based point feature descriptors are usually task-agnostic,
which pursue describing the individual 3D point clouds as accurate as possible.
However, the matching task aims at describing the corresponding points
consistently across different 3D point clouds. Therefore these too accurate
features may play a counterproductive role due to the inconsistent point
feature representations of correspondences caused by the unpredictable noise,
partiality, deformation, \etc, in the local geometry. In this paper, we propose
to learn a robust task-specific feature descriptor to consistently describe the
correct point correspondence under interference. Born with an Encoder and a
Dynamic Fusion module, our method EDFNet develops from two aspects. First, we
augment the matchability of correspondences by utilizing their repetitive local
structure. To this end, a special encoder is designed to exploit two input
point clouds jointly for each point descriptor. It not only captures the local
geometry of each point in the current point cloud by convolution, but also
exploits the repetitive structure from paired point cloud by Transformer.
Second, we propose a dynamical fusion module to jointly use different scale
features. There is an inevitable struggle between robustness and
discriminativeness of the single scale feature. Specifically, the small scale
feature is robust since little interference exists in this small receptive
field. But it is not sufficiently discriminative as there are many repetitive
local structures within a point cloud. Thus the resultant descriptors will lead
to many incorrect matches. In contrast, the large scale feature is more
discriminative by integrating more neighborhood information. ...
</p></li>
</ul>

<h3>Title: On Robust Incremental Learning over Many Multilingual Steps. (arXiv:2210.14307v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14307">http://arxiv.org/abs/2210.14307</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14307] On Robust Incremental Learning over Many Multilingual Steps](http://arxiv.org/abs/2210.14307)</code></li>
<li>Summary: <p>Recent work in incremental learning has introduced diverse approaches to
tackle catastrophic forgetting from data augmentation to optimized training
regimes. However, most of them focus on very few training steps. We propose a
method for robust incremental learning over dozens of fine-tuning steps using
data from a variety of languages. We show that a combination of
data-augmentation and an optimized training regime allows us to continue
improving the model even for as many as fifty training steps. Crucially, our
augmentation strategy does not require retaining access to previous training
data and is suitable in scenarios with privacy constraints.
</p></li>
</ul>

<h3>Title: RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering. (arXiv:2210.14353v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14353">http://arxiv.org/abs/2210.14353</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14353] RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering](http://arxiv.org/abs/2210.14353)</code></li>
<li>Summary: <p>We introduce RoMQA, the first benchmark for robust, multi-evidence,
multi-answer question answering (QA). RoMQA contains clusters of questions that
are derived from related constraints mined from the Wikidata knowledge graph.
RoMQA evaluates robustness of QA models to varying constraints by measuring
worst-case performance within each question cluster. Compared to prior QA
datasets, RoMQA has more human-written questions that require reasoning over
more evidence text and have, on average, many more correct answers. In
addition, human annotators rate RoMQA questions as more natural or likely to be
asked by people. We evaluate state-of-the-art large language models in
zero-shot, few-shot, and fine-tuning settings, and find that RoMQA is
challenging: zero-shot and few-shot models perform similarly to naive
baselines, while supervised retrieval methods perform well below gold evidence
upper bounds. Moreover, existing models are not robust to variations in
question constraints, but can be made more robust by tuning on clusters of
related questions. Our results show that RoMQA is a challenging benchmark for
large language models, and provides a quantifiable test to build more robust QA
methods.
</p></li>
</ul>

<h3>Title: Bi-Link: Bridging Inductive Link Predictions from Text via Contrastive Learning of Transformers and Prompts. (arXiv:2210.14463v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14463">http://arxiv.org/abs/2210.14463</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14463] Bi-Link: Bridging Inductive Link Predictions from Text via Contrastive Learning of Transformers and Prompts](http://arxiv.org/abs/2210.14463)</code></li>
<li>Summary: <p>Inductive knowledge graph completion requires models to comprehend the
underlying semantics and logic patterns of relations. With the advance of
pretrained language models, recent research have designed transformers for link
prediction tasks. However, empirical studies show that linearizing triples
affects the learning of relational patterns, such as inversion and symmetry. In
this paper, we propose Bi-Link, a contrastive learning framework with
probabilistic syntax prompts for link predictions. Using grammatical knowledge
of BERT, we efficiently search for relational prompts according to learnt
syntactical patterns that generalize to large knowledge graphs. To better
express symmetric relations, we design a symmetric link prediction model,
establishing bidirectional linking between forward prediction and backward
prediction. This bidirectional linking accommodates flexible self-ensemble
strategies at test time. In our experiments, Bi-Link outperforms recent
baselines on link prediction datasets (WN18RR, FB15K-237, and Wikidata5M).
Furthermore, we construct Zeshel-Ind as an in-domain inductive entity linking
the environment to evaluate Bi-Link. The experimental results demonstrate that
our method yields robust representations which can generalize under domain
shift.
</p></li>
</ul>

<h3>Title: Eeny, meeny, miny, moe. How to choose data for morphological inflection. (arXiv:2210.14465v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14465">http://arxiv.org/abs/2210.14465</a></li>
<li>Code URL: <a href="https://github.com/smuradoglu/almorphinfl">https://github.com/smuradoglu/almorphinfl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14465] Eeny, meeny, miny, moe](http://arxiv.org/abs/2210.14465)</code></li>
<li>Summary: <p>Data scarcity is a widespread problem in numerous natural language processing
(NLP) tasks for low-resource languages. Within morphology, the labour-intensive
work of tagging/glossing data is a serious bottleneck for both NLP and language
documentation. Active learning (AL) aims to reduce the cost of data annotation
by selecting data that is most informative for improving the model. In this
paper, we explore four sampling strategies for the task of morphological
inflection using a Transformer model: a pair of oracle experiments where data
is chosen based on whether the model already can or cannot inflect the test
forms correctly, as well as strategies based on high/low model confidence,
entropy, as well as random selection. We investigate the robustness of each
strategy across 30 typologically diverse languages. We also perform a more
in-depth case study of Nat\"ugu. Our results show a clear benefit to selecting
data based on model confidence and entropy. Unsurprisingly, the oracle
experiment, where only incorrectly handled forms are chosen for further
training, which is presented as a proxy for linguist/language consultant
feedback, shows the most improvement. This is followed closely by choosing
low-confidence and high-entropy predictions. We also show that despite the
conventional wisdom of larger data sets yielding better accuracy, introducing
more instances of high-confidence or low-entropy forms, or forms that the model
can already inflect correctly, can reduce model performance.
</p></li>
</ul>

<h3>Title: A Robust Bias Mitigation Procedure Based on the Stereotype Content Model. (arXiv:2210.14552v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14552">http://arxiv.org/abs/2210.14552</a></li>
<li>Code URL: <a href="https://github.com/mxeddie/demagnosticdebias">https://github.com/mxeddie/demagnosticdebias</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14552] A Robust Bias Mitigation Procedure Based on the Stereotype Content Model](http://arxiv.org/abs/2210.14552)</code></li>
<li>Summary: <p>The Stereotype Content model (SCM) states that we tend to perceive minority
groups as cold, incompetent or both. In this paper we adapt existing work to
demonstrate that the Stereotype Content model holds for contextualised word
embeddings, then use these results to evaluate a fine-tuning process designed
to drive a language model away from stereotyped portrayals of minority groups.
We find the SCM terms are better able to capture bias than demographic agnostic
terms related to pleasantness. Further, we were able to reduce the presence of
stereotypes in the model through a simple fine-tuning procedure that required
minimal human and computer resources, without harming downstream performance.
We present this work as a prototype of a debiasing procedure that aims to
remove the need for a priori knowledge of the specifics of bias in the model.
</p></li>
</ul>

<h3>Title: Multimodal Contrastive Learning via Uni-Modal Coding and Cross-Modal Prediction for Multimodal Sentiment Analysis. (arXiv:2210.14556v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14556">http://arxiv.org/abs/2210.14556</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14556] Multimodal Contrastive Learning via Uni-Modal Coding and Cross-Modal Prediction for Multimodal Sentiment Analysis](http://arxiv.org/abs/2210.14556)</code></li>
<li>Summary: <p>Multimodal representation learning is a challenging task in which previous
work mostly focus on either uni-modality pre-training or cross-modality fusion.
In fact, we regard modeling multimodal representation as building a skyscraper,
where laying stable foundation and designing the main structure are equally
essential. The former is like encoding robust uni-modal representation while
the later is like integrating interactive information among different
modalities, both of which are critical to learning an effective multimodal
representation. Recently, contrastive learning has been successfully applied in
representation learning, which can be utilized as the pillar of the skyscraper
and benefit the model to extract the most important features contained in the
multimodal data. In this paper, we propose a novel framework named MultiModal
Contrastive Learning (MMCL) for multimodal representation to capture intra- and
inter-modality dynamics simultaneously. Specifically, we devise uni-modal
contrastive coding with an efficient uni-modal feature augmentation strategy to
filter inherent noise contained in acoustic and visual modality and acquire
more robust uni-modality representations. Besides, a pseudo siamese network is
presented to predict representation across different modalities, which
successfully captures cross-modal dynamics. Moreover, we design two contrastive
learning tasks, instance- and sentiment-based contrastive learning, to promote
the process of prediction and learn more interactive information related to
sentiment. Extensive experiments conducted on two public datasets demonstrate
that our method surpasses the state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Linguistic-Enhanced Transformer with CTC Embedding for Speech Recognition. (arXiv:2210.14725v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14725">http://arxiv.org/abs/2210.14725</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14725] Linguistic-Enhanced Transformer with CTC Embedding for Speech Recognition](http://arxiv.org/abs/2210.14725)</code></li>
<li>Summary: <p>The recent emergence of joint CTC-Attention model shows significant
improvement in automatic speech recognition (ASR). The improvement largely lies
in the modeling of linguistic information by decoder. The decoder
joint-optimized with an acoustic encoder renders the language model from
ground-truth sequences in an auto-regressive manner during training. However,
the training corpus of the decoder is limited to the speech transcriptions,
which is far less than the corpus needed to train an acceptable language model.
This leads to poor robustness of decoder. To alleviate this problem, we propose
linguistic-enhanced transformer, which introduces refined CTC information to
decoder during training process, so that the decoder can be more robust. Our
experiments on AISHELL-1 speech corpus show that the character error rate (CER)
is relatively reduced by up to 7%. We also find that in joint CTC-Attention ASR
model, decoder is more sensitive to linguistic information than acoustic
information.
</p></li>
</ul>

<h3>Title: Causal Information Bottleneck Boosts Adversarial Robustness of Deep Neural Network. (arXiv:2210.14229v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14229">http://arxiv.org/abs/2210.14229</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14229] Causal Information Bottleneck Boosts Adversarial Robustness of Deep Neural Network](http://arxiv.org/abs/2210.14229)</code></li>
<li>Summary: <p>The information bottleneck (IB) method is a feasible defense solution against
adversarial attacks in deep learning. However, this method suffers from the
spurious correlation, which leads to the limitation of its further improvement
of adversarial robustness. In this paper, we incorporate the causal inference
into the IB framework to alleviate such a problem. Specifically, we divide the
features obtained by the IB method into robust features (content information)
and non-robust features (style information) via the instrumental variables to
estimate the causal effects. With the utilization of such a framework, the
influence of non-robust features could be mitigated to strengthen the
adversarial robustness. We make an analysis of the effectiveness of our
proposed method. The extensive experiments in MNIST, FashionMNIST, and CIFAR-10
show that our method exhibits the considerable robustness against multiple
adversarial attacks. Our code would be released.
</p></li>
</ul>

<h3>Title: Robustness of Locally Differentially Private Graph Analysis Against Poisoning. (arXiv:2210.14376v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14376">http://arxiv.org/abs/2210.14376</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14376] Robustness of Locally Differentially Private Graph Analysis Against Poisoning](http://arxiv.org/abs/2210.14376)</code></li>
<li>Summary: <p>Locally differentially private (LDP) graph analysis allows private analysis
on a graph that is distributed across multiple users. However, such
computations are vulnerable to data poisoning attacks where an adversary can
skew the results by submitting malformed data. In this paper, we formally study
the impact of poisoning attacks for graph degree estimation protocols under
LDP. We make two key technical contributions. First, we observe LDP makes a
protocol more vulnerable to poisoning -- the impact of poisoning is worse when
the adversary can directly poison their (noisy) responses, rather than their
input data. Second, we observe that graph data is naturally redundant -- every
edge is shared between two users. Leveraging this data redundancy, we design
robust degree estimation protocols under LDP that can significantly reduce the
impact of data poisoning and compute degree estimates with high accuracy. We
evaluate our proposed robust degree estimation protocols under poisoning
attacks on real-world datasets to demonstrate their efficacy in practice.
</p></li>
</ul>

<h3>Title: Rhino: Deep Causal Temporal Relationship Learning With History-dependent Noise. (arXiv:2210.14706v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14706">http://arxiv.org/abs/2210.14706</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14706] Rhino: Deep Causal Temporal Relationship Learning With History-dependent Noise](http://arxiv.org/abs/2210.14706)</code></li>
<li>Summary: <p>Discovering causal relationships between different variables from time series
data has been a long-standing challenge for many domains such as climate
science, finance, and healthcare. Given the complexity of real-world
relationships and the nature of observations in discrete time, causal discovery
methods need to consider non-linear relations between variables, instantaneous
effects and history-dependent noise (the change of noise distribution due to
past actions). However, previous works do not offer a solution addressing all
these problems together. In this paper, we propose a novel causal relationship
learning framework for time-series data, called Rhino, which combines vector
auto-regression, deep learning and variational inference to model non-linear
relationships with instantaneous effects while allowing the noise distribution
to be modulated by historical observations. Theoretically, we prove the
structural identifiability of Rhino. Our empirical results from extensive
synthetic experiments and two real-world benchmarks demonstrate better
discovery performance compared to relevant baselines, with ablation studies
revealing its robustness under model misspecification.
</p></li>
</ul>

<h3>Title: Robust Contextual Linear Bandits. (arXiv:2210.14483v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14483">http://arxiv.org/abs/2210.14483</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14483] Robust Contextual Linear Bandits](http://arxiv.org/abs/2210.14483)</code></li>
<li>Summary: <p>Model misspecification is a major consideration in applications of
statistical methods and machine learning. However, it is often neglected in
contextual bandits. This paper studies a common form of misspecification, an
inter-arm heterogeneity that is not captured by context. To address this issue,
we assume that the heterogeneity arises due to arm-specific random variables,
which can be learned. We call this setting a robust contextual bandit. The
arm-specific variables explain the unknown inter-arm heterogeneity, and we
incorporate them in the robust contextual estimator of the mean reward and its
uncertainty. We develop two efficient bandit algorithms for our setting: a UCB
algorithm called RoLinUCB and a posterior-sampling algorithm called RoLinTS. We
analyze both algorithms and bound their $n$-round Bayes regret. Our experiments
show that RoLinTS is comparably statistically efficient to the classic methods
when the misspecification is low, more robust when the misspecification is
high, and significantly more computationally efficient than its naive
implementation.
</p></li>
</ul>

<h3>Title: Uncertainty-based Meta-Reinforcement Learning for Robust Radar Tracking. (arXiv:2210.14532v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14532">http://arxiv.org/abs/2210.14532</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14532] Uncertainty-based Meta-Reinforcement Learning for Robust Radar Tracking](http://arxiv.org/abs/2210.14532)</code></li>
<li>Summary: <p>Nowadays, Deep Learning (DL) methods often overcome the limitations of
traditional signal processing approaches. Nevertheless, DL methods are barely
applied in real-life applications. This is mainly due to limited robustness and
distributional shift between training and test data. To this end, recent work
has proposed uncertainty mechanisms to increase their reliability. Besides,
meta-learning aims at improving the generalization capability of DL models. By
taking advantage of that, this paper proposes an uncertainty-based
Meta-Reinforcement Learning (Meta-RL) approach with Out-of-Distribution (OOD)
detection. The presented method performs a given task in unseen environments
and provides information about its complexity. This is done by determining
first and second-order statistics on the estimated reward. Using information
about its complexity, the proposed algorithm is able to point out when tracking
is reliable. To evaluate the proposed method, we benchmark it on a
radar-tracking dataset. There, we show that our method outperforms related
Meta-RL approaches on unseen tracking scenarios in peak performance by 16% and
the baseline by 35% while detecting OOD data with an F1-Score of 72%. This
shows that our method is robust to environmental changes and reliably detects
OOD scenarios.
</p></li>
</ul>

<h3>Title: Sparsity in Continuous-Depth Neural Networks. (arXiv:2210.14672v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14672">http://arxiv.org/abs/2210.14672</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14672] Sparsity in Continuous-Depth Neural Networks](http://arxiv.org/abs/2210.14672)</code></li>
<li>Summary: <p>Neural Ordinary Differential Equations (NODEs) have proven successful in
learning dynamical systems in terms of accurately recovering the observed
trajectories. While different types of sparsity have been proposed to improve
robustness, the generalization properties of NODEs for dynamical systems beyond
the observed data are underexplored. We systematically study the influence of
weight and feature sparsity on forecasting as well as on identifying the
underlying dynamical laws. Besides assessing existing methods, we propose a
regularization technique to sparsify "input-output connections" and extract
relevant features during training. Moreover, we curate real-world datasets
consisting of human motion capture and human hematopoiesis single-cell RNA-seq
data to realistically analyze different levels of out-of-distribution (OOD)
generalization in forecasting and dynamics identification respectively. Our
extensive empirical evaluation on these challenging benchmarks suggests that
weight sparsity improves generalization in the presence of noise or irregular
sampling. However, it does not prevent learning spurious feature dependencies
in the inferred dynamics, rendering them impractical for predictions under
interventions, or for inferring the true underlying dynamics. Instead, feature
sparsity can indeed help with recovering sparse ground-truth dynamics compared
to unregularized NODEs.
</p></li>
</ul>

<h3>Title: Comparison of neural closure models for discretised PDEs. (arXiv:2210.14675v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14675">http://arxiv.org/abs/2210.14675</a></li>
<li>Code URL: <a href="https://github.com/hugomelchers/neural-closure-models">https://github.com/hugomelchers/neural-closure-models</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14675] Comparison of neural closure models for discretised PDEs](http://arxiv.org/abs/2210.14675)</code></li>
<li>Summary: <p>Neural closure models have recently been proposed as a method for efficiently
approximating small scales in multiscale systems with neural networks. The
choice of loss function and associated training procedure has a large effect on
the accuracy and stability of the resulting neural closure model. In this work,
we systematically compare three distinct procedures: "derivative fitting",
"trajectory fitting" with discretise-then-optimise, and "trajectory fitting"
with optimise-then-discretise. Derivative fitting is conceptually the simplest
and computationally the most efficient approach and is found to perform
reasonably well on one of the test problems (Kuramoto-Sivashinsky) but poorly
on the other (Burgers). Trajectory fitting is computationally more expensive
but is more robust and is therefore the preferred approach. Of the two
trajectory fitting procedures, the discretise-then-optimise approach produces
more accurate models than the optimise-then-discretise approach. While the
optimise-then-discretise approach can still produce accurate models, care must
be taken in choosing the length of the trajectories used for training, in order
to train the models on long-term behaviour while still producing reasonably
accurate gradients during training. Two existing theorems are interpreted in a
novel way that gives insight into the long-term accuracy of a neural closure
model based on how accurate it is in the short term.
</p></li>
</ul>

<h3>Title: Maximum Likelihood Learning of Energy-Based Models for Simulation-Based Inference. (arXiv:2210.14756v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14756">http://arxiv.org/abs/2210.14756</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14756] Maximum Likelihood Learning of Energy-Based Models for Simulation-Based Inference](http://arxiv.org/abs/2210.14756)</code></li>
<li>Summary: <p>We introduce two synthetic likelihood methods for Simulation-Based Inference
(SBI), to conduct either amortized or targeted inference from experimental
observations when a high-fidelity simulator is available. Both methods learn a
conditional energy-based model (EBM) of the likelihood using synthetic data
generated by the simulator, conditioned on parameters drawn from a proposal
distribution. The learned likelihood can then be combined with any prior to
obtain a posterior estimate, from which samples can be drawn using MCMC. Our
methods uniquely combine a flexible Energy-Based Model and the minimization of
a KL loss: this is in contrast to other synthetic likelihood methods, which
either rely on normalizing flows, or minimize score-based objectives; choices
that come with known pitfalls. Our first method, Amortized Unnormalized Neural
Likelihood Estimation (AUNLE), introduces a tilting trick during training that
allows to significantly lower the computational cost of inference by enabling
the use of efficient MCMC techniques. Our second method, Sequential UNLE
(SUNLE), employs a robust doubly intractable approach in order to re-use
simulation data and improve posterior accuracy on a specific dataset. We
demonstrate the properties of both methods on a range of synthetic datasets,
and apply them to a neuroscience model of the pyloric network in the crab
Cancer Borealis, matching the performance of other synthetic likelihood methods
at a fraction of the simulation budget.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Automatic Diagnosis of Myocarditis Disease in Cardiac MRI Modality using Deep Transformers and Explainable Artificial Intelligence. (arXiv:2210.14611v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14611">http://arxiv.org/abs/2210.14611</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14611] Automatic Diagnosis of Myocarditis Disease in Cardiac MRI Modality using Deep Transformers and Explainable Artificial Intelligence](http://arxiv.org/abs/2210.14611)</code></li>
<li>Summary: <p>Myocarditis is among the most important cardiovascular diseases (CVDs),
endangering the health of many individuals by damaging the myocardium. Microbes
and viruses, such as HIV, play a vital role in myocarditis disease (MCD)
incidence. Lack of MCD diagnosis in the early stages is associated with
irreversible complications. Cardiac magnetic resonance imaging (CMRI) is highly
popular among cardiologists to diagnose CVDs. In this paper, a deep learning
(DL) based computer-aided diagnosis system (CADS) is presented for the
diagnosis of MCD using CMRI images. The proposed CADS includes dataset,
preprocessing, feature extraction, classification, and post-processing steps.
First, the Z-Alizadeh dataset was selected for the experiments. The
preprocessing step included noise removal, image resizing, and data
augmentation (DA). In this step, CutMix, and MixUp techniques were used for the
DA. Then, the most recent pre-trained and transformers models were used for
feature extraction and classification using CMRI images. Our results show high
performance for the detection of MCD using transformer models compared with the
pre-trained architectures. Among the DL architectures, Turbulence Neural
Transformer (TNT) architecture achieved an accuracy of 99.73% with 10-fold
cross-validation strategy. Explainable-based Grad Cam method is used to
visualize the MCD suspected areas in CMRI images.
</p></li>
</ul>

<h3>Title: Discourse-Aware Emotion Cause Extraction in Conversations. (arXiv:2210.14419v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14419">http://arxiv.org/abs/2210.14419</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14419] Discourse-Aware Emotion Cause Extraction in Conversations](http://arxiv.org/abs/2210.14419)</code></li>
<li>Summary: <p>Emotion Cause Extraction in Conversations (ECEC) aims to extract the
utterances which contain the emotional cause in conversations. Most prior
research focuses on modelling conversational contexts with sequential encoding,
ignoring the informative interactions between utterances and
conversational-specific features for ECEC. In this paper, we investigate the
importance of discourse structures in handling utterance interactions and
conversationspecific features for ECEC. To this end, we propose a
discourse-aware model (DAM) for this task. Concretely, we jointly model ECEC
with discourse parsing using a multi-task learning (MTL) framework and
explicitly encode discourse structures via gated graph neural network (gated
GNN), integrating rich utterance interaction information to our model. In
addition, we use gated GNN to further enhance our ECEC model with
conversation-specific features. Results on the benchmark corpus show that DAM
outperform the state-of-theart (SOTA) systems in the literature. This suggests
that the discourse structure may contain a potential link between emotional
utterances and their corresponding cause expressions. It also verifies the
effectiveness of conversationalspecific features. The codes of this paper will
be available on GitHub.
</p></li>
</ul>

<h3>Title: ReSel: N-ary Relation Extraction from Scientific Text and Tables by Learning to Retrieve and Select. (arXiv:2210.14427v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14427">http://arxiv.org/abs/2210.14427</a></li>
<li>Code URL: <a href="https://github.com/night-chen/resel">https://github.com/night-chen/resel</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14427] ReSel: N-ary Relation Extraction from Scientific Text and Tables by Learning to Retrieve and Select](http://arxiv.org/abs/2210.14427)</code></li>
<li>Summary: <p>We study the problem of extracting N-ary relation tuples from scientific
articles. This task is challenging because the target knowledge tuples can
reside in multiple parts and modalities of the document. Our proposed method
ReSel decomposes this task into a two-stage procedure that first retrieves the
most relevant paragraph/table and then selects the target entity from the
retrieved component. For the high-level retrieval stage, ReSel designs a simple
and effective feature set, which captures multi-level lexical and semantic
similarities between the query and components. For the low-level selection
stage, ReSel designs a cross-modal entity correlation graph along with a
multi-view architecture, which models both semantic and document-structural
relations between entities. Our experiments on three scientific information
extraction datasets show that ReSel outperforms state-of-the-art baselines
significantly.
</p></li>
</ul>

<h3>Title: Question-Interlocutor Scope Realized Graph Modeling over Key Utterances for Dialogue Reading Comprehension. (arXiv:2210.14456v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14456">http://arxiv.org/abs/2210.14456</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14456] Question-Interlocutor Scope Realized Graph Modeling over Key Utterances for Dialogue Reading Comprehension](http://arxiv.org/abs/2210.14456)</code></li>
<li>Summary: <p>In this work, we focus on dialogue reading comprehension (DRC), a task
extracting answer spans for questions from dialogues. Dialogue context modeling
in DRC is tricky due to complex speaker information and noisy dialogue context.
To solve the two problems, previous research proposes two self-supervised tasks
respectively: guessing who a randomly masked speaker is according to the
dialogue and predicting which utterance in the dialogue contains the answer.
Although these tasks are effective, there are still urging problems: (1)
randomly masking speakers regardless of the question cannot map the speaker
mentioned in the question to the corresponding speaker in the dialogue, and
ignores the speaker-centric nature of utterances. This leads to wrong answer
extraction from utterances in unrelated interlocutors' scopes; (2) the single
utterance prediction, preferring utterances similar to the question, is limited
in finding answer-contained utterances not similar to the question. To
alleviate these problems, we first propose a new key utterances extracting
method. It performs prediction on the unit formed by several contiguous
utterances, which can realize more answer-contained utterances. Based on
utterances in the extracted units, we then propose Question-Interlocutor Scope
Realized Graph (QuISG) modeling. As a graph constructed on the text of
utterances, QuISG additionally involves the question and question-mentioning
speaker names as nodes. To realize interlocutor scopes, speakers in the
dialogue are connected with the words in their corresponding utterances.
Experiments on the benchmarks show that our method can achieve better and
competitive results against previous works.
</p></li>
</ul>

<h3>Title: Autoregressive Structured Prediction with Language Models. (arXiv:2210.14698v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14698">http://arxiv.org/abs/2210.14698</a></li>
<li>Code URL: <a href="https://github.com/lyutyuh/asp">https://github.com/lyutyuh/asp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14698] Autoregressive Structured Prediction with Language Models](http://arxiv.org/abs/2210.14698)</code></li>
<li>Summary: <p>Recent years have seen a paradigm shift in NLP towards using pretrained
language models ({PLM}) for a wide range of tasks.
</p></li>
</ul>

<p>However, there are many difficult design decisions to represent structures
(e.g. tagged text, coreference chains) in a way such that they can be captured
by PLMs.
</p>
<p>Prior work on structured prediction with PLMs typically flattens the
structured output into a sequence, which limits the quality of structural
information being learned and leads to inferior performance compared to classic
discriminative models.
</p>
<p>In this work, we describe an approach to model structures as sequences of
actions in an autoregressive manner with PLMs, allowing in-structure
dependencies to be learned without any loss.
</p>
<p>Our approach achieves the new state-of-the-art on all the structured
prediction tasks we looked at, namely, named entity recognition, end-to-end
relation extraction, and coreference resolution.
</p>

<h3>Title: ProVe: A Pipeline for Automated Provenance Verification of Knowledge Graphs against Textual Sources. (arXiv:2210.14846v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14846">http://arxiv.org/abs/2210.14846</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14846] ProVe: A Pipeline for Automated Provenance Verification of Knowledge Graphs against Textual Sources](http://arxiv.org/abs/2210.14846)</code></li>
<li>Summary: <p>Knowledge Graphs are repositories of information that gather data from a
multitude of domains and sources in the form of semantic triples, serving as a
source of structured data for various crucial applications in the modern web
landscape, from Wikipedia infoboxes to search engines. Such graphs mainly serve
as secondary sources of information and depend on well-documented and
verifiable provenance to ensure their trustworthiness and usability. However,
their ability to systematically assess and assure the quality of this
provenance, most crucially whether it properly supports the graph's
information, relies mainly on manual processes that do not scale with size.
ProVe aims at remedying this, consisting of a pipelined approach that
automatically verifies whether a Knowledge Graph triple is supported by text
extracted from its documented provenance. ProVe is intended to assist
information curators and consists of four main steps involving rule-based
methods and machine learning models: text extraction, triple verbalisation,
sentence selection, and claim verification. ProVe is evaluated on a Wikidata
dataset, achieving promising results overall and excellent performance on the
binary classification task of detecting support from provenance, with 87.5%
accuracy and 82.9% F1-macro on text-rich sources. The evaluation data and
scripts used in this paper are available on GitHub and Figshare.
</p></li>
</ul>

<h3>Title: Causality Detection using Multiple Annotation Decision. (arXiv:2210.14852v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14852">http://arxiv.org/abs/2210.14852</a></li>
<li>Code URL: <a href="https://github.com/jyanqa/case-2022-causual-event">https://github.com/jyanqa/case-2022-causual-event</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14852] Causality Detection using Multiple Annotation Decision](http://arxiv.org/abs/2210.14852)</code></li>
<li>Summary: <p>The paper describes the work that has been submitted to the 5th workshop on
Challenges and Applications of Automated Extraction of socio-political events
from text (CASE 2022). The work is associated with Subtask 1 of Shared Task 3
that aims to detect causality in protest news corpus. The authors used
different large language models with customized cross-entropy loss functions
that exploit annotation information. The experiments showed that
bert-based-uncased with refined cross-entropy outperformed the others,
achieving a F1 score of 0.8501 on the Causal News Corpus dataset.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: FedClassAvg: Local Representation Learning for Personalized Federated Learning on Heterogeneous Neural Networks. (arXiv:2210.14226v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14226">http://arxiv.org/abs/2210.14226</a></li>
<li>Code URL: <a href="https://github.com/hukla/fedclassavg">https://github.com/hukla/fedclassavg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14226] FedClassAvg: Local Representation Learning for Personalized Federated Learning on Heterogeneous Neural Networks](http://arxiv.org/abs/2210.14226)</code></li>
<li>Summary: <p>Personalized federated learning is aimed at allowing numerous clients to
train personalized models while participating in collaborative training in a
communication-efficient manner without exchanging private data. However, many
personalized federated learning algorithms assume that clients have the same
neural network architecture, and those for heterogeneous models remain
understudied. In this study, we propose a novel personalized federated learning
method called federated classifier averaging (FedClassAvg). Deep neural
networks for supervised learning tasks consist of feature extractor and
classifier layers. FedClassAvg aggregates classifier weights as an agreement on
decision boundaries on feature spaces so that clients with not independently
and identically distributed (non-iid) data can learn about scarce labels. In
addition, local feature representation learning is applied to stabilize the
decision boundaries and improve the local feature extraction capabilities for
clients. While the existing methods require the collection of auxiliary data or
model weights to generate a counterpart, FedClassAvg only requires clients to
communicate with a couple of fully connected layers, which is highly
communication-efficient. Moreover, FedClassAvg does not require extra
optimization problems such as knowledge transfer, which requires intensive
computation overhead. We evaluated FedClassAvg through extensive experiments
and demonstrated it outperforms the current state-of-the-art algorithms on
heterogeneous personalized federated learning tasks.
</p></li>
</ul>

<h3>Title: Federated Learning Using Variance Reduced Stochastic Gradient for Probabilistically Activated Agents. (arXiv:2210.14362v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14362">http://arxiv.org/abs/2210.14362</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14362] Federated Learning Using Variance Reduced Stochastic Gradient for Probabilistically Activated Agents](http://arxiv.org/abs/2210.14362)</code></li>
<li>Summary: <p>This paper proposes an algorithm for Federated Learning (FL) with a two-layer
structure that achieves both variance reduction and a faster convergence rate
to an optimal solution in the setting where each agent has an arbitrary
probability of selection in each iteration. In distributed machine learning,
when privacy matters, FL is a functional tool. Placing FL in an environment
where it has some irregular connections of agents (devices), reaching a trained
model in both an economical and quick way can be a demanding job. The first
layer of our algorithm corresponds to the model parameter propagation across
agents done by the server. In the second layer, each agent does its local
update with a stochastic and variance-reduced technique called Stochastic
Variance Reduced Gradient (SVRG). We leverage the concept of variance reduction
from stochastic optimization when the agents want to do their local update step
to reduce the variance caused by stochastic gradient descent (SGD). We provide
a convergence bound for our algorithm which improves the rate from
$O(\frac{1}{\sqrt{K}})$ to $O(\frac{1}{K})$ by using a constant step-size. We
demonstrate the performance of our algorithm using numerical examples.
</p></li>
</ul>

<h3>Title: Federated Fuzzy Neural Network with Evolutionary Rule Learning. (arXiv:2210.14393v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14393">http://arxiv.org/abs/2210.14393</a></li>
<li>Code URL: <a href="https://github.com/leijiezhang/fedfnn">https://github.com/leijiezhang/fedfnn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14393] Federated Fuzzy Neural Network with Evolutionary Rule Learning](http://arxiv.org/abs/2210.14393)</code></li>
<li>Summary: <p>Distributed fuzzy neural networks (DFNNs) have attracted increasing attention
recently due to their learning abilities in handling data uncertainties in
distributed scenarios. However, it is challenging for DFNNs to handle cases in
which the local data are non-independent and identically distributed (non-IID).
In this paper, we propose a federated fuzzy neural network (FedFNN) with
evolutionary rule learning (ERL) to cope with non-IID issues as well as data
uncertainties. The FedFNN maintains a global set of rules in a server and a
personalized subset of these rules for each local client. ERL is inspired by
the theory of biological evolution; it encourages rule variations while
activating superior rules and deactivating inferior rules for local clients
with non-IID data. Specifically, ERL consists of two stages in an iterative
procedure: a rule cooperation stage that updates global rules by aggregating
local rules based on their activation statuses and a rule evolution stage that
evolves the global rules and updates the activation statuses of the local
rules. This procedure improves both the generalization and personalization of
the FedFNN for dealing with non-IID issues and data uncertainties. Extensive
experiments conducted on a range of datasets demonstrate the superiority of the
FedFNN over state-of-the-art methods.
</p></li>
</ul>

<h3>Title: FedX: Federated Learning for Compositional Pairwise Risk Optimization. (arXiv:2210.14396v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14396">http://arxiv.org/abs/2210.14396</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14396] FedX: Federated Learning for Compositional Pairwise Risk Optimization](http://arxiv.org/abs/2210.14396)</code></li>
<li>Summary: <p>In this paper, we tackle a novel federated learning (FL) problem for
optimizing a family of compositional pairwise risks, to which no existing FL
algorithms are applicable. In particular, the objective has the form of
$\mathbb E_{\mathbf z\sim \mathcal S_1} f(\mathbb E_{\mathbf z'\sim\mathcal
S_2} \ell(\mathbf w, \mathbf z, \mathbf z'))$, where two sets of data $\mathcal
S_1, \mathcal S_2$ are distributed over multiple machines, $\ell(\cdot;
\cdot,\cdot)$ is a pairwise loss that only depends on the prediction outputs of
the input data pairs $(\mathbf z, \mathbf z')$, and $f(\cdot)$ is possibly a
non-linear non-convex function. This problem has important applications in
machine learning, e.g., AUROC maximization with a pairwise loss, and partial
AUROC maximization with a compositional loss. The challenges for designing an
FL algorithm lie in the non-decomposability of the objective over multiple
machines and the interdependency between different machines. We propose two
provable FL algorithms (FedX) for handling linear and nonlinear $f$,
respectively. To address the challenges, we decouple the gradient's components
with two types, namely active parts and lazy parts, where the active parts
depend on local data that are computed with the local model and the lazy parts
depend on other machines that are communicated/computed based on historical
models and samples. We develop a novel theoretical analysis to combat the
latency of the lazy parts and the interdependency between the local model
parameters and the involved data for computing local gradient estimators. We
establish both iteration and communication complexities and show that using the
historical samples and models for computing the lazy parts do not degrade the
complexities. We conduct empirical studies of FedX for deep AUROC and partial
AUROC maximization, and demonstrate their performance compared with several
baselines.
</p></li>
</ul>

<h3>Title: Hierarchical Federated Learning with Momentum Acceleration in Multi-Tier Networks. (arXiv:2210.14560v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14560">http://arxiv.org/abs/2210.14560</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14560] Hierarchical Federated Learning with Momentum Acceleration in Multi-Tier Networks](http://arxiv.org/abs/2210.14560)</code></li>
<li>Summary: <p>In this paper, we propose Hierarchical Federated Learning with Momentum
Acceleration (HierMo), a three-tier worker-edge-cloud federated learning
algorithm that applies momentum for training acceleration. Momentum is
calculated and aggregated in the three tiers. We provide convergence analysis
for HierMo, showing a convergence rate of O(1/T). In the analysis, we develop a
new approach to characterize model aggregation, momentum aggregation, and their
interactions. Based on this result, {we prove that HierMo achieves a tighter
convergence upper bound compared with HierFAVG without momentum}. We also
propose HierOPT, which optimizes the aggregation periods (worker-edge and
edge-cloud aggregation periods) to minimize the loss given a limited training
time.
</p></li>
</ul>

<h3>Title: Coresets for Vertical Federated Learning: Regularized Linear Regression and $K$-Means Clustering. (arXiv:2210.14664v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14664">http://arxiv.org/abs/2210.14664</a></li>
<li>Code URL: <a href="https://github.com/haoyuzhao123/coreset-vfl-codes">https://github.com/haoyuzhao123/coreset-vfl-codes</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14664] Coresets for Vertical Federated Learning: Regularized Linear Regression and $K$-Means Clustering](http://arxiv.org/abs/2210.14664)</code></li>
<li>Summary: <p>Vertical federated learning (VFL), where data features are stored in multiple
parties distributively, is an important area in machine learning. However, the
communication complexity for VFL is typically very high. In this paper, we
propose a unified framework by constructing coresets in a distributed fashion
for communication-efficient VFL. We study two important learning tasks in the
VFL setting: regularized linear regression and $k$-means clustering, and apply
our coreset framework to both problems. We theoretically show that using
coresets can drastically alleviate the communication complexity, while nearly
maintain the solution quality. Numerical experiments are conducted to
corroborate our theoretical findings.
</p></li>
</ul>

<h3>Title: Personalized Federated Learning via Heterogeneous Modular Networks. (arXiv:2210.14830v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14830">http://arxiv.org/abs/2210.14830</a></li>
<li>Code URL: <a href="https://github.com/xztcwang/fedmn">https://github.com/xztcwang/fedmn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14830] Personalized Federated Learning via Heterogeneous Modular Networks](http://arxiv.org/abs/2210.14830)</code></li>
<li>Summary: <p>Personalized Federated Learning (PFL) which collaboratively trains a
federated model while considering local clients under privacy constraints has
attracted much attention. Despite its popularity, it has been observed that
existing PFL approaches result in sub-optimal solutions when the joint
distribution among local clients diverges. To address this issue, we present
Federated Modular Network (FedMN), a novel PFL approach that adaptively selects
sub-modules from a module pool to assemble heterogeneous neural architectures
for different clients. FedMN adopts a light-weighted routing hypernetwork to
model the joint distribution on each client and produce the personalized
selection of the module blocks for each client. To reduce the communication
burden in existing FL, we develop an efficient way to interact between the
clients and the server. We conduct extensive experiments on the real-world test
beds and the results show both the effectiveness and efficiency of the proposed
FedMN over the baselines.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: FairCLIP: Social Bias Elimination based on Attribute Prototype Learning and Representation Neutralization. (arXiv:2210.14562v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14562">http://arxiv.org/abs/2210.14562</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14562] FairCLIP: Social Bias Elimination based on Attribute Prototype Learning and Representation Neutralization](http://arxiv.org/abs/2210.14562)</code></li>
<li>Summary: <p>The Vision-Language Pre-training (VLP) models like CLIP have gained
popularity in recent years. However, many works found that the social biases
hidden in CLIP easily manifest in downstream tasks, especially in image
retrieval, which can have harmful effects on human society. In this work, we
propose FairCLIP to eliminate the social bias in CLIP-based image retrieval
without damaging the retrieval performance achieving the compatibility between
the debiasing effect and the retrieval performance. FairCLIP is divided into
two steps: Attribute Prototype Learning (APL) and Representation Neutralization
(RN). In the first step, we extract the concepts needed for debiasing in CLIP.
We use the query with learnable word vector prefixes as the extraction
structure. In the second step, we first divide the attributes into target and
bias attributes. By analysis, we find that both attributes have an impact on
the bias. Therefore, we try to eliminate the bias by using Re-Representation
Matrix (RRM) to achieve the neutralization of the representation. We compare
the debiasing effect and retrieval performance with other methods, and
experiments demonstrate that FairCLIP can achieve the best compatibility.
Although FairCLIP is used to eliminate bias in image retrieval, it achieves the
neutralization of the representation which is common to all CLIP downstream
tasks. This means that FairCLIP can be applied as a general debiasing method
for other fairness issues related to CLIP.
</p></li>
</ul>

<h3>Title: Geographic Citation Gaps in NLP Research. (arXiv:2210.14424v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14424">http://arxiv.org/abs/2210.14424</a></li>
<li>Code URL: <a href="https://github.com/iamjanvijay/acl-cite-net">https://github.com/iamjanvijay/acl-cite-net</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14424] Geographic Citation Gaps in NLP Research](http://arxiv.org/abs/2210.14424)</code></li>
<li>Summary: <p>In a fair world, people have equitable opportunities to education, to conduct
scientific research, to publish, and to get credit for their work, regardless
of where they live. However, it is common knowledge among researchers that a
vast number of papers accepted at top NLP venues come from a handful of western
countries and (lately) China; whereas, very few papers from Africa and South
America get published. Similar disparities are also believed to exist for paper
citation counts. In the spirit of "what we do not measure, we cannot improve",
this work asks a series of questions on the relationship between geographical
location and publication success (acceptance in top NLP venues and citation
impact). We first created a dataset of 70,000 papers from the ACL Anthology,
extracted their meta-information, and generated their citation network. We then
show that not only are there substantial geographical disparities in paper
acceptance and citation but also that these disparities persist even when
controlling for a number of variables such as venue of publication and
sub-field of NLP. Further, despite some steps taken by the NLP community to
improve geographical diversity, we show that the disparity in publication
metrics across locations is still on an increasing trend since the early 2000s.
We release our code and dataset here:
https://github.com/iamjanvijay/acl-cite-net
</p></li>
</ul>

<h3>Title: Classification and Self-Supervised Regression of Arrhythmic ECG Signals Using Convolutional Neural Networks. (arXiv:2210.14253v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14253">http://arxiv.org/abs/2210.14253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14253] Classification and Self-Supervised Regression of Arrhythmic ECG Signals Using Convolutional Neural Networks](http://arxiv.org/abs/2210.14253)</code></li>
<li>Summary: <p>Interpretation of electrocardiography (ECG) signals is required for
diagnosing cardiac arrhythmia. Recently, machine learning techniques have been
applied for automated computer-aided diagnosis. Machine learning tasks can be
divided into regression and classification. Regression can be used for noise
and artifacts removal as well as resolve issues of missing data from low
sampling frequency. Classification task concerns the prediction of output
diagnostic classes according to expert-labeled input classes. In this work, we
propose a deep neural network model capable of solving regression and
classification tasks. Moreover, we combined the two approaches, using unlabeled
and labeled data, to train the model. We tested the model on the MIT-BIH
Arrhythmia database. Our method showed high effectiveness in detecting cardiac
arrhythmia based on modified Lead II ECG records, as well as achieved high
quality of ECG signal approximation. For the former, our method attained
overall accuracy of 87:33% and balanced accuracy of 80:54%, on par with
reference approaches. For the latter, application of self-supervised learning
allowed for training without the need for expert labels. The regression model
yielded satisfactory performance with fairly accurate prediction of QRS
complexes. Transferring knowledge from regression to the classification task,
our method attained higher overall accuracy of 87:78%.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Exploring Document-Level Literary Machine Translation with Parallel Paragraphs from World Literature. (arXiv:2210.14250v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.14250">http://arxiv.org/abs/2210.14250</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.14250] Exploring Document-Level Literary Machine Translation with Parallel Paragraphs from World Literature](http://arxiv.org/abs/2210.14250)</code></li>
<li>Summary: <p>Literary translation is a culturally significant task, but it is bottlenecked
by the small number of qualified literary translators relative to the many
untranslated works published around the world. Machine translation (MT) holds
potential to complement the work of human translators by improving both
training procedures and their overall efficiency. Literary translation is less
constrained than more traditional MT settings since translators must balance
meaning equivalence, readability, and critical interpretability in the target
language. This property, along with the complex discourse-level context present
in literary texts, also makes literary MT more challenging to computationally
model and evaluate. To explore this task, we collect a dataset (Par3) of
non-English language novels in the public domain, each aligned at the paragraph
level to both human and automatic English translations. Using Par3, we discover
that expert literary translators prefer reference human translations over
machine-translated paragraphs at a rate of 84%, while state-of-the-art
automatic MT metrics do not correlate with those preferences. The experts note
that MT outputs contain not only mistranslations, but also discourse-disrupting
errors and stylistic inconsistencies. To address these problems, we train a
post-editing model whose output is preferred over normal MT output at a rate of
69% by experts. We publicly release Par3 at
https://github.com/katherinethai/par3/ to spur future research into literary
MT.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
