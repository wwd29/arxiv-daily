<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-06-11</h1>
<h3>Title: KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache</h3>
<ul>
<li><strong>Authors: </strong>Fei Li, Song Liu, Weiguo Wu, Shiqiang Nie, Jinyu Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08018">https://arxiv.org/abs/2506.08018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08018">https://arxiv.org/pdf/2506.08018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08018]] KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache(https://arxiv.org/abs/2506.08018)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The high memory demands of the Key-Value (KV) Cache during the inference of Large Language Models (LLMs) severely restrict their deployment in resource-constrained platforms. Quantization can effectively alleviate the memory pressure caused by KV Cache. However, existing methods either rely on static one-size-fits-all precision allocation or fail to dynamically prioritize critical KV in long-context tasks, forcing memory-accuracy-throughput tradeoffs. In this work, we propose a novel mixed-precision quantization method for KV Cache named KVmix. KVmix leverages gradient-based importance analysis to evaluate how individual Key and Value projection matrices affect the model loss, enabling layer-specific bit-width allocation for mix-precision quantization. It dynamically prioritizes higher precision for important layers while aggressively quantizing less influential ones, achieving a tunable balance between accuracy and efficiency. KVmix also introduces a dynamic long-context optimization strategy that adaptively keeps full-precision KV pairs for recent pivotal tokens and compresses older ones, achieving high-quality sequence generation with low memory usage. Additionally, KVmix provides efficient low-bit quantization and CUDA kernels to optimize computational overhead. On LLMs such as Llama and Mistral, KVmix achieves near-lossless inference performance with extremely low quantization configuration (Key 2.19bit Value 2.38bit), while delivering a remarkable 4.9x memory compression and a 5.3x speedup in inference throughput.</li>
</ul>

<h3>Title: FlowBERT: Prompt-tuned BERT for variable flow field prediction</h3>
<ul>
<li><strong>Authors: </strong>Weihao Zou, Weibing Feng, Pin Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08021">https://arxiv.org/abs/2506.08021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08021">https://arxiv.org/pdf/2506.08021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08021]] FlowBERT: Prompt-tuned BERT for variable flow field prediction(https://arxiv.org/abs/2506.08021)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This study proposes a universal flow field prediction framework based on knowledge transfer from large language model (LLM), addressing the high computational costs of traditional computational fluid dynamics (CFD) methods and the limited cross-condition transfer capability of existing deep learning models. The framework innovatively integrates Proper Orthogonal Decomposition (POD) dimensionality reduction with fine-tuning strategies for pretrained LLM, where POD facilitates compressed representation of flow field features while the fine-tuned model learns to encode system dynamics in state space. To enhance the model's adaptability to flow field data, we specifically designed fluid dynamics-oriented text templates that improve predictive performance through enriched contextual semantic information. Experimental results demonstrate that our framework outperforms conventional Transformer models in few-shot learning scenarios while exhibiting exceptional generalization across various inflow conditions and airfoil geometries. Ablation studies reveal the contributions of key components in the FlowBERT architecture. Compared to traditional Navier-Stokes equation solvers requiring hours of computation, our approach reduces prediction time to seconds while maintaining over 90% accuracy. The developed knowledge transfer paradigm establishes a new direction for rapid fluid dynamics prediction, with potential applications extending to aerodynamic optimization, flow control, and other engineering domains.</li>
</ul>

<h3>Title: Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining</h3>
<ul>
<li><strong>Authors: </strong>Chenxi Liu, Tianyi Xiong, Ruibo Chen, Yihan Wu, Junfeng Guo, Tianyi Zhou, Heng Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08022">https://arxiv.org/abs/2506.08022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08022">https://arxiv.org/pdf/2506.08022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08022]] Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining(https://arxiv.org/abs/2506.08022)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The task adaptation and alignment of Large Multimodal Models (LMMs) have been significantly advanced by instruction tuning and further strengthened by recent preference optimization. Yet, most LMMs still suffer from severe modality imbalance during reasoning, i.e., outweighing language prior biases over visual inputs, which bottlenecks their generalization to downstream tasks and causes hallucinations. However, existing preference optimization approaches for LMMs do not focus on restraining the internal biases of their Large Language Model (LLM) backbones when curating the training data. Moreover, they heavily rely on offline data and lack the capacity to explore diverse responses adaptive to dynamic distributional shifts during training. Meanwhile, Group Relative Policy Optimization (GRPO), a recent method using online-generated data and verified rewards to improve reasoning capabilities, remains largely underexplored in LMM alignment. In this paper, we propose a novel preference learning framework, Modality-Balancing Preference Optimization (MBPO), to address the modality imbalance in LMMs. MBPO constructs a more effective offline preference dataset by generating hard negatives, i.e., rejected responses misled by LLM biases due to limited usage of visual information, through adversarial perturbation of input images. Moreover, MBPO leverages the easy-to-verify nature of close-ended tasks to generate online responses with verified rewards. GRPO is then employed to train the model with offline-online hybrid data. Extensive experiments demonstrate that MBPO can enhance LMM performance on challenging vision-language tasks and effectively reduce hallucinations.</li>
</ul>

<h3>Title: ReCogDrive: A Reinforced Cognitive Framework for End-to-End Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Yongkang Li, Kaixin Xiong, Xiangyu Guo, Fang Li, Sixu Yan, Gangwei Xu, Lijun Zhou, Long Chen, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Wenyu Liu, Xinggang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08052">https://arxiv.org/abs/2506.08052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08052">https://arxiv.org/pdf/2506.08052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08052]] ReCogDrive: A Reinforced Cognitive Framework for End-to-End Autonomous Driving(https://arxiv.org/abs/2506.08052)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Although end-to-end autonomous driving has made remarkable progress, its performance degrades significantly in rare and long-tail scenarios. Recent approaches attempt to address this challenge by leveraging the rich world knowledge of Vision-Language Models (VLMs), but these methods suffer from several limitations: (1) a significant domain gap between the pre-training data of VLMs and real-world driving data, (2) a dimensionality mismatch between the discrete language space and the continuous action space, and (3) imitation learning tends to capture the average behavior present in the dataset, which may be suboptimal even dangerous. In this paper, we propose ReCogDrive, an autonomous driving system that integrates VLMs with diffusion planner, which adopts a three-stage paradigm for training. In the first stage, we use a large-scale driving question-answering datasets to train the VLMs, mitigating the domain discrepancy between generic content and real-world driving scenarios. In the second stage, we employ a diffusion-based planner to perform imitation learning, mapping representations from the latent language space to continuous driving actions. Finally, we fine-tune the diffusion planner using reinforcement learning with NAVSIM non-reactive simulator, enabling the model to generate safer, more human-like driving trajectories. We evaluate our approach on the planning-oriented NAVSIM benchmark, achieving a PDMS of 89.6 and setting a new state-of-the-art that surpasses the previous vision-only SOTA by 5.6 PDMS.</li>
</ul>

<h3>Title: Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques</h3>
<ul>
<li><strong>Authors: </strong>Asankhaya Sharma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08060">https://arxiv.org/abs/2506.08060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08060">https://arxiv.org/pdf/2506.08060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08060]] Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques(https://arxiv.org/abs/2506.08060)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have transformed natural language processing, yet supervised fine-tuning (SFT) remains computationally intensive. This paper formally proves that capabilities acquired through SFT can be approximated by a base transformer model using inference-time techniques, specifically in-context learning (ICL), without altering model parameters, under idealized assumptions including unbounded computational resources and access to the fine-tuning dataset. We extend these results to practical scenarios with finite context lengths and partial dataset access. For text generation tasks with fixed output length $l$, datasets of size $\mathrm{O}\left( \frac{m V}{\varepsilon^2} \log \frac{m}{\delta} \right)$ or, with bounded context, $\mathrm{O}\left( \frac{l \log V}{\varepsilon^2} \log \frac{1}{\delta} \right)$ suffice to approximate fine-tuned behavior across $m$ contexts within error $\varepsilon$, where $V$ is the vocabulary size and $\delta$ is the failure probability. For linear classification, datasets of size $\mathrm{O}\left( \frac{d}{\varepsilon} \right)$ or, with fixed context, $\mathrm{O}\left( \frac{1}{\varepsilon^2} \log \frac{1}{\delta} \right)$ are sufficient, where $d$ is the input dimension. Grounded in the Turing completeness of transformers, these results provide a theoretical foundation for resource-efficient deployment of large language models, with practical techniques like retrieval-augmented generation bridging theory to real-world applications.</li>
</ul>

<h3>Title: FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Woosung Kim, Jinho Lee, Jongmin Lee, Byung-Jun Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08062">https://arxiv.org/abs/2506.08062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08062">https://arxiv.org/pdf/2506.08062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08062]] FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning(https://arxiv.org/abs/2506.08062)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Multi-objective reinforcement learning (MORL) aims to optimize policies in the presence of conflicting objectives, where linear scalarization is commonly used to reduce vector-valued returns into scalar signals. While effective for certain preferences, this approach cannot capture fairness-oriented goals such as Nash social welfare or max-min fairness, which require nonlinear and non-additive trade-offs. Although several online algorithms have been proposed for specific fairness objectives, a unified approach for optimizing nonlinear welfare criteria in the offline setting-where learning must proceed from a fixed dataset-remains unexplored. In this work, we present FairDICE, the first offline MORL framework that directly optimizes nonlinear welfare objective. FairDICE leverages distribution correction estimation to jointly account for welfare maximization and distributional regularization, enabling stable and sample-efficient learning without requiring explicit preference weights or exhaustive weight search. Across multiple offline benchmarks, FairDICE demonstrates strong fairness-aware performance compared to existing baselines.</li>
</ul>

<h3>Title: CuRe: Cultural Gaps in the Long Tail of Text-to-Image Systems</h3>
<ul>
<li><strong>Authors: </strong>Aniket Rege, Zinnia Nie, Mahesh Ramesh, Unmesh Raskar, Zhuoran Yu, Aditya Kusupati, Yong Jae Lee, Ramya Korlakai Vinayak</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08071">https://arxiv.org/abs/2506.08071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08071">https://arxiv.org/pdf/2506.08071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08071]] CuRe: Cultural Gaps in the Long Tail of Text-to-Image Systems(https://arxiv.org/abs/2506.08071)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Popular text-to-image (T2I) systems are trained on web-scraped data, which is heavily Amero and Euro-centric, underrepresenting the cultures of the Global South. To analyze these biases, we introduce CuRe, a novel and scalable benchmarking and scoring suite for cultural representativeness that leverages the marginal utility of attribute specification to T2I systems as a proxy for human judgments. Our CuRe benchmark dataset has a novel categorical hierarchy built from the crowdsourced Wikimedia knowledge graph, with 300 cultural artifacts across 32 cultural subcategories grouped into six broad cultural axes (food, art, fashion, architecture, celebrations, and people). Our dataset's categorical hierarchy enables CuRe scorers to evaluate T2I systems by analyzing their response to increasing the informativeness of text conditioning, enabling fine-grained cultural comparisons. We empirically observe much stronger correlations of our class of scorers to human judgments of perceptual similarity, image-text alignment, and cultural diversity across image encoders (SigLIP 2, AIMV2 and DINOv2), vision-language models (OpenCLIP, SigLIP 2, Gemini 2.0 Flash) and state-of-the-art text-to-image systems, including three variants of Stable Diffusion (1.5, XL, 3.5 Large), FLUX.1 [dev], Ideogram 2.0, and DALL-E 3. The code and dataset is open-sourced and available at this https URL.</li>
</ul>

<h3>Title: Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Timothée Hornek Amir Sartipi, Igor Tchappi, Gilbert Fridgen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08113">https://arxiv.org/abs/2506.08113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08113">https://arxiv.org/pdf/2506.08113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08113]] Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting(https://arxiv.org/abs/2506.08113)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Accurate electricity price forecasting (EPF) is crucial for effective decision-making in power trading on the spot market. While recent advances in generative artificial intelligence (GenAI) and pre-trained large language models (LLMs) have inspired the development of numerous time series foundation models (TSFMs) for time series forecasting, their effectiveness in EPF remains uncertain. To address this gap, we benchmark several state-of-the-art pretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and TimeGPT--against established statistical and machine learning (ML) methods for EPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany, France, the Netherlands, Austria, and Belgium, we generate daily forecasts with a one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the TSFMs, performing on par with traditional models. However, the biseasonal MSTL model, which captures daily and weekly seasonality, stands out for its consistent performance across countries and evaluation metrics, with no TSFM statistically outperforming it.</li>
</ul>

<h3>Title: Conservative Bias in Large Language Models: Measuring Relation Predictions</h3>
<ul>
<li><strong>Authors: </strong>Toyin Aguda, Erik Wilson, Allan Anzagira, Simerjot Kaur, Charese Smiley</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08120">https://arxiv.org/abs/2506.08120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08120">https://arxiv.org/pdf/2506.08120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08120]] Conservative Bias in Large Language Models: Measuring Relation Predictions(https://arxiv.org/abs/2506.08120)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit pronounced conservative bias in relation extraction tasks, frequently defaulting to No_Relation label when an appropriate option is unavailable. While this behavior helps prevent incorrect relation assignments, our analysis reveals that it also leads to significant information loss when reasoning is not explicitly included in the output. We systematically evaluate this trade-off across multiple prompts, datasets, and relation types, introducing the concept of Hobson's choice to capture scenarios where models opt for safe but uninformative labels over hallucinated ones. Our findings suggest that conservative bias occurs twice as often as hallucination. To quantify this effect, we use SBERT and LLM prompts to capture the semantic similarity between conservative bias behaviors in constrained prompts and labels generated from semi-constrained and open-ended prompts.</li>
</ul>

<h3>Title: QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA</h3>
<ul>
<li><strong>Authors: </strong>Jacob Dineen (1), Aswin RRV (1), Qin Liu (2), Zhikun Xu (1), Xiao Ye (1), Ming Shen (1), Zhaonan Li (1), Shijie Lu (1), Chitta Baral (1), Muhao Chen (2), Ben Zhou (1) ((1) Arizona State University, (2) University of California Davis)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08123">https://arxiv.org/abs/2506.08123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08123">https://arxiv.org/pdf/2506.08123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08123]] QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA(https://arxiv.org/abs/2506.08123)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Alignment of large language models with explicit principles (such as helpfulness, honesty, and harmlessness) is crucial for ensuring safe and reliable AI systems. However, standard reward-based alignment methods typically collapse diverse feedback into a single scalar reward, entangling multiple objectives into one opaque training signal, which hinders interpretability. In this work, we introduce QA-LIGN, an automatic symbolic reward decomposition approach that preserves the structure of each constitutional principle within the reward mechanism. Instead of training a black-box reward model that outputs a monolithic score, QA-LIGN formulates principle-specific evaluation questions and derives separate reward components for each principle, making it a drop-in reward model replacement. Experiments aligning an uncensored large language model with a set of constitutional principles demonstrate that QA-LIGN offers greater transparency and adaptability in the alignment process. At the same time, our approach achieves performance on par with or better than a DPO baseline. Overall, these results represent a step toward more interpretable and controllable alignment of language models, achieved without sacrificing end-task performance.</li>
</ul>

<h3>Title: Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Hanbing Liu, Lang Cao, Yuanyi Ren, Mengyu Zhou, Haoyu Dong, Xiaojun Ma, Shi Han, Dongmei Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08125">https://arxiv.org/abs/2506.08125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08125">https://arxiv.org/pdf/2506.08125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08125]] Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning(https://arxiv.org/abs/2506.08125)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have demonstrated impressive reasoning capabilities, yet they often suffer from inefficiencies due to unnecessarily verbose or redundant outputs. While many works have explored reinforcement learning (RL) to enhance reasoning abilities, most primarily focus on improving accuracy, with limited attention to reasoning efficiency. Some existing approaches introduce direct length-based rewards to encourage brevity, but this often leads to noticeable drops in accuracy. In this paper, we propose Bingo, an RL framework that advances length-based reward design to boost efficient reasoning. Bingo incorporates two key mechanisms: a significance-aware length reward, which gradually guides the model to reduce only insignificant tokens, and a dynamic length reward, which initially encourages elaborate reasoning for hard questions but decays over time to improve overall efficiency. Experiments across multiple reasoning benchmarks show that Bingo improves both accuracy and efficiency. It outperforms the vanilla reward and several other length-based reward baselines in RL, achieving a favorable trade-off between accuracy and efficiency. These results underscore the potential of training LLMs explicitly for efficient reasoning.</li>
</ul>

<h3>Title: EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments</h3>
<ul>
<li><strong>Authors: </strong>Zefang Liu, Yinzhu Quan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08136">https://arxiv.org/abs/2506.08136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08136">https://arxiv.org/pdf/2506.08136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08136]] EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments(https://arxiv.org/abs/2506.08136)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce EconWebArena, a benchmark for evaluating autonomous agents on complex, multimodal economic tasks in realistic web environments. The benchmark comprises 360 curated tasks from 82 authoritative websites spanning domains such as macroeconomics, labor, finance, trade, and public policy. Each task challenges agents to navigate live websites, interpret structured and visual content, interact with real interfaces, and extract precise, time-sensitive data through multi-step workflows. We construct the benchmark by prompting multiple large language models (LLMs) to generate candidate tasks, followed by rigorous human curation to ensure clarity, feasibility, and source reliability. Unlike prior work, EconWebArena emphasizes fidelity to authoritative data sources and the need for grounded web-based economic reasoning. We evaluate a diverse set of state-of-the-art multimodal LLMs as web agents, analyze failure cases, and conduct ablation studies to assess the impact of visual grounding, plan-based reasoning, and interaction design. Our results reveal substantial performance gaps and highlight persistent challenges in grounding, navigation, and multimodal understanding, positioning EconWebArena as a rigorous testbed for economic web intelligence.</li>
</ul>

<h3>Title: IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Oishee Bintey Hoque, Abhijin Adiga, Aniruddha Adiga, Siddharth Chaudhary, Madhav V. Marathe, S. S. Ravi, Kirti Rajagopalan, Amanda Wilson, Samarth Swarup</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08137">https://arxiv.org/abs/2506.08137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08137">https://arxiv.org/pdf/2506.08137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08137]] IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation(https://arxiv.org/abs/2506.08137)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate canal network mapping is essential for water management, including irrigation planning and infrastructure maintenance. State-of-the-art semantic segmentation models for infrastructure mapping, such as roads, rely on large, well-annotated remote sensing datasets. However, incomplete or inadequate ground truth can hinder these learning approaches. Many infrastructure networks have graph-level properties such as reachability to a source (like canals) or connectivity (roads) that can be leveraged to improve these existing ground truth. This paper develops a novel iterative framework IGraSS, combining a semantic segmentation module-incorporating RGB and additional modalities (NDWI, DEM)-with a graph-based ground-truth refinement module. The segmentation module processes satellite imagery patches, while the refinement module operates on the entire data viewing the infrastructure network as a graph. Experiments show that IGraSS reduces unreachable canal segments from around 18% to 3%, and training with refined ground truth significantly improves canal identification. IGraSS serves as a robust framework for both refining noisy ground truth and mapping canal networks from remote sensing imagery. We also demonstrate the effectiveness and generalizability of IGraSS using road networks as an example, applying a different graph-theoretic constraint to complete road networks.</li>
</ul>

<h3>Title: Nearness of Neighbors Attention for Regression in Supervised Finetuning</h3>
<ul>
<li><strong>Authors: </strong>Aviad Susman, Mayte Suárez-Fariñas, Joseph T Colonel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08139">https://arxiv.org/abs/2506.08139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08139">https://arxiv.org/pdf/2506.08139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08139]] Nearness of Neighbors Attention for Regression in Supervised Finetuning(https://arxiv.org/abs/2506.08139)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>It is common in supervised machine learning to combine the feature extraction capabilities of neural networks with the predictive power of traditional algorithms, such as k-nearest neighbors (k-NN) or support vector machines. This procedure involves performing supervised fine-tuning (SFT) on a domain-appropriate feature extractor, followed by training a traditional predictor on the resulting SFT embeddings. When used in this manner, traditional predictors often deliver increased performance over the SFT model itself, despite the fine-tuned feature extractor yielding embeddings specifically optimized for prediction by the neural network's final dense layer. This suggests that directly incorporating traditional algorithms into SFT as prediction layers may further improve performance. However, many traditional algorithms have not been implemented as neural network layers due to their non-differentiable nature and their unique optimization requirements. As a step towards solving this problem, we introduce the Nearness of Neighbors Attention (NONA) regression layer. NONA uses the mechanics of neural network attention and a novel learned attention-masking scheme to yield a differentiable proxy of the k-NN regression algorithm. Results on multiple unstructured datasets show improved performance over both dense layer prediction and k-NN on SFT embeddings for regression.</li>
</ul>

<h3>Title: Accelerating Spectral Clustering under Fairness Constraints</h3>
<ul>
<li><strong>Authors: </strong>Francesco Tonin, Alex Lambert, Johan A. K. Suykens, Volkan Cevher</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08143">https://arxiv.org/abs/2506.08143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08143">https://arxiv.org/pdf/2506.08143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08143]] Accelerating Spectral Clustering under Fairness Constraints(https://arxiv.org/abs/2506.08143)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fairness of decision-making algorithms is an increasingly important issue. In this paper, we focus on spectral clustering with group fairness constraints, where every demographic group is represented in each cluster proportionally as in the general population. We present a new efficient method for fair spectral clustering (Fair SC) by casting the Fair SC problem within the difference of convex functions (DC) framework. To this end, we introduce a novel variable augmentation strategy and employ an alternating direction method of multipliers type of algorithm adapted to DC problems. We show that each associated subproblem can be solved efficiently, resulting in higher computational efficiency compared to prior work, which required a computationally expensive eigendecomposition. Numerical experiments demonstrate the effectiveness of our approach on both synthetic and real-world benchmarks, showing significant speedups in computation time over prior art, especially as the problem size grows. This work thus represents a considerable step forward towards the adoption of fair clustering in real-world applications.</li>
</ul>

<h3>Title: Fully data-driven inverse hyperelasticity with hyper-network neural ODE fields</h3>
<ul>
<li><strong>Authors: </strong>Vahidullah Taç, Amirhossein Amiri-Hezaveh, Manuel K. Rausch, Grace N. Bechtel, Francisco Sahli Costabal, Adrian Buganza Tepole</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08146">https://arxiv.org/abs/2506.08146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08146">https://arxiv.org/pdf/2506.08146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08146]] Fully data-driven inverse hyperelasticity with hyper-network neural ODE fields(https://arxiv.org/abs/2506.08146)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose a new framework for identifying mechanical properties of heterogeneous materials without a closed-form constitutive equation. Given a full-field measurement of the displacement field, for instance as obtained from digital image correlation (DIC), a continuous approximation of the strain field is obtained by training a neural network that incorporates Fourier features to effectively capture sharp gradients in the data. A physics-based data-driven method built upon ordinary neural differential equations (NODEs) is employed to discover constitutive equations. The NODE framework can represent arbitrary materials while satisfying constraints in the theory of constitutive equations by default. To account for heterogeneity, a hyper-network is defined, where the input is the material coordinate system, and the output is the NODE-based constitutive equation. The parameters of the hyper-network are optimized by minimizing a multi-objective loss function that includes penalty terms for violations of the strong form of the equilibrium equations of elasticity and the associated Neumann boundary conditions. We showcase the framework with several numerical examples, including heterogeneity arising from variations in material parameters, spatial transitions from isotropy to anisotropy, material identification in the presence of noise, and, ultimately, application to experimental data. As the numerical results suggest, the proposed approach is robust and general in identifying the mechanical properties of heterogeneous materials with very few assumptions, making it a suitable alternative to classical inverse methods.</li>
</ul>

<h3>Title: Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Usman, Muhammad Ahmad, M. Shahiki Tash, Irina Gelbukh, Rolando Quintero Tellez, Grigori Sidorov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08147">https://arxiv.org/abs/2506.08147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08147">https://arxiv.org/pdf/2506.08147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08147]] Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models(https://arxiv.org/abs/2506.08147)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Social media platforms are critical spaces for public discourse, shaping opinions and community dynamics, yet their widespread use has amplified harmful content, particularly hate speech, threatening online safety and inclusivity. While hate speech detection has been extensively studied in languages like English and Spanish, Urdu remains underexplored, especially using translation-based approaches. To address this gap, we introduce a trilingual dataset of 10,193 tweets in English (3,834 samples), Urdu (3,197 samples), and Spanish (3,162 samples), collected via keyword filtering, with a balanced distribution of 4,849 Hateful and 5,344 Not-Hateful labels. Our methodology leverages attention layers as a precursor to transformer-based models and large language models (LLMs), enhancing feature extraction for multilingual hate speech detection. For non-transformer models, we use TF-IDF for feature extraction. The dataset is benchmarked using state-of-the-art models, including GPT-3.5 Turbo and Qwen 2.5 72B, alongside traditional machine learning models like SVM and other transformers (e.g., BERT, RoBERTa). Three annotators, following rigorous guidelines, ensured high dataset quality, achieving a Fleiss' Kappa of 0.821. Our approach, integrating attention layers with GPT-3.5 Turbo and Qwen 2.5 72B, achieves strong performance, with macro F1 scores of 0.87 for English (GPT-3.5 Turbo), 0.85 for Spanish (GPT-3.5 Turbo), 0.81 for Urdu (Qwen 2.5 72B), and 0.88 for the joint multilingual model (Qwen 2.5 72B). These results reflect improvements of 8.75% in English (over SVM baseline 0.80), 8.97% in Spanish (over SVM baseline 0.78), 5.19% in Urdu (over SVM baseline 0.77), and 7.32% in the joint multilingual model (over SVM baseline 0.82). Our framework offers a robust solution for multilingual hate speech detection, fostering safer digital communities worldwide.</li>
</ul>

<h3>Title: BLUR: A Bi-Level Optimization Approach for LLM Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Hadi Reisizadeh, Jinghan Jia, Zhiqi Bu, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Sijia Liu, Mingyi Hong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08164">https://arxiv.org/abs/2506.08164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08164">https://arxiv.org/pdf/2506.08164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08164]] BLUR: A Bi-Level Optimization Approach for LLM Unlearning(https://arxiv.org/abs/2506.08164)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Enabling large language models (LLMs) to unlearn knowledge and capabilities acquired during training has proven vital for ensuring compliance with data regulations and promoting ethical practices in generative AI. Although there are growing interests in developing various unlearning algorithms, it remains unclear how to best formulate the unlearning problem. The most popular formulation uses a weighted sum of forget and retain loss, but it often leads to performance degradation due to the inherent trade-off between forget and retain losses. In this work, we argue that it is important to model the hierarchical structure of the unlearning problem, where the forget problem (which \textit{unlearns} certain knowledge and/or capabilities) takes priority over the retain problem (which preserves model utility). This hierarchical structure naturally leads to a bi-level optimization formulation where the lower-level objective focuses on minimizing the forget loss, while the upper-level objective aims to maintain the model's utility. Based on this new formulation, we propose a novel algorithm, termed Bi-Level UnleaRning (\texttt{BLUR}), which not only possesses strong theoretical guarantees but more importantly, delivers superior performance. In particular, our extensive experiments demonstrate that \texttt{BLUR} consistently outperforms all the state-of-the-art algorithms across various unlearning tasks, models, and metrics. Codes are available at this https URL.</li>
</ul>

<h3>Title: UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data</h3>
<ul>
<li><strong>Authors: </strong>Sunny Gupta, Nikita Jangid, Amit Sethi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08167">https://arxiv.org/abs/2506.08167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08167">https://arxiv.org/pdf/2506.08167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08167]] UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data(https://arxiv.org/abs/2506.08167)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) often suffers from severe performance degradation when faced with non-IID data, largely due to local classifier bias. Traditional remedies such as global model regularization or layer freezing either incur high computational costs or struggle to adapt to feature shifts. In this work, we propose UniVarFL, a novel FL framework that emulates IID-like training dynamics directly at the client level, eliminating the need for global model dependency. UniVarFL leverages two complementary regularization strategies during local training: Classifier Variance Regularization, which aligns class-wise probability distributions with those expected under IID conditions, effectively mitigating local classifier bias; and Hyperspherical Uniformity Regularization, which encourages a uniform distribution of feature representations across the hypersphere, thereby enhancing the model's ability to generalize under diverse data distributions. Extensive experiments on multiple benchmark datasets demonstrate that UniVarFL outperforms existing methods in accuracy, highlighting its potential as a highly scalable and efficient solution for real-world FL deployments, especially in resource-constrained settings. Code: this https URL</li>
</ul>

<h3>Title: Federated Learning on Stochastic Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Jingqiao Tang (1), Ryan Bausback (1), Feng Bao (1), Richard Archibald (2) ((1) Department of Mathematics at Florida State University, Tallahassee, Florida, USA, (2) Division of Computer Science and Mathematics, Oak Ridge National Laboratory, Oak Ridge, Tennessee, USA)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08169">https://arxiv.org/abs/2506.08169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08169">https://arxiv.org/pdf/2506.08169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08169]] Federated Learning on Stochastic Neural Networks(https://arxiv.org/abs/2506.08169)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a machine learning paradigm that leverages edge computing on client devices to optimize models while maintaining user privacy by ensuring that local data remains on the device. However, since all data is collected by clients, federated learning is susceptible to latent noise in local datasets. Factors such as limited measurement capabilities or human errors may introduce inaccuracies in client data. To address this challenge, we propose the use of a stochastic neural network as the local model within the federated learning framework. Stochastic neural networks not only facilitate the estimation of the true underlying states of the data but also enable the quantification of latent noise. We refer to our federated learning approach, which incorporates stochastic neural networks as local models, as Federated stochastic neural networks. We will present numerical experiments demonstrating the performance and effectiveness of our method, particularly in handling non-independent and identically distributed data.</li>
</ul>

<h3>Title: Can Artificial Intelligence Write Like Borges? An Evaluation Protocol for Spanish Microfiction</h3>
<ul>
<li><strong>Authors: </strong>Gerardo Aleman Manzanarez, Nora de la Cruz Arana, Jorge Garcia Flores, Yobany Garcia Medina, Raul Monroy, Nathalie Pernelle</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08172">https://arxiv.org/abs/2506.08172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08172">https://arxiv.org/pdf/2506.08172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08172]] Can Artificial Intelligence Write Like Borges? An Evaluation Protocol for Spanish Microfiction(https://arxiv.org/abs/2506.08172)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automated story writing has been a subject of study for over 60 years. Large language models can generate narratively consistent and linguistically coherent short fiction texts. Despite these advancements, rigorous assessment of such outputs for literary merit - especially concerning aesthetic qualities - has received scant attention. In this paper, we address the challenge of evaluating AI-generated microfictions and argue that this task requires consideration of literary criteria across various aspects of the text, such as thematic coherence, textual clarity, interpretive depth, and aesthetic quality. To facilitate this, we present GrAImes: an evaluation protocol grounded in literary theory, specifically drawing from a literary perspective, to offer an objective framework for assessing AI-generated microfiction. Furthermore, we report the results of our validation of the evaluation protocol, as answered by both literature experts and literary enthusiasts. This protocol will serve as a foundation for evaluating automatically generated microfictions and assessing their literary value.</li>
</ul>

<h3>Title: LLM-BT: Back-Translation as a Framework for Terminology Standardization and Dynamic Semantic Embedding</h3>
<ul>
<li><strong>Authors: </strong>Li Weigang, Pedro Carvalho Brom</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08174">https://arxiv.org/abs/2506.08174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08174">https://arxiv.org/pdf/2506.08174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08174]] LLM-BT: Back-Translation as a Framework for Terminology Standardization and Dynamic Semantic Embedding(https://arxiv.org/abs/2506.08174)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid growth of English technical terms challenges traditional expert-driven standardization, especially in fast-evolving fields like AI and quantum computing. Manual methods struggle to ensure multilingual consistency. We propose \textbf{LLM-BT}, a back-translation framework powered by large language models (LLMs) to automate terminology verification and standardization via cross-lingual semantic alignment. Our contributions are: \textbf{(1) Term-Level Consistency Validation:} Using English $\rightarrow$ intermediate language $\rightarrow$ English back-translation, LLM-BT achieves high term consistency across models (e.g., GPT-4, DeepSeek, Grok), with case studies showing over 90\% exact or semantic matches. \textbf{(2) Multi-Path Verification Workflow:} A novel ``Retrieve--Generate--Verify--Optimize'' pipeline integrates serial (e.g., EN $\rightarrow$ ZHcn $\rightarrow$ ZHtw $\rightarrow$ EN) and parallel (e.g., EN $\rightarrow$ Chinese/Portuguese $\rightarrow$ EN) BT routes. BLEU and term accuracy indicate strong cross-lingual robustness (BLEU $>$ 0.45; Portuguese accuracy 100\%). \textbf{(3) Back-Translation as Semantic Embedding:} BT is conceptualized as dynamic semantic embedding, revealing latent meaning trajectories. Unlike static embeddings, LLM-BT provides transparent path-based embeddings shaped by model evolution. LLM-BT transforms back-translation into an active engine for multilingual terminology standardization, enabling human--AI collaboration: machines ensure semantic fidelity, humans guide cultural interpretation. This infrastructure supports terminology governance across scientific and technological fields worldwide.</li>
</ul>

<h3>Title: FedGA-Tree: Federated Decision Tree using Genetic Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Anh V Nguyen, Diego Klabjan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08176">https://arxiv.org/abs/2506.08176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08176">https://arxiv.org/pdf/2506.08176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08176]] FedGA-Tree: Federated Decision Tree using Genetic Algorithm(https://arxiv.org/abs/2506.08176)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>In recent years, with rising concerns for data privacy, Federated Learning has gained prominence, as it enables collaborative training without the aggregation of raw data from participating clients. However, much of the current focus has been on parametric gradient-based models, while nonparametric counterparts such as decision tree are relatively understudied. Existing methods for adapting decision trees to Federated Learning generally combine a greedy tree-building algorithm with differential privacy to produce a global model for all clients. These methods are limited to classification trees and categorical data due to the constraints of differential privacy. In this paper, we explore an alternative approach that utilizes Genetic Algorithm to facilitate the construction of personalized decision trees and accommodate categorical and numerical data, thus allowing for both classification and regression trees. Comprehensive experiments demonstrate that our method surpasses decision trees trained solely on local data and a benchmark algorithm.</li>
</ul>

<h3>Title: Unable to forget: Proactive lnterference Reveals Working Memory Limits in LLMs Beyond Context Length</h3>
<ul>
<li><strong>Authors: </strong>Chupei Wang (University of Virginia), Jiaqiu Vince Sun (New York University)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08184">https://arxiv.org/abs/2506.08184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08184">https://arxiv.org/pdf/2506.08184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08184]] Unable to forget: Proactive lnterference Reveals Working Memory Limits in LLMs Beyond Context Length(https://arxiv.org/abs/2506.08184)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Information retrieval in Large Language Models (LLMs) is increasingly recognized as intertwined with generation capabilities rather than mere lookup. While longer contexts are often assumed to improve retrieval, the effects of intra-context interference remain understudied. To address this, we adapt the proactive interference (PI) paradigm from cognitive science, where earlier information disrupts recall of newer updates. In humans, susceptibility to such interference is inversely linked to working memory capacity. We introduce PI-LLM, an evaluation that sequentially streams semantically related key-value updates and queries only the final values. Although these final values are clearly positioned just before the query, LLM retrieval accuracy declines log-linearly toward zero as interference accumulates; errors arise from retrieving previously overwritten values. Attempts to mitigate interference via prompt engineering (e.g., instructing models to ignore earlier input) yield limited success. These findings reveal a fundamental constraint on LLMs' ability to disentangle interference and flexibly manipulate information, suggesting a working memory bottleneck beyond mere context access. This calls for approaches that strengthen models' ability to suppress irrelevant content during retrieval.</li>
</ul>

<h3>Title: Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion Models in a Vision-Language-Action Framework</h3>
<ul>
<li><strong>Authors: </strong>Huixin Zhan, Jason H. Moore</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08185">https://arxiv.org/abs/2506.08185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08185">https://arxiv.org/pdf/2506.08185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08185]] Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion Models in a Vision-Language-Action Framework(https://arxiv.org/abs/2506.08185)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer, diffusion</a></li>
<li><strong>Abstract: </strong>Surgeons exhibit distinct operating styles due to differences in training, experience, and motor behavior - yet current AI systems often ignore this personalization signal. We propose a novel approach to model fine-grained, surgeon-specific fingerprinting in robotic surgery using a discrete diffusion framework integrated with a vision-language-action (VLA) pipeline. Our method formulates gesture prediction as a structured sequence denoising task, conditioned on multimodal inputs including endoscopic video, surgical intent language, and a privacy-aware embedding of surgeon identity and skill. Personalized surgeon fingerprinting is encoded through natural language prompts using third-party language models, allowing the model to retain individual behavioral style without exposing explicit identity. We evaluate our method on the JIGSAWS dataset and demonstrate that it accurately reconstructs gesture sequences while learning meaningful motion fingerprints unique to each surgeon. To quantify the privacy implications of personalization, we perform membership inference attacks and find that more expressive embeddings improve task performance but simultaneously increase susceptibility to identity leakage. These findings demonstrate that while personalized embeddings improve performance, they also increase vulnerability to identity leakage, revealing the importance of balancing personalization with privacy risk in surgical modeling. Code is available at: this https URL.</li>
</ul>

<h3>Title: GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors</h3>
<ul>
<li><strong>Authors: </strong>Wenlong Meng, Shuguo Fan, Chengkun Wei, Min Chen, Yuwei Li, Yuanchao Zhang, Zhikun Zhang, Wenzhi Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08188">https://arxiv.org/abs/2506.08188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08188">https://arxiv.org/pdf/2506.08188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08188]] GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors(https://arxiv.org/abs/2506.08188)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce GradEscape, the first gradient-based evader designed to attack AI-generated text (AIGT) detectors. GradEscape overcomes the undifferentiable computation problem, caused by the discrete nature of text, by introducing a novel approach to construct weighted embeddings for the detector input. It then updates the evader model parameters using feedback from victim detectors, achieving high attack success with minimal text modification. To address the issue of tokenizer mismatch between the evader and the detector, we introduce a warm-started evader method, enabling GradEscape to adapt to detectors across any language model architecture. Moreover, we employ novel tokenizer inference and model extraction techniques, facilitating effective evasion even in query-only access. We evaluate GradEscape on four datasets and three widely-used language models, benchmarking it against four state-of-the-art AIGT evaders. Experimental results demonstrate that GradEscape outperforms existing evaders in various scenarios, including with an 11B paraphrase model, while utilizing only 139M parameters. We have successfully applied GradEscape to two real-world commercial AIGT detectors. Our analysis reveals that the primary vulnerability stems from disparity in text expression styles within the training data. We also propose a potential defense strategy to mitigate the threat of AIGT evaders. We open-source our GradEscape for developing more robust AIGT detectors.</li>
</ul>

<h3>Title: Generative Learning of Differentiable Object Models for Compositional Interpretation of Complex Scenes</h3>
<ul>
<li><strong>Authors: </strong>Antoni Nowinowski, Krzysztof Krawiec</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08191">https://arxiv.org/abs/2506.08191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08191">https://arxiv.org/pdf/2506.08191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08191]] Generative Learning of Differentiable Object Models for Compositional Interpretation of Complex Scenes(https://arxiv.org/abs/2506.08191)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>This study builds on the architecture of the Disentangler of Visual Priors (DVP), a type of autoencoder that learns to interpret scenes by decomposing the perceived objects into independent visual aspects of shape, size, orientation, and color appearance. These aspects are expressed as latent parameters which control a differentiable renderer that performs image reconstruction, so that the model can be trained end-to-end with gradient using reconstruction loss. In this study, we extend the original DVP so that it can handle multiple objects in a scene. We also exploit the interpretability of its latent by using the decoder to sample additional training examples and devising alternative training modes that rely on loss functions defined not only in the image space, but also in the latent space. This significantly facilitates training, which is otherwise challenging due to the presence of extensive plateaus in the image-space reconstruction loss. To examine the performance of this approach, we propose a new benchmark featuring multiple 2D objects, which subsumes the previously proposed Multi-dSprites dataset while being more parameterizable. We compare the DVP extended in these ways with two baselines (MONet and LIVE) and demonstrate its superiority in terms of reconstruction quality and capacity to decompose overlapping objects. We also analyze the gradients induced by the considered loss functions, explain how they impact the efficacy of training, and discuss the limitations of differentiable rendering in autoencoders and the ways in which they can be addressed.</li>
</ul>

<h3>Title: Interpreting Agent Behaviors in Reinforcement-Learning-Based Cyber-Battle Simulation Platforms</h3>
<ul>
<li><strong>Authors: </strong>Jared Claypoole, Steven Cheung, Ashish Gehani, Vinod Yegneswaran, Ahmad Ridley</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08192">https://arxiv.org/abs/2506.08192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08192">https://arxiv.org/pdf/2506.08192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08192]] Interpreting Agent Behaviors in Reinforcement-Learning-Based Cyber-Battle Simulation Platforms(https://arxiv.org/abs/2506.08192)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, interpretability</a></li>
<li><strong>Abstract: </strong>We analyze two open source deep reinforcement learning agents submitted to the CAGE Challenge 2 cyber defense challenge, where each competitor submitted an agent to defend a simulated network against each of several provided rules-based attack agents. We demonstrate that one can gain interpretability of agent successes and failures by simplifying the complex state and action spaces and by tracking important events, shedding light on the fine-grained behavior of both the defense and attack agents in each experimental scenario. By analyzing important events within an evaluation episode, we identify patterns in infiltration and clearing events that tell us how well the attacker and defender played their respective roles; for example, defenders were generally able to clear infiltrations within one or two timesteps of a host being exploited. By examining transitions in the environment's state caused by the various possible actions, we determine which actions tended to be effective and which did not, showing that certain important actions are between 40% and 99% ineffective. We examine how decoy services affect exploit success, concluding for instance that decoys block up to 94% of exploits that would directly grant privileged access to a host. Finally, we discuss the realism of the challenge and ways that the CAGE Challenge 4 has addressed some of our concerns.</li>
</ul>

<h3>Title: GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra</h3>
<ul>
<li><strong>Authors: </strong>Mateusz Michalkiewicz, Anekha Sokhal, Tadeusz Michalkiewicz, Piotr Pawlikowski, Mahsa Baktashmotlagh, Varun Jampani, Guha Balakrishnan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08194">https://arxiv.org/abs/2506.08194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08194">https://arxiv.org/pdf/2506.08194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08194]] GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra(https://arxiv.org/abs/2506.08194)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Monocular 3D reconstruction methods and vision-language models (VLMs) demonstrate impressive results on standard benchmarks, yet their true understanding of geometric properties remains unclear. We introduce GIQ , a comprehensive benchmark specifically designed to evaluate the geometric reasoning capabilities of vision and vision-language foundation models. GIQ comprises synthetic and real-world images of 224 diverse polyhedra - including Platonic, Archimedean, Johnson, and Catalan solids, as well as stellations and compound shapes - covering varying levels of complexity and symmetry. Through systematic experiments involving monocular 3D reconstruction, 3D symmetry detection, mental rotation tests, and zero-shot shape classification tasks, we reveal significant shortcomings in current models. State-of-the-art reconstruction algorithms trained on extensive 3D datasets struggle to reconstruct even basic geometric forms accurately. While foundation models effectively detect specific 3D symmetry elements via linear probing, they falter significantly in tasks requiring detailed geometric differentiation, such as mental rotation. Moreover, advanced vision-language assistants exhibit remarkably low accuracy on complex polyhedra, systematically misinterpreting basic properties like face geometry, convexity, and compound structures. GIQ is publicly available, providing a structured platform to highlight and address critical gaps in geometric intelligence, facilitating future progress in robust, geometry-aware representation learning.</li>
</ul>

<h3>Title: Correlated Noise Mechanisms for Differentially Private Learning</h3>
<ul>
<li><strong>Authors: </strong>Krishna Pillutla, Jalaj Upadhyay, Christopher A. Choquette-Choo, Krishnamurthy Dvijotham, Arun Ganesh, Monika Henzinger, Jonathan Katz, Ryan McKenna, H. Brendan McMahan, Keith Rush, Thomas Steinke, Abhradeep Thakurta</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08201">https://arxiv.org/abs/2506.08201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08201">https://arxiv.org/pdf/2506.08201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08201]] Correlated Noise Mechanisms for Differentially Private Learning(https://arxiv.org/abs/2506.08201)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>This monograph explores the design and analysis of correlated noise mechanisms for differential privacy (DP), focusing on their application to private training of AI and machine learning models via the core primitive of estimation of weighted prefix sums. While typical DP mechanisms inject independent noise into each step of a stochastic gradient (SGD) learning algorithm in order to protect the privacy of the training data, a growing body of recent research demonstrates that introducing (anti-)correlations in the noise can significantly improve privacy-utility trade-offs by carefully canceling out some of the noise added on earlier steps in subsequent steps. Such correlated noise mechanisms, known variously as matrix mechanisms, factorization mechanisms, and DP-Follow-the-Regularized-Leader (DP-FTRL) when applied to learning algorithms, have also been influential in practice, with industrial deployment at a global scale.</li>
</ul>

<h3>Title: A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Andrew Z. Wang, Songwei Ge, Tero Karras, Ming-Yu Liu, Yogesh Balaji</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08210">https://arxiv.org/abs/2506.08210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08210">https://arxiv.org/pdf/2506.08210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08210]] A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation(https://arxiv.org/abs/2506.08210)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Both text-to-image generation and large language models (LLMs) have made significant advancements. However, many text-to-image models still employ the somewhat outdated T5 and CLIP as their text encoders. In this work, we investigate the effectiveness of using modern decoder-only LLMs as text encoders for text-to-image diffusion models. We build a standardized training and evaluation pipeline that allows us to isolate and evaluate the effect of different text embeddings. We train a total of 27 text-to-image models with 12 different text encoders to analyze the critical aspects of LLMs that could impact text-to-image generation, including the approaches to extract embeddings, different LLMs variants, and model sizes. Our experiments reveal that the de facto way of using last-layer embeddings as conditioning leads to inferior performance. Instead, we explore embeddings from various layers and find that using layer-normalized averaging across all layers significantly improves alignment with complex prompts. Most LLMs with this conditioning outperform the baseline T5 model, showing enhanced performance in advanced visio-linguistic reasoning skills.</li>
</ul>

<h3>Title: What makes an Ensemble (Un) Interpretable?</h3>
<ul>
<li><strong>Authors: </strong>Shahaf Bassan, Guy Amir, Meirav Zehavi, Guy Katz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CC, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08216">https://arxiv.org/abs/2506.08216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08216">https://arxiv.org/pdf/2506.08216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08216]] What makes an Ensemble (Un) Interpretable?(https://arxiv.org/abs/2506.08216)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Ensemble models are widely recognized in the ML community for their limited interpretability. For instance, while a single decision tree is considered interpretable, ensembles of trees (e.g., boosted trees) are often treated as black-boxes. Despite this folklore recognition, there remains a lack of rigorous mathematical understanding of what particularly makes an ensemble (un)-interpretable, including how fundamental factors like the (1) *number*, (2) *size*, and (3) *type* of base models influence its interpretability. In this work, we seek to bridge this gap by applying concepts from computational complexity theory to study the challenges of generating explanations for various ensemble configurations. Our analysis uncovers nuanced complexity patterns influenced by various factors. For example, we demonstrate that under standard complexity assumptions like P$\neq$NP, interpreting ensembles remains intractable even when base models are of constant size. Surprisingly, the complexity changes drastically with the number of base models: small ensembles of decision trees are efficiently interpretable, whereas interpreting ensembles with even a constant number of linear models remains intractable. We believe that our findings provide a more robust foundation for understanding the interpretability of ensembles, emphasizing the benefits of examining it through a computational complexity lens.</li>
</ul>

<h3>Title: gh0stEdit: Exploiting Layer-Based Access Vulnerability Within Docker Container Images</h3>
<ul>
<li><strong>Authors: </strong>Alan Mills, Jonathan White, Phil Legg</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08218">https://arxiv.org/abs/2506.08218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08218">https://arxiv.org/pdf/2506.08218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08218]] gh0stEdit: Exploiting Layer-Based Access Vulnerability Within Docker Container Images(https://arxiv.org/abs/2506.08218)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Containerisation is a popular deployment process for application-level virtualisation using a layer-based approach. Docker is a leading provider of containerisation, and through the Docker Hub, users can supply Docker images for sharing and re-purposing popular software application containers. Using a combination of in-built inspection commands, publicly displayed image layer content, and static image scanning, Docker images are designed to ensure end users can clearly assess the content of the image before running them. In this paper we present \textbf{\textit{gh0stEdit}}, a vulnerability that fundamentally undermines the integrity of Docker images and subverts the assumed trust and transparency they utilise. The use of gh0stEdit allows an attacker to maliciously edit Docker images, in a way that is not shown within the image history, hierarchy or commands. This attack can also be carried out against signed images (Docker Content Trust) without invalidating the image signature. We present two use case studies for this vulnerability, and showcase how gh0stEdit is able to poison an image in a way that is not picked up through static or dynamic scanning tools. Our attack case studies highlight the issues in the current approach to Docker image security and trust, and expose an attack method which could potentially be exploited in the wild without being detected. To the best of our knowledge we are the first to provide detailed discussion on the exploit of this vulnerability.</li>
</ul>

<h3>Title: Jamais Vu: Exposing the Generalization Gap in Supervised Semantic Correspondence</h3>
<ul>
<li><strong>Authors: </strong>Octave Mariotti, Zhipeng Du, Yash Bhalgat, Oisin Mac Aodha, Hakan Bilen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08220">https://arxiv.org/abs/2506.08220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08220">https://arxiv.org/pdf/2506.08220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08220]] Jamais Vu: Exposing the Generalization Gap in Supervised Semantic Correspondence(https://arxiv.org/abs/2506.08220)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Semantic correspondence (SC) aims to establish semantically meaningful matches across different instances of an object category. We illustrate how recent supervised SC methods remain limited in their ability to generalize beyond sparsely annotated training keypoints, effectively acting as keypoint detectors. To address this, we propose a novel approach for learning dense correspondences by lifting 2D keypoints into a canonical 3D space using monocular depth estimation. Our method constructs a continuous canonical manifold that captures object geometry without requiring explicit 3D supervision or camera annotations. Additionally, we introduce SPair-U, an extension of SPair-71k with novel keypoint annotations, to better assess generalization. Experiments not only demonstrate that our model significantly outperforms supervised baselines on unseen keypoints, highlighting its effectiveness in learning robust correspondences, but that unsupervised baselines outperform supervised counterparts when generalized across different datasets.</li>
</ul>

<h3>Title: "I Wrote, I Paused, I Rewrote" Teaching LLMs to Read Between the Lines of Student Writing</h3>
<ul>
<li><strong>Authors: </strong>Samra Zafar, Shaheer Minhas, Syed Ali Hassan Zaidi, Arfa Naeem, Zahra Ali</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08221">https://arxiv.org/abs/2506.08221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08221">https://arxiv.org/pdf/2506.08221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08221]] "I Wrote, I Paused, I Rewrote" Teaching LLMs to Read Between the Lines of Student Writing(https://arxiv.org/abs/2506.08221)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models(LLMs) like Gemini are becoming common tools for supporting student writing. But most of their feedback is based only on the final essay missing important context about how that text was written. In this paper, we explore whether using writing process data, collected through keystroke logging and periodic snapshots, can help LLMs give feedback that better reflects how learners think and revise while writing. We built a digital writing tool that captures both what students type and how their essays evolve over time. Twenty students used this tool to write timed essays, which were then evaluated in two ways: (i) LLM generated feedback using both the final essay and the full writing trace, and (ii) After the task, students completed surveys about how useful and relatable they found the feedback. Early results show that learners preferred the process-aware LLM feedback, finding it more in tune with their own thinking. We also found that certain types of edits, like adding new content or reorganizing paragraphs, aligned closely with higher scores in areas like coherence and elaboration. Our findings suggest that making LLMs more aware of the writing process can lead to feedback that feels more meaningful, personal, and supportive.</li>
</ul>

<h3>Title: Mondrian: Transformer Operators via Domain Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Arthur Feeney, Kuei-Hsiang Huang, Aparna Chandramowlishwaran</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08226">https://arxiv.org/abs/2506.08226</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08226">https://arxiv.org/pdf/2506.08226</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08226]] Mondrian: Transformer Operators via Domain Decomposition(https://arxiv.org/abs/2506.08226)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Operator learning enables data-driven modeling of partial differential equations (PDEs) by learning mappings between function spaces. However, scaling transformer-based operator models to high-resolution, multiscale domains remains a challenge due to the quadratic cost of attention and its coupling to discretization. We introduce \textbf{Mondrian}, transformer operators that decompose a domain into non-overlapping subdomains and apply attention over sequences of subdomain-restricted functions. Leveraging principles from domain decomposition, Mondrian decouples attention from discretization. Within each subdomain, it replaces standard layers with expressive neural operators, and attention across subdomains is computed via softmax-based inner products over functions. The formulation naturally extends to hierarchical windowed and neighborhood attention, supporting both local and global interactions. Mondrian achieves strong performance on Allen-Cahn and Navier-Stokes PDEs, demonstrating resolution scaling without retraining. These results highlight the promise of domain-decomposed attention for scalable and general-purpose neural operators.</li>
</ul>

<h3>Title: A Good CREPE needs more than just Sugar: Investigating Biases in Compositional Vision-Language Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Vishaal Udandarao, Mehdi Cherti, Shyamgopal Karthik, Jenia Jitsev, Samuel Albanie, Matthias Bethge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08227">https://arxiv.org/abs/2506.08227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08227">https://arxiv.org/pdf/2506.08227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08227]] A Good CREPE needs more than just Sugar: Investigating Biases in Compositional Vision-Language Benchmarks(https://arxiv.org/abs/2506.08227)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>We investigate 17 benchmarks (e.g. SugarCREPE, VALSE) commonly used for measuring compositional understanding capabilities of vision-language models (VLMs). We scrutinize design choices in their construction, including data source (e.g. MS-COCO) and curation procedures (e.g. constructing negative images/captions), uncovering several inherent biases across most benchmarks. We find that blind heuristics (e.g. token-length, log-likelihood under a language model) perform on par with CLIP models, indicating that these benchmarks do not effectively measure compositional understanding. We demonstrate that the underlying factor is a distribution asymmetry between positive and negative images/captions, induced by the benchmark construction procedures. To mitigate these issues, we provide a few key recommendations for constructing more robust vision-language compositional understanding benchmarks, that would be less prone to such simple attacks.</li>
</ul>

<h3>Title: Scaling Laws of Motion Forecasting and Planning -- A Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Mustafa Baniodeh, Kratarth Goel, Scott Ettinger, Carlos Fuertes, Ari Seff, Tim Shen, Cole Gulino, Chenjie Yang, Ghassen Jerfel, Dokook Choe, Rui Wang, Vinutha Kallem, Sergio Casas, Rami Al-Rfou, Benjamin Sapp, Dragomir Anguelov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08228">https://arxiv.org/abs/2506.08228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08228">https://arxiv.org/pdf/2506.08228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08228]] Scaling Laws of Motion Forecasting and Planning -- A Technical Report(https://arxiv.org/abs/2506.08228)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We study the empirical scaling laws of a family of encoder-decoder autoregressive transformer models on the task of joint motion forecasting and planning in the autonomous driving domain. Using a 500 thousand hours driving dataset, we demonstrate that, similar to language modeling, model performance improves as a power-law function of the total compute budget, and we observe a strong correlation between model training loss and model evaluation metrics. Most interestingly, closed-loop metrics also improve with scaling, which has important implications for the suitability of open-loop metrics for model development and hill climbing. We also study the optimal scaling of the number of transformer parameters and the training data size for a training compute-optimal model. We find that as the training compute budget grows, optimal scaling requires increasing the model size 1.5x as fast as the dataset size. We also study inference-time compute scaling, where we observe that sampling and clustering the output of smaller models makes them competitive with larger models, up to a crossover point beyond which a larger models becomes more inference-compute efficient. Overall, our experimental results demonstrate that optimizing the training and inference-time scaling properties of motion forecasting and planning models is a key lever for improving their performance to address a wide variety of driving scenarios. Finally, we briefly study the utility of training on general logged driving data of other agents to improve the performance of the ego-agent, an important research area to address the scarcity of robotics data for large capacity models training.</li>
</ul>

<h3>Title: Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework</h3>
<ul>
<li><strong>Authors: </strong>Melissa Estevez, Nisha Singh, Lauren Dyson, Blythe Adamson, Qianyu Yuan, Megan W. Hildner, Erin Fidyk, Olive Mbah, Farhad Khan, Kathi Seidl-Rathkopf, Aaron B. Cohen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08231">https://arxiv.org/abs/2506.08231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08231">https://arxiv.org/pdf/2506.08231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08231]] Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework(https://arxiv.org/abs/2506.08231)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used to extract clinical data from electronic health records (EHRs), offering significant improvements in scalability and efficiency for real-world data (RWD) curation in oncology. However, the adoption of LLMs introduces new challenges in ensuring the reliability, accuracy, and fairness of extracted data, which are essential for research, regulatory, and clinical applications. Existing quality assurance frameworks for RWD and artificial intelligence do not fully address the unique error modes and complexities associated with LLM-extracted data. In this paper, we propose a comprehensive framework for evaluating the quality of clinical data extracted by LLMs. The framework integrates variable-level performance benchmarking against expert human abstraction, automated verification checks for internal consistency and plausibility, and replication analyses comparing LLM-extracted data to human-abstracted datasets or external standards. This multidimensional approach enables the identification of variables most in need of improvement, systematic detection of latent errors, and confirmation of dataset fitness-for-purpose in real-world research. Additionally, the framework supports bias assessment by stratifying metrics across demographic subgroups. By providing a rigorous and transparent method for assessing LLM-extracted RWD, this framework advances industry standards and supports the trustworthy use of AI-powered evidence generation in oncology research and practice.</li>
</ul>

<h3>Title: Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Yu-Ang Lee, Guan-Ting Yi, Mei-Yi Liu, Jui-Chao Lu, Guan-Bo Yang, Yun-Nung Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08234">https://arxiv.org/abs/2506.08234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08234">https://arxiv.org/pdf/2506.08234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08234]] Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions(https://arxiv.org/abs/2506.08234)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) and AI systems have led to a paradigm shift in the design and optimization of complex AI workflows. By integrating multiple components, compound AI systems have become increasingly adept at performing sophisticated tasks. However, as these systems grow in complexity, new challenges arise in optimizing not only individual components but also their interactions. While traditional optimization methods such as supervised fine-tuning (SFT) and reinforcement learning (RL) remain foundational, the rise of natural language feedback introduces promising new approaches, especially for optimizing non-differentiable systems. This paper provides a systematic review of recent progress in optimizing compound AI systems, encompassing both numerical and language-based techniques. We formalize the notion of compound AI system optimization, classify existing methods along several key dimensions, and highlight open research challenges and future directions in this rapidly evolving field. A list of surveyed papers is publicly available at this https URL.</li>
</ul>

<h3>Title: Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\rightarrow$ Evidence Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Shashidhar Reddy Javaji, Yupeng Cao, Haohang Li, Yangyang Yu, Nikhil Muralidhar, Zining Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08235">https://arxiv.org/abs/2506.08235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08235">https://arxiv.org/pdf/2506.08235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08235]] Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\rightarrow$ Evidence Reasoning(https://arxiv.org/abs/2506.08235)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly being used for complex research tasks such as literature review, idea generation, and scientific paper analysis, yet their ability to truly understand and process the intricate relationships within complex research papers, such as the logical links between claims and supporting evidence remains largely unexplored. In this study, we present CLAIM-BENCH, a comprehensive benchmark for evaluating LLMs' capabilities in scientific claim-evidence extraction and validation, a task that reflects deeper comprehension of scientific argumentation. We systematically compare three approaches which are inspired by divide and conquer approaches, across six diverse LLMs, highlighting model-specific strengths and weaknesses in scientific comprehension. Through evaluation involving over 300 claim-evidence pairs across multiple research domains, we reveal significant limitations in LLMs' ability to process complex scientific content. Our results demonstrate that closed-source models like GPT-4 and Claude consistently outperform open-source counterparts in precision and recall across claim-evidence identification tasks. Furthermore, strategically designed three-pass and one-by-one prompting approaches significantly improve LLMs' abilities to accurately link dispersed evidence with claims, although this comes at increased computational cost. CLAIM-BENCH sets a new standard for evaluating scientific comprehension in LLMs, offering both a diagnostic tool and a path forward for building systems capable of deeper, more reliable reasoning across full-length papers.</li>
</ul>

<h3>Title: Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic</h3>
<ul>
<li><strong>Authors: </strong>Zhenjiang Mao, Artem Bisliouk, Rohith Reddy Nama, Ivan Ruchkin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08243">https://arxiv.org/abs/2506.08243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08243">https://arxiv.org/pdf/2506.08243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08243]] Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic(https://arxiv.org/abs/2506.08243)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown impressive performance in mathematical reasoning tasks when guided by Chain-of-Thought (CoT) prompting. However, they tend to produce highly confident yet incorrect outputs, which poses significant risks in domains like education, where users may lack the expertise to assess reasoning steps. To address this, we propose a structured framework that models stepwise confidence as a temporal signal and evaluates it using Signal Temporal Logic (STL). In particular, we define formal STL-based constraints to capture desirable temporal properties and compute robustness scores that serve as structured, interpretable confidence estimates. Our approach also introduces a set of uncertainty reshaping strategies to enforce smoothness, monotonicity, and causal consistency across the reasoning trajectory. Experiments show that our approach consistently improves calibration metrics and provides more reliable uncertainty estimates than conventional confidence aggregation and post-hoc calibration.</li>
</ul>

<h3>Title: PoSyn: Secure Power Side-Channel Aware Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Amisha Srivastava, Samit S. Miftah, Hyunmin Kim, Debjit Pal, Kanad Basu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08252">https://arxiv.org/abs/2506.08252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08252">https://arxiv.org/pdf/2506.08252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08252]] PoSyn: Secure Power Side-Channel Aware Synthesis(https://arxiv.org/abs/2506.08252)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Power Side-Channel (PSC) attacks exploit power consumption patterns to extract sensitive information, posing risks to cryptographic operations crucial for secure systems. Traditional countermeasures, such as masking, face challenges including complex integration during synthesis, substantial area overhead, and susceptibility to optimization removal during logic synthesis. To address these issues, we introduce PoSyn, a novel logic synthesis framework designed to enhance cryptographic hardware resistance against PSC attacks. Our method centers on optimal bipartite mapping of vulnerable RTL components to standard cells from the technology library, aiming to minimize PSC leakage. By utilizing a cost function integrating critical characteristics from both the RTL design and the standard cell library, we strategically modify mapping criteria during RTL-to-netlist conversion without altering design functionality. Furthermore, we theoretically establish that PoSyn minimizes mutual information leakage, strengthening its security against PSC vulnerabilities. We evaluate PoSyn across various cryptographic hardware implementations, including AES, RSA, PRESENT, and post-quantum cryptographic algorithms such as Saber and CRYSTALS-Kyber, at technology nodes of 65nm, 45nm, and 15nm. Experimental results demonstrate a substantial reduction in success rates for Differential Power Analysis (DPA) and Correlation Power Analysis (CPA) attacks, achieving lows of 3% and 6%, respectively. TVLA analysis further confirms that synthesized netlists exhibit negligible leakage. Additionally, compared to conventional countermeasures like masking and shuffling, PoSyn significantly lowers attack success rates, achieving reductions of up to 72%, while simultaneously enhancing area efficiency by as much as 3.79 times.</li>
</ul>

<h3>Title: SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense</h3>
<ul>
<li><strong>Authors: </strong>Patryk Krukowski, Łukasz Gorczyca, Piotr Helm, Kamil Książek, Przemysław Spurek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08255">https://arxiv.org/abs/2506.08255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08255">https://arxiv.org/pdf/2506.08255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08255]] SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense(https://arxiv.org/abs/2506.08255)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Traditional deep neural networks suffer from several limitations, including catastrophic forgetting. When models are adapted to new datasets, they tend to quickly forget previously learned knowledge. Another significant issue is the lack of robustness to even small perturbations in the input data. In practice, we can often easily perform adversarial attacks and change the network's predictions, adding minimal noise to the input. Dedicated architectures and training procedures can solve each of the above problems separately. Unfortunately, currently, no model can simultaneously address both catastrophic forgetting and vulnerability to adversarial attacks. We introduce SHIELD (Secure Hypernetworks for Incremental Expansion and Learning Defense), a novel approach that integrates a hypernetwork-based continual learning approach with interval arithmetic. SHIELD use the hypernetwork to transfer trainable task embedding vectors into the weights of a target model dedicated to specific data. This paradigm allows for the dynamic generation of separate networks for each subtask, while the hypernetwork aggregates and analyzes information across all tasks. The target model takes in the input a data sample with a defined interval range, and by creating a hypercube, produces a prediction for the given range. Therefore, such target models provide strict guarantees against all possible attacks for data samples within the interval range. Our approach enhances security without sacrificing network adaptability, addressing the overlooked challenge of safety in continual learning.</li>
</ul>

<h3>Title: Highly Compressed Tokenizer Can Generate Without Training</h3>
<ul>
<li><strong>Authors: </strong>L. Lao Beyer, T. Li, X. Chen, S. Karaman, K. He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08257">https://arxiv.org/abs/2506.08257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08257">https://arxiv.org/pdf/2506.08257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08257]] Highly Compressed Tokenizer Can Generate Without Training(https://arxiv.org/abs/2506.08257)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Commonly used image tokenizers produce a 2D grid of spatially arranged tokens. In contrast, so-called 1D image tokenizers represent images as highly compressed one-dimensional sequences of as few as 32 discrete tokens. We find that the high degree of compression achieved by a 1D tokenizer with vector quantization enables image editing and generative capabilities through heuristic manipulation of tokens, demonstrating that even very crude manipulations -- such as copying and replacing tokens between latent representations of images -- enable fine-grained image editing by transferring appearance and semantic attributes. Motivated by the expressivity of the 1D tokenizer's latent space, we construct an image generation pipeline leveraging gradient-based test-time optimization of tokens with plug-and-play loss functions such as reconstruction or CLIP similarity. Our approach is demonstrated for inpainting and text-guided image editing use cases, and can generate diverse and realistic samples without requiring training of any generative model.</li>
</ul>

<h3>Title: Sparse Interpretable Deep Learning with LIES Networks for Symbolic Regression</h3>
<ul>
<li><strong>Authors: </strong>Mansooreh Montazerin, Majd Al Aawar, Antonio Ortega, Ajitesh Srivastava</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08267">https://arxiv.org/abs/2506.08267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08267">https://arxiv.org/pdf/2506.08267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08267]] Sparse Interpretable Deep Learning with LIES Networks for Symbolic Regression(https://arxiv.org/abs/2506.08267)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Symbolic regression (SR) aims to discover closed-form mathematical expressions that accurately describe data, offering interpretability and analytical insight beyond standard black-box models. Existing SR methods often rely on population-based search or autoregressive modeling, which struggle with scalability and symbolic consistency. We introduce LIES (Logarithm, Identity, Exponential, Sine), a fixed neural network architecture with interpretable primitive activations that are optimized to model symbolic expressions. We develop a framework to extract compact formulae from LIES networks by training with an appropriate oversampling strategy and a tailored loss function to promote sparsity and to prevent gradient instability. After training, it applies additional pruning strategies to further simplify the learned expressions into compact formulae. Our experiments on SR benchmarks show that the LIES framework consistently produces sparse and accurate symbolic formulae outperforming all baselines. We also demonstrate the importance of each design component through ablation studies.</li>
</ul>

<h3>Title: The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks</h3>
<ul>
<li><strong>Authors: </strong>João Manoel Herrera Pinheiro, Suzana Vilas Boas de Oliveira, Thiago Henrique Segreto Silva, Pedro Antonio Rabelo Saraiva, Enzo Ferreira de Souza, Leonardo André Ambrosio, Marcelo Becker</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08274">https://arxiv.org/abs/2506.08274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08274">https://arxiv.org/pdf/2506.08274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08274]] The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks(https://arxiv.org/abs/2506.08274)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This research addresses the critical lack of comprehensive studies on feature scaling by systematically evaluating 12 scaling techniques - including several less common transformations - across 14 different Machine Learning algorithms and 16 datasets for classification and regression tasks. We meticulously analyzed impacts on predictive performance (using metrics such as accuracy, MAE, MSE, and $R^2$) and computational costs (training time, inference time, and memory usage). Key findings reveal that while ensemble methods (such as Random Forest and gradient boosting models like XGBoost, CatBoost and LightGBM) demonstrate robust performance largely independent of scaling, other widely used models such as Logistic Regression, SVMs, TabNet, and MLPs show significant performance variations highly dependent on the chosen scaler. This extensive empirical analysis, with all source code, experimental results, and model parameters made publicly available to ensure complete transparency and reproducibility, offers model-specific crucial guidance to practitioners on the need for an optimal selection of feature scaling techniques.</li>
</ul>

<h3>Title: From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium</h3>
<ul>
<li><strong>Authors: </strong>Xie Yi, Zhanke Zhou, Chentao Cao, Qiyu Niu, Tongliang Liu, Bo Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08292">https://arxiv.org/abs/2506.08292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08292">https://arxiv.org/pdf/2506.08292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08292]] From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium(https://arxiv.org/abs/2506.08292)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-agent frameworks can substantially boost the reasoning power of large language models (LLMs), but they typically incur heavy computational costs and lack convergence guarantees. To overcome these challenges, we recast multi-LLM coordination as an incomplete-information game and seek a Bayesian Nash equilibrium (BNE), in which each agent optimally responds to its probabilistic beliefs about the strategies of others. We introduce Efficient Coordination via Nash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that marries distributed reasoning with centralized final output. Under ECON, each LLM independently selects responses that maximize its expected reward, conditioned on its beliefs about co-agents, without requiring costly inter-agent exchanges. We mathematically prove that ECON attains a markedly tighter regret bound than non-equilibrium multi-agent schemes. Empirically, ECON outperforms existing multi-LLM approaches by 11.2% on average across six benchmarks spanning complex reasoning and planning tasks. Further experiments demonstrate ECON's ability to flexibly incorporate additional models, confirming its scalability and paving the way toward larger, more powerful multi-LLM ensembles. The code is publicly available at: this https URL.</li>
</ul>

<h3>Title: From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?</h3>
<ul>
<li><strong>Authors: </strong>Zhanke Zhou, Xiao Feng, Zhaocheng Zhu, Jiangchao Yao, Sanmi Koyejo, Bo Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08295">https://arxiv.org/abs/2506.08295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08295">https://arxiv.org/pdf/2506.08295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08295]] From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?(https://arxiv.org/abs/2506.08295)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While existing benchmarks probe the reasoning abilities of large language models (LLMs) across diverse domains, they predominantly assess passive reasoning, providing models with all the information needed to reach a solution. By contrast, active reasoning-where an LLM must interact with external systems to acquire missing evidence or data-has received little systematic attention. To address this shortfall, we present AR-Bench, a novel benchmark designed explicitly to evaluate an LLM's active reasoning skills. AR-Bench comprises three task families-detective cases, situation puzzles, and guessing numbers-that together simulate real-world, agentic scenarios and measure performance across commonsense, logical, and symbolic reasoning challenges. Empirical evaluation on AR-Bench demonstrates that contemporary LLMs exhibit pronounced difficulties with active reasoning: they frequently fail to acquire or leverage the information needed to solve tasks. This gap highlights a stark divergence between their passive and active reasoning abilities. Moreover, ablation studies indicate that even advanced strategies, such as tree-based searching or post-training approaches, yield only modest gains and fall short of the levels required for real-world deployment. Collectively, these findings highlight the critical need to advance methodology for active reasoning, e.g., incorporating interactive learning, real-time feedback loops, and environment-aware objectives for training. The benchmark is publicly available at: this https URL.</li>
</ul>

<h3>Title: SEMA: a Scalable and Efficient Mamba like Attention via Token Localization and Averaging</h3>
<ul>
<li><strong>Authors: </strong>Nhat Thanh Tran, Fanghui Xue, Shuai Zhang, Jiancheng Lyu, Yunling Zheng, Yingyong Qi, Jack Xin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08297">https://arxiv.org/abs/2506.08297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08297">https://arxiv.org/pdf/2506.08297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08297]] SEMA: a Scalable and Efficient Mamba like Attention via Token Localization and Averaging(https://arxiv.org/abs/2506.08297)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Attention is the critical component of a transformer. Yet the quadratic computational complexity of vanilla full attention in the input size and the inability of its linear attention variant to focus have been challenges for computer vision tasks. We provide a mathematical definition of generalized attention and formulate both vanilla softmax attention and linear attention within the general framework. We prove that generalized attention disperses, that is, as the number of keys tends to infinity, the query assigns equal weights to all keys. Motivated by the dispersion property and recent development of Mamba form of attention, we design Scalable and Efficient Mamba like Attention (SEMA) which utilizes token localization to avoid dispersion and maintain focusing, complemented by theoretically consistent arithmetic averaging to capture global aspect of attention. We support our approach on Imagenet-1k where classification results show that SEMA is a scalable and effective alternative beyond linear attention, outperforming recent vision Mamba models on increasingly larger scales of images at similar model parameter sizes.</li>
</ul>

<h3>Title: H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs</h3>
<ul>
<li><strong>Authors: </strong>Trung-Kien Nguyen, Heng Ping, Shixuan Li, Peiyu Zhang, Nikos Kanakaris, Nicholas Kotov, Paul Bogdan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08298">https://arxiv.org/abs/2506.08298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08298">https://arxiv.org/pdf/2506.08298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08298]] H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs(https://arxiv.org/abs/2506.08298)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The growing interests and applications of graph learning in diverse domains have propelled the development of a unified model generalizing well across different graphs and tasks, known as the Graph Foundation Model (GFM). Existing research has leveraged text-attributed graphs (TAGs) to tackle the heterogeneity in node features among graphs. However, they primarily focus on homogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple types of nodes/edges reside, underexplored. To enhance the capabilities and applications of GFM, we introduce H$^2$GFM, a novel framework designed to generalize across both HoTAGs and HeTAGs. Our model projects diverse meta-relations among graphs under a unified textual space, and employs a context encoding to capture spatial and higher-order semantic relationships. To achieve robust node representations, we propose a novel context-adaptive graph transformer (CGT), effectively capturing information from both context neighbors and their relationships. Furthermore, we employ a mixture of CGT experts to capture the heterogeneity in structural patterns among graph types. Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well as learning scenarios demonstrate the effectiveness of our model.</li>
</ul>

<h3>Title: OpenRR-1k: A Scalable Dataset for Real-World Reflection Removal</h3>
<ul>
<li><strong>Authors: </strong>Kangning Yang, Ling Ouyang, Huiming Sun, Jie Cai, Lan Fu, Jiaming Ding, Chiu Man Ho, Zibo Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08299">https://arxiv.org/abs/2506.08299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08299">https://arxiv.org/pdf/2506.08299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08299]] OpenRR-1k: A Scalable Dataset for Real-World Reflection Removal(https://arxiv.org/abs/2506.08299)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reflection removal technology plays a crucial role in photography and computer vision applications. However, existing techniques are hindered by the lack of high-quality in-the-wild datasets. In this paper, we propose a novel paradigm for collecting reflection datasets from a fresh perspective. Our approach is convenient, cost-effective, and scalable, while ensuring that the collected data pairs are of high quality, perfectly aligned, and represent natural and diverse scenarios. Following this paradigm, we collect a Real-world, Diverse, and Pixel-aligned dataset (named OpenRR-1k dataset), which contains 1,000 high-quality transmission-reflection image pairs collected in the wild. Through the analysis of several reflection removal methods and benchmark evaluation experiments on our dataset, we demonstrate its effectiveness in improving robustness in challenging real-world environments. Our dataset is available at this https URL.</li>
</ul>

<h3>Title: Institutional Books 1.0: A 242B token dataset from Harvard Library's collections, refined for accuracy and usability</h3>
<ul>
<li><strong>Authors: </strong>Matteo Cargnelutti, Catherine Brobston, John Hess, Jack Cushman, Kristi Mukk, Aristana Scourtas, Kyle Courtney, Greg Leppert, Amanda Watson, Martha Whitehead, Jonathan Zittrain</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08300">https://arxiv.org/abs/2506.08300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08300">https://arxiv.org/pdf/2506.08300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08300]] Institutional Books 1.0: A 242B token dataset from Harvard Library's collections, refined for accuracy and usability(https://arxiv.org/abs/2506.08300)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) use data to learn about the world in order to produce meaningful correlations and predictions. As such, the nature, scale, quality, and diversity of the datasets used to train these models, or to support their work at inference time, have a direct impact on their quality. The rapid development and adoption of LLMs of varying quality has brought into focus the scarcity of publicly available, high-quality training data and revealed an urgent need to ground the stewardship of these datasets in sustainable practices with clear provenance chains. To that end, this technical report introduces Institutional Books 1.0, a large collection of public domain books originally digitized through Harvard Library's participation in the Google Books project, beginning in 2006. Working with Harvard Library, we extracted, analyzed, and processed these volumes into an extensively-documented dataset of historic texts. This analysis covers the entirety of Harvard Library's collection scanned as part of that project, originally spanning 1,075,899 volumes written in over 250 different languages for a total of approximately 250 billion tokens. As part of this initial release, the OCR-extracted text (original and post-processed) as well as the metadata (bibliographic, source, and generated) of the 983,004 volumes, or 242B tokens, identified as being in the public domain have been made available. This report describes this project's goals and methods as well as the results of the analyses we performed, all in service of making this historical collection more accessible and easier for humans and machines alike to filter, read and use.</li>
</ul>

<h3>Title: Learnable Spatial-Temporal Positional Encoding for Link Prediction</h3>
<ul>
<li><strong>Authors: </strong>Katherine Tieu, Dongqi Fu, Zihao Li, Ross Maciejewski, Jingrui He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08309">https://arxiv.org/abs/2506.08309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08309">https://arxiv.org/pdf/2506.08309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08309]] Learnable Spatial-Temporal Positional Encoding for Link Prediction(https://arxiv.org/abs/2506.08309)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Accurate predictions rely on the expressiveness power of graph deep learning frameworks like graph neural networks and graph transformers, where a positional encoding mechanism has become much more indispensable in recent state-of-the-art works to record the canonical position information. However, the current positional encoding is limited in three aspects: (1) most positional encoding methods use pre-defined, and fixed functions, which are inadequate to adapt to the complex attributed graphs; (2) a few pioneering works proposed the learnable positional encoding but are still limited to the structural information, not considering the real-world time-evolving topological and feature information; (3) most positional encoding methods are equipped with transformers' attention mechanism to fully leverage their capabilities, where the dense or relational attention is often unaffordable on large-scale structured data. Hence, we aim to develop Learnable Spatial-Temporal Positional Encoding in an effective and efficient manner and propose a simple temporal link prediction model named L-STEP. Briefly, for L-STEP, we (1) prove the proposed positional learning scheme can preserve the graph property from the spatial-temporal spectral viewpoint, (2) verify that MLPs can fully exploit the expressiveness and reach transformers' performance on that encoding, (3) change different initial positional encoding inputs to show robustness, (4) analyze the theoretical complexity and obtain less empirical running time than SOTA, and (5) demonstrate its temporal link prediction out-performance on 13 classic datasets and with 10 algorithms in both transductive and inductive settings using 3 different sampling strategies. Also, \name\ obtains the leading performance in the newest large-scale TGB benchmark. Our code is available at this https URL.</li>
</ul>

<h3>Title: Why Masking Diffusion Works: Condition on the Jump Schedule for Improved Discrete Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Alan N. Amin, Nate Gruver, Andrew Gordon Wilson</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08316">https://arxiv.org/abs/2506.08316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08316">https://arxiv.org/pdf/2506.08316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08316]] Why Masking Diffusion Works: Condition on the Jump Schedule for Improved Discrete Diffusion(https://arxiv.org/abs/2506.08316)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Discrete diffusion models, like continuous diffusion models, generate high-quality samples by gradually undoing noise applied to datapoints with a Markov process. Gradual generation in theory comes with many conceptual benefits; for example, inductive biases can be incorporated into the noising Markov process, and access to improved sampling algorithms. In practice, however, the consistently best performing discrete diffusion model is, surprisingly, masking diffusion, which does not denoise gradually. Here we explain the superior performance of masking diffusion by noting that it makes use of a fundamental difference between continuous and discrete Markov processes: discrete Markov processes evolve by discontinuous jumps at a fixed rate and, unlike other discrete diffusion models, masking diffusion builds in the known distribution of jump times and only learns where to jump to. We show that we can similarly bake in the known distribution of jump times into any discrete diffusion model. The resulting models - schedule-conditioned discrete diffusion (SCUD) - generalize classical discrete diffusion and masking diffusion. By applying SCUD to models with noising processes that incorporate inductive biases on images, text, and protein data, we build models that outperform masking.</li>
</ul>

<h3>Title: How Good LLM-Generated Password Policies Are?</h3>
<ul>
<li><strong>Authors: </strong>Vivek Vaidya, Aditya Patwardhan, Ashish Kundu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08320">https://arxiv.org/abs/2506.08320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08320">https://arxiv.org/pdf/2506.08320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08320]] How Good LLM-Generated Password Policies Are?(https://arxiv.org/abs/2506.08320)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative AI technologies, particularly Large Language Models (LLMs), are rapidly being adopted across industry, academia, and government sectors, owing to their remarkable capabilities in natural language processing. However, despite their strengths, the inconsistency and unpredictability of LLM outputs present substantial challenges, especially in security-critical domains such as access control. One critical issue that emerges prominently is the consistency of LLM-generated responses, which is paramount for ensuring secure and reliable operations. In this paper, we study the application of LLMs within the context of Cybersecurity Access Control Systems. Specifically, we investigate the consistency and accuracy of LLM-generated password policies, translating natural language prompts into executable this http URL configuration files. Our experimental methodology adopts two distinct approaches: firstly, we utilize pre-trained LLMs to generate configuration files purely from natural language prompts without additional guidance. Secondly, we provide these models with official this http URL documentation to serve as an informative baseline. We systematically assess the soundness, accuracy, and consistency of these AI-generated configurations. Our findings underscore significant challenges in the current generation of LLMs and contribute valuable insights into refining the deployment of LLMs in Access Control Systems.</li>
</ul>

<h3>Title: Hyperspectral Image Classification via Transformer-based Spectral-Spatial Attention Decoupling and Adaptive Gating</h3>
<ul>
<li><strong>Authors: </strong>Guandong Li, Mengxia Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08324">https://arxiv.org/abs/2506.08324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08324">https://arxiv.org/pdf/2506.08324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08324]] Hyperspectral Image Classification via Transformer-based Spectral-Spatial Attention Decoupling and Adaptive Gating(https://arxiv.org/abs/2506.08324)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Deep neural networks face several challenges in hyperspectral image classification, including high-dimensional data, sparse distribution of ground objects, and spectral redundancy, which often lead to classification overfitting and limited generalization capability. To more effectively extract and fuse spatial context with fine spectral information in hyperspectral image (HSI) classification, this paper proposes a novel network architecture called STNet. The core advantage of STNet stems from the dual innovative design of its Spatial-Spectral Transformer module: first, the fundamental explicit decoupling of spatial and spectral attention ensures targeted capture of key information in HSI; second, two functionally distinct gating mechanisms perform intelligent regulation at both the fusion level of attention flows (adaptive attention fusion gating) and the internal level of feature transformation (GFFN). This characteristic demonstrates superior feature extraction and fusion capabilities compared to traditional convolutional neural networks, while reducing overfitting risks in small-sample and high-noise scenarios. STNet enhances model representation capability without increasing network depth or width. The proposed method demonstrates superior performance on IN, UP, and KSC datasets, outperforming mainstream hyperspectral image classification approaches.</li>
</ul>

<h3>Title: Distortion Search, A Web Search Privacy Heuristic</h3>
<ul>
<li><strong>Authors: </strong>Kato Mivule, Kenneth Hopkinson</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08330">https://arxiv.org/abs/2506.08330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08330">https://arxiv.org/pdf/2506.08330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08330]] Distortion Search, A Web Search Privacy Heuristic(https://arxiv.org/abs/2506.08330)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Search engines have vast technical capabilities to retain Internet search logs for each user and thus present major privacy vulnerabilities to both individuals and organizations in revealing user intent. Additionally, many of the web search privacy enhancing tools available today require that the user trusts a third party, which make confidentiality of user intent even more challenging. The user is left at the mercy of the third party without the control over his or her own privacy. In this article, we suggest a user-centric heuristic, Distortion Search, a web search query privacy methodology that works by the formation of obfuscated search queries via the permutation of query keyword categories, and by strategically applying k-anonymised web navigational clicks on URLs and Ads to generate a distorted user profile and thus providing specific user intent and query confidentiality. We provide empirical results via the evaluation of distorted web search queries in terms of retrieved search results and the resulting web ads from search engines. Preliminary experimental results indicate that web search query and specific user intent privacy might be achievable from the user side without the involvement of the search engine or other third parties.</li>
</ul>

<h3>Title: Your Agent Can Defend Itself against Backdoor Attacks</h3>
<ul>
<li><strong>Authors: </strong>Li Changjiang, Liang Jiacheng, Cao Bochuan, Chen Jinghui, Wang Ting</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08336">https://arxiv.org/abs/2506.08336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08336">https://arxiv.org/pdf/2506.08336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08336]] Your Agent Can Defend Itself against Backdoor Attacks(https://arxiv.org/abs/2506.08336)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Despite their growing adoption across domains, large language model (LLM)-powered agents face significant security risks from backdoor attacks during training and fine-tuning. These compromised agents can subsequently be manipulated to execute malicious operations when presented with specific triggers in their inputs or environments. To address this pressing risk, we present ReAgent, a novel defense against a range of backdoor attacks on LLM-based agents. Intuitively, backdoor attacks often result in inconsistencies among the user's instruction, the agent's planning, and its execution. Drawing on this insight, ReAgent employs a two-level approach to detect potential backdoors. At the execution level, ReAgent verifies consistency between the agent's thoughts and actions; at the planning level, ReAgent leverages the agent's capability to reconstruct the instruction based on its thought trajectory, checking for consistency between the reconstructed instruction and the user's instruction. Extensive evaluation demonstrates ReAgent's effectiveness against various backdoor attacks across tasks. For instance, ReAgent reduces the attack success rate by up to 90\% in database operation tasks, outperforming existing defenses by large margins. This work reveals the potential of utilizing compromised agents themselves to mitigate backdoor risks.</li>
</ul>

<h3>Title: A Simple Analysis of Discretization Error in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Juhyeok Choi, Chenglin Fan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08337">https://arxiv.org/abs/2506.08337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08337">https://arxiv.org/pdf/2506.08337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08337]] A Simple Analysis of Discretization Error in Diffusion Models(https://arxiv.org/abs/2506.08337)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models, formulated as discretizations of stochastic differential equations (SDEs), achieve state-of-the-art generative performance. However, existing analyses of their discretization error often rely on complex probabilistic tools. In this work, we present a simplified theoretical framework for analyzing the Euler--Maruyama discretization of variance-preserving SDEs (VP-SDEs) in Denoising Diffusion Probabilistic Models (DDPMs), where $ T $ denotes the number of denoising steps in the diffusion process. Our approach leverages Grönwall's inequality to derive a convergence rate of $ \mathcal{O}(1/T^{1/2}) $ under Lipschitz assumptions, significantly streamlining prior proofs. Furthermore, we demonstrate that the Gaussian noise in the discretization can be replaced by a discrete random variable (e.g., Rademacher or uniform noise) without sacrificing convergence guarantees-an insight with practical implications for efficient sampling. Experiments validate our theory, showing that (1) the error scales as predicted, (2) discrete noise achieves comparable sample quality to Gaussian noise, and (3) incorrect noise scaling degrades performance. By unifying simplified analysis and discrete noise substitution, our work bridges theoretical rigor with practical efficiency in diffusion-based generative modeling.</li>
</ul>

<h3>Title: Dynamical System Optimization</h3>
<ul>
<li><strong>Authors: </strong>Emo Todorov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08340">https://arxiv.org/abs/2506.08340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08340">https://arxiv.org/pdf/2506.08340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08340]] Dynamical System Optimization(https://arxiv.org/abs/2506.08340)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We develop an optimization framework centered around a core idea: once a (parametric) policy is specified, control authority is transferred to the policy, resulting in an autonomous dynamical system. Thus we should be able to optimize policy parameters without further reference to controls or actions, and without directly using the machinery of approximate Dynamic Programming and Reinforcement Learning. Here we derive simpler algorithms at the autonomous system level, and show that they compute the same quantities as policy gradients and Hessians, natural gradients, proximal methods. Analogs to approximate policy iteration and off-policy learning are also available. Since policy parameters and other system parameters are treated uniformly, the same algorithms apply to behavioral cloning, mechanism design, system identification, learning of state estimators. Tuning of generative AI models is not only possible, but is conceptually closer to the present framework than to Reinforcement Learning.</li>
</ul>

<h3>Title: Differentially Private Relational Learning with Entity-level Privacy Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Yinan Huang, Haoteng Ying, Eli Chien, Rongzhe Wei, Pan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08347">https://arxiv.org/abs/2506.08347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08347">https://arxiv.org/pdf/2506.08347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08347]] Differentially Private Relational Learning with Entity-level Privacy Guarantees(https://arxiv.org/abs/2506.08347)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Learning with relational and network-structured data is increasingly vital in sensitive domains where protecting the privacy of individual entities is paramount. Differential Privacy (DP) offers a principled approach for quantifying privacy risks, with DP-SGD emerging as a standard mechanism for private model training. However, directly applying DP-SGD to relational learning is challenging due to two key factors: (i) entities often participate in multiple relations, resulting in high and difficult-to-control sensitivity; and (ii) relational learning typically involves multi-stage, potentially coupled (interdependent) sampling procedures that make standard privacy amplification analyses inapplicable. This work presents a principled framework for relational learning with formal entity-level DP guarantees. We provide a rigorous sensitivity analysis and introduce an adaptive gradient clipping scheme that modulates clipping thresholds based on entity occurrence frequency. We also extend the privacy amplification results to a tractable subclass of coupled sampling, where the dependence arises only through sample sizes. These contributions lead to a tailored DP-SGD variant for relational data with provable privacy guarantees. Experiments on fine-tuning text encoders over text-attributed network-structured relational data demonstrate the strong utility-privacy trade-offs of our approach. Our code is available at this https URL.</li>
</ul>

<h3>Title: Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Zhou, Xien Liu, Chenwei Yan, Chen Ning, Xiao Zhang, Boxun Li, Xiangling Fu, Shijin Wang, Guoping Hu, Yu Wang, Ji Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08349">https://arxiv.org/abs/2506.08349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08349">https://arxiv.org/pdf/2506.08349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08349]] Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving(https://arxiv.org/abs/2506.08349)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable performance on various medical benchmarks, but their capabilities across different cognitive levels remain underexplored. Inspired by Bloom's Taxonomy, we propose a multi-cognitive-level evaluation framework for assessing LLMs in the medical domain in this study. The framework integrates existing medical datasets and introduces tasks targeting three cognitive levels: preliminary knowledge grasp, comprehensive knowledge application, and scenario-based problem solving. Using this framework, we systematically evaluate state-of-the-art general and medical LLMs from six prominent families: Llama, Qwen, Gemma, Phi, GPT, and DeepSeek. Our findings reveal a significant performance decline as cognitive complexity increases across evaluated models, with model size playing a more critical role in performance at higher cognitive levels. Our study highlights the need to enhance LLMs' medical capabilities at higher cognitive levels and provides insights for developing LLMs suited to real-world medical applications.</li>
</ul>

<h3>Title: How Much To Guide: Revisiting Adaptive Guidance in Classifier-Free Guidance Text-to-Vision Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Huixuan Zhang, Junzhe Zhang, Xiaojun Wan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08351">https://arxiv.org/abs/2506.08351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08351">https://arxiv.org/pdf/2506.08351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08351]] How Much To Guide: Revisiting Adaptive Guidance in Classifier-Free Guidance Text-to-Vision Diffusion Models(https://arxiv.org/abs/2506.08351)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With the rapid development of text-to-vision generation diffusion models, classifier-free guidance has emerged as the most prevalent method for conditioning. However, this approach inherently requires twice as many steps for model forwarding compared to unconditional generation, resulting in significantly higher costs. While previous study has introduced the concept of adaptive guidance, it lacks solid analysis and empirical results, making previous method unable to be applied to general diffusion models. In this work, we present another perspective of applying adaptive guidance and propose Step AG, which is a simple, universally applicable adaptive guidance strategy. Our evaluations focus on both image quality and image-text alignment. whose results indicate that restricting classifier-free guidance to the first several denoising steps is sufficient for generating high-quality, well-conditioned images, achieving an average speedup of 20% to 30%. Such improvement is consistent across different settings such as inference steps, and various models including video generation models, highlighting the superiority of our method.</li>
</ul>

<h3>Title: MedMoE: Modality-Specialized Mixture of Experts for Medical Vision-Language Understanding</h3>
<ul>
<li><strong>Authors: </strong>Shivang Chopra, Lingchao Mao, Gabriela Sanchez-Rodriguez, Andrew J Feola, Jing Li, Zsolt Kira</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08356">https://arxiv.org/abs/2506.08356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08356">https://arxiv.org/pdf/2506.08356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08356]] MedMoE: Modality-Specialized Mixture of Experts for Medical Vision-Language Understanding(https://arxiv.org/abs/2506.08356)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Different medical imaging modalities capture diagnostic information at varying spatial resolutions, from coarse global patterns to fine-grained localized structures. However, most existing vision-language frameworks in the medical domain apply a uniform strategy for local feature extraction, overlooking the modality-specific demands. In this work, we present MedMoE, a modular and extensible vision-language processing framework that dynamically adapts visual representation based on the diagnostic context. MedMoE incorporates a Mixture-of-Experts (MoE) module conditioned on the report type, which routes multi-scale image features through specialized expert branches trained to capture modality-specific visual semantics. These experts operate over feature pyramids derived from a Swin Transformer backbone, enabling spatially adaptive attention to clinically relevant regions. This framework produces localized visual representations aligned with textual descriptions, without requiring modality-specific supervision at inference. Empirical results on diverse medical benchmarks demonstrate that MedMoE improves alignment and retrieval performance across imaging modalities, underscoring the value of modality-specialized visual representations in clinical vision-language systems.</li>
</ul>

<h3>Title: DEAL: Disentangling Transformer Head Activations for LLM Steering</h3>
<ul>
<li><strong>Authors: </strong>Li-Ming Zhan, Bo Liu, Zexin Lu, Chengqiang Xie, Jiannong Cao, Xiao-Ming Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08359">https://arxiv.org/abs/2506.08359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08359">https://arxiv.org/pdf/2506.08359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08359]] DEAL: Disentangling Transformer Head Activations for LLM Steering(https://arxiv.org/abs/2506.08359)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Inference-time steering aims to alter the response characteristics of large language models (LLMs) without modifying their underlying parameters. A critical step in this process is the identification of internal modules within LLMs that are associated with the target behavior. However, current approaches to module selection often depend on superficial cues or ad-hoc heuristics, which can result in suboptimal or unintended outcomes. In this work, we propose a principled causal-attribution framework for identifying behavior-relevant attention heads in transformers. For each head, we train a vector-quantized autoencoder (VQ-AE) on its attention activations, partitioning the latent space into behavior-relevant and behavior-irrelevant subspaces, each quantized with a shared learnable codebook. We assess the behavioral relevance of each head by quantifying the separability of VQ-AE encodings for behavior-aligned versus behavior-violating responses using a binary classification metric. This yields a behavioral relevance score that reflects each head discriminative capacity with respect to the target behavior, guiding both selection and importance weighting. Experiments on seven LLMs from two model families and five behavioral steering datasets demonstrate that our method enables more accurate inference-time interventions, achieving superior performance on the truthfulness-steering task. Furthermore, the heads selected by our approach exhibit strong zero-shot generalization in cross-domain truthfulness-steering scenarios.</li>
</ul>

<h3>Title: CC-RAG: Structured Multi-Hop Reasoning via Theme-Based Causal Graphs</h3>
<ul>
<li><strong>Authors: </strong>Jash Rajesh Parekh, Pengcheng Jiang, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08364">https://arxiv.org/abs/2506.08364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08364">https://arxiv.org/pdf/2506.08364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08364]] CC-RAG: Structured Multi-Hop Reasoning via Theme-Based Causal Graphs(https://arxiv.org/abs/2506.08364)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Understanding cause and effect relationships remains a formidable challenge for Large Language Models (LLMs), particularly in specialized domains where reasoning requires more than surface-level correlations. Retrieval-Augmented Generation (RAG) improves factual accuracy, but standard RAG pipelines treat evidence as flat context, lacking the structure required to model true causal dependencies. We introduce Causal-Chain RAG (CC-RAG), a novel approach that integrates zero-shot triple extraction and theme-aware graph chaining into the RAG pipeline, enabling structured multi-hop inference. Given a domain specific corpus, CC-RAG constructs a Directed Acyclic Graph (DAG) of <cause, relation, effect> triples and uses forward/backward chaining to guide structured answer generation. Experiments on two real-world domains: Bitcoin price fluctuations and Gaucher disease, show that CC-RAG outperforms standard RAG and zero-shot LLMs in chain similarity, information density, and lexical diversity. Both LLM-as-a-Judge and human evaluations consistently favor CC-RAG. Our results demonstrate that explicitly modeling causal structure enables LLMs to generate more accurate and interpretable responses, especially in specialized domains where flat retrieval fails.</li>
</ul>

<h3>Title: AlphaFold Database Debiasing for Robust Inverse Folding</h3>
<ul>
<li><strong>Authors: </strong>Cheng Tan, Zhenxiao Cao, Zhangyang Gao, Siyuan Li, Yufei Huang, Stan Z. Li</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08365">https://arxiv.org/abs/2506.08365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08365">https://arxiv.org/pdf/2506.08365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08365]] AlphaFold Database Debiasing for Robust Inverse Folding(https://arxiv.org/abs/2506.08365)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The AlphaFold Protein Structure Database (AFDB) offers unparalleled structural coverage at near-experimental accuracy, positioning it as a valuable resource for data-driven protein design. However, its direct use in training deep models that are sensitive to fine-grained atomic geometry, such as inverse folding, exposes a critical limitation. Comparative analysis of structural feature distributions reveals that AFDB structures exhibit distinct statistical regularities, reflecting a systematic geometric bias that deviates from the conformational diversity found in experimentally determined structures from the Protein Data Bank (PDB). While AFDB structures are cleaner and more idealized, PDB structures capture the intrinsic variability and physical realism essential for generalization in downstream tasks. To address this discrepancy, we introduce a Debiasing Structure AutoEncoder (DeSAE) that learns to reconstruct native-like conformations from intentionally corrupted backbone geometries. By training the model to recover plausible structural states, DeSAE implicitly captures a more robust and natural structural manifold. At inference, applying DeSAE to AFDB structures produces debiased structures that significantly improve inverse folding performance across multiple benchmarks. This work highlights the critical impact of subtle systematic biases in predicted structures and presents a principled framework for debiasing, significantly boosting the performance of structure-based learning tasks like inverse folding.</li>
</ul>

<h3>Title: Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding</h3>
<ul>
<li><strong>Authors: </strong>Zikai Xiao, Ziyang Wang, Wen Ma, Yan Zhang, Wei Shen, Yan Wang, Luqi Gong, Zuozhu Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08371">https://arxiv.org/abs/2506.08371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08371">https://arxiv.org/pdf/2506.08371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08371]] Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding(https://arxiv.org/abs/2506.08371)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) support long contexts, they struggle with performance degradation within the context window. Current solutions incur prohibitive training costs, leaving statistical behaviors and cost-effective approaches underexplored. From the decoding perspective, we identify the Posterior Salience Attenuation (PSA) phenomenon, where the salience ratio correlates with long-text performance degradation. Notably, despite the attenuation, gold tokens still occupy high-ranking positions in the decoding space. Motivated by it, we propose the training-free Positional Contrastive Decoding (PCD) that contrasts the logits derived from long-aware attention with those from designed local-aware attention, enabling the model to focus on the gains introduced by large-scale short-to-long training. Through the analysis of long-term decay simulation, we demonstrate that PCD effectively alleviates attention score degradation. Experimental results show that PCD achieves state-of-the-art performance on long-context benchmarks.</li>
</ul>

<h3>Title: Draft-based Approximate Inference for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Kevin Galim, Ethan Ewer, Wonjun Kang, Minjae Lee, Hyung Il Koo, Kangwook Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08373">https://arxiv.org/abs/2506.08373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08373">https://arxiv.org/pdf/2506.08373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08373]] Draft-based Approximate Inference for LLMs(https://arxiv.org/abs/2506.08373)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Optimizing inference for long-context Large Language Models (LLMs) is increasingly important due to the quadratic compute and linear memory complexity of Transformers. Existing approximation methods, such as key-value (KV) cache dropping, sparse attention, and prompt compression, typically rely on rough predictions of token or KV pair importance. We propose a novel framework for approximate LLM inference that leverages small draft models to more accurately predict the importance of tokens and KV pairs. Specifically, we introduce two instantiations of our proposed framework: (i) SpecKV, which leverages a draft output to accurately assess the importance of each KV pair for more effective KV cache dropping, and (ii) SpecPC, which uses the draft model's attention activations to identify and discard unimportant prompt tokens. To the best of our knowledge, this is the first work to use draft models for approximate LLM inference acceleration, extending their utility beyond traditional lossless speculative decoding. We motivate our methods with theoretical and empirical analyses, and show a strong correlation between the attention patterns of draft and target models. Extensive experiments on long-context benchmarks show that our methods consistently achieve higher accuracy than existing baselines, while preserving the same improvements in memory usage, latency, and throughput. Our code is available at this https URL.</li>
</ul>

<h3>Title: EIFBENCH: Extremely Complex Instruction Following Benchmark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tao Zou, Xinghua Zhang, Haiyang Yu, Minzheng Wang, Fei Huang, Yongbin Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08375">https://arxiv.org/abs/2506.08375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08375">https://arxiv.org/pdf/2506.08375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08375]] EIFBENCH: Extremely Complex Instruction Following Benchmark for Large Language Models(https://arxiv.org/abs/2506.08375)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>With the development and widespread application of large language models (LLMs), the new paradigm of "Model as Product" is rapidly evolving, and demands higher capabilities to address complex user needs, often requiring precise workflow execution which involves the accurate understanding of multiple tasks. However, existing benchmarks focusing on single-task environments with limited constraints lack the complexity required to fully reflect real-world scenarios. To bridge this gap, we present the Extremely Complex Instruction Following Benchmark (EIFBENCH), meticulously crafted to facilitate a more realistic and robust evaluation of LLMs. EIFBENCH not only includes multi-task scenarios that enable comprehensive assessment across diverse task types concurrently, but also integrates a variety of constraints, replicating complex operational environments. Furthermore, we propose the Segment Policy Optimization (SegPO) algorithm to enhance the LLM's ability to accurately fulfill multi-task workflow. Evaluations on EIFBENCH have unveiled considerable performance discrepancies in existing LLMs when challenged with these extremely complex instructions. This finding underscores the necessity for ongoing optimization to navigate the intricate challenges posed by LLM applications.</li>
</ul>

<h3>Title: Reinforce LLM Reasoning through Multi-Agent Reflection</h3>
<ul>
<li><strong>Authors: </strong>Yurun Yuan, Tengyang Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08379">https://arxiv.org/abs/2506.08379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08379">https://arxiv.org/pdf/2506.08379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08379]] Reinforce LLM Reasoning through Multi-Agent Reflection(https://arxiv.org/abs/2506.08379)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Leveraging more test-time computation has proven to be an effective way to boost the reasoning capabilities of large language models (LLMs). Among various methods, the verify-and-improve paradigm stands out for enabling dynamic solution exploration and feedback incorporation. However, existing approaches often suffer from restricted feedback spaces and lack of coordinated training of different parties, leading to suboptimal performance. To address this, we model this multi-turn refinement process as a Markov Decision Process and introduce DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement learning algorithm that trains an actor-critic LLM system to iteratively refine answers via direct preference learning on self-generated data. Theoretically, DPSDP can match the performance of any policy within the training distribution. Empirically, we instantiate DPSDP with various base models and show improvements on both in- and out-of-distribution benchmarks. For example, on benchmark MATH 500, majority voting over five refinement steps increases first-turn accuracy from 58.2% to 63.2% with Ministral-based models. An ablation study further confirms the benefits of multi-agent collaboration and out-of-distribution generalization.</li>
</ul>

<h3>Title: Network Threat Detection: Addressing Class Imbalanced Data with Deep Forest</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Chen, Rongbin Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08383">https://arxiv.org/abs/2506.08383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08383">https://arxiv.org/pdf/2506.08383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08383]] Network Threat Detection: Addressing Class Imbalanced Data with Deep Forest(https://arxiv.org/abs/2506.08383)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>With the rapid expansion of Internet of Things (IoT) networks, detecting malicious traffic in real-time has become a critical cybersecurity challenge. This research addresses the detection challenges by presenting a comprehensive empirical analysis of machine learning techniques for malware detection using the IoT-23 dataset provided by the Stratosphere Laboratory. We address the significant class imbalance within the dataset through three resampling strategies. We implement and compare a few machine learning techniques. Our findings demonstrate that the combination of appropriate imbalance treatment techniques with ensemble methods, particularly gcForest, achieves better detection performance compared to traditional approaches. This work contributes significantly to the development of more intelligent and efficient automated threat detection systems for IoT environments, helping to secure critical infrastructure against sophisticated cyber attacks while optimizing computational resource usage.</li>
</ul>

<h3>Title: mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks</h3>
<ul>
<li><strong>Authors: </strong>Luel Hagos Beyene, Vivek Verma, Min Ma, Jesujoba O. Alabi, Fabian David Schmidt, Joyce Nakatumba-Nabende, David Ifeoluwa Adelani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08400">https://arxiv.org/abs/2506.08400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08400">https://arxiv.org/pdf/2506.08400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08400]] mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks(https://arxiv.org/abs/2506.08400)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language models (LLMs) have demonstrated impressive performance on a wide range of tasks, including in multimodal settings such as speech. However, their evaluation is often limited to English and a few high-resource languages. For low-resource languages, there is no standardized evaluation benchmark. In this paper, we address this gap by introducing mSTEB, a new benchmark to evaluate the performance of LLMs on a wide range of tasks covering language identification, text classification, question answering, and translation tasks on both speech and text modalities. We evaluated the performance of leading LLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open models such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in performance between high-resource and low-resource languages, especially for languages spoken in Africa and Americas/Oceania. Our findings show that more investment is needed to address their under-representation in LLMs coverage.</li>
</ul>

<h3>Title: TACTIC: Translation Agents with Cognitive-Theoretic Interactive Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Weiya Li, Junjie Chen, Bei Li, Boyang Liu, Zichen Wen, Nuanqiao Shan, Xiaoqian Liu, Anping Liu, Huajie Liu, Youyan Wang, Wujiuge Yin, Hu Song, Bing Huang, Zhiyuan Xia, Jialiang Chen, Linfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08403">https://arxiv.org/abs/2506.08403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08403">https://arxiv.org/pdf/2506.08403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08403]] TACTIC: Translation Agents with Cognitive-Theoretic Interactive Collaboration(https://arxiv.org/abs/2506.08403)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Machine translation has long been a central task in natural language processing. With the rapid advancement of large language models (LLMs), there has been remarkable progress in translation quality. However, fully realizing the translation potential of LLMs remains an open challenge. Recent studies have explored multi-agent systems to decompose complex translation tasks into collaborative subtasks, showing initial promise in enhancing translation quality through agent cooperation and specialization. Nevertheless, existing multi-agent translation frameworks largely neglect foundational insights from cognitive translation studies. These insights emphasize how human translators employ different cognitive strategies, such as balancing literal and free translation, refining expressions based on context, and iteratively evaluating outputs. To address this limitation, we propose a cognitively informed multi-agent framework called TACTIC, which stands for T ranslation A gents with Cognitive- T heoretic Interactive Collaboration. The framework comprises six functionally distinct agents that mirror key cognitive processes observed in human translation behavior. These include agents for drafting, refinement, evaluation, scoring, context reasoning, and external knowledge gathering. By simulating an interactive and theory-grounded translation workflow, TACTIC effectively leverages the full capacity of LLMs for high-quality translation. Experimental results on diverse language pairs from the FLORES-200 and WMT24 benchmarks show that our method consistently achieves state-of-the-art performance. Using DeepSeek-V3 as the base model, TACTIC surpasses GPT-4.1 by an average of +0.6 XCOMET and +1.18 COMETKIWI-23. Compared to DeepSeek-R1, it further improves by +0.84 XCOMET and +2.99 COMETKIWI-23. Code is available at this https URL.</li>
</ul>

<h3>Title: Large Language Models Have Intrinsic Meta-Cognition, but Need a Good Lens</h3>
<ul>
<li><strong>Authors: </strong>Ziyang Ma, Qingyue Yuan, Zhenglin Wang, Deyu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08410">https://arxiv.org/abs/2506.08410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08410">https://arxiv.org/pdf/2506.08410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08410]] Large Language Models Have Intrinsic Meta-Cognition, but Need a Good Lens(https://arxiv.org/abs/2506.08410)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Previous research has primarily focused on the cognitive error detection capabilities of Large Language Models (LLMs), often prompting them to analyze mistakes in reasoning chains. However, few studies have examined the meta-cognitive abilities of LLMs (e.g., their self-awareness of step errors), which are crucial for their reliability. While studies on LLM self-evaluation present some measures, such as perplexity, which can reflect the answer correctness and be viewed as the lens of meta-cognition, they lack step-level analysis and adaptation. This paper studies the evaluation of LLM meta-cognition using the current lenses and how to improve these lenses. Specifically, we propose AutoMeco, an Automated Meta-cognition Evaluation framework for benchmarking the existing lenses. Furthermore, a training-free Markovian Intrinsic Reward Adjustment strategy, MIRA, is proposed to boost current meta-cognition lenses. Experimental results on three mathematical reasoning datasets and three LLMs show the reasonableness of AutoMeco by comparing it with Best-of-N verification. Moreover, the meta-cognition ability of LLMs can be better evaluated using MIRA.</li>
</ul>

<h3>Title: Learning to Hear Broken Motors: Signature-Guided Data Augmentation for Induction-Motor Diagnostics</h3>
<ul>
<li><strong>Authors: </strong>Saraa Ali, Aleksandr Khizhik, Stepan Svirin, Artem Ryzhikov, Denis Derkach</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08412">https://arxiv.org/abs/2506.08412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08412">https://arxiv.org/pdf/2506.08412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08412]] Learning to Hear Broken Motors: Signature-Guided Data Augmentation for Induction-Motor Diagnostics(https://arxiv.org/abs/2506.08412)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The application of machine learning (ML) algorithms in the intelligent diagnosis of three-phase engines has the potential to significantly enhance diagnostic performance and accuracy. Traditional methods largely rely on signature analysis, which, despite being a standard practice, can benefit from the integration of advanced ML techniques. In our study, we innovate by combining ML algorithms with a novel unsupervised anomaly generation methodology that takes into account the engine physics model. We propose Signature-Guided Data Augmentation (SGDA), an unsupervised framework that synthesizes physically plausible faults directly in the frequency domain of healthy current signals. Guided by Motor Current Signature Analysis, SGDA creates diverse and realistic anomalies without resorting to computationally intensive simulations. This hybrid approach leverages the strengths of both supervised ML and unsupervised signature analysis, achieving superior diagnostic accuracy and reliability along with wide industrial application. The findings highlight the potential of our approach to contribute significantly to the field of engine diagnostics, offering a robust and efficient solution for real-world applications.</li>
</ul>

<h3>Title: Improved Scaling Laws in Linear Regression via Data Reuse</h3>
<ul>
<li><strong>Authors: </strong>Licong Lin, Jingfeng Wu, Peter L. Bartlett</a></li>
<li><strong>Subjects: </strong>cs.LG, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08415">https://arxiv.org/abs/2506.08415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08415">https://arxiv.org/pdf/2506.08415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08415]] Improved Scaling Laws in Linear Regression via Data Reuse(https://arxiv.org/abs/2506.08415)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Neural scaling laws suggest that the test error of large language models trained online decreases polynomially as the model size and data size increase. However, such scaling can be unsustainable when running out of new data. In this work, we show that data reuse can improve existing scaling laws in linear regression. Specifically, we derive sharp test error bounds on $M$-dimensional linear models trained by multi-pass stochastic gradient descent (multi-pass SGD) on $N$ data with sketched features. Assuming that the data covariance has a power-law spectrum of degree $a$, and that the true parameter follows a prior with an aligned power-law spectrum of degree $b-a$ (with $a > b > 1$), we show that multi-pass SGD achieves a test error of $\Theta(M^{1-b} + L^{(1-b)/a})$, where $L \lesssim N^{a/b}$ is the number of iterations. In the same setting, one-pass SGD only attains a test error of $\Theta(M^{1-b} + N^{(1-b)/a})$ (see e.g., Lin et al., 2024). This suggests an improved scaling law via data reuse (i.e., choosing $L>N$) in data-constrained regimes. Numerical simulations are also provided to verify our theoretical findings.</li>
</ul>

<h3>Title: Online Learning-guided Learning Rate Adaptation via Gradient Alignment</h3>
<ul>
<li><strong>Authors: </strong>Ruichen Jiang, Ali Kavis, Aryan Mokhtari</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08419">https://arxiv.org/abs/2506.08419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08419">https://arxiv.org/pdf/2506.08419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08419]] Online Learning-guided Learning Rate Adaptation via Gradient Alignment(https://arxiv.org/abs/2506.08419)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The performance of an optimizer on large-scale deep learning models depends critically on fine-tuning the learning rate, often requiring an extensive grid search over base learning rates, schedules, and other hyperparameters. In this paper, we propose a principled framework called GALA (Gradient Alignment-based Learning rate Adaptation), which dynamically adjusts the learning rate by tracking the alignment between consecutive gradients and using a local curvature estimate. Guided by the convergence analysis, we formulate the problem of selecting the learning rate as a one-dimensional online learning problem. When paired with an online learning algorithm such as Follow-the-Regularized-Leader, our method produces a flexible, adaptive learning rate schedule that tends to increase when consecutive gradients are aligned and decrease otherwise. We establish a data-adaptive convergence rate for normalized SGD equipped with GALA in the smooth, nonconvex setting. Empirically, common optimizers such as SGD and Adam, when augmented with GALA, demonstrate robust performance across a wide range of initial learning rates and perform competitively without the need for tuning.</li>
</ul>

<h3>Title: HASFL: Heterogeneity-aware Split Federated Learning over Edge Computing Systems</h3>
<ul>
<li><strong>Authors: </strong>Zheng Lin, Zhe Chen, Xianhao Chen, Wei Ni, Yue Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08426">https://arxiv.org/abs/2506.08426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08426">https://arxiv.org/pdf/2506.08426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08426]] HASFL: Heterogeneity-aware Split Federated Learning over Edge Computing Systems(https://arxiv.org/abs/2506.08426)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Split federated learning (SFL) has emerged as a promising paradigm to democratize machine learning (ML) on edge devices by enabling layer-wise model partitioning. However, existing SFL approaches suffer significantly from the straggler effect due to the heterogeneous capabilities of edge devices. To address the fundamental challenge, we propose adaptively controlling batch sizes (BSs) and model splitting (MS) for edge devices to overcome resource heterogeneity. We first derive a tight convergence bound of SFL that quantifies the impact of varied BSs and MS on learning performance. Based on the convergence bound, we propose HASFL, a heterogeneity-aware SFL framework capable of adaptively controlling BS and MS to balance communication-computing latency and training convergence in heterogeneous edge networks. Extensive experiments with various datasets validate the effectiveness of HASFL and demonstrate its superiority over state-of-the-art benchmarks.</li>
</ul>

<h3>Title: Know-MRI: A Knowledge Mechanisms Revealer&Interpreter for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaxiang Liu, Boxuan Xing, Chenhao Yuan, Chenxiang Zhang, Di Wu, Xiusheng Huang, Haida Yu, Chuhan Lang, Pengfei Cao, Jun Zhao, Kang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08427">https://arxiv.org/abs/2506.08427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08427">https://arxiv.org/pdf/2506.08427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08427]] Know-MRI: A Knowledge Mechanisms Revealer&Interpreter for Large Language Models(https://arxiv.org/abs/2506.08427)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) continue to advance, there is a growing urgency to enhance the interpretability of their internal knowledge mechanisms. Consequently, many interpretation methods have emerged, aiming to unravel the knowledge mechanisms of LLMs from various perspectives. However, current interpretation methods differ in input data formats and interpreting outputs. The tools integrating these methods are only capable of supporting tasks with specific inputs, significantly constraining their practical applications. To address these challenges, we present an open-source Knowledge Mechanisms Revealer&Interpreter (Know-MRI) designed to analyze the knowledge mechanisms within LLMs systematically. Specifically, we have developed an extensible core module that can automatically match different input data with interpretation methods and consolidate the interpreting outputs. It enables users to freely choose appropriate interpretation methods based on the inputs, making it easier to comprehensively diagnose the model's internal knowledge mechanisms from multiple perspectives. Our code is available at this https URL. We also provide a demonstration video on this https URL.</li>
</ul>

<h3>Title: Better Reasoning with Less Data: Enhancing VLMs Through Unified Modality Scoring</h3>
<ul>
<li><strong>Authors: </strong>Mingjie Xu, Andrew Estornell, Hongzheng Yang, Yuzhi Zhao, Zhaowei Zhu, Qi Xuan, Jiaheng Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08429">https://arxiv.org/abs/2506.08429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08429">https://arxiv.org/pdf/2506.08429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08429]] Better Reasoning with Less Data: Enhancing VLMs Through Unified Modality Scoring(https://arxiv.org/abs/2506.08429)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The application of visual instruction tuning and other post-training techniques has significantly enhanced the capabilities of Large Language Models (LLMs) in visual understanding, enriching Vision-Language Models (VLMs) with more comprehensive visual language datasets. However, the effectiveness of VLMs is highly dependent on large-scale, high-quality datasets that ensure precise recognition and accurate reasoning. Two key challenges hinder progress: (1) noisy alignments between images and the corresponding text, which leads to misinterpretation, and (2) ambiguous or misleading text, which obscures visual content. To address these challenges, we propose SCALE (Single modality data quality and Cross modality Alignment Evaluation), a novel quality-driven data selection pipeline for VLM instruction tuning datasets. Specifically, SCALE integrates a cross-modality assessment framework that first assigns each data entry to its appropriate vision-language task, generates general and task-specific captions (covering scenes, objects, style, etc.), and evaluates the alignment, clarity, task rarity, text coherence, and image clarity of each entry based on the generated captions. We reveal that: (1) current unimodal quality assessment methods evaluate one modality while overlooking the rest, which can underestimate samples essential for specific tasks and discard the lower-quality instances that help build model robustness; and (2) appropriately generated image captions provide an efficient way to transfer the image-text multimodal task into a unified text modality.</li>
</ul>

<h3>Title: CAF-I: A Collaborative Multi-Agent Framework for Enhanced Irony Detection with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ziqi.Liu, Ziyang.Zhou, Mingxuan.Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08430">https://arxiv.org/abs/2506.08430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08430">https://arxiv.org/pdf/2506.08430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08430]] CAF-I: A Collaborative Multi-Agent Framework for Enhanced Irony Detection with Large Language Models(https://arxiv.org/abs/2506.08430)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) have become mainstream methods in the field of sarcasm detection. However, existing LLM methods face challenges in irony detection, including: 1. single-perspective limitations, 2. insufficient comprehensive understanding, and 3. lack of interpretability. This paper introduces the Collaborative Agent Framework for Irony (CAF-I), an LLM-driven multi-agent system designed to overcome these issues. CAF-I employs specialized agents for Context, Semantics, and Rhetoric, which perform multidimensional analysis and engage in interactive collaborative optimization. A Decision Agent then consolidates these perspectives, with a Refinement Evaluator Agent providing conditional feedback for optimization. Experiments on benchmark datasets establish CAF-I's state-of-the-art zero-shot performance. Achieving SOTA on the vast majority of metrics, CAF-I reaches an average Macro-F1 of 76.31, a 4.98 absolute improvement over the strongest prior baseline. This success is attained by its effective simulation of human-like multi-perspective analysis, enhancing detection accuracy and interpretability.</li>
</ul>

<h3>Title: Low-resource domain adaptation while minimizing energy and hardware resource consumption</h3>
<ul>
<li><strong>Authors: </strong>Hernán Maina, Nicolás Wolovick, Luciana Benotti</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08433">https://arxiv.org/abs/2506.08433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08433">https://arxiv.org/pdf/2506.08433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08433]] Low-resource domain adaptation while minimizing energy and hardware resource consumption(https://arxiv.org/abs/2506.08433)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training Large Language Models (LLMs) is costly in terms of energy, hardware, and annotated data, often resulting in a positionality rooted in predominant cultures and values (Santy et al., 2023). Domain adaptation has emerged as a promising strategy to better align models with diverse cultural and value contexts (Hershcovich et al., 2022), but its computational cost remains a significant barrier, particularly for research groups lacking access to large-scale infrastructure. In this paper, we evaluate how the use of different numerical precisions and data parallelization strategies impacts both training speed (as a proxy to energy and hardware consumption) and model accuracy, with the goal of facilitating domain adaptation in low-resource environments. Our findings are relevant to any setting where energy efficiency, accessibility, or limited hardware availability are key concerns.</li>
</ul>

<h3>Title: Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings</h3>
<ul>
<li><strong>Authors: </strong>Mingyuan Fan, Fuyi Wang, Cen Chen, Jianying Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08435">https://arxiv.org/abs/2506.08435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08435">https://arxiv.org/pdf/2506.08435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08435]] Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings(https://arxiv.org/abs/2506.08435)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) enables collaborative model training among multiple clients without the need to expose raw data. Its ability to safeguard privacy, at the heart of FL, has recently been a hot-button debate topic. To elaborate, several studies have introduced a type of attacks known as gradient leakage attacks (GLAs), which exploit the gradients shared during training to reconstruct clients' raw data. On the flip side, some literature, however, contends no substantial privacy risk in practical FL environments due to the effectiveness of such GLAs being limited to overly relaxed conditions, such as small batch sizes and knowledge of clients' data distributions. This paper bridges this critical gap by empirically demonstrating that clients' data can still be effectively reconstructed, even within realistic FL environments. Upon revisiting GLAs, we recognize that their performance failures stem from their inability to handle the gradient matching problem. To alleviate the performance bottlenecks identified above, we develop FedLeak, which introduces two novel techniques, partial gradient matching and gradient regularization. Moreover, to evaluate the performance of FedLeak in real-world FL environments, we formulate a practical evaluation protocol grounded in a thorough review of extensive FL literature and industry practices. Under this protocol, FedLeak can still achieve high-fidelity data reconstruction, thereby underscoring the significant vulnerability in FL systems and the urgent need for more effective defense methods.</li>
</ul>

<h3>Title: Olica: Efficient Structured Pruning of Large Language Models without Retraining</h3>
<ul>
<li><strong>Authors: </strong>Jiujun He, Huazhen Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08436">https://arxiv.org/abs/2506.08436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08436">https://arxiv.org/pdf/2506.08436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08436]] Olica: Efficient Structured Pruning of Large Language Models without Retraining(https://arxiv.org/abs/2506.08436)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Most existing structured pruning methods for Large Language Models (LLMs) require substantial computational and data resources for retraining to reestablish the corrupted correlations, making them prohibitively expensive. To address this, we propose a pruning framework for LLMs called Orthogonal decomposition and Linear Calibration (Olica), which eliminates the need for retraining. A key observation is that the multi-head attention (MHA) layer depends on two types of matrix products. By treating these matrix products as unified entities and applying principal component analysis (PCA), we extract the most important information to compress LLMs without sacrificing accuracy or disrupting their original structure. Consequently, retraining becomes unnecessary. A fast decomposition method is devised, reducing the complexity of PCA by a factor of the square of the number of attention heads. Additionally, to mitigate error accumulation problem caused by pruning the feed-forward network (FFN) layer, we introduce a linear calibration method to reconstruct the residual errors of pruned layers using low-rank matrices. By leveraging singular value decomposition (SVD) on the solution of the least-squares problem, these matrices are obtained without requiring retraining. Extensive experiments show that the proposed Olica is efficient in terms of data usage, GPU memory, and running time, while delivering superior performance across multiple benchmarks.</li>
</ul>

<h3>Title: Learning to Lead: Incentivizing Strategic Agents in the Dark</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Wu, Xinyi Zhong, Zhuoran Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08438">https://arxiv.org/abs/2506.08438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08438">https://arxiv.org/pdf/2506.08438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08438]] Learning to Lead: Incentivizing Strategic Agents in the Dark(https://arxiv.org/abs/2506.08438)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study an online learning version of the generalized principal-agent model, where a principal interacts repeatedly with a strategic agent possessing private types, private rewards, and taking unobservable actions. The agent is non-myopic, optimizing a discounted sum of future rewards and may strategically misreport types to manipulate the principal's learning. The principal, observing only her own realized rewards and the agent's reported types, aims to learn an optimal coordination mechanism that minimizes strategic regret. We develop the first provably sample-efficient algorithm for this challenging setting. Our approach features a novel pipeline that combines (i) a delaying mechanism to incentivize approximately myopic agent behavior, (ii) an innovative reward angle estimation framework that uses sector tests and a matching procedure to recover type-dependent reward functions, and (iii) a pessimistic-optimistic LinUCB algorithm that enables the principal to explore efficiently while respecting the agent's incentive constraints. We establish a near optimal $\tilde{O}(\sqrt{T}) $ regret bound for learning the principal's optimal policy, where $\tilde{O}(\cdot) $ omits logarithmic factors. Our results open up new avenues for designing robust online learning algorithms for a wide range of game-theoretic settings involving private types and strategic agents.</li>
</ul>

<h3>Title: GPS Spoofing Attacks on AI-based Navigation Systems with Obstacle Avoidance in UAV</h3>
<ul>
<li><strong>Authors: </strong>Ji Hyuk Jung, Mi Yeon Hong, Ji Won Yoon</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08445">https://arxiv.org/abs/2506.08445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08445">https://arxiv.org/pdf/2506.08445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08445]] GPS Spoofing Attacks on AI-based Navigation Systems with Obstacle Avoidance in UAV(https://arxiv.org/abs/2506.08445)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Recently, approaches using Deep Reinforcement Learning (DRL) have been proposed to solve UAV navigation systems in complex and unknown environments. However, despite extensive research and attention, systematic studies on various security aspects have not yet been conducted. Therefore, in this paper, we conduct research on security vulnerabilities in DRL-based navigation systems, particularly focusing on GPS spoofing attacks against the system. Many recent basic DRL-based navigation systems fundamentally share an efficient structure. This paper presents an attack model that operates through GPS spoofing attacks briefly modeling the range of spoofing attack against EKF sensor fusion of PX4 autopilot, and combine this with the DRL-based system to design attack scenarios that are closer to reality. Finally, this paper experimentally demonstrated that attacks are possible both in the basic DRL system and in attack models combining the DRL system with PX4 autopilot system.</li>
</ul>

<h3>Title: MAC: An Efficient Gradient Preconditioning using Mean Activation Approximated Curvature</h3>
<ul>
<li><strong>Authors: </strong>Hyunseok Seung, Jaewoo Lee, Hyunsuk Ko</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08464">https://arxiv.org/abs/2506.08464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08464">https://arxiv.org/pdf/2506.08464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08464]] MAC: An Efficient Gradient Preconditioning using Mean Activation Approximated Curvature(https://arxiv.org/abs/2506.08464)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Second-order optimization methods for training neural networks, such as KFAC, exhibit superior convergence by utilizing curvature information of loss landscape. However, it comes at the expense of high computational burden. In this work, we analyze the two components that constitute the layer-wise Fisher information matrix (FIM) used in KFAC: the Kronecker factors related to activations and pre-activation gradients. Based on empirical observations on their eigenspectra, we propose efficient approximations for them, resulting in a computationally efficient optimization method called MAC. To the best of our knowledge, MAC is the first algorithm to apply the Kronecker factorization to the FIM of attention layers used in transformers and explicitly integrate attention scores into the preconditioning. We also study the convergence property of MAC on nonlinear neural networks and provide two conditions under which it converges to global minima. Our extensive evaluations on various network architectures and datasets show that the proposed method outperforms KFAC and other state-of-the-art methods in terms of accuracy, end-to-end training time, and memory usage. Code is available at this https URL.</li>
</ul>

<h3>Title: MARMOT: Masked Autoencoder for Modeling Transient Imaging</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Shen, Ziheng Wang, Xingyue Peng, Suan Xia, Ruiqian Li, Shiying Li, Jingyi Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08470">https://arxiv.org/abs/2506.08470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08470">https://arxiv.org/pdf/2506.08470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08470]] MARMOT: Masked Autoencoder for Modeling Transient Imaging(https://arxiv.org/abs/2506.08470)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Pretrained models have demonstrated impressive success in many modalities such as language and vision. Recent works facilitate the pretraining paradigm in imaging research. Transients are a novel modality, which are captured for an object as photon counts versus arrival times using a precisely time-resolved sensor. In particular for non-line-of-sight (NLOS) scenarios, transients of hidden objects are measured beyond the sensor's direct line of sight. Using NLOS transients, the majority of previous works optimize volume density or surfaces to reconstruct the hidden objects and do not transfer priors learned from datasets. In this work, we present a masked autoencoder for modeling transient imaging, or MARMOT, to facilitate NLOS applications. Our MARMOT is a self-supervised model pretrianed on massive and diverse NLOS transient datasets. Using a Transformer-based encoder-decoder, MARMOT learns features from partially masked transients via a scanning pattern mask (SPM), where the unmasked subset is functionally equivalent to arbitrary sampling, and predicts full measurements. Pretrained on TransVerse-a synthesized transient dataset of 500K 3D models-MARMOT adapts to downstream imaging tasks using direct feature transfer or decoder finetuning. Comprehensive experiments are carried out in comparisons with state-of-the-art methods. Quantitative and qualitative results demonstrate the efficiency of our MARMOT.</li>
</ul>

<h3>Title: AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin</h3>
<ul>
<li><strong>Authors: </strong>Shuo Yang, Qihui Zhang, Yuyang Liu, Yue Huang, Xiaojun Jia, Kunpeng Ning, Jiayu Yao, Jigang Wang, Hailiang Dai, Yibing Song, Li Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08473">https://arxiv.org/abs/2506.08473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08473">https://arxiv.org/pdf/2506.08473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08473]] AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin(https://arxiv.org/abs/2506.08473)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are vulnerable to safety risks during fine-tuning, where small amounts of malicious or harmless data can compromise safeguards. In this paper, building on the concept of alignment direction -- defined by the weight difference between aligned and unaligned models -- we observe that perturbations along this direction preserve model safety. In contrast, perturbations along directions orthogonal to this alignment are strongly linked to harmful direction perturbations, rapidly degrading safety and framing the parameter space as a narrow safety basin. Based on this insight, we propose a methodology for safety fine-tuning called AsFT (Anchoring Safety in Fine-Tuning), which integrates a regularization term into the training objective. This term uses the alignment direction as an anchor to suppress updates in harmful directions, ensuring that fine-tuning is constrained within the narrow safety basin. Extensive experiments on multiple datasets show that AsFT outperforms Safe LoRA, reducing harmful behavior by 7.60 percent, improving model performance by 3.44 percent, and maintaining robust performance across various experimental settings. Code is available at this https URL</li>
</ul>

<h3>Title: Detecting Harmful Memes with Decoupled Understanding and Guided CoT Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Fengjun Pan, Anh Tuan Luu, Xiaobao Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08477">https://arxiv.org/abs/2506.08477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08477">https://arxiv.org/pdf/2506.08477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08477]] Detecting Harmful Memes with Decoupled Understanding and Guided CoT Reasoning(https://arxiv.org/abs/2506.08477)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Detecting harmful memes is essential for maintaining the integrity of online environments. However, current approaches often struggle with resource efficiency, flexibility, or explainability, limiting their practical deployment in content moderation systems. To address these challenges, we introduce U-CoT+, a novel framework for harmful meme detection. Instead of relying solely on prompting or fine-tuning multimodal models, we first develop a high-fidelity meme-to-text pipeline that converts visual memes into detail-preserving textual descriptions. This design decouples meme interpretation from meme classification, thus avoiding immediate reasoning over complex raw visual content and enabling resource-efficient harmful meme detection with general large language models (LLMs). Building on these textual descriptions, we further incorporate targeted, interpretable human-crafted guidelines to guide models' reasoning under zero-shot CoT prompting. As such, this framework allows for easy adaptation to different harmfulness detection criteria across platforms, regions, and over time, offering high flexibility and explainability. Extensive experiments on seven benchmark datasets validate the effectiveness of our framework, highlighting its potential for explainable and low-resource harmful meme detection using small-scale LLMs. Codes and data are available at: this https URL.</li>
</ul>

<h3>Title: One Patch to Rule Them All: Transforming Static Patches into Dynamic Attacks in the Physical World</h3>
<ul>
<li><strong>Authors: </strong>Xingshuo Han, Chen Ling, Shiyi Yao, Haozhao Wang, Hangcheng Liu, Yutong Wu, Shengmin Xu, Changhai Ou, Xinyi Huang, Tianwei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08482">https://arxiv.org/abs/2506.08482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08482">https://arxiv.org/pdf/2506.08482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08482]] One Patch to Rule Them All: Transforming Static Patches into Dynamic Attacks in the Physical World(https://arxiv.org/abs/2506.08482)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Numerous methods have been proposed to generate physical adversarial patches (PAPs) against real-world machine learning systems. However, each existing PAP typically supports only a single, fixed attack goal, and switching to a different objective requires re-generating and re-deploying a new PAP. This rigidity limits their practicality in dynamic environments like autonomous driving, where traffic conditions and attack goals can change rapidly. For example, if no obstacles are present around the target vehicle, the attack may fail to cause meaningful consequences. To overcome this limitation, we propose SwitchPatch, a novel PAP that is static yet enables dynamic and controllable attack outcomes based on real-time scenarios. Attackers can alter pre-defined conditions, e.g., by projecting different natural-color lights onto SwitchPatch to seamlessly switch between attack goals. Unlike prior work, SwitchPatch does not require re-generation or re-deployment for different objectives, significantly reducing cost and complexity. Furthermore, SwitchPatch remains benign when the enabling conditions are absent, enhancing its stealth. We evaluate SwitchPatch on two key tasks: traffic sign recognition (classification and detection) and depth estimation. First, we conduct theoretical analysis and empirical studies to demonstrate the feasibility of SwitchPatch and explore how many goals it can support using techniques like color light projection and occlusion. Second, we perform simulation-based experiments and ablation studies to verify its effectiveness and transferability. Third, we conduct outdoor tests using a Unmanned Ground Vehicle (UGV) to confirm its robustness in the physical world. Overall, SwitchPatch introduces a flexible and practical adversarial strategy that can be adapted to diverse tasks and real-world conditions.</li>
</ul>

<h3>Title: Fairness is Not Silence: Unmasking Vacuous Neutrality in Small Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sumanth Manduru, Carlotta Domeniconi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08487">https://arxiv.org/abs/2506.08487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08487">https://arxiv.org/pdf/2506.08487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08487]] Fairness is Not Silence: Unmasking Vacuous Neutrality in Small Language Models(https://arxiv.org/abs/2506.08487)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The rapid adoption of Small Language Models (SLMs) for on-device and resource-constrained deployments has outpaced our understanding of their ethical risks. To the best of our knowledge, we present the first large-scale audit of instruction-tuned SLMs spanning 0.5 to 5 billion parameters-an overlooked "middle tier" between BERT-class encoders and flagship LLMs. Our evaluation includes nine open-source models from the Qwen 2.5, LLaMA 3.2, Gemma 3, and Phi families. Using the BBQ benchmark under zero-shot prompting, we analyze both utility and fairness across ambiguous and disambiguated contexts. This evaluation reveals three key insights. First, competence and fairness need not be antagonistic: Phi models achieve F1 scores exceeding 90 percent while exhibiting minimal bias, showing that efficient and ethical NLP is attainable. Second, social bias varies significantly by architecture: Qwen 2.5 models may appear fair, but this often reflects vacuous neutrality, random guessing, or evasive behavior rather than genuine ethical alignment. In contrast, LLaMA 3.2 models exhibit stronger stereotypical bias, suggesting overconfidence rather than neutrality. Third, compression introduces nuanced trade-offs: 4-bit AWQ quantization improves F1 scores in ambiguous settings for LLaMA 3.2-3B but increases disability-related bias in Phi-4-Mini by over 7 percentage points. These insights provide practical guidance for the responsible deployment of SLMs in applications demanding fairness and efficiency, particularly benefiting small enterprises and resource-constrained environments.</li>
</ul>

<h3>Title: DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs</h3>
<ul>
<li><strong>Authors: </strong>Arie Cattan, Alon Jacovi, Ori Ram, Jonathan Herzig, Roee Aharoni, Sasha Goldshtein, Eran Ofek, Idan Szpektor, Avi Caciularu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08500">https://arxiv.org/abs/2506.08500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08500">https://arxiv.org/pdf/2506.08500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08500]] DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs(https://arxiv.org/abs/2506.08500)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) is a commonly used approach for enhancing large language models (LLMs) with relevant and up-to-date information. However, the retrieved sources can often contain conflicting information and it remains unclear how models should address such discrepancies. In this work, we first propose a novel taxonomy of knowledge conflict types in RAG, along with the desired model behavior for each type. We then introduce CONFLICTS, a high-quality benchmark with expert annotations of conflict types in a realistic RAG setting. CONFLICTS is the first benchmark that enables tracking progress on how models address a wide range of knowledge conflicts. We conduct extensive experiments on this benchmark, showing that LLMs often struggle to appropriately resolve conflicts between sources. While prompting LLMs to explicitly reason about the potential conflict in the retrieved documents significantly improves the quality and appropriateness of their responses, substantial room for improvement in future research remains.</li>
</ul>

<h3>Title: Explaining, Fast and Slow: Abstraction and Refinement of Provable Explanations</h3>
<ul>
<li><strong>Authors: </strong>Shahaf Bassan, Yizhak Yisrael Elboher, Tobias Ladner, Matthias Althoff, Guy Katz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08505">https://arxiv.org/abs/2506.08505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08505">https://arxiv.org/pdf/2506.08505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08505]] Explaining, Fast and Slow: Abstraction and Refinement of Provable Explanations(https://arxiv.org/abs/2506.08505)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Despite significant advancements in post-hoc explainability techniques for neural networks, many current methods rely on heuristics and do not provide formally provable guarantees over the explanations provided. Recent work has shown that it is possible to obtain explanations with formal guarantees by identifying subsets of input features that are sufficient to determine that predictions remain unchanged using neural network verification techniques. Despite the appeal of these explanations, their computation faces significant scalability challenges. In this work, we address this gap by proposing a novel abstraction-refinement technique for efficiently computing provably sufficient explanations of neural network predictions. Our method abstracts the original large neural network by constructing a substantially reduced network, where a sufficient explanation of the reduced network is also provably sufficient for the original network, hence significantly speeding up the verification process. If the explanation is in sufficient on the reduced network, we iteratively refine the network size by gradually increasing it until convergence. Our experiments demonstrate that our approach enhances the efficiency of obtaining provably sufficient explanations for neural network predictions while additionally providing a fine-grained interpretation of the network's predictions across different abstraction levels.</li>
</ul>

<h3>Title: MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding</h3>
<ul>
<li><strong>Authors: </strong>Zhiyi Zhu, Xiaoyu Wu, Zihao Liu, Linlin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08512">https://arxiv.org/abs/2506.08512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08512">https://arxiv.org/pdf/2506.08512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08512]] MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding(https://arxiv.org/abs/2506.08512)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Video Temporal Grounding (VTG), which aims to localize video clips corresponding to natural language queries, is a fundamental yet challenging task in video understanding. Existing Transformer-based methods often suffer from redundant attention and suboptimal multi-modal alignment. To address these limitations, we propose MLVTG, a novel framework that integrates two key modules: MambaAligner and LLMRefiner. MambaAligner uses stacked Vision Mamba blocks as a backbone instead of Transformers to model temporal dependencies and extract robust video representations for multi-modal alignment. LLMRefiner leverages the specific frozen layer of a pre-trained Large Language Model (LLM) to implicitly transfer semantic priors, enhancing multi-modal alignment without fine-tuning. This dual alignment strategy, temporal modeling via structured state-space dynamics and semantic purification via textual priors, enables more precise localization. Extensive experiments on QVHighlights, Charades-STA, and TVSum demonstrate that MLVTG achieves state-of-the-art performance and significantly outperforms existing baselines.</li>
</ul>

<h3>Title: DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training</h3>
<ul>
<li><strong>Authors: </strong>Jacob Piland, Chris Sweet, Adam Czakja</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08514">https://arxiv.org/abs/2506.08514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08514">https://arxiv.org/pdf/2506.08514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08514]] DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training(https://arxiv.org/abs/2506.08514)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Class Activation Mapping (CAM) and its gradient-based variants (e.g., GradCAM) have become standard tools for explaining Convolutional Neural Network (CNN) predictions. However, these approaches typically focus on individual logits, while for neural networks using softmax, the class membership probability estimates depend \textit{only} on the \textit{differences} between logits, not on their absolute values. This disconnect leaves standard CAMs vulnerable to adversarial manipulation, such as passive fooling, where a model is trained to produce misleading CAMs without affecting decision performance. We introduce \textbf{Salience-Hoax Activation Maps (SHAMs)}, an \emph{entropy-aware form of passive fooling} that serves as a benchmark for CAM robustness under adversarial conditions. To address the passive fooling vulnerability, we then propose \textbf{DiffGradCAM}, a novel, lightweight, and contrastive approach to class activation mapping that is both non-suceptible to passive fooling, but also matches the output of standard CAM methods such as GradCAM in the non-adversarial case. Together, SHAM and DiffGradCAM establish a new framework for probing and improving the robustness of saliency-based explanations. We validate both contributions across multi-class tasks with few and many classes.</li>
</ul>

<h3>Title: NeurIPS 2024 ML4CFD Competition: Results and Retrospective Analysis</h3>
<ul>
<li><strong>Authors: </strong>Mouadh Yagoubi, David Danan, Milad Leyli-Abadi, Ahmed Mazari, Jean-Patrick Brunet, Abbas Kabalan, Fabien Casenave, Yuxin Ma, Giovanni Catalani, Jean Fesquet, Jacob Helwig, Xuan Zhang, Haiyang Yu, Xavier Bertrand, Frederic Tost, Michael Baurheim, Joseph Morlier, Shuiwang Ji</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08516">https://arxiv.org/abs/2506.08516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08516">https://arxiv.org/pdf/2506.08516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08516]] NeurIPS 2024 ML4CFD Competition: Results and Retrospective Analysis(https://arxiv.org/abs/2506.08516)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The integration of machine learning (ML) into the physical sciences is reshaping computational paradigms, offering the potential to accelerate demanding simulations such as computational fluid dynamics (CFD). Yet, persistent challenges in accuracy, generalization, and physical consistency hinder the practical deployment of ML models in scientific domains. To address these limitations and systematically benchmark progress, we organized the ML4CFD competition, centered on surrogate modeling for aerodynamic simulations over two-dimensional airfoils. The competition attracted over 240 teams, who were provided with a curated dataset generated via OpenFOAM and evaluated through a multi-criteria framework encompassing predictive accuracy, physical fidelity, computational efficiency, and out-of-distribution generalization. This retrospective analysis reviews the competition outcomes, highlighting several approaches that outperformed baselines under our global evaluation score. Notably, the top entry exceeded the performance of the original OpenFOAM solver on aggregate metrics, illustrating the promise of ML-based surrogates to outperform traditional solvers under tailored criteria. Drawing from these results, we analyze the key design principles of top submissions, assess the robustness of our evaluation framework, and offer guidance for future scientific ML challenges.</li>
</ul>

<h3>Title: Robust Visual Localization via Semantic-Guided Multi-Scale Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zhongtao Tian, Wenhao Huang, Zhidong Chen, Xiao Wei Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08526">https://arxiv.org/abs/2506.08526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08526">https://arxiv.org/pdf/2506.08526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08526]] Robust Visual Localization via Semantic-Guided Multi-Scale Transformer(https://arxiv.org/abs/2506.08526)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Visual localization remains challenging in dynamic environments where fluctuating lighting, adverse weather, and moving objects disrupt appearance cues. Despite advances in feature representation, current absolute pose regression methods struggle to maintain consistency under varying conditions. To address this challenge, we propose a framework that synergistically combines multi-scale feature learning with semantic scene understanding. Our approach employs a hierarchical Transformer with cross-scale attention to fuse geometric details and contextual cues, preserving spatial precision while adapting to environmental changes. We improve the performance of this architecture with semantic supervision via neural scene representation during training, guiding the network to learn view-invariant features that encode persistent structural information while suppressing complex environmental interference. Experiments on TartanAir demonstrate that our approach outperforms existing pose regression methods in challenging scenarios with dynamic objects, illumination changes, and occlusions. Our findings show that integrating multi-scale processing with semantic guidance offers a promising strategy for robust visual localization in real-world dynamic environments.</li>
</ul>

<h3>Title: LiftVSR: Lifting Image Diffusion to Video Super-Resolution via Hybrid Temporal Modeling with Only 4$\times$RTX 4090s</h3>
<ul>
<li><strong>Authors: </strong>Xijun Wang, Xin Li, Bingchen Li, Zhibo Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08529">https://arxiv.org/abs/2506.08529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08529">https://arxiv.org/pdf/2506.08529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08529]] LiftVSR: Lifting Image Diffusion to Video Super-Resolution via Hybrid Temporal Modeling with Only 4$\times$RTX 4090s(https://arxiv.org/abs/2506.08529)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have significantly advanced video super-resolution (VSR) by enhancing perceptual quality, largely through elaborately designed temporal modeling to ensure inter-frame consistency. However, existing methods usually suffer from limited temporal coherence and prohibitively high computational costs (e.g., typically requiring over 8 NVIDIA A100-80G GPUs), especially for long videos. In this work, we propose LiftVSR, an efficient VSR framework that leverages and elevates the image-wise diffusion prior from PixArt-$\alpha$, achieving state-of-the-art results using only 4$\times$RTX 4090 GPUs. To balance long-term consistency and efficiency, we introduce a hybrid temporal modeling mechanism that decomposes temporal learning into two complementary components: (i) Dynamic Temporal Attention (DTA) for fine-grained temporal modeling within short frame segment ($\textit{i.e.}$, low complexity), and (ii) Attention Memory Cache (AMC) for long-term temporal modeling across segments ($\textit{i.e.}$, consistency). Specifically, DTA identifies multiple token flows across frames within multi-head query and key tokens to warp inter-frame contexts in the value tokens. AMC adaptively aggregates historical segment information via a cache unit, ensuring long-term coherence with minimal overhead. To further stabilize the cache interaction during inference, we introduce an asymmetric sampling strategy that mitigates feature mismatches arising from different diffusion sampling steps. Extensive experiments on several typical VSR benchmarks have demonstrated that LiftVSR achieves impressive performance with significantly lower computational costs.</li>
</ul>

<h3>Title: Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)</h3>
<ul>
<li><strong>Authors: </strong>Nihal Acharya Adde, Alexandra Gianzina, Hanno Gottschalk, Andreas Ebert</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08533">https://arxiv.org/abs/2506.08533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08533">https://arxiv.org/pdf/2506.08533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08533]] Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)(https://arxiv.org/abs/2506.08533)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces Evolutionary Multi-Objective Network Architecture Search (EMNAS) for the first time to optimize neural network architectures in large-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS uses genetic algorithms to automate network design, tailored to enhance rewards and reduce model size without compromising performance. Additionally, parallelization techniques are employed to accelerate the search, and teacher-student methodologies are implemented to ensure scalable optimization. This research underscores the potential of transfer learning as a robust framework for optimizing performance across iterative learning processes by effectively leveraging knowledge from earlier generations to enhance learning efficiency and stability in subsequent generations. Experimental results demonstrate that tailored EMNAS outperforms manually designed models, achieving higher rewards with fewer parameters. The findings of these strategies contribute positively to EMNAS for RL in autonomous driving, advancing the field toward better-performing networks suitable for real-world scenarios.</li>
</ul>

<h3>Title: TrajFlow: Multi-modal Motion Prediction via Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Qi Yan, Brian Zhang, Yutong Zhang, Daniel Yang, Joshua White, Di Chen, Jiachao Liu, Langechuan Liu, Binnan Zhuang, Shaoshuai Shi, Renjie Liao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08541">https://arxiv.org/abs/2506.08541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08541">https://arxiv.org/pdf/2506.08541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08541]] TrajFlow: Multi-modal Motion Prediction via Flow Matching(https://arxiv.org/abs/2506.08541)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Efficient and accurate motion prediction is crucial for ensuring safety and informed decision-making in autonomous driving, particularly under dynamic real-world conditions that necessitate multi-modal forecasts. We introduce TrajFlow, a novel flow matching-based motion prediction framework that addresses the scalability and efficiency challenges of existing generative trajectory prediction methods. Unlike conventional generative approaches that employ i.i.d. sampling and require multiple inference passes to capture diverse outcomes, TrajFlow predicts multiple plausible future trajectories in a single pass, significantly reducing computational overhead while maintaining coherence across predictions. Moreover, we propose a ranking loss based on the Plackett-Luce distribution to improve uncertainty estimation of predicted trajectories. Additionally, we design a self-conditioning training technique that reuses the model's own predictions to construct noisy inputs during a second forward pass, thereby improving generalization and accelerating inference. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across various key metrics, underscoring its effectiveness for safety-critical autonomous driving applications. The code and other details are available on the project website this https URL.</li>
</ul>

<h3>Title: Convergence of Spectral Principal Paths: How Deep Networks Distill Linear Representations from Noisy Inputs</h3>
<ul>
<li><strong>Authors: </strong>Bowei Tian, Xuntao Lyu, Meng Liu, Hongyi Wang, Ang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08543">https://arxiv.org/abs/2506.08543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08543">https://arxiv.org/pdf/2506.08543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08543]] Convergence of Spectral Principal Paths: How Deep Networks Distill Linear Representations from Noisy Inputs(https://arxiv.org/abs/2506.08543)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>High-level representations have become a central focus in enhancing AI transparency and control, shifting attention from individual neurons or circuits to structured semantic directions that align with human-interpretable concepts. Motivated by the Linear Representation Hypothesis (LRH), we propose the Input-Space Linearity Hypothesis (ISLH), which posits that concept-aligned directions originate in the input space and are selectively amplified with increasing depth. We then introduce the Spectral Principal Path (SPP) framework, which formalizes how deep networks progressively distill linear representations along a small set of dominant spectral directions. Building on this framework, we further demonstrate the multimodal robustness of these representations in Vision-Language Models (VLMs). By bridging theoretical insights with empirical validation, this work advances a structured theory of representation formation in deep networks, paving the way for improving AI robustness, fairness, and transparency.</li>
</ul>

<h3>Title: DeepForm: Reasoning Large Language Model for Communication System Formulation</h3>
<ul>
<li><strong>Authors: </strong>Panlong Wu, Ting Wang, Yifei Zhong, Haoqi Zhang, Zitong Wang, Fangxin Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08551">https://arxiv.org/abs/2506.08551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08551">https://arxiv.org/pdf/2506.08551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08551]] DeepForm: Reasoning Large Language Model for Communication System Formulation(https://arxiv.org/abs/2506.08551)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Communication system formulation is critical for advancing 6G and future wireless technologies, yet it remains a complex, expertise-intensive task. While Large Language Models (LLMs) offer potential, existing general-purpose models often lack the specialized domain knowledge, nuanced reasoning capabilities, and access to high-quality, domain-specific training data required for adapting a general LLM into an LLM specially for communication system formulation. To bridge this gap, we introduce DeepForm, the first reasoning LLM specially for automated communication system formulation. We propose the world-first large-scale, open-source dataset meticulously curated for this domain called Communication System Formulation Reasoning Corpus (CSFRC). Our framework employs a two-stage training strategy: first, Supervised Fine-Tuning (SFT) with Chain-of-Thought (CoT) data to distill domain knowledge; second, a novel rule-based Reinforcement Learning (RL) algorithm, C-ReMax based on ReMax, to cultivate advanced modeling capabilities and elicit sophisticated reasoning patterns like self-correction and verification. Extensive experiments demonstrate that our model achieves state-of-the-art performance, significantly outperforming larger proprietary LLMs on diverse senerios. We will release related resources to foster further research in this area after the paper is accepted.</li>
</ul>

<h3>Title: Efficient Post-Training Refinement of Latent Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xinyuan Wang, Dongjie Wang, Wangyang Ying, Haoyue Bai, Nanxu Gong, Sixun Dong, Kunpeng Liu, Yanjie Fu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08552">https://arxiv.org/abs/2506.08552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08552">https://arxiv.org/pdf/2506.08552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08552]] Efficient Post-Training Refinement of Latent Reasoning in Large Language Models(https://arxiv.org/abs/2506.08552)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning is a key component of language understanding in Large Language Models. While Chain-of-Thought prompting enhances performance via explicit intermediate steps, it suffers from sufficient token overhead and a fixed reasoning trajectory, preventing step-wise refinement. Recent advances in latent reasoning address these limitations by refining internal reasoning processes directly in the model's latent space, without producing explicit outputs. However, a key challenge remains: how to effectively update reasoning embeddings during post-training to guide the model toward more accurate solutions. To overcome this challenge, we propose a lightweight post-training framework that refines latent reasoning trajectories using two novel strategies: 1) Contrastive reasoning feedback, which compares reasoning embeddings against strong and weak baselines to infer effective update directions via embedding enhancement; 2) Residual embedding refinement, which stabilizes updates by progressively integrating current and historical gradients, enabling fast yet controlled convergence. Extensive experiments and case studies are conducted on five reasoning benchmarks to demonstrate the effectiveness of the proposed framework. Notably, a 5\% accuracy gain on MathQA without additional training.</li>
</ul>

<h3>Title: From Pixels to Graphs: using Scene and Knowledge Graphs for HD-EPIC VQA Challenge</h3>
<ul>
<li><strong>Authors: </strong>Agnese Taluzzi, Davide Gesualdi, Riccardo Santambrogio, Chiara Plizzari, Francesca Palermo, Simone Mentasti, Matteo Matteucci</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08553">https://arxiv.org/abs/2506.08553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08553">https://arxiv.org/pdf/2506.08553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08553]] From Pixels to Graphs: using Scene and Knowledge Graphs for HD-EPIC VQA Challenge(https://arxiv.org/abs/2506.08553)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This report presents SceneNet and KnowledgeNet, our approaches developed for the HD-EPIC VQA Challenge 2025. SceneNet leverages scene graphs generated with a multi-modal large language model (MLLM) to capture fine-grained object interactions, spatial relationships, and temporally grounded events. In parallel, KnowledgeNet incorporates ConceptNet's external commonsense knowledge to introduce high-level semantic connections between entities, enabling reasoning beyond directly observable visual evidence. Each method demonstrates distinct strengths across the seven categories of the HD-EPIC benchmark, and their combination within our framework results in an overall accuracy of 44.21% on the challenge, highlighting its effectiveness for complex egocentric VQA tasks.</li>
</ul>

<h3>Title: Towards Cross-Subject EMG Pattern Recognition via Dual-Branch Adversarial Feature Disentanglement</h3>
<ul>
<li><strong>Authors: </strong>Xinyue Niu, Akira Furui</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08555">https://arxiv.org/abs/2506.08555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08555">https://arxiv.org/pdf/2506.08555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08555]] Towards Cross-Subject EMG Pattern Recognition via Dual-Branch Adversarial Feature Disentanglement(https://arxiv.org/abs/2506.08555)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric</a></li>
<li><strong>Abstract: </strong>Cross-subject electromyography (EMG) pattern recognition faces significant challenges due to inter-subject variability in muscle anatomy, electrode placement, and signal characteristics. Traditional methods rely on subject-specific calibration data to adapt models to new users, an approach that is both time-consuming and impractical for large-scale, real-world deployment. This paper presents an approach to eliminate calibration requirements through feature disentanglement, enabling effective cross-subject generalization. We propose an end-to-end dual-branch adversarial neural network that simultaneously performs pattern recognition and individual identification by disentangling EMG features into pattern-specific and subject-specific components. The pattern-specific components facilitate robust pattern recognition for new users without model calibration, while the subject-specific components enable downstream applications such as task-invariant biometric identification. Experimental results demonstrate that the proposed model achieves robust performance on data from unseen users, outperforming various baseline methods in cross-subject scenarios. Overall, this study offers a new perspective for cross-subject EMG pattern recognition without model calibration and highlights the proposed model's potential for broader applications, such as task-independent biometric systems.</li>
</ul>

<h3>Title: Hierarchical Neural Collapse Detection Transformer for Class Incremental Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Duc Thanh Pham, Hong Dang Nguyen, Nhat Minh Nguyen Quoc, Linh Ngo Van, Sang Dinh Viet, Duc Anh Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08562">https://arxiv.org/abs/2506.08562</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08562">https://arxiv.org/pdf/2506.08562</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08562]] Hierarchical Neural Collapse Detection Transformer for Class Incremental Object Detection(https://arxiv.org/abs/2506.08562)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recently, object detection models have witnessed notable performance improvements, particularly with transformer-based models. However, new objects frequently appear in the real world, requiring detection models to continually learn without suffering from catastrophic forgetting. Although Incremental Object Detection (IOD) has emerged to address this challenge, these existing models are still not practical due to their limited performance and prolonged inference time. In this paper, we introduce a novel framework for IOD, called Hier-DETR: Hierarchical Neural Collapse Detection Transformer, ensuring both efficiency and competitive performance by leveraging Neural Collapse for imbalance dataset and Hierarchical relation of classes' labels.</li>
</ul>

<h3>Title: Generating Vision-Language Navigation Instructions Incorporated Fine-Grained Alignment Annotations</h3>
<ul>
<li><strong>Authors: </strong>Yibo Cui, Liang Xie, Yu Zhao, Jiawei Sun, Erwei Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08566">https://arxiv.org/abs/2506.08566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08566">https://arxiv.org/pdf/2506.08566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08566]] Generating Vision-Language Navigation Instructions Incorporated Fine-Grained Alignment Annotations(https://arxiv.org/abs/2506.08566)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vision-Language Navigation (VLN) enables intelligent agents to navigate environments by integrating visual perception and natural language instructions, yet faces significant challenges due to the scarcity of fine-grained cross-modal alignment annotations. Existing datasets primarily focus on global instruction-trajectory matching, neglecting sub-instruction-level and entity-level alignments critical for accurate navigation action decision-making. To address this limitation, we propose FCA-NIG, a generative framework that automatically constructs navigation instructions with dual-level fine-grained cross-modal annotations. In this framework, an augmented trajectory is first divided into sub-trajectories, which are then processed through GLIP-based landmark detection, crafted instruction construction, OFA-Speaker based R2R-like instruction generation, and CLIP-powered entity selection, generating sub-instruction-trajectory pairs with entity-landmark annotations. Finally, these sub-pairs are aggregated to form a complete instruction-trajectory pair. The framework generates the FCA-R2R dataset, the first large-scale augmentation dataset featuring precise sub-instruction-sub-trajectory and entity-landmark alignments. Extensive experiments demonstrate that training with FCA-R2R significantly improves the performance of multiple state-of-the-art VLN agents, including SF, EnvDrop, RecBERT, and HAMT. Incorporating sub-instruction-trajectory alignment enhances agents' state awareness and decision accuracy, while entity-landmark alignment further boosts navigation performance and generalization. These results highlight the effectiveness of FCA-NIG in generating high-quality, scalable training data without manual annotation, advancing fine-grained cross-modal learning in complex navigation tasks.</li>
</ul>

<h3>Title: The Geometries of Truth Are Orthogonal Across Tasks</h3>
<ul>
<li><strong>Authors: </strong>Waiss Azizian, Michael Kirchhof, Eugene Ndiaye, Louis Bethune, Michal Klein, Pierre Ablin, Marco Cuturi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08572">https://arxiv.org/abs/2506.08572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08572">https://arxiv.org/pdf/2506.08572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08572]] The Geometries of Truth Are Orthogonal Across Tasks(https://arxiv.org/abs/2506.08572)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive generalization capabilities across various tasks, but their claim to practical relevance is still mired by concerns on their reliability. Recent works have proposed examining the activations produced by an LLM at inference time to assess whether its answer to a question is correct. Some works claim that a "geometry of truth" can be learned from examples, in the sense that the activations that generate correct answers can be distinguished from those leading to mistakes with a linear classifier. In this work, we underline a limitation of these approaches: we observe that these "geometries of truth" are intrinsically task-dependent and fail to transfer across tasks. More precisely, we show that linear classifiers trained across distinct tasks share little similarity and, when trained with sparsity-enforcing regularizers, have almost disjoint supports. We show that more sophisticated approaches (e.g., using mixtures of probes and tasks) fail to overcome this limitation, likely because activation vectors commonly used to classify answers form clearly separated clusters when examined across tasks.</li>
</ul>

<h3>Title: SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models</h3>
<ul>
<li><strong>Authors: </strong>Alvise Dei Rossi, Matteo Metaldi, Michal Bechny, Irina Filchenko, Julia van der Meer, Markus H. Schmidt, Claudio L.A. Bassetti, Athina Tzovara, Francesca D. Faraci, Luigi Fiorillo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08574">https://arxiv.org/abs/2506.08574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08574">https://arxiv.org/pdf/2506.08574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08574]] SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models(https://arxiv.org/abs/2506.08574)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Despite advances in deep learning for automatic sleep staging, clinical adoption remains limited due to challenges in fair model evaluation, generalization across diverse datasets, model bias, and variability in human annotations. We present SLEEPYLAND, an open-source sleep staging evaluation framework designed to address these barriers. It includes more than 22'0000 hours in-domain (ID) sleep recordings, and more than 84'000 hours out-of-domain (OOD) sleep recordings, spanning a broad range of ages, sleep-wake disorders, and hardware setups. We release pre-trained models based on high-performing SoA architectures and evaluate them under standardized conditions across single- and multi-channel EEG/EOG configurations. We introduce SOMNUS, an ensemble combining models across architectures and channel setups via soft voting. SOMNUS achieves robust performance across twenty-four different datasets, with macro-F1 scores between 68.7% and 87.2%, outperforming individual models in 94.9% of cases. Notably, SOMNUS surpasses previous SoA methods, even including cases where compared models were trained ID while SOMNUS treated the same data as OOD. Using a subset of the BSWR (N=6'633), we quantify model biases linked to age, gender, AHI, and PLMI, showing that while ensemble improves robustness, no model architecture consistently minimizes bias in performance and clinical markers estimation. In evaluations on OOD multi-annotated datasets (DOD-H, DOD-O), SOMNUS exceeds the best human scorer, i.e., MF1 85.2% vs 80.8% on DOD-H, and 80.2% vs 75.9% on DOD-O, better reproducing the scorer consensus than any individual expert (k = 0.89/0.85 and ACS = 0.95/0.94 for healthy/OSA cohorts). Finally, we introduce ensemble disagreement metrics - entropy and inter-model divergence based - predicting regions of scorer disagreement with ROC AUCs up to 0.828, offering a data-driven proxy for human uncertainty.</li>
</ul>

<h3>Title: Diffusion-based Time Series Forecasting for Sewerage Systems</h3>
<ul>
<li><strong>Authors: </strong>Nicholas A. Pearson, Francesca Cairoli, Luca Bortolussi, Davide Russo, Francesca Zanello</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08577">https://arxiv.org/abs/2506.08577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08577">https://arxiv.org/pdf/2506.08577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08577]] Diffusion-based Time Series Forecasting for Sewerage Systems(https://arxiv.org/abs/2506.08577)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce a novel deep learning approach that harnesses the power of generative artificial intelligence to enhance the accuracy of contextual forecasting in sewerage systems. By developing a diffusion-based model that processes multivariate time series data, our system excels at capturing complex correlations across diverse environmental signals, enabling robust predictions even during extreme weather events. To strengthen the model's reliability, we further calibrate its predictions with a conformal inference technique, tailored for probabilistic time series data, ensuring that the resulting prediction intervals are statistically reliable and cover the true target values with a desired confidence level. Our empirical tests on real sewerage system data confirm the model's exceptional capability to deliver reliable contextual predictions, maintaining accuracy even under severe weather conditions.</li>
</ul>

<h3>Title: CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmark of Large Language Models in Mental Health Counseling</h3>
<ul>
<li><strong>Authors: </strong>Yahan Li, Jifan Yao, John Bosco S. Bunyi, Adam C. Frank, Angel Hwang, Ruishan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08584">https://arxiv.org/abs/2506.08584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08584">https://arxiv.org/pdf/2506.08584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08584]] CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmark of Large Language Models in Mental Health Counseling(https://arxiv.org/abs/2506.08584)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly proposed for use in mental health support, yet their behavior in realistic counseling scenarios remains largely untested. We introduce CounselBench, a large-scale benchmark developed with 100 mental health professionals to evaluate and stress-test LLMs in single-turn counseling. The first component, CounselBench-EVAL, contains 2,000 expert evaluations of responses from GPT-4, LLaMA 3, Gemini, and online human therapists to real patient questions. Each response is rated along six clinically grounded dimensions, with written rationales and span-level annotations. We find that LLMs often outperform online human therapists in perceived quality, but experts frequently flag their outputs for safety concerns such as unauthorized medical advice. Follow-up experiments show that LLM judges consistently overrate model responses and overlook safety issues identified by human experts. To probe failure modes more directly, we construct CounselBench-Adv, an adversarial dataset of 120 expert-authored counseling questions designed to trigger specific model issues. Evaluation across 2,880 responses from eight LLMs reveals consistent, model-specific failure patterns. Together, CounselBench establishes a clinically grounded framework for benchmarking and improving LLM behavior in high-stakes mental health settings.</li>
</ul>

<h3>Title: Diversity-Guided MLP Reduction for Efficient Large Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Chengchao Shen, Hourun Zhu, Gongfan Fang, Jianxin Wang, Xinchao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08591">https://arxiv.org/abs/2506.08591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08591">https://arxiv.org/pdf/2506.08591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08591]] Diversity-Guided MLP Reduction for Efficient Large Vision Transformers(https://arxiv.org/abs/2506.08591)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer models achieve excellent scaling property, where the performance is improved with the increment of model capacity. However, large-scale model parameters lead to an unaffordable cost of computing and memory. We analyze popular transformer architectures and find that multilayer perceptron (MLP) modules take up the majority of model parameters. To this end, we focus on the recoverability of the compressed models and propose a Diversity-Guided MLP Reduction (DGMR) method to significantly reduce the parameters of large vision transformers with only negligible performance degradation. Specifically, we conduct a Gram-Schmidt weight pruning strategy to eliminate redundant neurons of MLP hidden layer, while preserving weight diversity for better performance recover during distillation. Compared to the model trained from scratch, our pruned model only requires 0.06\% data of LAION-2B (for the training of large vision transformers) without labels (ImageNet-1K) to recover the original performance. Experimental results on several state-of-the-art large vision transformers demonstrate that our method achieves a more than 57.0\% parameter and FLOPs reduction in a near lossless manner. Notably, for EVA-CLIP-E (4.4B), our method accomplishes a 71.5\% parameter and FLOPs reduction without performance degradation. The source code and trained weights are available at this https URL.</li>
</ul>

<h3>Title: Hateful Person or Hateful Model? Investigating the Role of Personas in Hate Speech Detection by Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shuzhou Yuan, Ercong Nie, Mario Tawfelis, Helmut Schmid, Hinrich Schütze, Michael Färber</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08593">https://arxiv.org/abs/2506.08593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08593">https://arxiv.org/pdf/2506.08593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08593]] Hateful Person or Hateful Model? Investigating the Role of Personas in Hate Speech Detection by Large Language Models(https://arxiv.org/abs/2506.08593)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Hate speech detection is a socially sensitive and inherently subjective task, with judgments often varying based on personal traits. While prior work has examined how socio-demographic factors influence annotation, the impact of personality traits on Large Language Models (LLMs) remains largely unexplored. In this paper, we present the first comprehensive study on the role of persona prompts in hate speech classification, focusing on MBTI-based traits. A human annotation survey confirms that MBTI dimensions significantly affect labeling behavior. Extending this to LLMs, we prompt four open-source models with MBTI personas and evaluate their outputs across three hate speech datasets. Our analysis uncovers substantial persona-driven variation, including inconsistencies with ground truth, inter-persona disagreement, and logit-level biases. These findings highlight the need to carefully define persona prompts in LLM-based annotation workflows, with implications for fairness and alignment with human values.</li>
</ul>

<h3>Title: Transformers Meet Hyperspectral Imaging: A Comprehensive Study of Models, Challenges and Open Problems</h3>
<ul>
<li><strong>Authors: </strong>Guyang Zhang, Waleed Abdulla</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08596">https://arxiv.org/abs/2506.08596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08596">https://arxiv.org/pdf/2506.08596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08596]] Transformers Meet Hyperspectral Imaging: A Comprehensive Study of Models, Challenges and Open Problems(https://arxiv.org/abs/2506.08596)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, explainability, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have become the architecture of choice for learning long-range dependencies, yet their adoption in hyperspectral imaging (HSI) is still emerging. We reviewed more than 300 papers published up to 2025 and present the first end-to-end survey dedicated to Transformer-based HSI classification. The study categorizes every stage of a typical pipeline-pre-processing, patch or pixel tokenization, positional encoding, spatial-spectral feature extraction, multi-head self-attention variants, skip connections, and loss design-and contrasts alternative design choices with the unique spatial-spectral properties of HSI. We map the field's progress against persistent obstacles: scarce labeled data, extreme spectral dimensionality, computational overhead, and limited model explainability. Finally, we outline a research agenda prioritizing valuable public data sets, lightweight on-edge models, illumination and sensor shifts robustness, and intrinsically interpretable attention mechanisms. Our goal is to guide researchers in selecting, combining, or extending Transformer components that are truly fit for purpose for next-generation HSI applications.</li>
</ul>

<h3>Title: CALT: A Library for Computer Algebra with Transformer</h3>
<ul>
<li><strong>Authors: </strong>Hiroshi Kera, Shun Arakawa, Yuta Sato</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SC, math.AC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08600">https://arxiv.org/abs/2506.08600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08600">https://arxiv.org/pdf/2506.08600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08600]] CALT: A Library for Computer Algebra with Transformer(https://arxiv.org/abs/2506.08600)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in artificial intelligence have demonstrated the learnability of symbolic computation through end-to-end deep learning. Given a sufficient number of examples of symbolic expressions before and after the target computation, Transformer models - highly effective learners of sequence-to-sequence functions - can be trained to emulate the computation. This development opens up several intriguing challenges and new research directions, which require active contributions from the symbolic computation community. In this work, we introduce Computer Algebra with Transformer (CALT), a user-friendly Python library designed to help non-experts in deep learning train models for symbolic computation tasks.</li>
</ul>

<h3>Title: WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Tingzhi Li, Xuefeng Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08602">https://arxiv.org/abs/2506.08602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08602">https://arxiv.org/pdf/2506.08602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08602]] WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks(https://arxiv.org/abs/2506.08602)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) are increasingly deployed in graph-related applications, making ownership verification critical to protect their intellectual property against model theft. Fingerprinting and black-box watermarking are two main methods. However, the former relies on determining model similarity, which is computationally expensive and prone to ownership collisions after model post-processing such as model pruning or fine-tuning. The latter embeds backdoors, exposing watermarked models to the risk of backdoor attacks. Moreover, both methods enable ownership verification but do not convey additional information. As a result, each distributed model requires a unique trigger graph, and all trigger graphs must be used to query the suspect model during verification. Multiple queries increase the financial cost and the risk of detection. To address these challenges, this paper proposes WGLE, a novel black-box watermarking paradigm for GNNs that enables embedding the multi-bit string as the ownership information without using backdoors. WGLE builds on a key insight we term Layer-wise Distance Difference on an Edge (LDDE), which quantifies the difference between the feature distance and the prediction distance of two connected nodes. By predefining positive or negative LDDE values for multiple selected edges, WGLE embeds the watermark encoding the intended information without introducing incorrect mappings that compromise the primary task. WGLE is evaluated on six public datasets and six mainstream GNN architectures along with state-of-the-art methods. The results show that WGLE achieves 100% ownership verification accuracy, an average fidelity degradation of 0.85%, comparable robustness against potential attacks, and low embedding overhead. The code is available in the repository.</li>
</ul>

<h3>Title: Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation</h3>
<ul>
<li><strong>Authors: </strong>Giacomo Baldan, Qiang Liu, Alberto Guardone, Nils Thuerey</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08604">https://arxiv.org/abs/2506.08604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08604">https://arxiv.org/pdf/2506.08604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08604]] Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation(https://arxiv.org/abs/2506.08604)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative machine learning methods, such as diffusion models and flow matching, have shown great potential in modeling complex system behaviors and building efficient surrogate models. However, these methods typically learn the underlying physics implicitly from data. We propose Physics-Based Flow Matching (PBFM), a novel generative framework that explicitly embeds physical constraints, both PDE residuals and algebraic relations, into the flow matching objective. We also introduce temporal unrolling at training time that improves the accuracy of the final, noise-free sample prediction. Our method jointly minimizes the flow matching loss and the physics-based residual loss without requiring hyperparameter tuning of their relative weights. Additionally, we analyze the role of the minimum noise level, $\sigma_{\min}$, in the context of physical constraints and evaluate a stochastic sampling strategy that helps to reduce physical residuals. Through extensive benchmarks on three representative PDE problems, we show that our approach yields up to an $8\times$ more accurate physical residuals compared to FM, while clearly outperforming existing algorithms in terms of distributional accuracy. PBFM thus provides a principled and efficient framework for surrogate modeling, uncertainty quantification, and accelerated simulation in physics and engineering applications.</li>
</ul>

<h3>Title: Towards Class-wise Fair Adversarial Training via Anti-Bias Soft Label Distillation</h3>
<ul>
<li><strong>Authors: </strong>Shiji Zhao, Chi Chen, Ranjie Duan, Xizhe Wang, Xingxing Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08611">https://arxiv.org/abs/2506.08611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08611">https://arxiv.org/pdf/2506.08611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08611]] Towards Class-wise Fair Adversarial Training via Anti-Bias Soft Label Distillation(https://arxiv.org/abs/2506.08611)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Adversarial Training (AT) is widely recognized as an effective approach to enhance the adversarial robustness of Deep Neural Networks. As a variant of AT, Adversarial Robustness Distillation (ARD) has shown outstanding performance in enhancing the robustness of small models. However, both AT and ARD face robust fairness issue: these models tend to display strong adversarial robustness against some classes (easy classes) while demonstrating weak adversarial robustness against others (hard classes). This paper explores the underlying factors of this problem and points out the smoothness degree of soft labels for different classes significantly impacts the robust fairness from both empirical observation and theoretical analysis. Based on the above exploration, we propose Anti-Bias Soft Label Distillation (ABSLD) within the Knowledge Distillation framework to enhance the adversarial robust fairness. Specifically, ABSLD adaptively reduces the student's error risk gap between different classes, which is accomplished by adjusting the class-wise smoothness degree of teacher's soft labels during the training process, and the adjustment is managed by assigning varying temperatures to different classes. Additionally, as a label-based approach, ABSLD is highly adaptable and can be integrated with the sample-based methods. Extensive experiments demonstrate ABSLD outperforms state-of-the-art methods on the comprehensive performance of robustness and fairness.</li>
</ul>

<h3>Title: Data-Efficient Challenges in Visual Inductive Priors: A Retrospective</h3>
<ul>
<li><strong>Authors: </strong>Robert-Jan Bruintjes, Attila Lengyel, Osman Semih Kayhan, Davide Zambrano, Nergis Tömen, Hadi Jamali-Rad, Jan van Gemert</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08612">https://arxiv.org/abs/2506.08612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08612">https://arxiv.org/pdf/2506.08612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08612]] Data-Efficient Challenges in Visual Inductive Priors: A Retrospective(https://arxiv.org/abs/2506.08612)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep Learning requires large amounts of data to train models that work well. In data-deficient settings, performance can be degraded. We investigate which Deep Learning methods benefit training models in a data-deficient setting, by organizing the "VIPriors: Visual Inductive Priors for Data-Efficient Deep Learning" workshop series, featuring four editions of data-impaired challenges. These challenges address the problem of training deep learning models for computer vision tasks with limited data. Participants are limited to training models from scratch using a low number of training samples and are not allowed to use any form of transfer learning. We aim to stimulate the development of novel approaches that incorporate prior knowledge to improve the data efficiency of deep learning models. Successful challenge entries make use of large model ensembles that mix Transformers and CNNs, as well as heavy data augmentation. Novel prior knowledge-based methods contribute to success in some entries.</li>
</ul>

<h3>Title: SAMSelect: A Spectral Index Search for Marine Debris Visualization using Segment Anything</h3>
<ul>
<li><strong>Authors: </strong>Joost van Dalen, Yuki M. Asano, Marc Russwurm</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08613">https://arxiv.org/abs/2506.08613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08613">https://arxiv.org/pdf/2506.08613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08613]] SAMSelect: A Spectral Index Search for Marine Debris Visualization using Segment Anything(https://arxiv.org/abs/2506.08613)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This work proposes SAMSelect, an algorithm to obtain a salient three-channel visualization for multispectral images. We develop SAMSelect and show its use for marine scientists visually interpreting floating marine debris in Sentinel-2 imagery. These debris are notoriously difficult to visualize due to their compositional heterogeneity in medium-resolution imagery. Out of these difficulties, a visual interpretation of imagery showing marine debris remains a common practice by domain experts, who select bands and spectral indices on a case-by-case basis informed by common practices and heuristics. SAMSelect selects the band or index combination that achieves the best classification accuracy on a small annotated dataset through the Segment Anything Model. Its central assumption is that the three-channel visualization achieves the most accurate segmentation results also provide good visual information for photo-interpretation. We evaluate SAMSelect in three Sentinel-2 scenes containing generic marine debris in Accra, Ghana, and Durban, South Africa, and deployed plastic targets from the Plastic Litter Project. This reveals the potential of new previously unused band combinations (e.g., a normalized difference index of B8, B2), which demonstrate improved performance compared to literature-based indices. We describe the algorithm in this paper and provide an open-source code repository that will be helpful for domain scientists doing visual photo interpretation, especially in the marine field.</li>
</ul>

<h3>Title: ECMNet:Lightweight Semantic Segmentation with Efficient CNN-Mamba Network</h3>
<ul>
<li><strong>Authors: </strong>Feixiang Du, Shengkun Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08629">https://arxiv.org/abs/2506.08629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08629">https://arxiv.org/pdf/2506.08629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08629]] ECMNet:Lightweight Semantic Segmentation with Efficient CNN-Mamba Network(https://arxiv.org/abs/2506.08629)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In the past decade, Convolutional Neural Networks (CNNs) and Transformers have achieved wide applicaiton in semantic segmentation tasks. Although CNNs with Transformer models greatly improve performance, the global context modeling remains inadequate. Recently, Mamba achieved great potential in vision tasks, showing its advantages in modeling long-range dependency. In this paper, we propose a lightweight Efficient CNN-Mamba Network for semantic segmentation, dubbed as ECMNet. ECMNet combines CNN with Mamba skillfully in a capsule-based framework to address their complementary weaknesses. Specifically, We design a Enhanced Dual-Attention Block (EDAB) for lightweight bottleneck. In order to improve the representations ability of feature, We devise a Multi-Scale Attention Unit (MSAU) to integrate multi-scale feature aggregation, spatial aggregation and channel aggregation. Moreover, a Mamba enhanced Feature Fusion Module (FFM) merges diverse level feature, significantly enhancing segmented accuracy. Extensive experiments on two representative datasets demonstrate that the proposed model excels in accuracy and efficiency balance, achieving 70.6% mIoU on Cityscapes and 73.6% mIoU on CamVid test datasets, with 0.87M parameters and 8.27G FLOPs on a single RTX 3090 GPU platform.</li>
</ul>

<h3>Title: RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping</h3>
<ul>
<li><strong>Authors: </strong>Yang Bai, Liudi Yang, George Eskandar, Fengyi Shen, Dong Chen, Mohammad Altillawi, Ziyuan Liu, Gitta Kutyniok</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08632">https://arxiv.org/abs/2506.08632</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08632">https://arxiv.org/pdf/2506.08632</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08632]] RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping(https://arxiv.org/abs/2506.08632)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in generative models have revolutionized video synthesis and editing. However, the scarcity of diverse, high-quality datasets continues to hinder video-conditioned robotic learning, limiting cross-platform generalization. In this work, we address the challenge of swapping a robotic arm in one video with another: a key step for crossembodiment learning. Unlike previous methods that depend on paired video demonstrations in the same environmental settings, our proposed framework, RoboSwap, operates on unpaired data from diverse environments, alleviating the data collection needs. RoboSwap introduces a novel video editing pipeline integrating both GANs and diffusion models, combining their isolated advantages. Specifically, we segment robotic arms from their backgrounds and train an unpaired GAN model to translate one robotic arm to another. The translated arm is blended with the original video background and refined with a diffusion model to enhance coherence, motion realism and object interaction. The GAN and diffusion stages are trained independently. Our experiments demonstrate that RoboSwap outperforms state-of-the-art video and image editing models on three benchmarks in terms of both structural coherence and motion consistency, thereby offering a robust solution for generating reliable, cross-embodiment data in robotic learning.</li>
</ul>

<h3>Title: SurfR: Surface Reconstruction with Multi-scale Attention</h3>
<ul>
<li><strong>Authors: </strong>Siddhant Ranade, Gonçalo Dias Pais, Ross Tyler Whitaker, Jacinto C. Nascimento, Pedro Miraldo, Srikumar Ramalingam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08635">https://arxiv.org/abs/2506.08635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08635">https://arxiv.org/pdf/2506.08635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08635]] SurfR: Surface Reconstruction with Multi-scale Attention(https://arxiv.org/abs/2506.08635)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>We propose a fast and accurate surface reconstruction algorithm for unorganized point clouds using an implicit representation. Recent learning methods are either single-object representations with small neural models that allow for high surface details but require per-object training or generalized representations that require larger models and generalize to newer shapes but lack details, and inference is slow. We propose a new implicit representation for general 3D shapes that is faster than all the baselines at their optimum resolution, with only a marginal loss in performance compared to the state-of-the-art. We achieve the best accuracy-speed trade-off using three key contributions. Many implicit methods extract features from the point cloud to classify whether a query point is inside or outside the object. First, to speed up the reconstruction, we show that this feature extraction does not need to use the query point at an early stage (lazy query). Second, we use a parallel multi-scale grid representation to develop robust features for different noise levels and input resolutions. Finally, we show that attention across scales can provide improved reconstruction results.</li>
</ul>

<h3>Title: Orientation Matters: Making 3D Generative Models Orientation-Aligned</h3>
<ul>
<li><strong>Authors: </strong>Yichong Lu, Yuzhuo Tian, Zijin Jiang, Yikun Zhao, Yuanbo Yang, Hao Ouyang, Haoji Hu, Huimin Yu, Yujun Shen, Yiyi Liao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08640">https://arxiv.org/abs/2506.08640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08640">https://arxiv.org/pdf/2506.08640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08640]] Orientation Matters: Making 3D Generative Models Orientation-Aligned(https://arxiv.org/abs/2506.08640)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Humans intuitively perceive object shape and orientation from a single image, guided by strong priors about canonical poses. However, existing 3D generative models often produce misaligned results due to inconsistent training data, limiting their usability in downstream tasks. To address this gap, we introduce the task of orientation-aligned 3D object generation: producing 3D objects from single images with consistent orientations across categories. To facilitate this, we construct Objaverse-OA, a dataset of 14,832 orientation-aligned 3D models spanning 1,008 categories. Leveraging Objaverse-OA, we fine-tune two representative 3D generative models based on multi-view diffusion and 3D variational autoencoder frameworks to produce aligned objects that generalize well to unseen objects across various categories. Experimental results demonstrate the superiority of our method over post-hoc alignment approaches. Furthermore, we showcase downstream applications enabled by our aligned object generation, including zero-shot object orientation estimation via analysis-by-synthesis and efficient arrow-based object rotation manipulation.</li>
</ul>

<h3>Title: Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Simon Roschmann, Quentin Bouniot, Vasilii Feofanov, Ievgen Redko, Zeynep Akata</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08641">https://arxiv.org/abs/2506.08641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08641">https://arxiv.org/pdf/2506.08641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08641]] Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers(https://arxiv.org/abs/2506.08641)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Time series classification is a fundamental task in healthcare and industry, yet the development of time series foundation models (TSFMs) remains limited by the scarcity of publicly available time series datasets. In this work, we propose Time Vision Transformer (TiViT), a framework that converts time series into images to leverage the representational power of frozen Vision Transformers (ViTs) pretrained on large-scale image datasets. First, we theoretically motivate our approach by analyzing the 2D patching of ViTs for time series, showing that it can increase the number of label-relevant tokens and reduce the sample complexity. Second, we empirically demonstrate that TiViT achieves state-of-the-art performance on standard time series classification benchmarks by utilizing the hidden representations of large OpenCLIP models. We explore the structure of TiViT representations and find that intermediate layers with high intrinsic dimension are the most effective for time series classification. Finally, we assess the alignment between TiViT and TSFM representation spaces and identify a strong complementarity, with further performance gains achieved by combining their features. Our findings reveal yet another direction for reusing vision representations in a non-visual domain.</li>
</ul>

<h3>Title: MEMETRON: Metaheuristic Mechanisms for Test-time Response Optimization of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Son The Nguyen, Theja Tulabandhula</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08643">https://arxiv.org/abs/2506.08643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08643">https://arxiv.org/pdf/2506.08643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08643]] MEMETRON: Metaheuristic Mechanisms for Test-time Response Optimization of Large Language Models(https://arxiv.org/abs/2506.08643)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used for both open-ended and structured tasks, yet their inference-time behavior is still largely dictated by heuristic decoding strategies such as greedy search, sampling, or reranking. These methods provide limited control and do not explicitly optimize for task-specific objectives. We introduce MEMETRON, a task-agnostic framework that formulates LLM decoding as a discrete black-box optimization problem. MEMETRON leverages hybrid metaheuristic algorithms, GENETRON and ANNETRON, to search the response space, guided by reward models and contextual operations performed by the LLM itself. This approach enables efficient discovery of high-reward responses without requiring model retraining or gradient access. The framework is modular and generalizes across diverse tasks, requiring only a reward function and lightweight prompt templates. We evaluate our framework on the critical human preference alignment task and demonstrate that it significantly outperforms standard decoding and reranking methods, highlighting its potential to improve alignment without model retraining.</li>
</ul>

<h3>Title: Summarization for Generative Relation Extraction in the Microbiome Domain</h3>
<ul>
<li><strong>Authors: </strong>Oumaima El Khettari, Solen Quiniou, Samuel Chaffron</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08647">https://arxiv.org/abs/2506.08647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08647">https://arxiv.org/pdf/2506.08647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08647]] Summarization for Generative Relation Extraction in the Microbiome Domain(https://arxiv.org/abs/2506.08647)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>We explore a generative relation extraction (RE) pipeline tailored to the study of interactions in the intestinal microbiome, a complex and low-resource biomedical domain. Our method leverages summarization with large language models (LLMs) to refine context before extracting relations via instruction-tuned generation. Preliminary results on a dedicated corpus show that summarization improves generative RE performance by reducing noise and guiding the model. However, BERT-based RE approaches still outperform generative models. This ongoing work demonstrates the potential of generative methods to support the study of specialized domains in low-resources setting.</li>
</ul>

<h3>Title: Beyond Calibration: Physically Informed Learning for Raw-to-Raw Mapping</h3>
<ul>
<li><strong>Authors: </strong>Peter Grönquist, Stepan Tulyakov, Dengxin Dai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08650">https://arxiv.org/abs/2506.08650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08650">https://arxiv.org/pdf/2506.08650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08650]] Beyond Calibration: Physically Informed Learning for Raw-to-Raw Mapping(https://arxiv.org/abs/2506.08650)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Achieving consistent color reproduction across multiple cameras is essential for seamless image fusion and Image Processing Pipeline (ISP) compatibility in modern devices, but it is a challenging task due to variations in sensors and optics. Existing raw-to-raw conversion methods face limitations such as poor adaptability to changing illumination, high computational costs, or impractical requirements such as simultaneous camera operation and overlapping fields-of-view. We introduce the Neural Physical Model (NPM), a lightweight, physically-informed approach that simulates raw images under specified illumination to estimate transformations between devices. The NPM effectively adapts to varying illumination conditions, can be initialized with physical measurements, and supports training with or without paired data. Experiments on public datasets like NUS and BeyondRGB demonstrate that NPM outperforms recent state-of-the-art methods, providing robust chromatic consistency across different sensors and optical systems.</li>
</ul>

<h3>Title: JoFormer (Journey-based Transformer): Theory and Empirical Analysis on the Tiny Shakespeare Dataset</h3>
<ul>
<li><strong>Authors: </strong>Mahesh Godavarti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08652">https://arxiv.org/abs/2506.08652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08652">https://arxiv.org/pdf/2506.08652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08652]] JoFormer (Journey-based Transformer): Theory and Empirical Analysis on the Tiny Shakespeare Dataset(https://arxiv.org/abs/2506.08652)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have demonstrated remarkable success in sequence modeling, yet effectively incorporating positional information remains a challenging and active area of research. In this paper, we introduce JoFormer, a journey-based Transformer architecture grounded in a recently proposed non-commutative algebra for composing transformations across positions. JoFormer represents relative positions through learnable directional transforms that are sequentially composed along the input, thereby extending and generalizing existing approaches based on relative position representations. We derive the JoFormer attention mechanism from first principles and show that it subsumes standard methods such as rotary transformations as special cases. To evaluate its effectiveness, we compare JoFormer to the RoFormer baseline on the Tiny Shakespeare character-level language modeling task. Our results demonstrate that JoFormer consistently achieves lower perplexity and faster convergence, highlighting the advantages of its more expressive, journey-based treatment of position. Notably, the per-token JoFormer is still a primitive, conceptual variant with layer-independent angles, yet it already demonstrates strong performance-underscoring its promise as a proof of concept for more expressive architectures. We conclude by discussing how JoFormer offers a principled approach to integrating positional structure into Transformer architectures. The code used in this work is available at this https URL.</li>
</ul>

<h3>Title: Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness</h3>
<ul>
<li><strong>Authors: </strong>Jinkwan Jang, Hyungjin Park, Jinmyeong Choi, Taesup Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08660">https://arxiv.org/abs/2506.08660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08660">https://arxiv.org/pdf/2506.08660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08660]] Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness(https://arxiv.org/abs/2506.08660)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Real-world time series data are inherently multivariate, often exhibiting complex inter-channel dependencies. Each channel is typically sampled at its own period and is prone to missing values due to various practical and operational constraints. These characteristics pose fundamental challenges related to channel dependency, sampling asynchrony, and missingness, all of which must be addressed to enable robust and reliable forecasting in practical settings. However, most existing architectures are built on oversimplified assumptions, such as identical sampling periods across channels and fully observed inputs at test time, which often do not hold in real-world scenarios. To bridge this gap, we propose ChannelTokenFormer, a Transformer-based forecasting model with a flexible architecture designed to explicitly capture cross-channel interactions, accommodate channel-wise asynchronous sampling, and effectively handle missing values. Extensive experiments on three benchmark datasets modified to reflect practical settings, along with one real-world industrial dataset, demonstrate the superior robustness and accuracy of ChannelTokenFormer under challenging real-world conditions.</li>
</ul>

<h3>Title: Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search</h3>
<ul>
<li><strong>Authors: </strong>Dongge Han, Menglin Xia, Daniel Madrigal Diaz, Samuel Kessler, Ankur Mallick, Xuchao Zhang, Mirian Del Carmen Hipolito Garcia, Jin Xu, Victor Rühle, Saravan Rajmohan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08669">https://arxiv.org/abs/2506.08669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08669">https://arxiv.org/pdf/2506.08669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08669]] Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search(https://arxiv.org/abs/2506.08669)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Small language models (SLMs) offer promising and efficient alternatives to large language models (LLMs). However, SLMs' limited capacity restricts their reasoning capabilities and makes them sensitive to prompt variations. To address these challenges, we propose a novel framework that enhances SLM reasoning capabilities through LLM generated blueprints. The blueprints provide structured, high-level reasoning guides that help SLMs systematically tackle related problems. Furthermore, our framework integrates a prompt template search mechanism to mitigate the SLMs' sensitivity to prompt variations. Our framework demonstrates improved SLM performance across various tasks, including math (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improves the reasoning capabilities of SLMs without increasing model size or requiring additional training, offering a lightweight and deployment-friendly solution for on-device or resource-constrained environments.</li>
</ul>

<h3>Title: RuleReasoner: Reinforced Rule-based Reasoning via Domain-aware Dynamic Sampling</h3>
<ul>
<li><strong>Authors: </strong>Yang Liu, Jiaqi Li, Zilong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08672">https://arxiv.org/abs/2506.08672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08672">https://arxiv.org/pdf/2506.08672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08672]] RuleReasoner: Reinforced Rule-based Reasoning via Domain-aware Dynamic Sampling(https://arxiv.org/abs/2506.08672)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Rule-based reasoning has been acknowledged as one of the fundamental problems in reasoning, while deviations in rule formats, types, and complexity in real-world applications pose severe challenges. Recent studies have shown that large reasoning models (LRMs) have remarkable reasoning capabilities, and their performance is substantially enhanced by reinforcement learning (RL). However, it remains an open question whether small reasoning models (SRMs) can learn rule-based reasoning effectively with robust generalization across diverse tasks and domains. To address this, we introduce Reinforced Rule-based Reasoning, a.k.a. RuleReasoner, a simple yet effective method to conduct rule-based reasoning via a wide collection of curated tasks and a novel domain-aware dynamic sampling approach. Specifically, RuleReasoner resamples each training batch by updating the sampling weights of different domains based on historical rewards. This facilitates domain augmentation and flexible online learning schedules for RL, obviating the need for pre-hoc human-engineered mix-training recipes used in existing methods. Empirical evaluations on in-distribution (ID) and out-of-distribution (OOD) benchmarks reveal that RuleReasoner outperforms frontier LRMs by a significant margin ($\Delta$4.1% average points on eight ID tasks and $\Delta$10.4% average points on three OOD tasks over OpenAI-o1). Notably, our approach also exhibits higher computational efficiency compared to prior dynamic sampling methods for RL.</li>
</ul>

<h3>Title: Towards Fair Representation: Clustering and Consensus</h3>
<ul>
<li><strong>Authors: </strong>Diptarka Chakraborty, Kushagra Chatterjee, Debarati Das, Tien Long Nguyen, Romina Nobahari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08673">https://arxiv.org/abs/2506.08673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08673">https://arxiv.org/pdf/2506.08673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08673]] Towards Fair Representation: Clustering and Consensus(https://arxiv.org/abs/2506.08673)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Consensus clustering, a fundamental task in machine learning and data analysis, aims to aggregate multiple input clusterings of a dataset, potentially based on different non-sensitive attributes, into a single clustering that best represents the collective structure of the data. In this work, we study this fundamental problem through the lens of fair clustering, as introduced by Chierichetti et al. [NeurIPS'17], which incorporates the disparate impact doctrine to ensure proportional representation of each protected group in the dataset within every cluster. Our objective is to find a consensus clustering that is not only representative but also fair with respect to specific protected attributes. To the best of our knowledge, we are the first to address this problem and provide a constant-factor approximation. As part of our investigation, we examine how to minimally modify an existing clustering to enforce fairness -- an essential postprocessing step in many clustering applications that require fair representation. We develop an optimal algorithm for datasets with equal group representation and near-linear time constant factor approximation algorithms for more general scenarios with different proportions of two group sizes. We complement our approximation result by showing that the problem is NP-hard for two unequal-sized groups. Given the fundamental nature of this problem, we believe our results on Closest Fair Clustering could have broader implications for other clustering problems, particularly those for which no prior approximation guarantees exist for their fair variants.</li>
</ul>

<h3>Title: ATAS: Any-to-Any Self-Distillation for Enhanced Open-Vocabulary Dense Prediction</h3>
<ul>
<li><strong>Authors: </strong>Juan Yeo, Soonwoo Cha, Jiwoo Song, Hyunbin Jin, Taesup Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08678">https://arxiv.org/abs/2506.08678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08678">https://arxiv.org/pdf/2506.08678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08678]] ATAS: Any-to-Any Self-Distillation for Enhanced Open-Vocabulary Dense Prediction(https://arxiv.org/abs/2506.08678)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Vision-language models such as CLIP have recently propelled open-vocabulary dense prediction tasks by enabling recognition of a broad range of visual concepts. However, CLIP still struggles with fine-grained, region-level understanding, hindering its effectiveness on these dense prediction tasks. We identify two pivotal factors required to address this limitation: semantic coherence and fine-grained vision-language alignment. Current adaptation methods often improve fine-grained alignment at the expense of semantic coherence, and often rely on extra modules or supervised fine-tuning. To overcome these issues, we propose Any-to-Any Self-Distillation (ATAS), a novel approach that simultaneously enhances semantic coherence and fine-grained alignment by leveraging own knowledge of a model across all representation levels. Unlike prior methods, ATAS uses only unlabeled images and an internal self-distillation process to refine representations of CLIP vision encoders, preserving local semantic consistency while sharpening local detail recognition. On open-vocabulary object detection and semantic segmentation benchmarks, ATAS achieves substantial performance gains, outperforming baseline CLIP models. These results validate the effectiveness of our approach and underscore the importance of jointly maintaining semantic coherence and fine-grained alignment for advanced open-vocabulary dense prediction.</li>
</ul>

<h3>Title: Mitigating Reward Over-optimization in Direct Alignment Algorithms with Importance Sampling</h3>
<ul>
<li><strong>Authors: </strong>Phuc Minh Nguyen, Ngoc-Hieu Nguyen, Duy H. M. Nguyen, Anji Liu, An Mai, Binh T. Nguyen, Daniel Sonntag, Khoa D. Doan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08681">https://arxiv.org/abs/2506.08681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08681">https://arxiv.org/pdf/2506.08681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08681]] Mitigating Reward Over-optimization in Direct Alignment Algorithms with Importance Sampling(https://arxiv.org/abs/2506.08681)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Direct Alignment Algorithms (DAAs) such as Direct Preference Optimization (DPO) have emerged as alternatives to the standard Reinforcement Learning from Human Feedback (RLHF) for aligning large language models (LLMs) with human values. However, these methods are more susceptible to over-optimization, in which the model drifts away from the reference policy, leading to degraded performance as training progresses. This paper proposes a novel importance-sampling approach to mitigate the over-optimization problem of offline DAAs. This approach, called (IS-DAAs), multiplies the DAA objective with an importance ratio that accounts for the reference policy distribution. IS-DAAs additionally avoid the high variance issue associated with importance sampling by clipping the importance ratio to a maximum value. Our extensive experiments demonstrate that IS-DAAs can effectively mitigate over-optimization, especially under low regularization strength, and achieve better performance than other methods designed to address this problem. Our implementations are provided publicly at this link.</li>
</ul>

<h3>Title: Brevity is the soul of sustainability: Characterizing LLM response lengths</h3>
<ul>
<li><strong>Authors: </strong>Soham Poddar, Paramita Koley, Janardan Misra, Sanjay Podder, Navveen Balani, Niloy Ganguly, Saptarshi Ghosh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08686">https://arxiv.org/abs/2506.08686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08686">https://arxiv.org/pdf/2506.08686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08686]] Brevity is the soul of sustainability: Characterizing LLM response lengths(https://arxiv.org/abs/2506.08686)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A significant portion of the energy consumed by Large Language Models (LLMs) arises from their inference processes; hence developing energy-efficient methods for inference is crucial. While several techniques exist for inference optimization, output compression remains relatively unexplored, with only a few preliminary efforts addressing this aspect. In this work, we first benchmark 12 decoder-only LLMs across 5 datasets, revealing that these models often produce responses that are substantially longer than necessary. We then conduct a comprehensive quality assessment of LLM responses, formally defining six information categories present in LLM responses. We show that LLMs often tend to include redundant or additional information besides the minimal answer. To address this issue of long responses by LLMs, we explore several simple and intuitive prompt-engineering strategies. Empirical evaluation shows that appropriate prompts targeting length reduction and controlling information content can achieve significant energy optimization between 25-60\% by reducing the response length while preserving the quality of LLM responses.</li>
</ul>

<h3>Title: VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Congzhi Zhang, Jiawei Peng, Zhenglin Wang, Yilong Lai, Haowen Sun, Heng Chang, Fei Ma, Weijiang Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08691">https://arxiv.org/abs/2506.08691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08691">https://arxiv.org/pdf/2506.08691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08691]] VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism(https://arxiv.org/abs/2506.08691)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) have shown exceptional performance in multimodal tasks, but their effectiveness in complex visual reasoning is still constrained, especially when employing Chain-of-Thought prompting techniques. In this paper, we propose VReST, a novel training-free approach that enhances Reasoning in LVLMs through Monte Carlo Tree Search and Self-Reward mechanisms. VReST meticulously traverses the reasoning landscape by establishing a search tree, where each node encapsulates a reasoning step, and each path delineates a comprehensive reasoning sequence. Our innovative multimodal Self-Reward mechanism assesses the quality of reasoning steps by integrating the utility of sub-questions, answer correctness, and the relevance of vision-language clues, all without the need for additional models. VReST surpasses current prompting methods and secures state-of-the-art performance across three multimodal mathematical reasoning benchmarks. Furthermore, it substantiates the efficacy of test-time scaling laws in multimodal tasks, offering a promising direction for future research.</li>
</ul>

<h3>Title: On the Ethics of Using LLMs for Offensive Security</h3>
<ul>
<li><strong>Authors: </strong>Andreas Happe, Jürgen Cito</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08693">https://arxiv.org/abs/2506.08693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08693">https://arxiv.org/pdf/2506.08693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08693]] On the Ethics of Using LLMs for Offensive Security(https://arxiv.org/abs/2506.08693)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have rapidly evolved over the past few years and are currently evaluated for their efficacy within the domain of offensive cyber-security. While initial forays showcase the potential of LLMs to enhance security research, they also raise critical ethical concerns regarding the dual-use of offensive security tooling. This paper analyzes a set of papers that leverage LLMs for offensive security, focusing on how ethical considerations are expressed and justified in their work. The goal is to assess the culture of AI in offensive security research regarding ethics communication, highlighting trends, best practices, and gaps in current discourse. We provide insights into how the academic community navigates the fine line between innovation and ethical responsibility. Particularly, our results show that 13 of 15 reviewed prototypes (86.6\%) mentioned ethical considerations and are thus aware of the potential dual-use of their research. Main motivation given for the research was allowing broader access to penetration-testing as well as preparing defenders for AI-guided attackers.</li>
</ul>

<h3>Title: MoSiC: Optimal-Transport Motion Trajectory for Dense Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Mohammadreza Salehi, Shashanka Venkataramanan, Ioana Simion, Efstratios Gavves, Cees G. M. Snoek, Yuki M Asano</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08694">https://arxiv.org/abs/2506.08694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08694">https://arxiv.org/pdf/2506.08694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08694]] MoSiC: Optimal-Transport Motion Trajectory for Dense Self-Supervised Learning(https://arxiv.org/abs/2506.08694)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Dense self-supervised learning has shown great promise for learning pixel- and patch-level representations, but extending it to videos remains challenging due to the complexity of motion dynamics. Existing approaches struggle as they rely on static augmentations that fail under object deformations, occlusions, and camera movement, leading to inconsistent feature learning over time. We propose a motion-guided self-supervised learning framework that clusters dense point tracks to learn spatiotemporally consistent representations. By leveraging an off-the-shelf point tracker, we extract long-range motion trajectories and optimize feature clustering through a momentum-encoder-based optimal transport mechanism. To ensure temporal coherence, we propagate cluster assignments along tracked points, enforcing feature consistency across views despite viewpoint changes. Integrating motion as an implicit supervisory signal, our method learns representations that generalize across frames, improving robustness in dynamic scenes and challenging occlusion scenarios. By initializing from strong image-pretrained models and leveraging video data for training, we improve state-of-the-art by 1% to 6% on six image and video datasets and four evaluation benchmarks. The implementation is publicly available at our GitHub repository: this https URL</li>
</ul>

<h3>Title: ArrowPose: Segmentation, Detection, and 5 DoF Pose Estimation Network for Colorless Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Frederik Hagelskjaer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08699">https://arxiv.org/abs/2506.08699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08699">https://arxiv.org/pdf/2506.08699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08699]] ArrowPose: Segmentation, Detection, and 5 DoF Pose Estimation Network for Colorless Point Clouds(https://arxiv.org/abs/2506.08699)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents a fast detection and 5 DoF (Degrees of Freedom) pose estimation network for colorless point clouds. The pose estimation is calculated from center and top points of the object, predicted by the neural network. The network is trained on synthetic data, and tested on a benchmark dataset, where it demonstrates state-of-the-art performance and outperforms all colorless methods. The network is able to run inference in only 250 milliseconds making it usable in many scenarios. Project page with code at this http URL</li>
</ul>

<h3>Title: ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification on Scientific Charts</h3>
<ul>
<li><strong>Authors: </strong>Ruiran Su, Jiasheng Si, Zhijiang Guo, Janet B. Pierrehumbert</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08700">https://arxiv.org/abs/2506.08700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08700">https://arxiv.org/pdf/2506.08700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08700]] ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification on Scientific Charts(https://arxiv.org/abs/2506.08700)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Scientific fact-checking has mostly focused on text and tables, overlooking scientific charts, which are key for presenting quantitative evidence and statistical reasoning. We introduce ClimateViz, the first large-scale benchmark for scientific fact-checking using expert-curated scientific charts. ClimateViz contains 49,862 claims linked to 2,896 visualizations, each labeled as support, refute, or not enough information. To improve interpretability, each example includes structured knowledge graph explanations covering trends, comparisons, and causal relations. We evaluate state-of-the-art multimodal language models, including both proprietary and open-source systems, in zero-shot and few-shot settings. Results show that current models struggle with chart-based reasoning: even the best systems, such as Gemini 2.5 and InternVL 2.5, reach only 76.2 to 77.8 percent accuracy in label-only settings, far below human performance (89.3 and 92.7 percent). Explanation-augmented outputs improve performance in some models. We released our dataset and code alongside the paper.</li>
</ul>

<h3>Title: SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Mengjiao Ma, Qi Ma, Yue Li, Jiahuan Cheng, Runyi Yang, Bin Ren, Nikola Popovic, Mingqiang Wei, Nicu Sebe, Luc Van Gool, Theo Gevers, Martin R. Oswald, Danda Pani Paudel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08710">https://arxiv.org/abs/2506.08710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08710">https://arxiv.org/pdf/2506.08710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08710]] SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting(https://arxiv.org/abs/2506.08710)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) serves as a highly performant and efficient encoding of scene geometry, appearance, and semantics. Moreover, grounding language in 3D scenes has proven to be an effective strategy for 3D scene understanding. Current Language Gaussian Splatting line of work fall into three main groups: (i) per-scene optimization-based, (ii) per-scene optimization-free, and (iii) generalizable approach. However, most of them are evaluated only on rendered 2D views of a handful of scenes and viewpoints close to the training views, limiting ability and insight into holistic 3D understanding. To address this gap, we propose the first large-scale benchmark that systematically assesses these three groups of methods directly in 3D space, evaluating on 1060 scenes across three indoor datasets and one outdoor dataset. Benchmark results demonstrate a clear advantage of the generalizable paradigm, particularly in relaxing the scene-specific limitation, enabling fast feed-forward inference on novel scenes, and achieving superior segmentation performance. We further introduce GaussianWorld-49K a carefully curated 3DGS dataset comprising around 49K diverse indoor and outdoor scenes obtained from multiple sources, with which we demonstrate the generalizable approach could harness strong data priors. Our codes, benchmark, and datasets will be made public to accelerate research in generalizable 3DGS scene understanding.</li>
</ul>

<h3>Title: ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Large Language Model Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Hee Suk Yoon, Eunseop Yoon, Mark A. Hasegawa-Johnson, Sungwoong Kim, Chang D. Yoo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08712">https://arxiv.org/abs/2506.08712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08712">https://arxiv.org/pdf/2506.08712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08712]] ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Large Language Model Preference Optimization(https://arxiv.org/abs/2506.08712)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce ConfPO, a method for preference learning in Large Language Models (LLMs) that identifies and optimizes preference-critical tokens based solely on the training policy's confidence, without requiring any auxiliary models or compute. Unlike prior Direct Alignment Algorithms (DAAs) such as Direct Preference Optimization (DPO), which uniformly adjust all token probabilities regardless of their relevance to preference, ConfPO focuses optimization on the most impactful tokens. This targeted approach improves alignment quality while mitigating overoptimization (i.e., reward hacking) by using the KL divergence budget more efficiently. In contrast to recent token-level methods that rely on credit-assignment models or AI annotators, raising concerns about scalability and reliability, ConfPO is simple, lightweight, and model-free. Experimental results on challenging alignment benchmarks, including AlpacaEval 2 and Arena-Hard, demonstrate that ConfPO consistently outperforms uniform DAAs across various LLMs, delivering better alignment with zero additional computational overhead.</li>
</ul>

<h3>Title: Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure</h3>
<ul>
<li><strong>Authors: </strong>Fariz Ikhwantri, Dusica Marijan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08713">https://arxiv.org/abs/2506.08713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08713">https://arxiv.org/pdf/2506.08713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08713]] Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure(https://arxiv.org/abs/2506.08713)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ensuring complex systems meet regulations typically requires checking the validity of assurance cases through a claim-argument-evidence framework. Some challenges in this process include the complicated nature of legal and technical texts, the need for model explanations, and limited access to assurance case data. We propose a compliance detection approach based on Natural Language Inference (NLI): EXplainable CompLiance detection with Argumentative Inference of Multi-hop reasoning (EXCLAIM). We formulate the claim-argument-evidence structure of an assurance case as a multi-hop inference for explainable and traceable compliance detection. We address the limited number of assurance cases by generating them using large language models (LLMs). We introduce metrics that measure the coverage and structural consistency. We demonstrate the effectiveness of the generated assurance case from GDPR requirements in a multi-hop inference task as a case study. Our results highlight the potential of NLI-based approaches in automating the regulatory compliance process.</li>
</ul>

<h3>Title: Improved LLM Agents for Financial Document Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Nelvin Tan, Zian Seng, Liang Zhang, Yu-Ching Shih, Dong Yang, Amol Salunkhe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08726">https://arxiv.org/abs/2506.08726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08726">https://arxiv.org/pdf/2506.08726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08726]] Improved LLM Agents for Financial Document Question Answering(https://arxiv.org/abs/2506.08726)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown impressive capabilities on numerous natural language processing tasks. However, LLMs still struggle with numerical question answering for financial documents that include tabular and textual data. Recent works have showed the effectiveness of critic agents (i.e., self-correction) for this task given oracle labels. Building upon this framework, this paper examines the effectiveness of the traditional critic agent when oracle labels are not available, and show, through experiments, that this critic agent's performance deteriorates in this scenario. With this in mind, we present an improved critic agent, along with the calculator agent which outperforms the previous state-of-the-art approach (program-of-thought) and is safer. Furthermore, we investigate how our agents interact with each other, and how this interaction affects their performance.</li>
</ul>

<h3>Title: Breaking the ICE: Exploring promises and challenges of benchmarks for Inference Carbon & Energy estimation for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Samarth Sikand, Rohit Mehra, Priyavanshi Pathania, Nikhil Bamby, Vibhu Saujanya Sharma, Vikrant Kaulgud, Sanjay Podder, Adam P. Burden</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08727">https://arxiv.org/abs/2506.08727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08727">https://arxiv.org/pdf/2506.08727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08727]] Breaking the ICE: Exploring promises and challenges of benchmarks for Inference Carbon & Energy estimation for LLMs(https://arxiv.org/abs/2506.08727)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>While Generative AI stands to be one of the fastest adopted technologies ever, studies have made evident that the usage of Large Language Models (LLMs) puts significant burden on energy grids and our environment. It may prove a hindrance to the Sustainability goals of any organization. A crucial step in any Sustainability strategy is monitoring or estimating the energy consumption of various components. While there exist multiple tools for monitoring energy consumption, there is a dearth of tools/frameworks for estimating the consumption or carbon emissions. Current drawbacks of both monitoring and estimation tools include high input data points, intrusive nature, high error margin, etc. We posit that leveraging emerging LLM benchmarks and related data points can help overcome aforementioned challenges while balancing accuracy of the emission estimations. To that extent, we discuss the challenges of current approaches and present our evolving framework, R-ICE, which estimates prompt level inference carbon emissions by leveraging existing state-of-the-art(SOTA) benchmark. This direction provides a more practical and non-intrusive way to enable emerging use-cases like dynamic LLM routing, carbon accounting, etc. Our promising validation results suggest that benchmark-based modelling holds great potential for inference emission estimation and warrants further exploration from the scientific community.</li>
</ul>

<h3>Title: Geometric deep learning for local growth prediction on abdominal aortic aneurysm surfaces</h3>
<ul>
<li><strong>Authors: </strong>Dieuwertje Alblas, Patryk Rygiel, Julian Suk, Kaj O. Kappe, Marieke Hofman, Christoph Brune, Kak Khee Yeung, Jelmer M. Wolterink</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08729">https://arxiv.org/abs/2506.08729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08729">https://arxiv.org/pdf/2506.08729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08729]] Geometric deep learning for local growth prediction on abdominal aortic aneurysm surfaces(https://arxiv.org/abs/2506.08729)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Abdominal aortic aneurysms (AAAs) are progressive focal dilatations of the abdominal aorta. AAAs may rupture, with a survival rate of only 20\%. Current clinical guidelines recommend elective surgical repair when the maximum AAA diameter exceeds 55 mm in men or 50 mm in women. Patients that do not meet these criteria are periodically monitored, with surveillance intervals based on the maximum AAA diameter. However, this diameter does not take into account the complex relation between the 3D AAA shape and its growth, making standardized intervals potentially unfit. Personalized AAA growth predictions could improve monitoring strategies. We propose to use an SE(3)-symmetric transformer model to predict AAA growth directly on the vascular model surface enriched with local, multi-physical features. In contrast to other works which have parameterized the AAA shape, this representation preserves the vascular surface's anatomical structure and geometric fidelity. We train our model using a longitudinal dataset of 113 computed tomography angiography (CTA) scans of 24 AAA patients at irregularly sampled intervals. After training, our model predicts AAA growth to the next scan moment with a median diameter error of 1.18 mm. We further demonstrate our model's utility to identify whether a patient will become eligible for elective repair within two years (acc = 0.93). Finally, we evaluate our model's generalization on an external validation set consisting of 25 CTAs from 7 AAA patients from a different hospital. Our results show that local directional AAA growth prediction from the vascular surface is feasible and may contribute to personalized surveillance strategies.</li>
</ul>

<h3>Title: Societal AI Research Has Become Less Interdisciplinary</h3>
<ul>
<li><strong>Authors: </strong>Dror Kris Markus, Fabrizio Gilardi, Daria Stetsenko</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08738">https://arxiv.org/abs/2506.08738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08738">https://arxiv.org/pdf/2506.08738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08738]] Societal AI Research Has Become Less Interdisciplinary(https://arxiv.org/abs/2506.08738)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>As artificial intelligence (AI) systems become deeply embedded in everyday life, calls to align AI development with ethical and societal values have intensified. Interdisciplinary collaboration is often championed as a key pathway for fostering such engagement. Yet it remains unclear whether interdisciplinary research teams are actually leading this shift in practice. This study analyzes over 100,000 AI-related papers published on ArXiv between 2014 and 2024 to examine how ethical values and societal concerns are integrated into technical AI research. We develop a classifier to identify societal content and measure the extent to which research papers express these considerations. We find a striking shift: while interdisciplinary teams remain more likely to produce societally-oriented research, computer science-only teams now account for a growing share of the field's overall societal output. These teams are increasingly integrating societal concerns into their papers and tackling a wide range of domains - from fairness and safety to healthcare and misinformation. These findings challenge common assumptions about the drivers of societal AI and raise important questions. First, what are the implications for emerging understandings of AI safety and governance if most societally-oriented research is being undertaken by exclusively technical teams? Second, for scholars in the social sciences and humanities: in a technical field increasingly responsive to societal demands, what distinctive perspectives can we still offer to help shape the future of AI?</li>
</ul>

<h3>Title: Towards Secure and Private Language Models for Nuclear Power Plants</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Anwar, Mishca de Costa, Issam Hammad, Daniel Lau</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08746">https://arxiv.org/abs/2506.08746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08746">https://arxiv.org/pdf/2506.08746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08746]] Towards Secure and Private Language Models for Nuclear Power Plants(https://arxiv.org/abs/2506.08746)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, transformer, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces a domain-specific Large Language Model for nuclear applications, built from the publicly accessible Essential CANDU textbook. Drawing on a compact Transformer-based architecture, the model is trained on a single GPU to protect the sensitive data inherent in nuclear operations. Despite relying on a relatively small dataset, it shows encouraging signs of capturing specialized nuclear vocabulary, though the generated text sometimes lacks syntactic coherence. By focusing exclusively on nuclear content, this approach demonstrates the feasibility of in-house LLM solutions that align with rigorous cybersecurity and data confidentiality standards. Early successes in text generation underscore the model's utility for specialized tasks, while also revealing the need for richer corpora, more sophisticated preprocessing, and instruction fine-tuning to enhance domain accuracy. Future directions include extending the dataset to cover diverse nuclear subtopics, refining tokenization to reduce noise, and systematically evaluating the model's readiness for real-world applications in nuclear domain.</li>
</ul>

<h3>Title: Unlocking the Potential of Large Language Models in the Nuclear Industry with Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Anwar, Daniel Lau, Mishca de Costa, Issam Hammad</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08750">https://arxiv.org/abs/2506.08750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08750">https://arxiv.org/pdf/2506.08750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08750]] Unlocking the Potential of Large Language Models in the Nuclear Industry with Synthetic Data(https://arxiv.org/abs/2506.08750)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>The nuclear industry possesses a wealth of valuable information locked away in unstructured text data. This data, however, is not readily usable for advanced Large Language Model (LLM) applications that require clean, structured question-answer pairs for tasks like model training, fine-tuning, and evaluation. This paper explores how synthetic data generation can bridge this gap, enabling the development of robust LLMs for the nuclear domain. We discuss the challenges of data scarcity and privacy concerns inherent in the nuclear industry and how synthetic data provides a solution by transforming existing text data into usable Q&A pairs. This approach leverages LLMs to analyze text, extract key information, generate relevant questions, and evaluate the quality of the resulting synthetic dataset. By unlocking the potential of LLMs in the nuclear industry, synthetic data can pave the way for improved information retrieval, enhanced knowledge sharing, and more informed decision-making in this critical sector.</li>
</ul>

<h3>Title: Enhancing Accuracy and Maintainability in Nuclear Plant Data Retrieval: A Function-Calling LLM Approach Over NL-to-SQL</h3>
<ul>
<li><strong>Authors: </strong>Mishca de Costa, Muhammad Anwar, Dave Mercier, Mark Randall, Issam Hammad</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08757">https://arxiv.org/abs/2506.08757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08757">https://arxiv.org/pdf/2506.08757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08757]] Enhancing Accuracy and Maintainability in Nuclear Plant Data Retrieval: A Function-Calling LLM Approach Over NL-to-SQL(https://arxiv.org/abs/2506.08757)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieving operational data from nuclear power plants requires exceptional accuracy and transparency due to the criticality of the decisions it supports. Traditionally, natural language to SQL (NL-to-SQL) approaches have been explored for querying such data. While NL-to-SQL promises ease of use, it poses significant risks: end-users cannot easily validate generated SQL queries, and legacy nuclear plant databases -- often complex and poorly structured -- complicate query generation due to decades of incremental modifications. These challenges increase the likelihood of inaccuracies and reduce trust in the approach. In this work, we propose an alternative paradigm: leveraging function-calling large language models (LLMs) to address these challenges. Instead of directly generating SQL queries, we define a set of pre-approved, purpose-specific functions representing common use cases. Queries are processed by invoking these functions, which encapsulate validated SQL logic. This hybrid approach mitigates the risks associated with direct NL-to-SQL translations by ensuring that SQL queries are reviewed and optimized by experts before deployment. While this strategy introduces the upfront cost of developing and maintaining the function library, we demonstrate how NL-to-SQL tools can assist in the initial generation of function code, allowing experts to focus on validation rather than creation. Our study includes a performance comparison between direct NL-to-SQL generation and the proposed function-based approach, highlighting improvements in accuracy and maintainability. This work underscores the importance of balancing user accessibility with operational safety and provides a novel, actionable framework for robust data retrieval in critical systems.</li>
</ul>

<h3>Title: AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Hasanaath, Aisha Alansari, Ahmed Ashraf, Chafik Salmane, Hamzah Luqman, Saad Ezzini</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08768">https://arxiv.org/abs/2506.08768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08768">https://arxiv.org/pdf/2506.08768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08768]] AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP(https://arxiv.org/abs/2506.08768)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable progress in reasoning abilities and general natural language processing (NLP) tasks, yet their performance on Arabic data, characterized by rich morphology, diverse dialects, and complex script, remains underexplored. This paper presents a comprehensive benchmarking study of multiple reasoning-focused LLMs, with a special emphasis on the newly introduced DeepSeek models, across a suite of fifteen Arabic NLP tasks. We experiment with various strategies, including zero-shot, few-shot, and fine-tuning. This allows us to systematically evaluate performance on datasets covering a range of applications to examine their capacity for linguistic reasoning under different levels of complexity. Our experiments reveal several key findings. First, carefully selecting just three in-context examples delivers an average uplift of over 13 F1 points on classification tasks-boosting sentiment analysis from 35.3% to 87.5% and paraphrase detection from 56.1% to 87.0%. Second, reasoning-focused DeepSeek architectures outperform a strong GPT o4-mini baseline by an average of 12 F1 points on complex inference tasks in the zero-shot setting. Third, LoRA-based fine-tuning yields up to an additional 8 points in F1 and BLEU compared to equivalent increases in model scale. The code is available at this https URL</li>
</ul>

<h3>Title: RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jiayi Song, Kaiyu Li, Xiangyong Cao, Deyu Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08772">https://arxiv.org/abs/2506.08772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08772">https://arxiv.org/pdf/2506.08772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08772]] RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation(https://arxiv.org/abs/2506.08772)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation in remote sensing images is crucial for various applications, yet its performance is heavily reliant on large-scale, high-quality pixel-wise annotations, which are notoriously expensive and time-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers a promising alternative to mitigate this data dependency. However, existing SSS methods often struggle with the inherent distribution mismatch between limited labeled data and abundant unlabeled data, leading to suboptimal generalization. We propose that Vision Foundation Models (VFMs), pre-trained on vast and diverse datasets, possess robust generalization capabilities that can effectively bridge this distribution gap and provide strong semantic priors for SSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation and Fusion), a novel framework that leverages the powerful semantic knowledge embedded in VFMs to guide semi-supervised learning in remote sensing. Specifically, RS-MTDF employs multiple frozen VFMs (\textit{e.g.}, DINOv2 and CLIP) as expert teachers, utilizing feature-level distillation to align student features with their robust representations. To further enhance discriminative power, the distilled knowledge is seamlessly fused into the student decoder. Extensive experiments on three challenging remote sensing datasets (ISPRS Potsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achieves state-of-the-art performance. Notably, our method outperforms existing approaches across various label ratios on LoveDA and secures the highest IoU in the majority of semantic categories. These results underscore the efficacy of multi-teacher VFM guidance in significantly enhancing both generalization and semantic understanding for remote sensing segmentation. Ablation studies further validate the contribution of each proposed module.</li>
</ul>

<h3>Title: Lightweight and High-Throughput Secure Logging for Internet of Things and Cold Cloud Continuum</h3>
<ul>
<li><strong>Authors: </strong>Saif E. Nouma, Attila A. Yavuz</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08781">https://arxiv.org/abs/2506.08781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08781">https://arxiv.org/pdf/2506.08781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08781]] Lightweight and High-Throughput Secure Logging for Internet of Things and Cold Cloud Continuum(https://arxiv.org/abs/2506.08781)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>The growing deployment of resource-limited Internet of Things (IoT) devices and their expanding attack surfaces demand efficient and scalable security mechanisms. System logs are vital for the trust and auditability of IoT, and offloading their maintenance to a Cold Storage-as-a-Service (Cold-STaaS) enhances cost-effectiveness and reliability. However, existing cryptographic logging solutions either burden low-end IoT devices with heavy computation or create verification delays and storage inefficiencies at Cold-STaaS. There is a pressing need for cryptographic primitives that balance security, performance, and scalability across IoT-Cold-STaaS continuum. In this work, we present Parallel Optimal Signatures for Secure Logging (POSLO), a novel digital signature framework that, to our knowledge, is the first to offer constant-size signatures and public keys, near-optimal signing efficiency, and tunable fine-to-coarse-grained verification for log auditing. POSLO achieves these properties through efficient randomness management, flexible aggregation, and multiple algorithmic instantiations. It also introduces a GPU-accelerated batch verification framework that exploits homomorphic signature aggregation to deliver ultra-fast performance. For example, POSLO can verify 231 log entries per second on a mid-range consumer GPU (NVIDIA GTX 3060) while being significantly more compact than state-of-the-art. POSLO also preserves signer-side efficiency, offering substantial battery savings for IoT devices, and is well-suited for the IoT-Cold-STaaS ecosystem.</li>
</ul>

<h3>Title: A PDE-Based Image Dehazing Method via Atmospheric Scattering Theory</h3>
<ul>
<li><strong>Authors: </strong>Zhuoran Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08793">https://arxiv.org/abs/2506.08793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08793">https://arxiv.org/pdf/2506.08793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08793]] A PDE-Based Image Dehazing Method via Atmospheric Scattering Theory(https://arxiv.org/abs/2506.08793)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper presents a novel partial differential equation (PDE) framework for single-image dehazing. By integrating the atmospheric scattering model with nonlocal regularization and dark channel prior, we propose the improved PDE: \[ -\text{div}\left(D(\nabla u)\nabla u\right) + \lambda(t) G(u) = \Phi(I,t,A) \] where $D(\nabla u) = (|\nabla u| + \epsilon)^{-1}$ is the edge-preserving diffusion coefficient, $G(u)$ is the Gaussian convolution operator, and $\lambda(t)$ is the adaptive regularization parameter based on transmission map $t$. We prove the existence and uniqueness of weak solutions in $H_0^1(\Omega)$ using Lax-Milgram theorem, and implement an efficient fixed-point iteration scheme accelerated by PyTorch GPU computation. The experimental results demonstrate that this method is a promising deghazing solution that can be generalized to the deep model paradigm.</li>
</ul>

<h3>Title: Flow Diverse and Efficient: Learning Momentum Flow Matching via Stochastic Velocity Field Sampling</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Ma, Ruixun Liu, Sixian Liu, Jianjun Li, Bowen Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08796">https://arxiv.org/abs/2506.08796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08796">https://arxiv.org/pdf/2506.08796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08796]] Flow Diverse and Efficient: Learning Momentum Flow Matching via Stochastic Velocity Field Sampling(https://arxiv.org/abs/2506.08796)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion</a></li>
<li><strong>Abstract: </strong>Recently, the rectified flow (RF) has emerged as the new state-of-the-art among flow-based diffusion models due to its high efficiency advantage in straight path sampling, especially with the amazing images generated by a series of RF models such as Flux 1.0 and SD 3.0. Although a straight-line connection between the noisy and natural data distributions is intuitive, fast, and easy to optimize, it still inevitably leads to: 1) Diversity concerns, which arise since straight-line paths only cover a fairly restricted sampling space. 2) Multi-scale noise modeling concerns, since the straight line flow only needs to optimize the constant velocity field $\bm v$ between the two distributions $\bm\pi_0$ and $\bm\pi_1$. In this work, we present Discretized-RF, a new family of rectified flow (also called momentum flow models since they refer to the previous velocity component and the random velocity component in each diffusion step), which discretizes the straight path into a series of variable velocity field sub-paths (namely ``momentum fields'') to expand the search space, especially when close to the distribution $p_\text{noise}$. Different from the previous case where noise is directly superimposed on $\bm x$, we introduce noise on the velocity $\bm v$ of the sub-path to change its direction in order to improve the diversity and multi-scale noise modeling abilities. Experimental results on several representative datasets demonstrate that learning momentum flow matching by sampling random velocity fields will produce trajectories that are both diverse and efficient, and can consistently generate high-quality and diverse results. Code is available at this https URL.</li>
</ul>

<h3>Title: HunyuanVideo-HOMA: Generic Human-Object Interaction in Multimodal Driven Human Animation</h3>
<ul>
<li><strong>Authors: </strong>Ziyao Huang, Zixiang Zhou, Juan Cao, Yifeng Ma, Yi Chen, Zejing Rao, Zhiyong Xu, Hongmei Wang, Qin Lin, Yuan Zhou, Qinglin Lu, Fan Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08797">https://arxiv.org/abs/2506.08797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08797">https://arxiv.org/pdf/2506.08797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08797]] HunyuanVideo-HOMA: Generic Human-Object Interaction in Multimodal Driven Human Animation(https://arxiv.org/abs/2506.08797)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>To address key limitations in human-object interaction (HOI) video generation -- specifically the reliance on curated motion data, limited generalization to novel objects/scenarios, and restricted accessibility -- we introduce HunyuanVideo-HOMA, a weakly conditioned multimodal-driven framework. HunyuanVideo-HOMA enhances controllability and reduces dependency on precise inputs through sparse, decoupled motion guidance. It encodes appearance and motion signals into the dual input space of a multimodal diffusion transformer (MMDiT), fusing them within a shared context space to synthesize temporally consistent and physically plausible interactions. To optimize training, we integrate a parameter-space HOI adapter initialized from pretrained MMDiT weights, preserving prior knowledge while enabling efficient adaptation, and a facial cross-attention adapter for anatomically accurate audio-driven lip synchronization. Extensive experiments confirm state-of-the-art performance in interaction naturalness and generalization under weak supervision. Finally, HunyuanVideo-HOMA demonstrates versatility in text-conditioned generation and interactive object manipulation, supported by a user-friendly demo interface. The project page is at this https URL.</li>
</ul>

<h3>Title: HiSin: Efficient High-Resolution Sinogram Inpainting via Resolution-Guided Progressive Inference</h3>
<ul>
<li><strong>Authors: </strong>Jiaze E, Srutarshi Banerjee, Tekin Bicer, Guannan Wang, Yanfu Zhang, Bin Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08809">https://arxiv.org/abs/2506.08809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08809">https://arxiv.org/pdf/2506.08809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08809]] HiSin: Efficient High-Resolution Sinogram Inpainting via Resolution-Guided Progressive Inference(https://arxiv.org/abs/2506.08809)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>High-resolution sinogram inpainting is essential for computed tomography reconstruction, as missing high-frequency projections can lead to visible artifacts and diagnostic errors. Diffusion models are well-suited for this task due to their robustness and detail-preserving capabilities, but their application to high-resolution inputs is limited by excessive memory and computational demands. To address this limitation, we propose HiSin, a novel diffusion based framework for efficient sinogram inpainting via resolution-guided progressive inference. It progressively extracts global structure at low resolution and defers high-resolution inference to small patches, enabling memory-efficient inpainting. It further incorporates frequency-aware patch skipping and structure-adaptive step allocation to reduce redundant computation. Experimental results show that HiSin reduces peak memory usage by up to 31.25% and inference time by up to 18.15%, and maintains inpainting accuracy across datasets, resolutions, and mask conditions.</li>
</ul>

<h3>Title: The impact of fine tuning in LLaMA on hallucinations for named entity extraction in legal documentation</h3>
<ul>
<li><strong>Authors: </strong>Francisco Vargas, Alejandro González Coene, Gaston Escalante, Exequiel Lobón, Manuel Pulido</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08827">https://arxiv.org/abs/2506.08827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08827">https://arxiv.org/pdf/2506.08827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08827]] The impact of fine tuning in LLaMA on hallucinations for named entity extraction in legal documentation(https://arxiv.org/abs/2506.08827)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>The extraction of information about traffic accidents from legal documents is crucial for quantifying insurance company costs. Extracting entities such as percentages of physical and/or psychological disability and the involved compensation amounts is a challenging process, even for experts, due to the subtle arguments and reasoning in the court decision. A two-step procedure is proposed: first, segmenting the document identifying the most relevant segments, and then extracting the entities. For text segmentation, two methodologies are compared: a classic method based on regular expressions and a second approach that divides the document into blocks of n-tokens, which are then vectorized using multilingual models for semantic searches (text-embedding-ada-002/MiniLM-L12-v2 ). Subsequently, large language models (LLaMA-2 7b, 70b, LLaMA-3 8b, and GPT-4 Turbo) are applied with prompting to the selected segments for entity extraction. For the LLaMA models, fine-tuning is performed using LoRA. LLaMA-2 7b, even with zero temperature, shows a significant number of hallucinations in extractions which are an important contention point for named entity extraction. This work shows that these hallucinations are substantially reduced after finetuning the model. The performance of the methodology based on segment vectorization and subsequent use of LLMs significantly surpasses the classic method which achieves an accuracy of 39.5%. Among open-source models, LLaMA-2 70B with finetuning achieves the highest accuracy 79.4%, surpassing its base version 61.7%. Notably, the base LLaMA-3 8B model already performs comparably to the finetuned LLaMA-2 70B model, achieving 76.6%, highlighting the rapid progress in model development. Meanwhile, GPT-4 Turbo achieves the highest accuracy at 86.1%.</li>
</ul>

<h3>Title: Lightweight Electronic Signatures and Reliable Access Control Included in Sensor Networks to Prevent Cyber Attacks from Modifying Patient Data</h3>
<ul>
<li><strong>Authors: </strong>Mishall Al-Zubaidie</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08828">https://arxiv.org/abs/2506.08828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08828">https://arxiv.org/pdf/2506.08828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08828]] Lightweight Electronic Signatures and Reliable Access Control Included in Sensor Networks to Prevent Cyber Attacks from Modifying Patient Data(https://arxiv.org/abs/2506.08828)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack</a></li>
<li><strong>Abstract: </strong>Digital terrorism is a major cause of securing patient/healthcare providers data and information. Sensitive topics that may have an impact on a patient's health or even national security include patient health records and information on healthcare providers. Health databases and data sets have been continually breached by many, regular assaults, as well as local and remote servers equipped with wireless sensor networks (WSNs) in diverse locations. The problem was addressed by some contemporary strategies that were created to stop these assaults and guarantee the privacy of patient data and information transferred and gathered by sensors. Nevertheless, the literature analysis outlines many indications of weakness that persist in these methods. This study suggests a novel, reliable method that bolsters the information security and data gathered by sensors and kept on base station datasets. The proposed approach combines a number of security mechanisms, including symmetric cryptography for encryption, asymmetric cryptography for access control and signatures, and the Lesamnta-LW method in the signature process. Users' information is shielded from prying eyes by the careful application of these measures and a sound approach. Investigational comparisons, security studies, and thorough results show that the suggested method is better than earlier methods.</li>
</ul>

<h3>Title: Advancing STT for Low-Resource Real-World Speech</h3>
<ul>
<li><strong>Authors: </strong>Flavio D'Intino, Hans-Peter Hutter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08836">https://arxiv.org/abs/2506.08836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08836">https://arxiv.org/pdf/2506.08836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08836]] Advancing STT for Low-Resource Real-World Speech(https://arxiv.org/abs/2506.08836)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Swiss German is a low-resource language represented by diverse dialects that differ significantly from Standard German and from each other, lacking a standardized written form. As a result, transcribing Swiss German involves translating into Standard German. Existing datasets have been collected in controlled environments, yielding effective speech-to-text (STT) models, but these models struggle with spontaneous conversational speech. This paper, therefore, introduces the new SRB-300 dataset, a 300-hour annotated speech corpus featuring real-world long-audio recordings from 39 Swiss German radio and TV stations. It captures spontaneous speech across all major Swiss dialects recorded in various realistic environments and overcomes the limitation of prior sentence-level corpora. We fine-tuned multiple OpenAI Whisper models on the SRB-300 dataset, achieving notable enhancements over previous zero-shot performance metrics. Improvements in word error rate (WER) ranged from 19% to 33%, while BLEU scores increased between 8% and 40%. The best fine-tuned model, large-v3, achieved a WER of 17.1% and a BLEU score of 74.8. This advancement is crucial for developing effective and robust STT systems for Swiss German and other low-resource languages in real-world contexts.</li>
</ul>

<h3>Title: Design Patterns for Securing LLM Agents against Prompt Injections</h3>
<ul>
<li><strong>Authors: </strong>Luca Beurer-Kellner, Beat Buesser Ana-Maria Creţu, Edoardo Debenedetti, Daniel Dobos, Daniel Fabian, Marc Fischer, David Froelicher, Kathrin Grosse, Daniel Naeff, Ezinwanne Ozoani, Andrew Paverd, Florian Tramèr, Václav Volhejn</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08837">https://arxiv.org/abs/2506.08837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08837">https://arxiv.org/pdf/2506.08837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08837]] Design Patterns for Securing LLM Agents against Prompt Injections(https://arxiv.org/abs/2506.08837)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>As AI agents powered by Large Language Models (LLMs) become increasingly versatile and capable of addressing a broad spectrum of tasks, ensuring their security has become a critical challenge. Among the most pressing threats are prompt injection attacks, which exploit the agent's resilience on natural language inputs -- an especially dangerous threat when agents are granted tool access or handle sensitive information. In this work, we propose a set of principled design patterns for building AI agents with provable resistance to prompt injection. We systematically analyze these patterns, discuss their trade-offs in terms of utility and security, and illustrate their real-world applicability through a series of case studies.</li>
</ul>

<h3>Title: IMAGIC-500: IMputation benchmark on A Generative Imaginary Country (500k samples)</h3>
<ul>
<li><strong>Authors: </strong>Siyi Sun, David Antony Selby, Yunchuan Huang, Sebastian Vollmer, Seth Flaxman, Anisoara Calinescu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08844">https://arxiv.org/abs/2506.08844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08844">https://arxiv.org/pdf/2506.08844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08844]] IMAGIC-500: IMputation benchmark on A Generative Imaginary Country (500k samples)(https://arxiv.org/abs/2506.08844)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Missing data imputation in tabular datasets remains a pivotal challenge in data science and machine learning, particularly within socioeconomic research. However, real-world socioeconomic datasets are typically subject to strict data protection protocols, which often prohibit public sharing, even for synthetic derivatives. This severely limits the reproducibility and accessibility of benchmark studies in such settings. Further, there are very few publicly available synthetic datasets. Thus, there is limited availability of benchmarks for systematic evaluation of imputation methods on socioeconomic datasets, whether real or synthetic. In this study, we utilize the World Bank's publicly available synthetic dataset, Synthetic Data for an Imaginary Country, which closely mimics a real World Bank household survey while being fully public, enabling broad access for methodological research. With this as a starting point, we derived the IMAGIC-500 dataset: we select a subset of 500k individuals across approximately 100k households with 19 socioeconomic features, designed to reflect the hierarchical structure of real-world household surveys. This paper introduces a comprehensive missing data imputation benchmark on IMAGIC-500 under various missing mechanisms (MCAR, MAR, MNAR) and missingness ratios (10\%, 20\%, 30\%, 40\%, 50\%). Our evaluation considers the imputation accuracy for continuous and categorical variables, computational efficiency, and impact on downstream predictive tasks, such as estimating educational attainment at the individual level. The results highlight the strengths and weaknesses of statistical, traditional machine learning, and deep learning imputation techniques, including recent diffusion-based methods. The IMAGIC-500 dataset and benchmark aim to facilitate the development of robust imputation algorithms and foster reproducible social science research.</li>
</ul>

<h3>Title: Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jingguo Qu, Xinyang Han, Tonghuan Xiao, Jia Ai, Juan Wu, Tong Zhao, Jing Qin, Ann Dorothy King, Winnie Chiu-Wing Chu, Jing Cai, Michael Tin-Cheung Yingınst</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08849">https://arxiv.org/abs/2506.08849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08849">https://arxiv.org/pdf/2506.08849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08849]] Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis(https://arxiv.org/abs/2506.08849)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Medical ultrasonography is an essential imaging technique for examining superficial organs and tissues, including lymph nodes, breast, and thyroid. It employs high-frequency ultrasound waves to generate detailed images of the internal structures of the human body. However, manually contouring regions of interest in these images is a labor-intensive task that demands expertise and often results in inconsistent interpretations among individuals. Vision-language foundation models, which have excelled in various computer vision applications, present new opportunities for enhancing ultrasound image analysis. Yet, their performance is hindered by the significant differences between natural and medical imaging domains. This research seeks to overcome these challenges by developing domain adaptation methods for vision-language foundation models. In this study, we explore the fine-tuning pipeline for vision-language foundation models by utilizing large language model as text refiner with special-designed adaptation strategies and task-driven heads. Our approach has been extensively evaluated on six ultrasound datasets and two tasks: segmentation and classification. The experimental results show that our method can effectively improve the performance of vision-language foundation models for ultrasound image analysis, and outperform the existing state-of-the-art vision-language and pure foundation models. The source code of this study is available at \href{this https URL}{GitHub}.</li>
</ul>

<h3>Title: StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams</h3>
<ul>
<li><strong>Authors: </strong>Zike Wu, Qi Yan, Xuanyu Yi, Lele Wang, Renjie Liao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08862">https://arxiv.org/abs/2506.08862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08862">https://arxiv.org/pdf/2506.08862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08862]] StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams(https://arxiv.org/abs/2506.08862)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams is crucial for numerous real-world applications. However, existing methods struggle to jointly address three key challenges: 1) processing uncalibrated inputs in real time, 2) accurately modeling dynamic scene evolution, and 3) maintaining long-term stability and computational efficiency. To this end, we introduce StreamSplat, the first fully feed-forward framework that transforms uncalibrated video streams of arbitrary length into dynamic 3D Gaussian Splatting (3DGS) representations in an online manner, capable of recovering scene dynamics from temporally local observations. We propose two key technical innovations: a probabilistic sampling mechanism in the static encoder for 3DGS position prediction, and a bidirectional deformation field in the dynamic decoder that enables robust and efficient dynamic modeling. Extensive experiments on static and dynamic benchmarks demonstrate that StreamSplat consistently outperforms prior works in both reconstruction quality and dynamic scene modeling, while uniquely supporting online reconstruction of arbitrarily long video streams. Code and models are available at this https URL.</li>
</ul>

<h3>Title: SmartAttack: Air-Gap Attack via Smartwatches</h3>
<ul>
<li><strong>Authors: </strong>Mordechai Guri</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08866">https://arxiv.org/abs/2506.08866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08866">https://arxiv.org/pdf/2506.08866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08866]] SmartAttack: Air-Gap Attack via Smartwatches(https://arxiv.org/abs/2506.08866)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>Air-gapped systems are considered highly secure against data leaks due to their physical isolation from external networks. Despite this protection, ultrasonic communication has been demonstrated as an effective method for exfiltrating data from such systems. While smartphones have been extensively studied in the context of ultrasonic covert channels, smartwatches remain an underexplored yet effective attack vector. In this paper, we propose and evaluate SmartAttack, a novel method that leverages smartwatches as receivers for ultrasonic covert communication in air-gapped environments. Our approach utilizes the built-in microphones of smartwatches to capture covert signals in real time within the ultrasonic frequency range of 18-22 kHz. Through experimental validation, we assess the feasibility of this attack under varying environmental conditions, distances, orientations, and noise levels. Furthermore, we analyze smartwatch-specific factors that influence ultrasonic covert channels, including their continuous presence on the user's wrist, the impact of the human body on signal propagation, and the directional constraints of built-in microphones. Our findings highlight the security risks posed by smartwatches in high-security environments and outline mitigation strategies to counteract this emerging threat.</li>
</ul>

<h3>Title: Filling in the Blanks: Applying Data Imputation in incomplete Water Metering Data</h3>
<ul>
<li><strong>Authors: </strong>Dimitrios Amaxilatis, Themistoklis Sarantakos, Ioannis Chatzigiannakis, Georgios Mylonas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08882">https://arxiv.org/abs/2506.08882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08882">https://arxiv.org/pdf/2506.08882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08882]] Filling in the Blanks: Applying Data Imputation in incomplete Water Metering Data(https://arxiv.org/abs/2506.08882)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this work, we explore the application of recent data imputation techniques to enhance monitoring and management of water distribution networks using smart water meters, based on data derived from a real-world IoT water grid monitoring deployment. Despite the detailed data produced by such meters, data gaps due to technical issues can significantly impact operational decisions and efficiency. Our results, by comparing various imputation methods, such as k-Nearest Neighbors, MissForest, Transformers, and Recurrent Neural Networks, indicate that effective data imputation can substantially enhance the quality of the insights derived from water consumption data as we study their effect on accuracy and reliability of water metering data to provide solutions in applications like leak detection and predictive maintenance scheduling.</li>
</ul>

<h3>Title: InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis</h3>
<ul>
<li><strong>Authors: </strong>Shiqin Tang, Shujian Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08884">https://arxiv.org/abs/2506.08884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08884">https://arxiv.org/pdf/2506.08884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08884]] InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis(https://arxiv.org/abs/2506.08884)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, generative</a></li>
<li><strong>Abstract: </strong>Extracting meaningful latent representations from high-dimensional sequential data is a crucial challenge in machine learning, with applications spanning natural science and engineering. We introduce InfoDPCCA, a dynamic probabilistic Canonical Correlation Analysis (CCA) framework designed to model two interdependent sequences of observations. InfoDPCCA leverages a novel information-theoretic objective to extract a shared latent representation that captures the mutual structure between the data streams and balances representation compression and predictive sufficiency while also learning separate latent components that encode information specific to each sequence. Unlike prior dynamic CCA models, such as DPCCA, our approach explicitly enforces the shared latent space to encode only the mutual information between the sequences, improving interpretability and robustness. We further introduce a two-step training scheme to bridge the gap between information-theoretic representation learning and generative modeling, along with a residual connection mechanism to enhance training stability. Through experiments on synthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a tool for representation learning. Code of InfoDPCCA is available at this https URL.</li>
</ul>

<h3>Title: AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)</h3>
<ul>
<li><strong>Authors: </strong>Danush Khanna, Krishna Kumar, Basab Ghosh, Vinija Jain, Vasu Sharma, Aman Chadha, Amitava Das</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08885">https://arxiv.org/abs/2506.08885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08885">https://arxiv.org/pdf/2506.08885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08885]] AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)(https://arxiv.org/abs/2506.08885)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Adversarial threats against LLMs are escalating faster than current defenses can adapt. We expose a critical geometric blind spot in alignment: adversarial prompts exploit latent camouflage, embedding perilously close to the safe representation manifold while encoding unsafe intent thereby evading surface level defenses like Direct Preference Optimization (DPO), which remain blind to the latent geometry. We introduce ALKALI, the first rigorously curated adversarial benchmark and the most comprehensive to date spanning 9,000 prompts across three macro categories, six subtypes, and fifteen attack families. Evaluation of 21 leading LLMs reveals alarmingly high Attack Success Rates (ASRs) across both open and closed source models, exposing an underlying vulnerability we term latent camouflage, a structural blind spot where adversarial completions mimic the latent geometry of safe ones. To mitigate this vulnerability, we introduce GRACE - Geometric Representation Aware Contrastive Enhancement, an alignment framework coupling preference learning with latent space regularization. GRACE enforces two constraints: latent separation between safe and adversarial completions, and adversarial cohesion among unsafe and jailbreak behaviors. These operate over layerwise pooled embeddings guided by a learned attention profile, reshaping internal geometry without modifying the base model, and achieve up to 39% ASR reduction. Moreover, we introduce AVQI, a geometry aware metric that quantifies latent alignment failure via cluster separation and compactness. AVQI reveals when unsafe completions mimic the geometry of safe ones, offering a principled lens into how models internally encode safety. We make the code publicly available at this https URL.</li>
</ul>

<h3>Title: Product of Experts for Visual Generation</h3>
<ul>
<li><strong>Authors: </strong>Yunzhi Zhang, Carson Murtuza-Lanier, Zizhang Li, Yilun Du, Jiajun Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08894">https://arxiv.org/abs/2506.08894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08894">https://arxiv.org/pdf/2506.08894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08894]] Product of Experts for Visual Generation(https://arxiv.org/abs/2506.08894)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modern neural models capture rich priors and have complementary knowledge over shared data domains, e.g., images and videos. Integrating diverse knowledge from multiple sources -- including visual generative models, visual language models, and sources with human-crafted knowledge such as graphics engines and physics simulators -- remains under-explored. We propose a Product of Experts (PoE) framework that performs inference-time knowledge composition from heterogeneous models. This training-free approach samples from the product distribution across experts via Annealed Importance Sampling (AIS). Our framework shows practical benefits in image and video synthesis tasks, yielding better controllability than monolithic methods and additionally providing flexible user interfaces for specifying visual generation goals.</li>
</ul>

<h3>Title: WetCat: Automating Skill Assessment in Wetlab Cataract Surgery Videos</h3>
<ul>
<li><strong>Authors: </strong>Negin Ghamsarian, Raphael Sznitman, Klaus Schoeffmann, Jens Kowal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08896">https://arxiv.org/abs/2506.08896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08896">https://arxiv.org/pdf/2506.08896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08896]] WetCat: Automating Skill Assessment in Wetlab Cataract Surgery Videos(https://arxiv.org/abs/2506.08896)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>To meet the growing demand for systematic surgical training, wetlab environments have become indispensable platforms for hands-on practice in ophthalmology. Yet, traditional wetlab training depends heavily on manual performance evaluations, which are labor-intensive, time-consuming, and often subject to variability. Recent advances in computer vision offer promising avenues for automated skill assessment, enhancing both the efficiency and objectivity of surgical education. Despite notable progress in ophthalmic surgical datasets, existing resources predominantly focus on real surgeries or isolated tasks, falling short of supporting comprehensive skill evaluation in controlled wetlab settings. To address these limitations, we introduce WetCat, the first dataset of wetlab cataract surgery videos specifically curated for automated skill assessment. WetCat comprises high-resolution recordings of surgeries performed by trainees on artificial eyes, featuring comprehensive phase annotations and semantic segmentations of key anatomical structures. These annotations are meticulously designed to facilitate skill assessment during the critical capsulorhexis and phacoemulsification phases, adhering to standardized surgical skill assessment frameworks. By focusing on these essential phases, WetCat enables the development of interpretable, AI-driven evaluation tools aligned with established clinical metrics. This dataset lays a strong foundation for advancing objective, scalable surgical education and sets a new benchmark for automated workflow analysis and skill assessment in ophthalmology training. The dataset and annotations are publicly available in Synapse this https URL.</li>
</ul>

<h3>Title: PlantBert: An Open Source Language Model for Plant Science</h3>
<ul>
<li><strong>Authors: </strong>Hiba Khey, Amine Lakhder, Salma Rouichi, Imane El Ghabi, Kamal Hejjaoui, Younes En-nahli, Fahd Kalloubi, Moez Amri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08897">https://arxiv.org/abs/2506.08897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08897">https://arxiv.org/pdf/2506.08897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08897]] PlantBert: An Open Source Language Model for Plant Science(https://arxiv.org/abs/2506.08897)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The rapid advancement of transformer-based language models has catalyzed breakthroughs in biomedical and clinical natural language processing; however, plant science remains markedly underserved by such domain-adapted tools. In this work, we present PlantBert, a high-performance, open-source language model specifically tailored for extracting structured knowledge from plant stress-response literature. Built upon the DeBERTa architecture-known for its disentangled attention and robust contextual encoding-PlantBert is fine-tuned on a meticulously curated corpus of expert-annotated abstracts, with a primary focus on lentil (Lens culinaris) responses to diverse abiotic and biotic stressors. Our methodology combines transformer-based modeling with rule-enhanced linguistic post-processing and ontology-grounded entity normalization, enabling PlantBert to capture biologically meaningful relationships with precision and semantic fidelity. The underlying corpus is annotated using a hierarchical schema aligned with the Crop Ontology, encompassing molecular, physiological, biochemical, and agronomic dimensions of plant adaptation. PlantBert exhibits strong generalization capabilities across entity types and demonstrates the feasibility of robust domain adaptation in low-resource scientific fields. By providing a scalable and reproducible framework for high-resolution entity recognition, PlantBert bridges a critical gap in agricultural NLP and paves the way for intelligent, data-driven systems in plant genomics, phenomics, and agronomic knowledge discovery. Our model is publicly released to promote transparency and accelerate cross-disciplinary innovation in computational plant science.</li>
</ul>

<h3>Title: From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis</h3>
<ul>
<li><strong>Authors: </strong>Elias Horner, Cristinel Mateis, Guido Governatori, Agata Ciabattoni</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08899">https://arxiv.org/abs/2506.08899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08899">https://arxiv.org/pdf/2506.08899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08899]] From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis(https://arxiv.org/abs/2506.08899)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>We present a novel approach to the automated semantic analysis of legal texts using large language models (LLMs), targeting their transformation into formal representations in Defeasible Deontic Logic (DDL). We propose a structured pipeline that segments complex normative language into atomic snippets, extracts deontic rules, and evaluates them for syntactic and semantic coherence. Our methodology is evaluated across various LLM configurations, including prompt engineering strategies, fine-tuned models, and multi-stage pipelines, focusing on legal norms from the Australian Telecommunications Consumer Protections Code. Empirical results demonstrate promising alignment between machine-generated and expert-crafted formalizations, showing that LLMs - particularly when prompted effectively - can significantly contribute to scalable legal informatics.</li>
</ul>

<h3>Title: MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis</h3>
<ul>
<li><strong>Authors: </strong>José Morano, Botond Fazekas, Emese Sükei, Ronald Fecso, Taha Emre, Markus Gumpinger, Georg Faustmann, Marzieh Oghbaie, Ursula Schmidt-Erfurth, Hrvoje Bogunović</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08900">https://arxiv.org/abs/2506.08900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08900">https://arxiv.org/pdf/2506.08900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08900]] MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis(https://arxiv.org/abs/2506.08900)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Artificial intelligence (AI) has become a fundamental tool for assisting clinicians in analyzing ophthalmic images, such as optical coherence tomography (OCT). However, developing AI models often requires extensive annotation, and existing models tend to underperform on independent, unseen data. Foundation models (FMs), large AI models trained on vast unlabeled datasets, have shown promise in overcoming these challenges. Nonetheless, available FMs for ophthalmology lack extensive validation, especially for segmentation tasks, and focus on a single imaging modality. In this context, we propose MIRAGE, a novel multimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO) images. Additionally, we propose a new evaluation benchmark with OCT/SLO classification and segmentation tasks. The comparison with general and specialized FMs and segmentation methods shows the superiority of MIRAGE in both types of tasks, highlighting its suitability as a basis for the development of robust AI systems for retinal OCT image analysis. Both MIRAGE and the evaluation benchmark are publicly available: this https URL.</li>
</ul>

<h3>Title: Intention-Conditioned Flow Occupancy Models</h3>
<ul>
<li><strong>Authors: </strong>Chongyi Zheng, Seohong Park, Sergey Levine, Benjamin Eysenbach</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08902">https://arxiv.org/abs/2506.08902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08902">https://arxiv.org/pdf/2506.08902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08902]] Intention-Conditioned Flow Occupancy Models(https://arxiv.org/abs/2506.08902)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Large-scale pre-training has fundamentally changed how machine learning research is done today: large foundation models are trained once, and then can be used by anyone in the community (including those without data or compute resources to train a model from scratch) to adapt and fine-tune to specific tasks. Applying this same framework to reinforcement learning (RL) is appealing because it offers compelling avenues for addressing core challenges in RL, including sample efficiency and robustness. However, there remains a fundamental challenge to pre-train large models in the context of RL: actions have long-term dependencies, so training a foundation model that reasons across time is important. Recent advances in generative AI have provided new tools for modeling highly complex distributions. In this paper, we build a probabilistic model to predict which states an agent will visit in the temporally distant future (i.e., an occupancy measure) using flow matching. As large datasets are often constructed by many distinct users performing distinct tasks, we include in our model a latent variable capturing the user intention. This intention increases the expressivity of our model, and enables adaptation with generalized policy improvement. We call our proposed method intention-conditioned flow occupancy models (InFOM). Comparing with alternative methods for pre-training, our experiments on $36$ state-based and $4$ image-based benchmark tasks demonstrate that the proposed method achieves $1.8 \times$ median improvement in returns and increases success rates by $36\%$. Website: this https URL Code: this https URL</li>
</ul>

<h3>Title: Dialect Normalization using Large Language Models and Morphological Rules</h3>
<ul>
<li><strong>Authors: </strong>Antonios Dimakis (1 and 2), John Pavlopoulos (1 and 3), Antonios Anastasopoulos (1 and 4) ((1) Archimedes, Athena Research Center, Greece, (2) Department of Informatics and Telecommunications, NKUA, (3) Department of Informatics, Athens University of Economics and Business, Greece, (4) Department of Computer Science, George Mason University)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08907">https://arxiv.org/abs/2506.08907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08907">https://arxiv.org/pdf/2506.08907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08907]] Dialect Normalization using Large Language Models and Morphological Rules(https://arxiv.org/abs/2506.08907)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Natural language understanding systems struggle with low-resource languages, including many dialects of high-resource ones. Dialect-to-standard normalization attempts to tackle this issue by transforming dialectal text so that it can be used by standard-language tools downstream. In this study, we tackle this task by introducing a new normalization method that combines rule-based linguistically informed transformations and large language models (LLMs) with targeted few-shot prompting, without requiring any parallel data. We implement our method for Greek dialects and apply it on a dataset of regional proverbs, evaluating the outputs using human annotators. We then use this dataset to conduct downstream experiments, finding that previous results regarding these proverbs relied solely on superficial linguistic information, including orthographic artifacts, while new observations can still be made through the remaining semantics.</li>
</ul>

<h3>Title: Inherently Faithful Attention Maps for Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Ananthu Aniraj, Cassio F. Dantas, Dino Ienco, Diego Marcos</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08915">https://arxiv.org/abs/2506.08915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08915">https://arxiv.org/pdf/2506.08915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08915]] Inherently Faithful Attention Maps for Vision Transformers(https://arxiv.org/abs/2506.08915)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We introduce an attention-based method that uses learned binary attention masks to ensure that only attended image regions influence the prediction. Context can strongly affect object perception, sometimes leading to biased representations, particularly when objects appear in out-of-distribution backgrounds. At the same time, many image-level object-centric tasks require identifying relevant regions, often requiring context. To address this conundrum, we propose a two-stage framework: stage 1 processes the full image to discover object parts and identify task-relevant regions, while stage 2 leverages input attention masking to restrict its receptive field to these regions, enabling a focused analysis while filtering out potentially spurious information. Both stages are trained jointly, allowing stage 2 to refine stage 1. Extensive experiments across diverse benchmarks demonstrate that our approach significantly improves robustness against spurious correlations and out-of-distribution backgrounds.</li>
</ul>

<h3>Title: Enhancing generalizability of model discovery across parameter space with multi-experiment equation learning (ME-EQL)</h3>
<ul>
<li><strong>Authors: </strong>Maria-Veronica Ciocanel, John T. Nardini, Kevin B. Flores, Erica M. Rutter, Suzanne S. Sindi, Alexandria Volkening</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08916">https://arxiv.org/abs/2506.08916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08916">https://arxiv.org/pdf/2506.08916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08916]] Enhancing generalizability of model discovery across parameter space with multi-experiment equation learning (ME-EQL)(https://arxiv.org/abs/2506.08916)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Agent-based modeling (ABM) is a powerful tool for understanding self-organizing biological systems, but it is computationally intensive and often not analytically tractable. Equation learning (EQL) methods can derive continuum models from ABM data, but they typically require extensive simulations for each parameter set, raising concerns about generalizability. In this work, we extend EQL to Multi-experiment equation learning (ME-EQL) by introducing two methods: one-at-a-time ME-EQL (OAT ME-EQL), which learns individual models for each parameter set and connects them via interpolation, and embedded structure ME-EQL (ES ME-EQL), which builds a unified model library across parameters. We demonstrate these methods using a birth--death mean-field model and an on-lattice agent-based model of birth, death, and migration with spatial structure. Our results show that both methods significantly reduce the relative error in recovering parameters from agent-based simulations, with OAT ME-EQL offering better generalizability across parameter space. Our findings highlight the potential of equation learning from multiple experiments to enhance the generalizability and interpretability of learned models for complex biological systems.</li>
</ul>

<h3>Title: Quantifying Mix Network Privacy Erosion with Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Vasilios Mavroudis, Tariq Elahi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08918">https://arxiv.org/abs/2506.08918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08918">https://arxiv.org/pdf/2506.08918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08918]] Quantifying Mix Network Privacy Erosion with Generative Models(https://arxiv.org/abs/2506.08918)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>Modern mix networks improve over Tor and provide stronger privacy guarantees by robustly obfuscating metadata. As long as a message is routed through at least one honest mixnode, the privacy of the users involved is safeguarded. However, the complexity of the mixing mechanisms makes it difficult to estimate the cumulative privacy erosion occurring over time. This work uses a generative model trained on mixnet traffic to estimate the loss of privacy when users communicate persistently over a period of time. We train our large-language model from scratch on our specialized network traffic ``language'' and then use it to measure the sender-message unlinkability in various settings (e.g. mixing strategies, security parameters, observation window). Our findings reveal notable differences in privacy levels among mix strategies, even when they have similar mean latencies. In comparison, we demonstrate the limitations of traditional privacy metrics, such as entropy and log-likelihood, in fully capturing an adversary's potential to synthesize information from multiple observations. Finally, we show that larger models exhibit greater sample efficiency and superior capabilities implying that further advancements in transformers will consequently enhance the accuracy of model-based privacy estimates.</li>
</ul>

<h3>Title: PropMEND: Hypernetworks for Knowledge Propagation in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Leo Liu, Greg Durrett, Eunsol Choi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08920">https://arxiv.org/abs/2506.08920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08920">https://arxiv.org/pdf/2506.08920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08920]] PropMEND: Hypernetworks for Knowledge Propagation in LLMs(https://arxiv.org/abs/2506.08920)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge editing techniques for large language models (LLMs) can inject knowledge that is later reproducible verbatim, but they fall short on propagating that knowledge: models cannot answer questions that require reasoning with the injected knowledge. We present a hypernetwork-based approach for knowledge propagation, named PropMEND, where we meta-learn how to modify gradients of a language modeling loss to encourage injected information to propagate. Our approach extends the meta-objective of MEND [29] so that gradient updates on knowledge are transformed to enable answering multi-hop questions involving that knowledge. We show improved performance on the RippleEdit dataset, showing almost 2x accuracy on challenging multi-hop questions whose answers are not explicitly stated in the injected fact. We further introduce a new dataset, Controlled RippleEdit, to evaluate the generalization of our hypernetwork, testing knowledge propagation along relations and entities unseen during hypernetwork training. PropMEND still outperforms existing approaches in unseen entity-relation pairs, yet the performance gap decreases substantially, suggesting future work in propagating knowledge to a wide range of relations.</li>
</ul>

<h3>Title: Striking Back At Cobalt: Using Network Traffic Metadata To Detect Cobalt Strike Masquerading Command and Control Channels</h3>
<ul>
<li><strong>Authors: </strong>Clément Parssegny, Johan Mazel, Olivier Levillain, Pierre Chifflier</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08922">https://arxiv.org/abs/2506.08922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08922">https://arxiv.org/pdf/2506.08922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08922]] Striking Back At Cobalt: Using Network Traffic Metadata To Detect Cobalt Strike Masquerading Command and Control Channels(https://arxiv.org/abs/2506.08922)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Off-the-shelf software for Command and Control is often used by attackers and legitimate pentesters looking for discretion. Among other functionalities, these tools facilitate the customization of their network traffic so it can mimic popular websites, thereby increasing their secrecy. Cobalt Strike is one of the most famous solutions in this category, used by known advanced attacker groups such as "Mustang Panda" or "Nobelium". In response to these threats, Security Operation Centers and other defense actors struggle to detect Command and Control traffic, which often use encryption protocols such as TLS. Network traffic metadata-based machine learning approaches have been proposed to detect encrypted malware communications or fingerprint websites over Tor network. This paper presents a machine learning-based method to detect Cobalt Strike Command and Control activity based only on widely used network traffic metadata. The proposed method is, to the best of our knowledge, the first of its kind that is able to adapt the model it uses to the observed traffic to optimize its performance. This specificity permits our method to performs equally or better than the state of the art while using standard features. Our method is thus easier to use in a production environment and more explainable.</li>
</ul>

<h3>Title: Local MDI+: Local Feature Importances for Tree-Based Models</h3>
<ul>
<li><strong>Authors: </strong>Zhongyuan Liang, Zachary T. Rewolinski, Abhineet Agarwal, Tiffany M. Tang, Bin Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08928">https://arxiv.org/abs/2506.08928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08928">https://arxiv.org/pdf/2506.08928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08928]] Local MDI+: Local Feature Importances for Tree-Based Models(https://arxiv.org/abs/2506.08928)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Tree-based ensembles such as random forests remain the go-to for tabular data over deep learning models due to their prediction performance and computational efficiency. These advantages have led to their widespread deployment in high-stakes domains, where interpretability is essential for ensuring trustworthy predictions. This has motivated the development of popular local (i.e. sample-specific) feature importance (LFI) methods such as LIME and TreeSHAP. However, these approaches rely on approximations that ignore the model's internal structure and instead depend on potentially unstable perturbations. These issues are addressed in the global setting by MDI+, a feature importance method which exploits an equivalence between decision trees and linear models on a transformed node basis. However, the global MDI+ scores are not able to explain predictions when faced with heterogeneous individual characteristics. To address this gap, we propose Local MDI+ (LMDI+), a novel extension of the MDI+ framework to the sample specific setting. LMDI+ outperforms existing baselines LIME and TreeSHAP in identifying instance-specific signal features, averaging a 10% improvement in downstream task performance across twelve real-world benchmark datasets. It further demonstrates greater stability by consistently producing similar instance-level feature importance rankings across multiple random forest fits. Finally, LMDI+ enables local interpretability use cases, including the identification of closer counterfactuals and the discovery of homogeneous subgroups.</li>
</ul>

<h3>Title: What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Wendong Bu, Yang Wu, Qifan Yu, Minghe Gao, Bingchen Miao, Zhenkui Zhang, Kaihang Pan, Yunfei Li, Mengze Li, Wei Ji, Juncheng Li, Siliang Tang, Yueting Zhuang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08933">https://arxiv.org/abs/2506.08933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08933">https://arxiv.org/pdf/2506.08933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08933]] What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities(https://arxiv.org/abs/2506.08933)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As multimodal large language models (MLLMs) advance, MLLM-based virtual agents have demonstrated remarkable performance. However, existing benchmarks face significant limitations, including uncontrollable task complexity, extensive manual annotation with limited scenarios, and a lack of multidimensional evaluation. In response to these challenges, we introduce OmniBench, a self-generating, cross-platform, graph-based benchmark with an automated pipeline for synthesizing tasks of controllable complexity through subtask composition. To evaluate the diverse capabilities of virtual agents on the graph, we further present OmniEval, a multidimensional evaluation framework that includes subtask-level evaluation, graph-based metrics, and comprehensive tests across 10 capabilities. Our synthesized dataset contains 36k graph-structured tasks across 20 scenarios, achieving a 91\% human acceptance rate. Training on our graph-structured data shows that it can more efficiently guide agents compared to manually annotated data. We conduct multidimensional evaluations for various open-source and closed-source models, revealing their performance across various capabilities and paving the way for future advancements. Our project is available at this https URL.</li>
</ul>

<h3>Title: Can A Gamer Train A Mathematical Reasoning Model?</h3>
<ul>
<li><strong>Authors: </strong>Andrew Shin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08935">https://arxiv.org/abs/2506.08935</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08935">https://arxiv.org/pdf/2506.08935</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08935]] Can A Gamer Train A Mathematical Reasoning Model?(https://arxiv.org/abs/2506.08935)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) have achieved remarkable performance in various tasks including mathematical reasoning, their development typically demands prohibitive computational resources. Recent advancements have reduced costs for training capable models, yet even these approaches rely on high-end hardware clusters. In this paper, we demonstrate that a single average gaming GPU can train a solid mathematical reasoning model, by integrating reinforcement learning and memory optimization techniques. Specifically, we train a 1.5B parameter mathematical reasoning model on RTX 3080 Ti of 16GB memory that achieves comparable or better performance on mathematical reasoning benchmarks than models several times larger, in resource-constrained environments. Our results challenge the paradigm that state-of-the-art mathematical reasoning necessitates massive infrastructure, democratizing access to high-performance AI research. this https URL.</li>
</ul>

<h3>Title: FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Qinggang Zhang, Zhishang Xiang, Yilin Xiao, Le Wang, Junhui Li, Xinrun Wang, Jinsong Su</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08938">https://arxiv.org/abs/2506.08938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08938">https://arxiv.org/pdf/2506.08938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08938]] FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation(https://arxiv.org/abs/2506.08938)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) augmented with retrieval systems have demonstrated significant potential in handling knowledge-intensive tasks. However, these models often struggle with unfaithfulness issues, generating outputs that either ignore the retrieved context or inconsistently blend it with the LLM`s parametric knowledge. This issue is particularly severe in cases of knowledge conflict, where the retrieved context conflicts with the model`s parametric knowledge. While existing faithful RAG approaches enforce strict context adherence through well-designed prompts or modified decoding strategies, our analysis reveals a critical limitation: they achieve faithfulness by forcibly suppressing the model`s parametric knowledge, which undermines the model`s internal knowledge structure and increases the risk of misinterpreting the context. To this end, this paper proposes FaithfulRAG, a novel framework that resolves knowledge conflicts by explicitly modeling discrepancies between the model`s parametric knowledge and retrieved context. Specifically, FaithfulRAG identifies conflicting knowledge at the fact level and designs a self-thinking process, allowing LLMs to reason about and integrate conflicting facts before generating responses. Extensive experiments demonstrate that our method outperforms state-of-the-art methods. The code is available at https:// this http URL</li>
</ul>

<h3>Title: KARMA: A Multilevel Decomposition Hybrid Mamba Framework for Multivariate Long-Term Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Hang Ye, Gaoxiang Duan, Haoran Zeng, Yangxin Zhu, Lingxue Meng, Xiaoying Zheng, Yongxin Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08939">https://arxiv.org/abs/2506.08939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08939">https://arxiv.org/pdf/2506.08939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08939]] KARMA: A Multilevel Decomposition Hybrid Mamba Framework for Multivariate Long-Term Time Series Forecasting(https://arxiv.org/abs/2506.08939)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Multivariate long-term and efficient time series forecasting is a key requirement for a variety of practical applications, and there are complex interleaving time dynamics in time series data that require decomposition modeling. Traditional time series decomposition methods are single and rely on fixed rules, which are insufficient for mining the potential information of the series and adapting to the dynamic characteristics of complex series. On the other hand, the Transformer-based models for time series forecasting struggle to effectively model long sequences and intricate dynamic relationships due to their high computational complexity. To overcome these limitations, we introduce KARMA, with an Adaptive Time Channel Decomposition module (ATCD) to dynamically extract trend and seasonal components. It further integrates a Hybrid Frequency-Time Decomposition module (HFTD) to further decompose Series into frequency-domain and time-domain. These components are coupled with multi-scale Mamba-based KarmaBlock to efficiently process global and local information in a coordinated manner. Experiments on eight real-world datasets from diverse domains well demonstrated that KARMA significantly outperforms mainstream baseline methods in both predictive accuracy and computational efficiency. Code and full results are available at this repository: this https URL</li>
</ul>

<h3>Title: SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Hongjie Zhu, Xiwei Liu, Rundong Xue, Zeyu Zhang, Yong Xu, Daji Ergu, Ying Cai, Yang Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08949">https://arxiv.org/abs/2506.08949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08949">https://arxiv.org/pdf/2506.08949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08949]] SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging Segmentation(https://arxiv.org/abs/2506.08949)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>In the era of information explosion, efficiently leveraging large-scale unlabeled data while minimizing the reliance on high-quality pixel-level annotations remains a critical challenge in the field of medical imaging. Semi-supervised learning (SSL) enhances the utilization of unlabeled data by facilitating knowledge transfer, significantly improving the performance of fully supervised models and emerging as a highly promising research direction in medical image analysis. Inspired by the ability of Vision Foundation Models (e.g., SAM-2) to provide rich prior knowledge, we propose SSS (Semi-Supervised SAM-2), a novel approach that leverages SAM-2's robust feature extraction capabilities to uncover latent knowledge in unlabeled medical images, thus effectively enhancing feature support for fully supervised medical image segmentation. Specifically, building upon the single-stream "weak-to-strong" consistency regularization framework, this paper introduces a Discriminative Feature Enhancement (DFE) mechanism to further explore the feature discrepancies introduced by various data augmentation strategies across multiple views. By leveraging feature similarity and dissimilarity across multi-scale augmentation techniques, the method reconstructs and models the features, thereby effectively optimizing the salient regions. Furthermore, a prompt generator is developed that integrates Physical Constraints with a Sliding Window (PCSW) mechanism to generate input prompts for unlabeled data, fulfilling SAM-2's requirement for additional prompts. Extensive experiments demonstrate the superiority of the proposed method for semi-supervised medical image segmentation on two multi-label datasets, i.e., ACDC and BHSD. Notably, SSS achieves an average Dice score of 53.15 on BHSD, surpassing the previous state-of-the-art method by +3.65 Dice. Code will be available at this https URL.</li>
</ul>

<h3>Title: Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions</h3>
<ul>
<li><strong>Authors: </strong>Clara Lachenmaier, Judith Sieker, Sina Zarrieß</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08952">https://arxiv.org/abs/2506.08952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08952">https://arxiv.org/pdf/2506.08952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08952]] Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions(https://arxiv.org/abs/2506.08952)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Communication among humans relies on conversational grounding, allowing interlocutors to reach mutual understanding even when they do not have perfect knowledge and must resolve discrepancies in each other's beliefs. This paper investigates how large language models (LLMs) manage common ground in cases where they (don't) possess knowledge, focusing on facts in the political domain where the risk of misinformation and grounding failure is high. We examine the ability of LLMs to answer direct knowledge questions and loaded questions that presuppose misinformation. We evaluate whether loaded questions lead LLMs to engage in active grounding and correct false user beliefs, in connection to their level of knowledge and their political bias. Our findings highlight significant challenges in LLMs' ability to engage in grounding and reject false user beliefs, raising concerns about their role in mitigating misinformation in political discourse.</li>
</ul>

<h3>Title: Cross-Spectral Body Recognition with Side Information Embedding: Benchmarks on LLCM and Analyzing Range-Induced Occlusions on IJB-MDF</h3>
<ul>
<li><strong>Authors: </strong>Anirudh Nanduri, Siyuan Huang, Rama Chellappa</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08953">https://arxiv.org/abs/2506.08953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08953">https://arxiv.org/pdf/2506.08953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08953]] Cross-Spectral Body Recognition with Side Information Embedding: Benchmarks on LLCM and Analyzing Range-Induced Occlusions on IJB-MDF(https://arxiv.org/abs/2506.08953)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric, transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformers (ViTs) have demonstrated impressive performance across a wide range of biometric tasks, including face and body recognition. In this work, we adapt a ViT model pretrained on visible (VIS) imagery to the challenging problem of cross-spectral body recognition, which involves matching images captured in the visible and infrared (IR) domains. Recent ViT architectures have explored incorporating additional embeddings beyond traditional positional embeddings. Building on this idea, we integrate Side Information Embedding (SIE) and examine the impact of encoding domain and camera information to enhance cross-spectral matching. Surprisingly, our results show that encoding only camera information - without explicitly incorporating domain information - achieves state-of-the-art performance on the LLCM dataset. While occlusion handling has been extensively studied in visible-spectrum person re-identification (Re-ID), occlusions in visible-infrared (VI) Re-ID remain largely underexplored - primarily because existing VI-ReID datasets, such as LLCM, SYSU-MM01, and RegDB, predominantly feature full-body, unoccluded images. To address this gap, we analyze the impact of range-induced occlusions using the IARPA Janus Benchmark Multi-Domain Face (IJB-MDF) dataset, which provides a diverse set of visible and infrared images captured at various distances, enabling cross-range, cross-spectral evaluations.</li>
</ul>

<h3>Title: Segment Concealed Objects with Incomplete Supervision</h3>
<ul>
<li><strong>Authors: </strong>Chunming He, Kai Li, Yachao Zhang, Ziyun Yang, Youwei Pang, Longxiang Tang, Chengyu Fang, Yulun Zhang, Linghe Kong, Xiu Li, Sina Farsiu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08955">https://arxiv.org/abs/2506.08955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08955">https://arxiv.org/pdf/2506.08955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08955]] Segment Concealed Objects with Incomplete Supervision(https://arxiv.org/abs/2506.08955)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Incompletely-Supervised Concealed Object Segmentation (ISCOS) involves segmenting objects that seamlessly blend into their surrounding environments, utilizing incompletely annotated data, such as weak and semi-annotations, for model training. This task remains highly challenging due to (1) the limited supervision provided by the incompletely annotated training data, and (2) the difficulty of distinguishing concealed objects from the background, which arises from the intrinsic similarities in concealed scenarios. In this paper, we introduce the first unified method for ISCOS to address these challenges. To tackle the issue of incomplete supervision, we propose a unified mean-teacher framework, SEE, that leverages the vision foundation model, ``\emph{Segment Anything Model (SAM)}'', to generate pseudo-labels using coarse masks produced by the teacher model as prompts. To mitigate the effect of low-quality segmentation masks, we introduce a series of strategies for pseudo-label generation, storage, and supervision. These strategies aim to produce informative pseudo-labels, store the best pseudo-labels generated, and select the most reliable components to guide the student model, thereby ensuring robust network training. Additionally, to tackle the issue of intrinsic similarity, we design a hybrid-granularity feature grouping module that groups features at different granularities and aggregates these results. By clustering similar features, this module promotes segmentation coherence, facilitating more complete segmentation for both single-object and multiple-object images. We validate the effectiveness of our approach across multiple ISCOS tasks, and experimental results demonstrate that our method achieves state-of-the-art performance. Furthermore, SEE can serve as a plug-and-play solution, enhancing the performance of existing models.</li>
</ul>

<h3>Title: Towards Robust Deep Reinforcement Learning against Environmental State Perturbation</h3>
<ul>
<li><strong>Authors: </strong>Chenxu Wang, Huaping Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08961">https://arxiv.org/abs/2506.08961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08961">https://arxiv.org/pdf/2506.08961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08961]] Towards Robust Deep Reinforcement Learning against Environmental State Perturbation(https://arxiv.org/abs/2506.08961)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial attacks and robustness in Deep Reinforcement Learning (DRL) have been widely studied in various threat models; however, few consider environmental state perturbations, which are natural in embodied scenarios. To improve the robustness of DRL agents, we formulate the problem of environmental state perturbation, introducing a preliminary non-targeted attack method as a calibration adversary, and then propose a defense framework, named Boosted Adversarial Training (BAT), which first tunes the agents via supervised learning to avoid catastrophic failure and subsequently adversarially trains the agent with reinforcement learning. Extensive experimental results substantiate the vulnerability of mainstream agents under environmental state perturbations and the effectiveness of our proposed attack. The defense results demonstrate that while existing robust reinforcement learning algorithms may not be suitable, our BAT framework can significantly enhance the robustness of agents against environmental state perturbations across various situations.</li>
</ul>

<h3>Title: ORIDa: Object-centric Real-world Image Composition Dataset</h3>
<ul>
<li><strong>Authors: </strong>Jinwoo Kim, Sangmin Han, Jinho Jeong, Jiwoo Choi, Dongyoung Kim, Seon Joo Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08964">https://arxiv.org/abs/2506.08964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08964">https://arxiv.org/pdf/2506.08964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08964]] ORIDa: Object-centric Real-world Image Composition Dataset(https://arxiv.org/abs/2506.08964)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Object compositing, the task of placing and harmonizing objects in images of diverse visual scenes, has become an important task in computer vision with the rise of generative models. However, existing datasets lack the diversity and scale required to comprehensively explore real-world scenarios. We introduce ORIDa (Object-centric Real-world Image Composition Dataset), a large-scale, real-captured dataset containing over 30,000 images featuring 200 unique objects, each of which is presented across varied positions and scenes. ORIDa has two types of data: factual-counterfactual sets and factual-only scenes. The factual-counterfactual sets consist of four factual images showing an object in different positions within a scene and a single counterfactual (or background) image of the scene without the object, resulting in five images per scene. The factual-only scenes include a single image containing an object in a specific context, expanding the variety of environments. To our knowledge, ORIDa is the first publicly available dataset with its scale and complexity for real-world image composition. Extensive analysis and experiments highlight the value of ORIDa as a resource for advancing further research in object compositing.</li>
</ul>

<h3>Title: GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO</h3>
<ul>
<li><strong>Authors: </strong>Yiyang Zhao, Huiyu Bai, Xuejiao Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08965">https://arxiv.org/abs/2506.08965</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08965">https://arxiv.org/pdf/2506.08965</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08965]] GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO(https://arxiv.org/abs/2506.08965)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The ability to train high-performing reward models with few-shot data is critical for enhancing the efficiency and scalability of Reinforcement Learning from Human Feedback (RLHF). We propose a data augmentation and expansion framework that enables generative reward models trained on small datasets to achieve comparable performance to those trained on large-scale datasets. Traditional methods to train a generative reward model, such as Direct Preference Optimization (DPO), are constrained by inefficiencies in sample pairing and limited data diversity. This work introduces preference refinement, which employs Chain-of-Thought (CoT) sampling to uncover diverse and high-quality preference relationships. It also incorporates a perplexity-based scoring mechanism to assign nuanced preference levels and utilizes Multi-level Direct Preference Optimization (M-DPO) to enable the model to capture finer-grained preference differences between samples. Experimental results demonstrate that the proposed method significantly enhances data efficiency and model performance, enabling reward models trained in a few-shot setting to achieve results on par with those trained on large-scale datasets. This study underscores the potential of data-efficient strategies in advancing reward model optimization, offering a robust solution for low-resource RLHF applications.</li>
</ul>

<h3>Title: ADAM: Autonomous Discovery and Annotation Model using LLMs for Context-Aware Annotations</h3>
<ul>
<li><strong>Authors: </strong>Amirreza Rouhi, Solmaz Arezoomandan, Knut Peterson, Joseph T. Woods, David K. Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08968">https://arxiv.org/abs/2506.08968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08968">https://arxiv.org/pdf/2506.08968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08968]] ADAM: Autonomous Discovery and Annotation Model using LLMs for Context-Aware Annotations(https://arxiv.org/abs/2506.08968)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Object detection models typically rely on predefined categories, limiting their ability to identify novel objects in open-world scenarios. To overcome this constraint, we introduce ADAM: Autonomous Discovery and Annotation Model, a training-free, self-refining framework for open-world object labeling. ADAM leverages large language models (LLMs) to generate candidate labels for unknown objects based on contextual information from known entities within a scene. These labels are paired with visual embeddings from CLIP to construct an Embedding-Label Repository (ELR) that enables inference without category supervision. For a newly encountered unknown object, ADAM retrieves visually similar instances from the ELR and applies frequency-based voting and cross-modal re-ranking to assign a robust label. To further enhance consistency, we introduce a self-refinement loop that re-evaluates repository labels using visual cohesion analysis and k-nearest-neighbor-based majority re-labeling. Experimental results on the COCO and PASCAL datasets demonstrate that ADAM effectively annotates novel categories using only visual and contextual signals, without requiring any fine-tuning or retraining.</li>
</ul>

<h3>Title: Atomic-to-Compositional Generalization for Mobile Agents with A New Benchmark and Scheduling System</h3>
<ul>
<li><strong>Authors: </strong>Yuan Guo, Tingjia Miao, Zheng Wu, Pengzhou Cheng, Ming Zhou, Zhuosheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08972">https://arxiv.org/abs/2506.08972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08972">https://arxiv.org/pdf/2506.08972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08972]] Atomic-to-Compositional Generalization for Mobile Agents with A New Benchmark and Scheduling System(https://arxiv.org/abs/2506.08972)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autonomous agents powered by multimodal large language models have been developed to facilitate task execution on mobile devices. However, prior work has predominantly focused on atomic tasks -- such as shot-chain execution tasks and single-screen grounding tasks -- while overlooking the generalization to compositional tasks, which are indispensable for real-world applications. This work introduces UI-NEXUS, a comprehensive benchmark designed to evaluate mobile agents on three categories of compositional operations: Simple Concatenation, Context Transition, and Deep Dive. UI-NEXUS supports interactive evaluation in 20 fully controllable local utility app environments, as well as 30 online Chinese and English service apps. It comprises 100 interactive task templates with an average optimal step count of 14.05. Experimental results across a range of mobile agents with agentic workflow or agent-as-a-model show that UI-NEXUS presents significant challenges. Specifically, existing agents generally struggle to balance performance and efficiency, exhibiting representative failure modes such as under-execution, over-execution, and attention drift, causing visible atomic-to-compositional generalization gap. Inspired by these findings, we propose AGENT-NEXUS, a lightweight and efficient scheduling system to tackle compositional mobile tasks. AGENT-NEXUS extrapolates the abilities of existing mobile agents by dynamically decomposing long-horizon tasks to a series of self-contained atomic subtasks. AGENT-NEXUS achieves 24% to 40% task success rate improvement for existing mobile agents on compositional operation tasks within the UI-NEXUS benchmark without significantly sacrificing inference overhead. The demo video, dataset, and code are available on the project page at this https URL.</li>
</ul>

<h3>Title: Propositional Logic for Probing Generalization in Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Anna Langedijk, Jaap Jumelet, Willem Zuidema</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08978">https://arxiv.org/abs/2506.08978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08978">https://arxiv.org/pdf/2506.08978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08978]] Propositional Logic for Probing Generalization in Neural Networks(https://arxiv.org/abs/2506.08978)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>The extent to which neural networks are able to acquire and represent symbolic rules remains a key topic of research and debate. Much current work focuses on the impressive capabilities of large language models, as well as their often ill-understood failures on a wide range of reasoning tasks. In this paper, in contrast, we investigate the generalization behavior of three key neural architectures (Transformers, Graph Convolution Networks and LSTMs) in a controlled task rooted in propositional logic. The task requires models to generate satisfying assignments for logical formulas, making it a structured and interpretable setting for studying compositionality. We introduce a balanced extension of an existing dataset to eliminate superficial patterns and enable testing on unseen operator combinations. Using this dataset, we evaluate the ability of the three architectures to generalize beyond the training distribution. While all models perform well in-distribution, we find that generalization to unseen patterns, particularly those involving negation, remains a significant challenge. Transformers fail to apply negation compositionally, unless structural biases are introduced. Our findings highlight persistent limitations in the ability of standard architectures to learn systematic representations of logical operators, suggesting the need for stronger inductive biases to support robust rule-based reasoning.</li>
</ul>

<h3>Title: Rethinking Range-View LiDAR Segmentation in Adverse Weather</h3>
<ul>
<li><strong>Authors: </strong>Longyu Yang, Ping Hu, Lu Zhang, Jun Liu, Yap-Peng Tan, Heng Tao Shen, Xiaofeng Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08979">https://arxiv.org/abs/2506.08979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08979">https://arxiv.org/pdf/2506.08979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08979]] Rethinking Range-View LiDAR Segmentation in Adverse Weather(https://arxiv.org/abs/2506.08979)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>LiDAR segmentation has emerged as an important task to enrich multimedia experiences and analysis. Range-view-based methods have gained popularity due to their high computational efficiency and compatibility with real-time deployment. However, their generalized performance under adverse weather conditions remains underexplored, limiting their reliability in real-world environments. In this work, we identify and analyze the unique challenges that affect the generalization of range-view LiDAR segmentation in severe weather. To address these challenges, we propose a modular and lightweight framework that enhances robustness without altering the core architecture of existing models. Our method reformulates the initial stem block of standard range-view networks into two branches to process geometric attributes and reflectance intensity separately. Specifically, a Geometric Abnormality Suppression (GAS) module reduces the influence of weather-induced spatial noise, and a Reflectance Distortion Calibration (RDC) module corrects reflectance distortions through memory-guided adaptive instance normalization. The processed features are then fused and passed to the original segmentation pipeline. Extensive experiments on different benchmarks and baseline models demonstrate that our approach significantly improves generalization to adverse weather with minimal inference overhead, offering a practical and effective solution for real-world LiDAR segmentation.</li>
</ul>

<h3>Title: SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Xiao Liang, Zhong-Zhi Li, Yeyun Gong, Yang Wang, Hengyuan Zhang, Yelong Shen, Ying Nian Wu, Weizhu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08989">https://arxiv.org/abs/2506.08989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08989">https://arxiv.org/pdf/2506.08989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08989]] SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning(https://arxiv.org/abs/2506.08989)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for training large language models (LLMs) on complex reasoning tasks, such as mathematical problem solving. A prerequisite for the scalability of RLVR is a high-quality problem set with precise and verifiable answers. However, the scarcity of well-crafted human-labeled math problems and limited-verification answers in existing distillation-oriented synthetic datasets limit their effectiveness in RL. Additionally, most problem synthesis strategies indiscriminately expand the problem set without considering the model's capabilities, leading to low efficiency in generating useful questions. To mitigate this issue, we introduce a Self-aware Weakness-driven problem Synthesis framework (SwS) that systematically identifies model deficiencies and leverages them for problem augmentation. Specifically, we define weaknesses as questions that the model consistently fails to learn through its iterative sampling during RL training. We then extract the core concepts from these failure cases and synthesize new problems to strengthen the model's weak areas in subsequent augmented training, enabling it to focus on and gradually overcome its weaknesses. Without relying on external knowledge distillation, our framework enables robust generalization byempowering the model to self-identify and address its weaknesses in RL, yielding average performance gains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning benchmarks.</li>
</ul>

<h3>Title: Do Concept Replacement Techniques Really Erase Unacceptable Concepts?</h3>
<ul>
<li><strong>Authors: </strong>Anudeep Das, Gurjot Singh, Prach Chantasantitam, N. Asokan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08991">https://arxiv.org/abs/2506.08991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08991">https://arxiv.org/pdf/2506.08991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08991]] Do Concept Replacement Techniques Really Erase Unacceptable Concepts?(https://arxiv.org/abs/2506.08991)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models, particularly diffusion-based text-to-image (T2I) models, have demonstrated astounding success. However, aligning them to avoid generating content with unacceptable concepts (e.g., offensive or copyrighted content, or celebrity likenesses) remains a significant challenge. Concept replacement techniques (CRTs) aim to address this challenge, often by trying to "erase" unacceptable concepts from models. Recently, model providers have started offering image editing services which accept an image and a text prompt as input, to produce an image altered as specified by the prompt. These are known as image-to-image (I2I) models. In this paper, we first use an I2I model to empirically demonstrate that today's state-of-the-art CRTs do not in fact erase unacceptable concepts. Existing CRTs are thus likely to be ineffective in emerging I2I scenarios, despite their proven ability to remove unwanted concepts in T2I pipelines, highlighting the need to understand this discrepancy between T2I and I2I settings. Next, we argue that a good CRT, while replacing unacceptable concepts, should preserve other concepts specified in the inputs to generative models. We call this fidelity. Prior work on CRTs have neglected fidelity in the case of unacceptable concepts. Finally, we propose the use of targeted image-editing techniques to achieve both effectiveness and fidelity. We present such a technique, AntiMirror, and demonstrate its viability.</li>
</ul>

<h3>Title: Navigating Cookie Consent Violations Across the Globe</h3>
<ul>
<li><strong>Authors: </strong>Brian Tang, Duc Bui, Kang G. Shin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08996">https://arxiv.org/abs/2506.08996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08996">https://arxiv.org/pdf/2506.08996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08996]] Navigating Cookie Consent Violations Across the Globe(https://arxiv.org/abs/2506.08996)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Online services provide users with cookie banners to accept/reject the cookies placed on their web browsers. Despite the increased adoption of cookie banners, little has been done to ensure that cookie consent is compliant with privacy laws around the globe. Prior studies have found that cookies are often placed on browsers even after their explicit rejection by users. These inconsistencies in cookie banner behavior circumvent users' consent preferences and are known as cookie consent violations. To address this important problem, we propose an end-to-end system, called ConsentChk, that detects and analyzes cookie banner behavior. ConsentChk uses a formal model to systematically detect and categorize cookie consent violations. We investigate eight English-speaking regions across the world, and analyze cookie banner behavior across 1,793 globally-popular websites. Cookie behavior, cookie consent violation rates, and cookie banner implementations are found to be highly dependent on region. Our evaluation reveals that consent management platforms (CMPs) and website developers likely tailor cookie banner configurations based on their (often incorrect) interpretations of regional privacy laws. We discuss various root causes behind these cookie consent violations. The resulting implementations produce misleading cookie banners, indicating the prevalence of inconsistently implemented and enforced cookie consent between various regions.</li>
</ul>

<h3>Title: Employing self-supervised learning models for cross-linguistic child speech maturity classification</h3>
<ul>
<li><strong>Authors: </strong>Theo Zhang, Madurya Suresh, Anne S. Warlaumont, Kasia Hitczenko, Alejandrina Cristia, Margaret Cychosz</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.08999">https://arxiv.org/abs/2506.08999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.08999">https://arxiv.org/pdf/2506.08999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.08999]] Employing self-supervised learning models for cross-linguistic child speech maturity classification(https://arxiv.org/abs/2506.08999)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Speech technology systems struggle with many downstream tasks for child speech due to small training corpora and the difficulties that child speech pose. We apply a novel dataset, SpeechMaturity, to state-of-the-art transformer models to address a fundamental classification task: identifying child vocalizations. Unlike previous corpora, our dataset captures maximally ecologically-valid child vocalizations across an unprecedented sample, comprising children acquiring 25+ languages in the U.S., Bolivia, Vanuatu, Papua New Guinea, Solomon Islands, and France. The dataset contains 242,004 labeled vocalizations, magnitudes larger than previous work. Models were trained to distinguish between cry, laughter, mature (consonant+vowel), and immature speech (just consonant or vowel). Models trained on the dataset outperform state-of-the-art models trained on previous datasets, achieved classification accuracy comparable to humans, and were robust across rural and urban settings.</li>
</ul>

<h3>Title: Branched Schrödinger Bridge Matching</h3>
<ul>
<li><strong>Authors: </strong>Sophia Tang, Yinuo Zhang, Alexander Tong, Pranam Chatterjee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09007">https://arxiv.org/abs/2506.09007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09007">https://arxiv.org/pdf/2506.09007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09007]] Branched Schrödinger Bridge Matching(https://arxiv.org/abs/2506.09007)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Predicting the intermediate trajectories between an initial and target distribution is a central problem in generative modeling. Existing approaches, such as flow matching and Schrödinger Bridge Matching, effectively learn mappings between two distributions by modeling a single stochastic path. However, these methods are inherently limited to unimodal transitions and cannot capture branched or divergent evolution from a common origin to multiple distinct outcomes. To address this, we introduce Branched Schrödinger Bridge Matching (BranchSBM), a novel framework that learns branched Schrödinger bridges. BranchSBM parameterizes multiple time-dependent velocity fields and growth processes, enabling the representation of population-level divergence into multiple terminal distributions. We show that BranchSBM is not only more expressive but also essential for tasks involving multi-path surface navigation, modeling cell fate bifurcations from homogeneous progenitor states, and simulating diverging cellular responses to perturbations.</li>
</ul>

<h3>Title: Learning to Reason Across Parallel Samples for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jianing Qi, Xi Ye, Hao Tang, Zhigang Zhu, Eunsol Choi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09014">https://arxiv.org/abs/2506.09014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09014">https://arxiv.org/pdf/2506.09014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09014]] Learning to Reason Across Parallel Samples for LLM Reasoning(https://arxiv.org/abs/2506.09014)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scaling test-time compute brings substantial performance gains for large language models (LLMs). By sampling multiple answers and heuristically aggregate their answers (e.g., either through majority voting or using verifiers to rank the answers), one can achieve consistent performance gains in math domains. In this paper, we propose a new way to leverage such multiple sample set. We train a compact LLM, called Sample Set Aggregator (SSA), that takes a concatenated sequence of multiple samples and output the final answer, optimizing it for the answer accuracy with reinforcement learning. Experiments on multiple reasoning datasets show that SSA outperforms other test-time scaling methods such as reward model-based re-ranking. Our approach also shows a promising generalization ability, across sample set sizes, base model families and scales, and tasks. By separating LLMs to generate answers and LLMs to analyze and aggregate sampled answers, our approach can work with the outputs from premier black box models easily and efficiently.</li>
</ul>

<h3>Title: SPEED-RL: Faster Training of Reasoning Models via Online Curriculum Learning</h3>
<ul>
<li><strong>Authors: </strong>Ruiqi Zhang, Daman Arora, Song Mei, Andrea Zanette</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09016">https://arxiv.org/abs/2506.09016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09016">https://arxiv.org/pdf/2506.09016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09016]] SPEED-RL: Faster Training of Reasoning Models via Online Curriculum Learning(https://arxiv.org/abs/2506.09016)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training large language models with reinforcement learning (RL) against verifiable rewards significantly enhances their reasoning abilities, yet remains computationally expensive due to inefficient uniform prompt sampling. We introduce Selective Prompting with Efficient Estimation of Difficulty (SPEED), an adaptive online RL curriculum that selectively chooses training examples of intermediate difficulty to maximize learning efficiency. Theoretically, we establish that intermediate-difficulty prompts improve the gradient estimator's signal-to-noise ratio, accelerating convergence. Empirically, our efficient implementation leads to 2x to 6x faster training without degrading accuracy, requires no manual tuning, and integrates seamlessly into standard RL algorithms.</li>
</ul>

<h3>Title: Edit Flows: Flow Matching with Edit Operations</h3>
<ul>
<li><strong>Authors: </strong>Marton Havasi, Brian Karrer, Itai Gat, Ricky T. Q. Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09018">https://arxiv.org/abs/2506.09018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09018">https://arxiv.org/pdf/2506.09018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09018]] Edit Flows: Flow Matching with Edit Operations(https://arxiv.org/abs/2506.09018)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Autoregressive generative models naturally generate variable-length sequences, while non-autoregressive models struggle, often imposing rigid, token-wise structures. We propose Edit Flows, a non-autoregressive model that overcomes these limitations by defining a discrete flow over sequences through edit operations-insertions, deletions, and substitutions. By modeling these operations within a Continuous-time Markov Chain over the sequence space, Edit Flows enable flexible, position-relative generation that aligns more closely with the structure of sequence data. Our training method leverages an expanded state space with auxiliary variables, making the learning process efficient and tractable. Empirical results show that Edit Flows outperforms both autoregressive and mask models on image captioning and significantly outperforms the mask construction in text and code generation.</li>
</ul>

<h3>Title: Comparing human and LLM proofreading in L2 writing: Impact on lexical and syntactic features</h3>
<ul>
<li><strong>Authors: </strong>Hakyung Sung, Karla Csuros, Min-Chang Sung</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09021">https://arxiv.org/abs/2506.09021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09021">https://arxiv.org/pdf/2506.09021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09021]] Comparing human and LLM proofreading in L2 writing: Impact on lexical and syntactic features(https://arxiv.org/abs/2506.09021)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This study examines the lexical and syntactic interventions of human and LLM proofreading aimed at improving overall intelligibility in identical second language writings, and evaluates the consistency of outcomes across three LLMs (ChatGPT-4o, Llama3.1-8b, Deepseek-r1-8b). Findings show that both human and LLM proofreading enhance bigram lexical features, which may contribute to better coherence and contextual connectedness between adjacent words. However, LLM proofreading exhibits a more generative approach, extensively reworking vocabulary and sentence structures, such as employing more diverse and sophisticated vocabulary and incorporating a greater number of adjective modifiers in noun phrases. The proofreading outcomes are highly consistent in major lexical and syntactic features across the three models.</li>
</ul>

<h3>Title: Do MIL Models Transfer?</h3>
<ul>
<li><strong>Authors: </strong>Daniel Shao, Richard J. Chen, Andrew H. Song, Joel Runevic, Ming Y. Lu, Tong Ding, Faisal Mahmood</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09022">https://arxiv.org/abs/2506.09022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09022">https://arxiv.org/pdf/2506.09022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09022]] Do MIL Models Transfer?(https://arxiv.org/abs/2506.09022)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multiple Instance Learning (MIL) is a cornerstone approach in computational pathology (CPath) for generating clinically meaningful slide-level embeddings from gigapixel tissue images. However, MIL often struggles with small, weakly supervised clinical datasets. In contrast to fields such as NLP and conventional computer vision, where transfer learning is widely used to address data scarcity, the transferability of MIL models remains poorly understood. In this study, we systematically evaluate the transfer learning capabilities of pretrained MIL models by assessing 11 models across 21 pretraining tasks for morphological and molecular subtype prediction. Our results show that pretrained MIL models, even when trained on different organs than the target task, consistently outperform models trained from scratch. Moreover, pretraining on pancancer datasets enables strong generalization across organs and tasks, outperforming slide foundation models while using substantially less pretraining data. These findings highlight the robust adaptability of MIL models and demonstrate the benefits of leveraging transfer learning to boost performance in CPath. Lastly, we provide a resource which standardizes the implementation of MIL models and collection of pretrained model weights on popular CPath tasks, available at this https URL</li>
</ul>

<h3>Title: DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Felix Wagner, Pramit Saha, Harry Anthony, J. Alison Noble, Konstantinos Kamnitsas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09024">https://arxiv.org/abs/2506.09024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09024">https://arxiv.org/pdf/2506.09024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09024]] DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging(https://arxiv.org/abs/2506.09024)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Safe deployment of machine learning (ML) models in safety-critical domains such as medical imaging requires detecting inputs with characteristics not seen during training, known as out-of-distribution (OOD) detection, to prevent unreliable predictions. Effective OOD detection after deployment could benefit from access to the training data, enabling direct comparison between test samples and the training data distribution to identify differences. State-of-the-art OOD detection methods, however, either discard training data after deployment or assume that test samples and training data are centrally stored together, an assumption that rarely holds in real-world settings. This is because shipping training data with the deployed model is usually impossible due to the size of training databases, as well as proprietary or privacy constraints. We introduce the Isolation Network, an OOD detection framework that quantifies the difficulty of separating a target test sample from the training data by solving a binary classification task. We then propose Decentralized Isolation Networks (DIsoN), which enables the comparison of training and test data when data-sharing is impossible, by exchanging only model parameters between the remote computational nodes of training and deployment. We further extend DIsoN with class-conditioning, comparing a target sample solely with training data of its predicted class. We evaluate DIsoN on four medical imaging datasets (dermatology, chest X-ray, breast ultrasound, histopathology) across 12 OOD detection tasks. DIsoN performs favorably against existing methods while respecting data-privacy. This decentralized OOD detection framework opens the way for a new type of service that ML developers could provide along with their models: providing remote, secure utilization of their training data for OOD detection services. Code will be available upon acceptance at: *****</li>
</ul>

<h3>Title: Diffuse and Disperse: Image Generation with Representation Regularization</h3>
<ul>
<li><strong>Authors: </strong>Runqian Wang, Kaiming He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09027">https://arxiv.org/abs/2506.09027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09027">https://arxiv.org/pdf/2506.09027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09027]] Diffuse and Disperse: Image Generation with Representation Regularization(https://arxiv.org/abs/2506.09027)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The development of diffusion-based generative models over the past decade has largely proceeded independently of progress in representation learning. These diffusion models typically rely on regression-based objectives and generally lack explicit regularization. In this work, we propose \textit{Dispersive Loss}, a simple plug-and-play regularizer that effectively improves diffusion-based generative models. Our loss function encourages internal representations to disperse in the hidden space, analogous to contrastive self-supervised learning, with the key distinction that it requires no positive sample pairs and therefore does not interfere with the sampling process used for regression. Compared to the recent method of representation alignment (REPA), our approach is self-contained and minimalist, requiring no pre-training, no additional parameters, and no external data. We evaluate Dispersive Loss on the ImageNet dataset across a range of models and report consistent improvements over widely used and strong baselines. We hope our work will help bridge the gap between generative modeling and representation learning.</li>
</ul>

<h3>Title: Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Haozhen Zhang, Tao Feng, Jiaxuan You</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09033">https://arxiv.org/abs/2506.09033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09033">https://arxiv.org/pdf/2506.09033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09033]] Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning(https://arxiv.org/abs/2506.09033)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid emergence of diverse large language models (LLMs) has spurred the development of LLM routers that assign user queries to the most suitable model. However, existing LLM routers typically perform a single-round, one-to-one mapping (\textit{i.e.}, assigning each query to a single model in isolation), which limits their capability to tackle complex tasks that demand the complementary strengths of multiple LLMs. In this paper, we present \textbf{Router-R1}, a reinforcement learning (RL)-based framework that formulates multi-LLM routing and aggregation as a sequential decision process. Router-R1 instantiates the router itself as a capable LLM, leveraging its reasoning ability to interleave "think" actions (internal deliberation) with "route" actions (dynamic model invocation), and integrates each response into its evolving context. To guide learning, we employ a lightweight rule-based reward comprising format rewards, final outcome rewards, and a novel cost reward for performance and cost trade-off optimization, opening a pathway toward optimizing performance-cost tradeoffs via RL. Router-R1 also conditions only on simple model descriptors such as pricing, latency, and example performance, enabling strong generalization to unseen model selection. Experiments on seven general and multi-hop QA benchmarks show that Router-R1 outperforms over several strong baselines, achieving superior performance while maintaining robust generalization and cost this http URL is available at this https URL.</li>
</ul>

<h3>Title: FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed</h3>
<ul>
<li><strong>Authors: </strong>Sizhe Dang, Yangyang Guo, Yanjun Zhao, Haishan Ye, Xiaodong Zheng, Guang Dai, Ivor Tsang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09034">https://arxiv.org/abs/2506.09034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09034">https://arxiv.org/pdf/2506.09034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09034]] FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed(https://arxiv.org/abs/2506.09034)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks: the backward pass of first-order optimizers like Adam increases memory usage to more than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order (ZO) optimizers avoid this cost by estimating gradients only from forward passes, yet existing methods like MeZO usually require many more steps to converge. Can this trade-off between speed and memory in ZO be fundamentally improved? Normalized-SGD demonstrates strong empirical performance with greater memory efficiency than Adam. In light of this, we introduce FZOO, a Fast Zeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward passes needed for convergence by employing batched one-sided estimates that adapt step sizes based on the standard deviation of batch losses. It also accelerates per-batch computation through the use of Rademacher random vector perturbations coupled with CUDA's parallel processing. Extensive experiments on diverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3, across 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms MeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For RoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy and an 18 times reduction in forward passes compared to MeZO, achieving convergence speeds comparable to Adam. We also provide theoretical analysis proving FZOO's formal equivalence to a normalized-SGD update rule and its convergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling even larger memory savings. Overall, our results make single-GPU, high-speed, full-parameter fine-tuning practical and point toward future work on memory-efficient pre-training.</li>
</ul>

<h3>Title: MagCache: Fast Video Generation with Magnitude-Aware Cache</h3>
<ul>
<li><strong>Authors: </strong>Zehong Ma, Longhui Wei, Feng Wang, Shiliang Zhang, Qi Tian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09045">https://arxiv.org/abs/2506.09045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09045">https://arxiv.org/pdf/2506.09045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09045]] MagCache: Fast Video Generation with Magnitude-Aware Cache(https://arxiv.org/abs/2506.09045)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Existing acceleration techniques for video diffusion models often rely on uniform heuristics or time-embedding variants to skip timesteps and reuse cached features. These approaches typically require extensive calibration with curated prompts and risk inconsistent outputs due to prompt-specific overfitting. In this paper, we introduce a novel and robust discovery: a unified magnitude law observed across different models and prompts. Specifically, the magnitude ratio of successive residual outputs decreases monotonically and steadily in most timesteps while rapidly in the last several steps. Leveraging this insight, we introduce a Magnitude-aware Cache (MagCache) that adaptively skips unimportant timesteps using an error modeling mechanism and adaptive caching strategy. Unlike existing methods requiring dozens of curated samples for calibration, MagCache only requires a single sample for calibration. Experimental results show that MagCache achieves 2.1x and 2.68x speedups on Open-Sora and Wan 2.1, respectively, while preserving superior visual fidelity. It significantly outperforms existing methods in LPIPS, SSIM, and PSNR, under comparable computational budgets.</li>
</ul>

<h3>Title: Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation</h3>
<ul>
<li><strong>Authors: </strong>Xiaowen Ma, Chenyang Lin, Yao Zhang, Volker Tresp, Yunpu Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09046">https://arxiv.org/abs/2506.09046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09046">https://arxiv.org/pdf/2506.09046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09046]] Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation(https://arxiv.org/abs/2506.09046)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Leveraging multiple Large Language Models(LLMs) has proven effective for addressing complex, high-dimensional tasks, but current approaches often rely on static, manually engineered multi-agent configurations. To overcome these constraints, we present the Agentic Neural Network(ANN), a framework that conceptualizes multi-agent collaboration as a layered neural network architecture. In this design, each agent operates as a node, and each layer forms a cooperative "team" focused on a specific subtask. Agentic Neural Network follows a two-phase optimization strategy: (1) Forward Phase-Drawing inspiration from neural network forward passes, tasks are dynamically decomposed into subtasks, and cooperative agent teams with suitable aggregation methods are constructed layer by layer. (2) Backward Phase-Mirroring backpropagation, we refine both global and local collaboration through iterative feedback, allowing agents to self-evolve their roles, prompts, and coordination. This neuro-symbolic approach enables ANN to create new or specialized agent teams post-training, delivering notable gains in accuracy and adaptability. Across four benchmark datasets, ANN surpasses leading multi-agent baselines under the same configurations, showing consistent performance improvements. Our findings indicate that ANN provides a scalable, data-driven framework for multi-agent systems, combining the collaborative capabilities of LLMs with the efficiency and flexibility of neural network principles. We plan to open-source the entire framework.</li>
</ul>

<h3>Title: Understanding Task Vectors in In-Context Learning: Emergence, Functionality, and Limitations</h3>
<ul>
<li><strong>Authors: </strong>Yuxin Dong, Jiachen Jiang, Zhihui Zhu, Xia Ning</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.09048">https://arxiv.org/abs/2506.09048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.09048">https://arxiv.org/pdf/2506.09048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.09048]] Understanding Task Vectors in In-Context Learning: Emergence, Functionality, and Limitations(https://arxiv.org/abs/2506.09048)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Task vectors offer a compelling mechanism for accelerating inference in in-context learning (ICL) by distilling task-specific information into a single, reusable representation. Despite their empirical success, the underlying principles governing their emergence and functionality remain unclear. This work proposes the Linear Combination Conjecture, positing that task vectors act as single in-context demonstrations formed through linear combinations of the original ones. We provide both theoretical and empirical support for this conjecture. First, we show that task vectors naturally emerge in linear transformers trained on triplet-formatted prompts through loss landscape analysis. Next, we predict the failure of task vectors on representing high-rank mappings and confirm this on practical LLMs. Our findings are further validated through saliency analyses and parameter visualization, suggesting an enhancement of task vectors by injecting multiple ones into few-shot prompts. Together, our results advance the understanding of task vectors and shed light on the mechanisms underlying ICL in transformer-based models.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
