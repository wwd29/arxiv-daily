<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-04-30</h1>
<h3>Title: It's the same but not the same: Do LLMs distinguish Spanish varieties?</h3>
<ul>
<li><strong>Authors: </strong>Marina Mayor-Rocher, Cristina Pozo, Nina Melero, Gonzalo Martínez, María Grandury, Pedro Reviriego</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20049">https://arxiv.org/abs/2504.20049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20049">https://arxiv.org/pdf/2504.20049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20049]] It's the same but not the same: Do LLMs distinguish Spanish varieties?(https://arxiv.org/abs/2504.20049)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, large language models (LLMs) have demonstrated a high capacity for understanding and generating text in Spanish. However, with five hundred million native speakers, Spanish is not a homogeneous language but rather one rich in diatopic variations spanning both sides of the Atlantic. For this reason, in this study, we evaluate the ability of nine language models to identify and distinguish the morphosyntactic and lexical peculiarities of seven varieties of Spanish (Andean, Antillean, Continental Caribbean, Chilean, Peninsular, Mexican and Central American and Rioplatense) through a multiple-choice test. The results indicate that the Peninsular Spanish variety is the best identified by all models and that, among them, GPT-4o is the only model capable of recognizing the variability of the Spanish language. -- En los últimos años, los grandes modelos de lenguaje (LLMs, por sus siglas en inglés) han demostrado una alta capacidad para comprender y generar texto en español. Sin embargo, con quinientos millones de hablantes nativos, la española no es una lengua homogénea, sino rica en variedades diatópicas que se extienden a ambos lados del Atlántico. Por todo ello, evaluamos en este trabajo la capacidad de nueve modelos de lenguaje de identificar y discernir las peculiaridades morfosintácticas y léxicas de siete variedades de español (andino, antillano, caribeño continental, chileno, español peninsular, mexicano y centroamericano y rioplatense) mediante un test de respuesta múltiple. Los resultados obtenidos indican que la variedad de español peninsular es la mejor identificada por todos los modelos y que, de entre todos, GPT-4o es el único modelo capaz de identificar la variabilidad de la lengua española.</li>
</ul>

<h3>Title: Multi-Party Private Set Operations from Predicative Zero-Sharing</h3>
<ul>
<li><strong>Authors: </strong>Minglang Dong, Yu Chen, Cong Zhang, Yujie Bai, Yang Cao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20050">https://arxiv.org/abs/2504.20050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20050">https://arxiv.org/pdf/2504.20050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20050]] Multi-Party Private Set Operations from Predicative Zero-Sharing(https://arxiv.org/abs/2504.20050)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Typical protocols in the multi-party private set operations (MPSO) setting enable m > 2 parties to perform certain secure computation on the intersection or union of their private sets, realizing a very limited range of MPSO functionalities. Most works in this field focus on just one or two specific functionalities, resulting in a large variety of isolated schemes and a lack of a unified framework in MPSO research. In this work, we present an MPSO framework, which allows m parties, each holding a set, to securely compute any set formulas (arbitrary compositions of a finite number of binary set operations, including intersection, union and difference) on their private sets. Our framework is highly versatile and can be instantiated to accommodate a broad spectrum of MPSO functionalities. To the best of our knowledge, this is the first framework to achieve such a level of flexibility and generality in MPSO, without relying on generic secure multi-party computation (MPC) techniques. Our framework exhibits favorable theoretical and practical performance. The computation and communication complexity scale linearly with the set size n, and it achieves optimal complexity that is on par with the naive solution for widely used functionalities, such as multi-party private set intersection (MPSI), MPSI with cardinality output (MPSI-card), and MPSI with cardinality and sum (MPSI-card-sum), in the standard semi-honest model. Furthermore, the instantiations of our framework mainly from symmetric-key techniques yield efficient protocols for MPSI, MPSI-card, MPSI-card-sum, and multi-party private set union (MPSU), with online performance surpassing or matching the state of the art.</li>
</ul>

<h3>Title: Evaluating Large Language Models on Multiword Expressions in Multilingual and Code-Switched Contexts</h3>
<ul>
<li><strong>Authors: </strong>Frances Laureano De Leon, Harish Tayyar Madabushi, Mark G. Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20051">https://arxiv.org/abs/2504.20051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20051">https://arxiv.org/pdf/2504.20051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20051]] Evaluating Large Language Models on Multiword Expressions in Multilingual and Code-Switched Contexts(https://arxiv.org/abs/2504.20051)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multiword expressions, characterised by non-compositional meanings and syntactic irregularities, are an example of nuanced language. These expressions can be used literally or idiomatically, leading to significant changes in meaning. While large language models have demonstrated strong performance across many tasks, their ability to handle such linguistic subtleties remains uncertain. Therefore, this study evaluates how state-of-the-art language models process the ambiguity of potentially idiomatic multiword expressions, particularly in contexts that are less frequent, where models are less likely to rely on memorisation. By evaluating models across in Portuguese and Galician, in addition to English, and using a novel code-switched dataset and a novel task, we find that large language models, despite their strengths, struggle with nuanced language. In particular, we find that the latest models, including GPT-4, fail to outperform the xlm-roBERTa-base baselines in both detection and semantic tasks, with especially poor performance on the novel tasks we introduce, despite its similarity to existing tasks. Overall, our results demonstrate that multiword expressions, especially those which are ambiguous, continue to be a challenge to models.</li>
</ul>

<h3>Title: Marmot: Multi-Agent Reasoning for Multi-Object Self-Correcting in Improving Image-Text Alignment</h3>
<ul>
<li><strong>Authors: </strong>Jiayang Sun, Hongbo Wang, Jie Cao, Huaibo Huang, Ran He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20054">https://arxiv.org/abs/2504.20054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20054">https://arxiv.org/pdf/2504.20054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20054]] Marmot: Multi-Agent Reasoning for Multi-Object Self-Correcting in Improving Image-Text Alignment(https://arxiv.org/abs/2504.20054)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While diffusion models excel at generating high-quality images, they often struggle with accurate counting, attributes, and spatial relationships in complex multi-object scenes. To address these challenges, we propose Marmot, a novel and generalizable framework that employs Multi-Agent Reasoning for Multi-Object Self-Correcting, enhancing image-text alignment and facilitating more coherent multi-object image editing. Our framework adopts a divide-and-conquer strategy that decomposes the self-correction task into three critical dimensions (counting, attributes, and spatial relationships), and further divided into object-level subtasks. We construct a multi-agent editing system featuring a decision-execution-verification mechanism, effectively mitigating inter-object interference and enhancing editing reliability. To resolve the problem of subtask integration, we propose a Pixel-Domain Stitching Smoother that employs mask-guided two-stage latent space optimization. This innovation enables parallel processing of subtask results, thereby enhancing runtime efficiency while eliminating multi-stage distortion accumulation. Extensive experiments demonstrate that Marmot significantly improves accuracy in object counting, attribute assignment, and spatial relationships for image generation tasks.</li>
</ul>

<h3>Title: A constraints-based approach to fully interpretable neural networks for detecting learner behaviors</h3>
<ul>
<li><strong>Authors: </strong>Juan D. Pinto, Luc Paquette</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20055">https://arxiv.org/abs/2504.20055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20055">https://arxiv.org/pdf/2504.20055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20055]] A constraints-based approach to fully interpretable neural networks for detecting learner behaviors(https://arxiv.org/abs/2504.20055)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>The increasing use of complex machine learning models in education has led to concerns about their interpretability, which in turn has spurred interest in developing explainability techniques that are both faithful to the model's inner workings and intelligible to human end-users. In this paper, we describe a novel approach to creating a neural-network-based behavior detection model that is interpretable by design. Our model is fully interpretable, meaning that the parameters we extract for our explanations have a clear interpretation, fully capture the model's learned knowledge about the learner behavior of interest, and can be used to create explanations that are both faithful and intelligible. We achieve this by implementing a series of constraints to the model that both simplify its inference process and bring it closer to a human conception of the task at hand. We train the model to detect gaming-the-system behavior, evaluate its performance on this task, and compare its learned patterns to those identified by human experts. Our results show that the model is successfully able to learn patterns indicative of gaming-the-system behavior while providing evidence for fully interpretable explanations. We discuss the implications of our approach and suggest ways to evaluate explainability using a human-grounded approach.</li>
</ul>

<h3>Title: RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, Eli Gottlieb, Monica Lam, Yiping Lu, Kyunghyun Cho, Jiajun Wu, Li Fei-Fei, Lijuan Wang, Yejin Choi, Manling Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20073">https://arxiv.org/abs/2504.20073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20073">https://arxiv.org/pdf/2504.20073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20073]] RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning(https://arxiv.org/abs/2504.20073)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training large language models (LLMs) as interactive agents presents unique challenges including long-horizon decision making and interacting with stochastic environment feedback. While reinforcement learning (RL) has enabled progress in static tasks, multi-turn agent RL training remains underexplored. We propose StarPO (State-Thinking-Actions-Reward Policy Optimization), a general framework for trajectory-level agent RL, and introduce RAGEN, a modular system for training and evaluating LLM agents. Our study on three stylized environments reveals three core findings. First, our agent RL training shows a recurring mode of Echo Trap where reward variance cliffs and gradient spikes; we address this with StarPO-S, a stabilized variant with trajectory filtering, critic incorporation, and decoupled clipping. Second, we find the shaping of RL rollouts would benefit from diverse initial states, medium interaction granularity and more frequent sampling. Third, we show that without fine-grained, reasoning-aware reward signals, agent reasoning hardly emerge through multi-turn RL and they may show shallow strategies or hallucinated thoughts. Code and environments are available at this https URL.</li>
</ul>

<h3>Title: Edge-Based Learning for Improved Classification Under Adversarial Noise</h3>
<ul>
<li><strong>Authors: </strong>Manish Kansana, Keyan Alexander Rahimi, Elias Hossain, Iman Dehzangi, Noorbakhsh Amiri Golilarz</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20077">https://arxiv.org/abs/2504.20077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20077">https://arxiv.org/pdf/2504.20077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20077]] Edge-Based Learning for Improved Classification Under Adversarial Noise(https://arxiv.org/abs/2504.20077)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial noise introduces small perturbations in images, misleading deep learning models into misclassification and significantly impacting recognition accuracy. In this study, we analyzed the effects of Fast Gradient Sign Method (FGSM) adversarial noise on image classification and investigated whether training on specific image features can improve robustness. We hypothesize that while adversarial noise perturbs various regions of an image, edges may remain relatively stable and provide essential structural information for classification. To test this, we conducted a series of experiments using brain tumor and COVID datasets. Initially, we trained the models on clean images and then introduced subtle adversarial perturbations, which caused deep learning models to significantly misclassify the images. Retraining on a combination of clean and noisy images led to improved performance. To evaluate the robustness of the edge features, we extracted edges from the original/clean images and trained the models exclusively on edge-based representations. When noise was introduced to the images, the edge-based models demonstrated greater resilience to adversarial attacks compared to those trained on the original or clean images. These results suggest that while adversarial noise is able to exploit complex non-edge regions significantly more than edges, the improvement in the accuracy after retraining is marginally more in the original data as compared to the edges. Thus, leveraging edge-based learning can improve the resilience of deep learning models against adversarial perturbations.</li>
</ul>

<h3>Title: Understanding and Mitigating Risks of Generative AI in Financial Services</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Gehrmann, Claire Huang, Xian Teng, Sergei Yurovski, Iyanuoluwa Shode, Chirag S. Patel, Arjun Bhorkar, Naveen Thomas, John Doucette, David Rosenberg, Mark Dredze, David Rabinowitz</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20086">https://arxiv.org/abs/2504.20086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20086">https://arxiv.org/pdf/2504.20086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20086]] Understanding and Mitigating Risks of Generative AI in Financial Services(https://arxiv.org/abs/2504.20086)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>To responsibly develop Generative AI (GenAI) products, it is critical to define the scope of acceptable inputs and outputs. What constitutes a "safe" response is an actively debated question. Academic work puts an outsized focus on evaluating models by themselves for general purpose aspects such as toxicity, bias, and fairness, especially in conversational applications being used by a broad audience. In contrast, less focus is put on considering sociotechnical systems in specialized domains. Yet, those specialized systems can be subject to extensive and well-understood legal and regulatory scrutiny. These product-specific considerations need to be set in industry-specific laws, regulations, and corporate governance requirements. In this paper, we aim to highlight AI content safety considerations specific to the financial services domain and outline an associated AI content risk taxonomy. We compare this taxonomy to existing work in this space and discuss implications of risk category violations on various stakeholders. We evaluate how existing open-source technical guardrail solutions cover this taxonomy by assessing them on data collected via red-teaming activities. Our results demonstrate that these guardrails fail to detect most of the content risks we discuss.</li>
</ul>

<h3>Title: Towards Practical Second-Order Optimizers in Deep Learning: Insights from Fisher Information Analysis</h3>
<ul>
<li><strong>Authors: </strong>Damien Martins Gomes</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20096">https://arxiv.org/abs/2504.20096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20096">https://arxiv.org/pdf/2504.20096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20096]] Towards Practical Second-Order Optimizers in Deep Learning: Insights from Fisher Information Analysis(https://arxiv.org/abs/2504.20096)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>First-order optimization methods remain the standard for training deep neural networks (DNNs). Optimizers like Adam incorporate limited curvature information by preconditioning the stochastic gradient with a diagonal matrix. Despite the widespread adoption of first-order methods, second-order optimization algorithms often exhibit superior convergence compared to methods like Adam and SGD. However, their practicality in training DNNs is still limited by a significantly higher per-iteration computational cost compared to first-order methods. In this thesis, we present AdaFisher, a novel adaptive second-order optimizer that leverages a diagonal block-Kronecker approximation of the Fisher information matrix to adaptively precondition gradients. AdaFisher aims to bridge the gap between the improved convergence and generalization of second-order methods and the computational efficiency needed for training DNNs. Despite the traditionally slower speed of second-order optimizers, AdaFisher is effective for tasks such as image classification and language modeling, ex- hibiting remarkable stability and robustness during hyperparameter tuning. We demonstrate that AdaFisher outperforms state-of-the-art optimizers in both accuracy and convergence speed. The code is available from this https URL.</li>
</ul>

<h3>Title: Long-Distance Field Demonstration of Imaging-Free Drone Identification in Intracity Environments</h3>
<ul>
<li><strong>Authors: </strong>Junran Guo, Tonglin Mu, Keyuan Li, Jianing Li, Ziyang Luo, Ye Chen, Xiaodong Fan, Jinquan Huang, Minjie Liu, Jinbei Zhang, Ruoyang Qi, Naiting Gu, Shihai Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20097">https://arxiv.org/abs/2504.20097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20097">https://arxiv.org/pdf/2504.20097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20097]] Long-Distance Field Demonstration of Imaging-Free Drone Identification in Intracity Environments(https://arxiv.org/abs/2504.20097)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Detecting small objects, such as drones, over long distances presents a significant challenge with broad implications for security, surveillance, environmental monitoring, and autonomous systems. Traditional imaging-based methods rely on high-resolution image acquisition, but are often constrained by range, power consumption, and cost. In contrast, data-driven single-photon-single-pixel light detection and ranging (\text{D\textsuperscript{2}SP\textsuperscript{2}-LiDAR}) provides an imaging-free alternative, directly enabling target identification while reducing system complexity and cost. However, its detection range has been limited to a few hundred meters. Here, we introduce a novel integration of residual neural networks (ResNet) with \text{D\textsuperscript{2}SP\textsuperscript{2}-LiDAR}, incorporating a refined observation model to extend the detection range to 5~\si{\kilo\meter} in an intracity environment while enabling high-accuracy identification of drone poses and types. Experimental results demonstrate that our approach not only outperforms conventional imaging-based recognition systems, but also achieves 94.93\% pose identification accuracy and 97.99\% type classification accuracy, even under weak signal conditions with long distances and low signal-to-noise ratios (SNRs). These findings highlight the potential of imaging-free methods for robust long-range detection of small targets in real-world scenarios.</li>
</ul>

<h3>Title: Decoding Latent Spaces: Assessing the Interpretability of Time Series Foundation Models for Visual Analytics</h3>
<ul>
<li><strong>Authors: </strong>Inmaculada Santamaria-Valenzuela, Victor Rodriguez-Fernandez, Javier Huertas-Tato, Jong Hyuk Park, David Camacho</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20099">https://arxiv.org/abs/2504.20099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20099">https://arxiv.org/pdf/2504.20099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20099]] Decoding Latent Spaces: Assessing the Interpretability of Time Series Foundation Models for Visual Analytics(https://arxiv.org/abs/2504.20099)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>The present study explores the interpretability of latent spaces produced by time series foundation models, focusing on their potential for visual analysis tasks. Specifically, we evaluate the MOMENT family of models, a set of transformer-based, pre-trained architectures for multivariate time series tasks such as: imputation, prediction, classification, and anomaly detection. We evaluate the capacity of these models on five datasets to capture the underlying structures in time series data within their latent space projection and validate whether fine tuning improves the clarity of the resulting embedding spaces. Notable performance improvements in terms of loss reduction were observed after fine tuning. Visual analysis shows limited improvement in the interpretability of the embeddings, requiring further work. Results suggest that, although Time Series Foundation Models such as MOMENT are robust, their latent spaces may require additional methodological refinements to be adequately interpreted, such as alternative projection techniques, loss functions, or data preprocessing strategies. Despite the limitations of MOMENT, foundation models supose a big reduction in execution time and so a great advance for interactive visual analytics.</li>
</ul>

<h3>Title: HyboWaveNet: Hyperbolic Graph Neural Networks with Multi-Scale Wavelet Transform for Protein-Protein Interaction Prediction</h3>
<ul>
<li><strong>Authors: </strong>Qingzhi Yu, Shuai Yan, Wenfeng Dai, Xiang Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20102">https://arxiv.org/abs/2504.20102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20102">https://arxiv.org/pdf/2504.20102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20102]] HyboWaveNet: Hyperbolic Graph Neural Networks with Multi-Scale Wavelet Transform for Protein-Protein Interaction Prediction(https://arxiv.org/abs/2504.20102)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Protein-protein interactions (PPIs) are fundamental for deciphering cellular functions,disease pathways,and drug this http URL existing neural networks and machine learning methods have achieved high accuracy in PPI prediction,their black-box nature leads to a lack of causal interpretation of the prediction results and difficulty in capturing hierarchical geometries and multi-scale dynamic interaction patterns among this http URL address these challenges, we propose HyboWaveNet,a novel deep learning framework that collaborates with hyperbolic graphical neural networks (HGNNs) and multiscale graphical wavelet transform for robust PPI prediction. Mapping protein features to Lorentz space simulates hierarchical topological relationships among biomolecules via a hyperbolic distance metric,enabling node feature representations that better fit biological a this http URL inherently simulates hierarchical and scale-free biological relationships, while the integration of wavelet transforms enables adaptive extraction of local and global interaction features across different resolutions. Our framework generates node feature representations via a graph neural network under the Lorenz model and generates pairs of positive samples under multiple different views for comparative learning, followed by further feature extraction via multi-scale graph wavelet transforms to predict potential PPIs. Experiments on public datasets show that HyboWaveNet improves over both existing state-of-the-art methods. We also demonstrate through ablation experimental studies that the multi-scale graph wavelet transform module improves the predictive performance and generalization ability of HyboWaveNet. This work links geometric deep learning and signal processing to advance PPI prediction, providing a principled approach for analyzing complex biological systems</li>
</ul>

<h3>Title: An on-production high-resolution longitudinal neonatal fingerprint database in Brazil</h3>
<ul>
<li><strong>Authors: </strong>Luiz F. P. Southier, Marcelo Filipak, Luiz A. Zanlorensi, Ildefonso Wasilevski, Fabio Favarim, Jefferson T. Oliva, Marcelo Teixeira, Dalcimar Casanova</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20104">https://arxiv.org/abs/2504.20104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20104">https://arxiv.org/pdf/2504.20104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20104]] An on-production high-resolution longitudinal neonatal fingerprint database in Brazil(https://arxiv.org/abs/2504.20104)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, biometric</a></li>
<li><strong>Abstract: </strong>The neonatal period is critical for survival, requiring accurate and early identification to enable timely interventions such as vaccinations, HIV treatment, and nutrition programs. Biometric solutions offer potential for child protection by helping to prevent baby swaps, locate missing children, and support national identity systems. However, developing effective biometric identification systems for newborns remains a major challenge due to the physiological variability caused by finger growth, weight changes, and skin texture alterations during early development. Current literature has attempted to address these issues by applying scaling factors to emulate growth-induced distortions in minutiae maps, but such approaches fail to capture the complex and non-linear growth patterns of infants. A key barrier to progress in this domain is the lack of comprehensive, longitudinal biometric datasets capturing the evolution of neonatal fingerprints over time. This study addresses this gap by focusing on designing and developing a high-quality biometric database of neonatal fingerprints, acquired at multiple early life stages. The dataset is intended to support the training and evaluation of machine learning models aimed at emulating the effects of growth on biometric features. We hypothesize that such a dataset will enable the development of more robust and accurate Deep Learning-based models, capable of predicting changes in the minutiae map with higher fidelity than conventional scaling-based methods. Ultimately, this effort lays the groundwork for more reliable biometric identification systems tailored to the unique developmental trajectory of newborns.</li>
</ul>

<h3>Title: Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors</h3>
<ul>
<li><strong>Authors: </strong>Ren-Wei Liang, Chin-Ting Hsu, Chan-Hung Yu, Saransh Agrawal, Shih-Cheng Huang, Shang-Tse Chen, Kuan-Hao Huang, Shao-Hua Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20106">https://arxiv.org/abs/2504.20106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20106">https://arxiv.org/pdf/2504.20106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20106]] Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors(https://arxiv.org/abs/2504.20106)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ensuring that large language models (LLMs) are both helpful and harmless is a critical challenge, as overly strict constraints can lead to excessive refusals, while permissive models risk generating harmful content. Existing approaches, such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO), attempt to balance these trade-offs but suffer from performance conflicts, limited controllability, and poor extendability. To address these issues, we propose Preference Vector, a novel framework inspired by task arithmetic. Instead of optimizing multiple preferences within a single objective, we train separate models on individual preferences, extract behavior shifts as preference vectors, and dynamically merge them at test time. This modular approach enables fine-grained, user-controllable preference adjustments and facilitates seamless integration of new preferences without retraining. Experiments show that our proposed Preference Vector framework improves helpfulness without excessive conservatism, allows smooth control over preference trade-offs, and supports scalable multi-preference alignment.</li>
</ul>

<h3>Title: Attention to Detail: Fine-Scale Feature Preservation-Oriented Geometric Pre-training for AI-Driven Surrogate Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yu-hsuan Chen, Jing Bi, Cyril Ngo Ngoc, Victor Oancea, Jonathan Cagan, Levent Burak Kara</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20110">https://arxiv.org/abs/2504.20110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20110">https://arxiv.org/pdf/2504.20110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20110]] Attention to Detail: Fine-Scale Feature Preservation-Oriented Geometric Pre-training for AI-Driven Surrogate Modeling(https://arxiv.org/abs/2504.20110)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>AI-driven surrogate modeling has become an increasingly effective alternative to physics-based simulations for 3D design, analysis, and manufacturing. These models leverage data-driven methods to predict physical quantities traditionally requiring computationally expensive simulations. However, the scarcity of labeled CAD-to-simulation datasets has driven recent advancements in self-supervised and foundation models, where geometric representation learning is performed offline and later fine-tuned for specific downstream tasks. While these approaches have shown promise, their effectiveness is limited in applications requiring fine-scale geometric detail preservation. This work introduces a self-supervised geometric representation learning method designed to capture fine-scale geometric features from non-parametric 3D models. Unlike traditional end-to-end surrogate models, this approach decouples geometric feature extraction from downstream physics tasks, learning a latent space embedding guided by geometric reconstruction losses. Key elements include the essential use of near-zero level sampling and the innovative batch-adaptive attention-weighted loss function, which enhance the encoding of intricate design features. The proposed method is validated through case studies in structural mechanics, demonstrating strong performance in capturing design features and enabling accurate few-shot physics predictions. Comparisons with traditional parametric surrogate modeling highlight its potential to bridge the gap between geometric and physics-based representations, providing an effective solution for surrogate modeling in data-scarce scenarios.</li>
</ul>

<h3>Title: Forging and Removing Latent-Noise Diffusion Watermarks Using a Single Image</h3>
<ul>
<li><strong>Authors: </strong>Anubhav Jain, Yuya Kobayashi, Naoki Murata, Yuhta Takida, Takashi Shibuya, Yuki Mitsufuji, Niv Cohen, Nasir Memon, Julian Togelius</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20111">https://arxiv.org/abs/2504.20111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20111">https://arxiv.org/pdf/2504.20111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20111]] Forging and Removing Latent-Noise Diffusion Watermarks Using a Single Image(https://arxiv.org/abs/2504.20111)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, watermark, diffusion</a></li>
<li><strong>Abstract: </strong>Watermarking techniques are vital for protecting intellectual property and preventing fraudulent use of media. Most previous watermarking schemes designed for diffusion models embed a secret key in the initial noise. The resulting pattern is often considered hard to remove and forge into unrelated images. In this paper, we propose a black-box adversarial attack without presuming access to the diffusion model weights. Our attack uses only a single watermarked example and is based on a simple observation: there is a many-to-one mapping between images and initial noises. There are regions in the clean image latent space pertaining to each watermark that get mapped to the same initial noise when inverted. Based on this intuition, we propose an adversarial attack to forge the watermark by introducing perturbations to the images such that we can enter the region of watermarked images. We show that we can also apply a similar approach for watermark removal by learning perturbations to exit this region. We report results on multiple watermarking schemes (Tree-Ring, RingID, WIND, and Gaussian Shading) across two diffusion models (SDv1.4 and SDv2.0). Our results demonstrate the effectiveness of the attack and expose vulnerabilities in the watermarking methods, motivating future research on improving them.</li>
</ul>

<h3>Title: Supervised Pretraining for Material Property Prediction</h3>
<ul>
<li><strong>Authors: </strong>Chowdhury Mohammad Abid Rahman, Aldo H. Romero, Prashnna K. Gyawali</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20112">https://arxiv.org/abs/2504.20112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20112">https://arxiv.org/pdf/2504.20112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20112]] Supervised Pretraining for Material Property Prediction(https://arxiv.org/abs/2504.20112)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate prediction of material properties facilitates the discovery of novel materials with tailored functionalities. Deep learning models have recently shown superior accuracy and flexibility in capturing structure-property relationships. However, these models often rely on supervised learning, which requires large, well-annotated datasets an expensive and time-consuming process. Self-supervised learning (SSL) offers a promising alternative by pretraining on large, unlabeled datasets to develop foundation models that can be fine-tuned for material property prediction. In this work, we propose supervised pretraining, where available class information serves as surrogate labels to guide learning, even when downstream tasks involve unrelated material properties. We evaluate this strategy on two state-of-the-art SSL models and introduce a novel framework for supervised pretraining. To further enhance representation learning, we propose a graph-based augmentation technique that injects noise to improve robustness without structurally deforming material graphs. The resulting foundation models are fine-tuned for six challenging material property predictions, achieving significant performance gains over baselines, ranging from 2% to 6.67% improvement in mean absolute error (MAE) and establishing a new benchmark in material property prediction. This study represents the first exploration of supervised pertaining with surrogate labels in material property prediction, advancing methodology and application in the field.</li>
</ul>

<h3>Title: Benchmarking Transferability: A Framework for Fair and Robust Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Alireza Kazemi, Helia Rezvani, Mahsa Baktashmotlagh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20121">https://arxiv.org/abs/2504.20121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20121">https://arxiv.org/pdf/2504.20121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20121]] Benchmarking Transferability: A Framework for Fair and Robust Evaluation(https://arxiv.org/abs/2504.20121)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Transferability scores aim to quantify how well a model trained on one domain generalizes to a target domain. Despite numerous methods proposed for measuring transferability, their reliability and practical usefulness remain inconclusive, often due to differing experimental setups, datasets, and assumptions. In this paper, we introduce a comprehensive benchmarking framework designed to systematically evaluate transferability scores across diverse settings. Through extensive experiments, we observe variations in how different metrics perform under various scenarios, suggesting that current evaluation practices may not fully capture each method's strengths and limitations. Our findings underscore the value of standardized assessment protocols, paving the way for more reliable transferability measures and better-informed model selection in cross-domain applications. Additionally, we achieved a 3.5\% improvement using our proposed metric for the head-training fine-tuning experimental setup. Our code is available in this repository: this https URL.</li>
</ul>

<h3>Title: Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models</h3>
<ul>
<li><strong>Authors: </strong>Zae Myung Kim, Chanwoo Park, Vipul Raheja, Dongyeop Kang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20157">https://arxiv.org/abs/2504.20157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20157">https://arxiv.org/pdf/2504.20157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20157]] Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models(https://arxiv.org/abs/2504.20157)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reward-based alignment methods for large language models (LLMs) face two key limitations: vulnerability to reward hacking, where models exploit flaws in the reward signal; and reliance on brittle, labor-intensive prompt engineering when LLMs are used as reward models. We introduce Meta Policy Optimization (MPO), a framework that addresses these challenges by integrating a meta-reward model that dynamically refines the reward model's prompt throughout training. In MPO, the meta-reward model monitors the evolving training context and continuously adjusts the reward model's prompt to maintain high alignment, providing an adaptive reward signal that resists exploitation by the policy. This meta-learning approach promotes a more stable policy optimization, and greatly reduces the need for manual reward prompt design. It yields performance on par with or better than models guided by extensively hand-crafted reward prompts. Furthermore, we show that MPO maintains its effectiveness across diverse tasks, such as question answering and mathematical reasoning, without requiring specialized reward designs. Beyond standard RLAIF, MPO's meta-learning formulation is readily extensible to higher-level alignment frameworks. Overall, this method addresses theoretical and practical challenges in reward-based RL alignment for LLMs, paving the way for more robust and adaptable alignment strategies. The code and models will be publicly shared.</li>
</ul>

<h3>Title: MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools</h3>
<ul>
<li><strong>Authors: </strong>Nishant Subramani, Jason Eisner, Justin Svegliato, Benjamin Van Durme, Yu Su, Sam Thomson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20168">https://arxiv.org/abs/2504.20168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20168">https://arxiv.org/pdf/2504.20168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20168]] MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools(https://arxiv.org/abs/2504.20168)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Tool-using agents that act in the world need to be both useful and safe. Well-calibrated model confidences can be used to weigh the risk versus reward of potential actions, but prior work shows that many models are poorly calibrated. Inspired by interpretability literature exploring the internals of models, we propose a novel class of model-internal confidence estimators (MICE) to better assess confidence when calling tools. MICE first decodes from each intermediate layer of the language model using logitLens and then computes similarity scores between each layer's generation and the final output. These features are fed into a learned probabilistic classifier to assess confidence in the decoded output. On the simulated trial and error (STE) tool-calling dataset using Llama3 models, we find that MICE beats or matches the baselines on smoothed expected calibration error. Using MICE confidences to determine whether to call a tool significantly improves over strong baselines on a new metric, expected tool-calling utility. Further experiments show that MICE is sample-efficient, can generalize zero-shot to unseen APIs, and results in higher tool-calling utility in scenarios with varying risk levels. Our code is open source, available at this https URL.</li>
</ul>

<h3>Title: A Transformer-based Multimodal Fusion Model for Efficient Crowd Counting Using Visual and Wireless Signals</h3>
<ul>
<li><strong>Authors: </strong>Zhe Cui, Yuli Li, Le-Nam Tran</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20178">https://arxiv.org/abs/2504.20178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20178">https://arxiv.org/pdf/2504.20178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20178]] A Transformer-based Multimodal Fusion Model for Efficient Crowd Counting Using Visual and Wireless Signals(https://arxiv.org/abs/2504.20178)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Current crowd-counting models often rely on single-modal inputs, such as visual images or wireless signal data, which can result in significant information loss and suboptimal recognition performance. To address these shortcomings, we propose TransFusion, a novel multimodal fusion-based crowd- counting model that integrates Channel State Information (CSI) with image data. By leveraging the powerful capabilities of Transformer networks, TransFusion effectively combines these two distinct data modalities, enabling the capture of comprehen- sive global contextual information that is critical for accurate crowd estimation. However, while transformers are well capable of capturing global features, they potentially fail to identify finer- grained, local details essential for precise crowd counting. To mitigate this, we incorporate Convolutional Neural Networks (CNNs) into the model architecture, enhancing its ability to extract detailed local features that complement the global context provided by the Transformer. Extensive experimental evaluations demonstrate that TransFusion achieves high accuracy with minimal counting errors while maintaining superior efficiency.</li>
</ul>

<h3>Title: Integration Flow Models</h3>
<ul>
<li><strong>Authors: </strong>Jingjing Wang, Dan Zhang, Joshua Luo, Yin Yang, Feng Luo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20179">https://arxiv.org/abs/2504.20179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20179">https://arxiv.org/pdf/2504.20179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20179]] Integration Flow Models(https://arxiv.org/abs/2504.20179)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Ordinary differential equation (ODE) based generative models have emerged as a powerful approach for producing high-quality samples in many applications. However, the ODE-based methods either suffer the discretization error of numerical solvers of ODE, which restricts the quality of samples when only a few NFEs are used, or struggle with training instability. In this paper, we proposed Integration Flow, which directly learns the integral of ODE-based trajectory paths without solving the ODE functions. Moreover, Integration Flow explicitly incorporates the target state $\mathbf{x}_0$ as the anchor state in guiding the reverse-time dynamics. We have theoretically proven this can contribute to both stability and accuracy. To the best of our knowledge, Integration Flow is the first model with a unified structure to estimate ODE-based generative models and the first to show the exact straightness of 1-Rectified Flow without reflow. Through theoretical analysis and empirical evaluations, we show that Integration Flows achieve improved performance when it is applied to existing ODE-based models, such as diffusion models, Rectified Flows, and PFGM++. Specifically, Integration Flow achieves one-step generation on CIFAR10 with FIDs of 2.86 for the Variance Exploding (VE) diffusion model, 3.36 for rectified flow without reflow, and 2.91 for PFGM++; and on ImageNet with FIDs of 4.09 for VE diffusion model, 4.35 for rectified flow without reflow and 4.15 for PFGM++.</li>
</ul>

<h3>Title: Cybersecurity for Autonomous Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Sai varun reddy Bhemavarapu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20180">https://arxiv.org/abs/2504.20180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20180">https://arxiv.org/pdf/2504.20180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20180]] Cybersecurity for Autonomous Vehicles(https://arxiv.org/abs/2504.20180)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect</a></li>
<li><strong>Abstract: </strong>The increasing adoption of autonomous vehicles is bringing a major shift in the automotive industry. However, as these vehicles become more connected, cybersecurity threats have emerged as a serious concern. Protecting the security and integrity of autonomous systems is essential to prevent malicious activities that can harm passengers, other road users, and the overall transportation network. This paper focuses on addressing the cybersecurity issues in autonomous vehicles by examining the challenges and risks involved, which are important for building a secure future. Since autonomous vehicles depend on the communication between sensors, artificial intelligence, external infrastructure, and other systems, they are exposed to different types of cyber threats. A cybersecurity breach in an autonomous vehicle can cause serious problems, including a loss of public trust and safety. Therefore, it is very important to develop and apply strong cybersecurity measures to support the growth and acceptance of self-driving cars. This paper discusses major cybersecurity challenges like vulnerabilities in software and hardware, risks from wireless communication, and threats through external interfaces. It also reviews existing solutions such as secure software development, intrusion detection systems, cryptographic protocols, and anomaly detection methods. Additionally, the paper highlights the role of regulatory bodies, industry collaborations, and cybersecurity standards in creating a secure environment for autonomous vehicles. Setting clear rules and best practices is necessary for consistent protection across manufacturers and regions. By analyzing the current cybersecurity landscape and suggesting practical countermeasures, this paper aims to contribute to the safe development and public trust of autonomous vehicle technology.</li>
</ul>

<h3>Title: ProFi-Net: Prototype-based Feature Attention with Curriculum Augmentation for WiFi-based Gesture Recognition</h3>
<ul>
<li><strong>Authors: </strong>Zhe Cui, Shuxian Zhang, Kangzhi Lou, Le-Nam Tran</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20193">https://arxiv.org/abs/2504.20193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20193">https://arxiv.org/pdf/2504.20193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20193]] ProFi-Net: Prototype-based Feature Attention with Curriculum Augmentation for WiFi-based Gesture Recognition(https://arxiv.org/abs/2504.20193)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents ProFi-Net, a novel few-shot learning framework for WiFi-based gesture recognition that overcomes the chal- lenges of limited training data and sparse feature representations. ProFi- Net employs a prototype-based metric learning architecture enhanced with a feature-level attention mechanism, which dynamically refines the Euclidean distance by emphasizing the most discriminative feature di- mensions. Additionally, our approach introduces a curriculum-inspired data augmentation strategy exclusively on the query set. By progressively incorporating Gaussian noise of increasing magnitude, the model is ex- posed to a broader range of challenging variations, thereby improving its generalization and robustness to overfitting. Extensive experiments con- ducted across diverse real-world environments demonstrate that ProFi- Net significantly outperforms conventional prototype networks and other state-of-the-art few-shot learning methods in terms of classification ac- curacy and training efficiency.</li>
</ul>

<h3>Title: Representation Learning on a Random Lattice</h3>
<ul>
<li><strong>Authors: </strong>Aryeh Brill</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.dis-nn, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20197">https://arxiv.org/abs/2504.20197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20197">https://arxiv.org/pdf/2504.20197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20197]] Representation Learning on a Random Lattice(https://arxiv.org/abs/2504.20197)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Decomposing a deep neural network's learned representations into interpretable features could greatly enhance its safety and reliability. To better understand features, we adopt a geometric perspective, viewing them as a learned coordinate system for mapping an embedded data distribution. We motivate a model of a generic data distribution as a random lattice and analyze its properties using percolation theory. Learned features are categorized into context, component, and surface features. The model is qualitatively consistent with recent findings in mechanistic interpretability and suggests directions for future research.</li>
</ul>

<h3>Title: Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains</h3>
<ul>
<li><strong>Authors: </strong>Juntian Zhang, Chuanqi cheng, Yuhan Liu, Wei Liu, Jian Luan, Rui Yan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20199">https://arxiv.org/abs/2504.20199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20199">https://arxiv.org/pdf/2504.20199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20199]] Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains(https://arxiv.org/abs/2504.20199)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) achieve remarkable success in single-image tasks. However, real-world scenarios often involve intricate multi-image inputs, leading to a notable performance decline as models struggle to disentangle critical information scattered across complex visual features. In this work, we propose Focus-Centric Visual Chain, a novel paradigm that enhances VLMs'perception, comprehension, and reasoning abilities in multi-image scenarios. To facilitate this paradigm, we propose Focus-Centric Data Synthesis, a scalable bottom-up approach for synthesizing high-quality data with elaborate reasoning paths. Through this approach, We construct VISC-150K, a large-scale dataset with reasoning data in the form of Focus-Centric Visual Chain, specifically designed for multi-image tasks. Experimental results on seven multi-image benchmarks demonstrate that our method achieves average performance gains of 3.16% and 2.24% across two distinct model architectures, without compromising the general vision-language capabilities. our study represents a significant step toward more robust and capable vision-language systems that can handle complex visual scenarios.</li>
</ul>

<h3>Title: Remote Sensing Imagery for Flood Detection: Exploration of Augmentation Strategies</h3>
<ul>
<li><strong>Authors: </strong>Vladyslav Polushko, Damjan Hatic, Ronald Rösch, Thomas März, Markus Rauhut, Andreas Weinmann</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20203">https://arxiv.org/abs/2504.20203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20203">https://arxiv.org/pdf/2504.20203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20203]] Remote Sensing Imagery for Flood Detection: Exploration of Augmentation Strategies(https://arxiv.org/abs/2504.20203)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Floods cause serious problems around the world. Responding quickly and effectively requires accurate and timely information about the affected areas. The effective use of Remote Sensing images for accurate flood detection requires specific detection methods. Typically, Deep Neural Networks are employed, which are trained on specific datasets. For the purpose of river flood detection in RGB imagery, we use the BlessemFlood21 dataset. We here explore the use of different augmentation strategies, ranging from basic approaches to more complex techniques, including optical distortion. By identifying effective strategies, we aim to refine the training process of state-of-the-art Deep Learning segmentation networks.</li>
</ul>

<h3>Title: Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework</h3>
<ul>
<li><strong>Authors: </strong>Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, Kedar S. Namjoshi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20213">https://arxiv.org/abs/2504.20213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20213">https://arxiv.org/pdf/2504.20213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20213]] Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework(https://arxiv.org/abs/2504.20213)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the logical reasoning capabilities of large language models (LLMs). For a precisely defined yet tractable formulation, we choose the conceptually simple but technically complex task of constructing proofs in Boolean logic. A trained LLM receives as input a set of assumptions and a goal, and produces as output a proof that formally derives the goal from the assumptions. Incorrect proofs are caught by an automated proof checker. A critical obstacle for training is the scarcity of real-world proofs. We propose an efficient, randomized procedure for synthesizing valid proofs and introduce Template Transformation, a data augmentation technique that enhances the model's ability to handle complex logical expressions. The central evaluation question is whether an LLM has indeed learned to reason. We propose tests to measure the reasoning ability of a black-box LLM. By these measures, experiments demonstrate strong reasoning capabilities for assertions with short proofs, which decline with proof complexity. Notably, template transformation improves accuracy even for smaller models, suggesting its effectiveness across model scales.</li>
</ul>

<h3>Title: A Multimodal Pipeline for Clinical Data Extraction: Applying Vision-Language Models to Scans of Transfusion Reaction Reports</h3>
<ul>
<li><strong>Authors: </strong>Henning Schäfer, Cynthia S. Schmidt, Johannes Wutzkowsky, Kamil Lorek, Lea Reinartz, Johannes Rückert, Christian Temme, Britta Böckmann, Peter A. Horn, Christoph M. Friedrich</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20220">https://arxiv.org/abs/2504.20220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20220">https://arxiv.org/pdf/2504.20220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20220]] A Multimodal Pipeline for Clinical Data Extraction: Applying Vision-Language Models to Scans of Transfusion Reaction Reports(https://arxiv.org/abs/2504.20220)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Despite the growing adoption of electronic health records, many processes still rely on paper documents, reflecting the heterogeneous real-world conditions in which healthcare is delivered. The manual transcription process is time-consuming and prone to errors when transferring paper-based data to digital formats. To streamline this workflow, this study presents an open-source pipeline that extracts and categorizes checkbox data from scanned documents. Demonstrated on transfusion reaction reports, the design supports adaptation to other checkbox-rich document types. The proposed method integrates checkbox detection, multilingual optical character recognition (OCR) and multilingual vision-language models (VLMs). The pipeline achieves high precision and recall compared against annually compiled gold-standards from 2017 to 2024. The result is a reduction in administrative workload and accurate regulatory reporting. The open-source availability of this pipeline encourages self-hosted parsing of checkbox forms.</li>
</ul>

<h3>Title: Physics-Informed Diffusion Models for SAR Ship Wake Generation from Text Prompts</h3>
<ul>
<li><strong>Authors: </strong>Kamirul Kamirul, Odysseas Pappas, Alin Achim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20241">https://arxiv.org/abs/2504.20241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20241">https://arxiv.org/pdf/2504.20241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20241]] Physics-Informed Diffusion Models for SAR Ship Wake Generation from Text Prompts(https://arxiv.org/abs/2504.20241)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Detecting ship presence via wake signatures in SAR imagery is attracting considerable research interest, but limited annotated data availability poses significant challenges for supervised learning. Physics-based simulations are commonly used to address this data scarcity, although they are slow and constrain end-to-end learning. In this work, we explore a new direction for more efficient and end-to-end SAR ship wake simulation using a diffusion model trained on data generated by a physics-based simulator. The training dataset is built by pairing images produced by the simulator with text prompts derived from simulation parameters. Experimental result show that the model generates realistic Kelvin wake patterns and achieves significantly faster inference than the physics-based simulator. These results highlight the potential of diffusion models for fast and controllable wake image generation, opening new possibilities for end-to-end downstream tasks in maritime SAR analysis.</li>
</ul>

<h3>Title: A Case Study on the Use of Representativeness Bias as a Defense Against Adversarial Cyber Threats</h3>
<ul>
<li><strong>Authors: </strong>Briland Hitaj, Grit Denker, Laura Tinnel, Michael McAnally, Bruce DeBruhl, Nathan Bunting, Alex Fafard, Daniel Aaron, Richard D. Roberts, Joshua Lawson, Greg McCain, Dylan Starink</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20245">https://arxiv.org/abs/2504.20245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20245">https://arxiv.org/pdf/2504.20245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20245]] A Case Study on the Use of Representativeness Bias as a Defense Against Adversarial Cyber Threats(https://arxiv.org/abs/2504.20245)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Cyberspace is an ever-evolving battleground involving adversaries seeking to circumvent existing safeguards and defenders aiming to stay one step ahead by predicting and mitigating the next threat. Existing mitigation strategies have focused primarily on solutions that consider software or hardware aspects, often ignoring the human factor. This paper takes a first step towards psychology-informed, active defense strategies, where we target biases that human beings are susceptible to under conditions of uncertainty. Using capture-the-flag events, we create realistic challenges that tap into a particular cognitive bias: representativeness. This study finds that this bias can be triggered to thwart hacking attempts and divert hackers into non-vulnerable attack paths. Participants were exposed to two different challenges designed to exploit representativeness biases. One of the representativeness challenges significantly thwarted attackers away from vulnerable attack vectors and onto non-vulnerable paths, signifying an effective bias-based defense mechanism. This work paves the way towards cyber defense strategies that leverage additional human biases to thwart future, sophisticated adversarial attacks.</li>
</ul>

<h3>Title: Temporal Neural Operator for Modeling Time-Dependent Physical Phenomena</h3>
<ul>
<li><strong>Authors: </strong>W. Diab, M. Al-Kobaisi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20249">https://arxiv.org/abs/2504.20249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20249">https://arxiv.org/pdf/2504.20249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20249]] Temporal Neural Operator for Modeling Time-Dependent Physical Phenomena(https://arxiv.org/abs/2504.20249)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural Operators (NOs) are machine learning models designed to solve partial differential equations (PDEs) by learning to map between function spaces. Neural Operators such as the Deep Operator Network (DeepONet) and the Fourier Neural Operator (FNO) have demonstrated excellent generalization properties when mapping between spatial function spaces. However, they struggle in mapping the temporal dynamics of time-dependent PDEs, especially for time steps not explicitly seen during training. This limits their temporal accuracy as they do not leverage these dynamics in the training process. In addition, most NOs tend to be prohibitively costly to train, especially for higher-dimensional PDEs. In this paper, we propose the Temporal Neural Operator (TNO), an efficient neural operator specifically designed for spatio-temporal operator learning for time-dependent PDEs. TNO achieves this by introducing a temporal-branch to the DeepONet framework, leveraging the best architectural design choices from several other NOs, and a combination of training strategies including Markov assumption, teacher forcing, temporal bundling, and the flexibility to condition the output on the current state or past states. Through extensive benchmarking and an ablation study on a diverse set of example problems we demonstrate the TNO long range temporal extrapolation capabilities, robustness to error accumulation, resolution invariance, and flexibility to handle multiple input functions.</li>
</ul>

<h3>Title: Financial Data Analysis with Robust Federated Logistic Regression</h3>
<ul>
<li><strong>Authors: </strong>Kun Yang, Nikhil Krishnan, Sanjeev R. Kulkarni</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.GN, q-fin.ST, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20250">https://arxiv.org/abs/2504.20250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20250">https://arxiv.org/pdf/2504.20250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20250]] Financial Data Analysis with Robust Federated Logistic Regression(https://arxiv.org/abs/2504.20250)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>In this study, we focus on the analysis of financial data in a federated setting, wherein data is distributed across multiple clients or locations, and the raw data never leaves the local devices. Our primary focus is not only on the development of efficient learning frameworks (for protecting user data privacy) in the field of federated learning but also on the importance of designing models that are easier to interpret. In addition, we care about the robustness of the framework to outliers. To achieve these goals, we propose a robust federated logistic regression-based framework that strives to strike a balance between these goals. To verify the feasibility of our proposed framework, we carefully evaluate its performance not only on independently identically distributed (IID) data but also on non-IID data, especially in scenarios involving outliers. Extensive numerical results collected from multiple public datasets demonstrate that our proposed method can achieve comparable performance to those of classical centralized algorithms, such as Logistical Regression, Decision Tree, and K-Nearest Neighbors, in both binary and multi-class classification tasks.</li>
</ul>

<h3>Title: SA2FE: A Secure, Anonymous, Auditable, and Fair Edge Computing Service Offloading Framework</h3>
<ul>
<li><strong>Authors: </strong>Xiaojian Wang, Huayue Gu, Zhouyu Li, Fangtong Zhou, Ruozhou Yu, Dejun Yang, Guoliang Xue</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20260">https://arxiv.org/abs/2504.20260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20260">https://arxiv.org/pdf/2504.20260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20260]] SA2FE: A Secure, Anonymous, Auditable, and Fair Edge Computing Service Offloading Framework(https://arxiv.org/abs/2504.20260)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack, fair</a></li>
<li><strong>Abstract: </strong>The inclusion of pervasive computing devices in a democratized edge computing ecosystem can significantly expand the capability and coverage of near-end computing for large-scale applications. However, offloading user tasks to heterogeneous and decentralized edge devices comes with the dual risk of both endangered user data security and privacy due to the curious base station or malicious edge servers, and unfair offloading and malicious attacks targeting edge servers from other edge servers and/or users. Existing solutions to edge access control and offloading either rely on "always-on" cloud servers with reduced edge benefits or fail to protect sensitive user service information. To address these challenges, this paper presents SA2FE, a novel framework for edge access control, offloading and accounting. We design a rerandomizable puzzle primitive and a corresponding scheme to protect sensitive service information from eavesdroppers and ensure fair offloading decisions, while a blind token-based scheme safeguards user privacy, prevents double spending, and ensures usage accountability. The security of SA2FE is proved under the Universal Composability framework, and its performance and scalability are demonstrated with implementation on commodity mobile devices and edge servers.</li>
</ul>

<h3>Title: A Virtual Cybersecurity Department for Securing Digital Twins in Water Distribution Systems</h3>
<ul>
<li><strong>Authors: </strong>Mohammadhossein Homaei, Agustin Di Bartolo, Oscar Mogollon-Gutierrez, Fernando Broncano Morgado, Pablo Garcia Rodriguez</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20266">https://arxiv.org/abs/2504.20266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20266">https://arxiv.org/pdf/2504.20266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20266]] A Virtual Cybersecurity Department for Securing Digital Twins in Water Distribution Systems(https://arxiv.org/abs/2504.20266)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Digital twins (DTs) help improve real-time monitoring and decision-making in water distribution systems. However, their connectivity makes them easy targets for cyberattacks such as scanning, denial-of-service (DoS), and unauthorized access. Small and medium-sized enterprises (SMEs) that manage these systems often do not have enough budget or staff to build strong cybersecurity teams. To solve this problem, we present a Virtual Cybersecurity Department (VCD), an affordable and automated framework designed for SMEs. The VCD uses open-source tools like Zabbix for real-time monitoring, Suricata for network intrusion detection, Fail2Ban to block repeated login attempts, and simple firewall settings. To improve threat detection, we also add a machine-learning-based IDS trained on the OD-IDS2022 dataset using an improved ensemble model. This model detects cyber threats such as brute-force attacks, remote code execution (RCE), and network flooding, with 92\% accuracy and fewer false alarms. Our solution gives SMEs a practical and efficient way to secure water systems using low-cost and easy-to-manage tools.</li>
</ul>

<h3>Title: Smart Water Security with AI and Blockchain-Enhanced Digital Twins</h3>
<ul>
<li><strong>Authors: </strong>Mohammadhossein Homaei, Victor Gonzalez Morales, Oscar Mogollon Gutierrez, Ruben Molano Gomez, Andres Caro</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20275">https://arxiv.org/abs/2504.20275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20275">https://arxiv.org/pdf/2504.20275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20275]] Smart Water Security with AI and Blockchain-Enhanced Digital Twins(https://arxiv.org/abs/2504.20275)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Water distribution systems in rural areas face serious challenges such as a lack of real-time monitoring, vulnerability to cyberattacks, and unreliable data handling. This paper presents an integrated framework that combines LoRaWAN-based data acquisition, a machine learning-driven Intrusion Detection System (IDS), and a blockchain-enabled Digital Twin (BC-DT) platform for secure and transparent water management. The IDS filters anomalous or spoofed data using a Long Short-Term Memory (LSTM) Autoencoder and Isolation Forest before validated data is logged via smart contracts on a private Ethereum blockchain using Proof of Authority (PoA) consensus. The verified data feeds into a real-time DT model supporting leak detection, consumption forecasting, and predictive maintenance. Experimental results demonstrate that the system achieves over 80 transactions per second (TPS) with under 2 seconds of latency while remaining cost-effective and scalable for up to 1,000 smart meters. This work demonstrates a practical and secure architecture for decentralized water infrastructure in under-connected rural environments.</li>
</ul>

<h3>Title: Enhancing Systematic Reviews with Large Language Models: Using GPT-4 and Kimi</h3>
<ul>
<li><strong>Authors: </strong>Dandan Chen Kaptur, Yue Huang, Xuejun Ryan Ji, Yanhui Guo, Bradley Kaptur</a></li>
<li><strong>Subjects: </strong>cs.CL, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20276">https://arxiv.org/abs/2504.20276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20276">https://arxiv.org/pdf/2504.20276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20276]] Enhancing Systematic Reviews with Large Language Models: Using GPT-4 and Kimi(https://arxiv.org/abs/2504.20276)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This research delved into GPT-4 and Kimi, two Large Language Models (LLMs), for systematic reviews. We evaluated their performance by comparing LLM-generated codes with human-generated codes from a peer-reviewed systematic review on assessment. Our findings suggested that the performance of LLMs fluctuates by data volume and question complexity for systematic reviews.</li>
</ul>

<h3>Title: Generative Diffusion Models for Resource Allocation in Wireless Networks</h3>
<ul>
<li><strong>Authors: </strong>Yigit Berkay Uslu, Samar Hadou, Shirin Saeedi Bidokhti, Alejandro Ribeiro</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20277">https://arxiv.org/abs/2504.20277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20277">https://arxiv.org/pdf/2504.20277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20277]] Generative Diffusion Models for Resource Allocation in Wireless Networks(https://arxiv.org/abs/2504.20277)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper proposes a supervised training algorithm for learning stochastic resource allocation policies with generative diffusion models (GDMs). We formulate the allocation problem as the maximization of an ergodic utility function subject to ergodic Quality of Service (QoS) constraints. Given samples from a stochastic expert policy that yields a near-optimal solution to the problem, we train a GDM policy to imitate the expert and generate new samples from the optimal distribution. We achieve near-optimal performance through sequential execution of the generated samples. To enable generalization to a family of network configurations, we parameterize the backward diffusion process with a graph neural network (GNN) architecture. We present numerical results in a case study of power control in multi-user interference networks.</li>
</ul>

<h3>Title: FedCCL: Federated Clustered Continual Learning Framework for Privacy-focused Energy Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Michael A. Helcig, Stefan Nastic</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20282">https://arxiv.org/abs/2504.20282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20282">https://arxiv.org/pdf/2504.20282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20282]] FedCCL: Federated Clustered Continual Learning Framework for Privacy-focused Energy Forecasting(https://arxiv.org/abs/2504.20282)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Privacy-preserving distributed model training is crucial for modern machine learning applications, yet existing Federated Learning approaches struggle with heterogeneous data distributions and varying computational capabilities. Traditional solutions either treat all participants uniformly or require costly dynamic clustering during training, leading to reduced efficiency and delayed model specialization. We present FedCCL (Federated Clustered Continual Learning), a framework specifically designed for environments with static organizational characteristics but dynamic client availability. By combining static pre-training clustering with an adapted asynchronous FedAvg algorithm, FedCCL enables new clients to immediately profit from specialized models without prior exposure to their data distribution, while maintaining reduced coordination overhead and resilience to client disconnections. Our approach implements an asynchronous Federated Learning protocol with a three-tier model topology - global, cluster-specific, and local models - that efficiently manages knowledge sharing across heterogeneous participants. Evaluation using photovoltaic installations across central Europe demonstrates that FedCCL's location-based clustering achieves an energy prediction error of 3.93% (+-0.21%), while maintaining data privacy and showing that the framework maintains stability for population-independent deployments, with 0.14 percentage point degradation in performance for new installations. The results demonstrate that FedCCL offers an effective framework for privacy-preserving distributed learning, maintaining high accuracy and adaptability even with dynamic participant populations.</li>
</ul>

<h3>Title: Image Interpolation with Score-based Riemannian Metrics of Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Shinnosuke Saito, Takashi Matsubara</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20288">https://arxiv.org/abs/2504.20288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20288">https://arxiv.org/pdf/2504.20288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20288]] Image Interpolation with Score-based Riemannian Metrics of Diffusion Models(https://arxiv.org/abs/2504.20288)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models excel in content generation by implicitly learning the data manifold, yet they lack a practical method to leverage this manifold - unlike other deep generative models equipped with latent spaces. This paper introduces a novel framework that treats the data space of pre-trained diffusion models as a Riemannian manifold, with a metric derived from the score function. Experiments with MNIST and Stable Diffusion show that this geometry-aware approach yields image interpolations that are more realistic, less noisy, and more faithful to prompts than existing methods, demonstrating its potential for improved content generation and editing.</li>
</ul>

<h3>Title: The Dark Side of Digital Twins: Adversarial Attacks on AI-Driven Water Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Mohammadhossein Homaei, Victor Gonzalez Morales, Oscar Mogollon-Gutierrez, Andres Caro</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20295">https://arxiv.org/abs/2504.20295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20295">https://arxiv.org/pdf/2504.20295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20295]] The Dark Side of Digital Twins: Adversarial Attacks on AI-Driven Water Forecasting(https://arxiv.org/abs/2504.20295)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Digital twins (DTs) are improving water distribution systems by using real-time data, analytics, and prediction models to optimize operations. This paper presents a DT platform designed for a Spanish water supply network, utilizing Long Short-Term Memory (LSTM) networks to predict water consumption. However, machine learning models are vulnerable to adversarial attacks, such as the Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD). These attacks manipulate critical model parameters, injecting subtle distortions that degrade forecasting accuracy. To further exploit these vulnerabilities, we introduce a Learning Automata (LA) and Random LA-based approach that dynamically adjusts perturbations, making adversarial attacks more difficult to detect. Experimental results show that this approach significantly impacts prediction reliability, causing the Mean Absolute Percentage Error (MAPE) to rise from 26% to over 35%. Moreover, adaptive attack strategies amplify this effect, highlighting cybersecurity risks in AI-driven DTs. These findings emphasize the urgent need for robust defenses, including adversarial training, anomaly detection, and secure data pipelines.</li>
</ul>

<h3>Title: SoK: A Survey of Mixing Techniques and Mixers for Cryptocurrencies</h3>
<ul>
<li><strong>Authors: </strong>Juraj Mariani, Ivan Homoliak</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20296">https://arxiv.org/abs/2504.20296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20296">https://arxiv.org/pdf/2504.20296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20296]] SoK: A Survey of Mixing Techniques and Mixers for Cryptocurrencies(https://arxiv.org/abs/2504.20296)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>Blockchain technologies have overturned the digital finance industry by introducing a decentralized pseudonymous means of monetary transfer. The pseudonymous nature introduced privacy concerns, enabling various deanonymization techniques, which in turn spurred development of stronger anonymity-preserving measures. The purpose of this paper is to create a comprehensive survey of mixing techniques and implementations within the vast ecosystem surrounding anonymization tools and mechanisms available in blockchain cryptocurrencies. First, we begin by reviewing classifications used in the field. Then, we survey various obfuscation techniques, helping to delve into actual implementations and combinations of these techniques. Next, we identify the positive and negative attributes of the approaches and implementations included. Moreover, we examine the implications of anonymization tools for user privacy, including their effectiveness in preserving anonymity and susceptibility to attacks and vulnerabilities. Finally, we discuss the challenges and innovations for extending mixing services into the realm of smart contracts or cross-chain space.</li>
</ul>

<h3>Title: DeepAndes: A Self-Supervised Vision Foundation Model for Multi-Spectral Remote Sensing Imagery of the Andes</h3>
<ul>
<li><strong>Authors: </strong>Junlin Guo, James R. Zimmer-Dauphinee, Jordan M. Nieusma, Siqi Lu, Quan Liu, Ruining Deng, Can Cui, Jialin Yue, Yizhe Lin, Tianyuan Yao, Juming Xiong, Junchao Zhu, Chongyu Qu, Yuechen Yang, Mitchell Wilkes, Xiao Wang, Parker VanValkenburgh, Steven A. Wernke, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20303">https://arxiv.org/abs/2504.20303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20303">https://arxiv.org/pdf/2504.20303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20303]] DeepAndes: A Self-Supervised Vision Foundation Model for Multi-Spectral Remote Sensing Imagery of the Andes(https://arxiv.org/abs/2504.20303)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>By mapping sites at large scales using remotely sensed data, archaeologists can generate unique insights into long-term demographic trends, inter-regional social networks, and past adaptations to climate change. Remote sensing surveys complement field-based approaches, and their reach can be especially great when combined with deep learning and computer vision techniques. However, conventional supervised deep learning methods face challenges in annotating fine-grained archaeological features at scale. While recent vision foundation models have shown remarkable success in learning large-scale remote sensing data with minimal annotations, most off-the-shelf solutions are designed for RGB images rather than multi-spectral satellite imagery, such as the 8-band data used in our study. In this paper, we introduce DeepAndes, a transformer-based vision foundation model trained on three million multi-spectral satellite images, specifically tailored for Andean archaeology. DeepAndes incorporates a customized DINOv2 self-supervised learning algorithm optimized for 8-band multi-spectral imagery, marking the first foundation model designed explicitly for the Andes region. We evaluate its image understanding performance through imbalanced image classification, image instance retrieval, and pixel-level semantic segmentation tasks. Our experiments show that DeepAndes achieves superior F1 scores, mean average precision, and Dice scores in few-shot learning scenarios, significantly outperforming models trained from scratch or pre-trained on smaller datasets. This underscores the effectiveness of large-scale self-supervised pre-training in archaeological remote sensing. Codes will be available on this https URL.</li>
</ul>

<h3>Title: Dynamic Contextual Attention Network: Transforming Spatial Representations into Adaptive Insights for Endoscopic Polyp Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Teja Krishna Cherukuri, Nagur Shareef Shaik, Sribhuvan Reddy Yellu, Jun-Won Chung, Dong Hye Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20306">https://arxiv.org/abs/2504.20306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20306">https://arxiv.org/pdf/2504.20306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20306]] Dynamic Contextual Attention Network: Transforming Spatial Representations into Adaptive Insights for Endoscopic Polyp Diagnosis(https://arxiv.org/abs/2504.20306)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Colorectal polyps are key indicators for early detection of colorectal cancer. However, traditional endoscopic imaging often struggles with accurate polyp localization and lacks comprehensive contextual awareness, which can limit the explainability of diagnoses. To address these issues, we propose the Dynamic Contextual Attention Network (DCAN). This novel approach transforms spatial representations into adaptive contextual insights, using an attention mechanism that enhances focus on critical polyp regions without explicit localization modules. By integrating contextual awareness into the classification process, DCAN improves decision interpretability and overall diagnostic performance. This advancement in imaging could lead to more reliable colorectal cancer detection, enabling better patient outcomes.</li>
</ul>

<h3>Title: A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Greg Gluch, Shafi Goldwasser</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20310">https://arxiv.org/abs/2504.20310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20310">https://arxiv.org/pdf/2504.20310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20310]] A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning(https://arxiv.org/abs/2504.20310)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we initiate a cryptographically inspired theoretical study of detection versus mitigation of adversarial inputs produced by attackers of Machine Learning algorithms during inference time. We formally define defense by detection (DbD) and defense by mitigation (DbM). Our definitions come in the form of a 3-round protocol between two resource-bounded parties: a trainer/defender and an attacker. The attacker aims to produce inference-time inputs that fool the training algorithm. We define correctness, completeness, and soundness properties to capture successful defense at inference time while not degrading (too much) the performance of the algorithm on inputs from the training distribution. We first show that achieving DbD and achieving DbM are equivalent for ML classification tasks. Surprisingly, this is not the case for ML generative learning tasks, where there are many possible correct outputs that can be generated for each input. We show a separation between DbD and DbM by exhibiting a generative learning task for which is possible to defend by mitigation but is provably impossible to defend by detection under the assumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE), publicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARK) and Strongly Unforgeable Signatures exist. The mitigation phase uses significantly fewer samples than the initial training algorithm.</li>
</ul>

<h3>Title: Bayesian Experimental Design for Model Discrepancy Calibration: An Auto-Differentiable Ensemble Kalman Inversion Approach</h3>
<ul>
<li><strong>Authors: </strong>Huchen Yang, Xinghao Dong, Jin-Long Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20319">https://arxiv.org/abs/2504.20319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20319">https://arxiv.org/pdf/2504.20319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20319]] Bayesian Experimental Design for Model Discrepancy Calibration: An Auto-Differentiable Ensemble Kalman Inversion Approach(https://arxiv.org/abs/2504.20319)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Bayesian experimental design (BED) offers a principled framework for optimizing data acquisition by leveraging probabilistic inference. However, practical implementations of BED are often compromised by model discrepancy, i.e., the mismatch between predictive models and true physical systems, which can potentially lead to biased parameter estimates. While data-driven approaches have been recently explored to characterize the model discrepancy, the resulting high-dimensional parameter space poses severe challenges for both Bayesian updating and design optimization. In this work, we propose a hybrid BED framework enabled by auto-differentiable ensemble Kalman inversion (AD-EKI) that addresses these challenges by providing a computationally efficient, gradient-free alternative to estimate the information gain for high-dimensional network parameters. The AD-EKI allows a differentiable evaluation of the utility function in BED and thus facilitates the use of standard gradient-based methods for design optimization. In the proposed hybrid framework, we iteratively optimize experimental designs, decoupling the inference of low-dimensional physical parameters handled by standard BED methods, from the high-dimensional model discrepancy handled by AD-EKI. The identified optimal designs for the model discrepancy enable us to systematically collect informative data for its calibration. The performance of the proposed method is studied by a classical convection-diffusion BED example, and the hybrid framework enabled by AD-EKI efficiently identifies informative data to calibrate the model discrepancy and robustly infers the unknown physical parameters in the modeled system. Besides addressing the challenges of BED with model discrepancy, AD-EKI also potentially fosters efficient and scalable frameworks in many other areas with bilevel optimization, such as meta-learning and structure optimization.</li>
</ul>

<h3>Title: MicarVLMoE: A Modern Gated Cross-Aligned Vision-Language Mixture of Experts Model for Medical Image Captioning and Report Generation</h3>
<ul>
<li><strong>Authors: </strong>Amaan Izhar, Nurul Japar, Norisma Idris, Ting Dang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20343">https://arxiv.org/abs/2504.20343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20343">https://arxiv.org/pdf/2504.20343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20343]] MicarVLMoE: A Modern Gated Cross-Aligned Vision-Language Mixture of Experts Model for Medical Image Captioning and Report Generation(https://arxiv.org/abs/2504.20343)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Medical image reporting (MIR) aims to generate structured clinical descriptions from radiological images. Existing methods struggle with fine-grained feature extraction, multimodal alignment, and generalization across diverse imaging types, often relying on vanilla transformers and focusing primarily on chest X-rays. We propose MicarVLMoE, a vision-language mixture-of-experts model with gated cross-aligned fusion, designed to address these limitations. Our architecture includes: (i) a multiscale vision encoder (MSVE) for capturing anatomical details at varying resolutions, (ii) a multihead dual-branch latent attention (MDLA) module for vision-language alignment through latent bottleneck representations, and (iii) a modulated mixture-of-experts (MoE) decoder for adaptive expert specialization. We extend MIR to CT scans, retinal imaging, MRI scans, and gross pathology images, reporting state-of-the-art results on COVCTR, MMR, PGROSS, and ROCO datasets. Extensive experiments and ablations confirm improved clinical accuracy, cross-modal alignment, and model interpretability. Code is available at this https URL.</li>
</ul>

<h3>Title: Local Prompt Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yash Jain, Vishal Chowdhary</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20355">https://arxiv.org/abs/2504.20355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20355">https://arxiv.org/pdf/2504.20355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20355]] Local Prompt Optimization(https://arxiv.org/abs/2504.20355)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, the use of prompts to guide the output of Large Language Models have increased dramatically. However, even the best of experts struggle to choose the correct words to stitch up a prompt for the desired task. To solve this, LLM driven prompt optimization emerged as an important problem. Existing prompt optimization methods optimize a prompt globally, where in all the prompt tokens have to be optimized over a large vocabulary while solving a complex task. The large optimization space (tokens) leads to insufficient guidance for a better prompt. In this work, we introduce Local Prompt Optimization (LPO) that integrates with any general automatic prompt engineering method. We identify the optimization tokens in a prompt and nudge the LLM to focus only on those tokens in its optimization step. We observe remarkable performance improvements on Math Reasoning (GSM8k and MultiArith) and BIG-bench Hard benchmarks across various automatic prompt engineering methods. Further, we show that LPO converges to the optimal prompt faster than global methods.</li>
</ul>

<h3>Title: TTTFusion: A Test-Time Training-Based Strategy for Multimodal Medical Image Fusion in Surgical Robots</h3>
<ul>
<li><strong>Authors: </strong>Qinhua Xie, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20362">https://arxiv.org/abs/2504.20362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20362">https://arxiv.org/pdf/2504.20362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20362]] TTTFusion: A Test-Time Training-Based Strategy for Multimodal Medical Image Fusion in Surgical Robots(https://arxiv.org/abs/2504.20362)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>With the increasing use of surgical robots in clinical practice, enhancing their ability to process multimodal medical images has become a key research challenge. Although traditional medical image fusion methods have made progress in improving fusion accuracy, they still face significant challenges in real-time performance, fine-grained feature extraction, and edge this http URL this paper, we introduce TTTFusion, a Test-Time Training (TTT)-based image fusion strategy that dynamically adjusts model parameters during inference to efficiently fuse multimodal medical images. By adapting the model during the test phase, our method optimizes the parameters based on the input image data, leading to improved accuracy and better detail preservation in the fusion this http URL results demonstrate that TTTFusion significantly enhances the fusion quality of multimodal images compared to traditional fusion methods, particularly in fine-grained feature extraction and edge preservation. This approach not only improves image fusion accuracy but also offers a novel technical solution for real-time image processing in surgical robots.</li>
</ul>

<h3>Title: DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation</h3>
<ul>
<li><strong>Authors: </strong>Zhibo Man, Yuanmeng Chen, Yujie Zhang, Yufeng Chen, Jinan Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20371">https://arxiv.org/abs/2504.20371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20371">https://arxiv.org/pdf/2504.20371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20371]] DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation(https://arxiv.org/abs/2504.20371)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Currently, Large Language Models (LLMs) have achieved remarkable results in machine translation. However, their performance in multi-domain translation (MDT) is less satisfactory; the meanings of words can vary across different domains, highlighting the significant ambiguity inherent in MDT. Therefore, evaluating the disambiguation ability of LLMs in MDT remains an open problem. To this end, we present an evaluation and analysis of LLMs on disambiguation in multi-domain translation (DMDTEval), our systematic evaluation framework consisting of three critical aspects: (1) we construct a translation test set with multi-domain ambiguous word annotation, (2) we curate a diverse set of disambiguation prompting templates, and (3) we design precise disambiguation metrics, and study the efficacy of various prompting strategies on multiple state-of-the-art LLMs. Our extensive experiments reveal a number of crucial findings that we believe will pave the way and also facilitate further research in the critical area of improving the disambiguation of LLMs.</li>
</ul>

<h3>Title: Generative Learning for Slow Manifolds and Bifurcation Diagrams</h3>
<ul>
<li><strong>Authors: </strong>Ellis R. Crabtree, Dimitris G. Giovanis, Nikolaos Evangelou, Juan M. Bello-Rivas, Ioannis G. Kevrekidis</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20375">https://arxiv.org/abs/2504.20375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20375">https://arxiv.org/pdf/2504.20375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20375]] Generative Learning for Slow Manifolds and Bifurcation Diagrams(https://arxiv.org/abs/2504.20375)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In dynamical systems characterized by separation of time scales, the approximation of so called ``slow manifolds'', on which the long term dynamics lie, is a useful step for model reduction. Initializing on such slow manifolds is a useful step in modeling, since it circumvents fast transients, and is crucial in multiscale algorithms alternating between fine scale (fast) and coarser scale (slow) simulations. In a similar spirit, when one studies the infinite time dynamics of systems depending on parameters, the system attractors (e.g., its steady states) lie on bifurcation diagrams. Sampling these manifolds gives us representative attractors (here, steady states of ODEs or PDEs) at different parameter values. Algorithms for the systematic construction of these manifolds are required parts of the ``traditional'' numerical nonlinear dynamics toolkit. In more recent years, as the field of Machine Learning develops, conditional score-based generative models (cSGMs) have demonstrated capabilities in generating plausible data from target distributions that are conditioned on some given label. It is tempting to exploit such generative models to produce samples of data distributions conditioned on some quantity of interest (QoI). In this work, we present a framework for using cSGMs to quickly (a) initialize on a low-dimensional (reduced-order) slow manifold of a multi-time-scale system consistent with desired value(s) of a QoI (a ``label'') on the manifold, and (b) approximate steady states in a bifurcation diagram consistent with a (new, out-of-sample) parameter value. This conditional sampling can help uncover the geometry of the reduced slow-manifold and/or approximately ``fill in'' missing segments of steady states in a bifurcation diagram.</li>
</ul>

<h3>Title: Inception: Jailbreak the Memory Mechanism of Text-to-Image Generation Systems</h3>
<ul>
<li><strong>Authors: </strong>Shiqian Zhao, Jiayang Liu, Yiming Li, Runyi Hu, Xiaojun Jia, Wenshu Fan, Xinfeng Li, Jie Zhang, Wei Dong, Tianwei Zhang, Luu Anh Tuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20376">https://arxiv.org/abs/2504.20376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20376">https://arxiv.org/pdf/2504.20376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20376]] Inception: Jailbreak the Memory Mechanism of Text-to-Image Generation Systems(https://arxiv.org/abs/2504.20376)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, segmentation</a></li>
<li><strong>Abstract: </strong>Currently, the memory mechanism has been widely and successfully exploited in online text-to-image (T2I) generation systems ($e.g.$, DALL$\cdot$E 3) for alleviating the growing tokenization burden and capturing key information in multi-turn interactions. Despite its practicality, its security analyses have fallen far behind. In this paper, we reveal that this mechanism exacerbates the risk of jailbreak attacks. Different from previous attacks that fuse the unsafe target prompt into one ultimate adversarial prompt, which can be easily detected or may generate non-unsafe images due to under- or over-optimization, we propose Inception, the first multi-turn jailbreak attack against the memory mechanism in real-world text-to-image generation systems. Inception embeds the malice at the inception of the chat session turn by turn, leveraging the mechanism that T2I generation systems retrieve key information in their memory. Specifically, Inception mainly consists of two modules. It first segments the unsafe prompt into chunks, which are subsequently fed to the system in multiple turns, serving as pseudo-gradients for directive optimization. Specifically, we develop a series of segmentation policies that ensure the images generated are semantically consistent with the target prompt. Secondly, after segmentation, to overcome the challenge of the inseparability of minimum unsafe words, we propose recursion, a strategy that makes minimum unsafe words subdivisible. Collectively, segmentation and recursion ensure that all the request prompts are benign but can lead to malicious outcomes. We conduct experiments on the real-world text-to-image generation system ($i.e.$, DALL$\cdot$E 3) to validate the effectiveness of Inception. The results indicate that Inception surpasses the state-of-the-art by a 14\% margin in attack success rate.</li>
</ul>

<h3>Title: Sparse2DGS: Geometry-Prioritized Gaussian Splatting for Surface Reconstruction from Sparse Views</h3>
<ul>
<li><strong>Authors: </strong>Jiang Wu, Rui Li, Yu Zhu, Rong Guo, Jinqiu Sun, Yanning Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20378">https://arxiv.org/abs/2504.20378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20378">https://arxiv.org/pdf/2504.20378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20378]] Sparse2DGS: Geometry-Prioritized Gaussian Splatting for Surface Reconstruction from Sparse Views(https://arxiv.org/abs/2504.20378)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a Gaussian Splatting method for surface reconstruction using sparse input views. Previous methods relying on dense views struggle with extremely sparse Structure-from-Motion points for initialization. While learning-based Multi-view Stereo (MVS) provides dense 3D points, directly combining it with Gaussian Splatting leads to suboptimal results due to the ill-posed nature of sparse-view geometric optimization. We propose Sparse2DGS, an MVS-initialized Gaussian Splatting pipeline for complete and accurate reconstruction. Our key insight is to incorporate the geometric-prioritized enhancement schemes, allowing for direct and robust geometric learning under ill-posed conditions. Sparse2DGS outperforms existing methods by notable margins while being ${2}\times$ faster than the NeRF-based fine-tuning approach.</li>
</ul>

<h3>Title: Neural Stereo Video Compression with Hybrid Disparity Compensation</h3>
<ul>
<li><strong>Authors: </strong>Shiyin Jiang, Zhenghao Chen, Minghao Han, Xingyu Zhou, Leheng Zhang, Shuhang Gu</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20383">https://arxiv.org/abs/2504.20383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20383">https://arxiv.org/pdf/2504.20383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20383]] Neural Stereo Video Compression with Hybrid Disparity Compensation(https://arxiv.org/abs/2504.20383)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Disparity compensation represents the primary strategy in stereo video compression (SVC) for exploiting cross-view redundancy. These mechanisms can be broadly categorized into two types: one that employs explicit horizontal shifting, and another that utilizes an implicit cross-attention mechanism to reduce cross-view disparity redundancy. In this work, we propose a hybrid disparity compensation (HDC) strategy that leverages explicit pixel displacement as a robust prior feature to simplify optimization and perform implicit cross-attention mechanisms for subsequent warping operations, thereby capturing a broader range of disparity information. Specifically, HDC first computes a similarity map by fusing the horizontally shifted cross-view features to capture pixel displacement information. This similarity map is then normalized into an "explicit pixel-wise attention score" to perform the cross-attention mechanism, implicitly aligning features from one view to another. Building upon HDC, we introduce a novel end-to-end optimized neural stereo video compression framework, which integrates HDC-based modules into key coding operations, including cross-view feature extraction and reconstruction (HDC-FER) and cross-view entropy modeling (HDC-EM). Extensive experiments on SVC benchmarks, including KITTI 2012, KITTI 2015, and Nagoya, which cover both autonomous driving and general scenes, demonstrate that our framework outperforms both neural and traditional SVC methodologies.</li>
</ul>

<h3>Title: FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yanan Guo, Wenhui Dong, Jun Song, Shiding Zhu, Xuan Zhang, Hanqing Yang, Yingbo Wang, Yang Du, Xianing Chen, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20384">https://arxiv.org/abs/2504.20384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20384">https://arxiv.org/pdf/2504.20384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20384]] FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video Understanding(https://arxiv.org/abs/2504.20384)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in video understanding within visual large language models (VLLMs) have led to notable progress. However, the complexity of video data and contextual processing limitations still hinder long-video comprehension. A common approach is video feature compression to reduce token input to large language models, yet many methods either fail to prioritize essential features, leading to redundant inter-frame information, or introduce computationally expensive this http URL address these issues, we propose FiLA(Fine-grained Vision Language Model)-Video, a novel framework that leverages a lightweight dynamic-weight multi-frame fusion strategy, which adaptively integrates multiple frames into a single representation while preserving key video information and reducing computational costs. To enhance frame selection for fusion, we introduce a keyframe selection strategy, effectively identifying informative frames from a larger pool for improved summarization. Additionally, we present a simple yet effective long-video training data generation strategy, boosting model performance without extensive manual annotation. Experimental results demonstrate that FiLA-Video achieves superior efficiency and accuracy in long-video comprehension compared to existing methods.</li>
</ul>

<h3>Title: FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation</h3>
<ul>
<li><strong>Authors: </strong>Jae Yong Lee, Gwang Jae Jung, Byung Chan Lim, Hyung Ju Hwang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20408">https://arxiv.org/abs/2504.20408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20408">https://arxiv.org/pdf/2504.20408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20408]] FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation(https://arxiv.org/abs/2504.20408)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The Boltzmann equation, a fundamental model in kinetic theory, describes the evolution of particle distribution functions through a nonlinear, high-dimensional collision operator. However, its numerical solution remains computationally demanding, particularly for inelastic collisions and high-dimensional velocity domains. In this work, we propose the Fourier Neural Spectral Network (FourierSpecNet), a hybrid framework that integrates the Fourier spectral method with deep learning to approximate the collision operator in Fourier space efficiently. FourierSpecNet achieves resolution-invariant learning and supports zero-shot super-resolution, enabling accurate predictions at unseen resolutions without retraining. Beyond empirical validation, we establish a consistency result showing that the trained operator converges to the spectral solution as the discretization is refined. We evaluate our method on several benchmark cases, including Maxwellian and hard-sphere molecular models, as well as inelastic collision scenarios. The results demonstrate that FourierSpecNet offers competitive accuracy while significantly reducing computational cost compared to traditional spectral solvers. Our approach provides a robust and scalable alternative for solving the Boltzmann equation across both elastic and inelastic regimes.</li>
</ul>

<h3>Title: ADiff4TPP: Asynchronous Diffusion Models for Temporal Point Processes</h3>
<ul>
<li><strong>Authors: </strong>Amartya Mukherjee, Ruizhi Deng, He Zhao, Yuzhen Mao, Leonid Sigal, Frederick Tung</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20411">https://arxiv.org/abs/2504.20411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20411">https://arxiv.org/pdf/2504.20411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20411]] ADiff4TPP: Asynchronous Diffusion Models for Temporal Point Processes(https://arxiv.org/abs/2504.20411)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This work introduces a novel approach to modeling temporal point processes using diffusion models with an asynchronous noise schedule. At each step of the diffusion process, the noise schedule injects noise of varying scales into different parts of the data. With a careful design of the noise schedules, earlier events are generated faster than later ones, thus providing stronger conditioning for forecasting the more distant future. We derive an objective to effectively train these models for a general family of noise schedules based on conditional flow matching. Our method models the joint distribution of the latent representations of events in a sequence and achieves state-of-the-art results in predicting both the next inter-event time and event type on benchmark datasets. Additionally, it flexibly accommodates varying lengths of observation and prediction windows in different forecasting settings by adjusting the starting and ending points of the generation process. Finally, our method shows superior performance in long-horizon prediction tasks, outperforming existing baseline methods.</li>
</ul>

<h3>Title: Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation</h3>
<ul>
<li><strong>Authors: </strong>Joshua Chiu, Partha Protim Paul, Zahin Wahab</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20414">https://arxiv.org/abs/2504.20414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20414">https://arxiv.org/pdf/2504.20414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20414]] Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation(https://arxiv.org/abs/2504.20414)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, large language model</a></li>
<li><strong>Abstract: </strong>Searchable Symmetric Encryption (SSE) enables efficient search capabilities over encrypted data, allowing users to maintain privacy while utilizing cloud storage. However, SSE schemes are vulnerable to leakage attacks that exploit access patterns, search frequency, and volume information. Existing studies frequently assume that adversaries possess a substantial fraction of the encrypted dataset to mount effective inference attacks, implying there is a database leakage of such documents, thus, an assumption that may not hold in real-world scenarios. In this work, we investigate the feasibility of enhancing leakage attacks under a more realistic threat model in which adversaries have access to minimal leaked data. We propose a novel approach that leverages large language models (LLMs), specifically GPT-4 variants, to generate synthetic documents that statistically and semantically resemble the real-world dataset of Enron emails. Using the email corpus as a case study, we evaluate the effectiveness of synthetic data generated via random sampling and hierarchical clustering methods on the performance of the SAP (Search Access Pattern) keyword inference attack restricted to token volumes only. Our results demonstrate that, while the choice of LLM has limited effect, increasing dataset size and employing clustering-based generation significantly improve attack accuracy, achieving comparable performance to attacks using larger amounts of real data. We highlight the growing relevance of LLMs in adversarial contexts.</li>
</ul>

<h3>Title: Plant Disease Detection through Multimodal Large Language Models and Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Konstantinos I. Roumeliotis, Ranjan Sapkota, Manoj Karkee, Nikolaos D. Tselikas, Dimitrios K. Nasiopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20419">https://arxiv.org/abs/2504.20419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20419">https://arxiv.org/pdf/2504.20419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20419]] Plant Disease Detection through Multimodal Large Language Models and Convolutional Neural Networks(https://arxiv.org/abs/2504.20419)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automation in agriculture plays a vital role in addressing challenges related to crop monitoring and disease management, particularly through early detection systems. This study investigates the effectiveness of combining multimodal Large Language Models (LLMs), specifically GPT-4o, with Convolutional Neural Networks (CNNs) for automated plant disease classification using leaf imagery. Leveraging the PlantVillage dataset, we systematically evaluate model performance across zero-shot, few-shot, and progressive fine-tuning scenarios. A comparative analysis between GPT-4o and the widely used ResNet-50 model was conducted across three resolutions (100, 150, and 256 pixels) and two plant species (apple and corn). Results indicate that fine-tuned GPT-4o models achieved slightly better performance compared to the performance of ResNet-50, achieving up to 98.12% classification accuracy on apple leaf images, compared to 96.88% achieved by ResNet-50, with improved generalization and near-zero training loss. However, zero-shot performance of GPT-4o was significantly lower, underscoring the need for minimal training. Additional evaluations on cross-resolution and cross-plant generalization revealed the models' adaptability and limitations when applied to new domains. The findings highlight the promise of integrating multimodal LLMs into automated disease detection pipelines, enhancing the scalability and intelligence of precision agriculture systems while reducing the dependence on large, labeled datasets and high-resolution sensor infrastructure. Large Language Models, Vision Language Models, LLMs and CNNs, Disease Detection with Vision Language Models, VLMs</li>
</ul>

<h3>Title: Understanding GNNs and Homophily in Dynamic Node Classification</h3>
<ul>
<li><strong>Authors: </strong>Michael Ito, Danai Koutra, Jenna Wiens</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20421">https://arxiv.org/abs/2504.20421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20421">https://arxiv.org/pdf/2504.20421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20421]] Understanding GNNs and Homophily in Dynamic Node Classification(https://arxiv.org/abs/2504.20421)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Homophily, as a measure, has been critical to increasing our understanding of graph neural networks (GNNs). However, to date this measure has only been analyzed in the context of static graphs. In our work, we explore homophily in dynamic settings. Focusing on graph convolutional networks (GCNs), we demonstrate theoretically that in dynamic settings, current GCN discriminative performance is characterized by the probability that a node's future label is the same as its neighbors' current labels. Based on this insight, we propose dynamic homophily, a new measure of homophily that applies in the dynamic setting. This new measure correlates with GNN discriminative performance and sheds light on how to potentially design more powerful GNNs for dynamic graphs. Leveraging a variety of dynamic node classification datasets, we demonstrate that popular GNNs are not robust to low dynamic homophily. Going forward, our work represents an important step towards understanding homophily and GNN performance in dynamic node classification.</li>
</ul>

<h3>Title: Learning Laplacian Positional Encodings for Heterophilous Graphs</h3>
<ul>
<li><strong>Authors: </strong>Michael Ito, Jiong Zhu, Dexiong Chen, Danai Koutra, Jenna Wiens</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20430">https://arxiv.org/abs/2504.20430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20430">https://arxiv.org/pdf/2504.20430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20430]] Learning Laplacian Positional Encodings for Heterophilous Graphs(https://arxiv.org/abs/2504.20430)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this work, we theoretically demonstrate that current graph positional encodings (PEs) are not beneficial and could potentially hurt performance in tasks involving heterophilous graphs, where nodes that are close tend to have different labels. This limitation is critical as many real-world networks exhibit heterophily, and even highly homophilous graphs can contain local regions of strong heterophily. To address this limitation, we propose Learnable Laplacian Positional Encodings (LLPE), a new PE that leverages the full spectrum of the graph Laplacian, enabling them to capture graph structure on both homophilous and heterophilous graphs. Theoretically, we prove LLPE's ability to approximate a general class of graph distances and demonstrate its generalization properties. Empirically, our evaluation on 12 benchmarks demonstrates that LLPE improves accuracy across a variety of GNNs, including graph transformers, by up to 35% and 14% on synthetic and real-world graphs, respectively. Going forward, our work represents a significant step towards developing PEs that effectively capture complex structures in heterophilous graphs.</li>
</ul>

<h3>Title: AI Assisted Cervical Cancer Screening for Cytology Samples in Developing Countries</h3>
<ul>
<li><strong>Authors: </strong>Love Panta, Suraj Prasai, Karishma Malla Vaidya, Shyam Shrestha, Suresh Manandhar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20435">https://arxiv.org/abs/2504.20435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20435">https://arxiv.org/pdf/2504.20435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20435]] AI Assisted Cervical Cancer Screening for Cytology Samples in Developing Countries(https://arxiv.org/abs/2504.20435)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Cervical cancer remains a significant health challenge, with high incidence and mortality rates, particularly in transitioning countries. Conventional Liquid-Based Cytology(LBC) is a labor-intensive process, requires expert pathologists and is highly prone to errors, highlighting the need for more efficient screening methods. This paper introduces an innovative approach that integrates low-cost biological microscopes with our simple and efficient AI algorithms for automated whole-slide analysis. Our system uses a motorized microscope to capture cytology images, which are then processed through an AI pipeline involving image stitching, cell segmentation, and classification. We utilize the lightweight UNet-based model involving human-in-the-loop approach to train our segmentation model with minimal ROIs. CvT-based classification model, trained on the SIPaKMeD dataset, accurately categorizes five cell types. Our framework offers enhanced accuracy and efficiency in cervical cancer screening compared to various state-of-art methods, as demonstrated by different evaluation metrics.</li>
</ul>

<h3>Title: Network Attack Traffic Detection With Hybrid Quantum-Enhanced Convolution Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Zihao Wang, Kar Wai Fok, Vrizlynn L. L. Thing</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20436">https://arxiv.org/abs/2504.20436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20436">https://arxiv.org/pdf/2504.20436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20436]] Network Attack Traffic Detection With Hybrid Quantum-Enhanced Convolution Neural Network(https://arxiv.org/abs/2504.20436)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>The emerging paradigm of Quantum Machine Learning (QML) combines features of quantum computing and machine learning (ML). QML enables the generation and recognition of statistical data patterns that classical computers and classical ML methods struggle to effectively execute. QML utilizes quantum systems to enhance algorithmic computation speed and real-time data processing capabilities, making it one of the most promising tools in the field of ML. Quantum superposition and entanglement features also hold the promise to potentially expand the potential feature representation capabilities of ML. Therefore, in this study, we explore how quantum computing affects ML and whether it can further improve the detection performance on network traffic detection, especially on unseen attacks which are types of malicious traffic that do not exist in the ML training dataset. Classical ML models often perform poorly in detecting these unseen attacks because they have not been trained on such traffic. Hence, this paper focuses on designing and proposing novel hybrid structures of Quantum Convolutional Neural Network (QCNN) to achieve the detection of malicious traffic. The detection performance, generalization, and robustness of the QML solutions are evaluated and compared with classical ML running on classical computers. The emphasis lies in assessing whether the QML-based malicious traffic detection outperforms classical solutions. Based on experiment results, QCNN models demonstrated superior performance compared to classical ML approaches on unseen attack detection.</li>
</ul>

<h3>Title: GaLore 2: Large-Scale LLM Pre-Training by Gradient Low-Rank Projection</h3>
<ul>
<li><strong>Authors: </strong>DiJia Su, Andrew Gu, Jane Xu, Yuandong Tian, Jiawei Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20437">https://arxiv.org/abs/2504.20437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20437">https://arxiv.org/pdf/2504.20437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20437]] GaLore 2: Large-Scale LLM Pre-Training by Gradient Low-Rank Projection(https://arxiv.org/abs/2504.20437)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have revolutionized natural language understanding and generation but face significant memory bottlenecks during training. GaLore, Gradient Low-Rank Projection, addresses this issue by leveraging the inherent low-rank structure of weight gradients, enabling substantial memory savings without sacrificing performance. Recent works further extend GaLore from various aspects, including low-bit quantization and higher-order tensor structures. However, there are several remaining challenges for GaLore, such as the computational overhead of SVD for subspace updates and the integration with state-of-the-art training parallelization strategies (e.g., FSDP). In this paper, we present GaLore 2, an efficient and scalable GaLore framework that addresses these challenges and incorporates recent advancements. In addition, we demonstrate the scalability of GaLore 2 by pre-training Llama 7B from scratch using up to 500 billion training tokens, highlighting its potential impact on real LLM pre-training scenarios.</li>
</ul>

<h3>Title: PixelHacker: Image Inpainting with Structural and Semantic Consistency</h3>
<ul>
<li><strong>Authors: </strong>Ziyang Xu, Kangsheng Duan, Xiaolei Shen, Zhifeng Ding, Wenyu Liu, Xiaohu Ruan, Xiaoxin Chen, Xinggang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20438">https://arxiv.org/abs/2504.20438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20438">https://arxiv.org/pdf/2504.20438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20438]] PixelHacker: Image Inpainting with Structural and Semantic Consistency(https://arxiv.org/abs/2504.20438)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Image inpainting is a fundamental research area between image editing and image generation. Recent state-of-the-art (SOTA) methods have explored novel attention mechanisms, lightweight architectures, and context-aware modeling, demonstrating impressive performance. However, they often struggle with complex structure (e.g., texture, shape, spatial relations) and semantics (e.g., color consistency, object restoration, and logical correctness), leading to artifacts and inappropriate generation. To address this challenge, we design a simple yet effective inpainting paradigm called latent categories guidance, and further propose a diffusion-based model named PixelHacker. Specifically, we first construct a large dataset containing 14 million image-mask pairs by annotating foreground and background (potential 116 and 21 categories, respectively). Then, we encode potential foreground and background representations separately through two fixed-size embeddings, and intermittently inject these features into the denoising process via linear attention. Finally, by pre-training on our dataset and fine-tuning on open-source benchmarks, we obtain PixelHacker. Extensive experiments show that PixelHacker comprehensively outperforms the SOTA on a wide range of datasets (Places2, CelebA-HQ, and FFHQ) and exhibits remarkable consistency in both structure and semantics. Project page at this https URL.</li>
</ul>

<h3>Title: FT-MoE: Sustainable-learning Mixture of Experts Model for Fault-Tolerant Computing with Multiple Tasks</h3>
<ul>
<li><strong>Authors: </strong>Wenjing Xiao, Wenhao Song, Miaojiang Chen, Ruikun Luo, Min Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20446">https://arxiv.org/abs/2504.20446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20446">https://arxiv.org/pdf/2504.20446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20446]] FT-MoE: Sustainable-learning Mixture of Experts Model for Fault-Tolerant Computing with Multiple Tasks(https://arxiv.org/abs/2504.20446)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Intelligent fault-tolerant (FT) computing has recently demonstrated significant advantages of predicting and diagnosing faults in advance, enabling reliable service delivery. However, due to heterogeneity of fault knowledge and complex dependence relationships of time series log data, existing deep learning-based FT algorithms further improve detection performance relying on single neural network model with difficulty. To this end, we propose FT-MoE, a sustainable-learning mixture-of-experts model for fault-tolerant computing with multiple tasks, which enables different parameters learning distinct fault knowledge to achieve high-reliability for service system. Firstly, we use decoder-based transformer models to obtain fault prototype vectors of decoupling long-distance dependencies. Followed by, we present a dual mixture of experts networks for high-accurate prediction for both fault detection and classification tasks. Then, we design a two-stage optimization scheme of offline training and online tuning, which allows that in operation FT-MoE can also keep learning to adapt to dynamic service environments. Finally, to verify the effectiveness of FT-MoE, we conduct extensive experiments on the FT benchmark. Experimental results show that FT-MoE achieves superior performance compared to the state-of-the-art methods. Code will be available upon publication.</li>
</ul>

<h3>Title: Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Gabe Guo, Stefano Ermon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20456">https://arxiv.org/abs/2504.20456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20456">https://arxiv.org/pdf/2504.20456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20456]] Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding(https://arxiv.org/abs/2504.20456)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In arbitrary-order language models, it is an open question how to sample tokens in parallel from the correct joint distribution. With discrete diffusion models, the more tokens they generate in parallel, the less their predicted distributions adhere to the originally learned data distribution, as they rely on a conditional independence assumption that only works with infinitesimally small timesteps. We find that a different class of models, any-subset autoregressive models (AS-ARMs), holds the solution. As implied by the name, AS-ARMs can generate tokens in any order, and in parallel. Moreover, AS-ARMs support parallelized joint probability density estimation, allowing them to correct their own parallel-generated token distributions, via our Any-Subset Speculative Decoding (ASSD) algorithm. ASSD provably enables generation of tokens from the correct joint distribution, with the number of neural network calls upper bounded by the number of tokens predicted. We empirically verify that ASSD speeds up language generation, without sacrificing quality. Furthermore, we provide a mathematically justified scheme for training AS-ARMs for generation, and show that AS-ARMs achieve state-of-the-art performance among sub-200M parameter models on infilling benchmark tasks, and nearly match the performance of models 50X larger on code generation. Our theoretical and empirical results indicate that the once-forgotten AS-ARMs are a promising direction of language modeling.</li>
</ul>

<h3>Title: LMM4Gen3DHF: Benchmarking and Evaluating Multimodal 3D Human Face Generation with LMMs</h3>
<ul>
<li><strong>Authors: </strong>Woo Yi Yang, Jiarui Wang, Sijing Wu, Huiyu Duan, Yuxin Zhu, Liu Yang, Kang Fu, Guangtao Zhai, Xiongkuo Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20466">https://arxiv.org/abs/2504.20466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20466">https://arxiv.org/pdf/2504.20466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20466]] LMM4Gen3DHF: Benchmarking and Evaluating Multimodal 3D Human Face Generation with LMMs(https://arxiv.org/abs/2504.20466)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative</a></li>
<li><strong>Abstract: </strong>The rapid advancement in generative artificial intelligence have enabled the creation of 3D human faces (HFs) for applications including media production, virtual reality, security, healthcare, and game development, etc. However, assessing the quality and realism of these AI-generated 3D human faces remains a significant challenge due to the subjective nature of human perception and innate perceptual sensitivity to facial features. To this end, we conduct a comprehensive study on the quality assessment of AI-generated 3D human faces. We first introduce Gen3DHF, a large-scale benchmark comprising 2,000 videos of AI-Generated 3D Human Faces along with 4,000 Mean Opinion Scores (MOS) collected across two dimensions, i.e., quality and authenticity, 2,000 distortion-aware saliency maps and distortion descriptions. Based on Gen3DHF, we propose LMME3DHF, a Large Multimodal Model (LMM)-based metric for Evaluating 3DHF capable of quality and authenticity score prediction, distortion-aware visual question answering, and distortion-aware saliency prediction. Experimental results show that LMME3DHF achieves state-of-the-art performance, surpassing existing methods in both accurately predicting quality scores for AI-generated 3D human faces and effectively identifying distortion-aware salient regions and distortion types, while maintaining strong alignment with human perceptual judgments. Both the Gen3DHF database and the LMME3DHF will be released upon the publication.</li>
</ul>

<h3>Title: Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Enfa Fane, Mihai Surdeanu, Eduardo Blanco, Steven R. Corman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20469">https://arxiv.org/abs/2504.20469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20469">https://arxiv.org/pdf/2504.20469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20469]] Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large Language Models(https://arxiv.org/abs/2504.20469)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding how news narratives frame entities is crucial for studying media's impact on societal perceptions of events. In this paper, we evaluate the zero-shot capabilities of large language models (LLMs) in classifying framing roles. Through systematic experimentation, we assess the effects of input context, prompting strategies, and task decomposition. Our findings show that a hierarchical approach of first identifying broad roles and then fine-grained roles, outperforms single-step classification. We also demonstrate that optimal input contexts and prompts vary across task levels, highlighting the need for subtask-specific strategies. We achieve a Main Role Accuracy of 89.4% and an Exact Match Ratio of 34.5%, demonstrating the effectiveness of our approach. Our findings emphasize the importance of tailored prompt design and input context optimization for improving LLM performance in entity framing.</li>
</ul>

<h3>Title: The Estimation of Continual Causal Effect for Dataset Shifting Streams</h3>
<ul>
<li><strong>Authors: </strong>Baining Chen, Yiming Zhang, Yuqiao Han, Ruyue Zhang, Ruihuan Du, Zhishuo Zhou, Zhengdan Zhu, Xun Liu, Jiecheng Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20471">https://arxiv.org/abs/2504.20471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20471">https://arxiv.org/pdf/2504.20471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20471]] The Estimation of Continual Causal Effect for Dataset Shifting Streams(https://arxiv.org/abs/2504.20471)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Causal effect estimation has been widely used in marketing optimization. The framework of an uplift model followed by a constrained optimization algorithm is popular in practice. To enhance performance in the online environment, the framework needs to be improved to address the complexities caused by temporal dataset shift. This paper focuses on capturing the dataset shift from user behavior and domain distribution changing over time. We propose an Incremental Causal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle this challenge. The ICE-PKD framework includes two components: (i) a multi-treatment uplift network that eliminates confounding bias using counterfactual regression; (ii) an incremental training strategy that adapts to the temporal dataset shift by updating with the latest data and protects generalization via replay-based knowledge distillation. We also revisit the uplift modeling metrics and introduce a novel metric for more precise online evaluation in multiple treatment scenarios. Extensive experiments on both simulated and online datasets show that the proposed framework achieves better performance. The ICE-PKD framework has been deployed in the marketing system of Huaxiaozhu, a ride-hailing platform in China.</li>
</ul>

<h3>Title: Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction</h3>
<ul>
<li><strong>Authors: </strong>Yulin Chen, Haoran Li, Yuan Sui, Yue Liu, Yufei He, Yangqiu Song, Bryan Hooi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20472">https://arxiv.org/abs/2504.20472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20472">https://arxiv.org/pdf/2504.20472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20472]] Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction(https://arxiv.org/abs/2504.20472)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated impressive performance and have come to dominate the field of natural language processing (NLP) across various tasks. However, due to their strong instruction-following capabilities and inability to distinguish between instructions and data content, LLMs are vulnerable to prompt injection attacks. These attacks manipulate LLMs into deviating from the original input instructions and executing maliciously injected instructions within data content, such as web documents retrieved from search engines. Existing defense methods, including prompt-engineering and fine-tuning approaches, typically instruct models to follow the original input instructions while suppressing their tendencies to execute injected instructions. However, our experiments reveal that suppressing instruction-following tendencies is challenging. Through analyzing failure cases, we observe that although LLMs tend to respond to any recognized instructions, they are aware of which specific instructions they are executing and can correctly reference them within the original prompt. Motivated by these findings, we propose a novel defense method that leverages, rather than suppresses, the instruction-following abilities of LLMs. Our approach prompts LLMs to generate responses that include both answers and their corresponding instruction references. Based on these references, we filter out answers not associated with the original input instructions. Comprehensive experiments demonstrate that our method outperforms prompt-engineering baselines and achieves performance comparable to fine-tuning methods, reducing the attack success rate (ASR) to 0 percent in some scenarios. Moreover, our approach has minimal impact on overall utility.</li>
</ul>

<h3>Title: Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Linjuan Wu, Haoran Wei, Huan Lin, Tianhao Li, Baosong Yang, Weiming Lu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20484">https://arxiv.org/abs/2504.20484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20484">https://arxiv.org/pdf/2504.20484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20484]] Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training(https://arxiv.org/abs/2504.20484)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit remarkable multilingual capabilities despite English-dominated pre-training, attributed to cross-lingual mechanisms during pre-training. Existing methods for enhancing cross-lingual transfer remain constrained by parallel resources, suffering from limited linguistic and domain coverage. We propose Cross-lingual In-context Pre-training (CrossIC-PT), a simple and scalable approach that enhances cross-lingual transfer by leveraging semantically related bilingual texts via simple next-word prediction. We construct CrossIC-PT samples by interleaving semantic-related bilingual Wikipedia documents into a single context window. To access window size constraints, we implement a systematic segmentation policy to split long bilingual document pairs into chunks while adjusting the sliding window mechanism to preserve contextual coherence. We further extend data availability through a semantic retrieval framework to construct CrossIC-PT samples from web-crawled corpus. Experimental results demonstrate that CrossIC-PT improves multilingual performance on three models (Llama-3.1-8B, Qwen2.5-7B, and Qwen2.5-1.5B) across six target languages, yielding performance gains of 3.79%, 3.99%, and 1.95%, respectively, with additional improvements after data augmentation.</li>
</ul>

<h3>Title: Sleeping Giants - Activating Dormant Java Deserialization Gadget Chains through Stealthy Code Changes</h3>
<ul>
<li><strong>Authors: </strong>Bruno Kreyssig, Sabine Houy, Timothée Riom, Alexandre Bartel</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20485">https://arxiv.org/abs/2504.20485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20485">https://arxiv.org/pdf/2504.20485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20485]] Sleeping Giants - Activating Dormant Java Deserialization Gadget Chains through Stealthy Code Changes(https://arxiv.org/abs/2504.20485)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Java deserialization gadget chains are a well-researched critical software weakness. The vast majority of known gadget chains rely on gadgets from software dependencies. Furthermore, it has been shown that small code changes in dependencies have enabled these gadget chains. This makes gadget chain detection a purely reactive endeavor. Even if one dependency's deployment pipeline employs gadget chain detection, a gadget chain can still result from gadgets in other dependencies. In this work, we assess how likely small code changes are to enable a gadget chain. These changes could either be accidental or intentional as part of a supply chain attack. Specifically, we show that class serializability is a strongly fluctuating property over a dependency's evolution. Then, we investigate three change patterns by which an attacker could stealthily introduce gadgets into a dependency. We apply these patterns to 533 dependencies and run three state-of-the-art gadget chain detectors both on the original and the modified dependencies. The tools detect that applying the modification patterns can activate/inject gadget chains in 26.08% of the dependencies we selected. Finally, we verify the newly detected chains. As such, we identify dormant gadget chains in 53 dependencies that could be added through minor code modifications. This both shows that Java deserialization gadget chains are a broad liability to software and proves dormant gadget chains as a lucrative supply chain attack vector.</li>
</ul>

<h3>Title: Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression</h3>
<ul>
<li><strong>Authors: </strong>Yu Cui, Yujun Cai, Yiwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20493">https://arxiv.org/abs/2504.20493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20493">https://arxiv.org/pdf/2504.20493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20493]] Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression(https://arxiv.org/abs/2504.20493)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>While reasoning large language models (LLMs) demonstrate remarkable performance across various tasks, they also contain notable security vulnerabilities. Recent research has uncovered a "thinking-stopped" vulnerability in DeepSeek-R1, where model-generated reasoning tokens can forcibly interrupt the inference process, resulting in empty responses that compromise LLM-integrated applications. However, existing methods triggering this vulnerability require complex mathematical word problems with long prompts--even exceeding 5,000 tokens. To reduce the token cost and formally define this vulnerability, we propose a novel prompt injection attack named "Reasoning Interruption Attack", based on adaptive token compression. We demonstrate that simple standalone arithmetic tasks can effectively trigger this vulnerability, and the prompts based on such tasks exhibit simpler logical structures than mathematical word problems. We develop a systematic approach to efficiently collect attack prompts and an adaptive token compression framework that utilizes LLMs to automatically compress these prompts. Experiments show our compression framework significantly reduces prompt length while maintaining effective attack capabilities. We further investigate the attack's performance via output prefix and analyze the underlying causes of the vulnerability, providing valuable insights for improving security in reasoning LLMs.</li>
</ul>

<h3>Title: Large-scale visual SLAM for in-the-wild videos</h3>
<ul>
<li><strong>Authors: </strong>Shuo Sun, Torsten Sattler, Malcolm Mielle, Achim J. Lilienthal, Martin Magnusson</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20496">https://arxiv.org/abs/2504.20496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20496">https://arxiv.org/pdf/2504.20496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20496]] Large-scale visual SLAM for in-the-wild videos(https://arxiv.org/abs/2504.20496)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate and robust 3D scene reconstruction from casual, in-the-wild videos can significantly simplify robot deployment to new environments. However, reliable camera pose estimation and scene reconstruction from such unconstrained videos remains an open challenge. Existing visual-only SLAM methods perform well on benchmark datasets but struggle with real-world footage which often exhibits uncontrolled motion including rapid rotations and pure forward movements, textureless regions, and dynamic objects. We analyze the limitations of current methods and introduce a robust pipeline designed to improve 3D reconstruction from casual videos. We build upon recent deep visual odometry methods but increase robustness in several ways. Camera intrinsics are automatically recovered from the first few frames using structure-from-motion. Dynamic objects and less-constrained areas are masked with a predictive model. Additionally, we leverage monocular depth estimates to regularize bundle adjustment, mitigating errors in low-parallax situations. Finally, we integrate place recognition and loop closure to reduce long-term drift and refine both intrinsics and pose estimates through global bundle adjustment. We demonstrate large-scale contiguous 3D models from several online videos in various environments. In contrast, baseline methods typically produce locally inconsistent results at several points, producing separate segments or distorted maps. In lieu of ground-truth pose data, we evaluate map consistency, execution time and visual accuracy of re-rendered NeRF models. Our proposed system establishes a new baseline for visual reconstruction from casual uncontrolled videos found online, demonstrating more consistent reconstructions over longer sequences of in-the-wild videos than previously achieved.</li>
</ul>

<h3>Title: Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Jianhong Han, Yupei Wang, Liang Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20498">https://arxiv.org/abs/2504.20498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20498">https://arxiv.org/pdf/2504.20498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20498]] Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection(https://arxiv.org/abs/2504.20498)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Single-source Domain Generalization (SDG) in object detection aims to develop a detector using only data from a source domain that can exhibit strong generalization capability when applied to unseen target domains. Existing methods are built upon CNN-based detectors and primarily improve robustness by employing carefully designed data augmentation strategies integrated with feature alignment techniques. However, data augmentation methods have inherent drawbacks; they are only effective when the augmented sample distribution approximates or covers the unseen scenarios, thus failing to enhance generalization across all unseen domains. Furthermore, while the recent Detection Transformer (DETR) has demonstrated superior generalization capability in domain adaptation tasks due to its efficient global information extraction, its potential in SDG tasks remains unexplored. To this end, we introduce a strong DETR-based detector named the Style-Adaptive Detection Transformer (SA-DETR) for SDG in object detection. Specifically, we present a domain style adapter that projects the style representation of the unseen target domain into the training domain, enabling dynamic style adaptation. Then, we propose an object-aware contrastive learning module to guide the detector in extracting domain-invariant features through contrastive learning. By using object-aware gating masks to constrain feature aggregation in both spatial and semantic dimensions, this module achieves cross-domain contrast of instance-level features, thereby enhancing generalization. Extensive experiments demonstrate the superior performance and generalization capability of SA-DETR across five different weather scenarios. Code is released at this https URL.</li>
</ul>

<h3>Title: UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation</h3>
<ul>
<li><strong>Authors: </strong>Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20500">https://arxiv.org/abs/2504.20500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20500">https://arxiv.org/pdf/2504.20500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20500]] UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation(https://arxiv.org/abs/2504.20500)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present UniDetox, a universally applicable method designed to mitigate toxicity across various large language models (LLMs). Previous detoxification methods are typically model-specific, addressing only individual models or model families, and require careful hyperparameter tuning due to the trade-off between detoxification efficacy and language modeling performance. In contrast, UniDetox provides a detoxification technique that can be universally applied to a wide range of LLMs without the need for separate model-specific tuning. Specifically, we propose a novel and efficient dataset distillation technique for detoxification using contrastive decoding. This approach distills detoxifying representations in the form of synthetic text data, enabling universal detoxification of any LLM through fine-tuning with the distilled text. Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models, including OPT, Falcon, and LLaMA-2. Furthermore, UniDetox eliminates the need for separate hyperparameter tuning for each model, as a single hyperparameter configuration can be seamlessly applied across different models. Additionally, analysis of the detoxifying text reveals a reduction in politically biased content, providing insights into the attributes necessary for effective detoxification of LLMs.</li>
</ul>

<h3>Title: SteelBlastQC: Shot-blasted Steel Surface Dataset with Interpretable Detection of Surface Defects</h3>
<ul>
<li><strong>Authors: </strong>Irina Ruzavina, Lisa Sophie Theis, Jesse Lemeer, Rutger de Groen, Leo Ebeling, Andrej Hulak, Jouaria Ali, Guangzhi Tang, Rico Mockel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20510">https://arxiv.org/abs/2504.20510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20510">https://arxiv.org/pdf/2504.20510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20510]] SteelBlastQC: Shot-blasted Steel Surface Dataset with Interpretable Detection of Surface Defects(https://arxiv.org/abs/2504.20510)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Automating the quality control of shot-blasted steel surfaces is crucial for improving manufacturing efficiency and consistency. This study presents a dataset of 1654 labeled RGB images (512x512) of steel surfaces, classified as either "ready for paint" or "needs shot-blasting." The dataset captures real-world surface defects, including discoloration, welding lines, scratches and corrosion, making it well-suited for training computer vision models. Additionally, three classification approaches were evaluated: Compact Convolutional Transformers (CCT), Support Vector Machines (SVM) with ResNet-50 feature extraction, and a Convolutional Autoencoder (CAE). The supervised methods (CCT and SVM) achieve 95% classification accuracy on the test set, with CCT leveraging transformer-based attention mechanisms and SVM offering a computationally efficient alternative. The CAE approach, while less effective, establishes a baseline for unsupervised quality control. We present interpretable decision-making by all three neural networks, allowing industry users to visually pinpoint problematic regions and understand the model's rationale. By releasing the dataset and baseline codes, this work aims to support further research in defect detection, advance the development of interpretable computer vision models for quality control, and encourage the adoption of automated inspection systems in industrial applications.</li>
</ul>

<h3>Title: Dynamic Attention Analysis for Backdoor Detection in Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20518">https://arxiv.org/abs/2504.20518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20518">https://arxiv.org/pdf/2504.20518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20518]] Dynamic Attention Analysis for Backdoor Detection in Text-to-Image Diffusion Models(https://arxiv.org/abs/2504.20518)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, diffusion</a></li>
<li><strong>Abstract: </strong>Recent studies have revealed that text-to-image diffusion models are vulnerable to backdoor attacks, where attackers implant stealthy textual triggers to manipulate model outputs. Previous backdoor detection methods primarily focus on the static features of backdoor samples. However, a vital property of diffusion models is their inherent dynamism. This study introduces a novel backdoor detection perspective named Dynamic Attention Analysis (DAA), showing that these dynamic characteristics serve as better indicators for backdoor detection. Specifically, by examining the dynamic evolution of cross-attention maps, we observe that backdoor samples exhibit distinct feature evolution patterns at the $<$EOS$>$ token compared to benign samples. To quantify these dynamic anomalies, we first introduce DAA-I, which treats the tokens' attention maps as spatially independent and measures dynamic feature using the Frobenius norm. Furthermore, to better capture the interactions between attention maps and refine the feature, we propose a dynamical system-based approach, referred to as DAA-S. This model formulates the spatial correlations among attention maps using a graph-based state equation and we theoretically analyze the global asymptotic stability of this method. Extensive experiments across five representative backdoor attack scenarios demonstrate that our approach significantly surpasses existing detection methods, achieving an average F1 Score of 79.49% and an AUC of 87.67%. The code is available at this https URL.</li>
</ul>

<h3>Title: Wavelet-Filtering of Symbolic Music Representations for Folk Tune Segmentation and Classification</h3>
<ul>
<li><strong>Authors: </strong>Gissel Velarde, Tillman Weyde, David Meredith</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20522">https://arxiv.org/abs/2504.20522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20522">https://arxiv.org/pdf/2504.20522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20522]] Wavelet-Filtering of Symbolic Music Representations for Folk Tune Segmentation and Classification(https://arxiv.org/abs/2504.20522)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The aim of this study is to evaluate a machine-learning method in which symbolic representations of folk songs are segmented and classified into tune families with Haar-wavelet filtering. The method is compared with previously proposed Gestalt-based method. Melodies are represented as discrete symbolic pitch-time signals. We apply the continuous wavelet transform (CWT) with the Haar wavelet at specific scales, obtaining filtered versions of melodies emphasizing their information at particular time-scales. We use the filtered signal for representation and segmentation, using the wavelet coefficients' local maxima to indicate local boundaries and classify segments by means of k-nearest neighbours based on standard vector-metrics (Euclidean, cityblock), and compare the results to a Gestalt-based segmentation method and metrics applied directly to the pitch signal. We found that the wavelet based segmentation and wavelet-filtering of the pitch signal lead to better classification accuracy in cross-validated evaluation when the time-scale and other parameters are optimized.</li>
</ul>

<h3>Title: DeeP-Mod: Deep Dynamic Programming based Environment Modelling using Feature Extraction</h3>
<ul>
<li><strong>Authors: </strong>Chris Child, Lam Ngo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20535">https://arxiv.org/abs/2504.20535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20535">https://arxiv.org/pdf/2504.20535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20535]] DeeP-Mod: Deep Dynamic Programming based Environment Modelling using Feature Extraction(https://arxiv.org/abs/2504.20535)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The DeeP-Mod framework builds an environment model using features from a Deep Dynamic Programming Network (DDPN), trained via a Deep Q-Network (DQN). While Deep Q-Learning is effective in decision-making, state information is lost in deeper DQN layers due to mixed state-action representations. We address this by using Dynamic Programming (DP) to train a DDPN, where Value Iteration ensures the output represents state values, not state-action pairs. Extracting features from the DDPN preserves state information, enabling task and action set independence. We show that a reduced DDPN can be trained using features extracted from the original DDPN trained on an identical problem. This reduced DDPN achieves faster convergence under noise and outperforms the original DDPN. Finally, we introduce the DeeP-Mod framework, which creates an environment model using the evolution of features extracted from a DDPN in response to actions. A second DDPN, which learns directly from this feature model rather than raw states, can learn an effective feature-value representation and thus optimal policy. A key advantage of DeeP-Mod is that an externally defined environment model is not needed at any stage, making DDPN applicable to a wide range of environments.</li>
</ul>

<h3>Title: Starfish: Rebalancing Multi-Party Off-Chain Payment Channels</h3>
<ul>
<li><strong>Authors: </strong>Minghui Xu, Wenxuan Yu, Guangyong Shang, Guangpeng Qi, Dongliang Duan, Shan Wang, Kun Li, Yue Zhang, Xiuzhen Cheng</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20536">https://arxiv.org/abs/2504.20536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20536">https://arxiv.org/pdf/2504.20536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20536]] Starfish: Rebalancing Multi-Party Off-Chain Payment Channels(https://arxiv.org/abs/2504.20536)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Blockchain technology has revolutionized the way transactions are executed, but scalability remains a major challenge. Payment Channel Network (PCN), as a Layer-2 scaling solution, has been proposed to address this issue. However, skewed payments can deplete the balance of one party within a channel, restricting the ability of PCNs to transact through a path and subsequently reducing the transaction success rate. To address this issue, the technology of rebalancing has been proposed. However, existing rebalancing strategies in PCNs are limited in their capacity and efficiency. Cycle-based approaches only address rebalancing within groups of nodes that form a cycle network, while non-cycle-based approaches face high complexity of on-chain operations and limitations on rebalancing capacity. In this study, we propose Starfish, a rebalancing approach that captures the star-shaped network structure to provide high rebalancing efficiency and large channel capacity. Starfish requires only $N$-time on-chain operations to connect independent channels and aggregate the total budget of all channels. To demonstrate the correctness and advantages of our method, we provide a formal security proof of the Starfish protocol and conduct comparative experiments with existing rebalancing techniques.</li>
</ul>

<h3>Title: Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for Electronic Health Records</h3>
<ul>
<li><strong>Authors: </strong>Jesus Lovon (IRIT-IRIS), Thouria Ben-Haddi, Jules Di Scala, Jose G. Moreno (IRIT-IRIS), Lynda Tamine (IRIT-IRIS)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20547">https://arxiv.org/abs/2504.20547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20547">https://arxiv.org/pdf/2504.20547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20547]] Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for Electronic Health Records(https://arxiv.org/abs/2504.20547)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The lack of standardized evaluation benchmarks in the medical domain for text inputs can be a barrier to widely adopting and leveraging the potential of natural language models for health-related downstream tasks. This paper revisited an openly available MIMIC-IV benchmark for electronic health records (EHRs) to address this issue. First, we integrate the MIMIC-IV data within the Hugging Face datasets library to allow an easy share and use of this collection. Second, we investigate the application of templates to convert EHR tabular data to text. Experiments using fine-tuned and zero-shot LLMs on the mortality of patients task show that fine-tuned text-based models are competitive against robust tabular classifiers. In contrast, zero-shot LLMs struggle to leverage EHR representations. This study underlines the potential of text-based approaches in the medical field and highlights areas for further improvement.</li>
</ul>

<h3>Title: BrAIcht, a theatrical agent that speaks like Bertolt Brecht's characters</h3>
<ul>
<li><strong>Authors: </strong>Baz Roland, Kristina Malyseva, Anna Pappa (LIASD), Tristan Cazenave (APA)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20552">https://arxiv.org/abs/2504.20552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20552">https://arxiv.org/pdf/2504.20552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20552]] BrAIcht, a theatrical agent that speaks like Bertolt Brecht's characters(https://arxiv.org/abs/2504.20552)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This project introduces BrAIcht, an AI conversational agent that creates dialogues in the distinctive style of the famous German playwright Bertolt Brecht. BrAIcht is fine-tuned using German LeoLM, a large language model with 7 billion parameters and a modified version of the base Llama2 suitable for German language tasks. For fine-tuning, 29 plays of Bertolt Brecht and 907 of other German plays that are stylistically similar to Bertolt Brecht are used to form a more di-erse dataset. Due to the limited memory capacity, a parameterefficient fine-tuning technique called QLoRA is implemented to train the large language model. The results, based on BLEU score and perplexity, show very promising performance of BrAIcht in generating dialogues in the style of Bertolt Brecht.</li>
</ul>

<h3>Title: Mutual Information Minimization for Side-Channel Attack Resistance via Optimal Noise Injection</h3>
<ul>
<li><strong>Authors: </strong>Jiheon Woo, Daewon Seo, Young-Sik Kim, Namyoon Lee, Yuval Cassuto, Yongjune Kim</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20556">https://arxiv.org/abs/2504.20556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20556">https://arxiv.org/pdf/2504.20556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20556]] Mutual Information Minimization for Side-Channel Attack Resistance via Optimal Noise Injection(https://arxiv.org/abs/2504.20556)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Side-channel attacks (SCAs) pose a serious threat to system security by extracting secret keys through physical leakages such as power consumption, timing variations, and electromagnetic emissions. Among existing countermeasures, artificial noise injection is recognized as one of the most effective techniques. However, its high power consumption poses a major challenge for resource-constrained systems such as Internet of Things (IoT) devices, motivating the development of more efficient protection schemes. In this paper, we model SCAs as a communication channel and aim to suppress information leakage by minimizing the mutual information between the secret information and side-channel observations, subject to a power constraint on the artificial noise. We propose an optimal artificial noise injection method to minimize the mutual information in systems with Gaussian inputs. Specifically, we formulate two convex optimization problems: 1) minimizing the total mutual information, and 2) minimizing the maximum mutual information across observations. Numerical results show that the proposed methods significantly reduce both total and maximum mutual information compared to conventional techniques, confirming their effectiveness for resource-constrained, security-critical systems.</li>
</ul>

<h3>Title: Digital Shielding for Cross-Domain Wi-Fi Signal Adaptation using Relativistic Average Generative Adversarial Network</h3>
<ul>
<li><strong>Authors: </strong>Danilo Avola, Federica Bruni, Gian Luca Foresti, Daniele Pannone, Amedeo Ranaldi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20568">https://arxiv.org/abs/2504.20568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20568">https://arxiv.org/pdf/2504.20568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20568]] Digital Shielding for Cross-Domain Wi-Fi Signal Adaptation using Relativistic Average Generative Adversarial Network(https://arxiv.org/abs/2504.20568)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, generative</a></li>
<li><strong>Abstract: </strong>Wi-Fi sensing uses radio-frequency signals from Wi-Fi devices to analyze environments, enabling tasks such as tracking people, detecting intrusions, and recognizing gestures. The rise of this technology is driven by the IEEE 802.11bf standard and growing demand for tools that can ensure privacy and operate through obstacles. However, the performance of Wi-Fi sensing is heavily influenced by environmental conditions, especially when extracting spatial and temporal features from the surrounding scene. A key challenge is achieving robust generalization across domains, ensuring stable performance even when the sensing environment changes significantly. This paper introduces a novel deep learning model for cross-domain adaptation of Wi-Fi signals, inspired by physical signal shielding. The model uses a Relativistic average Generative Adversarial Network (RaGAN) with Bidirectional Long Short-Term Memory (Bi-LSTM) architectures for both the generator and discriminator. To simulate physical shielding, an acrylic box lined with electromagnetic shielding fabric was constructed, mimicking a Faraday cage. Wi-Fi signal spectra were collected from various materials both inside (domain-free) and outside (domain-dependent) the box to train the model. A multi-class Support Vector Machine (SVM) was trained on domain-free spectra and tested on signals denoised by the RaGAN. The system achieved 96% accuracy and demonstrated strong material discrimination capabilities, offering potential for use in security applications to identify concealed objects based on their composition.</li>
</ul>

<h3>Title: VIMU: Effective Physics-based Realtime Detection and Recovery against Stealthy Attacks on UAVs</h3>
<ul>
<li><strong>Authors: </strong>Yunbo Wang, Cong Sun, Qiaosen Liu, Bingnan Su, Zongxu Zhang, Michael Norris, Gang Tan, Jianfeng Ma</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20569">https://arxiv.org/abs/2504.20569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20569">https://arxiv.org/pdf/2504.20569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20569]] VIMU: Effective Physics-based Realtime Detection and Recovery against Stealthy Attacks on UAVs(https://arxiv.org/abs/2504.20569)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>Sensor attacks on robotic vehicles have become pervasive and manipulative. Their latest advancements exploit sensor and detector characteristics to bypass detection. Recent security efforts have leveraged the physics-based model to detect or mitigate sensor attacks. However, these approaches are only resilient to a few sensor attacks and still need improvement in detection effectiveness. We present VIMU, an efficient sensor attack detection and resilience system for unmanned aerial vehicles. We propose a detection algorithm, CS-EMA, that leverages low-pass filtering to identify stealthy gyroscope attacks while achieving an overall effective sensor attack detection. We develop a fine-grained nonlinear physical model with precise aerodynamic and propulsion wrench modeling. We also augment the state estimation with a FIFO buffer safeguard to mitigate the impact of high-rate IMU attacks. The proposed physical model and buffer safeguard provide an effective system state recovery toward maintaining flight stability. We implement VIMU on PX4 autopilot. The evaluation results demonstrate the effectiveness of VIMU in detecting and mitigating various realistic sensor attacks, especially stealthy attacks.</li>
</ul>

<h3>Title: ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jin Xie, Ruishi He, Songze Li, Xiaojun Jia, Shouling Ji</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20570">https://arxiv.org/abs/2504.20570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20570">https://arxiv.org/pdf/2504.20570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20570]] ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models(https://arxiv.org/abs/2504.20570)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, extraction, federate, large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) has emerged as a practical solution for adapting large language models (LLMs) to custom datasets with significantly reduced computational cost. When carrying out PEFT under collaborative learning scenarios (e.g., federated learning), it is often required to exchange model updates (or gradients) across parties. These gradients, even with limited dimensions, can cause severe breach of data privacy. Recent works have shown that both contextual prefixes and personally identifiable information (PII) can be exposed through gradients. However, \emph{simultaneously} and \emph{accurately} recovering both components from the same training instance remains infeasible due to the following challenges: 1) limited number of PEFT parameters; 2) high-dimensional token spaces; and 3) large batch sizes. We propose ReCIT, a novel privacy attack that addresses all challenges, and achieves recovery of \emph{full} private data from PEFT gradients with high fidelity. Specifically, ReCIT proposes to enhance the memorization capability of the pre-trained model through malicious fine-tuning with Personal Notes; ReCIT also proposes a novel filter-based token extraction technique and a token pairing mechanism, to accurately reconstruct tokens from the training sequences with large batch sizes. Extensive evaluations show that ReCIT consistently outperforms state-of-the-art gradient inversion and memorization-based attacks across different PEFT paradigms. It achieves up to 10$\times$ higher PII recovery rates and remains effective across varying batch sizes, especially in settings where prefix reconstruction is intractable for conventional approaches. These findings highlight an urgent need to reassess the privacy guarantees of PEFT, especially in decentralized or shared training environments.</li>
</ul>

<h3>Title: Reinforcement Learning for Reasoning in Large Language Models with One Training Example</h3>
<ul>
<li><strong>Authors: </strong>Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20571">https://arxiv.org/abs/2504.20571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20571">https://arxiv.org/pdf/2504.20571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20571]] Reinforcement Learning for Reasoning in Large Language Models with One Training Example(https://arxiv.org/abs/2504.20571)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We show that reinforcement learning with verifiable reward using one training example (1-shot RLVR) is effective in incentivizing the math reasoning capabilities of large language models (LLMs). Applying RLVR to the base model Qwen2.5-Math-1.5B, we identify a single example that elevates model performance on MATH500 from 36.0% to 73.6%, and improves the average performance across six common mathematical reasoning benchmarks from 17.6% to 35.7%. This result matches the performance obtained using the 1.2k DeepScaleR subset (MATH500: 73.6%, average: 35.9%), which includes the aforementioned example. Similar substantial improvements are observed across various models (Qwen2.5-Math-7B, Llama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and PPO), and different math examples (many of which yield approximately 30% or greater improvement on MATH500 when employed as a single training example). In addition, we identify some interesting phenomena during 1-shot RLVR, including cross-domain generalization, increased frequency of self-reflection, and sustained test performance improvement even after the training accuracy has saturated, a phenomenon we term post-saturation generalization. Moreover, we verify that the effectiveness of 1-shot RLVR primarily arises from the policy gradient loss, distinguishing it from the "grokking" phenomenon. We also show the critical role of promoting exploration (e.g., by adding entropy loss with an appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe that applying entropy loss alone, without any outcome reward, significantly enhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%. These findings can inspire future work on RLVR data efficiency and encourage a re-examination of both recent progress and the underlying mechanisms in RLVR. Our code, model, and data are open source at this https URL</li>
</ul>

<h3>Title: PartHOI: Part-based Hand-Object Interaction Transfer via Generalized Cylinders</h3>
<ul>
<li><strong>Authors: </strong>Qiaochu Wang, Chufeng Xiao, Manfred Lau, Hongbo Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20599">https://arxiv.org/abs/2504.20599</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20599">https://arxiv.org/pdf/2504.20599</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20599]] PartHOI: Part-based Hand-Object Interaction Transfer via Generalized Cylinders(https://arxiv.org/abs/2504.20599)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning-based methods to understand and model hand-object interactions (HOI) require a large amount of high-quality HOI data. One way to create HOI data is to transfer hand poses from a source object to another based on the objects' geometry. However, current methods for transferring hand poses between objects rely on shape matching, limiting the ability to transfer poses across different categories due to differences in their shapes and sizes. We observe that HOI often involves specific semantic parts of objects, which often have more consistent shapes across categories. In addition, constructing size-invariant correspondences between these parts is important for cross-category transfer. Based on these insights, we introduce a novel method PartHOI for part-based HOI transfer. Using a generalized cylinder representation to parameterize an object parts' geometry, PartHOI establishes a robust geometric correspondence between object parts, and enables the transfer of contact points. Given the transferred points, we optimize a hand pose to fit the target object well. Qualitative and quantitative results demonstrate that our method can generalize HOI transfers well even for cross-category objects, and produce high-fidelity results that are superior to the existing methods.</li>
</ul>

<h3>Title: WenyanGPT: A Large Language Model for Classical Chinese Tasks</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Yao, Mengdi Wang, Bo Chen, Xiaobing Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20609">https://arxiv.org/abs/2504.20609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20609">https://arxiv.org/pdf/2504.20609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20609]] WenyanGPT: A Large Language Model for Classical Chinese Tasks(https://arxiv.org/abs/2504.20609)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Classical Chinese, as the core carrier of Chinese culture, plays a crucial role in the inheritance and study of ancient literature. However, existing natural language processing models primarily optimize for Modern Chinese, resulting in inadequate performance on Classical Chinese. This paper presents a comprehensive solution for Classical Chinese language processing. By continuing pre-training and instruction fine-tuning on the LLaMA3-8B-Chinese model, we construct a large language model, WenyanGPT, which is specifically designed for Classical Chinese tasks. Additionally, we develop an evaluation benchmark dataset, WenyanBENCH. Experimental results on WenyanBENCH demonstrate that WenyanGPT significantly outperforms current advanced LLMs in various Classical Chinese tasks. We make the model's training data, instruction fine-tuning data\footnote, and evaluation benchmark dataset publicly available to promote further research and development in the field of Classical Chinese processing.</li>
</ul>

<h3>Title: The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Swaroop Dora, Deven Lunkad, Naziya Aslam, S. Venkatesan, Sandeep Kumar Shukla</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20612">https://arxiv.org/abs/2504.20612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20612">https://arxiv.org/pdf/2504.20612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20612]] The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models(https://arxiv.org/abs/2504.20612)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Large Language Models (LLMs) has enhanced software development processes, minimizing the time and effort required for coding and enhancing developer productivity. However, despite their potential benefits, code generated by LLMs has been shown to generate insecure code in controlled environments, raising critical concerns about their reliability and security in real-world applications. This paper uses predefined security parameters to evaluate the security compliance of LLM-generated code across multiple models, such as ChatGPT, DeepSeek, Claude, Gemini and Grok. The analysis reveals critical vulnerabilities in authentication mechanisms, session management, input validation and HTTP security headers. Although some models implement security measures to a limited extent, none fully align with industry best practices, highlighting the associated risks in automated software development. Our findings underscore that human expertise is crucial to ensure secure software deployment or review of LLM-generated code. Also, there is a need for robust security assessment frameworks to enhance the reliability of LLM-generated code in real-world applications.</li>
</ul>

<h3>Title: A Novel Cipher for Enhancing MAVLink Security: Design, Security Analysis, and Performance Evaluation Using a Drone Testbed</h3>
<ul>
<li><strong>Authors: </strong>Bhavya Dixit, Ananthapadmanabhan A., Adheeba Thahsin, Saketh Pathak, Gaurav S. Kasbekar, Arnab Maity</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20626">https://arxiv.org/abs/2504.20626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20626">https://arxiv.org/pdf/2504.20626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20626]] A Novel Cipher for Enhancing MAVLink Security: Design, Security Analysis, and Performance Evaluation Using a Drone Testbed(https://arxiv.org/abs/2504.20626)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>We present MAVShield, a novel lightweight cipher designed to secure communications in Unmanned Aerial Vehicles (UAVs) using the MAVLink protocol, which by default transmits unencrypted messages between UAVs and Ground Control Stations (GCS). While existing studies propose encryption for MAVLink, most remain theoretical or simulation-based. We implement MAVShield alongside AES-CTR, ChaCha20, Speck-CTR, and Rabbit, and evaluate them on a real drone testbed. A comprehensive security analysis using statistical test suites (NIST and Diehard) demonstrates strong resistance of the novel cipher to cryptanalysis. Performance evaluation across key metrics including memory usage, CPU load, and battery power consumption, demonstrates that MAVShield outperforms existing algorithms and offers an efficient, real-world solution for securing MAVLink communications in UAVs.</li>
</ul>

<h3>Title: AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation</h3>
<ul>
<li><strong>Authors: </strong>Jeongsoo Choi, Ji-Hoon Kim, Kim Sung-Bin, Tae-Hyun Oh, Joon Son Chung</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20629">https://arxiv.org/abs/2504.20629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20629">https://arxiv.org/pdf/2504.20629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20629]] AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation(https://arxiv.org/abs/2504.20629)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we address the task of multimodal-to-speech generation, which aims to synthesize high-quality speech from multiple input modalities: text, video, and reference audio. This task has gained increasing attention due to its wide range of applications, such as film production, dubbing, and virtual avatars. Despite recent progress, existing methods still suffer from limitations in speech intelligibility, audio-video synchronization, speech naturalness, and voice similarity to the reference speaker. To address these challenges, we propose AlignDiT, a multimodal Aligned Diffusion Transformer that generates accurate, synchronized, and natural-sounding speech from aligned multimodal inputs. Built upon the in-context learning capability of the DiT architecture, AlignDiT explores three effective strategies to align multimodal representations. Furthermore, we introduce a novel multimodal classifier-free guidance mechanism that allows the model to adaptively balance information from each modality during speech synthesis. Extensive experiments demonstrate that AlignDiT significantly outperforms existing methods across multiple benchmarks in terms of quality, synchronization, and speaker similarity. Moreover, AlignDiT exhibits strong generalization capability across various multimodal tasks, such as video-to-speech synthesis and visual forced alignment, consistently achieving state-of-the-art performance. The demo page is available at this https URL .</li>
</ul>

<h3>Title: Bridging the Generalisation Gap: Synthetic Data Generation for Multi-Site Clinical Model Validation</h3>
<ul>
<li><strong>Authors: </strong>Bradley Segal, Joshua Fieggen, David Clifton, Lei Clifton</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20635">https://arxiv.org/abs/2504.20635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20635">https://arxiv.org/pdf/2504.20635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20635]] Bridging the Generalisation Gap: Synthetic Data Generation for Multi-Site Clinical Model Validation(https://arxiv.org/abs/2504.20635)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, generative</a></li>
<li><strong>Abstract: </strong>Ensuring the generalisability of clinical machine learning (ML) models across diverse healthcare settings remains a significant challenge due to variability in patient demographics, disease prevalence, and institutional practices. Existing model evaluation approaches often rely on real-world datasets, which are limited in availability, embed confounding biases, and lack the flexibility needed for systematic experimentation. Furthermore, while generative models aim for statistical realism, they often lack transparency and explicit control over factors driving distributional shifts. In this work, we propose a novel structured synthetic data framework designed for the controlled benchmarking of model robustness, fairness, and generalisability. Unlike approaches focused solely on mimicking observed data, our framework provides explicit control over the data generating process, including site-specific prevalence variations, hierarchical subgroup effects, and structured feature interactions. This enables targeted investigation into how models respond to specific distributional shifts and potential biases. Through controlled experiments, we demonstrate the framework's ability to isolate the impact of site variations, support fairness-aware audits, and reveal generalisation failures, particularly highlighting how model complexity interacts with site-specific effects. This work contributes a reproducible, interpretable, and configurable tool designed to advance the reliable deployment of ML in clinical settings.</li>
</ul>

<h3>Title: Protocol Dialects as Formal Patterns: A Composable Theory of Lingos - Technical report</h3>
<ul>
<li><strong>Authors: </strong>Víctor García, Santiago Escobar, Catherine Meadows, Jose Meseguer</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20637">https://arxiv.org/abs/2504.20637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20637">https://arxiv.org/pdf/2504.20637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20637]] Protocol Dialects as Formal Patterns: A Composable Theory of Lingos - Technical report(https://arxiv.org/abs/2504.20637)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Protocol dialects are methods for modifying protocols that provide light-weight security, especially against easy attacks that can lead to more serious ones. A lingo is a dialect's key security component by making attackers unable to "speak" the lingo. A lingo's "talk" changes all the time, becoming a moving target for attackers. We present several kinds of lingo transformations and compositions to generate stronger lingos from simpler ones, thus making dialects more secure.</li>
</ul>

<h3>Title: Decision-centric fairness: Evaluation and optimization for resource allocation problems</h3>
<ul>
<li><strong>Authors: </strong>Simon De Vos, Jente Van Belle, Andres Algaba, Wouter Verbeke, Sam Verboven</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20642">https://arxiv.org/abs/2504.20642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20642">https://arxiv.org/pdf/2504.20642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20642]] Decision-centric fairness: Evaluation and optimization for resource allocation problems(https://arxiv.org/abs/2504.20642)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Data-driven decision support tools play an increasingly central role in decision-making across various domains. In this work, we focus on binary classification models for predicting positive-outcome scores and deciding on resource allocation, e.g., credit scores for granting loans or churn propensity scores for targeting customers with a retention campaign. Such models may exhibit discriminatory behavior toward specific demographic groups through their predicted scores, potentially leading to unfair resource allocation. We focus on demographic parity as a fairness metric to compare the proportions of instances that are selected based on their positive outcome scores across groups. In this work, we propose a decision-centric fairness methodology that induces fairness only within the decision-making region -- the range of relevant decision thresholds on the score that may be used to decide on resource allocation -- as an alternative to a global fairness approach that seeks to enforce parity across the entire score distribution. By restricting the induction of fairness to the decision-making region, the proposed decision-centric approach avoids imposing overly restrictive constraints on the model, which may unnecessarily degrade the quality of the predicted scores. We empirically compare our approach to a global fairness approach on multiple (semi-synthetic) datasets to identify scenarios in which focusing on fairness where it truly matters, i.e., decision-centric fairness, proves beneficial.</li>
</ul>

<h3>Title: Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations</h3>
<ul>
<li><strong>Authors: </strong>Moran Mizrahi, Chen Shani, Gabriel Stanovsky, Dan Jurafsky, Dafna Shahaf</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20643">https://arxiv.org/abs/2504.20643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20643">https://arxiv.org/pdf/2504.20643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20643]] Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations(https://arxiv.org/abs/2504.20643)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel at countless tasks, yet struggle with creativity. In this paper, we introduce a novel approach that couples LLMs with structured representations and cognitively inspired manipulations to generate more creative and diverse ideas. Our notion of creativity goes beyond superficial token-level variations; rather, we explicitly recombine structured representations of existing ideas, allowing our algorithm to effectively explore the more abstract landscape of ideas. We demonstrate our approach in the culinary domain with DishCOVER, a model that generates creative recipes. Experiments comparing our model's results to those of GPT-4o show greater diversity. Domain expert evaluations reveal that our outputs, which are mostly coherent and feasible culinary creations, significantly surpass GPT-4o in terms of novelty, thus outperforming it in creative generation. We hope our work inspires further research into structured creativity in AI.</li>
</ul>

<h3>Title: Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection</h3>
<ul>
<li><strong>Authors: </strong>Ziqing Fan, Siyuan Du, Shengchao Hu, Pingjie Wang, Li Shen, Ya Zhang, Dacheng Tao, Yanfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20644">https://arxiv.org/abs/2504.20644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20644">https://arxiv.org/pdf/2504.20644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20644]] Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection(https://arxiv.org/abs/2504.20644)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Selecting high-quality pre-training data for large language models (LLMs) is crucial for enhancing their overall performance under limited computation budget, improving both training and sample efficiency. Recent advancements in file selection primarily rely on using an existing or trained proxy model to assess the similarity of samples to a target domain, such as high quality sources BookCorpus and Wikipedia. However, upon revisiting these methods, the domain-similarity selection criteria demonstrates a diversity dilemma, this http URL collapse in the feature space, improving performance on the domain-related tasks but causing severe degradation on generic performance. To prevent collapse and enhance diversity, we propose a DiverSified File selection algorithm (DiSF), which selects the most decorrelated text files in the feature space. We approach this with a classical greedy algorithm to achieve more uniform eigenvalues in the feature covariance matrix of the selected texts, analyzing its approximation to the optimal solution under a formulation of $\gamma$-weakly submodular optimization problem. Empirically, we establish a benchmark and conduct extensive experiments on the TinyLlama architecture with models from 120M to 1.1B parameters. Evaluating across nine tasks from the Harness framework, DiSF demonstrates a significant improvement on overall performance. Specifically, DiSF saves 98.5% of 590M training files in SlimPajama, outperforming the full-data pre-training within a 50B training budget, and achieving about 1.5x training efficiency and 5x data efficiency.</li>
</ul>

<h3>Title: LDPoly: Latent Diffusion for Polygonal Road Outline Extraction in Large-Scale Topographic Mapping</h3>
<ul>
<li><strong>Authors: </strong>Weiqin Jiao, Hao Cheng, George Vosselman, Claudio Persello</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20645">https://arxiv.org/abs/2504.20645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20645">https://arxiv.org/pdf/2504.20645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20645]] LDPoly: Latent Diffusion for Polygonal Road Outline Extraction in Large-Scale Topographic Mapping(https://arxiv.org/abs/2504.20645)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Polygonal road outline extraction from high-resolution aerial images is an important task in large-scale topographic mapping, where roads are represented as vectorized polygons, capturing essential geometric features with minimal vertex redundancy. Despite its importance, no existing method has been explicitly designed for this task. While polygonal building outline extraction has been extensively studied, the unique characteristics of roads, such as branching structures and topological connectivity, pose challenges to these methods. To address this gap, we introduce LDPoly, the first dedicated framework for extracting polygonal road outlines from high-resolution aerial images. Our method leverages a novel Dual-Latent Diffusion Model with a Channel-Embedded Fusion Module, enabling the model to simultaneously generate road masks and vertex heatmaps. A tailored polygonization method is then applied to obtain accurate vectorized road polygons with minimal vertex redundancy. We evaluate LDPoly on a new benchmark dataset, Map2ImLas, which contains detailed polygonal annotations for various topographic objects in several Dutch regions. Our experiments include both in-region and cross-region evaluations, with the latter designed to assess the model's generalization performance on unseen regions. Quantitative and qualitative results demonstrate that LDPoly outperforms state-of-the-art polygon extraction methods across various metrics, including pixel-level coverage, vertex efficiency, polygon regularity, and road connectivity. We also design two new metrics to assess polygon simplicity and boundary smoothness. Moreover, this work represents the first application of diffusion models for extracting precise vectorized object outlines without redundant vertices from remote-sensing imagery, paving the way for future advancements in this field.</li>
</ul>

<h3>Title: Federated learning, ethics, and the double black box problem in medical AI</h3>
<ul>
<li><strong>Authors: </strong>Joshua Hatherley, Anders Søgaard, Angela Ballantyne, Ruben Pauwels</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20656">https://arxiv.org/abs/2504.20656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20656">https://arxiv.org/pdf/2504.20656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20656]] Federated learning, ethics, and the double black box problem in medical AI(https://arxiv.org/abs/2504.20656)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a machine learning approach that allows multiple devices or institutions to collaboratively train a model without sharing their local data with a third-party. FL is considered a promising way to address patient privacy concerns in medical artificial intelligence. The ethical risks of medical FL systems themselves, however, have thus far been underexamined. This paper aims to address this gap. We argue that medical FL presents a new variety of opacity -- federation opacity -- that, in turn, generates a distinctive double black box problem in healthcare AI. We highlight several instances in which the anticipated benefits of medical FL may be exaggerated, and conclude by highlighting key challenges that must be overcome to make FL ethically feasible in medicine.</li>
</ul>

<h3>Title: Quantum-Enhanced Hybrid Reinforcement Learning Framework for Dynamic Path Planning in Autonomous Systems</h3>
<ul>
<li><strong>Authors: </strong>Sahil Tomar, Shamshe Alam, Sandeep Kumar, Amit Mathur</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.ET, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20660">https://arxiv.org/abs/2504.20660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20660">https://arxiv.org/pdf/2504.20660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20660]] Quantum-Enhanced Hybrid Reinforcement Learning Framework for Dynamic Path Planning in Autonomous Systems(https://arxiv.org/abs/2504.20660)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, a novel quantum classical hybrid framework is proposed that synergizes quantum with Classical Reinforcement Learning. By leveraging the inherent parallelism of quantum computing, the proposed approach generates robust Q tables and specialized turn cost estimations, which are then integrated with a classical Reinforcement Learning pipeline. The Classical Quantum fusion results in rapid convergence of training, reducing the training time significantly and improved adaptability in scenarios featuring static, dynamic, and moving obstacles. Simulator based evaluations demonstrate significant enhancements in path efficiency, trajectory smoothness, and mission success rates, underscoring the potential of framework for real time, autonomous navigation in complex and unpredictable environments. Furthermore, the proposed framework was tested beyond simulations on practical scenarios, including real world map data such as the IIT Delhi campus, reinforcing its potential for real time, autonomous navigation in complex and unpredictable environments.</li>
</ul>

<h3>Title: SFi-Former: Sparse Flow Induced Attention for Graph Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zhonghao Li, Ji Shi, Xinming Zhang, Miao Zhang, Bo Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20666">https://arxiv.org/abs/2504.20666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20666">https://arxiv.org/pdf/2504.20666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20666]] SFi-Former: Sparse Flow Induced Attention for Graph Transformer(https://arxiv.org/abs/2504.20666)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Graph Transformers (GTs) have demonstrated superior performance compared to traditional message-passing graph neural networks in many studies, especially in processing graph data with long-range dependencies. However, GTs tend to suffer from weak inductive bias, overfitting and over-globalizing problems due to the dense attention. In this paper, we introduce SFi-attention, a novel attention mechanism designed to learn sparse pattern by minimizing an energy function based on network flows with l1-norm regularization, to relieve those issues caused by dense attention. Furthermore, SFi-Former is accordingly devised which can leverage the sparse attention pattern of SFi-attention to generate sparse network flows beyond adjacency matrix of graph data. Specifically, SFi-Former aggregates features selectively from other nodes through flexible adaptation of the sparse attention, leading to a more robust model. We validate our SFi-Former on various graph datasets, especially those graph data exhibiting long-range dependencies. Experimental results show that our SFi-Former obtains competitive performance on GNN Benchmark datasets and SOTA performance on LongRange Graph Benchmark (LRGB) datasets. Additionally, our model gives rise to smaller generalization gaps, which indicates that it is less prone to over-fitting. Click here for codes.</li>
</ul>

<h3>Title: Explanations Go Linear: Interpretable and Individual Latent Encoding for Post-hoc Explainability</h3>
<ul>
<li><strong>Authors: </strong>Simone Piaggesi, Riccardo Guidotti, Fosca Giannotti, Dino Pedreschi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20667">https://arxiv.org/abs/2504.20667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20667">https://arxiv.org/pdf/2504.20667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20667]] Explanations Go Linear: Interpretable and Individual Latent Encoding for Post-hoc Explainability(https://arxiv.org/abs/2504.20667)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Post-hoc explainability is essential for understanding black-box machine learning models. Surrogate-based techniques are widely used for local and global model-agnostic explanations but have significant limitations. Local surrogates capture non-linearities but are computationally expensive and sensitive to parameters, while global surrogates are more efficient but struggle with complex local behaviors. In this paper, we present ILLUME, a flexible and interpretable framework grounded in representation learning, that can be integrated with various surrogate models to provide explanations for any black-box classifier. Specifically, our approach combines a globally trained surrogate with instance-specific linear transformations learned with a meta-encoder to generate both local and global explanations. Through extensive empirical evaluations, we demonstrate the effectiveness of ILLUME in producing feature attributions and decision rules that are not only accurate but also robust and faithful to the black-box, thus providing a unified explanation framework that effectively addresses the limitations of traditional surrogate methods.</li>
</ul>

<h3>Title: A Generative-AI-Driven Claim Retrieval System Capable of Detecting and Retrieving Claims from Social Media Platforms in Multiple Languages</h3>
<ul>
<li><strong>Authors: </strong>Ivan Vykopal, Martin Hyben, Robert Moro, Michal Gregor, Jakub Simko</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20668">https://arxiv.org/abs/2504.20668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20668">https://arxiv.org/pdf/2504.20668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20668]] A Generative-AI-Driven Claim Retrieval System Capable of Detecting and Retrieving Claims from Social Media Platforms in Multiple Languages(https://arxiv.org/abs/2504.20668)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Online disinformation poses a global challenge, placing significant demands on fact-checkers who must verify claims efficiently to prevent the spread of false information. A major issue in this process is the redundant verification of already fact-checked claims, which increases workload and delays responses to newly emerging claims. This research introduces an approach that retrieves previously fact-checked claims, evaluates their relevance to a given input, and provides supplementary information to support fact-checkers. Our method employs large language models (LLMs) to filter irrelevant fact-checks and generate concise summaries and explanations, enabling fact-checkers to faster assess whether a claim has been verified before. In addition, we evaluate our approach through both automatic and human assessments, where humans interact with the developed tool to review its effectiveness. Our results demonstrate that LLMs are able to filter out many irrelevant fact-checks and, therefore, reduce effort and streamline the fact-checking process.</li>
</ul>

<h3>Title: Advance Fake Video Detection via Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Joy Battocchio (1), Stefano Dell'Anna (1), Andrea Montibeller (1), Giulia Boato (1,2) ((1) University of Trento, Trento, Italy, (2) Truebees srl, Trento, Italy)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20669">https://arxiv.org/abs/2504.20669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20669">https://arxiv.org/pdf/2504.20669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20669]] Advance Fake Video Detection via Vision Transformers(https://arxiv.org/abs/2504.20669)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in AI-based multimedia generation have enabled the creation of hyper-realistic images and videos, raising concerns about their potential use in spreading misinformation. The widespread accessibility of generative techniques, which allow for the production of fake multimedia from prompts or existing media, along with their continuous refinement, underscores the urgent need for highly accurate and generalizable AI-generated media detection methods, underlined also by new regulations like the European Digital AI Act. In this paper, we draw inspiration from Vision Transformer (ViT)-based fake image detection and extend this idea to video. We propose an {original} %innovative framework that effectively integrates ViT embeddings over time to enhance detection performance. Our method shows promising accuracy, generalization, and few-shot learning capabilities across a new, large and diverse dataset of videos generated using five open source generative techniques from the state-of-the-art, as well as a separate dataset containing videos produced by proprietary generative methods.</li>
</ul>

<h3>Title: Occlusion-aware Driver Monitoring System using the Driver Monitoring Dataset</h3>
<ul>
<li><strong>Authors: </strong>Paola Natalia Cañas, Alexander Diez, David Galvañ, Marcos Nieto, Igor Rodríguez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20677">https://arxiv.org/abs/2504.20677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20677">https://arxiv.org/pdf/2504.20677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20677]] Occlusion-aware Driver Monitoring System using the Driver Monitoring Dataset(https://arxiv.org/abs/2504.20677)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a robust, occlusion-aware driver monitoring system (DMS) utilizing the Driver Monitoring Dataset (DMD). The system performs driver identification, gaze estimation by regions, and face occlusion detection under varying lighting conditions, including challenging low-light scenarios. Aligned with EuroNCAP recommendations, the inclusion of occlusion detection enhances situational awareness and system trustworthiness by indicating when the system's performance may be degraded. The system employs separate algorithms trained on RGB and infrared (IR) images to ensure reliable functioning. We detail the development and integration of these algorithms into a cohesive pipeline, addressing the challenges of working with different sensors and real-car implementation. Evaluation on the DMD and in real-world scenarios demonstrates the effectiveness of the proposed system, highlighting the superior performance of RGB-based models and the pioneering contribution of robust occlusion detection in DMS.</li>
</ul>

<h3>Title: Data Encryption Battlefield: A Deep Dive into the Dynamic Confrontations in Ransomware Attacks</h3>
<ul>
<li><strong>Authors: </strong>Arash Mahboubi, Hamed Aboutorab, Seyit Camtepe, Hang Thanh Bui, Khanh Luong, Keyvan Ansari, Shenlu Wang, Bazara Barry</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20681">https://arxiv.org/abs/2504.20681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20681">https://arxiv.org/pdf/2504.20681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20681]] Data Encryption Battlefield: A Deep Dive into the Dynamic Confrontations in Ransomware Attacks(https://arxiv.org/abs/2504.20681)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>In the rapidly evolving landscape of cybersecurity threats, ransomware represents a significant challenge. Attackers increasingly employ sophisticated encryption methods, such as entropy reduction through Base64 encoding, and partial or intermittent encryption to evade traditional detection methods. This study explores the dynamic battle between adversaries who continuously refine encryption strategies and defenders developing advanced countermeasures to protect vulnerable data. We investigate the application of online incremental machine learning algorithms designed to predict file encryption activities despite adversaries evolving obfuscation techniques. Our analysis utilizes an extensive dataset of 32.6 GB, comprising 11,928 files across multiple formats, including Microsoft Word documents (doc), PowerPoint presentations (ppt), Excel spreadsheets (xlsx), image formats (jpg, jpeg, png, tif, gif), PDFs (pdf), audio (mp3), and video (mp4) files. These files were encrypted by 75 distinct ransomware families, facilitating a robust empirical evaluation of machine learning classifiers effectiveness against diverse encryption tactics. Results highlight the Hoeffding Tree algorithms superior incremental learning capability, particularly effective in detecting traditional and AES-Base64 encryption methods employed to lower entropy. Conversely, the Random Forest classifier with warm-start functionality excels at identifying intermittent encryption methods, demonstrating the necessity of tailored machine learning solutions to counter sophisticated ransomware strategies.</li>
</ul>

<h3>Title: OG-HFYOLO :Orientation gradient guidance and heterogeneous feature fusion for deformation table cell instance segmentation</h3>
<ul>
<li><strong>Authors: </strong>Long Liu, Cihui Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20682">https://arxiv.org/abs/2504.20682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20682">https://arxiv.org/pdf/2504.20682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20682]] OG-HFYOLO :Orientation gradient guidance and heterogeneous feature fusion for deformation table cell instance segmentation(https://arxiv.org/abs/2504.20682)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Table structure recognition is a key task in document analysis. However, the geometric deformation in deformed tables causes a weak correlation between content information and structure, resulting in downstream tasks not being able to obtain accurate content information. To obtain fine-grained spatial coordinates of cells, we propose the OG-HFYOLO model, which enhances the edge response by Gradient Orientation-aware Extractor, combines a Heterogeneous Kernel Cross Fusion module and a scale-aware loss function to adapt to multi-scale objective features, and introduces mask-driven non-maximal suppression in the post-processing, which replaces the traditional bounding box suppression mechanism. Furthermore, we also propose a data generator, filling the gap in the dataset for fine-grained deformation table cell spatial coordinate localization, and derive a large-scale dataset named Deformation Wired Table (DWTAL). Experiments show that our proposed model demonstrates excellent segmentation accuracy on all mainstream instance segmentation models. The dataset and the source code are open source: this https URL.</li>
</ul>

<h3>Title: Efficient Listener: Dyadic Facial Motion Synthesis via Action Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Zesheng Wang, Alexandre Bruckert, Patrick Le Callet, Guangtao Zhai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20685">https://arxiv.org/abs/2504.20685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20685">https://arxiv.org/pdf/2504.20685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20685]] Efficient Listener: Dyadic Facial Motion Synthesis via Action Diffusion(https://arxiv.org/abs/2504.20685)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating realistic listener facial motions in dyadic conversations remains challenging due to the high-dimensional action space and temporal dependency requirements. Existing approaches usually consider extracting 3D Morphable Model (3DMM) coefficients and modeling in the 3DMM space. However, this makes the computational speed of the 3DMM a bottleneck, making it difficult to achieve real-time interactive responses. To tackle this problem, we propose Facial Action Diffusion (FAD), which introduces the diffusion methods from the field of image generation to achieve efficient facial action generation. We further build the Efficient Listener Network (ELNet) specially designed to accommodate both the visual and audio information of the speaker as input. Considering of FAD and ELNet, the proposed method learns effective listener facial motion representations and leads to improvements of performance over the state-of-the-art methods while reducing 99% computational time.</li>
</ul>

<h3>Title: What's Wrong with Your Synthetic Tabular Data? Using Explainable AI to Evaluate Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Jan Kapar, Niklas Koenen, Martin Jullum</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20687">https://arxiv.org/abs/2504.20687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20687">https://arxiv.org/pdf/2504.20687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20687]] What's Wrong with Your Synthetic Tabular Data? Using Explainable AI to Evaluate Generative Models(https://arxiv.org/abs/2504.20687)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Evaluating synthetic tabular data is challenging, since they can differ from the real data in so many ways. There exist numerous metrics of synthetic data quality, ranging from statistical distances to predictive performance, often providing conflicting results. Moreover, they fail to explain or pinpoint the specific weaknesses in the synthetic data. To address this, we apply explainable AI (XAI) techniques to a binary detection classifier trained to distinguish real from synthetic data. While the classifier identifies distributional differences, XAI concepts such as feature importance and feature effects, analyzed through methods like permutation feature importance, partial dependence plots, Shapley values and counterfactual explanations, reveal why synthetic data are distinguishable, highlighting inconsistencies, unrealistic dependencies, or missing patterns. This interpretability increases transparency in synthetic data evaluation and provides deeper insights beyond conventional metrics, helping diagnose and improve synthetic data quality. We apply our approach to two tabular datasets and generative models, showing that it uncovers issues overlooked by standard evaluation techniques.</li>
</ul>

<h3>Title: DICOM Compatible, 3D Multimodality Image Encryption using Hyperchaotic Signal</h3>
<ul>
<li><strong>Authors: </strong>Anandik N Anand, Sishu Shankar Muni, Abhishek Kaushik</a></li>
<li><strong>Subjects: </strong>cs.CR, nlin.CD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20689">https://arxiv.org/abs/2504.20689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20689">https://arxiv.org/pdf/2504.20689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20689]] DICOM Compatible, 3D Multimodality Image Encryption using Hyperchaotic Signal(https://arxiv.org/abs/2504.20689)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Medical image encryption plays an important role in protecting sensitive health information from cyberattacks and unauthorized access. In this paper, we introduce a secure and robust encryption scheme that is multi-modality compatible and works with MRI, CT, X-Ray and Ultrasound images for different anatomical region of interest. The method utilizes hyperchaotic signals and multi-level diffusion methods. The encryption starts by taking DICOM image as input, then padding to increase the image area. Chaotic signals are produced by a logistic map and are used to carry out pixel random permutation. Then, multi-level diffusion is carried out by 4-bit, 8-bit, radial and adjacent diffusion to provide high randomness and immunity against statistical attacks. In addition, we propose a captcha-based authentication scheme to further improve security. An algorithm generates alphanumeric captcha-based image which is encrypted with the same chaotic and diffusion methods as the medical image. Both encrypted images(DICOM image and captcha image) are then superimposed to create a final encrypted output, essentially integrating dual-layer security. Upon decryption, the superimposed image is again decomposed back to original medical and captcha images, and inverse operations are performed to obtain the original unencrypted data. Experimental results show that the proposed method provides strong protection with no loss in image integrity, thereby reducing unauthorized data breaches to a significant level. The dual-encryption approach not only protects the confidentiality of the medical images but also enhances authentication by incorporating captcha.</li>
</ul>

<h3>Title: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zechuan Zhang, Ji Xie, Yu Lu, Zongxin Yang, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20690">https://arxiv.org/abs/2504.20690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20690">https://arxiv.org/pdf/2504.20690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20690]] In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer(https://arxiv.org/abs/2504.20690)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Instruction-based image editing enables robust image modification via natural language prompts, yet current methods face a precision-efficiency tradeoff. Fine-tuning methods demand significant computational resources and large datasets, while training-free techniques struggle with instruction comprehension and edit quality. We resolve this dilemma by leveraging large-scale Diffusion Transformer (DiT)' enhanced generation capacity and native contextual awareness. Our solution introduces three contributions: (1) an in-context editing framework for zero-shot instruction compliance using in-context prompting, avoiding structural changes; (2) a LoRA-MoE hybrid tuning strategy that enhances flexibility with efficient adaptation and dynamic expert routing, without extensive retraining; and (3) an early filter inference-time scaling method using vision-language models (VLMs) to select better initial noise early, improving edit quality. Extensive evaluations demonstrate our method's superiority: it outperforms state-of-the-art approaches while requiring only 0.5% training data and 1% trainable parameters compared to conventional baselines. This work establishes a new paradigm that enables high-precision yet efficient instruction-guided editing. Codes and demos can be found in this https URL.</li>
</ul>

<h3>Title: Building Trust in Healthcare with Privacy Techniques: Blockchain in the Cloud</h3>
<ul>
<li><strong>Authors: </strong>Ferhat Ozgur Catak, Chunming Rong, Øyvind Meinich-Bache, Sara Brunner, Kjersti Engan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20700">https://arxiv.org/abs/2504.20700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20700">https://arxiv.org/pdf/2504.20700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20700]] Building Trust in Healthcare with Privacy Techniques: Blockchain in the Cloud(https://arxiv.org/abs/2504.20700)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect</a></li>
<li><strong>Abstract: </strong>This study introduces a cutting-edge architecture developed for the NewbornTime project, which uses advanced AI to analyze video data at birth and during newborn resuscitation, with the aim of improving newborn care. The proposed architecture addresses the crucial issues of patient consent, data security, and investing trust in healthcare by integrating Ethereum blockchain with cloud computing. Our blockchain-based consent application simplifies patient consent's secure and transparent management. We explain the smart contract mechanisms and privacy measures employed, ensuring data protection while permitting controlled data sharing among authorized parties. This work demonstrates the potential of combining blockchain and cloud technologies in healthcare, emphasizing their role in maintaining data integrity, with implications for computer science and healthcare innovation.</li>
</ul>

<h3>Title: BrightCookies at SemEval-2025 Task 9: Exploring Data Augmentation for Food Hazard Classification</h3>
<ul>
<li><strong>Authors: </strong>Foteini Papadopoulou, Osman Mutlu, Neris Özen, Bas H.M. van der Velden, Iris Hendrickx, Ali Hürriyetoğlu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20703">https://arxiv.org/abs/2504.20703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20703">https://arxiv.org/pdf/2504.20703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20703]] BrightCookies at SemEval-2025 Task 9: Exploring Data Augmentation for Food Hazard Classification(https://arxiv.org/abs/2504.20703)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents our system developed for the SemEval-2025 Task 9: The Food Hazard Detection Challenge. The shared task's objective is to evaluate explainable classification systems for classifying hazards and products in two levels of granularity from food recall incident reports. In this work, we propose text augmentation techniques as a way to improve poor performance on minority classes and compare their effect for each category on various transformer and machine learning models. We explore three word-level data augmentation techniques, namely synonym replacement, random word swapping, and contextual word insertion. The results show that transformer models tend to have a better overall performance. None of the three augmentation techniques consistently improved overall performance for classifying hazards and products. We observed a statistically significant improvement (P < 0.05) in the fine-grained categories when using the BERT model to compare the baseline with each augmented model. Compared to the baseline, the contextual words insertion augmentation improved the accuracy of predictions for the minority hazard classes by 6%. This suggests that targeted augmentation of minority classes can improve the performance of transformer models.</li>
</ul>

<h3>Title: Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think</h3>
<ul>
<li><strong>Authors: </strong>Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20708">https://arxiv.org/abs/2504.20708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20708">https://arxiv.org/pdf/2504.20708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20708]] Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think(https://arxiv.org/abs/2504.20708)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) leverage step-by-step reasoning to solve complex problems. Standard evaluation practice involves generating a complete reasoning trace and assessing the correctness of the final answer presented at its conclusion. In this paper, we challenge the reliance on the final answer by posing the following two questions: Does the final answer reliably represent the model's optimal conclusion? Can alternative reasoning paths yield different results? To answer these questions, we analyze intermediate reasoning steps, termed subthoughts, and propose a method based on our findings. Our approach involves segmenting a reasoning trace into sequential subthoughts based on linguistic cues. We start by prompting the model to generate continuations from the end-point of each intermediate subthought. We extract a potential answer from every completed continuation originating from different subthoughts. We find that aggregating these answers by selecting the most frequent one (the mode) often yields significantly higher accuracy compared to relying solely on the answer derived from the original complete trace. Analyzing the consistency among the answers derived from different subthoughts reveals characteristics that correlate with the model's confidence and correctness, suggesting potential for identifying less reliable answers. Our experiments across various LLMs and challenging mathematical reasoning datasets (AIME2024 and AIME2025) show consistent accuracy improvements, with gains reaching up to 13\% and 10\% respectively. Implementation is available at: this https URL.</li>
</ul>

<h3>Title: Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Roman Abramov, Felix Steinbauer, Gjergji Kasneci</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20752">https://arxiv.org/abs/2504.20752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20752">https://arxiv.org/pdf/2504.20752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20752]] Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers(https://arxiv.org/abs/2504.20752)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have achieved great success in numerous NLP tasks but continue to exhibit notable gaps in multi-step factual reasoning, especially when real-world knowledge is sparse. Recent advances in grokking have demonstrated that neural networks can transition from memorizing to perfectly generalizing once they detect underlying logical patterns - yet these studies have primarily used small, synthetic tasks. In this paper, for the first time, we extend grokking to real-world factual data and address the challenge of dataset sparsity by augmenting existing knowledge graphs with carefully designed synthetic data to raise the ratio $\phi_r$ of inferred facts to atomic facts above the threshold required for grokking. Surprisingly, we find that even factually incorrect synthetic data can strengthen emergent reasoning circuits rather than degrade accuracy, as it forces the model to rely on relational structure rather than memorization. When evaluated on multi-hop reasoning benchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA - substantially improving over strong baselines and matching or exceeding current state-of-the-art results. We further provide an in-depth analysis of how increasing $\phi_r$ drives the formation of generalizing circuits inside Transformers. Our findings suggest that grokking-based data augmentation can unlock implicit multi-hop reasoning capabilities, opening the door to more robust and interpretable factual reasoning in large-scale language models.</li>
</ul>

<h3>Title: DDPS: Discrete Diffusion Posterior Sampling for Paths in Layered Graphs</h3>
<ul>
<li><strong>Authors: </strong>Hao Luan, See-Kiong Ng, Chun Kai Ling</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20754">https://arxiv.org/abs/2504.20754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20754">https://arxiv.org/pdf/2504.20754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20754]] DDPS: Discrete Diffusion Posterior Sampling for Paths in Layered Graphs(https://arxiv.org/abs/2504.20754)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models form an important class of generative models today, accounting for much of the state of the art in cutting edge AI research. While numerous extensions beyond image and video generation exist, few of such approaches address the issue of explicit constraints in the samples generated. In this paper, we study the problem of generating paths in a layered graph (a variant of a directed acyclic graph) using discrete diffusion models, while guaranteeing that our generated samples are indeed paths. Our approach utilizes a simple yet effective representation for paths which we call the padded adjacency-list matrix (PALM). In addition, we show how to effectively perform classifier guidance, which helps steer the sampled paths to specific preferred edges without any retraining of the diffusion model. Our preliminary results show that empirically, our method outperforms alternatives which do not explicitly account for path constraints.</li>
</ul>

<h3>Title: did:self A registry-less DID method</h3>
<ul>
<li><strong>Authors: </strong>Nikos Fotiou, George C. Polyzos, Vasilios A. Siris</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20767">https://arxiv.org/abs/2504.20767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20767">https://arxiv.org/pdf/2504.20767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20767]] did:self A registry-less DID method(https://arxiv.org/abs/2504.20767)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>We introduce did:self, a Decentralized Identifier (DID) method that does not depend on any trusted registry for storing the corresponding DID documents. Information for authenticating a did:self subject can be disseminated using any means and without making any security assumption about the delivery method. did:self is lightweight, it allows controlled delegation, it offers increased security and privacy, and it can be used for identifying people, content, as well as IoT devices. Furthermore, DID documents in did:self can be implicit, allowing re-construction of DID documents based on other authentication material, such as JSON Web Tokens and X.509 certificates.</li>
</ul>

<h3>Title: Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption</h3>
<ul>
<li><strong>Authors: </strong>Wenxiao Wang, Parsa Hosseini, Soheil Feizi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20769">https://arxiv.org/abs/2504.20769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20769">https://arxiv.org/pdf/2504.20769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20769]] Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption(https://arxiv.org/abs/2504.20769)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-thought prompting has demonstrated great success in facilitating the reasoning abilities of large language models. In this work, we explore how these enhanced reasoning abilities can be exploited to improve the robustness of large language models in tasks that are not necessarily reasoning-focused. In particular, we show how a wide range of large language models exhibit significantly improved robustness against reference corruption using a simple method called chain-of-defensive-thought, where only a few exemplars with structured and defensive reasoning are provided as demonstrations. Empirically, the improvements can be astounding, especially given the simplicity and applicability of the method. For example, in the Natural Questions task, the accuracy of GPT-4o degrades from 60% to as low as 3% with standard prompting when 1 out of 10 references provided is corrupted with prompt injection attacks. In contrast, GPT-4o using chain-of-defensive-thought prompting maintains an accuracy of 50%.</li>
</ul>

<h3>Title: JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation</h3>
<ul>
<li><strong>Authors: </strong>Ji Shi, Chengxun Xie, Zhonghao Li, Xinming Zhang, Miao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20770">https://arxiv.org/abs/2504.20770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20770">https://arxiv.org/pdf/2504.20770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20770]] JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation(https://arxiv.org/abs/2504.20770)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>The discovery of new molecules based on the original chemical molecule distributions is of great importance in medicine. The graph transformer, with its advantages of high performance and scalability compared to traditional graph networks, has been widely explored in recent research for applications of graph structures. However, current transformer-based graph decoders struggle to effectively utilize graph information, which limits their capacity to leverage only sequences of nodes rather than the complex topological structures of molecule graphs. This paper focuses on building a graph transformer-based framework for molecular generation, which we call \textbf{JTreeformer} as it transforms graph generation into junction tree generation. It combines GCN parallel with multi-head attention as the encoder. It integrates a directed acyclic GCN into a graph-based Transformer to serve as a decoder, which can iteratively synthesize the entire molecule by leveraging information from the partially constructed molecular structure at each step. In addition, a diffusion model is inserted in the latent space generated by the encoder, to enhance the efficiency and effectiveness of sampling further. The empirical results demonstrate that our novel framework outperforms existing molecule generation methods, thus offering a promising tool to advance drug discovery (this https URL).</li>
</ul>

<h3>Title: Turing Machine Evaluation for Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Haitao Wu, Zongbo Han, Huaxi Huang, Changqing Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20771">https://arxiv.org/abs/2504.20771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20771">https://arxiv.org/pdf/2504.20771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20771]] Turing Machine Evaluation for Large Language Model(https://arxiv.org/abs/2504.20771)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid development and widespread application of Large Language Models (LLMs), rigorous evaluation has become particularly crucial. This research adopts a novel perspective, focusing on evaluating the core computational reasoning ability of LLMs, defined as the capacity of model to accurately understand rules, and execute logically computing operations. This capability assesses the reliability of LLMs as precise executors, and is critical to advanced tasks such as complex code generation and multi-step problem-solving. We propose an evaluation framework based on Universal Turing Machine (UTM) simulation. This framework requires LLMs to strictly follow instructions and track dynamic states, such as tape content and read/write head position, during multi-step computations. To enable standardized evaluation, we developed TMBench, a benchmark for systematically studying the computational reasoning capabilities of LLMs. TMBench provides several key advantages, including knowledge-agnostic evaluation, adjustable difficulty, foundational coverage through Turing machine encoding, and unlimited capacity for instance generation, ensuring scalability as models continue to evolve. We find that model performance on TMBench correlates strongly with performance on other recognized reasoning benchmarks (Pearson correlation coefficient is 0.73), clearly demonstrating that computational reasoning is a significant dimension for measuring the deep capabilities of LLMs. Code and data are available at this https URL.</li>
</ul>

<h3>Title: Q-Fusion: Diffusing Quantum Circuits</h3>
<ul>
<li><strong>Authors: </strong>Collin Beaudoin, Swaroop Ghosh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20794">https://arxiv.org/abs/2504.20794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20794">https://arxiv.org/pdf/2504.20794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20794]] Q-Fusion: Diffusing Quantum Circuits(https://arxiv.org/abs/2504.20794)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Quantum computing holds great potential for solving socially relevant and computationally complex problems. Furthermore, quantum machine learning (QML) promises to rapidly improve our current machine learning capabilities. However, current noisy intermediate-scale quantum (NISQ) devices are constrained by limitations in the number of qubits and gate counts, which hinder their full capabilities. Furthermore, the design of quantum algorithms remains a laborious task, requiring significant domain expertise and time. Quantum Architecture Search (QAS) aims to streamline this process by automatically generating novel quantum circuits, reducing the need for manual intervention. In this paper, we propose a diffusion-based algorithm leveraging the LayerDAG framework to generate new quantum circuits. This method contrasts with other approaches that utilize large language models (LLMs), reinforcement learning (RL), variational autoencoders (VAE), and similar techniques. Our results demonstrate that the proposed model consistently generates 100% valid quantum circuit outputs.</li>
</ul>

<h3>Title: Unlocking User-oriented Pages: Intention-driven Black-box Scanner for Real-world Web Applications</h3>
<ul>
<li><strong>Authors: </strong>Weizhe Wang, Yao Zhang, Kaitai Liang, Guangquan Xu, Hongpeng Bai, Qingyang Yan, Xi Zheng, Bin Wu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20801">https://arxiv.org/abs/2504.20801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20801">https://arxiv.org/pdf/2504.20801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20801]] Unlocking User-oriented Pages: Intention-driven Black-box Scanner for Real-world Web Applications(https://arxiv.org/abs/2504.20801)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Black-box scanners have played a significant role in detecting vulnerabilities for web applications. A key focus in current black-box scanning is increasing test coverage (i.e., accessing more web pages). However, since many web applications are user-oriented, some deep pages can only be accessed through complex user interactions, which are difficult to reach by existing black-box scanners. To fill this gap, a key insight is that web pages contain a wealth of semantic information that can aid in understanding potential user intention. Based on this insight, we propose Hoyen, a black-box scanner that uses the Large Language Model to predict user intention and provide guidance for expanding the scanning scope. Hoyen has been rigorously evaluated on 12 popular open-source web applications and compared with 6 representative tools. The results demonstrate that Hoyen performs a comprehensive exploration of web applications, expanding the attack surface while achieving about 2x than the coverage of other scanners on average, with high request accuracy. Furthermore, Hoyen detected over 90% of its requests towards the core functionality of the application, detecting more vulnerabilities than other scanners, including unique vulnerabilities in well-known web applications. Our data/code is available at this https URL</li>
</ul>

<h3>Title: An approach to melodic segmentation and classification based on filtering with the Haar-wavelet</h3>
<ul>
<li><strong>Authors: </strong>Gissel Velarde, Tillman Weyde, David Meredith</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20822">https://arxiv.org/abs/2504.20822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20822">https://arxiv.org/pdf/2504.20822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20822]] An approach to melodic segmentation and classification based on filtering with the Haar-wavelet(https://arxiv.org/abs/2504.20822)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We present a novel method of classification and segmentation of melodies in symbolic representation. The method is based on filtering pitch as a signal over time with the Haar-wavelet, and we evaluate it on two tasks. The filtered signal corresponds to a single-scale signal ws from the continuous Haar wavelet transform. The melodies are first segmented using local maxima or zero-crossings of w_s. The segments of w_s are then classified using the k-nearest neighbour algorithm with Euclidian and city-block distances. The method proves more effective than using unfiltered pitch signals and Gestalt-based segmentation when used to recognize the parent works of segments from Bach's Two-Part Inventions (BWV 772-786). When used to classify 360 Dutch folk tunes into 26 tune families, the performance of the method is comparable to the use of pitch signals, but not as good as that of string-matching methods based on multiple features.</li>
</ul>

<h3>Title: Hybrid Quantum Recurrent Neural Network For Remaining Useful Life Prediction</h3>
<ul>
<li><strong>Authors: </strong>Olga Tsurkan, Aleksandra Konstantinova, Aleksandr Sedykh, Dmitrii Zhiganov, Arsenii Senokosov, Daniil Tarpanov, Matvei Anoshin, Leonid Fedichkin</a></li>
<li><strong>Subjects: </strong>cs.LG, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20823">https://arxiv.org/abs/2504.20823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20823">https://arxiv.org/pdf/2504.20823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20823]] Hybrid Quantum Recurrent Neural Network For Remaining Useful Life Prediction(https://arxiv.org/abs/2504.20823)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Predictive maintenance in aerospace heavily relies on accurate estimation of the remaining useful life of jet engines. In this paper, we introduce a Hybrid Quantum Recurrent Neural Network frame- work, combining Quantum Long Short-Term Memory layers with classical dense layers for Remaining Useful Life forecasting on NASA's Commercial Modular Aero-Propulsion System Simulation dataset. Each Quantum Long Short-Term Memory gate replaces conventional linear transformations with Quantum Depth-Infused circuits, allowing the network to learn high-frequency components more effectively. Experimental results demonstrate that, despite having fewer trainable parameters, the Hybrid Quantum Recurrent Neural Network achieves up to a 5% improvement over a Recurrent Neural Network based on stacked Long Short-Term Memory layers in terms of mean root mean squared error and mean absolute error. Moreover, a thorough comparison of our method with established techniques, including Random Forest, Convolutional Neural Network, and Multilayer Perceptron, demonstrates that our approach, which achieves a Root Mean Squared Error of 15.46, surpasses these baselines by approximately 13.68%, 16.21%, and 7.87%, respectively. Nevertheless, it remains outperformed by certain advanced joint architectures. Our findings highlight the poten- tial of hybrid quantum-classical approaches for robust time-series forecasting under limited data conditions, offering new avenues for enhancing reliability in predictive maintenance tasks.</li>
</ul>

<h3>Title: DP-SMOTE: Integrating Differential Privacy and Oversampling Technique to Preserve Privacy in Smart Homes</h3>
<ul>
<li><strong>Authors: </strong>Amr Tarek Elsayed, Almohammady Sobhi Alsharkawy, Mohamed Sayed Farag, Shaban Ebrahim Abu Yusuf</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20827">https://arxiv.org/abs/2504.20827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20827">https://arxiv.org/pdf/2504.20827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20827]] DP-SMOTE: Integrating Differential Privacy and Oversampling Technique to Preserve Privacy in Smart Homes(https://arxiv.org/abs/2504.20827)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, robust</a></li>
<li><strong>Abstract: </strong>Smart homes represent intelligent environments where interconnected devices gather information, enhancing users living experiences by ensuring comfort, safety, and efficient energy management. To enhance the quality of life, companies in the smart device industry collect user data, including activities, preferences, and power consumption. However, sharing such data necessitates privacy-preserving practices. This paper introduces a robust method for secure sharing of data to service providers, grounded in differential privacy (DP). This empowers smart home residents to contribute usage statistics while safeguarding their privacy. The approach incorporates the Synthetic Minority Oversampling technique (SMOTe) and seamlessly integrates Gaussian noise to generate synthetic data, enabling data and statistics sharing while preserving individual privacy. The proposed method employs the SMOTe algorithm and applies Gaussian noise to generate data. Subsequently, it employs a k-anonymity function to assess reidentification risk before sharing the data. The simulation outcomes demonstrate that our method delivers strong performance in safeguarding privacy and in accuracy, recall, and f-measure metrics. This approach is particularly effective in smart homes, offering substantial utility in privacy at a reidentification risk of 30%, with Gaussian noise set to 0.3, SMOTe at 500%, and the application of a k-anonymity function with k = 2. Additionally, it shows a high classification accuracy, ranging from 90% to 98%, across various classification techniques.</li>
</ul>

<h3>Title: GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion</h3>
<ul>
<li><strong>Authors: </strong>Jiaxin Hong, Sixu Chen, Shuoyang Sun, Hongyao Yu, Hao Fang, Yuqi Tan, Bin Chen, Shuhan Qi, Jiawei Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20829">https://arxiv.org/abs/2504.20829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20829">https://arxiv.org/pdf/2504.20829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20829]] GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion(https://arxiv.org/abs/2504.20829)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene representation and novel view synthesis, its rapid adoption in safety-critical domains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of potential security vulnerabilities. This paper presents the first systematic study of backdoor threats in 3DGS pipelines. We identify that adversaries may implant backdoor views to induce malicious scene confusion during inference, potentially leading to environmental misperception in autonomous navigation or spatial distortion in immersive environments. To uncover this risk, we propose GuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap injects malicious views at specific attack viewpoints while preserving high-quality rendering in non-target views, ensuring minimal detectability and maximizing potential harm. Specifically, the proposed method consists of a three-stage pipeline (attack, stabilization, and normal training) to implant stealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing attack efficacy and perceptual realism to expose security risks in 3D rendering. Extensive experiments on both synthetic and real-world datasets demonstrate that GuassTrap can effectively embed imperceptible yet harmful backdoor views while maintaining high-quality rendering in normal views, validating its robustness, adaptability, and practical applicability.</li>
</ul>

<h3>Title: Reinforcement Learning for LLM Reasoning Under Memory Constraints</h3>
<ul>
<li><strong>Authors: </strong>Alan Lee, Harry Tong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20834">https://arxiv.org/abs/2504.20834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20834">https://arxiv.org/pdf/2504.20834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20834]] Reinforcement Learning for LLM Reasoning Under Memory Constraints(https://arxiv.org/abs/2504.20834)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We explore reinforcement learning (RL) techniques to enhance reasoning within targeted problem spaces in large language models (LLMs) under memory and compute constraints. Our focus is on critic-free methods compatible with LoRA fine-tuning on a single 40GB GPU, a common limitation in academic settings. We introduce S-GRPO, a memory-efficient variant of Group Relative Policy Optimization, and T-SPMO, a token-level prefix matching strategy for fine-grained credit assignment. Despite limited resources, when used to fine-tune Qwen2-1.5B both methods significantly improve SVAMP benchmark accuracy from 46% to above 70% using LoRA training. T-SPMO also excels in multi-digit multiplication tasks, underscoring the potential of RL fine-tuning under hardware constraints. Additionally, we find that our full-token GRPO baseline under LoRA fine-tuning did not improve model performance (compared to base model) on either task, suggesting that our memory-efficient methods may act as a form of regularization that stabilizes training when only a small subset of parameters are updated.</li>
</ul>

<h3>Title: RadSAM: Segmenting 3D radiological images with a 2D promptable model</h3>
<ul>
<li><strong>Authors: </strong>Julien Khlaut, Elodie Ferreres, Daniel Tordjman, Hélène Philippe, Tom Boeken, Pierre Manceron, Corentin Dancette</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20837">https://arxiv.org/abs/2504.20837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20837">https://arxiv.org/pdf/2504.20837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20837]] RadSAM: Segmenting 3D radiological images with a 2D promptable model(https://arxiv.org/abs/2504.20837)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation is a crucial and time-consuming task in clinical care, where mask precision is extremely important. The Segment Anything Model (SAM) offers a promising approach, as it provides an interactive interface based on visual prompting and edition to refine an initial segmentation. This model has strong generalization capabilities, does not rely on predefined classes, and adapts to diverse objects; however, it is pre-trained on natural images and lacks the ability to process medical data effectively. In addition, this model is built for 2D images, whereas a whole medical domain is based on 3D images, such as CT and MRI. Recent adaptations of SAM for medical imaging are based on 2D models, thus requiring one prompt per slice to segment 3D objects, making the segmentation process tedious. They also lack important features such as editing. To bridge this gap, we propose RadSAM, a novel method for segmenting 3D objects with a 2D model from a single prompt. In practice, we train a 2D model using noisy masks as initial prompts, in addition to bounding boxes and points. We then use this novel prompt type with an iterative inference pipeline to reconstruct the 3D mask slice-by-slice. We introduce a benchmark to evaluate the model's ability to segment 3D objects in CT images from a single prompt and evaluate the models' out-of-domain transfer and edition capabilities. We demonstrate the effectiveness of our approach against state-of-the-art models on this benchmark using the AMOS abdominal organ segmentation dataset.</li>
</ul>

<h3>Title: Universal language model with the intervention of quantum theory</h3>
<ul>
<li><strong>Authors: </strong>D.-F. Qin</a></li>
<li><strong>Subjects: </strong>cs.CL, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20839">https://arxiv.org/abs/2504.20839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20839">https://arxiv.org/pdf/2504.20839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20839]] Universal language model with the intervention of quantum theory(https://arxiv.org/abs/2504.20839)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper examines language modeling based on the theory of quantum mechanics. It focuses on the introduction of quantum mechanics into the symbol-meaning pairs of language in order to build a representation model of natural language. At the same time, it is realized that word embedding, which is widely used as a basic technique for statistical language modeling, can be explained and improved by the mathematical framework of quantum mechanics. On this basis, this paper continues to try to use quantum statistics and other related theories to study the mathematical representation, natural evolution and statistical properties of natural language. It is also assumed that the source of such quantum properties is the physicality of information. The feasibility of using quantum theory to model natural language is pointed out through the construction of a experimental code. The paper discusses, in terms of applications, the possible help of the theory in constructing generative models that are popular nowadays. A preliminary discussion of future applications of the theory to quantum computers is also presented.</li>
</ul>

<h3>Title: Mitigating the Structural Bias in Graph Adversarial Defenses</h3>
<ul>
<li><strong>Authors: </strong>Junyuan Fang, Huimin Liu, Han Yang, Jiajing Wu, Zibin Zheng, Chi K. Tse</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20848">https://arxiv.org/abs/2504.20848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20848">https://arxiv.org/pdf/2504.20848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20848]] Mitigating the Structural Bias in Graph Adversarial Defenses(https://arxiv.org/abs/2504.20848)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>In recent years, graph neural networks (GNNs) have shown great potential in addressing various graph structure-related downstream tasks. However, recent studies have found that current GNNs are susceptible to malicious adversarial attacks. Given the inevitable presence of adversarial attacks in the real world, a variety of defense methods have been proposed to counter these attacks and enhance the robustness of GNNs. Despite the commendable performance of these defense methods, we have observed that they tend to exhibit a structural bias in terms of their defense capability on nodes with low degree (i.e., tail nodes), which is similar to the structural bias of traditional GNNs on nodes with low degree in the clean graph. Therefore, in this work, we propose a defense strategy by including hetero-homo augmented graph construction, $k$NN augmented graph construction, and multi-view node-wise attention modules to mitigate the structural bias of GNNs against adversarial attacks. Notably, the hetero-homo augmented graph consists of removing heterophilic links (i.e., links connecting nodes with dissimilar features) globally and adding homophilic links (i.e., links connecting nodes with similar features) for nodes with low degree. To further enhance the defense capability, an attention mechanism is adopted to adaptively combine the representations from the above two kinds of graph views. We conduct extensive experiments to demonstrate the defense and debiasing effect of the proposed strategy on benchmark datasets.</li>
</ul>

<h3>Title: JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated Marketing Text in the Music Industry</h3>
<ul>
<li><strong>Authors: </strong>Anum Afzal, Alexandre Mercier, Florian Matthes</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20849">https://arxiv.org/abs/2504.20849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20849">https://arxiv.org/pdf/2504.20849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20849]] JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated Marketing Text in the Music Industry(https://arxiv.org/abs/2504.20849)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Online platforms are increasingly interested in using Data-to-Text technologies to generate content and help their users. Unfortunately, traditional generative methods often fall into repetitive patterns, resulting in monotonous galleries of texts after only a few iterations. In this paper, we investigate LLM-based data-to-text approaches to automatically generate marketing texts that are of sufficient quality and diverse enough for broad adoption. We leverage Language Models such as T5, GPT-3.5, GPT-4, and LLaMa2 in conjunction with fine-tuning, few-shot, and zero-shot approaches to set a baseline for diverse marketing texts. We also introduce a metric JaccDiv to evaluate the diversity of a set of texts. This research extends its relevance beyond the music industry, proving beneficial in various fields where repetitive automated content generation is prevalent.</li>
</ul>

<h3>Title: FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mainak Singha, Subhankar Roy, Sarthak Mehrotra, Ankit Jha, Moloud Abdar, Biplab Banerjee, Elisa Ricci</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20860">https://arxiv.org/abs/2504.20860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20860">https://arxiv.org/pdf/2504.20860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20860]] FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models(https://arxiv.org/abs/2504.20860)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Textual prompt tuning adapts Vision-Language Models (e.g., CLIP) in federated learning by tuning lightweight input tokens (or prompts) on local client data, while keeping network weights frozen. Post training, only the prompts are shared by the clients with the central server for aggregation. However, textual prompt tuning often struggles with overfitting to known concepts and may be overly reliant on memorized text features, limiting its adaptability to unseen concepts. To address this limitation, we propose Federated Multimodal Visual Prompt Tuning (FedMVP) that conditions the prompts on comprehensive contextual information -- image-conditioned features and textual attribute features of a class -- that is multimodal in nature. At the core of FedMVP is a PromptFormer module that synergistically aligns textual and visual features through cross-attention, enabling richer contexual integration. The dynamically generated multimodal visual prompts are then input to the frozen vision encoder of CLIP, and trained with a combination of CLIP similarity loss and a consistency loss. Extensive evaluation on 20 datasets spanning three generalization settings demonstrates that FedMVP not only preserves performance on in-distribution classes and domains, but also displays higher generalizability to unseen classes and domains when compared to state-of-the-art methods. Codes will be released upon acceptance.</li>
</ul>

<h3>Title: AI-GenBench: A New Ongoing Benchmark for AI-Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Lorenzo Pellegrini, Davide Cozzolino, Serafino Pandolfini, Davide Maltoni, Matteo Ferrara, Luisa Verdoliva, Marco Prati, Marco Ramilli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20865">https://arxiv.org/abs/2504.20865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20865">https://arxiv.org/pdf/2504.20865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20865]] AI-GenBench: A New Ongoing Benchmark for AI-Generated Image Detection(https://arxiv.org/abs/2504.20865)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The rapid advancement of generative AI has revolutionized image creation, enabling high-quality synthesis from text prompts while raising critical challenges for media authenticity. We present Ai-GenBench, a novel benchmark designed to address the urgent need for robust detection of AI-generated images in real-world scenarios. Unlike existing solutions that evaluate models on static datasets, Ai-GenBench introduces a temporal evaluation framework where detection methods are incrementally trained on synthetic images, historically ordered by their generative models, to test their ability to generalize to new generative models, such as the transition from GANs to diffusion models. Our benchmark focuses on high-quality, diverse visual content and overcomes key limitations of current approaches, including arbitrary dataset splits, unfair comparisons, and excessive computational demands. Ai-GenBench provides a comprehensive dataset, a standardized evaluation protocol, and accessible tools for both researchers and non-experts (e.g., journalists, fact-checkers), ensuring reproducibility while maintaining practical training requirements. By establishing clear evaluation rules and controlled augmentation strategies, Ai-GenBench enables meaningful comparison of detection methods and scalable solutions. Code and data are publicly available to ensure reproducibility and to support the development of robust forensic detectors to keep pace with the rise of new synthetic generators.</li>
</ul>

<h3>Title: Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Junyuan Fang, Han Yang, Haixian Wen, Jiajing Wu, Zibin Zheng, Chi K. Tse</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20869">https://arxiv.org/abs/2504.20869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20869">https://arxiv.org/pdf/2504.20869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20869]] Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks(https://arxiv.org/abs/2504.20869)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, interpretability</a></li>
<li><strong>Abstract: </strong>Graph neural networks have been widely utilized to solve graph-related tasks because of their strong learning power in utilizing the local information of neighbors. However, recent studies on graph adversarial attacks have proven that current graph neural networks are not robust against malicious attacks. Yet much of the existing work has focused on the optimization objective based on attack performance to obtain (near) optimal perturbations, but paid less attention to the strength quantification of each perturbation such as the injection of a particular node/link, which makes the choice of perturbations a black-box model that lacks interpretability. In this work, we propose the concept of noise to quantify the attack strength of each adversarial link. Furthermore, we propose three attack strategies based on the defined noise and classification margins in terms of single and multiple steps optimization. Extensive experiments conducted on benchmark datasets against three representative graph neural networks demonstrate the effectiveness of the proposed attack strategies. Particularly, we also investigate the preferred patterns of effective adversarial perturbations by analyzing the corresponding properties of the selected perturbation nodes.</li>
</ul>

<h3>Title: FLIM-based Salient Object Detection Networks with Adaptive Decoders</h3>
<ul>
<li><strong>Authors: </strong>Gilson Junior Soares, Matheus Abrantes Cerqueira, Jancarlo F. Gomes, Laurent Najman, Silvio Jamil F. Guimarães, Alexandre Xavier Falcão</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20872">https://arxiv.org/abs/2504.20872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20872">https://arxiv.org/pdf/2504.20872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20872]] FLIM-based Salient Object Detection Networks with Adaptive Decoders(https://arxiv.org/abs/2504.20872)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Salient Object Detection (SOD) methods can locate objects that stand out in an image, assign higher values to their pixels in a saliency map, and binarize the map outputting a predicted segmentation mask. A recent tendency is to investigate pre-trained lightweight models rather than deep neural networks in SOD tasks, coping with applications under limited computational resources. In this context, we have investigated lightweight networks using a methodology named Feature Learning from Image Markers (FLIM), which assumes that the encoder's kernels can be estimated from marker pixels on discriminative regions of a few representative images. This work proposes flyweight networks, hundreds of times lighter than lightweight models, for SOD by combining a FLIM encoder with an adaptive decoder, whose weights are estimated for each input image by a given heuristic function. Such FLIM networks are trained from three to four representative images only and without backpropagation, making the models suitable for applications under labeled data constraints as well. We study five adaptive decoders; two of them are introduced here. Differently from the previous ones that rely on one neuron per pixel with shared weights, the heuristic functions of the new adaptive decoders estimate the weights of each neuron per pixel. We compare FLIM models with adaptive decoders for two challenging SOD tasks with three lightweight networks from the state-of-the-art, two FLIM networks with decoders trained by backpropagation, and one FLIM network whose labeled markers define the decoder's weights. The experiments demonstrate the advantages of the proposed networks over the baselines, revealing the importance of further investigating such methods in new applications.</li>
</ul>

<h3>Title: Evaluating Generative Models for Tabular Data: Novel Metrics and Benchmarking</h3>
<ul>
<li><strong>Authors: </strong>Dayananda Herurkar, Ahmad Ali, Andreas Dengel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20900">https://arxiv.org/abs/2504.20900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20900">https://arxiv.org/pdf/2504.20900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20900]] Evaluating Generative Models for Tabular Data: Novel Metrics and Benchmarking(https://arxiv.org/abs/2504.20900)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Generative models have revolutionized multiple domains, yet their application to tabular data remains underexplored. Evaluating generative models for tabular data presents unique challenges due to structural complexity, large-scale variability, and mixed data types, making it difficult to intuitively capture intricate patterns. Existing evaluation metrics offer only partial insights, lacking a comprehensive measure of generative performance. To address this limitation, we propose three novel evaluation metrics: FAED, FPCAD, and RFIS. Our extensive experimental analysis, conducted on three standard network intrusion detection datasets, compares these metrics with established evaluation methods such as Fidelity, Utility, TSTR, and TRTS. Our results demonstrate that FAED effectively captures generative modeling issues overlooked by existing metrics. While FPCAD exhibits promising performance, further refinements are necessary to enhance its reliability. Our proposed framework provides a robust and practical approach for assessing generative models in tabular data applications.</li>
</ul>

<h3>Title: Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Quentin Guimard, Moreno D'Incà, Massimiliano Mancini, Elisa Ricci</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20902">https://arxiv.org/abs/2504.20902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20902">https://arxiv.org/pdf/2504.20902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20902]] Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers(https://arxiv.org/abs/2504.20902)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A person downloading a pre-trained model from the web should be aware of its biases. Existing approaches for bias identification rely on datasets containing labels for the task of interest, something that a non-expert may not have access to, or may not have the necessary resources to collect: this greatly limits the number of tasks where model biases can be identified. In this work, we present Classifier-to-Bias (C2B), the first bias discovery framework that works without access to any labeled data: it only relies on a textual description of the classification task to identify biases in the target classification model. This description is fed to a large language model to generate bias proposals and corresponding captions depicting biases together with task-specific target labels. A retrieval model collects images for those captions, which are then used to assess the accuracy of the model w.r.t. the given biases. C2B is training-free, does not require any annotations, has no constraints on the list of biases, and can be applied to any pre-trained model on any classification task. Experiments on two publicly available datasets show that C2B discovers biases beyond those of the original datasets and outperforms a recent state-of-the-art bias detection baseline that relies on task-specific annotations, being a promising first step toward addressing task-agnostic unsupervised bias detection.</li>
</ul>

<h3>Title: Dual Explanations via Subgraph Matching for Malware Detection</h3>
<ul>
<li><strong>Authors: </strong>Hossein Shokouhinejad, Roozbeh Razavi-Far, Griffin Higgins, Ali A. Ghorbani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20904">https://arxiv.org/abs/2504.20904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20904">https://arxiv.org/pdf/2504.20904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20904]] Dual Explanations via Subgraph Matching for Malware Detection(https://arxiv.org/abs/2504.20904)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, interpretability</a></li>
<li><strong>Abstract: </strong>Interpretable malware detection is crucial for understanding harmful behaviors and building trust in automated security systems. Traditional explainable methods for Graph Neural Networks (GNNs) often highlight important regions within a graph but fail to associate them with known benign or malicious behavioral patterns. This limitation reduces their utility in security contexts, where alignment with verified prototypes is essential. In this work, we introduce a novel dual prototype-driven explainable framework that interprets GNN-based malware detection decisions. This dual explainable framework integrates a base explainer (a state-of-the-art explainer) with a novel second-level explainer which is designed by subgraph matching technique, called SubMatch explainer. The proposed explainer assigns interpretable scores to nodes based on their association with matched subgraphs, offering a fine-grained distinction between benign and malicious regions. This prototype-guided scoring mechanism enables more interpretable, behavior-aligned explanations. Experimental results demonstrate that our method preserves high detection performance while significantly improving interpretability in malware analysis.</li>
</ul>

<h3>Title: GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In Industrial Control Systems</h3>
<ul>
<li><strong>Authors: </strong>Sarad Venugopalan, Sridhar Adepu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20906">https://arxiv.org/abs/2504.20906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20906">https://arxiv.org/pdf/2504.20906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20906]] GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In Industrial Control Systems(https://arxiv.org/abs/2504.20906)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, explainability</a></li>
<li><strong>Abstract: </strong>The continuous monitoring of the interactions between cyber-physical components of any industrial control system (ICS) is required to secure automation of the system controls, and to guarantee plant processes are fail-safe and remain in an acceptably safe state. Safety is achieved by managing actuation (where electric signals are used to trigger physical movement), dependent on corresponding sensor readings; used as ground truth in decision making. Timely detection of anomalies (attacks, faults and unascertained states) in ICSs is crucial for the safe running of a plant, the safety of its personnel, and for the safe provision of any services provided. We propose an anomaly detection method that involves accurate linearization of the non-linear forms arising from sensor-actuator(s) relationships, primarily because solving linear models is easier and well understood. Further, the time complexity of the anomaly detection scenario/problem at hand is lowered using dimensionality reduction of the actuator(s) in relationship with a sensor. We accomplish this by using a well-known water treatment testbed as a use case. Our experiments show millisecond time response to detect anomalies and provide explainability; that are not simultaneously achieved by other state of the art AI/ML models with eXplainable AI (XAI) used for the same purpose. Further, we pin-point the sensor(s) and its actuation state for which anomaly was detected.</li>
</ul>

<h3>Title: Statistical and Predictive Analysis to Identify Risk Factors and Effects of Post COVID-19 Syndrome</h3>
<ul>
<li><strong>Authors: </strong>Milad Leyli-abadi, Jean-Patrick Brunet, Axel Tahmasebimoradi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20915">https://arxiv.org/abs/2504.20915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20915">https://arxiv.org/pdf/2504.20915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20915]] Statistical and Predictive Analysis to Identify Risk Factors and Effects of Post COVID-19 Syndrome(https://arxiv.org/abs/2504.20915)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Based on recent studies, some COVID-19 symptoms can persist for months after infection, leading to what is termed long COVID. Factors such as vaccination timing, patient characteristics, and symptoms during the acute phase of infection may contribute to the prolonged effects and intensity of long COVID. Each patient, based on their unique combination of factors, develops a specific risk or intensity of long COVID. In this work, we aim to achieve two objectives: (1) conduct a statistical analysis to identify relationships between various factors and long COVID, and (2) perform predictive analysis of long COVID intensity using these factors. We benchmark and interpret various data-driven approaches, including linear models, random forests, gradient boosting, and neural networks, using data from the Lifelines COVID-19 cohort. Our results show that Neural Networks (NN) achieve the best performance in terms of MAPE, with predictions averaging 19\% error. Additionally, interpretability analysis reveals key factors such as loss of smell, headache, muscle pain, and vaccination timing as significant predictors, while chronic disease and gender are critical risk factors. These insights provide valuable guidance for understanding long COVID and developing targeted interventions.</li>
</ul>

<h3>Title: DYNAMAX: Dynamic computing for Transformers and Mamba based architectures</h3>
<ul>
<li><strong>Authors: </strong>Miguel Nogales, Matteo Gambella, Manuel Roveri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20922">https://arxiv.org/abs/2504.20922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20922">https://arxiv.org/pdf/2504.20922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20922]] DYNAMAX: Dynamic computing for Transformers and Mamba based architectures(https://arxiv.org/abs/2504.20922)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Early exits (EEs) offer a promising approach to reducing computational costs and latency by dynamically terminating inference once a satisfactory prediction confidence on a data sample is achieved. Although many works integrate EEs into encoder-only Transformers, their application to decoder-only architectures and, more importantly, Mamba models, a novel family of state-space architectures in the LLM realm, remains insufficiently explored. This work introduces DYNAMAX, the first framework to exploit the unique properties of Mamba architectures for early exit mechanisms. We not only integrate EEs into Mamba but also repurpose Mamba as an efficient EE classifier for both Mamba-based and transformer-based LLMs, showcasing its versatility. Our experiments employ the Mistral 7B transformer compared to the Codestral 7B Mamba model, using data sets such as TruthfulQA, CoQA, and TriviaQA to evaluate computational savings, accuracy, and consistency. The results highlight the adaptability of Mamba as a powerful EE classifier and its efficiency in balancing computational cost and performance quality across NLP tasks. By leveraging Mamba's inherent design for dynamic processing, we open pathways for scalable and efficient inference in embedded applications and resource-constrained environments. This study underscores the transformative potential of Mamba in redefining dynamic computing paradigms for LLMs.</li>
</ul>

<h3>Title: Bipartite Randomized Response Mechanism for Local Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Shun Zhang, Hai Zhu, Zhili Chen, Neal N. Xiong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20926">https://arxiv.org/abs/2504.20926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20926">https://arxiv.org/pdf/2504.20926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20926]] Bipartite Randomized Response Mechanism for Local Differential Privacy(https://arxiv.org/abs/2504.20926)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>With the increasing importance of data privacy, Local Differential Privacy (LDP) has recently become a strong measure of privacy for protecting each user's privacy from data analysts without relying on a trusted third party. In many cases, both data providers and data analysts hope to maximize the utility of released data. In this paper, we study the fundamental trade-off formulated as a constrained optimization problem: maximizing data utility subject to the constraint of LDP budgets. In particular, the Generalized Randomized Response (GRR) treats all discrete data equally except for the true data. For this, we introduce an adaptive LDP mechanism called Bipartite Randomized Response (BRR), which solves the above privacy-utility maximization problem from the global standpoint. We prove that for any utility function and any privacy level, solving the maximization problem is equivalent to confirming how many high-utility data to be treated equally as the true data on release probability, the outcome of which gives the optimal randomized response. Further, solving this linear program can be computationally cheap in theory. Several examples of utility functions defined by distance metrics and applications in decision trees and deep learning are presented. The results of various experiments show that our BRR significantly outperforms the state-of-the-art LDP mechanisms of both continuous and distributed types.</li>
</ul>

<h3>Title: Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Zhengfu He, Junxuan Wang, Rui Lin, Xuyang Ge, Wentao Shu, Qiong Tang, Junping Zhang, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20938">https://arxiv.org/abs/2504.20938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20938">https://arxiv.org/pdf/2504.20938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20938]] Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition(https://arxiv.org/abs/2504.20938)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We propose Low-Rank Sparse Attention (Lorsa), a sparse replacement model of Transformer attention layers to disentangle original Multi Head Self Attention (MHSA) into individually comprehensible components. Lorsa is designed to address the challenge of attention superposition to understand attention-mediated interaction between features in different token positions. We show that Lorsa heads find cleaner and finer-grained versions of previously discovered MHSA behaviors like induction heads, successor heads and attention sink behavior (i.e., heavily attending to the first token). Lorsa and Sparse Autoencoder (SAE) are both sparse dictionary learning methods applied to different Transformer components, and lead to consistent findings in many ways. For instance, we discover a comprehensive family of arithmetic-specific Lorsa heads, each corresponding to an atomic operation in Llama-3.1-8B. Automated interpretability analysis indicates that Lorsa achieves parity with SAE in interpretability while Lorsa exhibits superior circuit discovery properties, especially for features computed collectively by multiple MHSA heads. We also conduct extensive experiments on architectural design ablation, Lorsa scaling law and error analysis.</li>
</ul>

<h3>Title: Conformal-DP: Differential Privacy on Riemannian Manifolds via Conformal Transformation</h3>
<ul>
<li><strong>Authors: </strong>Peilin He, Liou Tang, M. Amin Rahimian, James Joshi</a></li>
<li><strong>Subjects: </strong>cs.CR, math.DG, stat.OT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20941">https://arxiv.org/abs/2504.20941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20941">https://arxiv.org/pdf/2504.20941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20941]] Conformal-DP: Differential Privacy on Riemannian Manifolds via Conformal Transformation(https://arxiv.org/abs/2504.20941)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>Differential Privacy (DP) has been established as a safeguard for private data sharing by adding perturbations to information release. Prior research on DP has extended beyond data in the flat Euclidean space and addressed data on curved manifolds, e.g., diffusion tensor MRI, social networks, or organ shape analysis, by adding perturbations along geodesic distances. However, existing manifold-aware DP methods rely on the assumption that samples are uniformly distributed across the manifold. In reality, data densities vary, leading to a biased noise imbalance across manifold regions, weakening the privacy-utility trade-offs. To address this gap, we propose a novel mechanism: Conformal-DP, utilizing conformal transformations on the Riemannian manifold to equalize local sample density and to redefine geodesic distances accordingly while preserving the intrinsic geometry of the manifold. Our theoretical analysis yields two main results. First, we prove that the conformal factor computed from local kernel-density estimates is explicitly data-density-aware; Second, under the conformal metric, the mechanism satisfies $ \varepsilon $-differential privacy on any complete Riemannian manifold and admits a closed-form upper bound on the expected geodesic error that depends only on the maximal density ratio, not on global curvatureof the manifold. Our experimental results validate that the mechanism achieves high utility while providing the $ \varepsilon $-DP guarantee for both homogeneous and especially heterogeneous manifold data.</li>
</ul>

<h3>Title: Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tyler McDonald, Ali Emami</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20946">https://arxiv.org/abs/2504.20946</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20946">https://arxiv.org/pdf/2504.20946</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20946]] Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models(https://arxiv.org/abs/2504.20946)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) continue to be leveraged for daily tasks, prompt engineering remains an active field of contribution within computational linguistics, particularly in domains requiring specialized knowledge such as arithmetic reasoning. While these LLMs are optimized for a variety of tasks, their exhaustive employment may become computationally or financially cumbersome for small teams. Additionally, complete reliance on proprietary, closed-source models often limits customization and adaptability, posing significant challenges in research and application scalability. Instead, by leveraging open-source models at or below 7 billion parameters, we can optimize our resource usage while still observing remarkable gains over standard prompting approaches. To cultivate this notion, we introduce Trace-of-Thought Prompting, a simple, zero-shot prompt engineering method that instructs LLMs to create observable subproblems using critical problem-solving, specifically designed to enhance arithmetic reasoning capabilities. When applied to open-source models in tandem with GPT-4, we observe that Trace-of-Thought not only allows novel insight into the problem-solving process but also introduces performance gains as large as 125% on language models at or below 7 billion parameters. This approach underscores the potential of open-source initiatives in democratizing AI research and improving the accessibility of high-quality computational linguistics applications.</li>
</ul>

<h3>Title: DS_FusionNet: Dynamic Dual-Stream Fusion with Bidirectional Knowledge Distillation for Plant Disease Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yanghui Song, Chengfu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20948">https://arxiv.org/abs/2504.20948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20948">https://arxiv.org/pdf/2504.20948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20948]] DS_FusionNet: Dynamic Dual-Stream Fusion with Bidirectional Knowledge Distillation for Plant Disease Recognition(https://arxiv.org/abs/2504.20948)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Given the severe challenges confronting the global growth security of economic crops, precise identification and prevention of plant diseases has emerged as a critical issue in artificial intelligence-enabled agricultural technology. To address the technical challenges in plant disease recognition, including small-sample learning, leaf occlusion, illumination variations, and high inter-class similarity, this study innovatively proposes a Dynamic Dual-Stream Fusion Network (DS_FusionNet). The network integrates a dual-backbone architecture, deformable dynamic fusion modules, and bidirectional knowledge distillation strategy, significantly enhancing recognition accuracy. Experimental results demonstrate that DS_FusionNet achieves classification accuracies exceeding 90% using only 10% of the PlantDisease and CIFAR-10 datasets, while maintaining 85% accuracy on the complex PlantWild dataset, exhibiting exceptional generalization capabilities. This research not only provides novel technical insights for fine-grained image classification but also establishes a robust foundation for precise identification and management of agricultural diseases.</li>
</ul>

<h3>Title: Information Gravity: A Field-Theoretic Model for Token Selection in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Maryna Vyshnyvetska</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20951">https://arxiv.org/abs/2504.20951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20951">https://arxiv.org/pdf/2504.20951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20951]] Information Gravity: A Field-Theoretic Model for Token Selection in Large Language Models(https://arxiv.org/abs/2504.20951)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose a theoretical model called "information gravity" to describe the text generation process in large language models (LLMs). The model uses physical apparatus from field theory and spacetime geometry to formalize the interaction between user queries and the probability distribution of generated tokens. A query is viewed as an object with "information mass" that curves the semantic space of the model, creating gravitational potential wells that "attract" tokens during generation. This model offers a mechanism to explain several observed phenomena in LLM behavior, including hallucinations (emerging from low-density semantic voids), sensitivity to query formulation (due to semantic field curvature changes), and the influence of sampling temperature on output diversity.</li>
</ul>

<h3>Title: OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification</h3>
<ul>
<li><strong>Authors: </strong>Shangyu Li, Juyong Jiang, Tiancheng Zhao, Jiasi Shen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.OS, cs.PL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20964">https://arxiv.org/abs/2504.20964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20964">https://arxiv.org/pdf/2504.20964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20964]] OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification(https://arxiv.org/abs/2504.20964)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce OSVBench, a new benchmark for evaluating Large Language Models (LLMs) in generating complete specification code pertaining to operating system kernel verification tasks. The benchmark first defines the specification generation problem into a program synthesis problem within a confined scope of syntax and semantics by providing LLMs with the programming model. The LLMs are required to understand the provided verification assumption and the potential syntax and semantics space to search for, then generate the complete specification for the potentially buggy operating system code implementation under the guidance of the high-level functional description of the operating system. This benchmark is built upon a real-world operating system kernel, Hyperkernel, and consists of 245 complex specification generation tasks in total, each is a long context task of about 20k-30k tokens. Our comprehensive evaluation of 12 LLMs exhibits the limited performance of the current LLMs on the specification generation tasks for operating system verification. Significant disparities in their performance on the benchmark highlight differences in their ability to handle long-context code generation tasks. The evaluation toolkit and benchmark are available at this https URL.</li>
</ul>

<h3>Title: AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security</h3>
<ul>
<li><strong>Authors: </strong>Zikui Cai, Shayan Shabihi, Bang An, Zora Che, Brian R. Bartoldson, Bhavya Kailkhura, Tom Goldstein, Furong Huang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20965">https://arxiv.org/abs/2504.20965</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20965">https://arxiv.org/pdf/2504.20965</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20965]] AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security(https://arxiv.org/abs/2504.20965)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>We introduce AegisLLM, a cooperative multi-agent defense against adversarial attacks and information leakage. In AegisLLM, a structured workflow of autonomous agents - orchestrator, deflector, responder, and evaluator - collaborate to ensure safe and compliant LLM outputs, while self-improving over time through prompt optimization. We show that scaling agentic reasoning system at test-time - both by incorporating additional agent roles and by leveraging automated prompt optimization (such as DSPy)- substantially enhances robustness without compromising model utility. This test-time defense enables real-time adaptability to evolving attacks, without requiring model retraining. Comprehensive evaluations across key threat scenarios, including unlearning and jailbreaking, demonstrate the effectiveness of AegisLLM. On the WMDP unlearning benchmark, AegisLLM achieves near-perfect unlearning with only 20 training examples and fewer than 300 LM calls. For jailbreaking benchmarks, we achieve 51% improvement compared to the base model on StrongReject, with false refusal rates of only 7.9% on PHTest compared to 18-55% for comparable methods. Our results highlight the advantages of adaptive, agentic reasoning over static defenses, establishing AegisLLM as a strong runtime alternative to traditional approaches based on model modifications. Code is available at this https URL</li>
</ul>

<h3>Title: Softpick: No Attention Sink, No Massive Activations with Rectified Softmax</h3>
<ul>
<li><strong>Authors: </strong>Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20966">https://arxiv.org/abs/2504.20966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20966">https://arxiv.org/pdf/2504.20966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20966]] Softpick: No Attention Sink, No Massive Activations with Rectified Softmax(https://arxiv.org/abs/2504.20966)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We introduce softpick, a rectified, not sum-to-one, drop-in replacement for softmax in transformer attention mechanisms that eliminates attention sink and massive activations. Our experiments with 340M parameter models demonstrate that softpick maintains performance parity with softmax on standard benchmarks while achieving 0% sink rate. The softpick transformer produces hidden states with significantly lower kurtosis (340 vs 33,510) and creates sparse attention maps (46.97% sparsity). Models using softpick consistently outperform softmax when quantized, with particularly pronounced advantages at lower bit precisions. Our analysis and discussion shows how softpick has the potential to open new possibilities for quantization, low-precision training, sparsity optimization, pruning, and interpretability. Our code is available at this https URL.</li>
</ul>

<h3>Title: SetKE: Knowledge Editing for Knowledge Elements Overlap</h3>
<ul>
<li><strong>Authors: </strong>Yifan Wei, Xiaoyan Yu, Ran Song, Hao Peng, Angsheng Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20972">https://arxiv.org/abs/2504.20972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20972">https://arxiv.org/pdf/2504.20972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20972]] SetKE: Knowledge Editing for Knowledge Elements Overlap(https://arxiv.org/abs/2504.20972)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in tasks such as retrieval and question answering but require updates to incorporate new knowledge and reduce inaccuracies and hallucinations. Traditional updating methods, like fine-tuning and incremental learning, face challenges such as overfitting and high computational costs. Knowledge Editing (KE) provides a promising alternative but often overlooks the Knowledge Element Overlap (KEO) phenomenon, where multiple triplets share common elements, leading to editing conflicts. We identify the prevalence of KEO in existing KE datasets and show its significant impact on current KE methods, causing performance degradation in handling such triplets. To address this, we propose a new formulation, Knowledge Set Editing (KSE), and introduce SetKE, a method that edits sets of triplets simultaneously. Experimental results demonstrate that SetKE outperforms existing methods in KEO scenarios on mainstream LLMs. Additionally, we introduce EditSet, a dataset containing KEO triplets, providing a comprehensive benchmark.</li>
</ul>

<h3>Title: Equivariant non-linear maps for neural networks on homogeneous spaces</h3>
<ul>
<li><strong>Authors: </strong>Elias Nyholm, Oscar Carlsson, Maurice Weiler, Daniel Persson</a></li>
<li><strong>Subjects: </strong>cs.LG, math.RT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20974">https://arxiv.org/abs/2504.20974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20974">https://arxiv.org/pdf/2504.20974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20974]] Equivariant non-linear maps for neural networks on homogeneous spaces(https://arxiv.org/abs/2504.20974)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents a novel framework for non-linear equivariant neural network layers on homogeneous spaces. The seminal work of Cohen et al. on equivariant $G$-CNNs on homogeneous spaces characterized the representation theory of such layers in the linear setting, finding that they are given by convolutions with kernels satisfying so-called steerability constraints. Motivated by the empirical success of non-linear layers, such as self-attention or input dependent kernels, we set out to generalize these insights to the non-linear setting. We derive generalized steerability constraints that any such layer needs to satisfy and prove the universality of our construction. The insights gained into the symmetry-constrained functional dependence of equivariant operators on feature maps and group elements informs the design of future equivariant neural network layers. We demonstrate how several common equivariant network architectures - $G$-CNNs, implicit steerable kernel networks, conventional and relative position embedded attention based transformers, and LieTransformers - may be derived from our framework.</li>
</ul>

<h3>Title: ACE: A Security Architecture for LLM-Integrated App Systems</h3>
<ul>
<li><strong>Authors: </strong>Evan Li, Tushin Mallick, Evan Rose, William Robertson, Alina Oprea, Cristina Nita-Rotaru</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20984">https://arxiv.org/abs/2504.20984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20984">https://arxiv.org/pdf/2504.20984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20984]] ACE: A Security Architecture for LLM-Integrated App Systems(https://arxiv.org/abs/2504.20984)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, large language model</a></li>
<li><strong>Abstract: </strong>LLM-integrated app systems extend the utility of Large Language Models (LLMs) with third-party apps that are invoked by a system LLM using interleaved planning and execution phases to answer user queries. These systems introduce new attack vectors where malicious apps can cause integrity violation of planning or execution, availability breakdown, or privacy compromise during execution. In this work, we identify new attacks impacting the integrity of planning, as well as the integrity and availability of execution in LLM-integrated apps, and demonstrate them against IsolateGPT, a recent solution designed to mitigate attacks from malicious apps. We propose Abstract-Concrete-Execute (ACE), a new secure architecture for LLM-integrated app systems that provides security guarantees for system planning and execution. Specifically, ACE decouples planning into two phases by first creating an abstract execution plan using only trusted information, and then mapping the abstract plan to a concrete plan using installed system apps. We verify that the plans generated by our system satisfy user-specified secure information flow constraints via static analysis on the structured plan output. During execution, ACE enforces data and capability barriers between apps, and ensures that the execution is conducted according to the trusted abstract plan. We show experimentally that our system is secure against attacks from the INJECAGENT benchmark, a standard benchmark for control flow integrity in the face of indirect prompt injection attacks, and our newly introduced attacks. Our architecture represents a significant advancement towards hardening LLM-based systems containing system facilities of varying levels of trustworthiness.</li>
</ul>

<h3>Title: Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Atul Sharma, Kavindu Herath, Saurabh Bagchi, Chaoyue Liu, Somali Chaterji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20988">https://arxiv.org/abs/2504.20988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20988">https://arxiv.org/pdf/2504.20988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20988]] Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine Learning(https://arxiv.org/abs/2504.20988)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We introduce the Hubs and Spokes Learning (HSL) framework, a novel paradigm for collaborative machine learning that combines the strengths of Federated Learning (FL) and Decentralized Learning (P2PL). HSL employs a two-tier communication structure that avoids the single point of failure inherent in FL and outperforms the state-of-the-art P2PL framework, Epidemic Learning Local (ELL). At equal communication budgets (total edges), HSL achieves higher performance than ELL, while at significantly lower communication budgets, it can match ELL's performance. For instance, with only 400 edges, HSL reaches the same test accuracy that ELL achieves with 1000 edges for 100 peers (spokes) on CIFAR-10, demonstrating its suitability for resource-constrained systems. HSL also achieves stronger consensus among nodes after mixing, resulting in improved performance with fewer training rounds. We substantiate these claims through rigorous theoretical analyses and extensive experimental results, showcasing HSL's practicality for large-scale collaborative learning.</li>
</ul>

<h3>Title: X-Fusion: Introducing New Modality to Frozen Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan Iyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20996">https://arxiv.org/abs/2504.20996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20996">https://arxiv.org/pdf/2504.20996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20996]] X-Fusion: Introducing New Modality to Frozen Large Language Models(https://arxiv.org/abs/2504.20996)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose X-Fusion, a framework that extends pretrained Large Language Models (LLMs) for multimodal tasks while preserving their language capabilities. X-Fusion employs a dual-tower design with modality-specific weights, keeping the LLM's parameters frozen while integrating vision-specific information for both understanding and generation. Our experiments demonstrate that X-Fusion consistently outperforms alternative architectures on both image-to-text and text-to-image tasks. We find that incorporating understanding-focused data improves generation quality, reducing image data noise enhances overall performance, and feature alignment accelerates convergence for smaller models but has minimal impact on larger ones. Our findings provide valuable insights into building efficient unified multimodal models.</li>
</ul>

<h3>Title: Toward Efficient Exploration by Large Language Model Agents</h3>
<ul>
<li><strong>Authors: </strong>Dilip Arumugam, Thomas L. Griffiths</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.20997">https://arxiv.org/abs/2504.20997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.20997">https://arxiv.org/pdf/2504.20997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.20997]] Toward Efficient Exploration by Large Language Model Agents(https://arxiv.org/abs/2504.20997)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A burgeoning area within reinforcement learning (RL) is the design of sequential decision-making agents centered around large language models (LLMs). While autonomous decision-making agents powered by modern LLMs could facilitate numerous real-world applications, such successes demand agents that are capable of data-efficient RL. One key obstacle to achieving data efficiency in RL is exploration, a challenge that we demonstrate many recent proposals for LLM agent designs struggle to contend with. Meanwhile, classic algorithms from the RL literature known to gracefully address exploration require technical machinery that can be challenging to operationalize in purely natural language settings. In this work, rather than relying on finetuning or in-context learning to coax LLMs into implicitly imitating a RL algorithm, we illustrate how LLMs can be used to explicitly implement an existing RL algorithm (Posterior Sampling for Reinforcement Learning) whose capacity for statistically-efficient exploration is already well-studied. We offer empirical results demonstrating how our LLM-based implementation of a known, data-efficient RL algorithm can be considerably more effective in natural language tasks that demand prudent exploration.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
