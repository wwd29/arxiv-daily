<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-01-01</h1>
<h2>secure</h2>
<h3>Title: SentinelLMs: Encrypted Input Adaptation and Fine-tuning of Language Models for Private and Secure Inference. (arXiv:2312.17342v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17342">http://arxiv.org/abs/2312.17342</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17342]] SentinelLMs: Encrypted Input Adaptation and Fine-tuning of Language Models for Private and Secure Inference(http://arxiv.org/abs/2312.17342)</code></li>
<li>Summary: <p>This paper addresses the privacy and security concerns associated with deep
neural language models, which serve as crucial components in various modern
AI-based applications. These models are often used after being pre-trained and
fine-tuned for specific tasks, with deployment on servers accessed through the
internet. However, this introduces two fundamental risks: (a) the transmission
of user inputs to the server via the network gives rise to interception
vulnerabilities, and (b) privacy concerns emerge as organizations that deploy
such models store user data with restricted context. To address this, we
propose a novel method to adapt and fine-tune transformer-based language models
on passkey-encrypted user-specific text. The original pre-trained language
model first undergoes a quick adaptation (without any further pre-training)
with a series of irreversible transformations applied to the tokenizer and
token embeddings. This enables the model to perform inference on encrypted
inputs while preventing reverse engineering of text from model parameters and
intermediate outputs. After adaptation, models are fine-tuned on encrypted
versions of existing training datasets. Experimental evaluation employing
adapted versions of renowned models (e.g., BERT, RoBERTa) across established
benchmark English and multilingual datasets for text classification and
sequence labeling shows that encrypted models achieve performance parity with
their original counterparts. This serves to safeguard performance, privacy, and
security cohesively.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Improving Intrusion Detection with Domain-Invariant Representation Learning in Latent Space. (arXiv:2312.17300v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17300">http://arxiv.org/abs/2312.17300</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17300]] Improving Intrusion Detection with Domain-Invariant Representation Learning in Latent Space(http://arxiv.org/abs/2312.17300)</code></li>
<li>Summary: <p>Domain generalization focuses on leveraging knowledge from multiple related
domains with ample training data and labels to enhance inference on unseen
in-distribution (IN) and out-of-distribution (OOD) domains. In our study, we
introduce a two-phase representation learning technique using multi-task
learning. This approach aims to cultivate a latent space from features spanning
multiple domains, encompassing both native and cross-domains, to amplify
generalization to IN and OOD territories. Additionally, we attempt to
disentangle the latent space by minimizing the mutual information between the
prior and latent space, effectively de-correlating spurious feature
correlations. Collectively, the joint optimization will facilitate
domain-invariant feature learning. We assess the model's efficacy across
multiple cybersecurity datasets, using standard classification metrics on both
unseen IN and OOD sets, and juxtapose the results with contemporary domain
generalization methods.
</p></li>
</ul>

<h3>Title: AIJack: Security and Privacy Risk Simulator for Machine Learning. (arXiv:2312.17667v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17667">http://arxiv.org/abs/2312.17667</a></li>
<li>Code URL: <a href="https://github.com/Koukyosyumei/AIJack">https://github.com/Koukyosyumei/AIJack</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17667]] AIJack: Security and Privacy Risk Simulator for Machine Learning(http://arxiv.org/abs/2312.17667)</code></li>
<li>Summary: <p>This paper introduces AIJack, an open-source library designed to assess
security and privacy risks associated with the training and deployment of
machine learning models. Amid the growing interest in big data and AI,
advancements in machine learning research and business are accelerating.
However, recent studies reveal potential threats, such as the theft of training
data and the manipulation of models by malicious attackers. Therefore, a
comprehensive understanding of machine learning's security and privacy
vulnerabilities is crucial for the safe integration of machine learning into
real-world products. AIJack aims to address this need by providing a library
with various attack and defense methods through a unified API. The library is
publicly available on GitHub (https://github.com/Koukyosyumei/AIJack).
</p></li>
</ul>

<h3>Title: Malware Detection in IOT Systems Using Machine Learning Techniques. (arXiv:2312.17683v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17683">http://arxiv.org/abs/2312.17683</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17683]] Malware Detection in IOT Systems Using Machine Learning Techniques(http://arxiv.org/abs/2312.17683)</code></li>
<li>Summary: <p>Malware detection in IoT environments necessitates robust methodologies. This
study introduces a CNN-LSTM hybrid model for IoT malware identification and
evaluates its performance against established methods. Leveraging K-fold
cross-validation, the proposed approach achieved 95.5% accuracy, surpassing
existing methods. The CNN algorithm enabled superior learning model
construction, and the LSTM classifier exhibited heightened accuracy in
classification. Comparative analysis against prevalent techniques demonstrated
the efficacy of the proposed model, highlighting its potential for enhancing
IoT security. The study advocates for future exploration of SVMs as
alternatives, emphasizes the need for distributed detection strategies, and
underscores the importance of predictive analyses for a more powerful IOT
security. This research serves as a platform for developing more resilient
security measures in IoT ecosystems.
</p></li>
</ul>

<h3>Title: Comparing Effectiveness and Efficiency of Interactive Application Security Testing (IAST) and Runtime Application Self-Protection (RASP) Tools in a Large Java-based System. (arXiv:2312.17726v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17726">http://arxiv.org/abs/2312.17726</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17726]] Comparing Effectiveness and Efficiency of Interactive Application Security Testing (IAST) and Runtime Application Self-Protection (RASP) Tools in a Large Java-based System(http://arxiv.org/abs/2312.17726)</code></li>
<li>Summary: <p>Security resources are scarce, and practitioners need guidance in the
effective and efficient usage of techniques and tools available in the
cybersecurity industry. Two emerging tool types, Interactive Application
Security Testing (IAST) and Runtime Application Self-Protection (RASP), have
not been thoroughly evaluated against well-established counterparts such as
Dynamic Application Security Testing (DAST) and Static Application Security
Testing (SAST). The goal of this research is to aid practitioners in making
informed choices about the use of Interactive Application Security Testing
(IAST) and Runtime Application Self-Protection (RASP) tools through an analysis
of their effectiveness and efficiency in comparison with different
vulnerability detection and prevention techniques and tools. We apply IAST and
RASP on OpenMRS, an open-source Java-based online application. We compare the
efficiency and effectiveness of IAST and RASP with techniques applied on
OpenMRS in prior work. We measure efficiency and effectiveness in terms of the
number and type of vulnerabilities detected and prevented per hour. Our study
shows IAST performed relatively well compared to other techniques, performing
second-best in both efficiency and effectiveness. IAST detected eight Top-10
OWASP security risks compared to nine by SMPT and seven for EMPT, DAST, and
SAST. IAST found more vulnerabilities than SMPT. The efficiency of IAST (2.14
VpH) is second to only EMPT (2.22 VpH). These findings imply that our study
benefited from using IAST when conducting black-box security testing. In the
context of a large, enterprise-scale web application such as OpenMRS, RASP does
not replace vulnerability detection, while IAST is a powerful tool that
complements other techniques.
</p></li>
</ul>

<h2>privacy</h2>
<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Jatmo: Prompt Injection Defense by Task-Specific Finetuning. (arXiv:2312.17673v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17673">http://arxiv.org/abs/2312.17673</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17673]] Jatmo: Prompt Injection Defense by Task-Specific Finetuning(http://arxiv.org/abs/2312.17673)</code></li>
<li>Summary: <p>Large Language Models (LLMs) are attracting significant research attention
due to their instruction-following abilities, allowing users and developers to
leverage LLMs for a variety of tasks. However, LLMs are vulnerable to
prompt-injection attacks: a class of attacks that hijack the model's
instruction-following abilities, changing responses to prompts to undesired,
possibly malicious ones. In this work, we introduce Jatmo, a method for
generating task-specific models resilient to prompt-injection attacks. Jatmo
leverages the fact that LLMs can only follow instructions once they have
undergone instruction tuning. It harnesses a teacher instruction-tuned model to
generate a task-specific dataset, which is then used to fine-tune a base model
(i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a
dataset of inputs for the task: it uses the teacher model to generate outputs.
For situations with no pre-existing datasets, Jatmo can use a single example,
or in some cases none at all, to produce a fully synthetic dataset. Our
experiments on six tasks show that Jatmo models provide the same quality of
outputs on their specific task as standard LLMs, while being resilient to
prompt injections. The best attacks succeeded in less than 0.5% of cases
against our models, versus over 90% success rate against GPT-3.5-Turbo. We
release Jatmo at https://github.com/wagner-group/prompt-injection-defense.
</p></li>
</ul>

<h3>Title: Towards Zero-Trust 6GC: A Software Defined Perimeter Approach with Dynamic Moving Target Defense Mechanism. (arXiv:2312.17271v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17271">http://arxiv.org/abs/2312.17271</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17271]] Towards Zero-Trust 6GC: A Software Defined Perimeter Approach with Dynamic Moving Target Defense Mechanism(http://arxiv.org/abs/2312.17271)</code></li>
<li>Summary: <p>The upcoming Sixth Generation (6G) network is projected to grapple with a
range of security concerns, encompassing access control, authentication, secure
connections among 6G Core (6GC) entities, and trustworthiness. Classical
Virtual Private Networks (VPNs), extensively deployed in Evolved Packet Core
(EPC) network infrastructure, are notoriously susceptible to a variety of
attacks, including man-in-the-middle incursions, Domain Name System (DNS)
hijacking, Denial of Service (DoS) attacks, port scanning, and persistent
unauthorized access attempts. This paper introduces the concept of Software
Defined Perimeter (SDP) as an innovative solution, providing an alternative to
VPNs with the goal of fostering a secure zero-trust milieu within the 6G Core
networks. We capitalize on the SDP controller-based authentication and
authorization mechanisms to secure the EPC network's control and data plane
functions, conceiving an architecture that is expansible to the 6G network.
Further, we augment the SDP zero-trust capabilities via the incorporation of a
dynamic component, the Moving Target Defense (MTD). This enhances the network's
resilience against attacks targeting traditionally static network environments
established via VPNs. Following rigorous testbed analysis, our proposed
framework manifests superior resilience against DoS and port scanning attacks
when juxtaposed with traditional VPN methodologies.
</p></li>
</ul>

<h3>Title: Can you See me? On the Visibility of NOPs against Android Malware Detectors. (arXiv:2312.17356v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17356">http://arxiv.org/abs/2312.17356</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17356]] Can you See me? On the Visibility of NOPs against Android Malware Detectors(http://arxiv.org/abs/2312.17356)</code></li>
<li>Summary: <p>Android malware still represents the most significant threat to mobile
systems. While Machine Learning systems are increasingly used to identify these
threats, past studies have revealed that attackers can bypass these detection
mechanisms by making subtle changes to Android applications, such as adding
specific API calls. These modifications are often referred to as No OPerations
(NOP), which ideally should not alter the semantics of the program. However,
many NOPs can be spotted and eliminated by refining the app analysis process.
This paper proposes a visibility metric that assesses the difficulty in
spotting NOPs and similar non-operational codes. We tested our metric on a
state-of-the-art, opcode-based deep learning system for Android malware
detection. We implemented attacks on the feature and problem spaces and
calculated their visibility according to our metric. The attained results show
an intriguing trade-off between evasion efficacy and detectability: our metric
can be valuable to ensure the real effectiveness of an adversarial attack, also
serving as a useful aid to develop better defenses.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: MVPatch: More Vivid Patch for Adversarial Camouflaged Attacks on Object Detectors in the Physical World. (arXiv:2312.17431v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17431">http://arxiv.org/abs/2312.17431</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17431]] MVPatch: More Vivid Patch for Adversarial Camouflaged Attacks on Object Detectors in the Physical World(http://arxiv.org/abs/2312.17431)</code></li>
<li>Summary: <p>Recent research has shown that adversarial patches can manipulate outputs
from object detection models. However, the conspicuous patterns on these
patches may draw more attention and raise suspicions among humans. Moreover,
existing works have primarily focused on the attack performance of individual
models and have neglected the generation of adversarial patches for ensemble
attacks on multiple object detection models. To tackle these concerns, we
propose a novel approach referred to as the More Vivid Patch (MVPatch), which
aims to improve the transferability and stealthiness of adversarial patches
while considering the limitations observed in prior paradigms, such as easy
identification and poor transferability. Our approach incorporates an attack
algorithm that decreases object confidence scores of multiple object detectors
by using the ensemble attack loss function, thereby enhancing the
transferability of adversarial patches. Additionally, we propose a lightweight
visual similarity measurement algorithm realized by the Compared Specified
Image Similarity (CSS) loss function, which allows for the generation of
natural and stealthy adversarial patches without the reliance on additional
generative models. Extensive experiments demonstrate that the proposed MVPatch
algorithm achieves superior attack transferability compared to similar
algorithms in both digital and physical domains, while also exhibiting a more
natural appearance. These findings emphasize the remarkable stealthiness and
transferability of the proposed MVPatch attack algorithm.
</p></li>
</ul>

<h3>Title: Anticipated Network Surveillance -- An extrapolated study to predict cyber-attacks using Machine Learning and Data Analytics. (arXiv:2312.17270v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17270">http://arxiv.org/abs/2312.17270</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17270]] Anticipated Network Surveillance -- An extrapolated study to predict cyber-attacks using Machine Learning and Data Analytics(http://arxiv.org/abs/2312.17270)</code></li>
<li>Summary: <p>Machine learning and data mining techniques are utiized for enhancement of
the security of any network. Researchers used machine learning for pattern
detection, anomaly detection, dynamic policy setting, etc. The methods allow
the program to learn from data and make decisions without human intervention,
consuming a huge training period and computation power. This paper discusses a
novel technique to predict an upcoming attack in a network based on several
data parameters. The dataset is continuous in real-time implementation. The
proposed model comprises dataset pre-processing, and training, followed by the
testing phase. Based on the results of the testing phase, the best model is
selected using which, event class which may lead to an attack is extracted. The
event statistics are used for attack
</p></li>
</ul>

<h3>Title: Explainability-Based Adversarial Attack on Graphs Through Edge Perturbation. (arXiv:2312.17301v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17301">http://arxiv.org/abs/2312.17301</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17301]] Explainability-Based Adversarial Attack on Graphs Through Edge Perturbation(http://arxiv.org/abs/2312.17301)</code></li>
<li>Summary: <p>Despite the success of graph neural networks (GNNs) in various domains, they
exhibit susceptibility to adversarial attacks. Understanding these
vulnerabilities is crucial for developing robust and secure applications. In
this paper, we investigate the impact of test time adversarial attacks through
edge perturbations which involve both edge insertions and deletions. A novel
explainability-based method is proposed to identify important nodes in the
graph and perform edge perturbation between these nodes. The proposed method is
tested for node classification with three different architectures and datasets.
The results suggest that introducing edges between nodes of different classes
has higher impact as compared to removing edges among nodes within the same
class.
</p></li>
</ul>

<h3>Title: Simple client-side encryption of personal information with Web Assembly. (arXiv:2312.17689v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17689">http://arxiv.org/abs/2312.17689</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17689]] Simple client-side encryption of personal information with Web Assembly(http://arxiv.org/abs/2312.17689)</code></li>
<li>Summary: <p>The HTTPS protocol has enforced a higher level of robustness to several
attacks; however, it is not easy to set up the required certificates on
intranets, nor is it effective in the case the server confidentiality is not
reliable, as in the case of cloud services, or it could be compromised. A
simple method is proposed to encrypt the data on the client side, using Web
Assembly. It never transfers data to the server as clear text. Searching fields
in the server is made possible by an encoding scheme that ensures a stable
prefix correspondence between ciphertext and plaintext. The method has been
developed for a semantic medical database, and allows accessing personal data
using an additional password while maintaining non-sensitive information in
clear form. Web Assembly has been chosen to guarantee the fast and efficient
execution of encrypting/decrypting operations and because of its characteristic
of producing modules that are very robust against reverse engineering. The code
is available at https://github.com/mfalda/client-encdec.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: TimePillars: Temporally-Recurrent 3D LiDAR Object Detection. (arXiv:2312.17260v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17260">http://arxiv.org/abs/2312.17260</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17260]] TimePillars: Temporally-Recurrent 3D LiDAR Object Detection(http://arxiv.org/abs/2312.17260)</code></li>
<li>Summary: <p>Object detection applied to LiDAR point clouds is a relevant task in
robotics, and particularly in autonomous driving. Single frame methods,
predominant in the field, exploit information from individual sensor scans.
Recent approaches achieve good performance, at relatively low inference time.
Nevertheless, given the inherent high sparsity of LiDAR data, these methods
struggle in long-range detection (e.g. 200m) which we deem to be critical in
achieving safe automation. Aggregating multiple scans not only leads to a
denser point cloud representation, but it also brings time-awareness to the
system, and provides information about how the environment is changing.
Solutions of this kind, however, are often highly problem-specific, demand
careful data processing, and tend not to fulfil runtime requirements. In this
context we propose TimePillars, a temporally-recurrent object detection
pipeline which leverages the pillar representation of LiDAR data across time,
respecting hardware integration efficiency constraints, and exploiting the
diversity and long-range information of the novel Zenseact Open Dataset (ZOD).
Through experimentation, we prove the benefits of having recurrency, and show
how basic building blocks are enough to achieve robust and efficient results.
</p></li>
</ul>

<h3>Title: $\mu$-Net: ConvNext-Based U-Nets for Cosmic Muon Tomography. (arXiv:2312.17265v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17265">http://arxiv.org/abs/2312.17265</a></li>
<li>Code URL: <a href="https://github.com/jedlimlx/Muon-Tomography-AI">https://github.com/jedlimlx/Muon-Tomography-AI</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17265]] $\mu$-Net: ConvNext-Based U-Nets for Cosmic Muon Tomography(http://arxiv.org/abs/2312.17265)</code></li>
<li>Summary: <p>Muon scattering tomography utilises muons, typically originating from cosmic
rays to image the interiors of dense objects. However, due to the low flux of
cosmic ray muons at sea-level and the highly complex interactions that muons
display when travelling through matter, existing reconstruction algorithms
often suffer from low resolution and high noise. In this work, we develop a
novel two-stage deep learning algorithm, $\mu$-Net, consisting of an MLP to
predict the muon trajectory and a ConvNeXt-based U-Net to convert the
scattering points into voxels. $\mu$-Net achieves a state-of-the-art
performance of 17.14 PSNR at the dosage of 1024 muons, outperforming
traditional reconstruction algorithms such as the point of closest approach
algorithm and maximum likelihood and expectation maximisation algorithm.
Furthermore, we find that our method is robust to various corruptions such as
inaccuracies in the muon momentum or a limited detector resolution. We also
generate and publicly release the first large-scale dataset that maps muon
detections to voxels. We hope that our research will spark further
investigations into the potential of deep learning to revolutionise this field.
</p></li>
</ul>

<h3>Title: X Modality Assisting RGBT Object Tracking. (arXiv:2312.17273v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17273">http://arxiv.org/abs/2312.17273</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17273]] X Modality Assisting RGBT Object Tracking(http://arxiv.org/abs/2312.17273)</code></li>
<li>Summary: <p>Learning robust multi-modal feature representations is critical for boosting
tracking performance. To this end, we propose a novel X Modality Assisting
Network (X-Net) to shed light on the impact of the fusion paradigm by
decoupling the visual object tracking into three distinct levels, facilitating
subsequent processing. Firstly, to tackle the feature learning hurdles stemming
from significant differences between RGB and thermal modalities, a
plug-and-play pixel-level generation module (PGM) is proposed based on
self-knowledge distillation learning, which effectively generates X modality to
bridge the gap between the dual patterns while reducing noise interference.
Subsequently, to further achieve the optimal sample feature representation and
facilitate cross-modal interactions, we propose a feature-level interaction
module (FIM) that incorporates a mixed feature interaction transformer and a
spatial-dimensional feature translation strategy. Ultimately, aiming at random
drifting due to missing instance features, we propose a flexible online
optimized strategy called the decision-level refinement module (DRM), which
contains optical flow and refinement mechanisms. Experiments are conducted on
three benchmarks to verify that the proposed X-Net outperforms state-of-the-art
trackers.
</p></li>
</ul>

<h3>Title: MoD2T:Model-Data-Driven Motion-Static Object Tracking Method. (arXiv:2312.17641v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17641">http://arxiv.org/abs/2312.17641</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17641]] MoD2T:Model-Data-Driven Motion-Static Object Tracking Method(http://arxiv.org/abs/2312.17641)</code></li>
<li>Summary: <p>The domain of Multi-Object Tracking (MOT) is of paramount significance within
the realm of video analysis. However, both traditional methodologies and deep
learning-based approaches within this domain exhibit inherent limitations. Deep
learning methods driven exclusively by data exhibit challenges in accurately
discerning the motion states of objects, while traditional methods relying on
comprehensive mathematical models may suffer from suboptimal tracking
precision. To address these challenges, we introduce the Model-Data-Driven
Motion-Static Object Tracking Method (MoD2T). We propose a novel architecture
that adeptly amalgamates traditional mathematical modeling with deep
learning-based MOT frameworks, thereby effectively mitigating the limitations
associated with sole reliance on established methodologies or advanced deep
learning techniques. MoD2T's fusion of mathematical modeling and deep learning
augments the precision of object motion determination, consequently enhancing
tracking accuracy. Our empirical experiments robustly substantiate MoD2T's
efficacy across a diverse array of scenarios, including UAV aerial surveillance
and street-level tracking. To assess MoD2T's proficiency in discerning object
motion states, we introduce MVF1 metric. This novel performance metric is
designed to measure the accuracy of motion state classification, providing a
comprehensive evaluation of MoD2T's performance. Meticulous experiments
substantiate the rationale behind MVF1's formulation. To provide a
comprehensive assessment of MoD2T's performance, we meticulously annotate
diverse datasets and subject MoD2T to rigorous testing. The achieved MVF1
scores, which measure the accuracy of motion state classification, are
particularly noteworthy in scenarios marked by minimal or mild camera motion,
with values of 0.774 on the KITTI dataset, 0.521 on MOT17, and 0.827 on UAVDT.
</p></li>
</ul>

<h3>Title: TACIT: A Target-Agnostic Feature Disentanglement Framework for Cross-Domain Text Classification. (arXiv:2312.17263v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17263">http://arxiv.org/abs/2312.17263</a></li>
<li>Code URL: <a href="https://github.com/songruiecho/tacit">https://github.com/songruiecho/tacit</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17263]] TACIT: A Target-Agnostic Feature Disentanglement Framework for Cross-Domain Text Classification(http://arxiv.org/abs/2312.17263)</code></li>
<li>Summary: <p>Cross-domain text classification aims to transfer models from label-rich
source domains to label-poor target domains, giving it a wide range of
practical applications. Many approaches promote cross-domain generalization by
capturing domain-invariant features. However, these methods rely on unlabeled
samples provided by the target domains, which renders the model ineffective
when the target domain is agnostic. Furthermore, the models are easily
disturbed by shortcut learning in the source domain, which also hinders the
improvement of domain generalization ability. To solve the aforementioned
issues, this paper proposes TACIT, a target domain agnostic feature
disentanglement framework which adaptively decouples robust and unrobust
features by Variational Auto-Encoders. Additionally, to encourage the
separation of unrobust features from robust features, we design a feature
distillation task that compels unrobust features to approximate the output of
the teacher. The teacher model is trained with a few easy samples that are easy
to carry potential unknown shortcuts. Experimental results verify that our
framework achieves comparable results to state-of-the-art baselines while
utilizing only source domain data.
</p></li>
</ul>

<h3>Title: Towards Faithful Explanations for Text Classification with Robustness Improvement and Explanation Guided Training. (arXiv:2312.17591v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17591">http://arxiv.org/abs/2312.17591</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17591]] Towards Faithful Explanations for Text Classification with Robustness Improvement and Explanation Guided Training(http://arxiv.org/abs/2312.17591)</code></li>
<li>Summary: <p>Feature attribution methods highlight the important input tokens as
explanations to model predictions, which have been widely applied to deep
neural networks towards trustworthy AI. However, recent works show that
explanations provided by these methods face challenges of being faithful and
robust. In this paper, we propose a method with Robustness improvement and
Explanation Guided training towards more faithful EXplanations (REGEX) for text
classification. First, we improve model robustness by input gradient
regularization technique and virtual adversarial training. Secondly, we use
salient ranking to mask noisy tokens and maximize the similarity between model
attention and feature attribution, which can be seen as a self-training
procedure without importing other external information. We conduct extensive
experiments on six datasets with five attribution methods, and also evaluate
the faithfulness in the out-of-domain setting. The results show that REGEX
improves fidelity metrics of explanations in all settings and further achieves
consistent gains based on two randomization tests. Moreover, we show that using
highlight explanations produced by REGEX to train select-then-predict models
results in comparable task performance to the end-to-end method.
</p></li>
</ul>

<h3>Title: Out of the Ordinary: Spectrally Adapting Regression for Covariate Shift. (arXiv:2312.17463v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17463">http://arxiv.org/abs/2312.17463</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17463]] Out of the Ordinary: Spectrally Adapting Regression for Covariate Shift(http://arxiv.org/abs/2312.17463)</code></li>
<li>Summary: <p>Designing deep neural network classifiers that perform robustly on
distributions differing from the available training data is an active area of
machine learning research. However, out-of-distribution generalization for
regression-the analogous problem for modeling continuous targets-remains
relatively unexplored. To tackle this problem, we return to first principles
and analyze how the closed-form solution for Ordinary Least Squares (OLS)
regression is sensitive to covariate shift. We characterize the
out-of-distribution risk of the OLS model in terms of the eigenspectrum
decomposition of the source and target data. We then use this insight to
propose a method for adapting the weights of the last layer of a pre-trained
neural regression model to perform better on input data originating from a
different distribution. We demonstrate how this lightweight spectral adaptation
procedure can improve out-of-distribution performance for synthetic and
real-world datasets.
</p></li>
</ul>

<h3>Title: Embedded feature selection in LSTM networks with multi-objective evolutionary ensemble learning for time series forecasting. (arXiv:2312.17517v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17517">http://arxiv.org/abs/2312.17517</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17517]] Embedded feature selection in LSTM networks with multi-objective evolutionary ensemble learning for time series forecasting(http://arxiv.org/abs/2312.17517)</code></li>
<li>Summary: <p>Time series forecasting plays a crucial role in diverse fields, necessitating
the development of robust models that can effectively handle complex temporal
patterns. In this article, we present a novel feature selection method embedded
in Long Short-Term Memory networks, leveraging a multi-objective evolutionary
algorithm. Our approach optimizes the weights and biases of the LSTM in a
partitioned manner, with each objective function of the evolutionary algorithm
targeting the root mean square error in a specific data partition. The set of
non-dominated forecast models identified by the algorithm is then utilized to
construct a meta-model through stacking-based ensemble learning. Furthermore,
our proposed method provides an avenue for attribute importance determination,
as the frequency of selection for each attribute in the set of non-dominated
forecasting models reflects their significance. This attribute importance
insight adds an interpretable dimension to the forecasting process.
Experimental evaluations on air quality time series data from Italy and
southeast Spain demonstrate that our method substantially improves the
generalization ability of conventional LSTMs, effectively reducing overfitting.
Comparative analyses against state-of-the-art CancelOut and EAR-FS methods
highlight the superior performance of our approach.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction. (arXiv:2312.17346v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17346">http://arxiv.org/abs/2312.17346</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17346]] STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction(http://arxiv.org/abs/2312.17346)</code></li>
<li>Summary: <p>We present STanHop-Net (Sparse Tandem Hopfield Network) for multivariate time
series prediction with memory-enhanced capabilities. At the heart of our
approach is STanHop, a novel Hopfield-based neural network block, which
sparsely learns and stores both temporal and cross-series representations in a
data-dependent fashion. In essence, STanHop sequentially learn temporal
representation and cross-series representation using two tandem sparse Hopfield
layers. In addition, StanHop incorporates two additional external memory
modules: a Plug-and-Play module and a Tune-and-Play module for train-less and
task-aware memory-enhancements, respectively. They allow StanHop-Net to swiftly
respond to certain sudden events. Methodologically, we construct the
StanHop-Net by stacking STanHop blocks in a hierarchical fashion, enabling
multi-resolution feature extraction with resolution-specific sparsity.
Theoretically, we introduce a sparse extension of the modern Hopfield model
(Generalized Sparse Modern Hopfield Model) and show that it endows a tighter
memory retrieval error compared to the dense counterpart without sacrificing
memory capacity. Empirically, we validate the efficacy of our framework on both
synthetic and real-world settings.
</p></li>
</ul>

<h3>Title: ESGReveal: An LLM-based approach for extracting structured data from ESG reports. (arXiv:2312.17264v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17264">http://arxiv.org/abs/2312.17264</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17264]] ESGReveal: An LLM-based approach for extracting structured data from ESG reports(http://arxiv.org/abs/2312.17264)</code></li>
<li>Summary: <p>ESGReveal is an innovative method proposed for efficiently extracting and
analyzing Environmental, Social, and Governance (ESG) data from corporate
reports, catering to the critical need for reliable ESG information retrieval.
This approach utilizes Large Language Models (LLM) enhanced with Retrieval
Augmented Generation (RAG) techniques. The ESGReveal system includes an ESG
metadata module for targeted queries, a preprocessing module for assembling
databases, and an LLM agent for data extraction. Its efficacy was appraised
using ESG reports from 166 companies across various sectors listed on the Hong
Kong Stock Exchange in 2022, ensuring comprehensive industry and market
capitalization representation. Utilizing ESGReveal unearthed significant
insights into ESG reporting with GPT-4, demonstrating an accuracy of 76.9% in
data extraction and 83.7% in disclosure analysis, which is an improvement over
baseline models. This highlights the framework's capacity to refine ESG data
analysis precision. Moreover, it revealed a demand for reinforced ESG
disclosures, with environmental and social data disclosures standing at 69.5%
and 57.2%, respectively, suggesting a pursuit for more corporate transparency.
While current iterations of ESGReveal do not process pictorial information, a
functionality intended for future enhancement, the study calls for continued
research to further develop and compare the analytical capabilities of various
LLMs. In summary, ESGReveal is a stride forward in ESG data processing,
offering stakeholders a sophisticated tool to better evaluate and advance
corporate sustainability efforts. Its evolution is promising in promoting
transparency in corporate reporting and aligning with broader sustainable
development aims.
</p></li>
</ul>

<h3>Title: Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning. (arXiv:2312.17267v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17267">http://arxiv.org/abs/2312.17267</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17267]] Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning(http://arxiv.org/abs/2312.17267)</code></li>
<li>Summary: <p>Recently, prompt-tuning with pre-trained language models (PLMs) has
demonstrated the significantly enhancing ability of relation extraction (RE)
tasks. However, in low-resource scenarios, where the available training data is
scarce, previous prompt-based methods may still perform poorly for prompt-based
representation learning due to a superficial understanding of the relation. To
this end, we highlight the importance of learning high-quality relation
representation in low-resource scenarios for RE, and propose a novel
prompt-based relation representation method, named MVRE
(\underline{M}ulti-\underline{V}iew \underline{R}elation
\underline{E}xtraction), to better leverage the capacity of PLMs to improve the
performance of RE within the low-resource prompt-tuning paradigm. Specifically,
MVRE decouples each relation into different perspectives to encompass
multi-view relation representations for maximizing the likelihood during
relation inference. Furthermore, we also design a Global-Local loss and a
Dynamic-Initialization method for better alignment of the multi-view
relation-representing virtual words, containing the semantics of relation
labels during the optimization learning process and initialization. Extensive
experiments on three benchmark datasets show that our method can achieve
state-of-the-art in low-resource settings.
</p></li>
</ul>

<h3>Title: Action-Item-Driven Summarization of Long Meeting Transcripts. (arXiv:2312.17581v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17581">http://arxiv.org/abs/2312.17581</a></li>
<li>Code URL: <a href="https://github.com/logangolia/meeting-summarization">https://github.com/logangolia/meeting-summarization</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17581]] Action-Item-Driven Summarization of Long Meeting Transcripts(http://arxiv.org/abs/2312.17581)</code></li>
<li>Summary: <p>The increased prevalence of online meetings has significantly enhanced the
practicality of a model that can automatically generate the summary of a given
meeting. This paper introduces a novel and effective approach to automate the
generation of meeting summaries. Current approaches to this problem generate
general and basic summaries, considering the meeting simply as a long dialogue.
However, our novel algorithms can generate abstractive meeting summaries that
are driven by the action items contained in the meeting transcript. This is
done by recursively generating summaries and employing our action-item
extraction algorithm for each section of the meeting in parallel. All of these
sectional summaries are then combined and summarized together to create a
coherent and action-item-driven summary. In addition, this paper introduces
three novel methods for dividing up long transcripts into topic-based sections
to improve the time efficiency of our algorithm, as well as to resolve the
issue of large language models (LLMs) forgetting long-term dependencies. Our
pipeline achieved a BERTScore of 64.98 across the AMI corpus, which is an
approximately 4.98% increase from the current state-of-the-art result produced
by a fine-tuned BART (Bidirectional and Auto-Regressive Transformers) model.
</p></li>
</ul>

<h3>Title: Large Language Models for Generative Information Extraction: A Survey. (arXiv:2312.17617v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17617">http://arxiv.org/abs/2312.17617</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17617]] Large Language Models for Generative Information Extraction: A Survey(http://arxiv.org/abs/2312.17617)</code></li>
<li>Summary: <p>Information extraction (IE) aims to extract structural knowledge (such as
entities, relations, and events) from plain natural language texts. Recently,
generative Large Language Models (LLMs) have demonstrated remarkable
capabilities in text understanding and generation, allowing for generalization
across various domains and tasks. As a result, numerous works have been
proposed to harness abilities of LLMs and offer viable solutions for IE tasks
based on a generative paradigm. To conduct a comprehensive systematic review
and exploration of LLM efforts for IE tasks, in this study, we survey the most
recent advancements in this field. We first present an extensive overview by
categorizing these works in terms of various IE subtasks and learning
paradigms, then we empirically analyze the most advanced methods and discover
the emerging trend of IE tasks with LLMs. Based on thorough review conducted,
we identify several insights in technique and promising research directions
that deserve further exploration in future studies. We maintain a public
repository and consistently update related resources at:
\url{https://github.com/quqxui/Awesome-LLM4IE-Papers}.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Differentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning. (arXiv:2312.17493v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17493">http://arxiv.org/abs/2312.17493</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17493]] Differentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning(http://arxiv.org/abs/2312.17493)</code></li>
<li>Summary: <p>The surge in interest and application of large language models (LLMs) has
sparked a drive to fine-tune these models to suit specific applications, such
as finance and medical science. However, concerns regarding data privacy have
emerged, especially when multiple stakeholders aim to collaboratively enhance
LLMs using sensitive data. In this scenario, federated learning becomes a
natural choice, allowing decentralized fine-tuning without exposing raw data to
central servers. Motivated by this, we investigate how data privacy can be
ensured in LLM fine-tuning through practical federated learning approaches,
enabling secure contributions from multiple parties to enhance LLMs. Yet,
challenges arise: 1) despite avoiding raw data exposure, there is a risk of
inferring sensitive information from model outputs, and 2) federated learning
for LLMs incurs notable communication overhead. To address these challenges,
this article introduces DP-LoRA, a novel federated learning algorithm tailored
for LLMs. DP-LoRA preserves data privacy by employing a Gaussian mechanism that
adds noise in weight updates, maintaining individual data privacy while
facilitating collaborative model training. Moreover, DP-LoRA optimizes
communication efficiency via low-rank adaptation, minimizing the transmission
of updated weights during distributed training. The experimental results across
medical, financial, and general datasets using various LLMs demonstrate that
DP-LoRA effectively ensures strict privacy constraints while minimizing
communication overhead.
</p></li>
</ul>

<h3>Title: LEFL: Low Entropy Client Sampling in Federated Learning. (arXiv:2312.17430v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17430">http://arxiv.org/abs/2312.17430</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17430]] LEFL: Low Entropy Client Sampling in Federated Learning(http://arxiv.org/abs/2312.17430)</code></li>
<li>Summary: <p>Federated learning (FL) is a machine learning paradigm where multiple clients
collaborate to optimize a single global model using their private data. The
global model is maintained by a central server that orchestrates the FL
training process through a series of training rounds. In each round, the server
samples clients from a client pool before sending them its latest global model
parameters for further optimization. Naive sampling strategies implement random
client sampling and fail to factor client data distributions for privacy
reasons. Hence we proposes an alternative sampling strategy by performing a
one-time clustering of clients based on their model's learned high-level
features while respecting data privacy. This enables the server to perform
stratified client sampling across clusters in every round. We show datasets of
sampled clients selected with this approach yield a low relative entropy with
respect to the global data distribution. Consequently, the FL training becomes
less noisy and significantly improves the convergence of the global model by as
much as 7.4% in some experiments. Furthermore, it also significantly reduces
the communication rounds required to achieve a target accuracy.
</p></li>
</ul>

<h3>Title: FedLED: Label-Free Equipment Fault Diagnosis with Vertical Federated Transfer Learning. (arXiv:2312.17451v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17451">http://arxiv.org/abs/2312.17451</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17451]] FedLED: Label-Free Equipment Fault Diagnosis with Vertical Federated Transfer Learning(http://arxiv.org/abs/2312.17451)</code></li>
<li>Summary: <p>Intelligent equipment fault diagnosis based on Federated Transfer Learning
(FTL) attracts considerable attention from both academia and industry. It
allows real-world industrial agents with limited samples to construct a fault
diagnosis model without jeopardizing their raw data privacy. Existing
approaches, however, can neither address the intense sample heterogeneity
caused by different working conditions of practical agents, nor the extreme
fault label scarcity, even zero, of newly deployed equipment. To address these
issues, we present FedLED, the first unsupervised vertical FTL equipment fault
diagnosis method, where knowledge of the unlabeled target domain is further
exploited for effective unsupervised model transfer. Results of extensive
experiments using data of real equipment monitoring demonstrate that FedLED
obviously outperforms SOTA approaches in terms of both diagnosis accuracy (up
to 4.13 times) and generality. We expect our work to inspire further study on
label-free equipment fault diagnosis systematically enhanced by target domain
knowledge.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h3>Title: 3VL: using Trees to teach Vision & Language models compositional concepts. (arXiv:2312.17345v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17345">http://arxiv.org/abs/2312.17345</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17345]] 3VL: using Trees to teach Vision & Language models compositional concepts(http://arxiv.org/abs/2312.17345)</code></li>
<li>Summary: <p>Vision-Language models (VLMs) have proved effective at aligning image and
text representations, producing superior zero-shot results when transferred to
many downstream tasks. However, these representations suffer some key
shortcomings in Compositional Language Concepts (CLC) understanding such as
recognizing objects' attributes, states, and relations between different
objects. Moreover, VLMs typically have poor interpretability, making it
challenging to debug and mitigate compositional-understanding failures. In this
work, we introduce the Tree-augmented Vision-Language (3VL) model architecture
and training technique accompanied by our proposed Anchor inference method and
Differential Relevance (DiRe) interpretability tool. By expanding the text of
an arbitrary image-text pair into a hierarchical tree structure using language
analysis tools, 3VL allows inducing this structure into the visual
representation learned by the model, enhancing its interpretability and
compositional reasoning. Additionally, we show how Anchor, a simple technique
for text unification, can be employed to filter nuisance factors while
increasing CLC understanding performance, e.g., on the fundamental VL-Checklist
benchmark. We also exhibit how DiRe, which performs a differential comparison
between VLM relevancy maps, enables us to generate compelling visualizations of
the reasons for a model's success or failure.
</p></li>
</ul>

<h3>Title: Interpretable and Explainable Machine Learning Methods for Predictive Process Monitoring: A Systematic Literature Review. (arXiv:2312.17584v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17584">http://arxiv.org/abs/2312.17584</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17584]] Interpretable and Explainable Machine Learning Methods for Predictive Process Monitoring: A Systematic Literature Review(http://arxiv.org/abs/2312.17584)</code></li>
<li>Summary: <p>This paper presents a systematic literature review (SLR) on the
explainability and interpretability of machine learning (ML) models within the
context of predictive process mining, using the PRISMA framework. Given the
rapid advancement of artificial intelligence (AI) and ML systems, understanding
the "black-box" nature of these technologies has become increasingly critical.
Focusing specifically on the domain of process mining, this paper delves into
the challenges of interpreting ML models trained with complex business process
data. We differentiate between intrinsically interpretable models and those
that require post-hoc explanation techniques, providing a comprehensive
overview of the current methodologies and their applications across various
application domains. Through a rigorous bibliographic analysis, this research
offers a detailed synthesis of the state of explainability and interpretability
in predictive process mining, identifying key trends, challenges, and future
directions. Our findings aim to equip researchers and practitioners with a
deeper understanding of how to develop and implement more trustworthy,
transparent, and effective intelligent systems for predictive process
analytics.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: XAI for In-hospital Mortality Prediction via Multimodal ICU Data. (arXiv:2312.17624v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17624">http://arxiv.org/abs/2312.17624</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17624]] XAI for In-hospital Mortality Prediction via Multimodal ICU Data(http://arxiv.org/abs/2312.17624)</code></li>
<li>Summary: <p>Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.
</p></li>
</ul>

<h2>watermark</h2>
<h3>Title: Optimizing watermarks for large language models. (arXiv:2312.17295v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17295">http://arxiv.org/abs/2312.17295</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17295]] Optimizing watermarks for large language models(http://arxiv.org/abs/2312.17295)</code></li>
<li>Summary: <p>With the rise of large language models (LLMs) and concerns about potential
misuse, watermarks for generative LLMs have recently attracted much attention.
An important aspect of such watermarks is the trade-off between their
identifiability and their impact on the quality of the generated text. This
paper introduces a systematic approach to this trade-off in terms of a
multi-objective optimization problem. For a large class of robust, efficient
watermarks, the associated Pareto optimal solutions are identified and shown to
outperform the currently default watermark.
</p></li>
</ul>

<h2>diffusion</h2>
<h3>Title: Leveraging Open-Vocabulary Diffusion to Camouflaged Instance Segmentation. (arXiv:2312.17505v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17505">http://arxiv.org/abs/2312.17505</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17505]] Leveraging Open-Vocabulary Diffusion to Camouflaged Instance Segmentation(http://arxiv.org/abs/2312.17505)</code></li>
<li>Summary: <p>Text-to-image diffusion techniques have shown exceptional capability of
producing high-quality images from text descriptions. This indicates that there
exists a strong correlation between the visual and textual domains. In
addition, text-image discriminative models such as CLIP excel in image
labelling from text prompts, thanks to the rich and diverse information
available from open concepts. In this paper, we leverage these technical
advances to solve a challenging problem in computer vision: camouflaged
instance segmentation. Specifically, we propose a method built upon a
state-of-the-art diffusion model, empowered by open-vocabulary to learn
multi-scale textual-visual features for camouflaged object representations.
Such cross-domain representations are desirable in segmenting camouflaged
objects where visual cues are subtle to distinguish the objects from the
background, especially in segmenting novel objects which are not seen in
training. We also develop technically supportive components to effectively fuse
cross-domain features and engage relevant features towards respective
foreground objects. We validate our method and compare it with existing ones on
several benchmark datasets of camouflaged instance segmentation and generic
open-vocabulary instance segmentation. Experimental results confirm the
advances of our method over existing ones. We will publish our code and
pre-trained models to support future research.
</p></li>
</ul>

<h3>Title: FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis. (arXiv:2312.17681v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17681">http://arxiv.org/abs/2312.17681</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17681]] FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis(http://arxiv.org/abs/2312.17681)</code></li>
<li>Summary: <p>Diffusion models have transformed the image-to-image (I2I) synthesis and are
now permeating into videos. However, the advancement of video-to-video (V2V)
synthesis has been hampered by the challenge of maintaining temporal
consistency across video frames. This paper proposes a consistent V2V synthesis
framework by jointly leveraging spatial conditions and temporal optical flow
clues within the source video. Contrary to prior methods that strictly adhere
to optical flow, our approach harnesses its benefits while handling the
imperfection in flow estimation. We encode the optical flow via warping from
the first frame and serve it as a supplementary reference in the diffusion
model. This enables our model for video synthesis by editing the first frame
with any prevalent I2I models and then propagating edits to successive frames.
Our V2V model, FlowVid, demonstrates remarkable properties: (1) Flexibility:
FlowVid works seamlessly with existing I2I models, facilitating various
modifications, including stylization, object swaps, and local edits. (2)
Efficiency: Generation of a 4-second video with 30 FPS and 512x512 resolution
takes only 1.5 minutes, which is 3.1x, 7.2x, and 10.5x faster than CoDeF,
Rerender, and TokenFlow, respectively. (3) High-quality: In user studies, our
FlowVid is preferred 45.7% of the time, outperforming CoDeF (3.5%), Rerender
(10.2%), and TokenFlow (40.4%).
</p></li>
</ul>

<h3>Title: PINN surrogate of Li-ion battery models for parameter inference. Part II: Regularization and application of the pseudo-2D model. (arXiv:2312.17336v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17336">http://arxiv.org/abs/2312.17336</a></li>
<li>Code URL: <a href="https://github.com/nrel/pinnstripes">https://github.com/nrel/pinnstripes</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17336]] PINN surrogate of Li-ion battery models for parameter inference(http://arxiv.org/abs/2312.17336)</code></li>
<li>Summary: <p>Bayesian parameter inference is useful to improve Li-ion battery diagnostics
and can help formulate battery aging models. However, it is computationally
intensive and cannot be easily repeated for multiple cycles, multiple operating
conditions, or multiple replicate cells. To reduce the computational cost of
Bayesian calibration, numerical solvers for physics-based models can be
replaced with faster surrogates. A physics-informed neural network (PINN) is
developed as a surrogate for the pseudo-2D (P2D) battery model calibration. For
the P2D surrogate, additional training regularization was needed as compared to
the PINN single-particle model (SPM) developed in Part I. Both the PINN SPM and
P2D surrogate models are exercised for parameter inference and compared to data
obtained from a direct numerical solution of the governing equations. A
parameter inference study highlights the ability to use these PINNs to
calibrate scaling parameters for the cathode Li diffusion and the anode
exchange current density. By realizing computational speed-ups of 2250x for the
P2D model, as compared to using standard integrating methods, the PINN
surrogates enable rapid state-of-health diagnostics. In the low-data
availability scenario, the testing error was estimated to 2mV for the SPM
surrogate and 10mV for the P2D surrogate which could be mitigated with
additional data.
</p></li>
</ul>

<h3>Title: Classifier-free graph diffusion for molecular property targeting. (arXiv:2312.17397v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17397">http://arxiv.org/abs/2312.17397</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17397]] Classifier-free graph diffusion for molecular property targeting(http://arxiv.org/abs/2312.17397)</code></li>
<li>Summary: <p>This work focuses on the task of property targeting: that is, generating
molecules conditioned on target chemical properties to expedite candidate
screening for novel drug and materials development. DiGress is a recent
diffusion model for molecular graphs whose distinctive feature is allowing
property targeting through classifier-based (CB) guidance. While CB guidance
may work to generate molecular-like graphs, we hint at the fact that its
assumptions apply poorly to the chemical domain. Based on this insight we
propose a classifier-free DiGress (FreeGress), which works by directly
injecting the conditioning information into the training process. CF guidance
is convenient given its less stringent assumptions and since it does not
require to train an auxiliary property regressor, thus halving the number of
trainable parameters in the model. We empirically show that our model yields up
to 79% improvement in Mean Absolute Error with respect to DiGress on property
targeting tasks on QM9 and ZINC-250k benchmarks. As an additional contribution,
we propose a simple yet powerful approach to improve chemical validity of
generated samples, based on the observation that certain chemical properties
such as molecular weight correlate with the number of atoms in molecules.
</p></li>
</ul>

<h3>Title: Data Augmentation for Supervised Graph Outlier Detection with Latent Diffusion Models. (arXiv:2312.17679v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17679">http://arxiv.org/abs/2312.17679</a></li>
<li>Code URL: <a href="https://github.com/kayzliu/godm">https://github.com/kayzliu/godm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17679]] Data Augmentation for Supervised Graph Outlier Detection with Latent Diffusion Models(http://arxiv.org/abs/2312.17679)</code></li>
<li>Summary: <p>Graph outlier detection is a prominent task of research and application in
the realm of graph neural networks. It identifies the outlier nodes that
exhibit deviation from the majority in the graph. One of the fundamental
challenges confronting supervised graph outlier detection algorithms is the
prevalent issue of class imbalance, where the scarcity of outlier instances
compared to normal instances often results in suboptimal performance.
Conventional methods mitigate the imbalance by reweighting instances in the
estimation of the loss function, assigning higher weights to outliers and lower
weights to inliers. Nonetheless, these strategies are prone to overfitting and
underfitting, respectively. Recently, generative models, especially diffusion
models, have demonstrated their efficacy in synthesizing high-fidelity images.
Despite their extraordinary generation quality, their potential in data
augmentation for supervised graph outlier detection remains largely
underexplored.
</p>
<p>To bridge this gap, we introduce GODM, a novel data augmentation for
mitigating class imbalance in supervised Graph Outlier detection with latent
Diffusion Models. Specifically, our proposed method consists of three key
components: (1) Variantioanl Encoder maps the heterogeneous information
inherent within the graph data into a unified latent space. (2) Graph Generator
synthesizes graph data that are statistically similar to real outliers from
latent space, and (3) Latent Diffusion Model learns the latent space
distribution of real organic data by iterative denoising. Extensive experiments
conducted on multiple datasets substantiate the effectiveness and efficiency of
GODM. The case study further demonstrated the generation quality of our
synthetic data. To foster accessibility and reproducibility, we encapsulate
GODM into a plug-and-play package and release it at the Python Package Index
(PyPI).
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Transformer-Based Multi-Object Smoothing with Decoupled Data Association and Smoothing. (arXiv:2312.17261v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17261">http://arxiv.org/abs/2312.17261</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17261]] Transformer-Based Multi-Object Smoothing with Decoupled Data Association and Smoothing(http://arxiv.org/abs/2312.17261)</code></li>
<li>Summary: <p>Multi-object tracking (MOT) is the task of estimating the state trajectories
of an unknown and time-varying number of objects over a certain time window.
Several algorithms have been proposed to tackle the multi-object smoothing
task, where object detections can be conditioned on all the measurements in the
time window. However, the best-performing methods suffer from intractable
computational complexity and require approximations, performing suboptimally in
complex settings. Deep learning based algorithms are a possible venue for
tackling this issue but have not been applied extensively in settings where
accurate multi-object models are available and measurements are
low-dimensional. We propose a novel DL architecture specifically tailored for
this setting that decouples the data association task from the smoothing task.
We compare the performance of the proposed smoother to the state-of-the-art in
different tasks of varying difficulty and provide, to the best of our
knowledge, the first comparison between traditional Bayesian trackers and DL
trackers in the smoothing problem setting.
</p></li>
</ul>

<h3>Title: RefineNet: Enhancing Text-to-Image Conversion with High-Resolution and Detail Accuracy through Hierarchical Transformers and Progressive Refinement. (arXiv:2312.17274v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17274">http://arxiv.org/abs/2312.17274</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17274]] RefineNet: Enhancing Text-to-Image Conversion with High-Resolution and Detail Accuracy through Hierarchical Transformers and Progressive Refinement(http://arxiv.org/abs/2312.17274)</code></li>
<li>Summary: <p>In this research, we introduce RefineNet, a novel architecture designed to
address resolution limitations in text-to-image conversion systems. We explore
the challenges of generating high-resolution images from textual descriptions,
focusing on the trade-offs between detail accuracy and computational
efficiency. RefineNet leverages a hierarchical Transformer combined with
progressive and conditional refinement techniques, outperforming existing
models in producing detailed and high-quality images. Through extensive
experiments on diverse datasets, we demonstrate RefineNet's superiority in
clarity and resolution, particularly in complex image categories like animals,
plants, and human faces. Our work not only advances the field of image-to-text
conversion but also opens new avenues for high-fidelity image generation in
various applications.
</p></li>
</ul>

<h3>Title: Count What You Want: Exemplar Identification and Few-shot Counting of Human Actions in the Wild. (arXiv:2312.17330v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17330">http://arxiv.org/abs/2312.17330</a></li>
<li>Code URL: <a href="https://github.com/cvlab-stonybrook/exrac">https://github.com/cvlab-stonybrook/exrac</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17330]] Count What You Want: Exemplar Identification and Few-shot Counting of Human Actions in the Wild(http://arxiv.org/abs/2312.17330)</code></li>
<li>Summary: <p>This paper addresses the task of counting human actions of interest using
sensor data from wearable devices. We propose a novel exemplar-based framework,
allowing users to provide exemplars of the actions they want to count by
vocalizing predefined sounds ''one'', ''two'', and ''three''. Our method first
localizes temporal positions of these utterances from the audio sequence. These
positions serve as the basis for identifying exemplars representing the action
class of interest. A similarity map is then computed between the exemplars and
the entire sensor data sequence, which is further fed into a density estimation
module to generate a sequence of estimated density values. Summing these
density values provides the final count. To develop and evaluate our approach,
we introduce a diverse and realistic dataset consisting of real-world data from
37 subjects and 50 action categories, encompassing both sensor and audio data.
The experiments on this dataset demonstrate the viability of the proposed
method in counting instances of actions from new classes and subjects that were
not part of the training data. On average, the discrepancy between the
predicted count and the ground truth value is 7.47, significantly lower than
the errors of the frequency-based and transformer-based methods. Our project,
code and dataset can be found at https://github.com/cvlab-stonybrook/ExRAC.
</p></li>
</ul>

<h3>Title: HEAP: Unsupervised Object Discovery and Localization with Contrastive Grouping. (arXiv:2312.17492v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17492">http://arxiv.org/abs/2312.17492</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17492]] HEAP: Unsupervised Object Discovery and Localization with Contrastive Grouping(http://arxiv.org/abs/2312.17492)</code></li>
<li>Summary: <p>Unsupervised object discovery and localization aims to detect or segment
objects in an image without any supervision. Recent efforts have demonstrated a
notable potential to identify salient foreground objects by utilizing
self-supervised transformer features. However, their scopes only build upon
patch-level features within an image, neglecting region/image-level and
cross-image relationships at a broader scale. Moreover, these methods cannot
differentiate various semantics from multiple instances. To address these
problems, we introduce Hierarchical mErging framework via contrAstive grouPing
(HEAP). Specifically, a novel lightweight head with cross-attention mechanism
is designed to adaptively group intra-image patches into semantically coherent
regions based on correlation among self-supervised features. Further, to ensure
the distinguishability among various regions, we introduce a region-level
contrastive clustering loss to pull closer similar regions across images. Also,
an image-level contrastive loss is present to push foreground and background
representations apart, with which foreground objects and background are
accordingly discovered. HEAP facilitates efficient hierarchical image
decomposition, which contributes to more accurate object discovery while also
enabling differentiation among objects of various classes. Extensive
experimental results on semantic segmentation retrieval, unsupervised object
discovery, and saliency detection tasks demonstrate that HEAP achieves
state-of-the-art performance.
</p></li>
</ul>

<h3>Title: A Fully Automated Pipeline Using Swin Transformers for Deep Learning-Based Blood Segmentation on Head CT Scans After Aneurysmal Subarachnoid Hemorrhage. (arXiv:2312.17553v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17553">http://arxiv.org/abs/2312.17553</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17553]] A Fully Automated Pipeline Using Swin Transformers for Deep Learning-Based Blood Segmentation on Head CT Scans After Aneurysmal Subarachnoid Hemorrhage(http://arxiv.org/abs/2312.17553)</code></li>
<li>Summary: <p>Background: Accurate volumetric assessment of spontaneous subarachnoid
hemorrhage (SAH) is a labor-intensive task performed with current manual and
semiautomatic methods that might be relevant for its clinical and prognostic
implications. In the present research, we sought to develop and validate an
artificial intelligence-driven, fully automated blood segmentation tool for SAH
patients via noncontrast computed tomography (NCCT) scans employing a
transformer-based Swin UNETR architecture. Methods: We retrospectively analyzed
NCCT scans from patients with confirmed aneurysmal subarachnoid hemorrhage
(aSAH) utilizing the Swin UNETR for segmentation. The performance of the
proposed method was evaluated against manually segmented ground truth data
using metrics such as Dice score, intersection over union (IoU), the volumetric
similarity index (VSI), the symmetric average surface distance (SASD), and
sensitivity and specificity. A validation cohort from an external institution
was included to test the generalizability of the model. Results: The model
demonstrated high accuracy with robust performance metrics across the internal
and external validation cohorts. Notably, it achieved high Dice coefficient
(0.873), IoU (0.810), VSI (0.840), sensitivity (0.821) and specificity (0.996)
values and a low SASD (1.866), suggesting proficiency in segmenting blood in
SAH patients. The model's efficiency was reflected in its processing speed,
indicating potential for real-time applications. Conclusions: Our Swin
UNETR-based model offers significant advances in the automated segmentation of
blood after aSAH on NCCT images. Despite the computational intensity, the model
operates effectively on standard hardware with a user-friendly interface,
facilitating broader clinical adoption. Further validation across diverse
datasets is warranted to confirm its clinical reliability.
</p></li>
</ul>

<h3>Title: P2M2-Net: Part-Aware Prompt-Guided Multimodal Point Cloud Completion. (arXiv:2312.17611v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17611">http://arxiv.org/abs/2312.17611</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17611]] P2M2-Net: Part-Aware Prompt-Guided Multimodal Point Cloud Completion(http://arxiv.org/abs/2312.17611)</code></li>
<li>Summary: <p>Inferring missing regions from severely occluded point clouds is highly
challenging. Especially for 3D shapes with rich geometry and structure details,
inherent ambiguities of the unknown parts are existing. Existing approaches
either learn a one-to-one mapping in a supervised manner or train a generative
model to synthesize the missing points for the completion of 3D point cloud
shapes. These methods, however, lack the controllability for the completion
process and the results are either deterministic or exhibiting uncontrolled
diversity. Inspired by the prompt-driven data generation and editing, we
propose a novel prompt-guided point cloud completion framework, coined
P2M2-Net, to enable more controllable and more diverse shape completion. Given
an input partial point cloud and a text prompt describing the part-aware
information such as semantics and structure of the missing region, our
Transformer-based completion network can efficiently fuse the multimodal
features and generate diverse results following the prompt guidance. We train
the P2M2-Net on a new large-scale PartNet-Prompt dataset and conduct extensive
experiments on two challenging shape completion benchmarks. Quantitative and
qualitative results show the efficacy of incorporating prompts for more
controllable part-aware point cloud completion and generation. Code and data
are available at https://github.com/JLU-ICL/P2M2-Net.
</p></li>
</ul>

<h3>Title: Multiscale Vision Transformers meet Bipartite Matching for efficient single-stage Action Localization. (arXiv:2312.17686v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17686">http://arxiv.org/abs/2312.17686</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17686]] Multiscale Vision Transformers meet Bipartite Matching for efficient single-stage Action Localization(http://arxiv.org/abs/2312.17686)</code></li>
<li>Summary: <p>Action Localization is a challenging problem that combines detection and
recognition tasks, which are often addressed separately. State-of-the-art
methods rely on off-the-shelf bounding box detections pre-computed at high
resolution and propose transformer models that focus on the classification task
alone. Such two-stage solutions are prohibitive for real-time deployment. On
the other hand, single-stage methods target both tasks by devoting part of the
network (generally the backbone) to sharing the majority of the workload,
compromising performance for speed. These methods build on adding a DETR head
with learnable queries that, after cross- and self-attention can be sent to
corresponding MLPs for detecting a person's bounding box and action. However,
DETR-like architectures are challenging to train and can incur in big
complexity.
</p>
<p>In this paper, we observe that a straight bipartite matching loss can be
applied to the output tokens of a vision transformer. This results in a
backbone + MLP architecture that can do both tasks without the need of an extra
encoder-decoder head and learnable queries. We show that a single MViT-S
architecture trained with bipartite matching to perform both tasks surpasses
the same MViT-S when trained with RoI align on pre-computed bounding boxes.
With a careful design of token pooling and the proposed training pipeline, our
MViTv2-S model achieves +3 mAP on AVA2.2. w.r.t. the two-stage counterpart.
Code and models will be released after paper revision.
</p></li>
</ul>

<h3>Title: Multimodal Classification of Teaching Activities from University Lecture Recordings. (arXiv:2312.17262v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17262">http://arxiv.org/abs/2312.17262</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17262]] Multimodal Classification of Teaching Activities from University Lecture Recordings(http://arxiv.org/abs/2312.17262)</code></li>
<li>Summary: <p>The way of understanding online higher education has greatly changed due to
the worldwide pandemic situation. Teaching is undertaken remotely, and the
faculty incorporate lecture audio recordings as part of the teaching material.
This new online teaching-learning setting has largely impacted university
classes. While online teaching technology that enriches virtual classrooms has
been abundant over the past two years, the same has not occurred in supporting
students during online learning. {To overcome this limitation, our aim is to
work toward enabling students to easily access the piece of the lesson
recording in which the teacher explains a theoretical concept, solves an
exercise, or comments on organizational issues of the course. To that end, we
present a multimodal classification algorithm that identifies the type of
activity that is being carried out at any time of the lesson by using a
transformer-based language model that exploits features from the audio file and
from the automated lecture transcription. The experimental results will show
that some academic activities are more easily identifiable with the audio
signal while resorting to the text transcription is needed to identify others.
All in all, our contribution aims to recognize the academic activities of a
teacher during a lesson.
</p></li>
</ul>

<h3>Title: AI Content Self-Detection for Transformer-based Large Language Models. (arXiv:2312.17289v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17289">http://arxiv.org/abs/2312.17289</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17289]] AI Content Self-Detection for Transformer-based Large Language Models(http://arxiv.org/abs/2312.17289)</code></li>
<li>Summary: <p>$ $The usage of generative artificial intelligence (AI) tools based on large
language models, including ChatGPT, Bard, and Claude, for text generation has
many exciting applications with the potential for phenomenal productivity
gains. One issue is authorship attribution when using AI tools. This is
especially important in an academic setting where the inappropriate use of
generative AI tools may hinder student learning or stifle research by creating
a large amount of automatically generated derivative work. Existing plagiarism
detection systems can trace the source of submitted text but are not yet
equipped with methods to accurately detect AI-generated text. This paper
introduces the idea of direct origin detection and evaluates whether generative
AI systems can recognize their output and distinguish it from human-written
texts. We argue why current transformer-based models may be able to self-detect
their own generated text and perform a small empirical study using zero-shot
learning to investigate if that is the case. Results reveal varying
capabilities of AI systems to identify their generated text. Google's Bard
model exhibits the largest capability of self-detection with an accuracy of
94\%, followed by OpenAI's ChatGPT with 83\%. On the other hand, Anthropic's
Claude model seems to be not able to self-detect.
</p></li>
</ul>

<h3>Title: MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining. (arXiv:2312.17482v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17482">http://arxiv.org/abs/2312.17482</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17482]] MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining(http://arxiv.org/abs/2312.17482)</code></li>
<li>Summary: <p>Although BERT-style encoder models are heavily used in NLP research, many
researchers do not pretrain their own BERTs from scratch due to the high cost
of training. In the past half-decade since BERT first rose to prominence, many
advances have been made with other transformer architectures and training
configurations that have yet to be systematically incorporated into BERT. Here,
we introduce MosaicBERT, a BERT-style encoder architecture and training recipe
that is empirically optimized for fast pretraining. This efficient architecture
incorporates FlashAttention, Attention with Linear Biases (ALiBi), Gated Linear
Units (GLU), a module to dynamically remove padded tokens, and low precision
LayerNorm into the classic transformer encoder block. The training recipe
includes a 30% masking ratio for the Masked Language Modeling (MLM) objective,
bfloat16 precision, and vocabulary size optimized for GPU throughput, in
addition to best-practices from RoBERTa and other encoder models. When
pretrained from scratch on the C4 dataset, this base model achieves a
downstream average GLUE (dev) score of 79.6 in 1.13 hours on 8 A100 80 GB GPUs
at a cost of roughly $20. We plot extensive accuracy vs. pretraining speed
Pareto curves and show that MosaicBERT base and large are consistently Pareto
optimal when compared to a competitive BERT base and large. This empirical
speed up in pretraining enables researchers and engineers to pretrain custom
BERT-style models at low cost instead of finetune on existing generic models.
We open source our model weights and code.
</p></li>
</ul>

<h3>Title: ClST: A Convolutional Transformer Framework for Automatic Modulation Recognition by Knowledge Distillation. (arXiv:2312.17446v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17446">http://arxiv.org/abs/2312.17446</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17446]] ClST: A Convolutional Transformer Framework for Automatic Modulation Recognition by Knowledge Distillation(http://arxiv.org/abs/2312.17446)</code></li>
<li>Summary: <p>With the rapid development of deep learning (DL) in recent years, automatic
modulation recognition (AMR) with DL has achieved high accuracy. However,
insufficient training signal data in complicated channel environments and
large-scale DL models are critical factors that make DL methods difficult to
deploy in practice. Aiming to these problems, we propose a novel neural network
named convolution-linked signal transformer (ClST) and a novel knowledge
distillation method named signal knowledge distillation (SKD). The ClST is
accomplished through three primary modifications: a hierarchy of transformer
containing convolution, a novel attention mechanism named parallel
spatial-channel attention (PSCA) mechanism and a novel convolutional
transformer block named convolution-transformer projection (CTP) to leverage a
convolutional projection. The SKD is a knowledge distillation method to
effectively reduce the parameters and complexity of neural networks. We train
two lightweight neural networks using the SKD algorithm, KD-CNN and
KD-MobileNet, to meet the demand that neural networks can be used on
miniaturized devices. The simulation results demonstrate that the ClST
outperforms advanced neural networks on all datasets. Moreover, both KD-CNN and
KD-MobileNet obtain higher recognition accuracy with less network complexity,
which is very beneficial for the deployment of AMR on miniaturized
communication devices.
</p></li>
</ul>

<h3>Title: Integrating Chemical Language and Molecular Graph in Multimodal Fused Deep Learning for Drug Property Prediction. (arXiv:2312.17495v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17495">http://arxiv.org/abs/2312.17495</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17495]] Integrating Chemical Language and Molecular Graph in Multimodal Fused Deep Learning for Drug Property Prediction(http://arxiv.org/abs/2312.17495)</code></li>
<li>Summary: <p>Accurately predicting molecular properties is a challenging but essential
task in drug discovery. Recently, many mono-modal deep learning methods have
been successfully applied to molecular property prediction. However, the
inherent limitation of mono-modal learning arises from relying solely on one
modality of molecular representation, which restricts a comprehensive
understanding of drug molecules and hampers their resilience against data
noise. To overcome the limitations, we construct multimodal deep learning
models to cover different molecular representations. We convert drug molecules
into three molecular representations, SMILES-encoded vectors, ECFP
fingerprints, and molecular graphs. To process the modal information,
Transformer-Encoder, bi-directional gated recurrent units (BiGRU), and graph
convolutional network (GCN) are utilized for feature learning respectively,
which can enhance the model capability to acquire complementary and naturally
occurring bioinformatics information. We evaluated our triple-modal model on
six molecule datasets. Different from bi-modal learning models, we adopt five
fusion methods to capture the specific features and leverage the contribution
of each modal information better. Compared with mono-modal models, our
multimodal fused deep learning (MMFDL) models outperform single models in
accuracy, reliability, and resistance capability against noise. Moreover, we
demonstrate its generalization ability in the prediction of binding constants
for protein-ligand complex molecules in the refined set of PDBbind. The
advantage of the multimodal model lies in its ability to process diverse
sources of data using proper models and suitable fusion methods, which would
enhance the noise resistance of the model while obtaining data diversity.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Distance Guided Generative Adversarial Network for Explainable Binary Classifications. (arXiv:2312.17538v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17538">http://arxiv.org/abs/2312.17538</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17538]] Distance Guided Generative Adversarial Network for Explainable Binary Classifications(http://arxiv.org/abs/2312.17538)</code></li>
<li>Summary: <p>Despite the potential benefits of data augmentation for mitigating the data
insufficiency, traditional augmentation methods primarily rely on the prior
intra-domain knowledge. On the other hand, advanced generative adversarial
networks (GANs) generate inter-domain samples with limited variety. These
previous methods make limited contributions to describing the decision
boundaries for binary classification. In this paper, we propose a distance
guided GAN (DisGAN) which controls the variation degrees of generated samples
in the hyperplane space. Specifically, we instantiate the idea of DisGAN by
combining two ways. The first way is vertical distance GAN (VerDisGAN) where
the inter-domain generation is conditioned on the vertical distances. The
second way is horizontal distance GAN (HorDisGAN) where the intra-domain
generation is conditioned on the horizontal distances. Furthermore, VerDisGAN
can produce the class-specific regions by mapping the source images to the
hyperplane. Experimental results show that DisGAN consistently outperforms the
GAN-based augmentation methods with explainable binary classification. The
proposed method can apply to different classification architectures and has
potential to extend to multi-class classification.
</p></li>
</ul>

<h3>Title: PanGu-$\pi$: Enhancing Language Model Architectures via Nonlinearity Compensation. (arXiv:2312.17276v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17276">http://arxiv.org/abs/2312.17276</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17276]] PanGu-$\pi$: Enhancing Language Model Architectures via Nonlinearity Compensation(http://arxiv.org/abs/2312.17276)</code></li>
<li>Summary: <p>The recent trend of large language models (LLMs) is to increase the scale of
both model size (\aka the number of parameters) and dataset to achieve better
generative ability, which is definitely proved by a lot of work such as the
famous GPT and Llama. However, large models often involve massive computational
costs, and practical applications cannot afford such high prices. However, the
method of constructing a strong model architecture for LLMs is rarely
discussed. We first analyze the state-of-the-art language model architectures
and observe the feature collapse problem. Based on the theoretical analysis, we
propose that the nonlinearity is also very important for language models, which
is usually studied in convolutional neural networks for vision tasks. The
series informed activation function is then introduced with tiny calculations
that can be ignored, and an augmented shortcut is further used to enhance the
model nonlinearity. We then demonstrate that the proposed approach is
significantly effective for enhancing the model nonlinearity through carefully
designed ablations; thus, we present a new efficient model architecture for
establishing modern, namely, PanGu-$\pi$. Experiments are then conducted using
the same dataset and training strategy to compare PanGu-$\pi$ with
state-of-the-art LLMs. The results show that PanGu-$\pi$-7B can achieve a
comparable performance to that of benchmarks with about 10\% inference
speed-up, and PanGu-$\pi$-1B can achieve state-of-the-art performance in terms
of accuracy and efficiency. In addition, we have deployed PanGu-$\pi$-7B in the
high-value domains of finance and law, developing an LLM named YunShan for
practical application. The results show that YunShan can surpass other models
with similar scales on benchmarks.
</p></li>
</ul>

<h3>Title: EHR Interaction Between Patients and AI: NoteAid EHR Interaction. (arXiv:2312.17475v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17475">http://arxiv.org/abs/2312.17475</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17475]] EHR Interaction Between Patients and AI: NoteAid EHR Interaction(http://arxiv.org/abs/2312.17475)</code></li>
<li>Summary: <p>With the rapid advancement of Large Language Models (LLMs) and their
outstanding performance in semantic and contextual comprehension, the potential
of LLMs in specialized domains warrants exploration. This paper introduces the
NoteAid EHR Interaction Pipeline, an innovative approach developed using
generative LLMs to assist in patient education, a task stemming from the need
to aid patients in understanding Electronic Health Records (EHRs). Building
upon the NoteAid work, we designed two novel tasks from the patient's
perspective: providing explanations for EHR content that patients may not
understand and answering questions posed by patients after reading their EHRs.
We extracted datasets containing 10,000 instances from MIMIC Discharge
Summaries and 876 instances from the MADE medical notes collection,
respectively, executing the two tasks through the NoteAid EHR Interaction
Pipeline with these data. Performance data of LLMs on these tasks were
collected and constructed as the corresponding NoteAid EHR Interaction Dataset.
Through a comprehensive evaluation of the entire dataset using LLM assessment
and a rigorous manual evaluation of 64 instances, we showcase the potential of
LLMs in patient education. Besides, the results provide valuable data support
for future exploration and applications in this domain while also supplying
high-quality synthetic datasets for in-house system training.
</p></li>
</ul>

<h3>Title: Building Efficient Universal Classifiers with Natural Language Inference. (arXiv:2312.17543v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17543">http://arxiv.org/abs/2312.17543</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17543]] Building Efficient Universal Classifiers with Natural Language Inference(http://arxiv.org/abs/2312.17543)</code></li>
<li>Summary: <p>Generative Large Language Models (LLMs) have become the mainstream choice for
fewshot and zeroshot learning thanks to the universality of text generation.
Many users, however, do not need the broad capabilities of generative LLMs when
they only want to automate a classification task. Smaller BERT-like models can
also learn universal tasks, which allow them to do any text classification task
without requiring fine-tuning (zeroshot classification) or to learn new tasks
with only a few examples (fewshot), while being significantly more efficient
than generative LLMs. This paper (1) explains how Natural Language Inference
(NLI) can be used as a universal classification task that follows similar
principles as instruction fine-tuning of generative LLMs, (2) provides a
step-by-step guide with reusable Jupyter notebooks for building a universal
classifier, and (3) shares the resulting universal classifier that is trained
on 33 datasets with 389 diverse classes. Parts of the code we share has been
used to train our older zeroshot classifiers that have been downloaded more
than 55 million times via the Hugging Face Hub as of December 2023. Our new
classifier improves zeroshot performance by 9.4%.
</p></li>
</ul>

<h3>Title: Generative Posterior Networks for Approximately Bayesian Epistemic Uncertainty Estimation. (arXiv:2312.17411v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17411">http://arxiv.org/abs/2312.17411</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17411]] Generative Posterior Networks for Approximately Bayesian Epistemic Uncertainty Estimation(http://arxiv.org/abs/2312.17411)</code></li>
<li>Summary: <p>In many real-world problems, there is a limited set of training data, but an
abundance of unlabeled data. We propose a new method, Generative Posterior
Networks (GPNs), that uses unlabeled data to estimate epistemic uncertainty in
high-dimensional problems. A GPN is a generative model that, given a prior
distribution over functions, approximates the posterior distribution directly
by regularizing the network towards samples from the prior. We prove
theoretically that our method indeed approximates the Bayesian posterior and
show empirically that it improves epistemic uncertainty estimation and
scalability over competing methods.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Video Understanding with Large Language Models: A Survey. (arXiv:2312.17432v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17432">http://arxiv.org/abs/2312.17432</a></li>
<li>Code URL: <a href="https://github.com/yunlong10/awesome-llms-for-video-understanding">https://github.com/yunlong10/awesome-llms-for-video-understanding</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17432]] Video Understanding with Large Language Models: A Survey(http://arxiv.org/abs/2312.17432)</code></li>
<li>Summary: <p>With the burgeoning growth of online video platforms and the escalating
volume of video content, the demand for proficient video understanding tools
has intensified markedly. With Large Language Models (LLMs) showcasing
remarkable capabilities in key language tasks, this survey provides a detailed
overview of the recent advancements in video understanding harnessing the power
of LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisingly
advanced, particularly their ability for open-ended spatial-temporal reasoning
combined with commonsense knowledge, suggesting a promising path for future
video understanding. We examine the unique characteristics and capabilities of
Vid-LLMs, categorizing the approaches into four main types: LLM-based Video
Agents, Vid-LLMs Pretraining, Vid-LLMs Instruction Tuning, and Hybrid Methods.
Furthermore, this survey also presents a comprehensive study of the tasks and
datasets for Vid-LLMs, along with the methodologies employed for evaluation.
Additionally, the survey explores the expansive applications of Vid-LLMs across
various domains, thereby showcasing their remarkable scalability and
versatility in addressing challenges in real-world video understanding.
Finally, the survey summarizes the limitations of existing Vid-LLMs and the
directions for future research. For more information, we recommend readers
visit the repository at
https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.
</p></li>
</ul>

<h3>Title: Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models. (arXiv:2312.17661v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17661">http://arxiv.org/abs/2312.17661</a></li>
<li>Code URL: <a href="https://github.com/eternityyw/gemini-commonsense-evaluation">https://github.com/eternityyw/gemini-commonsense-evaluation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17661]] Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models(http://arxiv.org/abs/2312.17661)</code></li>
<li>Summary: <p>The burgeoning interest in Multimodal Large Language Models (MLLMs), such as
OpenAI's GPT-4V(ision), has significantly impacted both academic and industrial
realms. These models enhance Large Language Models (LLMs) with advanced visual
understanding capabilities, facilitating their application in a variety of
multimodal tasks. Recently, Google introduced Gemini, a cutting-edge MLLM
designed specifically for multimodal integration. Despite its advancements,
preliminary benchmarks indicate that Gemini lags behind GPT models in
commonsense reasoning tasks. However, this assessment, based on a limited
dataset (i.e., HellaSWAG), does not fully capture Gemini's authentic
commonsense reasoning potential. To address this gap, our study undertakes a
thorough evaluation of Gemini's performance in complex reasoning tasks that
necessitate the integration of commonsense knowledge across modalities. We
carry out a comprehensive analysis of 12 commonsense reasoning datasets,
ranging from general to domain-specific tasks. This includes 11 datasets
focused solely on language, as well as one that incorporates multimodal
elements. Our experiments across four LLMs and two MLLMs demonstrate Gemini's
competitive commonsense reasoning capabilities. Additionally, we identify
common challenges faced by current LLMs and MLLMs in addressing commonsense
problems, underscoring the need for further advancements in enhancing the
commonsense reasoning abilities of these models.
</p></li>
</ul>

<h3>Title: Faithful Model Evaluation for Model-Based Metrics. (arXiv:2312.17254v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17254">http://arxiv.org/abs/2312.17254</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17254]] Faithful Model Evaluation for Model-Based Metrics(http://arxiv.org/abs/2312.17254)</code></li>
<li>Summary: <p>Statistical significance testing is used in natural language processing (NLP)
to determine whether the results of a study or experiment are likely to be due
to chance or if they reflect a genuine relationship. A key step in significance
testing is the estimation of confidence interval which is a function of sample
variance. Sample variance calculation is straightforward when evaluating
against ground truth. However, in many cases, a metric model is often used for
evaluation. For example, to compare toxicity of two large language models, a
toxicity classifier is used for evaluation. Existing works usually do not
consider the variance change due to metric model errors, which can lead to
wrong conclusions. In this work, we establish the mathematical foundation of
significance testing for model-based metrics. With experiments on public
benchmark datasets and a production system, we show that considering metric
model errors to calculate sample variances for model-based metrics changes the
conclusions in certain experiments.
</p></li>
</ul>

<h3>Title: From Bytes to Biases: Investigating the Cultural Self-Perception of Large Language Models. (arXiv:2312.17256v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17256">http://arxiv.org/abs/2312.17256</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17256]] From Bytes to Biases: Investigating the Cultural Self-Perception of Large Language Models(http://arxiv.org/abs/2312.17256)</code></li>
<li>Summary: <p>Large language models (LLMs) are able to engage in natural-sounding
conversations with humans, showcasing unprecedented capabilities for
information retrieval and automated decision support. They have disrupted
human-technology interaction and the way businesses operate. However,
technologies based on generative artificial intelligence (GenAI) are known to
hallucinate, misinform, and display biases introduced by the massive datasets
on which they are trained. Existing research indicates that humans may
unconsciously internalize these biases, which can persist even after they stop
using the programs. This study explores the cultural self-perception of LLMs by
prompting ChatGPT (OpenAI) and Bard (Google) with value questions derived from
the GLOBE project. The findings reveal that their cultural self-perception is
most closely aligned with the values of English-speaking countries and
countries characterized by sustained economic competitiveness. Recognizing the
cultural biases of LLMs and understanding how they work is crucial for all
members of society because one does not want the black box of artificial
intelligence to perpetuate bias in humans, who might, in turn, inadvertently
create and train even more biased algorithms.
</p></li>
</ul>

<h3>Title: Evolving Large Language Model Assistant with Long-Term Conditional Memory. (arXiv:2312.17257v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17257">http://arxiv.org/abs/2312.17257</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17257]] Evolving Large Language Model Assistant with Long-Term Conditional Memory(http://arxiv.org/abs/2312.17257)</code></li>
<li>Summary: <p>With the rapid development of large language models, AI assistants like
ChatGPT have widely entered people's works and lives. In this paper, we present
an evolving large language model assistant that utilizes verbal long-term
memory. It focuses on preserving the knowledge and experience from the history
dialogue between the user and AI assistant, which can be applied to future
dialogue for generating a better response. The model generates a set of records
for each finished dialogue and stores them in the memory. In later usage, given
a new user input, the model uses it to retrieve its related memory to improve
the quality of the response. To find the best form of memory, we explore
different ways of constructing the memory and propose a new memorizing
mechanism called conditional memory to solve the problems in previous methods.
We also investigate the retrieval and usage of memory in the generation
process. The assistant uses GPT-4 as the backbone and we evaluate it on three
constructed test datasets focusing on different abilities required by an AI
assistant with long-term memory.
</p></li>
</ul>

<h3>Title: Empowering Working Memory for Large Language Model Agents. (arXiv:2312.17259v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17259">http://arxiv.org/abs/2312.17259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17259]] Empowering Working Memory for Large Language Model Agents(http://arxiv.org/abs/2312.17259)</code></li>
<li>Summary: <p>Large language models (LLMs) have achieved impressive linguistic
capabilities. However, a key limitation persists in their lack of human-like
memory faculties. LLMs exhibit constrained memory retention across sequential
interactions, hindering complex reasoning. This paper explores the potential of
applying cognitive psychology's working memory frameworks, to enhance LLM
architecture. The limitations of traditional LLM memory designs are analyzed,
including their isolation of distinct dialog episodes and lack of persistent
memory links. To address this, an innovative model is proposed incorporating a
centralized Working Memory Hub and Episodic Buffer access to retain memories
across episodes. This architecture aims to provide greater continuity for
nuanced contextual reasoning during intricate tasks and collaborative
scenarios. While promising, further research is required into optimizing
episodic memory encoding, storage, prioritization, retrieval, and security.
Overall, this paper provides a strategic blueprint for developing LLM agents
with more sophisticated, human-like memory capabilities, highlighting memory
mechanisms as a vital frontier in artificial general intelligence.
</p></li>
</ul>

<h3>Title: Conversational Question Answering with Reformulations over Knowledge Graph. (arXiv:2312.17269v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17269">http://arxiv.org/abs/2312.17269</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17269]] Conversational Question Answering with Reformulations over Knowledge Graph(http://arxiv.org/abs/2312.17269)</code></li>
<li>Summary: <p>conversational question answering (convQA) over knowledge graphs (KGs)
involves answering multi-turn natural language questions about information
contained in a KG. State-of-the-art methods of ConvQA often struggle with
inexplicit question-answer pairs. These inputs are easy for human beings to
understand given a conversation history, but hard for a machine to interpret,
which can degrade ConvQA performance. To address this problem, we propose a
reinforcement learning (RL) based model, CornNet, which utilizes question
reformulations generated by large language models (LLMs) to improve ConvQA
performance. CornNet adopts a teacher-student architecture where a teacher
model learns question representations using human writing reformulations, and a
student model to mimic the teacher model's output via reformulations generated
by LLMs. The learned question representation is then used by an RL model to
locate the correct answer in a KG. Extensive experimental results show that
CornNet outperforms state-of-the-art convQA models.
</p></li>
</ul>

<h3>Title: Large Language Models for Conducting Advanced Text Analytics Information Systems Research. (arXiv:2312.17278v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17278">http://arxiv.org/abs/2312.17278</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17278]] Large Language Models for Conducting Advanced Text Analytics Information Systems Research(http://arxiv.org/abs/2312.17278)</code></li>
<li>Summary: <p>The exponential growth of digital content has generated massive textual
datasets, necessitating advanced analytical approaches. Large Language Models
(LLMs) have emerged as tools capable of processing and extracting insights from
massive unstructured textual datasets. However, how to leverage LLMs for
text-based Information Systems (IS) research is currently unclear. To assist IS
research in understanding how to operationalize LLMs, we propose a Text
Analytics for Information Systems Research (TAISR) framework. Our proposed
framework provides detailed recommendations grounded in IS and LLM literature
on how to conduct meaningful text-based IS research. We conducted three case
studies in business intelligence using our TAISR framework to demonstrate its
application across several IS research contexts. We also outline potential
challenges and limitations in adopting LLMs for IS. By offering a systematic
approach and evidence of its utility, our TAISR framework contributes to future
IS research streams looking to incorporate powerful LLMs for text analytics.
</p></li>
</ul>

<h3>Title: Structured Packing in LLM Training Improves Long Context Utilization. (arXiv:2312.17296v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17296">http://arxiv.org/abs/2312.17296</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17296]] Structured Packing in LLM Training Improves Long Context Utilization(http://arxiv.org/abs/2312.17296)</code></li>
<li>Summary: <p>Recent advances in long-context Large Language Models (LCLMs) have generated
significant interest, especially in applications such as querying scientific
research papers. However, their potential is often limited by inadequate
context utilization. We identify the absence of long-range semantic
dependencies in typical training data as a primary hindrance. To address this,
we delve into the benefits of frequently incorporating related documents into
training inputs. Using the inherent directory structure of code data as a
source of training examples, we demonstrate improvements in perplexity, even
for tasks unrelated to coding. Building on these findings, but with a broader
focus, we introduce Structured Packing for Long Context (SPLiCe). SPLiCe is an
innovative method for creating training examples by using a retrieval method to
collate the most mutually relevant documents into a single training context.
Our results indicate that \method{} enhances model performance and can be used
to train large models to utilize long contexts better. We validate our results
by training a large $3$B model, showing both perplexity improvements and better
long-context performance on downstream tasks.
</p></li>
</ul>

<h3>Title: AQUALLM: Audio Question Answering Data Generation Using Large Language Models. (arXiv:2312.17343v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17343">http://arxiv.org/abs/2312.17343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17343]] AQUALLM: Audio Question Answering Data Generation Using Large Language Models(http://arxiv.org/abs/2312.17343)</code></li>
<li>Summary: <p>Audio Question Answering (AQA) constitutes a pivotal task in which machines
analyze both audio signals and natural language questions to produce precise
natural language answers. The significance of possessing high-quality, diverse,
and extensive AQA datasets cannot be overstated when aiming for the precision
of an AQA system. While there has been notable focus on developing accurate and
efficient AQA models, the creation of high-quality, diverse, and extensive
datasets for the specific task at hand has not garnered considerable attention.
To address this challenge, this work makes several contributions. We introduce
a scalable AQA data generation pipeline, denoted as the AQUALLM framework,
which relies on Large Language Models (LLMs). This framework utilizes existing
audio-caption annotations and incorporates state-of-the-art LLMs to generate
expansive, high-quality AQA datasets. Additionally, we present three extensive
and high-quality benchmark datasets for AQA, contributing significantly to the
progression of AQA research. AQA models trained on the proposed datasets set
superior benchmarks compared to the existing state-of-the-art. Moreover, models
trained on our datasets demonstrate enhanced generalizability when compared to
models trained using human-annotated AQA data. Code and datasets will be
accessible on GitHub~\footnote{\url{https://github.com/swarupbehera/AQUALLM}}.
</p></li>
</ul>

<h3>Title: Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters. (arXiv:2312.17476v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17476">http://arxiv.org/abs/2312.17476</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17476]] Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters(http://arxiv.org/abs/2312.17476)</code></li>
<li>Summary: <p>The advancement of Large Language Models (LLMs) has led to their widespread
use across a broad spectrum of tasks including decision making. Prior studies
have compared the decision making abilities of LLMs with those of humans from a
psychological perspective. However, these studies have not always properly
accounted for the sensitivity of LLMs' behavior to hyperparameters and
variations in the prompt. In this study, we examine LLMs' performance on the
Horizon decision making task studied by Binz and Schulz (2023) analyzing how
LLMs respond to variations in prompts and hyperparameters. By experimenting on
three OpenAI language models possessing different capabilities, we observe that
the decision making abilities fluctuate based on the input prompts and
temperature settings. Contrary to previous findings language models display a
human-like exploration exploitation tradeoff after simple adjustments to the
prompt.
</p></li>
</ul>

<h3>Title: Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models through Intervention without Tuning. (arXiv:2312.17484v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17484">http://arxiv.org/abs/2312.17484</a></li>
<li>Code URL: <a href="https://github.com/jongjyh/trfr">https://github.com/jongjyh/trfr</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17484]] Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models through Intervention without Tuning(http://arxiv.org/abs/2312.17484)</code></li>
<li>Summary: <p>Despite the great success of large language models (LLMs) in various tasks,
they suffer from generating hallucinations. We introduce Truth Forest, a method
that enhances truthfulness in LLMs by uncovering hidden truth representations
using multi-dimensional orthogonal probes. Specifically, it creates multiple
orthogonal bases for modeling truth by incorporating orthogonal constraints
into the probes. Moreover, we introduce Random Peek, a systematic technique
considering an extended range of positions within the sequence, reducing the
gap between discerning and generating truth features in LLMs. By employing this
approach, we improved the truthfulness of Llama-2-7B from 40.8\% to 74.5\% on
TruthfulQA. Likewise, significant improvements are observed in fine-tuned
models. We conducted a thorough analysis of truth features using probes. Our
visualization results show that orthogonal probes capture complementary
truth-related features, forming well-defined clusters that reveal the inherent
structure of the dataset. Code: \url{https://github.com/jongjyh/trfr}
</p></li>
</ul>

<h3>Title: Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game. (arXiv:2312.17515v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17515">http://arxiv.org/abs/2312.17515</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17515]] Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game(http://arxiv.org/abs/2312.17515)</code></li>
<li>Summary: <p>Multi-agent collaboration with Large Language Models (LLMs) demonstrates
proficiency in basic tasks, yet its efficiency in more complex scenarios
remains unexplored. In gaming environments, these agents often face situations
without established coordination protocols, requiring them to make intelligent
inferences about teammates from limited data. This problem motivates the area
of ad hoc teamwork, in which an agent may potentially cooperate with a variety
of teammates to achieve a shared goal. Our study focuses on the ad hoc teamwork
problem where the agent operates in an environment driven by natural language.
Our findings reveal the potential of LLM agents in team collaboration,
highlighting issues related to hallucinations in communication. To address this
issue, we develop CodeAct, a general agent that equips LLM with enhanced memory
and code-driven reasoning, enabling the repurposing of partial information for
rapid adaptation to new teammates.
</p></li>
</ul>

<h3>Title: Overview of the PromptCBLUE Shared Task in CHIP2023. (arXiv:2312.17522v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17522">http://arxiv.org/abs/2312.17522</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17522]] Overview of the PromptCBLUE Shared Task in CHIP2023(http://arxiv.org/abs/2312.17522)</code></li>
<li>Summary: <p>This paper presents an overview of the PromptCBLUE shared task
(<a href="http://cips-chip.org.cn/2023/eval1">this http URL</a>) held in the CHIP-2023 Conference. This
shared task reformualtes the CBLUE benchmark, and provide a good testbed for
Chinese open-domain or medical-domain large language models (LLMs) in general
medical natural language processing. Two different tracks are held: (a) prompt
tuning track, investigating the multitask prompt tuning of LLMs, (b) probing
the in-context learning capabilities of open-sourced LLMs. Many teams from both
the industry and academia participated in the shared tasks, and the top teams
achieved amazing test results. This paper describes the tasks, the datasets,
evaluation metrics, and the top systems for both tasks. Finally, the paper
summarizes the techniques and results of the evaluation of the various
approaches explored by the participating teams.
</p></li>
</ul>

<h3>Title: Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception. (arXiv:2312.17532v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17532">http://arxiv.org/abs/2312.17532</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17532]] Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception(http://arxiv.org/abs/2312.17532)</code></li>
<li>Summary: <p>Quantities are distinct and critical components of texts that characterize
the magnitude properties of entities, providing a precise perspective for the
understanding of natural language, especially for reasoning tasks. In recent
years, there has been a flurry of research on reasoning tasks based on large
language models (LLMs), most of which solely focus on numerical values,
neglecting the dimensional concept of quantities with units despite its
importance. We argue that the concept of dimension is essential for precisely
understanding quantities and of great significance for LLMs to perform
quantitative reasoning. However, the lack of dimension knowledge and
quantity-related benchmarks has resulted in low performance of LLMs. Hence, we
present a framework to enhance the quantitative reasoning ability of language
models based on dimension perception. We first construct a dimensional unit
knowledge base (DimUnitKB) to address the knowledge gap in this area. We
propose a benchmark DimEval consisting of seven tasks of three categories to
probe and enhance the dimension perception skills of LLMs. To evaluate the
effectiveness of our methods, we propose a quantitative reasoning task and
conduct experiments. The experimental results show that our dimension
perception method dramatically improves accuracy (43.55%-&gt;50.67%) on
quantitative reasoning tasks compared to GPT-4.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Semantic segmentation of SEM images of lower bainitic and tempered martensitic steels. (arXiv:2312.17251v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17251">http://arxiv.org/abs/2312.17251</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17251]] Semantic segmentation of SEM images of lower bainitic and tempered martensitic steels(http://arxiv.org/abs/2312.17251)</code></li>
<li>Summary: <p>This study employs deep learning techniques to segment scanning electron
microscope images, enabling a quantitative analysis of carbide precipitates in
lower bainite and tempered martensite steels with comparable strength.
Following segmentation, carbides are investigated, and their volume percentage,
size distribution, and orientations are probed within the image dataset. Our
findings reveal that lower bainite and tempered martensite exhibit comparable
volume percentages of carbides, albeit with a more uniform distribution of
carbides in tempered martensite. Carbides in lower bainite demonstrate a
tendency for better alignment than those in tempered martensite, aligning with
the observations of other researchers. However, both microstructures display a
scattered carbide orientation, devoid of any discernible pattern. Comparative
analysis of aspect ratios and sizes of carbides in lower bainite and tempered
martensite unveils striking similarities. The deep learning model achieves an
impressive pixelwise accuracy of 98.0% in classifying carbide/iron matrix at
the individual pixel level. The semantic segmentation derived from deep
learning extends its applicability to the analysis of secondary phases in
various materials, offering a time-efficient, versatile AI-powered workflow for
quantitative microstructure analysis.
</p></li>
</ul>

<h3>Title: Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision. (arXiv:2312.17285v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17285">http://arxiv.org/abs/2312.17285</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17285]] Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision(http://arxiv.org/abs/2312.17285)</code></li>
<li>Summary: <p>Understanding intermediate representations of the concepts learned by deep
learning classifiers is indispensable for interpreting general model behaviors.
Existing approaches to reveal learned concepts often rely on human supervision,
such as pre-defined concept sets or segmentation processes. In this paper, we
propose a novel unsupervised method for discovering distributed representations
of concepts by selecting a principal subset of neurons. Our empirical findings
demonstrate that instances with similar neuron activation states tend to share
coherent concepts. Based on the observations, the proposed method selects
principal neurons that construct an interpretable region, namely a Relaxed
Decision Region (RDR), encompassing instances with coherent concepts in the
feature space. It can be utilized to identify unlabeled subclasses within data
and to detect the causes of misclassifications. Furthermore, the applicability
of our method across various layers discloses distinct distributed
representations over the layers, which provides deeper insights into the
internal mechanisms of the deep learning model.
</p></li>
</ul>

<h3>Title: Tracking with Human-Intent Reasoning. (arXiv:2312.17448v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17448">http://arxiv.org/abs/2312.17448</a></li>
<li>Code URL: <a href="https://github.com/jiawen-zhu/trackgpt">https://github.com/jiawen-zhu/trackgpt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17448]] Tracking with Human-Intent Reasoning(http://arxiv.org/abs/2312.17448)</code></li>
<li>Summary: <p>Advances in perception modeling have significantly improved the performance
of object tracking. However, the current methods for specifying the target
object in the initial frame are either by 1) using a box or mask template, or
by 2) providing an explicit language description. These manners are cumbersome
and do not allow the tracker to have self-reasoning ability. Therefore, this
work proposes a new tracking task -- Instruction Tracking, which involves
providing implicit tracking instructions that require the trackers to perform
tracking automatically in video frames. To achieve this, we investigate the
integration of knowledge and reasoning capabilities from a Large
Vision-Language Model (LVLM) for object tracking. Specifically, we propose a
tracker called TrackGPT, which is capable of performing complex reasoning-based
tracking. TrackGPT first uses LVLM to understand tracking instructions and
condense the cues of what target to track into referring embeddings. The
perception component then generates the tracking results based on the
embeddings. To evaluate the performance of TrackGPT, we construct an
instruction tracking benchmark called InsTrack, which contains over one
thousand instruction-video pairs for instruction tuning and evaluation.
Experiments show that TrackGPT achieves competitive performance on referring
video object segmentation benchmarks, such as getting a new state-of the-art
performance of 66.5 $\mathcal{J}\&amp;\mathcal{F}$ on Refer-DAVIS. It also
demonstrates a superior performance of instruction tracking under new
evaluation protocols. The code and models are available at
\href{https://github.com/jiawen-zhu/TrackGPT}{https://github.com/jiawen-zhu/TrackGPT}.
</p></li>
</ul>

<h3>Title: Benchmarking the CoW with the TopCoW Challenge: Topology-Aware Anatomical Segmentation of the Circle of Willis for CTA and MRA. (arXiv:2312.17670v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17670">http://arxiv.org/abs/2312.17670</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17670]] Benchmarking the CoW with the TopCoW Challenge: Topology-Aware Anatomical Segmentation of the Circle of Willis for CTA and MRA(http://arxiv.org/abs/2312.17670)</code></li>
<li>Summary: <p>The Circle of Willis (CoW) is an important network of arteries connecting
major circulations of the brain. Its vascular architecture is believed to
affect the risk, severity, and clinical outcome of serious neuro-vascular
diseases. However, characterizing the highly variable CoW anatomy is still a
manual and time-consuming expert task. The CoW is usually imaged by two
angiographic imaging modalities, magnetic resonance angiography (MRA) and
computed tomography angiography (CTA), but there exist limited public datasets
with annotations on CoW anatomy, especially for CTA. Therefore we organized the
TopCoW Challenge in 2023 with the release of an annotated CoW dataset and
invited submissions worldwide for the CoW segmentation task, which attracted
over 140 registered participants from four continents. TopCoW dataset was the
first public dataset with voxel-level annotations for CoW's 13 vessel
components, made possible by virtual-reality (VR) technology. It was also the
first dataset with paired MRA and CTA from the same patients. TopCoW challenge
aimed to tackle the CoW characterization problem as a multiclass anatomical
segmentation task with an emphasis on topological metrics. The top performing
teams managed to segment many CoW components to Dice scores around 90%, but
with lower scores for communicating arteries and rare variants. There were also
topological mistakes for predictions with high Dice scores. Additional
topological analysis revealed further areas for improvement in detecting
certain CoW components and matching CoW variant's topology accurately. TopCoW
represented a first attempt at benchmarking the CoW anatomical segmentation
task for MRA and CTA, both morphologically and topologically.
</p></li>
</ul>

<h3>Title: Learning Vision from Models Rivals Learning Vision from Data. (arXiv:2312.17742v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17742">http://arxiv.org/abs/2312.17742</a></li>
<li>Code URL: <a href="https://github.com/google-research/syn-rep-learn">https://github.com/google-research/syn-rep-learn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17742]] Learning Vision from Models Rivals Learning Vision from Data(http://arxiv.org/abs/2312.17742)</code></li>
<li>Summary: <p>We introduce SynCLR, a novel approach for learning visual representations
exclusively from synthetic images and synthetic captions, without any real
data. We synthesize a large dataset of image captions using LLMs, then use an
off-the-shelf text-to-image model to generate multiple images corresponding to
each synthetic caption. We perform visual representation learning on these
synthetic images via contrastive learning, treating images sharing the same
caption as positive pairs. The resulting representations transfer well to many
downstream tasks, competing favorably with other general-purpose visual
representation learners such as CLIP and DINO v2 in image classification tasks.
Furthermore, in dense prediction tasks such as semantic segmentation, SynCLR
outperforms previous self-supervised methods by a significant margin, e.g.,
improving over MAE and iBOT by 6.2 and 4.3 mIoU on ADE20k for ViT-B/16.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
