<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Hardening and Speeding Up Zero-interaction Pairing and Authentication. (arXiv:2306.04458v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04458">http://arxiv.org/abs/2306.04458</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04458] Hardening and Speeding Up Zero-interaction Pairing and Authentication](http://arxiv.org/abs/2306.04458) #secure</code></li>
<li>Summary: <p>Establishing and maintaining secure communications in the Internet of Things
(IoT) is vital to protect smart devices. Zero-interaction pairing (ZIP) and
zero-interaction authentication (ZIA) enable IoT devices to establish and
maintain secure communications without user interaction by utilizing devices'
ambient context, e.g., audio. For autonomous operation, ZIP and ZIA require the
context to have enough entropy to resist attacks and complete in a timely
manner. Despite the low-entropy context being the norm, like inside an
unoccupied room, the research community has yet to come up with ZIP and ZIA
schemes operating under such conditions. We propose HARDZIPA, a novel approach
that turns commodity IoT actuators into injecting devices, generating
high-entropy context. Here, we combine the capability of IoT actuators to
impact the environment, e.g., emitting a sound, with a pseudorandom number
generator (PRNG) featured by many actuators to craft hard-to-predict context
stimuli. To demonstrate the feasibility of HARDZIPA, we implement it on
off-the-shelf IoT actuators, i.e., smart speakers, lights, and humidifiers. We
comprehensively evaluate HARDZIPA, collecting over 80 hours of various context
data in real-world scenarios. Our results show that HARDZIPA is able to thwart
advanced active attacks on ZIP and ZIA schemes, while doubling the amount of
context entropy in many cases, which allows two times faster pairing and
authentication.
</p></li>
</ul>

<h3>Title: Differentially Private Selection from Secure Distributed Computin. (arXiv:2306.04564v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04564">http://arxiv.org/abs/2306.04564</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04564] Differentially Private Selection from Secure Distributed Computin](http://arxiv.org/abs/2306.04564) #secure</code></li>
<li>Summary: <p>Given a collection of vectors $x^{(1)},\dots,x^{(n)} \in {0,1}^d$, the
selection problem asks to report the index of an "approximately largest" entry
in $x=\sum_{j=1}^n x^{(j)}$. Selection abstracts a host of problems--in machine
learning it can be used for hyperparameter tuning, feature selection, or to
model empirical risk minimization. We study selection under differential
privacy, where a released index guarantees privacy for each vectors. Though
selection can be solved with an excellent utility guarantee in the central
model of differential privacy, the distributed setting lacks solutions.
Specifically, strong privacy guarantees with high utility are offered in high
trust settings, but not in low trust settings. For example, in the popular
shuffle model of distributed differential privacy, there are strong lower
bounds suggesting that the utility of the central model cannot be obtained. In
this paper we design a protocol for differentially private selection in a trust
setting similar to the shuffle model--with the crucial difference that our
protocol tolerates corrupted servers while maintaining privacy. Our protocol
uses techniques from secure multi-party computation (MPC) to implement a
protocol that: (i) has utility on par with the best mechanisms in the central
model, (ii) scales to large, distributed collections of high-dimensional
vectors, and (iii) uses $k\geq 3$ servers that collaborate to compute the
result, where the differential privacy holds assuming an honest majority. Since
general-purpose MPC techniques are not sufficiently scalable, we propose a
novel application of integer secret sharing, and evaluate the utility and
efficiency of our protocol theoretically and empirically. Our protocol is the
first to demonstrate that large-scale differentially private selection is
possible in a distributed setting.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: NFT.mine: An xDeepFM-based Recommender System for Non-fungible Token (NFT) Buyers. (arXiv:2306.03942v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03942">http://arxiv.org/abs/2306.03942</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03942] NFT](http://arxiv.org/abs/2306.03942) #security</code></li>
<li>Summary: <p>Non-fungible token (NFT) is a tradable unit of data stored on the blockchain
which can be associated with some digital asset as a certification of
ownership. The past several years have witnessed the exponential growth of the
NFT market. In 2021, the NFT market reached its peak with more than $40 billion
trades. Despite the booming NFT market, most NFT-related studies focus on its
technical aspect, such as standards, protocols, and security, while our study
aims at developing a pioneering recommender system for NFT buyers. In this
paper, we introduce an extreme deep factorization machine (xDeepFM)-based
recommender system, NFT.mine, which achieves real-time data collection, data
cleaning, feature extraction, training, and inference. We used data from
OpenSea, the most influential NFT trading platform, to testify the performance
of NFT.mine. As a result, experiments showed that compared to traditional
models such as logistic regression, naive Bayes, random forest, etc., NFT.mine
outperforms them with higher AUC and lower cross entropy loss and outputs
personalized recommendations for NFT buyers.
</p></li>
</ul>

<h3>Title: High-Performance Caching of Homomorphic Encryption for Cloud Databases. (arXiv:2306.04227v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04227">http://arxiv.org/abs/2306.04227</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04227] High-Performance Caching of Homomorphic Encryption for Cloud Databases](http://arxiv.org/abs/2306.04227) #security</code></li>
<li>Summary: <p>While homomorphic encryption (HE) has garnered significant research interest
in cloud-based outsourced databases due to its algebraic properties over
ciphertexts, the computational overhead associated with HE has hindered its
widespread adoption in production database systems. Recently, a caching
technique called Radix-based additive caching of homomorphic encryption (Rache)
was proposed in SIGMOD'23. The primary objective of this paper is to address
the performance overhead resulting from the expensive randomization process in
Rache. To achieve this, we propose a novel encryption algorithm called $ASEnc$,
which replaces the computationally intensive full scan of radixes with the
caching of a polynomial number of radix-powers during an offline stage. This
design significantly reduces the performance impact caused by randomization.
Furthermore, this paper aims to extend Rache's capabilities to support
floating-point numbers. To accomplish this, we introduce a new encryption
algorithm named $FSEnc$, leveraging efficient constant multiplication available
in state-of-the-art fully homomorphic encryption (FHE) schemes. Notably,
$FSEnc$ offers the flexibility to cache the coefficients instead of the radixes
themselves, which may result in a large number of cached ciphertexts. However,
we manage this efficiently by streaming the dynamically cached ciphertexts
through a vector of circular buffers. We demonstrate that both encryption
algorithms guarantee semantic security (IND-CPA). To validate their
performance, we implement both algorithms as loadable functions in MySQL 8.0
and deploy the system prototype on a 96-core server hosted in the Chameleon
Cloud. Experimental results showcase that $ASEnc$ outperforms Rache by
2.3--3.3$\times$, while $FSEnc$ surpasses the state-of-the-art floating-point
FHE CKKS by 1.8--5.6$\times$.
</p></li>
</ul>

<h3>Title: Development and Analysis of P2SCP: A Paradigm for Penetration Testing of Systems that Cannot be Subjected to the Risk of Penetration Testing. (arXiv:2306.04279v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04279">http://arxiv.org/abs/2306.04279</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04279] Development and Analysis of P2SCP: A Paradigm for Penetration Testing of Systems that Cannot be Subjected to the Risk of Penetration Testing](http://arxiv.org/abs/2306.04279) #security</code></li>
<li>Summary: <p>Penetration testing increases the security of systems through tasking testers
to 'think like the adversary' and attempt to find the ways that an attacker
would break into the system. For many systems, this can be conducted in a safe
and controlled way; however, some systems are so critical to human life and
safety that the risk of their failure or disablement due to active penetration
testing cannot be assumed. These systems are also critical to evaluate the
security of, to prevent attackers from disabling them or causing their
maloperation; however, this must be done in a manner that doesn't risk the very
malady that testing seeks to avoid through the testing process itself. This
paper presents P2SCP, a paradigm for penetration testing of systems that cannot
be subjected to the risk of penetration testing. It discusses how data
collection, the creation of digital twins and cousins and evaluative analysis
can be utilized to conduct virtual penetration tests on critical infrastructure
systems. This proposed paradigm is analyzed through the use of several case
studies.
</p></li>
</ul>

<h3>Title: Development of a Multi-purpose Fuzzer to Perform Assessment as Input to a Cybersecurity Risk Assessment and Analysis System. (arXiv:2306.04284v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04284">http://arxiv.org/abs/2306.04284</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04284] Development of a Multi-purpose Fuzzer to Perform Assessment as Input to a Cybersecurity Risk Assessment and Analysis System](http://arxiv.org/abs/2306.04284) #security</code></li>
<li>Summary: <p>Fuzzing is utilized for testing software and systems for cybersecurity risk
via the automated adaptation of inputs. It facilitates the identification of
software bugs and misconfigurations that may create vulnerabilities, cause
abnormal operations or result in systems' failure. While many fuzzers have been
purpose-developed for testing specific systems, this paper proposes a
generalized fuzzer that provides a specific capability for testing software and
cyber-physical systems which utilize configuration files. While this fuzzer
facilitates the detection of system and software defects and vulnerabilities,
it also facilitates the determination of the impact of settings on device
operations. This later capability facilitates the modeling of the devices in a
cybersecurity risk assessment and analysis system. This paper describes and
assesses the performance of the proposed fuzzer technology. It also details how
the fuzzer operates as part of the broader cybersecurity risk assessment and
analysis system.
</p></li>
</ul>

<h3>Title: Security Analysis of WG-7 Lightweight Stream Cipher against Cube Attack. (arXiv:2306.04352v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04352">http://arxiv.org/abs/2306.04352</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04352] Security Analysis of WG-7 Lightweight Stream Cipher against Cube Attack](http://arxiv.org/abs/2306.04352) #security</code></li>
<li>Summary: <p>Welch--Gong (WG) is a hardware-oriented LFSR-based stream cipher. WG-7 is a
version of the eStream submission Welch--Gong, used for RFID encryption and
authentication purposes. It offers 80-bit cryptographic security. In modern
days, almost all ciphers achieve the security by exploiting the nonlinear
feedback structure. In this paper, we investigate the security of the nonlinear
feedback-based initialization phase of the WG-7 stream cipher using the
conventional bit-based division property of cube attack, by considering the
cipher in a non-blackbox polynomial setting. In our work, we mount the cube
attack using mixed-integer-linear-programming(MILP) models. The results of our
attack enable us to recover the secret key of WG-7 after 20 rounds of
initialization utilizing $2^{10}$ keystream bits in $2^{73}$ time. We show that
our proposed attack takes significantly lower data complexity. To the best of
our knowledge, our attack is the first one that investigates the security of
the nonlinear feedback-based initialization phase of WG-7 cipher.
</p></li>
</ul>

<h3>Title: Sustainable Adaptive Security. (arXiv:2306.04481v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04481">http://arxiv.org/abs/2306.04481</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04481] Sustainable Adaptive Security](http://arxiv.org/abs/2306.04481) #security</code></li>
<li>Summary: <p>With software systems permeating our lives, we are entitled to expect that
such systems are secure by design, and that such security endures throughout
the use of these systems and their subsequent evolution. Although adaptive
security systems have been proposed to continuously protect assets from harm,
they can only mitigate threats arising from changes foreseen at design time. In
this paper, we propose the notion of Sustainable Adaptive Security (SAS) which
reflects such enduring protection by augmenting adaptive security systems with
the capability of mitigating newly discovered threats. To achieve this
objective, a SAS system should be designed by combining automation (e.g., to
discover and mitigate security threats) and human intervention (e.g., to
resolve uncertainties during threat discovery and mitigation). In this paper,
we use a smart home example to showcase how we can engineer the activities of
the MAPE (Monitor, Analysis, Planning, and Execution) loop of systems
satisfying sustainable adaptive security. We suggest that using anomaly
detection together with abductive reasoning can help discover new threats and
guide the evolution of security requirements and controls. We also exemplify
situations when humans can be involved in the execution of the activities of
the MAPE loop and discuss the requirements to engineer human interventions.
</p></li>
</ul>

<h3>Title: The Effect of Length on Key Fingerprint Verification Security and Usability. (arXiv:2306.04574v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04574">http://arxiv.org/abs/2306.04574</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04574] The Effect of Length on Key Fingerprint Verification Security and Usability](http://arxiv.org/abs/2306.04574) #security</code></li>
<li>Summary: <p>In applications such as end-to-end encrypted instant messaging, secure email,
and device pairing, users need to compare key fingerprints to detect
impersonation and adversary-in-the-middle attacks. Key fingerprints are usually
computed as truncated hashes of each party's view of the channel keys, encoded
as an alphanumeric or numeric string, and compared out-of-band, e.g. manually,
to detect any inconsistencies. Previous work has extensively studied the
usability of various verification strategies and encoding formats, however, the
exact effect of key fingerprint length on the security and usability of key
fingerprint verification has not been rigorously investigated. We present a
162-participant study on the effect of numeric key fingerprint length on
comparison time and error rate. While the results confirm some widely-held
intuitions such as general comparison times and errors increasing significantly
with length, a closer look reveals interesting nuances. The significant rise in
comparison time only occurs when highly similar fingerprints are compared, and
comparison time remains relatively constant otherwise. On errors, our results
clearly distinguish between security non-critical errors that remain low
irrespective of length and security critical errors that significantly rise,
especially at higher fingerprint lengths. A noteworthy implication of this
latter result is that Signal/WhatsApp key fingerprints provide a considerably
lower level of security than usually assumed.
</p></li>
</ul>

<h3>Title: Prefix Siphoning: Exploiting LSM-Tree Range Filters For Information Disclosure (Full Version). (arXiv:2306.04602v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04602">http://arxiv.org/abs/2306.04602</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04602] Prefix Siphoning: Exploiting LSM-Tree Range Filters For Information Disclosure (Full Version)](http://arxiv.org/abs/2306.04602) #security</code></li>
<li>Summary: <p>Key-value stores typically leave access control to the systems for which they
act as storage engines. Unfortunately, attackers may circumvent such read
access controls via timing attacks on the key-value store, which use
differences in query response times to glean information about stored data.
</p></li>
</ul>

<p>To date, key-value store timing attacks have aimed to disclose stored values
and have exploited external mechanisms that can be disabled for protection. In
this paper, we point out that key disclosure is also a security threat -- and
demonstrate key disclosure timing attacks that exploit mechanisms of the
key-value store itself.
</p>
<p>We target LSM-tree based key-value stores utilizing range filters, which have
been recently proposed to optimize LSM-tree range queries. We analyze the
impact of the range filters SuRF and prefix Bloom filter on LSM-trees through a
security lens, and show that they enable a key disclosure timing attack, which
we call prefix siphoning. Prefix siphoning successfully leverages benign
queries for non-present keys to identify prefixes of actual keys -- and in some
cases, full keys -- in scenarios where brute force searching for keys (via
exhaustive enumeration or random guesses) is infeasible.
</p>

<h2>privacy</h2>
<h3>Title: SF-FSDA: Source-Free Few-Shot Domain Adaptive Object Detection with Efficient Labeled Data Factory. (arXiv:2306.04385v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04385">http://arxiv.org/abs/2306.04385</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04385] SF-FSDA: Source-Free Few-Shot Domain Adaptive Object Detection with Efficient Labeled Data Factory](http://arxiv.org/abs/2306.04385) #privacy</code></li>
<li>Summary: <p>Domain adaptive object detection aims to leverage the knowledge learned from
a labeled source domain to improve the performance on an unlabeled target
domain. Prior works typically require the access to the source domain data for
adaptation, and the availability of sufficient data on the target domain.
However, these assumptions may not hold due to data privacy and rare data
collection. In this paper, we propose and investigate a more practical and
challenging domain adaptive object detection problem under both source-free and
few-shot conditions, named as SF-FSDA. To overcome this problem, we develop an
efficient labeled data factory based approach. Without accessing the source
domain, the data factory renders i) infinite amount of synthesized
target-domain like images, under the guidance of the few-shot image samples and
text description from the target domain; ii) corresponding bounding box and
category annotations, only demanding minimum human effort, i.e., a few manually
labeled examples. On the one hand, the synthesized images mitigate the
knowledge insufficiency brought by the few-shot condition. On the other hand,
compared to the popular pseudo-label technique, the generated annotations from
data factory not only get rid of the reliance on the source pretrained object
detection model, but also alleviate the unavoidably pseudo-label noise due to
domain shift and source-free condition. The generated dataset is further
utilized to adapt the source pretrained object detection model, realizing the
robust object detection under SF-FSDA. The experiments on different settings
showcase that our proposed approach outperforms other state-of-the-art methods
on SF-FSDA problem. Our codes and models will be made publicly available.
</p></li>
</ul>

<h3>Title: Point Cloud Video Anomaly Detection Based on Point Spatio-Temporal Auto-Encoder. (arXiv:2306.04466v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04466">http://arxiv.org/abs/2306.04466</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04466] Point Cloud Video Anomaly Detection Based on Point Spatio-Temporal Auto-Encoder](http://arxiv.org/abs/2306.04466) #privacy</code></li>
<li>Summary: <p>Video anomaly detection has great potential in enhancing safety in the
production and monitoring of crucial areas. Currently, most video anomaly
detection methods are based on RGB modality, but its redundant semantic
information may breach the privacy of residents or patients. The 3D data
obtained by depth camera and LiDAR can accurately locate anomalous events in 3D
space while preserving human posture and motion information. Identifying
individuals through the point cloud is difficult due to its sparsity, which
protects personal privacy. In this study, we propose Point Spatio-Temporal
Auto-Encoder (PSTAE), an autoencoder framework that uses point cloud videos as
input to detect anomalies in point cloud videos. We introduce PSTOp and
PSTTransOp to maintain spatial geometric and temporal motion information in
point cloud videos. To measure the reconstruction loss of the proposed
autoencoder framework, we propose a reconstruction loss measurement strategy
based on a shallow feature extractor. Experimental results on the TIMo dataset
show that our method outperforms currently representative depth modality-based
methods in terms of AUROC and has superior performance in detecting Medical
Issue anomalies. These results suggest the potential of point cloud modality in
video anomaly detection. Our method sets a new state-of-the-art (SOTA) on the
TIMo dataset.
</p></li>
</ul>

<h3>Title: PILLAR: How to make semi-private learning more effective. (arXiv:2306.03962v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03962">http://arxiv.org/abs/2306.03962</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03962] PILLAR: How to make semi-private learning more effective](http://arxiv.org/abs/2306.03962) #privacy</code></li>
<li>Summary: <p>In Semi-Supervised Semi-Private (SP) learning, the learner has access to both
public unlabelled and private labelled data. We propose a computationally
efficient algorithm that, under mild assumptions on the data, provably achieves
significantly lower private labelled sample complexity and can be efficiently
run on real-world datasets. For this purpose, we leverage the features
extracted by networks pre-trained on public (labelled or unlabelled) data,
whose distribution can significantly differ from the one on which SP learning
is performed. To validate its empirical effectiveness, we propose a wide
variety of experiments under tight privacy constraints ($\epsilon = 0.1$) and
with a focus on low-data regimes. In all of these settings, our algorithm
exhibits significantly improved performance over available baselines that use
similar amounts of public data.
</p></li>
</ul>

<h3>Title: Is Homomorphic Encryption Feasible for Smart Mobility?. (arXiv:2306.04195v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04195">http://arxiv.org/abs/2306.04195</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04195] Is Homomorphic Encryption Feasible for Smart Mobility?](http://arxiv.org/abs/2306.04195) #privacy</code></li>
<li>Summary: <p>Smart mobility is a promising approach to meet urban transport needs in an
environmentally and and user-friendly way. Smart mobility computes itineraries
with multiple means of transportation, e.g., trams, rental bikes or electric
scooters, according to customer preferences. A mobility platform cares for
reservations, connecting transports, invoicing and billing. This requires
sharing sensible personal data with multiple parties, and puts data privacy at
risk. In this paper, we investigate if fully homomorphic encryption (FHE) can
be applied in practice to mitigate such privacy issues. FHE allows to calculate
on encrypted data, without having to decrypt it first. We implemented three
typical distributed computations in a smart mobility scenario with SEAL, a
recent programming library for FHE. With this implementation, we have measured
memory consumption and execution times for three variants of distributed
transactions, that are representative for a wide range of smart mobility tasks.
Our evaluation shows, that FHE is indeed applicable to smart mobility: With
today's processing capabilities, state-of-the-art FHE increases a smart
mobility transaction by about 100 milliseconds and less than 3 microcents.
</p></li>
</ul>

<h3>Title: A Threat Model for Soft Privacy on Smart Cars. (arXiv:2306.04222v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04222">http://arxiv.org/abs/2306.04222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04222] A Threat Model for Soft Privacy on Smart Cars](http://arxiv.org/abs/2306.04222) #privacy</code></li>
<li>Summary: <p>Modern cars are getting so computerised that ENISA's phrase "smart cars" is a
perfect fit. The amount of personal data that they process is very large and,
yet, increasing. Hence, the need to address citizens' privacy while they drive
and, correspondingly, the importance of privacy threat modelling (in support of
a respective risk assessment, such as through a Data Protection Impact
Assessment). This paper addresses privacy threats by advancing a general
modelling methodology and by demonstrating it specifically on soft privacy,
which ensures citizens' full control on their personal data. By considering all
relevant threat agents, the paper applies the methodology to the specific
automotive domain while keeping threats at the same level of detail as ENISA's.
The main result beside the modelling methodology consists of both
domain-independent and automotive domain-dependent soft privacy threats. While
cybersecurity has been vastly threat-modelled so far, this paper extends the
literature with a threat model for soft privacy on smart cars, producing 17
domain-independent threats that, associated with 41 domain-specific assets,
shape a novel set of domain-dependent threats in automotive.
</p></li>
</ul>

<h3>Title: CaptAinGlove: Capacitive and Inertial Fusion-Based Glove for Real-Time on Edge Hand Gesture Recognition for Drone Control. (arXiv:2306.04319v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04319">http://arxiv.org/abs/2306.04319</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04319] CaptAinGlove: Capacitive and Inertial Fusion-Based Glove for Real-Time on Edge Hand Gesture Recognition for Drone Control](http://arxiv.org/abs/2306.04319) #privacy</code></li>
<li>Summary: <p>We present CaptAinGlove, a textile-based, low-power (1.15Watts),
privacy-conscious, real-time on-the-edge (RTE) glove-based solution with a tiny
memory footprint (2MB), designed to recognize hand gestures used for drone
control. We employ lightweight convolutional neural networks as the backbone
models and a hierarchical multimodal fusion to reduce power consumption and
improve accuracy. The system yields an F1-score of 80% for the offline
evaluation of nine classes; eight hand gesture commands and null activity. For
the RTE, we obtained an F1-score of 67% (one user).
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: CFDP: Common Frequency Domain Pruning. (arXiv:2306.04147v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04147">http://arxiv.org/abs/2306.04147</a></li>
<li>Code URL: <a href="https://github.com/skhaki18/cfdp">https://github.com/skhaki18/cfdp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04147] CFDP: Common Frequency Domain Pruning](http://arxiv.org/abs/2306.04147) #attack</code></li>
<li>Summary: <p>As the saying goes, sometimes less is more -- and when it comes to neural
networks, that couldn't be more true. Enter pruning, the art of selectively
trimming away unnecessary parts of a network to create a more streamlined,
efficient architecture. In this paper, we introduce a novel end-to-end pipeline
for model pruning via the frequency domain. This work aims to shed light on the
interoperability of intermediate model outputs and their significance beyond
the spatial domain. Our method, dubbed Common Frequency Domain Pruning (CFDP)
aims to extrapolate common frequency characteristics defined over the feature
maps to rank the individual channels of a layer based on their level of
importance in learning the representation. By harnessing the power of CFDP, we
have achieved state-of-the-art results on CIFAR-10 with GoogLeNet reaching an
accuracy of 95.25%, that is, +0.2% from the original model. We also outperform
all benchmarks and match the original model's performance on ImageNet, using
only 55% of the trainable parameters and 60% of the FLOPs. In addition to
notable performances, models produced via CFDP exhibit robustness to a variety
of configurations including pruning from untrained neural architectures, and
resistance to adversarial attacks. The implementation code can be found at
https://github.com/Skhaki18/CFDP.
</p></li>
</ul>

<h3>Title: PromptAttack: Probing Dialogue State Trackers with Adversarial Prompts. (arXiv:2306.04535v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04535">http://arxiv.org/abs/2306.04535</a></li>
<li>Code URL: <a href="https://github.com/dongxiangjue/promptattack">https://github.com/dongxiangjue/promptattack</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04535] PromptAttack: Probing Dialogue State Trackers with Adversarial Prompts](http://arxiv.org/abs/2306.04535) #attack</code></li>
<li>Summary: <p>A key component of modern conversational systems is the Dialogue State
Tracker (or DST), which models a user's goals and needs. Toward building more
robust and reliable DSTs, we introduce a prompt-based learning approach to
automatically generate effective adversarial examples to probe DST models. Two
key characteristics of this approach are: (i) it only needs the output of the
DST with no need for model parameters, and (ii) it can learn to generate
natural language utterances that can target any DST. Through experiments over
state-of-the-art DSTs, the proposed framework leads to the greatest reduction
in accuracy and the best attack success rate while maintaining good fluency and
a low perturbation ratio. We also show how much the generated adversarial
examples can bolster a DST through adversarial training. These results indicate
the strength of prompt-based attacks on DSTs and leave open avenues for
continued refinement.
</p></li>
</ul>

<h3>Title: Extracting Cloud-based Model with Prior Knowledge. (arXiv:2306.04192v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04192">http://arxiv.org/abs/2306.04192</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04192] Extracting Cloud-based Model with Prior Knowledge](http://arxiv.org/abs/2306.04192) #attack</code></li>
<li>Summary: <p>Machine Learning-as-a-Service, a pay-as-you-go business pattern, is widely
accepted by third-party users and developers. However, the open inference APIs
may be utilized by malicious customers to conduct model extraction attacks,
i.e., attackers can replicate a cloud-based black-box model merely via querying
malicious examples. Existing model extraction attacks mainly depend on the
posterior knowledge (i.e., predictions of query samples) from Oracle. Thus,
they either require high query overhead to simulate the decision boundary, or
suffer from generalization errors and overfitting problems due to query budget
limitations. To mitigate it, this work proposes an efficient model extraction
attack based on prior knowledge for the first time. The insight is that prior
knowledge of unlabeled proxy datasets is conducive to the search for the
decision boundary (e.g., informative samples). Specifically, we leverage
self-supervised learning including autoencoder and contrastive learning to
pre-compile the prior knowledge of the proxy dataset into the feature extractor
of the substitute model. Then we adopt entropy to measure and sample the most
informative examples to query the target model. Our design leverages both prior
and posterior knowledge to extract the model and thus eliminates
generalizability errors and overfitting problems. We conduct extensive
experiments on open APIs like Traffic Recognition, Flower Recognition,
Moderation Recognition, and NSFW Recognition from real-world platforms, Azure
and Clarifai. The experimental results demonstrate the effectiveness and
efficiency of our attack. For example, our attack achieves 95.1% fidelity with
merely 1.8K queries (cost 2.16$) on the NSFW Recognition API. Also, the
adversarial examples generated with our substitute model have better
transferability than others, which reveals that our scheme is more conducive to
downstream attacks.
</p></li>
</ul>

<h3>Title: Development of a System Vulnerability Analysis Tool for Assessment of Complex Mission Critical Systems. (arXiv:2306.04280v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04280">http://arxiv.org/abs/2306.04280</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04280] Development of a System Vulnerability Analysis Tool for Assessment of Complex Mission Critical Systems](http://arxiv.org/abs/2306.04280) #attack</code></li>
<li>Summary: <p>A system vulnerability analysis technique (SVAT) for complex mission critical
systems (CMCS) was developed in response to the need to be able to conduct
penetration testing on large industrial systems which cannot be taken offline
or risk disablement or impairment for conventional penetration testing.
SVAT-CMCS facilitates the use of known vulnerability and exploit information,
incremental testing of system components and data analysis techniques to
identify attack pathways in CMCSs. This data can be utilized for corrective
activities or to target controlled manual follow-up testing. This paper
presents the SVAT-CMCS paradigm and describes its implementation in a software
tool, which was built using the Blackboard Architecture, that can be utilized
for attack pathway identification. The performance of this tool is
characterized using three example models. In particular, it explores the path
generation speed and the impact of link cap restrictions on system operations,
under different levels of network size and complexity. Accurate fact-rule
processing is also tested using these models. The results show significant
decreases in path generation efficiency as the link cap and network complexity
increase; however, rule processing accuracy is not impacted.
</p></li>
</ul>

<h3>Title: Vulnerable Smart Contract Function Locating Based on Multi-Relational Nested Graph Convolutional Network. (arXiv:2306.04479v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04479">http://arxiv.org/abs/2306.04479</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04479] Vulnerable Smart Contract Function Locating Based on Multi-Relational Nested Graph Convolutional Network](http://arxiv.org/abs/2306.04479) #attack</code></li>
<li>Summary: <p>The immutable and trustable characteristics of blockchain enable smart
contracts to be applied in various fields. Unfortunately, smart contracts are
subject to various vulnerabilities, which are frequently exploited by
attackers, causing financial damage to users.In this paper, we study the
problem of vulnerable smart contract function locating. We construct a novel
Multi-Relational Nested contract Graph (MRNG) to better characterize the rich
syntactic and semantic information in the smart contract code, including the
relationships between data and instructions. An MRNG represents a smart
contract, where each node represents a function in the smart contract and each
edge describes the calling relationship between the functions. In addition, we
create a Multi-Relational Function Graph (MRFG) for each function, which
characterizes the corresponding function code. That is, each function is
characterized as an MRFG, which corresponds to a node in the MRNG. Each MRFG
uses different types of edges to represent the different control and data
relationships between nodes within a function. We also propose a
Multi-Relational Nested Graph Convolutional Network (MRN-GCN) to process the
MRNG. MRN-GCN first extracts and aggregates features from each MRFG, using the
edge-enhanced graph convolution network and self-attention mechanism. The
extracted feature vector is then assigned to the corresponding node in the MRNG
to obtain a new Featured Contract Graph (FCG) for the smart contract. Graph
convolution is used to further extract features from the FCG. Finally, a feed
forward network with a Sigmoid function is used to locate the vulnerable
functions. Experimental results on the real-world smart contract datasets show
that model MRN-GCN can effectively improve the accuracy, precision, recall and
F1-score performance of vulnerable smart contract function locating.
</p></li>
</ul>

<h3>Title: Divide and Repair: Using Options to Improve Performance of Imitation Learning Against Adversarial Demonstrations. (arXiv:2306.04581v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04581">http://arxiv.org/abs/2306.04581</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04581] Divide and Repair: Using Options to Improve Performance of Imitation Learning Against Adversarial Demonstrations](http://arxiv.org/abs/2306.04581) #attack</code></li>
<li>Summary: <p>We consider the problem of learning to perform a task from demonstrations
given by teachers or experts, when some of the experts' demonstrations might be
adversarial and demonstrate an incorrect way to perform the task. We propose a
novel technique that can identify parts of demonstrated trajectories that have
not been significantly modified by the adversary and utilize them for learning,
using temporally extended policies or options. We first define a trajectory
divergence measure based on the spatial and temporal features of demonstrated
trajectories to detect and discard parts of the trajectories that have been
significantly modified by an adversarial expert, and, could degrade the
learner's performance, if used for learning, We then use an options-based
algorithm that partitions trajectories and learns only from the parts of
trajectories that have been determined as admissible. We provide theoretical
results of our technique to show that repairing partial trajectories improves
the sample efficiency of the demonstrations without degrading the learner's
performance. We then evaluate the proposed algorithm for learning to play an
Atari-like, computer-based game called LunarLander in the presence of different
types and degrees of adversarial attacks of demonstrated trajectories. Our
experimental results show that our technique can identify adversarially
modified parts of the demonstrated trajectories and successfully prevent the
learning performance from degrading due to adversarial demonstrations.
</p></li>
</ul>

<h3>Title: Membership inference attack with relative decision boundary distance. (arXiv:2306.04109v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04109">http://arxiv.org/abs/2306.04109</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04109] Membership inference attack with relative decision boundary distance](http://arxiv.org/abs/2306.04109) #attack</code></li>
<li>Summary: <p>Membership inference attack is one of the most popular privacy attacks in
machine learning, which aims to predict whether a given sample was contained in
the target model's training set. Label-only membership inference attack is a
variant that exploits sample robustness and attracts more attention since it
assumes a practical scenario in which the adversary only has access to the
predicted labels of the input samples. However, since the decision boundary
distance, which measures robustness, is strongly affected by the random initial
image, the adversary may get opposite results even for the same input samples.
In this paper, we propose a new attack method, called muti-class adaptive
membership inference attack in the label-only setting. All decision boundary
distances for all target classes have been traversed in the early attack
iterations, and the subsequent attack iterations continue with the shortest
decision boundary distance to obtain a stable and optimal decision boundary
distance. Instead of using a single boundary distance, the relative boundary
distance between samples and neighboring points has also been employed as a new
membership score to distinguish between member samples inside the training set
and nonmember samples outside the training set. Experiments show that previous
label-only membership inference attacks using the untargeted HopSkipJump
algorithm fail to achieve optimal decision bounds in more than half of the
samples, whereas our multi-targeted HopSkipJump algorithm succeeds in almost
all samples. In addition, extensive experiments show that our multi-class
adaptive MIA outperforms current label-only membership inference attacks in the
CIFAR10, and CIFAR100 datasets, especially for the true positive rate at low
false positive rates metric.
</p></li>
</ul>

<h3>Title: Adversarial Sample Detection Through Neural Network Transport Dynamics. (arXiv:2306.04252v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04252">http://arxiv.org/abs/2306.04252</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04252] Adversarial Sample Detection Through Neural Network Transport Dynamics](http://arxiv.org/abs/2306.04252) #attack</code></li>
<li>Summary: <p>We propose a detector of adversarial samples that is based on the view of
neural networks as discrete dynamic systems. The detector tells clean inputs
from abnormal ones by comparing the discrete vector fields they follow through
the layers. We also show that regularizing this vector field during training
makes the network more regular on the data distribution's support, thus making
the activations of clean inputs more distinguishable from those of abnormal
ones. Experimentally, we compare our detector favorably to other detectors on
seen and unseen attacks, and show that the regularization of the network's
dynamics improves the performance of adversarial detectors that use the
internal embeddings as inputs, while also improving test accuracy.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Q: How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks? A: Self-Train on Unlabeled Images!. (arXiv:2306.03932v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03932">http://arxiv.org/abs/2306.03932</a></li>
<li>Code URL: <a href="https://github.com/codezakh/seltda">https://github.com/codezakh/seltda</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03932] Q: How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks? A: Self-Train on Unlabeled Images!](http://arxiv.org/abs/2306.03932) #robust</code></li>
<li>Summary: <p>Finetuning a large vision language model (VLM) on a target dataset after
large scale pretraining is a dominant paradigm in visual question answering
(VQA). Datasets for specialized tasks such as knowledge-based VQA or VQA in non
natural-image domains are orders of magnitude smaller than those for
general-purpose VQA. While collecting additional labels for specialized tasks
or domains can be challenging, unlabeled images are often available. We
introduce SelTDA (Self-Taught Data Augmentation), a strategy for finetuning
large VLMs on small-scale VQA datasets. SelTDA uses the VLM and target dataset
to build a teacher model that can generate question-answer pseudolabels
directly conditioned on an image alone, allowing us to pseudolabel unlabeled
images. SelTDA then finetunes the initial VLM on the original dataset augmented
with freshly pseudolabeled images. We describe a series of experiments showing
that our self-taught data augmentation increases robustness to adversarially
searched questions, counterfactual examples and rephrasings, improves domain
generalization, and results in greater retention of numerical reasoning skills.
The proposed strategy requires no additional annotations or architectural
modifications, and is compatible with any modern encoder-decoder multimodal
transformer. Code available at https://github.com/codezakh/SelTDA.
</p></li>
</ul>

<h3>Title: StructuredMesh: 3D Structured Optimization of Fa\c{c}ade Components on Photogrammetric Mesh Models using Binary Integer Programming. (arXiv:2306.04184v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04184">http://arxiv.org/abs/2306.04184</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04184] StructuredMesh: 3D Structured Optimization of Fa\c{c}ade Components on Photogrammetric Mesh Models using Binary Integer Programming](http://arxiv.org/abs/2306.04184) #robust</code></li>
<li>Summary: <p>The lack of fa\c{c}ade structures in photogrammetric mesh models renders them
inadequate for meeting the demands of intricate applications. Moreover, these
mesh models exhibit irregular surfaces with considerable geometric noise and
texture quality imperfections, making the restoration of structures
challenging. To address these shortcomings, we present StructuredMesh, a novel
approach for reconstructing fa\c{c}ade structures conforming to the regularity
of buildings within photogrammetric mesh models. Our method involves capturing
multi-view color and depth images of the building model using a virtual camera
and employing a deep learning object detection pipeline to semi-automatically
extract the bounding boxes of fa\c{c}ade components such as windows, doors, and
balconies from the color image. We then utilize the depth image to remap these
boxes into 3D space, generating an initial fa\c{c}ade layout. Leveraging
architectural knowledge, we apply binary integer programming (BIP) to optimize
the 3D layout's structure, encompassing the positions, orientations, and sizes
of all components. The refined layout subsequently informs fa\c{c}ade modeling
through instance replacement. We conducted experiments utilizing building mesh
models from three distinct datasets, demonstrating the adaptability,
robustness, and noise resistance of our proposed methodology. Furthermore, our
3D layout evaluation metrics reveal that the optimized layout enhances
precision, recall, and F-score by 6.5%, 4.5%, and 5.5%, respectively, in
comparison to the initial layout.
</p></li>
</ul>

<h3>Title: Learning Probabilistic Coordinate Fields for Robust Correspondences. (arXiv:2306.04231v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04231">http://arxiv.org/abs/2306.04231</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04231] Learning Probabilistic Coordinate Fields for Robust Correspondences](http://arxiv.org/abs/2306.04231) #robust</code></li>
<li>Summary: <p>We introduce Probabilistic Coordinate Fields (PCFs), a novel
geometric-invariant coordinate representation for image correspondence
problems. In contrast to standard Cartesian coordinates, PCFs encode
coordinates in correspondence-specific barycentric coordinate systems (BCS)
with affine invariance. To know \textit{when and where to trust} the encoded
coordinates, we implement PCFs in a probabilistic network termed PCF-Net, which
parameterizes the distribution of coordinate fields as Gaussian mixture models.
By jointly optimizing coordinate fields and their confidence conditioned on
dense flows, PCF-Net can work with various feature descriptors when quantifying
the reliability of PCFs by confidence maps. An interesting observation of this
work is that the learned confidence map converges to geometrically coherent and
semantically consistent regions, which facilitates robust coordinate
representation. By delivering the confident coordinates to keypoint/feature
descriptors, we show that PCF-Net can be used as a plug-in to existing
correspondence-dependent approaches. Extensive experiments on both indoor and
outdoor datasets suggest that accurate geometric invariant coordinates help to
achieve the state of the art in several correspondence problems, such as sparse
feature matching, dense image registration, camera pose estimation, and
consistency filtering. Further, the interpretable confidence map predicted by
PCF-Net can also be leveraged to other novel applications from texture transfer
to multi-homography classification.
</p></li>
</ul>

<h3>Title: ICON$^2$: Reliably Benchmarking Predictive Inequity in Object Detection. (arXiv:2306.04482v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04482">http://arxiv.org/abs/2306.04482</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04482] ICON$^2$: Reliably Benchmarking Predictive Inequity in Object Detection](http://arxiv.org/abs/2306.04482) #robust</code></li>
<li>Summary: <p>As computer vision systems are being increasingly deployed at scale in
high-stakes applications like autonomous driving, concerns about social bias in
these systems are rising. Analysis of fairness in real-world vision systems,
such as object detection in driving scenes, has been limited to observing
predictive inequity across attributes such as pedestrian skin tone, and lacks a
consistent methodology to disentangle the role of confounding variables e.g.
does my model perform worse for a certain skin tone, or are such scenes in my
dataset more challenging due to occlusion and crowds? In this work, we
introduce ICON$^2$, a framework for robustly answering this question. ICON$^2$
leverages prior knowledge on the deficiencies of object detection systems to
identify performance discrepancies across sub-populations, compute correlations
between these potential confounders and a given sensitive attribute, and
control for the most likely confounders to obtain a more reliable estimate of
model bias. Using our approach, we conduct an in-depth study on the performance
of object detection with respect to income from the BDD100K driving dataset,
revealing useful insights.
</p></li>
</ul>

<h3>Title: ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image Collections. (arXiv:2306.04619v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04619">http://arxiv.org/abs/2306.04619</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04619] ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image Collections](http://arxiv.org/abs/2306.04619) #robust</code></li>
<li>Summary: <p>Estimating 3D articulated shapes like animal bodies from monocular images is
inherently challenging due to the ambiguities of camera viewpoint, pose,
texture, lighting, etc. We propose ARTIC3D, a self-supervised framework to
reconstruct per-instance 3D shapes from a sparse image collection in-the-wild.
Specifically, ARTIC3D is built upon a skeleton-based surface representation and
is further guided by 2D diffusion priors from Stable Diffusion. First, we
enhance the input images with occlusions/truncation via 2D diffusion to obtain
cleaner mask estimates and semantic features. Second, we perform
diffusion-guided 3D optimization to estimate shape and texture that are of
high-fidelity and faithful to input images. We also propose a novel technique
to calculate more stable image-level gradients via diffusion models compared to
existing alternatives. Finally, we produce realistic animations by fine-tuning
the rendered shape and texture under rigid part transformations. Extensive
evaluations on multiple existing datasets as well as newly introduced noisy web
image collections with occlusions and truncation demonstrate that ARTIC3D
outputs are more robust to noisy images, higher quality in terms of shape and
texture details, and more realistic when animated. Project page:
https://chhankyao.github.io/artic3d/
</p></li>
</ul>

<h3>Title: Cross-Genre Argument Mining: Can Language Models Automatically Fill in Missing Discourse Markers?. (arXiv:2306.04314v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04314">http://arxiv.org/abs/2306.04314</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04314] Cross-Genre Argument Mining: Can Language Models Automatically Fill in Missing Discourse Markers?](http://arxiv.org/abs/2306.04314) #robust</code></li>
<li>Summary: <p>Available corpora for Argument Mining differ along several axes, and one of
the key differences is the presence (or absence) of discourse markers to signal
argumentative content. Exploring effective ways to use discourse markers has
received wide attention in various discourse parsing tasks, from which it is
well-known that discourse markers are strong indicators of discourse relations.
To improve the robustness of Argument Mining systems across different genres,
we propose to automatically augment a given text with discourse markers such
that all relations are explicitly signaled. Our analysis unveils that popular
language models taken out-of-the-box fail on this task; however, when
fine-tuned on a new heterogeneous dataset that we construct (including
synthetic and real examples), they perform considerably better. We demonstrate
the impact of our approach on an Argument Mining downstream task, evaluated on
different corpora, showing that language models can be trained to automatically
fill in discourse markers across different corpora, improving the performance
of a downstream model in some, but not all, cases. Our proposed approach can
further be employed as an assistive tool for better discourse understanding.
</p></li>
</ul>

<h3>Title: GPT Self-Supervision for a Better Data Annotator. (arXiv:2306.04349v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04349">http://arxiv.org/abs/2306.04349</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04349] GPT Self-Supervision for a Better Data Annotator](http://arxiv.org/abs/2306.04349) #robust</code></li>
<li>Summary: <p>The task of annotating data into concise summaries poses a significant
challenge across various domains, frequently requiring the allocation of
significant time and specialized knowledge by human experts. Despite existing
efforts to use large language models for annotation tasks, significant problems
such as limited applicability to unlabeled data, the absence of self-supervised
methods, and the lack of focus on complex structured data still persist. In
this work, we propose a GPT self-supervision annotation method. This method
embodies a generating-recovering paradigm that leverages the capabilities of
one-shot learning capabilities in Generative Pretrained Transformer (GPT). The
proposed approach comprises a one-shot tuning phase followed by a generation
phase. In the one-shot tuning phase, we sample a data from the support set as
part of the prompt for GPT to generate a textual summary, which is then used to
recover the original data. The alignment score between the recovered and
original data serves as a self-supervision navigator to refine the process. In
the generation stage, the optimally selected one-shot sample serves as a
template in the prompt and is applied to generating summaries from challenging
datasets. The annotation performance is evaluated by tuning several human
feedback reward networks and by calculating alignment scores between original
and recovered data at both sentence and structure levels. Our self-supervised
annotation method consistently achieves competitive scores, convincingly
demonstrating its robust strength in various data-to-summary annotation tasks.
</p></li>
</ul>

<h3>Title: Label Aware Speech Representation Learning For Language Identification. (arXiv:2306.04374v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04374">http://arxiv.org/abs/2306.04374</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04374] Label Aware Speech Representation Learning For Language Identification](http://arxiv.org/abs/2306.04374) #robust</code></li>
<li>Summary: <p>Speech representation learning approaches for non-semantic tasks such as
language recognition have either explored supervised embedding extraction
methods using a classifier model or self-supervised representation learning
approaches using raw data. In this paper, we propose a novel framework of
combining self-supervised representation learning with the language label
information for the pre-training task. This framework, termed as Label Aware
Speech Representation (LASR) learning, uses a triplet based objective function
to incorporate language labels along with the self-supervised loss function.
The speech representations are further fine-tuned for the downstream task. The
language recognition experiments are performed on two public datasets - FLEURS
and Dhwani. In these experiments, we illustrate that the proposed LASR
framework improves over the state-of-the-art systems on language
identification. We also report an analysis of the robustness of LASR approach
to noisy/missing labels as well as its application to multi-lingual speech
recognition tasks.
</p></li>
</ul>

<h3>Title: PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts. (arXiv:2306.04528v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04528">http://arxiv.org/abs/2306.04528</a></li>
<li>Code URL: <a href="https://github.com/microsoft/promptbench">https://github.com/microsoft/promptbench</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04528] PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts](http://arxiv.org/abs/2306.04528) #robust</code></li>
<li>Summary: <p>The increasing reliance on Large Language Models (LLMs) across academia and
industry necessitates a comprehensive understanding of their robustness to
prompts. In response to this vital need, we introduce PromptBench, a robustness
benchmark designed to measure LLMs' resilience to adversarial prompts. This
study uses a plethora of adversarial textual attacks targeting prompts across
multiple levels: character, word, sentence, and semantic. These prompts are
then employed in diverse tasks, such as sentiment analysis, natural language
inference, reading comprehension, machine translation, and math
problem-solving. Our study generates 4,032 adversarial prompts, meticulously
evaluated over 8 tasks and 13 datasets, with 567,084 test samples in total. Our
findings demonstrate that contemporary LLMs are vulnerable to adversarial
prompts. Furthermore, we present comprehensive analysis to understand the
mystery behind prompt robustness and its transferability. We then offer
insightful robustness analysis and pragmatic recommendations for prompt
composition, beneficial to both researchers and everyday users. We make our
code, prompts, and methodologies to generate adversarial prompts publicly
accessible, thereby enabling and encouraging collaborative exploration in this
pivotal field: https://github.com/microsoft/promptbench.
</p></li>
</ul>

<h3>Title: Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations. (arXiv:2306.04618v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04618">http://arxiv.org/abs/2306.04618</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04618] Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations](http://arxiv.org/abs/2306.04618) #robust</code></li>
<li>Summary: <p>This paper reexamines the research on out-of-distribution (OOD) robustness in
the field of NLP. We find that the distribution shift settings in previous
studies commonly lack adequate challenges, hindering the accurate evaluation of
OOD robustness. To address these issues, we propose a benchmark construction
protocol that ensures clear differentiation and challenging distribution
shifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution
robustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we
conduct a series of experiments on pre-trained language models for analysis and
evaluation of OOD robustness. First, for vanilla fine-tuning, we examine the
relationship between in-distribution (ID) and OOD performance. We identify
three typical types that unveil the inner learning mechanism, which could
potentially facilitate the forecasting of OOD robustness, correlating with the
advancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and
find that, despite exhibiting some effectiveness in specific cases, they do not
offer significant improvement compared to vanilla fine-tuning. Further, we
evaluate 5 LLMs with various adaptation paradigms and find that when sufficient
ID data is available, fine-tuning domain-specific models outperform LLMs on ID
examples significantly. However, in the case of OOD instances, prioritizing
LLMs with in-context learning yields better results. We identify that both
fine-tuned small models and LLMs face challenges in effectively addressing
downstream tasks. The code is public at
\url{https://github.com/lifan-yuan/OOD_NLP}.
</p></li>
</ul>

<h3>Title: Agent Performing Autonomous Stock Trading under Good and Bad Situations. (arXiv:2306.03985v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03985">http://arxiv.org/abs/2306.03985</a></li>
<li>Code URL: <a href="https://github.com/yunfeiluo/autonomous-stock-trading">https://github.com/yunfeiluo/autonomous-stock-trading</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03985] Agent Performing Autonomous Stock Trading under Good and Bad Situations](http://arxiv.org/abs/2306.03985) #robust</code></li>
<li>Summary: <p>Stock trading is one of the popular ways for financial management. However,
the market and the environment of economy is unstable and usually not
predictable. Furthermore, engaging in stock trading requires time and effort to
analyze, create strategies, and make decisions. It would be convenient and
effective if an agent could assist or even do the task of analyzing and
modeling the past data and then generate a strategy for autonomous trading.
Recently, reinforcement learning has been shown to be robust in various tasks
that involve achieving a goal with a decision making strategy based on
time-series data. In this project, we have developed a pipeline that simulates
the stock trading environment and have trained an agent to automate the stock
trading process with deep reinforcement learning methods, including deep
Q-learning, deep SARSA, and the policy gradient method. We evaluate our
platform during relatively good (before 2021) and bad (2021 - 2022) situations.
The stocks we've evaluated on including Google, Apple, Tesla, Meta, Microsoft,
and IBM. These stocks are among the popular ones, and the changes in trends are
representative in terms of having good and bad situations. We showed that
before 2021, the three reinforcement methods we have tried always provide
promising profit returns with total annual rates around $70\%$ to $90\%$, while
maintain a positive profit return after 2021 with total annual rates around 2%
to 7%.
</p></li>
</ul>

<h3>Title: Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings. (arXiv:2306.04064v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04064">http://arxiv.org/abs/2306.04064</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04064] Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings](http://arxiv.org/abs/2306.04064) #robust</code></li>
<li>Summary: <p>Research on adversarial robustness is primarily focused on image and text
data. Yet, many scenarios in which lack of robustness can result in serious
risks, such as fraud detection, medical diagnosis, or recommender systems often
do not rely on images or text but instead on tabular data. Adversarial
robustness in tabular data poses two serious challenges. First, tabular
datasets often contain categorical features, and therefore cannot be tackled
directly with existing optimization procedures. Second, in the tabular domain,
algorithms that are not based on deep networks are widely used and offer great
performance, but algorithms to enhance robustness are tailored to neural
networks (e.g. adversarial training).
</p></li>
</ul>

<p>In this paper, we tackle both challenges. We present a method that allows us
to train adversarially robust deep networks for tabular data and to transfer
this robustness to other classifiers via universal robust embeddings tailored
to categorical data. These embeddings, created using a bilevel alternating
minimization framework, can be transferred to boosted trees or random forests
making them robust without the need for adversarial training while preserving
their high accuracy on tabular data. We show that our methods outperform
existing techniques within a practical threat model suitable for tabular data.
</p>

<h3>Title: A novel deeponet model for learning moving-solution operators with applications to earthquake hypocenter localization. (arXiv:2306.04096v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04096">http://arxiv.org/abs/2306.04096</a></li>
<li>Code URL: <a href="https://github.com/ehsanhaghighat/x-deeponet">https://github.com/ehsanhaghighat/x-deeponet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04096] A novel deeponet model for learning moving-solution operators with applications to earthquake hypocenter localization](http://arxiv.org/abs/2306.04096) #robust</code></li>
<li>Summary: <p>Seismicity induced by human activities poses a significant threat to public
safety, emphasizing the need for accurate and timely earthquake hypocenter
localization. In this study, we introduce X-DeepONet, a novel variant of deep
operator networks (DeepONets), for learning moving-solution operators of
parametric partial differential equations (PDEs), with application to real-time
earthquake localization. Leveraging the power of neural operators, X-DeepONet
learns to estimate traveltime fields associated with earthquake sources by
incorporating information from seismic arrival times and velocity models.
Similar to the DeepONet, X-DeepONet includes a trunk net and a branch net.
Additionally, we introduce a root network that not only takes the standard
DeepONet's multiplication operator as input, it also takes addition and
subtraction operators. We show that for problems with moving fields, the
standard multiplication operation of DeepONet is insufficient to capture field
relocation, while addition and subtraction operators along with the eXtended
root significantly improve its accuracy both under data-driven (supervised) and
physics-informed (unsupervised) training. We demonstrate the effectiveness of
X-DeepONet through various experiments, including scenarios with variable
velocity models and arrival times. The results show remarkable accuracy in
earthquake localization, even for heterogeneous and complex velocity models.
The proposed framework also exhibits excellent generalization capabilities and
robustness against noisy arrival times. The method provides a computationally
efficient approach for quantifying uncertainty in hypocenter locations
resulting from traveltime pick errors and velocity model variations. Our
results underscore X-DeepONet's potential to improve seismic monitoring
systems, aiding the development of early warning systems for seismic hazard
mitigation.
</p></li>
</ul>

<h3>Title: Efficient Alternating Minimization with Applications to Weighted Low Rank Approximation. (arXiv:2306.04169v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04169">http://arxiv.org/abs/2306.04169</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04169] Efficient Alternating Minimization with Applications to Weighted Low Rank Approximation](http://arxiv.org/abs/2306.04169) #robust</code></li>
<li>Summary: <p>Weighted low rank approximation is a fundamental problem in numerical linear
algebra, and it has many applications in machine learning. Given a matrix $M
\in \mathbb{R}^{n \times n}$, a weight matrix $W \in \mathbb{R}_{\geq 0}^{n
\times n}$, a parameter $k$, the goal is to output two matrices $U, V \in
\mathbb{R}^{n \times k}$ such that $\| W \circ (M - U V) \|_F$ is minimized,
where $\circ$ denotes the Hadamard product. Such a problem is known to be
NP-hard and even hard to approximate [RSW16]. Meanwhile, alternating
minimization is a good heuristic solution for approximating weighted low rank
approximation. The work [LLR16] shows that, under mild assumptions, alternating
minimization does provide provable guarantees. In this work, we develop an
efficient and robust framework for alternating minimization. For weighted low
rank approximation, this improves the runtime of [LLR16] from $n^2 k^2$ to
$n^2k$. At the heart of our work framework is a high-accuracy multiple response
regression solver together with a robust analysis of alternating minimization.
</p></li>
</ul>

<h3>Title: Optimal Transport Model Distributional Robustness. (arXiv:2306.04178v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04178">http://arxiv.org/abs/2306.04178</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04178] Optimal Transport Model Distributional Robustness](http://arxiv.org/abs/2306.04178) #robust</code></li>
<li>Summary: <p>Distributional robustness is a promising framework for training deep learning
models that are less vulnerable to adversarial examples and data distribution
shifts. Previous works have mainly focused on exploiting distributional
robustness in data space. In this work, we explore an optimal transport-based
distributional robustness framework on model spaces. Specifically, we examine a
model distribution in a Wasserstein ball of a given center model distribution
that maximizes the loss. We have developed theories that allow us to learn the
optimal robust center model distribution. Interestingly, through our developed
theories, we can flexibly incorporate the concept of sharpness awareness into
training a single model, ensemble models, and Bayesian Neural Networks by
considering specific forms of the center model distribution, such as a Dirac
delta distribution over a single model, a uniform distribution over several
models, and a general Bayesian Neural Network. Furthermore, we demonstrate that
sharpness-aware minimization (SAM) is a specific case of our framework when
using a Dirac delta distribution over a single model, while our framework can
be viewed as a probabilistic extension of SAM. We conduct extensive experiments
to demonstrate the usefulness of our framework in the aforementioned settings,
and the results show remarkable improvements in our approaches to the
baselines.
</p></li>
</ul>

<h3>Title: Self-Adjusting Weighted Expected Improvement for Bayesian Optimization. (arXiv:2306.04262v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04262">http://arxiv.org/abs/2306.04262</a></li>
<li>Code URL: <a href="https://github.com/automl/sawei">https://github.com/automl/sawei</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04262] Self-Adjusting Weighted Expected Improvement for Bayesian Optimization](http://arxiv.org/abs/2306.04262) #robust</code></li>
<li>Summary: <p>Bayesian Optimization (BO) is a class of surrogate-based, sample-efficient
algorithms for optimizing black-box problems with small evaluation budgets. The
BO pipeline itself is highly configurable with many different design choices
regarding the initial design, surrogate model, and acquisition function (AF).
Unfortunately, our understanding of how to select suitable components for a
problem at hand is very limited. In this work, we focus on the definition of
the AF, whose main purpose is to balance the trade-off between exploring
regions with high uncertainty and those with high promise for good solutions.
We propose Self-Adjusting Weighted Expected Improvement (SAWEI), where we let
the exploration-exploitation trade-off self-adjust in a data-driven manner,
based on a convergence criterion for BO. On the noise-free black-box BBOB
functions of the COCO benchmarking platform, our method exhibits a favorable
any-time performance compared to handcrafted baselines and serves as a robust
default choice for any problem structure. The suitability of our method also
transfers to HPOBench. With SAWEI, we are a step closer to on-the-fly,
data-driven, and robust BO designs that automatically adjust their sampling
behavior to the problem at hand.
</p></li>
</ul>

<h3>Title: Timing Process Interventions with Causal Inference and Reinforcement Learning. (arXiv:2306.04299v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04299">http://arxiv.org/abs/2306.04299</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04299] Timing Process Interventions with Causal Inference and Reinforcement Learning](http://arxiv.org/abs/2306.04299) #robust</code></li>
<li>Summary: <p>The shift from the understanding and prediction of processes to their
optimization offers great benefits to businesses and other organizations.
Precisely timed process interventions are the cornerstones of effective
optimization. Prescriptive process monitoring (PresPM) is the sub-field of
process mining that concentrates on process optimization. The emerging PresPM
literature identifies state-of-the-art methods, causal inference (CI) and
reinforcement learning (RL), without presenting a quantitative comparison. Most
experiments are carried out using historical data, causing problems with the
accuracy of the methods' evaluations and preempting online RL. Our contribution
consists of experiments on timed process interventions with synthetic data that
renders genuine online RL and the comparison to CI possible, and allows for an
accurate evaluation of the results. Our experiments reveal that RL's policies
outperform those from CI and are more robust at the same time. Indeed, the RL
policies approach perfect policies. Unlike CI, the unaltered online RL approach
can be applied to other, more generic PresPM problems such as next best
activity recommendations. Nonetheless, CI has its merits in settings where
online learning is not an option.
</p></li>
</ul>

<h3>Title: Balancing of competitive two-player Game Levels with Reinforcement Learning. (arXiv:2306.04429v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04429">http://arxiv.org/abs/2306.04429</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04429] Balancing of competitive two-player Game Levels with Reinforcement Learning](http://arxiv.org/abs/2306.04429) #robust</code></li>
<li>Summary: <p>The balancing process for game levels in a competitive two-player context
involves a lot of manual work and testing, particularly in non-symmetrical game
levels. In this paper, we propose an architecture for automated balancing of
tile-based levels within the recently introduced PCGRL framework (procedural
content generation via reinforcement learning). Our architecture is divided
into three parts: (1) a level generator, (2) a balancing agent and, (3) a
reward modeling simulation. By playing the level in a simulation repeatedly,
the balancing agent is rewarded for modifying it towards the same win rates for
all players. To this end, we introduce a novel family of swap-based
representations to increase robustness towards playability. We show that this
approach is capable to teach an agent how to alter a level for balancing better
and faster than plain PCGRL. In addition, by analyzing the agent's swapping
behavior, we can draw conclusions about which tile types influence the
balancing most. We test and show our results using the Neural MMO (NMMO)
environment in a competitive two-player setting.
</p></li>
</ul>

<h3>Title: Faithful Knowledge Distillation. (arXiv:2306.04431v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04431">http://arxiv.org/abs/2306.04431</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04431] Faithful Knowledge Distillation](http://arxiv.org/abs/2306.04431) #robust</code></li>
<li>Summary: <p>Knowledge distillation (KD) has received much attention due to its success in
compressing networks to allow for their deployment in resource-constrained
systems. While the problem of adversarial robustness has been studied before in
the KD setting, previous works overlook what we term the relative calibration
of the student network with respect to its teacher in terms of soft
confidences. In particular, we focus on two crucial questions with regard to a
teacher-student pair: (i) do the teacher and student disagree at points close
to correctly classified dataset examples, and (ii) is the distilled student as
confident as the teacher around dataset examples? These are critical questions
when considering the deployment of a smaller student network trained from a
robust teacher within a safety-critical setting. To address these questions, we
introduce a faithful imitation framework to discuss the relative calibration of
confidences, as well as provide empirical and certified methods to evaluate the
relative calibration of a student w.r.t. its teacher. Further, to verifiably
align the relative calibration incentives of the student to those of its
teacher, we introduce faithful distillation. Our experiments on the MNIST and
Fashion-MNIST datasets demonstrate the need for such an analysis and the
advantages of the increased verifiability of faithful distillation over
alternative adversarial distillation methods.
</p></li>
</ul>

<h3>Title: Training-Free Neural Active Learning with Initialization-Robustness Guarantees. (arXiv:2306.04454v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04454">http://arxiv.org/abs/2306.04454</a></li>
<li>Code URL: <a href="https://github.com/apivich-h/init-robust-al">https://github.com/apivich-h/init-robust-al</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04454] Training-Free Neural Active Learning with Initialization-Robustness Guarantees](http://arxiv.org/abs/2306.04454) #robust</code></li>
<li>Summary: <p>Existing neural active learning algorithms have aimed to optimize the
predictive performance of neural networks (NNs) by selecting data for
labelling. However, other than a good predictive performance, being robust
against random parameter initializations is also a crucial requirement in
safety-critical applications. To this end, we introduce our expected variance
with Gaussian processes (EV-GP) criterion for neural active learning, which is
theoretically guaranteed to select data points which lead to trained NNs with
both (a) good predictive performances and (b) initialization robustness.
Importantly, our EV-GP criterion is training-free, i.e., it does not require
any training of the NN during data selection, which makes it computationally
efficient. We empirically demonstrate that our EV-GP criterion is highly
correlated with both initialization robustness and generalization performance,
and show that it consistently outperforms baseline methods in terms of both
desiderata, especially in situations with limited initial data or large batch
sizes.
</p></li>
</ul>

<h3>Title: Recent applications of machine learning, remote sensing, and iot approaches in yield prediction: a critical review. (arXiv:2306.04566v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04566">http://arxiv.org/abs/2306.04566</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04566] Recent applications of machine learning, remote sensing, and iot approaches in yield prediction: a critical review](http://arxiv.org/abs/2306.04566) #robust</code></li>
<li>Summary: <p>The integration of remote sensing and machine learning in agriculture is
transforming the industry by providing insights and predictions through data
analysis. This combination leads to improved yield prediction and water
management, resulting in increased efficiency, better yields, and more
sustainable agricultural practices. Achieving the United Nations' Sustainable
Development Goals, especially "zero hunger," requires the investigation of crop
yield and precipitation gaps, which can be accomplished through, the usage of
artificial intelligence (AI), machine learning (ML), remote sensing (RS), and
the internet of things (IoT). By integrating these technologies, a robust
agricultural mobile or web application can be developed, providing farmers and
decision-makers with valuable information and tools for improving crop
management and increasing efficiency. Several studies have investigated these
new technologies and their potential for diverse tasks such as crop monitoring,
yield prediction, irrigation management, etc. Through a critical review, this
paper reviews relevant articles that have used RS, ML, cloud computing, and IoT
in crop yield prediction. It reviews the current state-of-the-art in this field
by critically evaluating different machine-learning approaches proposed in the
literature for crop yield prediction and water management. It provides insights
into how these methods can improve decision-making in agricultural production
systems. This work will serve as a compendium for those interested in yield
prediction in terms of primary literature but, most importantly, what
approaches can be used for real-time and robust prediction.
</p></li>
</ul>

<h3>Title: Generalization Across Observation Shifts in Reinforcement Learning. (arXiv:2306.04595v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04595">http://arxiv.org/abs/2306.04595</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04595] Generalization Across Observation Shifts in Reinforcement Learning](http://arxiv.org/abs/2306.04595) #robust</code></li>
<li>Summary: <p>Learning policies which are robust to changes in the environment are critical
for real world deployment of Reinforcement Learning agents. They are also
necessary for achieving good generalization across environment shifts. We focus
on bisimulation metrics, which provide a powerful means for abstracting task
relevant components of the observation and learning a succinct representation
space for training the agent using reinforcement learning. In this work, we
extend the bisimulation framework to also account for context dependent
observation shifts. Specifically, we focus on the simulator based learning
setting and use alternate observations to learn a representation space which is
invariant to observation shifts using a novel bisimulation based objective.
This allows us to deploy the agent to varying observation settings during test
time and generalize to unseen scenarios. We further provide novel theoretical
bounds for simulator fidelity and performance transfer guarantees for using a
learnt policy to unseen shifts. Empirical analysis on the high-dimensional
image based control domains demonstrates the efficacy of our method.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: ECQED: Emotion-Cause Quadruple Extraction in Dialogs. (arXiv:2306.03969v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03969">http://arxiv.org/abs/2306.03969</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03969] ECQED: Emotion-Cause Quadruple Extraction in Dialogs](http://arxiv.org/abs/2306.03969) #extraction</code></li>
<li>Summary: <p>The existing emotion-cause pair extraction (ECPE) task, unfortunately,
ignores extracting the emotion type and cause type, while these fine-grained
meta-information can be practically useful in real-world applications, i.e.,
chat robots and empathic dialog generation. Also the current ECPE is limited to
the scenario of single text piece, while neglecting the studies at dialog level
that should have more realistic values. In this paper, we extend the ECPE task
with a broader definition and scenario, presenting a new task, Emotion-Cause
Quadruple Extraction in Dialogs (ECQED), which requires detecting emotion-cause
utterance pairs and emotion and cause types. We present an ECQED model based on
a structural and semantic heterogeneous graph as well as a parallel grid
tagging scheme, which advances in effectively incorporating the dialog context
structure, meanwhile solving the challenging overlapped quadruple issue. Via
experiments we show that introducing the fine-grained emotion and cause
features evidently helps better dialog generation. Also our proposed ECQED
system shows exceptional superiority over baselines on both the emotion-cause
quadruple or pair extraction tasks, meanwhile being highly efficient.
</p></li>
</ul>

<h3>Title: Leveraging Knowledge Graph Embeddings to Enhance Contextual Representations for Relation Extraction. (arXiv:2306.04203v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04203">http://arxiv.org/abs/2306.04203</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04203] Leveraging Knowledge Graph Embeddings to Enhance Contextual Representations for Relation Extraction](http://arxiv.org/abs/2306.04203) #extraction</code></li>
<li>Summary: <p>Relation extraction task is a crucial and challenging aspect of Natural
Language Processing. Several methods have surfaced as of late, exhibiting
notable performance in addressing the task; however, most of these approaches
rely on vast amounts of data from large-scale knowledge graphs or language
models pretrained on voluminous corpora. In this paper, we hone in on the
effective utilization of solely the knowledge supplied by a corpus to create a
high-performing model. Our objective is to showcase that by leveraging the
hierarchical structure and relational distribution of entities within a corpus
without introducing external knowledge, a relation extraction model can achieve
significantly enhanced performance. We therefore proposed a relation extraction
approach based on the incorporation of pretrained knowledge graph embeddings at
the corpus scale into the sentence-level contextual representation. We
conducted a series of experiments which revealed promising and very interesting
results for our proposed approach.The obtained results demonstrated an
outperformance of our method compared to context-based relation extraction
models.
</p></li>
</ul>

<h3>Title: Co-evolving Graph Reasoning Network for Emotion-Cause Pair Extraction. (arXiv:2306.04340v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04340">http://arxiv.org/abs/2306.04340</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04340] Co-evolving Graph Reasoning Network for Emotion-Cause Pair Extraction](http://arxiv.org/abs/2306.04340) #extraction</code></li>
<li>Summary: <p>Emotion-Cause Pair Extraction (ECPE) aims to extract all emotion clauses and
their corresponding cause clauses from a document. Existing approaches tackle
this task through multi-task learning (MTL) framework in which the two subtasks
provide indicative clues for ECPE. However, the previous MTL framework
considers only one round of multi-task reasoning and ignores the reverse
feedbacks from ECPE to the subtasks. Besides, its multi-task reasoning only
relies on semantics-level interactions, which cannot capture the explicit
dependencies, and both the encoder sharing and multi-task hidden states
concatenations can hardly capture the causalities. To solve these issues, we
first put forward a new MTL framework based on Co-evolving Reasoning. It (1)
models the bidirectional feedbacks between ECPE and its subtasks; (2) allows
the three tasks to evolve together and prompt each other recurrently; (3)
integrates prediction-level interactions to capture explicit dependencies. Then
we propose a novel multi-task relational graph (MRG) to sufficiently exploit
the causal relations. Finally, we propose a Co-evolving Graph Reasoning Network
(CGR-Net) that implements our MTL framework and conducts Co-evolving Reasoning
on MRG. Experimental results show that our model achieves new state-of-the-art
performance, and further analysis confirms the advantages of our method.
</p></li>
</ul>

<h3>Title: Enhancing In-Context Learning with Answer Feedback for Multi-Span Question Answering. (arXiv:2306.04508v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04508">http://arxiv.org/abs/2306.04508</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04508] Enhancing In-Context Learning with Answer Feedback for Multi-Span Question Answering](http://arxiv.org/abs/2306.04508) #extraction</code></li>
<li>Summary: <p>Whereas the recent emergence of large language models (LLMs) like ChatGPT has
exhibited impressive general performance, it still has a large gap with
fully-supervised models on specific tasks such as multi-span question
answering. Previous researches found that in-context learning is an effective
approach to exploiting LLM, by using a few task-related labeled data as
demonstration examples to construct a few-shot prompt for answering new
questions. A popular implementation is to concatenate a few questions and their
correct answers through simple templates, informing LLM of the desired output.
In this paper, we propose a novel way of employing labeled data such that it
also informs LLM of some undesired output, by extending demonstration examples
with feedback about answers predicted by an off-the-shelf model, e.g., correct,
incorrect, or incomplete. Experiments on three multi-span question answering
datasets as well as a keyphrase extraction dataset show that our new prompting
strategy consistently improves LLM's in-context learning performance.
</p></li>
</ul>

<h3>Title: Permutation Equivariant Graph Framelets for Heterophilous Semi-supervised Learning. (arXiv:2306.04265v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04265">http://arxiv.org/abs/2306.04265</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04265] Permutation Equivariant Graph Framelets for Heterophilous Semi-supervised Learning](http://arxiv.org/abs/2306.04265) #extraction</code></li>
<li>Summary: <p>The nature of heterophilous graphs is significantly different with that of
homophilous graphs, which suggests aggregations beyond 1-hop neighborhood and
causes difficulties in early graph neural network models. In this paper, we
develop a new way to implement multi-scale extraction via constructing
Haar-type graph framelets with desired properties of permutation equivariance,
efficiency, and sparsity, for deep learning tasks on graphs. We further deisgn
a graph framelet neural network model PEGFAN using our constructed graph
framelets. The experiments are conducted on a synthetic dataset and 9 benchmark
datasets to compare performance with other state-of-the-art models. The result
shows that our model can achieve best performance on certain datasets of
heterophilous graphs (including the majority of heterophilous datasets with
relatively larger sizes and denser connections) and competitive performance on
the remaining.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Phoenix: A Federated Generative Diffusion Model. (arXiv:2306.04098v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04098">http://arxiv.org/abs/2306.04098</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04098] Phoenix: A Federated Generative Diffusion Model](http://arxiv.org/abs/2306.04098) #federate</code></li>
<li>Summary: <p>Generative AI has made impressive strides in enabling users to create diverse
and realistic visual content such as images, videos, and audio. However,
training generative models on large centralized datasets can pose challenges in
terms of data privacy, security, and accessibility. Federated learning (FL) is
an approach that uses decentralized techniques to collaboratively train a
shared deep learning model while retaining the training data on individual edge
devices to preserve data privacy. This paper proposes a novel method for
training a Denoising Diffusion Probabilistic Model (DDPM) across multiple data
sources using FL techniques. Diffusion models, a newly emerging generative
model, show promising results in achieving superior quality images than
Generative Adversarial Networks (GANs). Our proposed method Phoenix is an
unconditional diffusion model that leverages strategies to improve the data
diversity of generated samples even when trained on data with statistical
heterogeneity or Non-IID (Non-Independent and Identically Distributed) data. We
demonstrate how our approach outperforms the default diffusion model in an FL
setting. These results indicate that high-quality samples can be generated by
maintaining data diversity, preserving privacy, and reducing communication
between data sources, offering exciting new possibilities in the field of
generative AI.
</p></li>
</ul>

<h3>Title: FedVal: Different good or different bad in federated learning. (arXiv:2306.04040v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04040">http://arxiv.org/abs/2306.04040</a></li>
<li>Code URL: <a href="https://github.com/viktorvaladi/fedval">https://github.com/viktorvaladi/fedval</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04040] FedVal: Different good or different bad in federated learning](http://arxiv.org/abs/2306.04040) #federate</code></li>
<li>Summary: <p>Federated learning (FL) systems are susceptible to attacks from malicious
actors who might attempt to corrupt the training model through various
poisoning attacks. FL also poses new challenges in addressing group bias, such
as ensuring fair performance for different demographic groups. Traditional
methods used to address such biases require centralized access to the data,
which FL systems do not have. In this paper, we present a novel approach FedVal
for both robustness and fairness that does not require any additional
information from clients that could raise privacy concerns and consequently
compromise the integrity of the FL system. To this end, we propose an
innovative score function based on a server-side validation method that
assesses client updates and determines the optimal aggregation balance between
locally-trained models. Our research shows that this approach not only provides
solid protection against poisoning attacks but can also be used to reduce group
bias and subsequently promote fairness while maintaining the system's
capability for differential privacy. Extensive experiments on the CIFAR-10,
FEMNIST, and PUMS ACSIncome datasets in different configurations demonstrate
the effectiveness of our method, resulting in state-of-the-art performances. We
have proven robustness in situations where 80% of participating clients are
malicious. Additionally, we have shown a significant increase in accuracy for
underrepresented labels from 32% to 53%, and increase in recall rate for
underrepresented features from 19% to 50%.
</p></li>
</ul>

<h3>Title: Fast Optimal Locally Private Mean Estimation via Random Projections. (arXiv:2306.04444v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04444">http://arxiv.org/abs/2306.04444</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04444] Fast Optimal Locally Private Mean Estimation via Random Projections](http://arxiv.org/abs/2306.04444) #federate</code></li>
<li>Summary: <p>We study the problem of locally private mean estimation of high-dimensional
vectors in the Euclidean ball. Existing algorithms for this problem either
incur sub-optimal error or have high communication and/or run-time complexity.
We propose a new algorithmic framework, ProjUnit, for private mean estimation
that yields algorithms that are computationally efficient, have low
communication complexity, and incur optimal error up to a $1+o(1)$-factor. Our
framework is deceptively simple: each randomizer projects its input to a random
low-dimensional subspace, normalizes the result, and then runs an optimal
algorithm such as PrivUnitG in the lower-dimensional space. In addition, we
show that, by appropriately correlating the random projection matrices across
devices, we can achieve fast server run-time. We mathematically analyze the
error of the algorithm in terms of properties of the random projections, and
study two instantiations. Lastly, our experiments for private mean estimation
and private federated learning demonstrate that our algorithms empirically
obtain nearly the same utility as optimal ones while having significantly lower
communication and computational cost.
</p></li>
</ul>

<h3>Title: Guiding The Last Layer in Federated Learning with Pre-Trained Models. (arXiv:2306.03937v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03937">http://arxiv.org/abs/2306.03937</a></li>
<li>Code URL: <a href="https://github.com/gwenlegate/guidinglastlayerflpretrain">https://github.com/gwenlegate/guidinglastlayerflpretrain</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03937] Guiding The Last Layer in Federated Learning with Pre-Trained Models](http://arxiv.org/abs/2306.03937) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) is an emerging paradigm that allows a model to be
trained across a number of participants without sharing data. Recent works have
begun to consider the effects of using pre-trained models as an initialization
point for existing FL algorithms; however, these approaches ignore the vast
body of efficient transfer learning literature from the centralized learning
setting. Here we revisit the problem of FL from a pre-trained model considered
in prior work and expand it to a set of computer vision transfer learning
problems. We first observe that simply fitting a linear classification head can
be efficient and effective in many cases. We then show that in the FL setting,
fitting a classifier using the Nearest Class Means (NCM) can be done exactly
and orders of magnitude more efficiently than existing proposals, while
obtaining strong performance. Finally, we demonstrate that using a two-phase
approach of obtaining the classifier and then fine-tuning the model can yield
rapid convergence and improved generalization in the federated setting. We
demonstrate the potential our method has to reduce communication and compute
costs while achieving better model performance.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Randomized 3D Scene Generation for Generalizable Self-supervised Pre-training. (arXiv:2306.04237v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04237">http://arxiv.org/abs/2306.04237</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04237] Randomized 3D Scene Generation for Generalizable Self-supervised Pre-training](http://arxiv.org/abs/2306.04237) #fair</code></li>
<li>Summary: <p>Capturing and labeling real-world 3D data is laborious and time-consuming,
which makes it costly to train strong 3D models. To address this issue,
previous works generate randomized 3D scenes and pre-train models on generated
data. Although the pre-trained models gain promising performance boosts,
previous works have two major shortcomings. First, they focus on only one
downstream task (i.e., object detection). Second, a fair comparison of
generated data is still lacking. In this work, we systematically compare data
generation methods using a unified setup. To clarify the generalization of the
pre-trained models, we evaluate their performance in multiple tasks (e.g.,
object detection and semantic segmentation) and with different pre-training
methods (e.g., masked autoencoder and contrastive learning). Moreover, we
propose a new method to generate 3D scenes with spherical harmonics. It
surpasses the previous formula-driven method with a clear margin and achieves
on-par results with methods using real-world scans and CAD models.
</p></li>
</ul>

<h3>Title: Echoes from Alexandria: A Large Resource for Multilingual Book Summarization. (arXiv:2306.04334v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04334">http://arxiv.org/abs/2306.04334</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04334] Echoes from Alexandria: A Large Resource for Multilingual Book Summarization](http://arxiv.org/abs/2306.04334) #fair</code></li>
<li>Summary: <p>In recent years, research in text summarization has mainly focused on the
news domain, where texts are typically short and have strong layout features.
The task of full-book summarization presents additional challenges which are
hard to tackle with current resources, due to their limited size and
availability in English only. To overcome these limitations, we present "Echoes
from Alexandria", or in shortened form, "Echoes", a large resource for
multilingual book summarization. Echoes features three novel datasets: i)
Echo-Wiki, for multilingual book summarization, ii) Echo-XSum, for
extremely-compressive multilingual book summarization, and iii) Echo-FairySum,
for extractive book summarization. To the best of our knowledge, Echoes, with
its thousands of books and summaries, is the largest resource, and the first to
be multilingual, featuring 5 languages and 25 language pairs. In addition to
Echoes, we also introduce a new extractive-then-abstractive baseline, and,
supported by our experimental results and manual analysis of the summaries
generated, we argue that this baseline is more suitable for book summarization
than purely-abstractive approaches. We release our resource and software at
https://github.com/Babelscape/echoes-from-alexandria in the hope of fostering
innovative research in multilingual book summarization.
</p></li>
</ul>

<h3>Title: Examining Bias in Opinion Summarisation Through the Perspective of Opinion Diversity. (arXiv:2306.04424v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04424">http://arxiv.org/abs/2306.04424</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04424] Examining Bias in Opinion Summarisation Through the Perspective of Opinion Diversity](http://arxiv.org/abs/2306.04424) #fair</code></li>
<li>Summary: <p>Opinion summarisation is a task that aims to condense the information
presented in the source documents while retaining the core message and
opinions. A summary that only represents the majority opinions will leave the
minority opinions unrepresented in the summary. In this paper, we use the
stance towards a certain target as an opinion. We study bias in opinion
summarisation from the perspective of opinion diversity, which measures whether
the model generated summary can cover a diverse set of opinions. In addition,
we examine opinion similarity, a measure of how closely related two opinions
are in terms of their stance on a given topic, and its relationship with
opinion diversity. Through the lens of stances towards a topic, we examine
opinion diversity and similarity using three debatable topics under COVID-19.
Experimental results on these topics revealed that a higher degree of
similarity of opinions did not indicate good diversity or fairly cover the
various opinions originally presented in the source documents. We found that
BART and ChatGPT can better capture diverse opinions presented in the source
documents.
</p></li>
</ul>

<h3>Title: Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions. (arXiv:2306.04597v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04597">http://arxiv.org/abs/2306.04597</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04597] Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions](http://arxiv.org/abs/2306.04597) #fair</code></li>
<li>Summary: <p>Societal biases present in pre-trained large language models are a critical
issue as these models have been shown to propagate biases in countless
downstream applications, rendering them unfair towards specific groups of
people. Since large-scale retraining of these models from scratch is both time
and compute-expensive, a variety of approaches have been previously proposed
that de-bias a pre-trained model. While the majority of current
state-of-the-art debiasing methods focus on changes to the training regime, in
this paper, we propose data intervention strategies as a powerful yet simple
technique to reduce gender bias in pre-trained models. Specifically, we
empirically show that by fine-tuning a pre-trained model on only 10 de-biased
(intervened) training examples, the tendency to favor any gender is
significantly reduced. Since our proposed method only needs a few training
examples, our few-shot debiasing approach is highly feasible and practical.
Through extensive experimentation, we show that our debiasing technique
performs better than competitive state-of-the-art baselines with minimal loss
in language modeling ability.
</p></li>
</ul>

<h3>Title: BeMap: Balanced Message Passing for Fair Graph Neural Network. (arXiv:2306.04107v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04107">http://arxiv.org/abs/2306.04107</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04107] BeMap: Balanced Message Passing for Fair Graph Neural Network](http://arxiv.org/abs/2306.04107) #fair</code></li>
<li>Summary: <p>Graph Neural Network (GNN) has shown strong empirical performance in many
downstream tasks by iteratively aggregating information from the local
neighborhood of each node, i.e., message passing. However, concrete evidence
has revealed that a graph neural network could be biased against certain
demographic groups, which calls for the consideration of algorithmic fairness.
Despite the increasing efforts in ensuring algorithmic fairness on graph neural
networks, they often do not explicitly consider the induced bias caused by
message passing in GNN during training. In this paper, we first investigate the
problem of bias amplification in message passing. We empirically and
theoretically demonstrate that message passing could amplify the bias when the
1-hop neighbors from different demographic groups are unbalanced. Guided by
such analyses, we propose BeMap, a fair message passing method, that leverages
a balance-aware sampling strategy to balance the number of the 1-hop neighbors
of each node among different demographic groups. Extensive experiments on node
classification demonstrate the efficacy of our proposed BeMap method in
mitigating bias while maintaining classification accuracy.
</p></li>
</ul>

<h3>Title: M$^3$Fair: Mitigating Bias in Healthcare Data through Multi-Level and Multi-Sensitive-Attribute Reweighting Method. (arXiv:2306.04118v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04118">http://arxiv.org/abs/2306.04118</a></li>
<li>Code URL: <a href="https://github.com/yhzhu99/m3fair">https://github.com/yhzhu99/m3fair</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04118] M$^3$Fair: Mitigating Bias in Healthcare Data through Multi-Level and Multi-Sensitive-Attribute Reweighting Method](http://arxiv.org/abs/2306.04118) #fair</code></li>
<li>Summary: <p>In the data-driven artificial intelligence paradigm, models heavily rely on
large amounts of training data. However, factors like sampling distribution
imbalance can lead to issues of bias and unfairness in healthcare data.
Sensitive attributes, such as race, gender, age, and medical condition, are
characteristics of individuals that are commonly associated with discrimination
or bias. In healthcare AI, these attributes can play a significant role in
determining the quality of care that individuals receive. For example, minority
groups often receive fewer procedures and poorer-quality medical care than
white individuals in US. Therefore, detecting and mitigating bias in data is
crucial to enhancing health equity. Bias mitigation methods include
pre-processing, in-processing, and post-processing. Among them, Reweighting
(RW) is a widely used pre-processing method that performs well in balancing
machine learning performance and fairness performance. RW adjusts the weights
for samples within each (group, label) combination, where these weights are
utilized in loss functions. However, RW is limited to considering only a single
sensitive attribute when mitigating bias and assumes that each sensitive
attribute is equally important. This may result in potential inaccuracies when
addressing intersectional bias. To address these limitations, we propose
M3Fair, a multi-level and multi-sensitive-attribute reweighting method by
extending the RW method to multiple sensitive attributes at multiple levels.
Our experiments on real-world datasets show that the approach is effective,
straightforward, and generalizable in addressing the healthcare fairness
issues.
</p></li>
</ul>

<h3>Title: Migrate Demographic Group For Fair GNNs. (arXiv:2306.04212v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04212">http://arxiv.org/abs/2306.04212</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04212] Migrate Demographic Group For Fair GNNs](http://arxiv.org/abs/2306.04212) #fair</code></li>
<li>Summary: <p>Graph Neural networks (GNNs) have been applied in many scenarios due to the
superior performance of graph learning. However, fairness is always ignored
when designing GNNs. As a consequence, biased information in training data can
easily affect vanilla GNNs, causing biased results toward particular
demographic groups (divided by sensitive attributes, such as race and age).
There have been efforts to address the fairness issue. However, existing fair
techniques generally divide the demographic groups by raw sensitive attributes
and assume that are fixed. The biased information correlated with raw sensitive
attributes will run through the training process regardless of the implemented
fair techniques. It is urgent to resolve this problem for training fair GNNs.
To tackle this problem, we propose a brand new framework, FairMigration, which
can dynamically migrate the demographic groups instead of keeping that fixed
with raw sensitive attributes. FairMigration is composed of two training
stages. In the first stage, the GNNs are initially optimized by personalized
self-supervised learning, and the demographic groups are adjusted dynamically.
In the second stage, the new demographic groups are frozen and supervised
learning is carried out under the constraints of new demographic groups and
adversarial training. Extensive experiments reveal that FairMigration balances
model performance and fairness well.
</p></li>
</ul>

<h3>Title: A Fair Classifier Embracing Triplet Collapse. (arXiv:2306.04400v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04400">http://arxiv.org/abs/2306.04400</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04400] A Fair Classifier Embracing Triplet Collapse](http://arxiv.org/abs/2306.04400) #fair</code></li>
<li>Summary: <p>In this paper, we study the behaviour of the triplet loss and show that it
can be exploited to limit the biases created and perpetuated by machine
learning models. Our fair classifier uses the collapse of the triplet loss when
its margin is greater than the maximum distance between two points in the
latent space, in the case of stochastic triplet selection.
</p></li>
</ul>

<h3>Title: Fair Column Subset Selection. (arXiv:2306.04489v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04489">http://arxiv.org/abs/2306.04489</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04489] Fair Column Subset Selection](http://arxiv.org/abs/2306.04489) #fair</code></li>
<li>Summary: <p>We consider the problem of fair column subset selection. In particular, we
assume that two groups are present in the data, and the chosen column subset
must provide a good approximation for both, relative to their respective best
rank-k approximations. We show that this fair setting introduces significant
challenges: in order to extend known results, one cannot do better than the
trivial solution of simply picking twice as many columns as the original
methods. We adopt a known approach based on deterministic leverage-score
sampling, and show that merely sampling a subset of appropriate size becomes
NP-hard in the presence of two groups. Whereas finding a subset of two times
the desired size is trivial, we provide an efficient algorithm that achieves
the same guarantees with essentially 1.5 times that size. We validate our
methods through an extensive set of experiments on real-world data.
</p></li>
</ul>

<h3>Title: Optimal Fair Multi-Agent Bandits. (arXiv:2306.04498v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04498">http://arxiv.org/abs/2306.04498</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04498] Optimal Fair Multi-Agent Bandits](http://arxiv.org/abs/2306.04498) #fair</code></li>
<li>Summary: <p>In this paper, we study the problem of fair multi-agent multi-arm bandit
learning when agents do not communicate with each other, except collision
information, provided to agents accessing the same arm simultaneously. We
provide an algorithm with regret $O\left(N^3 \log N \log T \right)$ (assuming
bounded rewards, with unknown bound). This significantly improves previous
results which had regret of order $O(\log T \log\log T)$ and exponential
dependence on the number of agents. The result is attained by using a
distributed auction algorithm to learn the sample-optimal matching, a new type
of exploitation phase whose length is derived from the observed samples, and a
novel order-statistics-based regret analysis. Simulation results present the
dependence of the regret on $\log T$.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Effective Neural Topic Modeling with Embedding Clustering Regularization. (arXiv:2306.04217v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04217">http://arxiv.org/abs/2306.04217</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04217] Effective Neural Topic Modeling with Embedding Clustering Regularization](http://arxiv.org/abs/2306.04217) #interpretability</code></li>
<li>Summary: <p>Topic models have been prevalent for decades with various applications.
However, existing topic models commonly suffer from the notorious topic
collapsing: discovered topics semantically collapse towards each other, leading
to highly repetitive topics, insufficient topic discovery, and damaged model
interpretability. In this paper, we propose a new neural topic model, Embedding
Clustering Regularization Topic Model (ECRTM). Besides the existing
reconstruction error, we propose a novel Embedding Clustering Regularization
(ECR), which forces each topic embedding to be the center of a separately
aggregated word embedding cluster in the semantic space. This enables each
produced topic to contain distinct word semantics, which alleviates topic
collapsing. Regularized by ECR, our ECRTM generates diverse and coherent topics
together with high-quality topic distributions of documents. Extensive
experiments on benchmark datasets demonstrate that ECRTM effectively addresses
the topic collapsing issue and consistently surpasses state-of-the-art
baselines in terms of topic quality, topic distributions of documents, and
downstream classification tasks.
</p></li>
</ul>

<h3>Title: World Models for Math Story Problems. (arXiv:2306.04347v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04347">http://arxiv.org/abs/2306.04347</a></li>
<li>Code URL: <a href="https://github.com/eth-nlped/mathworld">https://github.com/eth-nlped/mathworld</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04347] World Models for Math Story Problems](http://arxiv.org/abs/2306.04347) #interpretability</code></li>
<li>Summary: <p>Solving math story problems is a complex task for students and NLP models
alike, requiring them to understand the world as described in the story and
reason over it to compute an answer. Recent years have seen impressive
performance on automatically solving these problems with large pre-trained
language models and innovative techniques to prompt them. However, it remains
unclear if these models possess accurate representations of mathematical
concepts. This leads to lack of interpretability and trustworthiness which
impedes their usefulness in various applications. In this paper, we consolidate
previous work on categorizing and representing math story problems and develop
MathWorld, which is a graph-based semantic formalism specific for the domain of
math story problems. With MathWorld, we can assign world models to math story
problems which represent the situations and actions introduced in the text and
their mathematical relationships. We combine math story problems from several
existing datasets and annotate a corpus of 1,019 problems and 3,204 logical
forms with MathWorld. Using this data, we demonstrate the following use cases
of MathWorld: (1) prompting language models with synthetically generated
question-answer pairs to probe their reasoning and world modeling abilities,
and (2) generating new problems by using the world models as a design space.
</p></li>
</ul>

<h3>Title: Hardness of Deceptive Certificate Selection. (arXiv:2306.04505v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04505">http://arxiv.org/abs/2306.04505</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04505] Hardness of Deceptive Certificate Selection](http://arxiv.org/abs/2306.04505) #interpretability</code></li>
<li>Summary: <p>Recent progress towards theoretical interpretability guarantees for AI has
been made with classifiers that are based on interactive proof systems. A
prover selects a certificate from the datapoint and sends it to a verifier who
decides the class. In the context of machine learning, such a certificate can
be a feature that is informative of the class. For a setup with high soundness
and completeness, the exchanged certificates must have a high mutual
information with the true class of the datapoint. However, this guarantee
relies on a bound on the Asymmetric Feature Correlation of the dataset, a
property that so far is difficult to estimate for high-dimensional data. It was
conjectured in W\"aldchen et al. that it is computationally hard to exploit the
AFC, which is what we prove here.
</p></li>
</ul>

<p>We consider a malicious prover-verifier duo that aims to exploit the AFC to
achieve high completeness and soundness while using uninformative certificates.
We show that this task is $\mathsf{NP}$-hard and cannot be approximated better
than $\mathcal{O}(m^{1/8 - \epsilon})$, where $m$ is the number of possible
certificates, for $\epsilon>0$ under the Dense-vs-Random conjecture. This is
some evidence that AFC should not prevent the use of interactive classification
for real-world tasks, as it is computationally hard to be exploited.
</p>

<h3>Title: Generalized Teacher Forcing for Learning Chaotic Dynamics. (arXiv:2306.04406v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04406">http://arxiv.org/abs/2306.04406</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04406] Generalized Teacher Forcing for Learning Chaotic Dynamics](http://arxiv.org/abs/2306.04406) #interpretability</code></li>
<li>Summary: <p>Chaotic dynamical systems (DS) are ubiquitous in nature and society. Often we
are interested in reconstructing such systems from observed time series for
prediction or mechanistic insight, where by reconstruction we mean learning
geometrical and invariant temporal properties of the system in question (like
attractors). However, training reconstruction algorithms like recurrent neural
networks (RNNs) on such systems by gradient-descent based techniques faces
severe challenges. This is mainly due to exploding gradients caused by the
exponential divergence of trajectories in chaotic systems. Moreover, for
(scientific) interpretability we wish to have as low dimensional
reconstructions as possible, preferably in a model which is mathematically
tractable. Here we report that a surprisingly simple modification of teacher
forcing leads to provably strictly all-time bounded gradients in training on
chaotic systems, and, when paired with a simple architectural rearrangement of
a tractable RNN design, piecewise-linear RNNs (PLRNNs), allows for faithful
reconstruction in spaces of at most the dimensionality of the observed system.
We show on several DS that with these amendments we can reconstruct DS better
than current SOTA algorithms, in much lower dimensions. Performance differences
were particularly compelling on real world data with which most other methods
severely struggled. This work thus led to a simple yet powerful DS
reconstruction algorithm which is highly interpretable at the same time.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: MarineVRS: Marine Video Retrieval System with Explainability via Semantic Understanding. (arXiv:2306.04593v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04593">http://arxiv.org/abs/2306.04593</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04593] MarineVRS: Marine Video Retrieval System with Explainability via Semantic Understanding](http://arxiv.org/abs/2306.04593) #explainability</code></li>
<li>Summary: <p>Building a video retrieval system that is robust and reliable, especially for
the marine environment, is a challenging task due to several factors such as
dealing with massive amounts of dense and repetitive data, occlusion,
blurriness, low lighting conditions, and abstract queries. To address these
challenges, we present MarineVRS, a novel and flexible video retrieval system
designed explicitly for the marine domain. MarineVRS integrates
state-of-the-art methods for visual and linguistic object representation to
enable efficient and accurate search and analysis of vast volumes of underwater
video data. In addition, unlike the conventional video retrieval system, which
only permits users to index a collection of images or videos and search using a
free-form natural language sentence, our retrieval system includes an
additional Explainability module that outputs the segmentation masks of the
objects that the input query referred to. This feature allows users to identify
and isolate specific objects in the video footage, leading to more detailed
analysis and understanding of their behavior and movements. Finally, with its
adaptability, explainability, accuracy, and scalability, MarineVRS is a
powerful tool for marine researchers and scientists to efficiently and
accurately process vast amounts of data and gain deeper insights into the
behavior and movements of marine species.
</p></li>
</ul>

<h2>watermark</h2>
<h3>Title: On the Reliability of Watermarks for Large Language Models. (arXiv:2306.04634v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04634">http://arxiv.org/abs/2306.04634</a></li>
<li>Code URL: <a href="https://github.com/jwkirchenbauer/lm-watermarking">https://github.com/jwkirchenbauer/lm-watermarking</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04634] On the Reliability of Watermarks for Large Language Models](http://arxiv.org/abs/2306.04634) #watermark</code></li>
<li>Summary: <p>Large language models (LLMs) are now deployed to everyday use and positioned
to produce large quantities of text in the coming decade. Machine-generated
text may displace human-written text on the internet and has the potential to
be used for malicious purposes, such as spearphishing attacks and social media
bots. Watermarking is a simple and effective strategy for mitigating such harms
by enabling the detection and documentation of LLM-generated text. Yet, a
crucial question remains: How reliable is watermarking in realistic settings in
the wild? There, watermarked text might be mixed with other text sources,
paraphrased by human writers or other language models, and used for
applications in a broad number of domains, both social and technical. In this
paper, we explore different detection schemes, quantify their power at
detecting watermarks, and determine how much machine-generated text needs to be
observed in each scenario to reliably detect the watermark. We especially
highlight our human study, where we investigate the reliability of watermarking
when faced with human paraphrasing. We compare watermark-based detection to
other detection strategies, finding overall that watermarking is a reliable
solution, especially because of its sample complexity - for all attacks we
consider, the watermark evidence compounds the more examples are given, and the
watermark is eventually detected.
</p></li>
</ul>

<h2>diffusion</h2>
<h3>Title: Improving Diffusion-based Image Translation using Asymmetric Gradient Guidance. (arXiv:2306.04396v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04396">http://arxiv.org/abs/2306.04396</a></li>
<li>Code URL: <a href="https://github.com/submissionanon18/agg">https://github.com/submissionanon18/agg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04396] Improving Diffusion-based Image Translation using Asymmetric Gradient Guidance](http://arxiv.org/abs/2306.04396) #diffusion</code></li>
<li>Summary: <p>Diffusion models have shown significant progress in image translation tasks
recently. However, due to their stochastic nature, there's often a trade-off
between style transformation and content preservation. Current strategies aim
to disentangle style and content, preserving the source image's structure while
successfully transitioning from a source to a target domain under text or
one-shot image conditions. Yet, these methods often require computationally
intense fine-tuning of diffusion models or additional neural networks. To
address these challenges, here we present an approach that guides the reverse
process of diffusion sampling by applying asymmetric gradient guidance. This
results in quicker and more stable image manipulation for both text-guided and
image-guided image translation. Our model's adaptability allows it to be
implemented with both image- and latent-diffusion models. Experiments show that
our method outperforms various state-of-the-art models in image translation
tasks.
</p></li>
</ul>

<h3>Title: Multi-modal Latent Diffusion. (arXiv:2306.04445v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04445">http://arxiv.org/abs/2306.04445</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04445] Multi-modal Latent Diffusion](http://arxiv.org/abs/2306.04445) #diffusion</code></li>
<li>Summary: <p>Multi-modal data-sets are ubiquitous in modern applications, and multi-modal
Variational Autoencoders are a popular family of models that aim to learn a
joint representation of the different modalities. However, existing approaches
suffer from a coherence-quality tradeoff, where models with good generation
quality lack generative coherence across modalities, and vice versa. We discuss
the limitations underlying the unsatisfactory performance of existing methods,
to motivate the need for a different approach. We propose a novel method that
uses a set of independently trained, uni-modal, deterministic autoencoders.
Individual latent variables are concatenated into a common latent space, which
is fed to a masked diffusion model to enable generative modeling. We also
introduce a new multi-time training method to learn the conditional score
network for multi-modal diffusion. Our methodology substantially outperforms
competitors in both generation quality and coherence, as shown through an
extensive experimental campaign.
</p></li>
</ul>

<h3>Title: On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04542">http://arxiv.org/abs/2306.04542</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04542] On the Design Fundamentals of Diffusion Models: A Survey](http://arxiv.org/abs/2306.04542) #diffusion</code></li>
<li>Summary: <p>Diffusion models are generative models, which gradually add and remove noise
to learn the underlying distribution of training data for data generation. The
components of diffusion models have gained significant attention with many
design choices proposed. Existing reviews have primarily focused on
higher-level solutions, thereby covering less on the design fundamentals of
components. This study seeks to address this gap by providing a comprehensive
and coherent review on component-wise design choices in diffusion models.
Specifically, we organize this review according to their three key components,
namely the forward process, the reverse process, and the sampling procedure.
This allows us to provide a fine-grained perspective of diffusion models,
benefiting future studies in the analysis of individual components, the
applicability of design choices, and the implementation of diffusion models.
</p></li>
</ul>

<h3>Title: Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt. (arXiv:2306.04607v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04607">http://arxiv.org/abs/2306.04607</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04607] Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt](http://arxiv.org/abs/2306.04607) #diffusion</code></li>
<li>Summary: <p>Diffusion models have attracted significant attention due to their remarkable
ability to create content and generate data for tasks such as image
classification. However, the usage of diffusion models to generate high-quality
object detection data remains an underexplored area, where not only the
image-level perceptual quality but also geometric conditions such as bounding
boxes and camera views are essential. Previous studies have utilized either
copy-paste synthesis or layout-to-image (L2I) generation with specifically
designed modules to encode semantic layouts. In this paper, we propose
GeoDiffusion, a simple framework that can flexibly translate various geometric
conditions into text prompts and empower the pre-trained text-to-image (T2I)
diffusion models for high-quality detection data generation. Unlike previous
L2I methods, our GeoDiffusion is able to encode not only bounding boxes but
also extra geometric conditions such as camera views in self-driving scenes.
Extensive experiments demonstrate GeoDiffusion outperforms previous L2I methods
while maintaining 4x training time faster. To the best of our knowledge, this
is the first work to adopt diffusion models for layout-to-image generation with
geometric conditions and demonstrate that L2I-generated images can be
beneficial for improving the performance of object detectors.
</p></li>
</ul>

<h3>Title: Designing a Better Asymmetric VQGAN for StableDiffusion. (arXiv:2306.04632v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04632">http://arxiv.org/abs/2306.04632</a></li>
<li>Code URL: <a href="https://github.com/buxiangzhiren/asymmetric_vqgan">https://github.com/buxiangzhiren/asymmetric_vqgan</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04632] Designing a Better Asymmetric VQGAN for StableDiffusion](http://arxiv.org/abs/2306.04632) #diffusion</code></li>
<li>Summary: <p>StableDiffusion is a revolutionary text-to-image generator that is causing a
stir in the world of image generation and editing. Unlike traditional methods
that learn a diffusion model in pixel space, StableDiffusion learns a diffusion
model in the latent space via a VQGAN, ensuring both efficiency and quality. It
not only supports image generation tasks, but also enables image editing for
real images, such as image inpainting and local editing. However, we have
observed that the vanilla VQGAN used in StableDiffusion leads to significant
information loss, causing distortion artifacts even in non-edited image
regions. To this end, we propose a new asymmetric VQGAN with two simple
designs. Firstly, in addition to the input from the encoder, the decoder
contains a conditional branch that incorporates information from task-specific
priors, such as the unmasked image region in inpainting. Secondly, the decoder
is much heavier than the encoder, allowing for more detailed recovery while
only slightly increasing the total inference cost. The training cost of our
asymmetric VQGAN is cheap, and we only need to retrain a new asymmetric decoder
while keeping the vanilla VQGAN encoder and StableDiffusion unchanged. Our
asymmetric VQGAN can be widely used in StableDiffusion-based inpainting and
local editing methods. Extensive experiments demonstrate that it can
significantly improve the inpainting and editing performance, while maintaining
the original text-to-image capability. The code is available at
\url{https://github.com/buxiangzhiren/Asymmetric_VQGAN}.
</p></li>
</ul>

<h3>Title: Randomized Schur Complement Views for Graph Contrastive Learning. (arXiv:2306.04004v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04004">http://arxiv.org/abs/2306.04004</a></li>
<li>Code URL: <a href="https://github.com/kvignesh1420/rlap">https://github.com/kvignesh1420/rlap</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04004] Randomized Schur Complement Views for Graph Contrastive Learning](http://arxiv.org/abs/2306.04004) #diffusion</code></li>
<li>Summary: <p>We introduce a randomized topological augmentor based on Schur complements
for Graph Contrastive Learning (GCL). Given a graph laplacian matrix, the
technique generates unbiased approximations of its Schur complements and treats
the corresponding graphs as augmented views. We discuss the benefits of our
approach, provide theoretical justifications and present connections with graph
diffusion. Unlike previous efforts, we study the empirical effectiveness of the
augmentor in a controlled fashion by varying the design choices for subsequent
GCL phases, such as encoding and contrasting. Extensive experiments on node and
graph classification benchmarks demonstrate that our technique consistently
outperforms pre-defined and adaptive augmentation approaches to achieve
state-of-the-art results.
</p></li>
</ul>

<h3>Title: MESSY Estimation: Maximum-Entropy based Stochastic and Symbolic densitY Estimation. (arXiv:2306.04120v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04120">http://arxiv.org/abs/2306.04120</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04120] MESSY Estimation: Maximum-Entropy based Stochastic and Symbolic densitY Estimation](http://arxiv.org/abs/2306.04120) #diffusion</code></li>
<li>Summary: <p>We introduce MESSY estimation, a Maximum-Entropy based Stochastic and
Symbolic densitY estimation method. The proposed approach recovers probability
density functions symbolically from samples using moments of a Gradient flow in
which the ansatz serves as the driving force. In particular, we construct a
gradient-based drift-diffusion process that connects samples of the unknown
distribution function to a guess symbolic expression. We then show that when
the guess distribution has the maximum entropy form, the parameters of this
distribution can be found efficiently by solving a linear system of equations
constructed using the moments of the provided samples. Furthermore, we use
Symbolic regression to explore the space of smooth functions and find optimal
basis functions for the exponent of the maximum entropy functional leading to
good conditioning. The cost of the proposed method in each iteration of the
random search is linear with the number of samples and quadratic with the
number of basis functions. We validate the proposed MESSY estimation method
against other benchmark methods for the case of a bi-modal and a discontinuous
density, as well as a density at the limit of physical realizability. We find
that the addition of a symbolic search for basis functions improves the
accuracy of the estimation at a reasonable additional computational cost. Our
results suggest that the proposed method outperforms existing density recovery
methods in the limit of a small to moderate number of samples by providing a
low-bias and tractable symbolic description of the unknown density at a
reasonable computational cost.
</p></li>
</ul>

<h3>Title: A Survey on Generative Diffusion Models for Structured Data. (arXiv:2306.04139v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04139">http://arxiv.org/abs/2306.04139</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04139] A Survey on Generative Diffusion Models for Structured Data](http://arxiv.org/abs/2306.04139) #diffusion</code></li>
<li>Summary: <p>In recent years, generative diffusion models have achieved a rapid paradigm
shift in deep generative models by showing groundbreaking performance across
various applications. Meanwhile, structured data, encompassing tabular and time
series data, has been received comparatively limited attention from the deep
learning research community, despite its omnipresence and extensive
applications. Thus, there is still a lack of literature and its review on
structured data modelling via diffusion models, compared to other data
modalities such as computer vision and natural language processing. Hence, in
this paper, we present a comprehensive review of recently proposed diffusion
models in the field of structured data. First, this survey provides a concise
overview of the score-based diffusion model theory, subsequently proceeding to
the technical descriptions of the majority of pioneering works using structured
data in both data-driven general tasks and domain-specific applications.
Thereafter, we analyse and discuss the limitations and challenges shown in
existing works and suggest potential research directions. We hope this review
serves as a catalyst for the research community, promoting the developments in
generative diffusion models for structured data.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Energy-Based Models for Cross-Modal Localization using Convolutional Transformers. (arXiv:2306.04021v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04021">http://arxiv.org/abs/2306.04021</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04021] Energy-Based Models for Cross-Modal Localization using Convolutional Transformers](http://arxiv.org/abs/2306.04021) #transformer</code></li>
<li>Summary: <p>We present a novel framework using Energy-Based Models (EBMs) for localizing
a ground vehicle mounted with a range sensor against satellite imagery in the
absence of GPS. Lidar sensors have become ubiquitous on autonomous vehicles for
describing its surrounding environment. Map priors are typically built using
the same sensor modality for localization purposes. However, these map building
endeavors using range sensors are often expensive and time-consuming.
Alternatively, we leverage the use of satellite images as map priors, which are
widely available, easily accessible, and provide comprehensive coverage. We
propose a method using convolutional transformers that performs accurate
metric-level localization in a cross-modal manner, which is challenging due to
the drastic difference in appearance between the sparse range sensor readings
and the rich satellite imagery. We train our model end-to-end and demonstrate
our approach achieving higher accuracy than the state-of-the-art on KITTI,
Pandaset, and a custom dataset.
</p></li>
</ul>

<h3>Title: BokehOrNot: Transforming Bokeh Effect with Image Transformer and Lens Metadata Embedding. (arXiv:2306.04032v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04032">http://arxiv.org/abs/2306.04032</a></li>
<li>Code URL: <a href="https://github.com/indicator0/bokehornot">https://github.com/indicator0/bokehornot</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04032] BokehOrNot: Transforming Bokeh Effect with Image Transformer and Lens Metadata Embedding](http://arxiv.org/abs/2306.04032) #transformer</code></li>
<li>Summary: <p>Bokeh effect is an optical phenomenon that offers a pleasant visual
experience, typically generated by high-end cameras with wide aperture lenses.
The task of bokeh effect transformation aims to produce a desired effect in one
set of lenses and apertures based on another combination. Current models are
limited in their ability to render a specific set of bokeh effects, primarily
transformations from sharp to blur. In this paper, we propose a novel universal
method for embedding lens metadata into the model and introducing a loss
calculation method using alpha masks from the newly released Bokeh Effect
Transformation Dataset(BETD) [3]. Based on the above techniques, we propose the
BokehOrNot model, which is capable of producing both blur-to-sharp and
sharp-to-blur bokeh effect with various combinations of lenses and aperture
sizes. Our proposed model outperforms current leading bokeh rendering and image
restoration models and renders visually natural bokeh effects. Our code is
available at: https://github.com/indicator0/bokehornot.
</p></li>
</ul>

<h3>Title: Efficient Vision Transformer for Human Pose Estimation via Patch Selection. (arXiv:2306.04225v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04225">http://arxiv.org/abs/2306.04225</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04225] Efficient Vision Transformer for Human Pose Estimation via Patch Selection](http://arxiv.org/abs/2306.04225) #transformer</code></li>
<li>Summary: <p>While Convolutional Neural Networks (CNNs) have been widely successful in 2D
human pose estimation, Vision Transformers (ViTs) have emerged as a promising
alternative to CNNs, boosting state-of-the-art performance. However, the
quadratic computational complexity of ViTs has limited their applicability for
processing high-resolution images and long videos. To address this challenge,
we propose a simple method for reducing ViT's computational complexity based on
selecting and processing a small number of most informative patches while
disregarding others. We leverage a lightweight pose estimation network to guide
the patch selection process, ensuring that the selected patches contain the
most important information. Our experimental results on three widely used 2D
pose estimation benchmarks, namely COCO, MPII and OCHuman, demonstrate the
effectiveness of our proposed methods in significantly improving speed and
reducing computational complexity with a slight drop in performance.
</p></li>
</ul>

<h3>Title: Normalization Layers Are All That Sharpness-Aware Minimization Needs. (arXiv:2306.04226v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04226">http://arxiv.org/abs/2306.04226</a></li>
<li>Code URL: <a href="https://github.com/mueller-mp/sam-on">https://github.com/mueller-mp/sam-on</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04226] Normalization Layers Are All That Sharpness-Aware Minimization Needs](http://arxiv.org/abs/2306.04226) #transformer</code></li>
<li>Summary: <p>Sharpness-aware minimization (SAM) was proposed to reduce sharpness of minima
and has been shown to enhance generalization performance in various settings.
In this work we show that perturbing only the affine normalization parameters
(comprising less than 0.1% of the total parameters) in the adversarial step of
SAM outperforms perturbing all of the parameters. This finding generalizes to
different SAM variants and both ResNet (Batch Normalization) and Vision
Transformer (Layer Normalization) architectures. We consider alternative sparse
perturbation approaches and find that these do not achieve similar performance
enhancement at such extreme sparsity levels, showing that this behaviour is
unique to the normalization layers. Although our findings reaffirm the
effectiveness of SAM in improving generalization performance, they cast doubt
on whether this is solely caused by reduced sharpness. The code for our
experiments is publicly available at https://github.com/mueller-mp/SAM-ON.
</p></li>
</ul>

<h3>Title: Revising deep learning methods in parking lot occupancy detection. (arXiv:2306.04288v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04288">http://arxiv.org/abs/2306.04288</a></li>
<li>Code URL: <a href="https://github.com/eighonet/parking-research">https://github.com/eighonet/parking-research</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04288] Revising deep learning methods in parking lot occupancy detection](http://arxiv.org/abs/2306.04288) #transformer</code></li>
<li>Summary: <p>Parking guidance systems have recently become a popular trend as a part of
the smart cities' paradigm of development. The crucial part of such systems is
the algorithm allowing drivers to search for available parking lots across
regions of interest. The classic approach to this task is based on the
application of neural network classifiers to camera records. However, existing
systems demonstrate a lack of generalization ability and appropriate testing
regarding specific visual conditions. In this study, we extensively evaluate
state-of-the-art parking lot occupancy detection algorithms, compare their
prediction quality with the recently emerged vision transformers, and propose a
new pipeline based on EfficientNet architecture. Performed computational
experiments have demonstrated the performance increase in the case of our
model, which was evaluated on 5 different datasets.
</p></li>
</ul>

<h3>Title: Sentiment Analysis in Finance: From Transformers Back to eXplainable Lexicons (XLex). (arXiv:2306.03997v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03997">http://arxiv.org/abs/2306.03997</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03997] Sentiment Analysis in Finance: From Transformers Back to eXplainable Lexicons (XLex)](http://arxiv.org/abs/2306.03997) #transformer</code></li>
<li>Summary: <p>Lexicon-based sentiment analysis (SA) in finance leverages specialized,
manually annotated lexicons created by human experts to extract sentiment from
financial texts. Although lexicon-based methods are simple to implement and
fast to operate on textual data, they require considerable manual annotation
efforts to create, maintain, and update the lexicons. These methods are also
considered inferior to the deep learning-based approaches, such as transformer
models, which have become dominant in various NLP tasks due to their remarkable
performance. However, transformers require extensive data and computational
resources for both training and testing. Additionally, they involve significant
prediction times, making them unsuitable for real-time production environments
or systems with limited processing capabilities. In this paper, we introduce a
novel methodology named eXplainable Lexicons (XLex) that combines the
advantages of both lexicon-based methods and transformer models. We propose an
approach that utilizes transformers and SHapley Additive exPlanations (SHAP)
for explainability to learn financial lexicons. Our study presents four main
contributions. Firstly, we demonstrate that transformer-aided explainable
lexicons can enhance the vocabulary coverage of the benchmark Loughran-McDonald
(LM) lexicon, reducing the human involvement in annotating, maintaining, and
updating the lexicons. Secondly, we show that the resulting lexicon outperforms
the standard LM lexicon in SA of financial datasets. Thirdly, we illustrate
that the lexicon-based approach is significantly more efficient in terms of
model speed and size compared to transformers. Lastly, the XLex approach is
inherently more interpretable than transformer models as lexicon models rely on
predefined rules, allowing for better insights into the results of SA and
making the XLex approach a viable tool for financial decision-making.
</p></li>
</ul>

<h3>Title: Transfer Learning of Transformer-based Speech Recognition Models from Czech to Slovak. (arXiv:2306.04399v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04399">http://arxiv.org/abs/2306.04399</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04399] Transfer Learning of Transformer-based Speech Recognition Models from Czech to Slovak](http://arxiv.org/abs/2306.04399) #transformer</code></li>
<li>Summary: <p>In this paper, we are comparing several methods of training the Slovak speech
recognition models based on the Transformers architecture. Specifically, we are
exploring the approach of transfer learning from the existing Czech pre-trained
Wav2Vec 2.0 model into Slovak. We are demonstrating the benefits of the
proposed approach on three Slovak datasets. Our Slovak models scored the best
results when initializing the weights from the Czech model at the beginning of
the pre-training phase. Our results show that the knowledge stored in the Cezch
pre-trained model can be successfully reused to solve tasks in Slovak while
outperforming even much larger public multilingual models.
</p></li>
</ul>

<h3>Title: Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers. (arXiv:2306.04504v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04504">http://arxiv.org/abs/2306.04504</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04504] Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers](http://arxiv.org/abs/2306.04504) #transformer</code></li>
<li>Summary: <p>ChatGPT is a large language model developed by OpenAI. Despite its impressive
performance across various tasks, no prior work has investigated its capability
in the biomedical domain yet. To this end, this paper aims to evaluate the
performance of ChatGPT on various benchmark biomedical tasks, such as relation
extraction, document classification, question answering, and summarization. To
the best of our knowledge, this is the first work that conducts an extensive
evaluation of ChatGPT in the biomedical domain. Interestingly, we find based on
our evaluation that in biomedical datasets that have smaller training sets,
zero-shot ChatGPT even outperforms the state-of-the-art fine-tuned generative
transformer models, such as BioGPT and BioBART. This suggests that ChatGPT's
pre-training on large text corpora makes it quite specialized even in the
biomedical domain. Our findings demonstrate that ChatGPT has the potential to
be a valuable tool for various tasks in the biomedical domain that lack large
annotated data.
</p></li>
</ul>

<h3>Title: Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection. (arXiv:2306.04637v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04637">http://arxiv.org/abs/2306.04637</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04637] Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection](http://arxiv.org/abs/2306.04637) #transformer</code></li>
<li>Summary: <p>Neural sequence models based on the transformer architecture have
demonstrated remarkable \emph{in-context learning} (ICL) abilities, where they
can perform new tasks when prompted with training and test examples, without
any parameter update to the model. This work first provides a comprehensive
statistical theory for transformers to perform ICL. Concretely, we show that
transformers can implement a broad class of standard machine learning
algorithms in context, such as least squares, ridge regression, Lasso, learning
generalized linear models, and gradient descent on two-layer neural networks,
with near-optimal predictive power on various in-context data distributions.
Using an efficient implementation of in-context gradient descent as the
underlying mechanism, our transformer constructions admit mild size bounds, and
can be learned with polynomially many pretraining sequences.
</p></li>
</ul>

<p>Building on these ``base'' ICL algorithms, intriguingly, we show that
transformers can implement more complex ICL procedures involving
\emph{in-context algorithm selection}, akin to what a statistician can do in
real life -- A \emph{single} transformer can adaptively select different base
ICL algorithms -- or even perform qualitatively different tasks -- on different
input sequences, without any explicit prompting of the right algorithm or task.
We both establish this in theory by explicit constructions, and also observe
this phenomenon experimentally. In theory, we construct two general mechanisms
for algorithm selection with concrete examples: pre-ICL testing, and post-ICL
validation. As an example, we use the post-ICL validation mechanism to
construct a transformer that can perform nearly Bayes-optimal ICL on a
challenging task -- noisy linear models with mixed noise levels.
Experimentally, we demonstrate the strong in-context algorithm selection
capabilities of standard transformer architectures.
</p>

<h3>Title: Proximity-Informed Calibration for Deep Neural Networks. (arXiv:2306.04590v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04590">http://arxiv.org/abs/2306.04590</a></li>
<li>Code URL: <a href="https://github.com/miaoxiong2320/proximitybias-calibration">https://github.com/miaoxiong2320/proximitybias-calibration</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04590] Proximity-Informed Calibration for Deep Neural Networks](http://arxiv.org/abs/2306.04590) #transformer</code></li>
<li>Summary: <p>Confidence calibration is central to providing accurate and interpretable
uncertainty estimates, especially under safety-critical scenarios. However, we
find that existing calibration algorithms often overlook the issue of proximity
bias, a phenomenon where models tend to be more overconfident in low proximity
data (i.e., lying in the sparse region of the data distribution) compared to
high proximity samples, and thus suffer from inconsistent miscalibration across
different proximity samples. We examine the problem over pretrained ImageNet
models and observe that: 1) Proximity bias exists across a wide variety of
model architectures and sizes; 2) Transformer-based models are more susceptible
to proximity bias than CNN-based models; 3) Proximity bias persists even after
performing popular calibration algorithms like temperature scaling; 4) Models
tend to overfit more heavily on low proximity samples than on high proximity
samples. Motivated by the empirical findings, we propose ProCal, a
plug-and-play algorithm with a theoretical guarantee to adjust sample
confidence based on proximity. To further quantify the effectiveness of
calibration algorithms in mitigating proximity bias, we introduce
proximity-informed expected calibration error (PIECE) with theoretical
analysis. We show that ProCal is effective in addressing proximity bias and
improving calibration on balanced, long-tail, and distribution-shift settings
under four metrics over various model architectures.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image Translation. (arXiv:2306.04636v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04636">http://arxiv.org/abs/2306.04636</a></li>
<li>Code URL: <a href="https://github.com/williamyang1991/gp-unit">https://github.com/williamyang1991/gp-unit</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04636] GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image Translation](http://arxiv.org/abs/2306.04636) #generative</code></li>
<li>Summary: <p>Recent advances in deep learning have witnessed many successful unsupervised
image-to-image translation models that learn correspondences between two visual
domains without paired data. However, it is still a great challenge to build
robust mappings between various domains especially for those with drastic
visual discrepancies. In this paper, we introduce a novel versatile framework,
Generative Prior-guided UNsupervised Image-to-image Translation (GP-UNIT), that
improves the quality, applicability and controllability of the existing
translation models. The key idea of GP-UNIT is to distill the generative prior
from pre-trained class-conditional GANs to build coarse-level cross-domain
correspondences, and to apply the learned prior to adversarial translations to
excavate fine-level correspondences. With the learned multi-level content
correspondences, GP-UNIT is able to perform valid translations between both
close domains and distant domains. For close domains, GP-UNIT can be
conditioned on a parameter to determine the intensity of the content
correspondences during translation, allowing users to balance between content
and style consistency. For distant domains, semi-supervised learning is
explored to guide GP-UNIT to discover accurate semantic correspondences that
are hard to learn solely from the appearance. We validate the superiority of
GP-UNIT over state-of-the-art translation models in robust, high-quality and
diversified translations between various domains through extensive experiments.
</p></li>
</ul>

<h3>Title: Augmenting Reddit Posts to Determine Wellness Dimensions impacting Mental Health. (arXiv:2306.04059v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04059">http://arxiv.org/abs/2306.04059</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04059] Augmenting Reddit Posts to Determine Wellness Dimensions impacting Mental Health](http://arxiv.org/abs/2306.04059) #generative</code></li>
<li>Summary: <p>Amid ongoing health crisis, there is a growing necessity to discern possible
signs of Wellness Dimensions (WD) manifested in self-narrated text. As the
distribution of WD on social media data is intrinsically imbalanced, we
experiment the generative NLP models for data augmentation to enable further
improvement in the pre-screening task of classifying WD. To this end, we
propose a simple yet effective data augmentation approach through prompt-based
Generative NLP models, and evaluate the ROUGE scores and syntactic/semantic
similarity among existing interpretations and augmented data. Our approach with
ChatGPT model surpasses all the other methods and achieves improvement over
baselines such as Easy-Data Augmentation and Backtranslation. Introducing data
augmentation to generate more training samples and balanced dataset, results in
the improved F-score and the Matthew's Correlation Coefficient for upto 13.11%
and 15.95%, respectively.
</p></li>
</ul>

<h3>Title: Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation. (arXiv:2306.04101v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04101">http://arxiv.org/abs/2306.04101</a></li>
<li>Code URL: <a href="https://github.com/xiusic/gotta">https://github.com/xiusic/gotta</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04101] Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation](http://arxiv.org/abs/2306.04101) #generative</code></li>
<li>Summary: <p>Few-shot question answering (QA) aims at precisely discovering answers to a
set of questions from context passages while only a few training samples are
available. Although existing studies have made some progress and can usually
achieve proper results, they suffer from understanding deep semantics for
reasoning out the questions. In this paper, we develop Gotta, a Generative
prOmpT-based daTa Augmentation framework to mitigate the challenge above.
Inspired by the human reasoning process, we propose to integrate the cloze task
to enhance few-shot QA learning. Following the recent success of prompt-tuning,
we present the cloze task in the same format as the main QA task, allowing the
model to learn both tasks seamlessly together to fully take advantage of the
power of prompt-tuning. Extensive experiments on widely used benchmarks
demonstrate that Gotta consistently outperforms competitive baselines,
validating the effectiveness of our proposed prompt-tuning-based cloze task,
which not only fine-tunes language models but also learns to guide reasoning in
QA tasks. Further analysis shows that the prompt-based loss incorporates the
auxiliary task better than the multi-task loss, highlighting the strength of
prompt-tuning on the few-shot QA task.
</p></li>
</ul>

<h3>Title: From the One, Judge of the Whole: Typed Entailment Graph Construction with Predicate Generation. (arXiv:2306.04170v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04170">http://arxiv.org/abs/2306.04170</a></li>
<li>Code URL: <a href="https://github.com/zacharychenpk/tp-egg">https://github.com/zacharychenpk/tp-egg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04170] From the One, Judge of the Whole: Typed Entailment Graph Construction with Predicate Generation](http://arxiv.org/abs/2306.04170) #generative</code></li>
<li>Summary: <p>Entailment Graphs (EGs) have been constructed based on extracted corpora as a
strong and explainable form to indicate context-independent entailment
relations in natural languages. However, EGs built by previous methods often
suffer from the severe sparsity issues, due to limited corpora available and
the long-tail phenomenon of predicate distributions. In this paper, we propose
a multi-stage method, Typed Predicate-Entailment Graph Generator (TP-EGG), to
tackle this problem. Given several seed predicates, TP-EGG builds the graphs by
generating new predicates and detecting entailment relations among them. The
generative nature of TP-EGG helps us leverage the recent advances from large
pretrained language models (PLMs), while avoiding the reliance on carefully
prepared corpora. Experiments on benchmark datasets show that TP-EGG can
generate high-quality and scale-controllable entailment graphs, achieving
significant in-domain improvement over state-of-the-art EGs and boosting the
performance of down-stream inference tasks.
</p></li>
</ul>

<h3>Title: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems. (arXiv:2306.04357v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04357">http://arxiv.org/abs/2306.04357</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04357] ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems](http://arxiv.org/abs/2306.04357) #generative</code></li>
<li>Summary: <p>Dialogue response selection aims to select an appropriate response from
several candidates based on a given user and system utterance history. Recent
studies have been improving the accuracy of dialogue response selection through
post-training, mostly relying on naive masked language modeling methods.
However, the recently developed generative methods have shown promising text
representation capabilities in IR community, which could potentially lead to
better dialogue semantics modeling. Thus, in this paper, we propose Dial-MAE
(Dialogue Contextual Masking Auto-encoder), a straightforward yet effective
post-training technique tailored for dialogue response selection. Dial-MAE uses
an asymmetric encoder-decoder architecture that learns to better compress the
semantics of the dialogue into dialogue-dense vectors. The process of Dial-MAE
involves a deep encoder creating a dialogue embedding with the masked dialogue
context, followed by a shallow decoder that uses this embedding along with the
highly masked response to restore the original response. Our experiments have
demonstrated that Dial-MAE is highly effective, achieving state-of-the-art
performance on two commonly evaluated benchmarks.
</p></li>
</ul>

<h3>Title: Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning. (arXiv:2306.04551v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04551">http://arxiv.org/abs/2306.04551</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04551] Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning](http://arxiv.org/abs/2306.04551) #generative</code></li>
<li>Summary: <p>Generative artificial intelligence (AI) is a promising direction for
augmenting clinical diagnostic decision support and reducing diagnostic errors,
a leading contributor to medical errors. To further the development of clinical
AI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a
comprehensive generative AI framework, comprised of six tasks representing key
components in clinical reasoning. We present a comparative analysis of
in-domain versus out-of-domain language models as well as multi-task versus
single task training with a focus on the problem summarization task in DR.BENCH
(Gao et al., 2023). We demonstrate that a multi-task, clinically trained
language model outperforms its general domain counterpart by a large margin,
establishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.
This research underscores the value of domain-specific training for optimizing
clinical diagnostic reasoning tasks.
</p></li>
</ul>

<h3>Title: Learning Causal Mechanisms through Orthogonal Neural Networks. (arXiv:2306.03938v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03938">http://arxiv.org/abs/2306.03938</a></li>
<li>Code URL: <a href="https://github.com/causalpodnn/causalpodnn">https://github.com/causalpodnn/causalpodnn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03938] Learning Causal Mechanisms through Orthogonal Neural Networks](http://arxiv.org/abs/2306.03938) #generative</code></li>
<li>Summary: <p>A fundamental feature of human intelligence is the ability to infer
high-level abstractions from low-level sensory data. An essential component of
such inference is the ability to discover modularized generative mechanisms.
Despite many efforts to use statistical learning and pattern recognition for
finding disentangled factors, arguably human intelligence remains unmatched in
this area.
</p></li>
</ul>

<p>In this paper, we investigate a problem of learning, in a fully unsupervised
manner, the inverse of a set of independent mechanisms from distorted data
points. We postulate, and justify this claim with experimental results, that an
important weakness of existing machine learning solutions lies in the
insufficiency of cross-module diversification. Addressing this crucial
discrepancy between human and machine intelligence is an important challenge
for pattern recognition systems.
</p>
<p>To this end, our work proposes an unsupervised method that discovers and
disentangles a set of independent mechanisms from unlabeled data, and learns
how to invert them. A number of experts compete against each other for
individual data points in an adversarial setting: one that best inverses the
(unknown) generative mechanism is the winner. We demonstrate that introducing
an orthogonalization layer into the expert architectures enforces additional
diversity in the outputs, leading to significantly better separability.
Moreover, we propose a procedure for relocating data points between experts to
further prevent any one from claiming multiple mechanisms. We experimentally
illustrate that these techniques allow discovery and modularization of much
less pronounced transformations, in addition to considerably faster
convergence.
</p>

<h3>Title: Partial Inference in Structured Prediction. (arXiv:2306.03949v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03949">http://arxiv.org/abs/2306.03949</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03949] Partial Inference in Structured Prediction](http://arxiv.org/abs/2306.03949) #generative</code></li>
<li>Summary: <p>In this paper, we examine the problem of partial inference in the context of
structured prediction. Using a generative model approach, we consider the task
of maximizing a score function with unary and pairwise potentials in the space
of labels on graphs. Employing a two-stage convex optimization algorithm for
label recovery, we analyze the conditions under which a majority of the labels
can be recovered. We introduce a novel perspective on the Karush-Kuhn-Tucker
(KKT) conditions and primal and dual construction, and provide statistical and
topological requirements for partial recovery with provable guarantees.
</p></li>
</ul>

<h3>Title: One-Dimensional Deep Image Prior for Curve Fitting of S-Parameters from Electromagnetic Solvers. (arXiv:2306.04001v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04001">http://arxiv.org/abs/2306.04001</a></li>
<li>Code URL: <a href="https://github.com/sriram-ravula/curvefitting-dip">https://github.com/sriram-ravula/curvefitting-dip</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04001] One-Dimensional Deep Image Prior for Curve Fitting of S-Parameters from Electromagnetic Solvers](http://arxiv.org/abs/2306.04001) #generative</code></li>
<li>Summary: <p>A key problem when modeling signal integrity for passive filters and
interconnects in IC packages is the need for multiple S-parameter measurements
within a desired frequency band to obtain adequate resolution. These samples
are often computationally expensive to obtain using electromagnetic (EM) field
solvers. Therefore, a common approach is to select a small subset of the
necessary samples and use an appropriate fitting mechanism to recreate a
densely-sampled broadband representation. We present the first deep generative
model-based approach to fit S-parameters from EM solvers using one-dimensional
Deep Image Prior (DIP). DIP is a technique that optimizes the weights of a
randomly-initialized convolutional neural network to fit a signal from noisy or
under-determined measurements. We design a custom architecture and propose a
novel regularization inspired by smoothing splines that penalizes discontinuous
jumps. We experimentally compare DIP to publicly available and proprietary
industrial implementations of Vector Fitting (VF), the industry-standard tool
for fitting S-parameters. Relative to publicly available implementations of VF,
our method shows superior performance on nearly all test examples using only
5-15% of the frequency samples. Our method is also competitive to proprietary
VF tools and often outperforms them for challenging input instances.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks. (arXiv:2306.04362v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04362">http://arxiv.org/abs/2306.04362</a></li>
<li>Code URL: <a href="https://github.com/x-plug/youku-mplug">https://github.com/x-plug/youku-mplug</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04362] Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks](http://arxiv.org/abs/2306.04362) #large language model</code></li>
<li>Summary: <p>To promote the development of Vision-Language Pre-training (VLP) and
multimodal Large Language Model (LLM) in the Chinese community, we firstly
release the largest public Chinese high-quality video-language dataset named
Youku-mPLUG, which is collected from Youku, a well-known Chinese video-sharing
website, with strict criteria of safety, diversity, and quality. Youku-mPLUG
contains 10 million Chinese video-text pairs filtered from 400 million raw
videos across a wide range of 45 diverse categories for large-scale
pre-training. In addition, to facilitate a comprehensive evaluation of
video-language models, we carefully build the largest human-annotated Chinese
benchmarks covering three popular video-language tasks of cross-modal
retrieval, video captioning, and video category classification. Youku-mPLUG can
enable researchers to conduct more in-depth multimodal research and develop
better applications in the future. Furthermore, we release popular
video-language pre-training models, ALPRO and mPLUG-2, and our proposed
modularized decoder-only model mPLUG-video pre-trained on Youku-mPLUG.
Experiments show that models pre-trained on Youku-mPLUG gain up to 23.1%
improvement in video category classification. Besides, mPLUG-video achieves a
new state-of-the-art result on these benchmarks with 80.5% top-1 accuracy in
video category classification and 68.9 CIDEr score in video captioning,
respectively. Finally, we scale up mPLUG-video based on the frozen Bloomz with
only 1.7% trainable parameters as Chinese multimodal LLM, and demonstrate
impressive instruction and video understanding ability. The zero-shot
instruction understanding experiment indicates that pretraining with
Youku-mPLUG can enhance the ability to comprehend overall and detailed visual
semantics, recognize scene text, and leverage open-domain knowledge.
</p></li>
</ul>

<h3>Title: M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning. (arXiv:2306.04387v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04387">http://arxiv.org/abs/2306.04387</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04387] M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning](http://arxiv.org/abs/2306.04387) #large language model</code></li>
<li>Summary: <p>Instruction tuning has significantly advanced large language models (LLMs)
such as ChatGPT, enabling them to align with human instructions across diverse
tasks. However, progress in open vision-language models (VLMs) has been limited
due to the scarcity of high-quality instruction datasets. To tackle this
challenge and promote research in the vision-language field, we introduce the
Multi-Modal, Multilingual Instruction Tuning (M$^3$IT) dataset, designed to
optimize VLM alignment with human instructions. Our M$^3$IT dataset comprises
40 carefully curated datasets, including 2.4 million instances and 400 manually
written task instructions, reformatted into a vision-to-text structure. Key
tasks are translated into 80 languages with an advanced translation system,
ensuring broader accessibility. M$^3$IT surpasses previous datasets regarding
task coverage, instruction number and instance scale. Moreover, we develop
Ying-VLM, a VLM model trained on our M$^3$IT dataset, showcasing its potential
to answer complex questions requiring world knowledge, generalize to unseen
video tasks, and comprehend unseen instructions in Chinese. To encourage
further research, we have open-sourced both the dataset and trained models.
</p></li>
</ul>

<h3>Title: Turning large language models into cognitive models. (arXiv:2306.03917v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03917">http://arxiv.org/abs/2306.03917</a></li>
<li>Code URL: <a href="https://github.com/marcelbinz/centaur">https://github.com/marcelbinz/centaur</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03917] Turning large language models into cognitive models](http://arxiv.org/abs/2306.03917) #large language model</code></li>
<li>Summary: <p>Large language models are powerful systems that excel at many tasks, ranging
from translation to mathematical reasoning. Yet, at the same time, these models
often show unhuman-like characteristics. In the present paper, we address this
gap and ask whether large language models can be turned into cognitive models.
We find that -- after finetuning them on data from psychological experiments --
these models offer accurate representations of human behavior, even
outperforming traditional cognitive models in two decision-making domains. In
addition, we show that their representations contain the information necessary
to model behavior on the level of individual subjects. Finally, we demonstrate
that finetuning on multiple tasks enables large language models to predict
human behavior in a previously unseen task. Taken together, these results
suggest that large, pre-trained models can be adapted to become generalist
cognitive models, thereby opening up new research directions that could
transform cognitive psychology and the behavioral sciences as a whole.
</p></li>
</ul>

<h3>Title: MISGENDERED: Limits of Large Language Models in Understanding Pronouns. (arXiv:2306.03950v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03950">http://arxiv.org/abs/2306.03950</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03950] MISGENDERED: Limits of Large Language Models in Understanding Pronouns](http://arxiv.org/abs/2306.03950) #large language model</code></li>
<li>Summary: <p>Content Warning: This paper contains examples of misgendering and erasure
that could be offensive and potentially triggering.
</p></li>
</ul>

<p>Gender bias in language technologies has been widely studied, but research
has mostly been restricted to a binary paradigm of gender. It is essential also
to consider non-binary gender identities, as excluding them can cause further
harm to an already marginalized group. In this paper, we comprehensively
evaluate popular language models for their ability to correctly use English
gender-neutral pronouns (e.g., singular they, them) and neo-pronouns (e.g., ze,
xe, thon) that are used by individuals whose gender identity is not represented
by binary pronouns. We introduce MISGENDERED, a framework for evaluating large
language models' ability to correctly use preferred pronouns, consisting of (i)
instances declaring an individual's pronoun, followed by a sentence with a
missing pronoun, and (ii) an experimental setup for evaluating masked and
auto-regressive language models using a unified method. When prompted
out-of-the-box, language models perform poorly at correctly predicting
neo-pronouns (averaging 7.6% accuracy) and gender-neutral pronouns (averaging
31.0% accuracy). This inability to generalize results from a lack of
representation of non-binary pronouns in training data and memorized
associations. Few-shot adaptation with explicit examples in the prompt improves
the performance but plateaus at only 45.4% for neo-pronouns. We release the
full dataset, code, and demo at
https://tamannahossainkay.github.io/misgendered/
</p>

<h3>Title: Leveraging Explicit Procedural Instructions for Data-Efficient Action Prediction. (arXiv:2306.03959v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03959">http://arxiv.org/abs/2306.03959</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03959] Leveraging Explicit Procedural Instructions for Data-Efficient Action Prediction](http://arxiv.org/abs/2306.03959) #large language model</code></li>
<li>Summary: <p>Task-oriented dialogues often require agents to enact complex, multi-step
procedures in order to meet user requests. While large language models have
found success automating these dialogues in constrained environments, their
widespread deployment is limited by the substantial quantities of task-specific
data required for training. The following paper presents a data-efficient
solution to constructing dialogue systems, leveraging explicit instructions
derived from agent guidelines, such as company policies or customer service
manuals. Our proposed Knowledge-Augmented Dialogue System (KADS) combines a
large language model with a knowledge retrieval module that pulls documents
outlining relevant procedures from a predefined set of policies, given a
user-agent interaction. To train this system, we introduce a semi-supervised
pre-training scheme that employs dialogue-document matching and action-oriented
masked language modeling with partial parameter freezing. We evaluate the
effectiveness of our approach on prominent task-oriented dialogue datasets,
Action-Based Conversations Dataset and Schema-Guided Dialogue, for two dialogue
tasks: action state tracking and workflow discovery. Our results demonstrate
that procedural knowledge augmentation improves accuracy predicting in- and
out-of-distribution actions while preserving high performance in settings with
low or sparse data.
</p></li>
</ul>

<h3>Title: B\"{u}y\"{u}k dil modellerinin T\"{u}rk\c{c}e verisetleri ile e\u{g}itilmesi ve ince ayarlanmas\i. (arXiv:2306.03978v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03978">http://arxiv.org/abs/2306.03978</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03978] B\"{u}y\"{u}k dil modellerinin T\"{u}rk\c{c}e verisetleri ile e\u{g}itilmesi ve ince ayarlanmas\i](http://arxiv.org/abs/2306.03978) #large language model</code></li>
<li>Summary: <p>Large language models have advanced enormously, gained vast attraction and
are having a phase of intensed research. Some of the developed models and
training datasets have been made open-accessible. Hence these may be further
fine-tuned with some techniques to obtain specialized models for specific
tasks. When it comes to Turkish language, open-access models do not provide
satisfactory coverage. This is also observed over published datasets. In this
work, we propose some ideas to mitigate this issue: creating large Turkish
datasets, training LLMs with these and fine-tuning pre-trained models with
Turkish inputs. We report our findings on Turkish-based trainings with the
problems encountered along the way. We conclude with outcomes of these
experiments and propose ideas for further works.
</p></li>
</ul>

<p>--
</p>
<p>B\"uy\"uk dil modelleri inan{\i}lmaz \"ol\c{c}\"ude geli\c{s}mekte, b\"uy\"uk
ilgi toplayarak ve \"uzerlerinde yo\u{g}un ara\c{s}tirmalarin yapildi\u{g}i bir
d\"onemdedirler. Geli\c{s}tirilen modeller ve e\u{g}itimde kullanilan
verisetlerinden bazilari a\c{c}ik eri\c{s}imli olarak sunulmaktadir. B\"oylece
ince ayarlama teknikleri uygulayarak \"ozelle\c{s}mi\c{s} g\"orevler i\c{c}in
\c{c}ali\c{s}abilir modeller elde edilmektedir. T\"urk\c{c}e s\"oz konusu
oldu\u{g}unda bu modellerinin kapsayicili\u{g}i yeterli d\"uzeyde de\u{g}ildir.
Bu durum, yayimlanan verisetlerinde de g\"ozlemlenebilir. Bunu a\c{s}manin
yollari T\"urk\c{c}e i\c{c}erikli b\"uy\"uk verisetlerinin olu\c{s}turulmasi,
b\"uy\"uk dil modellerinin bunlarla e\u{g}itilmesi ve \"onceden
e\u{g}itilmi\c{s} modellerin T\"urk\c{c}e girdilerle ince ayarlanmalari
olabilir. Bu \c{c}ali\c{s}mada a\c{c}ik eri\c{s}imli dil modelleri ve
verisetleri \"uzerinde durulmakta ve T\"urk\c{c}e temelli bazi deneyler,
kar\c{s}ila\c{s}ilan sorunlar ve sonu\c{c}lar irdelenmektedir.
</p>

<h3>Title: XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations. (arXiv:2306.04085v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04085">http://arxiv.org/abs/2306.04085</a></li>
<li>Code URL: <a href="https://github.com/psunlpgroup/xsemplr">https://github.com/psunlpgroup/xsemplr</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04085] XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations](http://arxiv.org/abs/2306.04085) #large language model</code></li>
<li>Summary: <p>Cross-Lingual Semantic Parsing (CLSP) aims to translate queries in multiple
natural languages (NLs) into meaning representations (MRs) such as SQL, lambda
calculus, and logic forms. However, existing CLSP models are separately
proposed and evaluated on datasets of limited tasks and applications, impeding
a comprehensive and unified evaluation of CLSP on a diverse range of NLs and
MRs. To this end, we present XSemPLR, a unified benchmark for cross-lingual
semantic parsing featured with 22 natural languages and 8 meaning
representations by examining and selecting 9 existing datasets to cover 5 tasks
and 164 domains. We use XSemPLR to conduct a comprehensive benchmark study on a
wide range of multilingual language models including encoder-based models
(mBERT, XLM-R), encoder-decoder models (mBART, mT5), and decoder-based models
(Codex, BLOOM). We design 6 experiment settings covering various lingual
combinations (monolingual, multilingual, cross-lingual) and numbers of learning
samples (full dataset, few-shot, and zero-shot). Our experiments show that
encoder-decoder models (mT5) achieve the highest performance compared with
other popular models, and multilingual training can further improve the average
performance. Notably, multilingual large language models (e.g., BLOOM) are
still inadequate to perform CLSP tasks. We also find that the performance gap
between monolingual training and cross-lingual transfer learning is still
significant for multilingual models, though it can be mitigated by
cross-lingual few-shot training. Our dataset and code are available at
https://github.com/psunlpgroup/XSemPLR.
</p></li>
</ul>

<h3>Title: Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering. (arXiv:2306.04136v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04136">http://arxiv.org/abs/2306.04136</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04136] Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering](http://arxiv.org/abs/2306.04136) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) are capable of performing zero-shot closed-book
question answering tasks, based on their internal knowledge stored in
parameters during pre-training. However, such internalized knowledge might be
insufficient and incorrect, which could lead LLMs to generate factually wrong
answers. Furthermore, fine-tuning LLMs to update their knowledge is expensive.
To this end, we propose to augment the knowledge directly in the input of LLMs.
Specifically, we first retrieve the relevant facts to the input question from
the knowledge graph based on semantic similarities between the question and its
associated facts. After that, we prepend the retrieved facts to the input
question in the form of the prompt, which is then forwarded to LLMs to generate
the answer. Our framework, Knowledge-Augmented language model PromptING
(KAPING), requires no model training, thus completely zero-shot. We validate
the performance of our KAPING framework on the knowledge graph question
answering task, that aims to answer the user's question based on facts over a
knowledge graph, on which ours outperforms relevant zero-shot baselines by up
to 48% in average, across multiple LLMs of various sizes.
</p></li>
</ul>

<h3>Title: Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions. (arXiv:2306.04140v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04140">http://arxiv.org/abs/2306.04140</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04140] Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions](http://arxiv.org/abs/2306.04140) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) can be used to generate text data for training
and evaluating other models. However, creating high-quality datasets with LLMs
can be challenging. In this work, we explore human-AI partnerships to
facilitate high diversity and accuracy in LLM-based text data generation. We
first examine two approaches to diversify text generation: 1) logit
suppression, which minimizes the generation of languages that have already been
frequently generated, and 2) temperature sampling, which flattens the token
sampling probability. We found that diversification approaches can increase
data diversity but often at the cost of data accuracy (i.e., text and labels
being appropriate for the target domain). To address this issue, we examined
two human interventions, 1) label replacement (LR), correcting misaligned
labels, and 2) out-of-scope filtering (OOSF), removing instances that are out
of the user's domain of interest or to which no considered label applies. With
oracle studies, we found that LR increases the absolute accuracy of models
trained with diversified datasets by 14.4%. Moreover, we found that some models
trained with data generated with LR interventions outperformed LLM-based
few-shot classification. In contrast, OOSF was not effective in increasing
model accuracy, implying the need for future work in human-in-the-loop text
data generation.
</p></li>
</ul>

<h3>Title: A New Dataset and Empirical Study for Sentence Simplification in Chinese. (arXiv:2306.04188v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04188">http://arxiv.org/abs/2306.04188</a></li>
<li>Code URL: <a href="https://github.com/maybenotime/css">https://github.com/maybenotime/css</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04188] A New Dataset and Empirical Study for Sentence Simplification in Chinese](http://arxiv.org/abs/2306.04188) #large language model</code></li>
<li>Summary: <p>Sentence Simplification is a valuable technique that can benefit language
learners and children a lot. However, current research focuses more on English
sentence simplification. The development of Chinese sentence simplification is
relatively slow due to the lack of data. To alleviate this limitation, this
paper introduces CSS, a new dataset for assessing sentence simplification in
Chinese. We collect manual simplifications from human annotators and perform
data analysis to show the difference between English and Chinese sentence
simplifications. Furthermore, we test several unsupervised and zero/few-shot
learning methods on CSS and analyze the automatic evaluation and human
evaluation results. In the end, we explore whether Large Language Models can
serve as high-quality Chinese sentence simplification systems by evaluating
them on CSS.
</p></li>
</ul>

<h3>Title: Multilingual Clinical NER: Translation or Cross-lingual Transfer?. (arXiv:2306.04384v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04384">http://arxiv.org/abs/2306.04384</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04384] Multilingual Clinical NER: Translation or Cross-lingual Transfer?](http://arxiv.org/abs/2306.04384) #large language model</code></li>
<li>Summary: <p>Natural language tasks like Named Entity Recognition (NER) in the clinical
domain on non-English texts can be very time-consuming and expensive due to the
lack of annotated data. Cross-lingual transfer (CLT) is a way to circumvent
this issue thanks to the ability of multilingual large language models to be
fine-tuned on a specific task in one language and to provide high accuracy for
the same task in another language. However, other methods leveraging
translation models can be used to perform NER without annotated data in the
target language, by either translating the training set or test set. This paper
compares cross-lingual transfer with these two alternative methods, to perform
clinical NER in French and in German without any training data in those
languages. To this end, we release MedNERF a medical NER test set extracted
from French drug prescriptions and annotated with the same guidelines as an
English dataset. Through extensive experiments on this dataset and on a German
medical dataset (Frei and Kramer, 2021), we show that translation-based methods
can achieve similar performance to CLT but require more care in their design.
And while they can take advantage of monolingual clinical language models,
those do not guarantee better results than large general-purpose multilingual
models, whether with cross-lingual transfer or translation.
</p></li>
</ul>

<h3>Title: STEPS: A Benchmark for Order Reasoning in Sequential Tasks. (arXiv:2306.04441v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04441">http://arxiv.org/abs/2306.04441</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04441] STEPS: A Benchmark for Order Reasoning in Sequential Tasks](http://arxiv.org/abs/2306.04441) #large language model</code></li>
<li>Summary: <p>Various human activities can be abstracted into a sequence of actions in
natural text, i.e. cooking, repairing, manufacturing, etc. Such action
sequences heavily depend on the executing order, while disorder in action
sequences leads to failure of further task execution by robots or AI agents.
Therefore, to verify the order reasoning capability of current neural models in
sequential tasks, we propose a challenging benchmark , named STEPS. STEPS
involves two subtask settings, focusing on determining the rationality of given
next step in recipes and selecting the reasonable step from the multi-choice
question, respectively. We describe the data construction and task
formulations, and benchmark most of significant Large Language Models (LLMs).
The experimental results demonstrate 1) The commonsense reasoning of action
orders in sequential tasks are challenging to resolve via zero-shot prompting
or few-shot in-context learning for LLMs; 2) Prompting method still
significantly lags behind tuning-based method on STEPS.
</p></li>
</ul>

<h3>Title: Long-form analogies generated by chatGPT lack human-like psycholinguistic properties. (arXiv:2306.04537v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04537">http://arxiv.org/abs/2306.04537</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04537] Long-form analogies generated by chatGPT lack human-like psycholinguistic properties](http://arxiv.org/abs/2306.04537) #large language model</code></li>
<li>Summary: <p>Psycholinguistic analyses provide a means of evaluating large language model
(LLM) output and making systematic comparisons to human-generated text. These
methods can be used to characterize the psycholinguistic properties of LLM
output and illustrate areas where LLMs fall short in comparison to
human-generated text. In this work, we apply psycholinguistic methods to
evaluate individual sentences from long-form analogies about biochemical
concepts. We compare analogies generated by human subjects enrolled in
introductory biochemistry courses to analogies generated by chatGPT. We perform
a supervised classification analysis using 78 features extracted from
Coh-metrix that analyze text cohesion, language, and readability (Graesser et.
al., 2004). Results illustrate high performance for classifying
student-generated and chatGPT-generated analogies. To evaluate which features
contribute most to model performance, we use a hierarchical clustering
approach. Results from this analysis illustrate several linguistic differences
between the two sources.
</p></li>
</ul>

<h3>Title: The Two Word Test: A Semantic Benchmark for Large Language Models. (arXiv:2306.04610v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04610">http://arxiv.org/abs/2306.04610</a></li>
<li>Code URL: <a href="https://github.com/nickriccardi/two-word-test">https://github.com/nickriccardi/two-word-test</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04610] The Two Word Test: A Semantic Benchmark for Large Language Models](http://arxiv.org/abs/2306.04610) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have shown remarkable abilities recently,
including passing advanced professional exams and demanding benchmark tests.
This performance has led many to suggest that they are close to achieving
humanlike or 'true' understanding of language, and even Artificial General
Intelligence (AGI). Here, we provide a new open-source benchmark that can
assess semantic abilities of LLMs using two-word phrases using a task that can
be performed relatively easily by humans without advanced training. Combining
multiple words into a single concept is a fundamental aspect of human language
and intelligence. The test requires meaningfulness judgments of 1768 noun-noun
combinations that have been rated as meaningful (e.g., baby boy) or not
meaningful (e.g., goat sky). by 150 human raters. We provide versions of the
task that probe meaningfulness ratings on a 0-4 scale as well as binary
judgments. We conducted a series of experiments using the TWT on GPT-4,
GPT-3.5, and Bard, with both versions. Results demonstrated that, compared to
humans, all models perform poorly at rating meaningfulness of these phrases.
GPT-3.5 and Bard are also unable to make binary discriminations between
sensible and nonsense phrases as making sense. GPT-4 makes a substantial
improvement in binary discrimination of combinatorial phrases but is still
significantly worse than human performance. The TWT can be used to understand
the limitations and weaknesses of current LLMs, and potentially improve them.
The test also reminds us that caution is warranted in attributing 'true
understanding' or AGI to LLMs. TWT is available at:
https://github.com/NickRiccardi/two-word-test
</p></li>
</ul>

<h3>Title: ModuleFormer: Learning Modular Large Language Models From Uncurated Data. (arXiv:2306.04640v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04640">http://arxiv.org/abs/2306.04640</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04640] ModuleFormer: Learning Modular Large Language Models From Uncurated Data](http://arxiv.org/abs/2306.04640) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have achieved remarkable results. But existing
models are expensive to train and deploy, and it is also difficult to expand
their knowledge beyond pre-training data without forgetting previous knowledge.
This paper proposes a new neural network architecture, ModuleFormer, that
leverages modularity to improve the efficiency and flexibility of large
language models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).
Unlike the previous SMoE-based modular language model [Gururangan et al.,
2021], which requires domain-labeled data to learn domain-specific experts,
ModuleFormer can induce modularity from uncurated data with its new load
balancing and load concentration losses. ModuleFormer is a modular architecture
that includes two different types of modules, new stick-breaking attention
heads, and feedforward experts. Different modules are sparsely activated
conditions on the input token during training and inference. In our experiment,
we found that the modular architecture enables three important abilities for
large pre-trained language models: 1) Efficiency, since ModuleFormer only
activates a subset of its modules for each input token, thus it could achieve
the same performance as dense LLMs with more than two times throughput; 2)
Extendability, ModuleFormer is more immune to catastrophic forgetting than
dense LLMs and can be easily extended with new modules to learn new knowledge
that is not included in the training data; 3) Specialisation, finetuning
ModuleFormer could specialize a subset of modules to the finetuning task, and
the task-unrelated modules could be easily pruned for a lightweight deployment.
</p></li>
</ul>

<h3>Title: StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code. (arXiv:2306.04556v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04556">http://arxiv.org/abs/2306.04556</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04556] StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code](http://arxiv.org/abs/2306.04556) #large language model</code></li>
<li>Summary: <p>Code LLMs are being rapidly deployed and there is evidence that they can make
professional programmers more productive. Current benchmarks for code
generation measure whether models generate correct programs given an expert
prompt. In this paper, we present a new benchmark containing multiple prompts
per problem, written by a specific population of non-expert prompters:
beginning programmers. StudentEval contains 1,749 prompts for 48 problems,
written by 80 students who have only completed one semester of Python
programming. Our students wrote these prompts while working interactively with
a Code LLM, and we observed very mixed success rates. We use StudentEval to
evaluate 5 Code LLMs and find that StudentEval is a better discriminator of
model performance than existing benchmarks. We analyze the prompts and find
significant variation in students' prompting techniques. We also find that
nondeterministic LLM sampling could mislead students into thinking that their
prompts are more (or less) effective than they actually are, which has
implications for how to teach with Code LLMs.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Real-Time Online Unsupervised Domain Adaptation for Real-World Person Re-identification. (arXiv:2306.03993v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.03993">http://arxiv.org/abs/2306.03993</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.03993] Real-Time Online Unsupervised Domain Adaptation for Real-World Person Re-identification](http://arxiv.org/abs/2306.03993) #segmentation</code></li>
<li>Summary: <p>Following the popularity of Unsupervised Domain Adaptation (UDA) in person
re-identification, the recently proposed setting of Online Unsupervised Domain
Adaptation (OUDA) attempts to bridge the gap towards practical applications by
introducing a consideration of streaming data. However, this still falls short
of truly representing real-world applications. This paper defines the setting
of Real-world Real-time Online Unsupervised Domain Adaptation (R$^2$OUDA) for
Person Re-identification. The R$^2$OUDA setting sets the stage for true
real-world real-time OUDA, bringing to light four major limitations found in
real-world applications that are often neglected in current research: system
generated person images, subset distribution selection, time-based data stream
segmentation, and a segment-based time constraint. To address all aspects of
this new R$^2$OUDA setting, this paper further proposes Real-World Real-Time
Online Streaming Mutual Mean-Teaching (R$^2$MMT), a novel multi-camera system
for real-world person re-identification. Taking a popular person
re-identification dataset, R$^2$MMT was used to construct over 100 data subsets
and train more than 3000 models, exploring the breadth of the R$^2$OUDA setting
to understand the training time and accuracy trade-offs and limitations for
real-world applications. R$^2$MMT, a real-world system able to respect the
strict constraints of the proposed R$^2$OUDA setting, achieves accuracies
within 0.1% of comparable OUDA methods that cannot be applied directly to
real-world applications.
</p></li>
</ul>

<h3>Title: 1st Place Solution for PVUW Challenge 2023: Video Panoptic Segmentation. (arXiv:2306.04091v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04091">http://arxiv.org/abs/2306.04091</a></li>
<li>Code URL: <a href="https://github.com/zhang-tao-whu/DVIS">https://github.com/zhang-tao-whu/DVIS</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04091] 1st Place Solution for PVUW Challenge 2023: Video Panoptic Segmentation](http://arxiv.org/abs/2306.04091) #segmentation</code></li>
<li>Summary: <p>Video panoptic segmentation is a challenging task that serves as the
cornerstone of numerous downstream applications, including video editing and
autonomous driving. We believe that the decoupling strategy proposed by DVIS
enables more effective utilization of temporal information for both "thing" and
"stuff" objects. In this report, we successfully validated the effectiveness of
the decoupling strategy in video panoptic segmentation. Finally, our method
achieved a VPQ score of 51.4 and 53.7 in the development and test phases,
respectively, and ultimately ranked 1st in the VPS track of the 2nd PVUW
Challenge. The code is available at https://github.com/zhang-tao-whu/DVIS
</p></li>
</ul>

<h3>Title: MultiSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos. (arXiv:2306.04216v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04216">http://arxiv.org/abs/2306.04216</a></li>
<li>Code URL: <a href="https://github.com/Jason-Qiu/MultiSum_model">https://github.com/Jason-Qiu/MultiSum_model</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04216] MultiSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos](http://arxiv.org/abs/2306.04216) #segmentation</code></li>
<li>Summary: <p>Multimodal summarization with multimodal output (MSMO) has emerged as a
promising research direction. Nonetheless, numerous limitations exist within
existing public MSMO datasets, including insufficient upkeep, data
inaccessibility, limited size, and the absence of proper categorization, which
pose significant challenges to effective research. To address these challenges
and provide a comprehensive dataset for this new direction, we have
meticulously curated the MultiSum dataset. Our new dataset features (1)
Human-validated summaries for both video and textual content, providing
superior human instruction and labels for multimodal learning. (2)
Comprehensively and meticulously arranged categorization, spanning 17 principal
categories and 170 subcategories to encapsulate a diverse array of real-world
scenarios. (3) Benchmark tests performed on the proposed dataset to assess
varied tasks and methods, including video temporal segmentation, video
summarization, text summarization, and multimodal summarization. To champion
accessibility and collaboration, we release the MultiSum dataset and the data
collection tool as fully open-source resources, fostering transparency and
accelerating future developments. Our project website can be found at
https://multisum-dataset.github.io/.
</p></li>
</ul>

<h3>Title: CorrMatch: Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation. (arXiv:2306.04300v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04300">http://arxiv.org/abs/2306.04300</a></li>
<li>Code URL: <a href="https://github.com/bbbbchan/corrmatch">https://github.com/bbbbchan/corrmatch</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04300] CorrMatch: Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation](http://arxiv.org/abs/2306.04300) #segmentation</code></li>
<li>Summary: <p>In this paper, we present a simple but performant semi-supervised semantic
segmentation approach, termed CorrMatch. Our goal is to mine more high-quality
regions from the unlabeled images to leverage the unlabeled data more
efficiently via consistency regularization. The key contributions of our
CorrMatch are two novel and complementary strategies. First, we introduce an
adaptive threshold updating strategy with a relaxed initialization to expand
the high-quality regions. Furthermore, we propose to propagate high-confidence
predictions through measuring the pairwise similarities between pixels. Despite
its simplicity, we show that CorrMatch achieves great performance on popular
semi-supervised semantic segmentation benchmarks. Taking the DeepLabV3+
framework with ResNet-101 backbone as our segmentation model, we receive a 76%+
mIoU score on the Pascal VOC 2012 segmentation benchmark with only 92 annotated
images provided. We also achieve a consistent improvement over previous
semi-supervised semantic segmentation models. Code will be made publicly
available.
</p></li>
</ul>

<h3>Title: ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation. (arXiv:2306.04344v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04344">http://arxiv.org/abs/2306.04344</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04344] ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation](http://arxiv.org/abs/2306.04344) #segmentation</code></li>
<li>Summary: <p>Since real-world machine systems are running in non-stationary and
continually changing environments, Continual Test-Time Adaptation (CTTA) task
is proposed to adapt the pre-trained model to continually changing target
domains. Recently, existing methods mainly focus on model-based adaptation,
which aims to leverage a self-training manner to extract the target domain
knowledge. However, pseudo labels can be noisy and the updated model parameters
are uncertain under dynamic data distributions, leading to error accumulation
and catastrophic forgetting in the continual adaptation process. To tackle
these challenges and maintain the model plasticity, we tactfully design a
Visual Domain Adapter (ViDA) for CTTA, explicitly handling both domain-specific
and domain-agnostic knowledge. Specifically, we first comprehensively explore
the different domain representations of the adapters with trainable high and
low-rank embedding space. Then we inject ViDAs into the pre-trained model,
which leverages high-rank and low-rank prototypes to adapt the current domain
distribution and maintain the continual domain-shared knowledge, respectively.
To adapt to the various distribution shifts of each sample in target domains,
we further propose a Homeostatic Knowledge Allotment (HKA) strategy, which
adaptively merges knowledge from each ViDA with different rank prototypes.
Extensive experiments conducted on four widely-used benchmarks demonstrate that
our proposed method achieves state-of-the-art performance in both
classification and segmentation CTTA tasks. In addition, our method can be
regarded as a novel transfer paradigm and showcases promising results in
zero-shot adaptation of foundation models to continual downstream tasks and
distributions.
</p></li>
</ul>

<h3>Title: Fine-Grained Visual Prompting. (arXiv:2306.04356v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04356">http://arxiv.org/abs/2306.04356</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04356] Fine-Grained Visual Prompting](http://arxiv.org/abs/2306.04356) #segmentation</code></li>
<li>Summary: <p>Vision-Language Models (VLMs), such as CLIP, have demonstrated impressive
zero-shot transfer capabilities in image-level visual perception. However,
these models have shown limited performance in instance-level tasks that demand
precise localization and recognition. Previous works have suggested that
incorporating visual prompts, such as colorful boxes or circles, can improve
the ability of models to recognize objects of interest. Nonetheless, compared
to language prompting, visual prompting designs are rarely explored. Existing
approaches, which employ coarse visual cues such as colorful boxes or circles,
often result in sub-optimal performance due to the inclusion of irrelevant and
noisy pixels. In this paper, we carefully study the visual prompting designs by
exploring more fine-grained markings, such as segmentation masks and their
variations. In addition, we introduce a new zero-shot framework that leverages
pixel-level annotations acquired from a generalist segmentation model for
fine-grained visual prompting. Consequently, our investigation reveals that a
straightforward application of blur outside the target mask, referred to as the
Blur Reverse Mask, exhibits exceptional effectiveness. This proposed prompting
strategy leverages the precise mask annotations to reduce focus on weakly
related regions while retaining spatial coherence between the target and the
surrounding background. Our Fine-Grained Visual Prompting (FGVP) demonstrates
superior performance in zero-shot comprehension of referring expressions on the
RefCOCO, RefCOCO+, and RefCOCOg benchmarks. It outperforms prior methods by an
average margin of 3.0% to 4.6%, with a maximum improvement of 12.5% on the
RefCOCO+ testA subset. The part detection experiments conducted on the PACO
dataset further validate the preponderance of FGVP over existing visual
prompting techniques. Code and models will be made available.
</p></li>
</ul>

<h3>Title: FoSp: Focus and Separation Network for Early Smoke Segmentation. (arXiv:2306.04474v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04474">http://arxiv.org/abs/2306.04474</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04474] FoSp: Focus and Separation Network for Early Smoke Segmentation](http://arxiv.org/abs/2306.04474) #segmentation</code></li>
<li>Summary: <p>Early smoke segmentation (ESS) enables the accurate identification of smoke
sources, facilitating the prompt extinguishing of fires and preventing
large-scale gas leaks. But ESS poses greater challenges than conventional
object and regular smoke segmentation due to its small scale and transparent
appearance, which can result in high miss detection rate and low precision. To
address these issues, a Focus and Separation Network (FoSp) is proposed. We
first introduce a Focus module employing bidirectional cascade which guides
low-resolution and high-resolution features towards mid-resolution to locate
and determine the scope of smoke, reducing the miss detection rate. Next, we
propose a Separation module that separates smoke images into a pure smoke
foreground and a smoke-free background, enhancing the contrast between smoke
and background fundamentally, improving segmentation precision. Finally, a
Domain Fusion module is developed to integrate the distinctive features of the
two modules which can balance recall and precision to achieve high F_beta.
Futhermore, to promote the development of ESS, we introduce a high-quality
real-world dataset called SmokeSeg, which contains more small and transparent
smoke than the existing datasets. Experimental results show that our model
achieves the best performance on three available datasets: SYN70K (mIoU:
83.00%), SMOKE5K (F_beta: 81.6%) and SmokeSeg (F_beta: 72.05%). Especially, our
FoSp outperforms SegFormer by 7.71% (F_beta) for early smoke segmentation on
SmokeSeg.
</p></li>
</ul>

<h3>Title: NeMO: Neural Map Growing System for Spatiotemporal Fusion in Bird's-Eye-View and BDD-Map Benchmark. (arXiv:2306.04540v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04540">http://arxiv.org/abs/2306.04540</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04540] NeMO: Neural Map Growing System for Spatiotemporal Fusion in Bird's-Eye-View and BDD-Map Benchmark](http://arxiv.org/abs/2306.04540) #segmentation</code></li>
<li>Summary: <p>Vision-centric Bird's-Eye View (BEV) representation is essential for
autonomous driving systems (ADS). Multi-frame temporal fusion which leverages
historical information has been demonstrated to provide more comprehensive
perception results. While most research focuses on ego-centric maps of fixed
settings, long-range local map generation remains less explored. This work
outlines a new paradigm, named NeMO, for generating local maps through the
utilization of a readable and writable big map, a learning-based fusion module,
and an interaction mechanism between the two. With an assumption that the
feature distribution of all BEV grids follows an identical pattern, we adopt a
shared-weight neural network for all grids to update the big map. This paradigm
supports the fusion of longer time series and the generation of long-range BEV
local maps. Furthermore, we release BDD-Map, a BDD100K-based dataset
incorporating map element annotations, including lane lines, boundaries, and
pedestrian crossing. Experiments on the NuScenes and BDD-Map datasets
demonstrate that NeMO outperforms state-of-the-art map segmentation methods. We
also provide a new scene-level BEV map evaluation setting along with the
corresponding baseline for a more comprehensive comparison.
</p></li>
</ul>

<h3>Title: PhenoBench -- A Large Dataset and Benchmarks for Semantic Image Interpretation in the Agricultural Domain. (arXiv:2306.04557v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04557">http://arxiv.org/abs/2306.04557</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04557] PhenoBench -- A Large Dataset and Benchmarks for Semantic Image Interpretation in the Agricultural Domain](http://arxiv.org/abs/2306.04557) #segmentation</code></li>
<li>Summary: <p>The production of food, feed, fiber, and fuel is a key task of agriculture.
Especially crop production has to cope with a multitude of challenges in the
upcoming decades caused by a growing world population, climate change, the need
for sustainable production, lack of skilled workers, and generally the limited
availability of arable land. Vision systems could help cope with these
challenges by offering tools to make better and more sustainable field
management decisions and support the breeding of new varieties of crops by
allowing temporally dense and reproducible measurements. Recently, tackling
perception tasks in the agricultural domain got increasing interest in the
computer vision and robotics community since agricultural robotics are one
promising solution for coping with the lack of workers and enable a more
sustainable agricultural production at the same time. While large datasets and
benchmarks in other domains are readily available and have enabled significant
progress toward more reliable vision systems, agricultural datasets and
benchmarks are comparably rare. In this paper, we present a large dataset and
benchmarks for the semantic interpretation of images of real agricultural
fields. Our dataset recorded with a UAV provides high-quality, dense
annotations of crops and weeds, but also fine-grained labels of crop leaves at
the same time, which enable the development of novel algorithms for visual
perception in the agricultural domain. Together with the labeled data, we
provide novel benchmarks for evaluating different visual perception tasks on a
hidden test set comprised of different fields: known fields covered by the
training data and a completely unseen field. The tasks cover semantic
segmentation, panoptic segmentation of plants, leaf instance segmentation,
detection of plants and leaves, and hierarchical panoptic segmentation for
jointly identifying plants and leaves.
</p></li>
</ul>

<h3>Title: Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast Contrastive Fusion. (arXiv:2306.04633v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.04633">http://arxiv.org/abs/2306.04633</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.04633] Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast Contrastive Fusion](http://arxiv.org/abs/2306.04633) #segmentation</code></li>
<li>Summary: <p>Instance segmentation in 3D is a challenging task due to the lack of
large-scale annotated datasets. In this paper, we show that this task can be
addressed effectively by leveraging instead 2D pre-trained models for instance
segmentation. We propose a novel approach to lift 2D segments to 3D and fuse
them by means of a neural field representation, which encourages multi-view
consistency across frames. The core of our approach is a slow-fast clustering
objective function, which is scalable and well-suited for scenes with a large
number of objects. Unlike previous approaches, our method does not require an
upper bound on the number of objects or object tracking across frames. To
demonstrate the scalability of the slow-fast clustering, we create a new
semi-realistic dataset called the Messy Rooms dataset, which features scenes
with up to 500 objects per scene. Our approach outperforms the state-of-the-art
on challenging scenes from the ScanNet, Hypersim, and Replica datasets, as well
as on our newly created Messy Rooms dataset, demonstrating the effectiveness
and scalability of our slow-fast clustering method.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
