<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-02-07</h1>
<h3>Title: SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular  Value Penalization</h3>
<ul>
<li><strong>Authors: </strong>Xixu Hu, Runkai Zheng, Jindong Wang, Cheuk Hang Leung, Qi Wu, Xing Xie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03317">https://arxiv.org/abs/2402.03317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03317">https://arxiv.org/pdf/2402.03317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03317]] SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular  Value Penalization(https://arxiv.org/abs/2402.03317)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformers (ViTs) have gained prominence as a preferred choice for a wide range of computer vision tasks due to their exceptional performance. However, their widespread adoption has raised concerns about security in the face of malicious attacks. Most existing methods rely on empirical adjustments during the training process, lacking a clear theoretical foundation. In this study, we address this gap by introducing SpecFormer, specifically designed to enhance ViTs' resilience against adversarial attacks, with support from carefully derived theoretical guarantees. We establish local Lipschitz bounds for the self-attention layer and introduce a novel approach, Maximum Singular Value Penalization (MSVP), to attain precise control over these bounds. We seamlessly integrate MSVP into ViTs' attention layers, using the power iteration method for enhanced computational efficiency. The modified model, SpecFormer, effectively reduces the spectral norms of attention weight matrices, thereby enhancing network local Lipschitzness. This, in turn, leads to improved training efficiency and robustness. Extensive experiments on CIFAR and ImageNet datasets confirm SpecFormer's superior performance in defending against adversarial attacks.</li>
</ul>

<h3>Title: Connect Later: Improving Fine-tuning for Robustness with Targeted  Augmentations</h3>
<ul>
<li><strong>Authors: </strong>Helen Qu, Sang Michael Xie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03325">https://arxiv.org/abs/2402.03325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03325">https://arxiv.org/pdf/2402.03325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03325]] Connect Later: Improving Fine-tuning for Robustness with Targeted  Augmentations(https://arxiv.org/abs/2402.03325)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Models trained on a labeled source domain (e.g., labeled images from wildlife camera traps) often generalize poorly when deployed on an out-of-distribution (OOD) target domain (e.g., images from new camera trap locations). In the domain adaptation setting where unlabeled target data is available, self-supervised pretraining (e.g., masked autoencoding or contrastive learning) is a promising method to mitigate this performance drop. Pretraining improves OOD error when the generic data augmentations used (e.g., masking or cropping) connect the source and target domains, which may be far apart in the input space. In this paper, we show on real-world tasks that standard fine-tuning after pretraining does not consistently improve OOD error over simply training from scratch on labeled source data. To better leverage pretraining for distribution shifts, we propose Connect Later: after pretraining with generic augmentations, fine-tune with targeted augmentations designed with knowledge of the distribution shift. Pretraining learns good representations within the source and target domains, while targeted augmentations connect the domains better during fine-tuning. Connect Later improves average OOD error over standard fine-tuning and supervised learning with targeted augmentations on 4 real-world datasets: Connect Later achieves the state-of-the-art on astronomical time-series classification (AstroClassification) by 2.5%, wildlife species identification (iWildCam-WILDS) with ResNet-50 by 0.9%, and tumor identification (Camelyon17-WILDS) with DenseNet121 by 1.1%; as well as best performance on a new dataset for astronomical time-series redshift prediction (Redshifts) by 0.03 RMSE (11% relative). Code and datasets are available at https://github.com/helenqu/connect-later.</li>
</ul>

<h3>Title: Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dingning Liu, Xiaoshui Huang, Yuenan Hou, Zhihui Wang, Zhenfei Yin, Yongshun Gong, Peng Gao, Wanli Ouyang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03327">https://arxiv.org/abs/2402.03327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03327">https://arxiv.org/pdf/2402.03327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03327]] Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with  Large Language Models(https://arxiv.org/abs/2402.03327)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce Uni3D-LLM, a unified framework that leverages a Large Language Model (LLM) to integrate tasks of 3D perception, generation, and editing within point cloud scenes. This framework empowers users to effortlessly generate and modify objects at specified locations within a scene, guided by the versatility of natural language descriptions. Uni3D-LLM harnesses the expressive power of natural language to allow for precise command over the generation and editing of 3D objects, thereby significantly enhancing operational flexibility and controllability. By mapping point cloud into the unified representation space, Uni3D-LLM achieves cross-application functionality, enabling the seamless execution of a wide array of tasks, ranging from the accurate instantiation of 3D objects to the diverse requirements of interactive design. Through a comprehensive suite of rigorous experiments, the efficacy of Uni3D-LLM in the comprehension, generation, and editing of point cloud has been validated. Additionally, we have assessed the impact of integrating a point cloud perception module on the generation and editing processes, confirming the substantial potential of our approach for practical applications.</li>
</ul>

<h3>Title: Large-scale Generative AI Models Lack Visual Number Sense</h3>
<ul>
<li><strong>Authors: </strong>Alberto Testolin, Kuinan Hou, Marco Zorzi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03328">https://arxiv.org/abs/2402.03328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03328">https://arxiv.org/pdf/2402.03328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03328]] Large-scale Generative AI Models Lack Visual Number Sense(https://arxiv.org/abs/2402.03328)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Humans can readily judge the number of objects in a visual scene, even without counting, and such a skill has been documented in a variety of animal species and in babies prior to language development and formal schooling. Numerical judgments are error-free for small sets, while for larger collections responses become approximate, with variability increasing proportionally to the target number. This response pattern is observed for items of all kinds, despite variation in object features (such as color or shape), suggesting that our visual number sense relies on abstract representations of numerosity. Here, we investigated whether generative Artificial Intelligence (AI) models based on large-scale transformer architectures can reliably name the number of objects in simple visual stimuli or generate images containing a target number of items in the 1-10 range. Surprisingly, none of the foundation models considered performed in a human-like way: They all made striking errors even with small numbers, the response variability often did not increase in a systematic way, and the pattern of errors varied with object category. Our findings demonstrate that advanced AI systems still lack a basic ability that supports an intuitive understanding of numbers, which in humans is foundational for numeracy and mathematical development.</li>
</ul>

<h3>Title: Unsupervised Salient Patch Selection for Data-Efficient Reinforcement  Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhaohui Jiang, Paul Weng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03329">https://arxiv.org/abs/2402.03329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03329">https://arxiv.org/pdf/2402.03329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03329]] Unsupervised Salient Patch Selection for Data-Efficient Reinforcement  Learning(https://arxiv.org/abs/2402.03329)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>To improve the sample efficiency of vision-based deep reinforcement learning (RL), we propose a novel method, called SPIRL, to automatically extract important patches from input images. Following Masked Auto-Encoders, SPIRL is based on Vision Transformer models pre-trained in a self-supervised fashion to reconstruct images from randomly-sampled patches. These pre-trained models can then be exploited to detect and select salient patches, defined as hard to reconstruct from neighboring patches. In RL, the SPIRL agent processes selected salient patches via an attention module. We empirically validate SPIRL on Atari games to test its data-efficiency against relevant state-of-the-art methods, including some traditional model-based methods and keypoint-based models. In addition, we analyze our model's interpretability capabilities.</li>
</ul>

<h3>Title: Interplay of Semantic Communication and Knowledge Learning</h3>
<ul>
<li><strong>Authors: </strong>Fei Ni, Bingyan Wang, Rongpeng Li, Zhifeng Zhao, Honggang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03339">https://arxiv.org/abs/2402.03339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03339">https://arxiv.org/pdf/2402.03339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03339]] Interplay of Semantic Communication and Knowledge Learning(https://arxiv.org/abs/2402.03339)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the swiftly advancing realm of communication technologies, Semantic Communication (SemCom), which emphasizes knowledge understanding and processing, has emerged as a hot topic. By integrating artificial intelligence technologies, SemCom facilitates a profound understanding, analysis and transmission of communication content. In this chapter, we clarify the means of knowledge learning in SemCom with a particular focus on the utilization of Knowledge Graphs (KGs). Specifically, we first review existing efforts that combine SemCom with knowledge learning. Subsequently, we introduce a KG-enhanced SemCom system, wherein the receiver is carefully calibrated to leverage knowledge from its static knowledge base for ameliorating the decoding performance. Contingent upon this framework, we further explore potential approaches that can empower the system to operate in evolving knowledge base more effectively. Furthermore, we investigate the possibility of integration with Large Language Models (LLMs) for data augmentation, offering additional perspective into the potential implementation means of SemCom. Extensive numerical results demonstrate that the proposed framework yields superior performance on top of the KG-enhanced decoding and manifests its versatility under different scenarios.</li>
</ul>

<h3>Title: Transfer Learning With Densenet201 Architecture Model For Potato Leaf  Disease Classification</h3>
<ul>
<li><strong>Authors: </strong>Rifqi Alfinnur Charisma, Faisal Dharma Adhinata</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03347">https://arxiv.org/abs/2402.03347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03347">https://arxiv.org/pdf/2402.03347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03347]] Transfer Learning With Densenet201 Architecture Model For Potato Leaf  Disease Classification(https://arxiv.org/abs/2402.03347)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Potato plants are plants that are beneficial to humans. Like other plants in general, potato plants also have diseases; if this disease is not treated immediately, there will be a significant decrease in food production. Therefore, it is necessary to detect diseases quickly and precisely so that disease control can be carried out effectively and efficiently. Classification of potato leaf disease can be done directly. Still, the symptoms cannot always explain the type of disease that attacks potato leaves because there are many types of diseases with symptoms that look the same. Humans also have deficiencies in determining the results of identification of potato leaf disease, so sometimes the results of identification between individuals can be different. Therefore, the use of Deep Learning for the classification process of potato leaf disease is expected to shorten the time and have a high classification accuracy. This study uses a deep learning method with the DenseNet201 architecture. The choice to use the DenseNet201 algorithm in this study is because the model can identify important features of potato leaves and recognize early signs of emerging diseases. This study aimed to evaluate the effectiveness of the transfer learning method with the DenseNet201 architecture in increasing the classification accuracy of potato leaf disease compared to traditional classification methods. This study uses two types of scenarios, namely, comparing the number of dropouts and comparing the three optimizers. This test produces the best model using dropout 0.1 and Adam optimizer with an accuracy of 99.5% for training, 95.2% for validation, and 96% for the confusion matrix. In this study, using data testing, as many as 40 images were tested into the model that has been built. The test results on this model resulted in a new accuracy for classifying potato leaf disease, namely 92.5%.</li>
</ul>

<h3>Title: Respect the model: Fine-grained and Robust Explanation with Sharing  Ratio Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Sangyu Han, Yearim Kim, Nojun Kwak</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03348">https://arxiv.org/abs/2402.03348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03348">https://arxiv.org/pdf/2402.03348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03348]] Respect the model: Fine-grained and Robust Explanation with Sharing  Ratio Decomposition(https://arxiv.org/abs/2402.03348)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>The truthfulness of existing explanation methods in authentically elucidating the underlying model's decision-making process has been questioned. Existing methods have deviated from faithfully representing the model, thus susceptible to adversarial attacks. To address this, we propose a novel eXplainable AI (XAI) method called SRD (Sharing Ratio Decomposition), which sincerely reflects the model's inference process, resulting in significantly enhanced robustness in our explanations. Different from the conventional emphasis on the neuronal level, we adopt a vector perspective to consider the intricate nonlinear interactions between filters. We also introduce an interesting observation termed Activation-Pattern-Only Prediction (APOP), letting us emphasize the importance of inactive neurons and redefine relevance encapsulating all relevant information including both active and inactive neurons. Our method, SRD, allows for the recursive decomposition of a Pointwise Feature Vector (PFV), providing a high-resolution Effective Receptive Field (ERF) at any layer.</li>
</ul>

<h3>Title: SeMalloc: Semantics-Informed Memory Allocator</h3>
<ul>
<li><strong>Authors: </strong>Ruizhe Wang, Meng Xu, N. Asokan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03373">https://arxiv.org/abs/2402.03373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03373">https://arxiv.org/pdf/2402.03373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03373]] SeMalloc: Semantics-Informed Memory Allocator(https://arxiv.org/abs/2402.03373)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Use-after-free (UAF) is a critical and prevalent problem in memory unsafe languages. While many solutions have been proposed, they seem to balance security, run-time cost, and memory overhead (an impossible trinity) in awkward ways. In this paper, we show that a balance can be achieved by passing more semantics about the heap object to the allocator for it to make informed allocation decisions. More specifically, we propose a new notion of thread-, context-, and flow-sensitive "type", SemaType, to capture the semantics and prototype a SemaType-based allocator that aims for the best trade-off amongst the impossible trinity. In SeMalloc, only heap objects allocated from the same call site and via the same function call stack can possibly share a virtual memory address, which effectively stops type-confusion attacks and make UAF vulnerabilities harder to exploit. Through extensive empirical evaluation, we show that SeMalloc is realistic: (a) SeMalloc is effective in thwarting all real-world vulnerabilities we tested; (b) benchmark programs run even slightly faster with SeMalloc than the default heap allocator, at a memory overhead ranges from 46% to 247%; and (c) SeMalloc balances security and overhead strictly better than other closely related works.</li>
</ul>

<h3>Title: Psychological Assessments with Large Language Models: A Privacy-Focused  and Cost-Effective Approach</h3>
<ul>
<li><strong>Authors: </strong>Sergi Blanco-Cuaresma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03435">https://arxiv.org/abs/2402.03435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03435">https://arxiv.org/pdf/2402.03435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03435]] Psychological Assessments with Large Language Models: A Privacy-Focused  and Cost-Effective Approach(https://arxiv.org/abs/2402.03435)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>This study explores the use of Large Language Models (LLMs) to analyze text comments from Reddit users, aiming to achieve two primary objectives: firstly, to pinpoint critical excerpts that support a predefined psychological assessment of suicidal risk; and secondly, to summarize the material to substantiate the preassigned suicidal risk level. The work is circumscribed to the use of "open-source" LLMs that can be run locally, thereby enhancing data privacy. Furthermore, it prioritizes models with low computational requirements, making it accessible to both individuals and institutions operating on limited computing budgets. The implemented strategy only relies on a carefully crafted prompt and a grammar to guide the LLM's text completion. Despite its simplicity, the evaluation metrics show outstanding results, making it a valuable privacy-focused and cost-effective approach. This work is part of the Computational Linguistics and Clinical Psychology (CLPsych) 2024 shared task.</li>
</ul>

<h3>Title: Denoising Diffusion via Image-Based Rendering</h3>
<ul>
<li><strong>Authors: </strong>Titas Anciukevicius, Fabian Manhardt, Federico Tombari, Paul Henderson</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03445">https://arxiv.org/abs/2402.03445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03445">https://arxiv.org/pdf/2402.03445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03445]] Denoising Diffusion via Image-Based Rendering(https://arxiv.org/abs/2402.03445)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generating 3D scenes is a challenging open problem, which requires synthesizing plausible content that is fully consistent in 3D space. While recent methods such as neural radiance fields excel at view synthesis and 3D reconstruction, they cannot synthesize plausible details in unobserved regions since they lack a generative capability. Conversely, existing generative methods are typically not capable of reconstructing detailed, large-scale scenes in the wild, as they use limited-capacity 3D scene representations, require aligned camera poses, or rely on additional regularizers. In this work, we introduce the first diffusion model able to perform fast, detailed reconstruction and generation of real-world 3D scenes. To achieve this, we make three contributions. First, we introduce a new neural scene representation, IB-planes, that can efficiently and accurately represent large 3D scenes, dynamically allocating more capacity as needed to capture details visible in each image. Second, we propose a denoising-diffusion framework to learn a prior over this novel 3D scene representation, using only 2D images without the need for any additional supervision signal such as masks or depths. This supports 3D reconstruction and generation in a unified architecture. Third, we develop a principled approach to avoid trivial 3D solutions when integrating the image-based rendering with the diffusion model, by dropping out representations of some images. We evaluate the model on several challenging datasets of real and synthetic images, and demonstrate superior results on generation, novel view synthesis and 3D reconstruction.</li>
</ul>

<h3>Title: Decentralized Sporadic Federated Learning: A Unified Methodology with  Generalized Convergence Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Shahryar Zehtabi, Dong-Jun Han, Rohit Parasnis, Seyyedali Hosseinalipour, Christopher G. Brinton</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03448">https://arxiv.org/abs/2402.03448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03448">https://arxiv.org/pdf/2402.03448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03448]] Decentralized Sporadic Federated Learning: A Unified Methodology with  Generalized Convergence Guarantees(https://arxiv.org/abs/2402.03448)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Decentralized Federated Learning (DFL) has received significant recent research attention, capturing settings where both model updates and model aggregations -- the two key FL processes -- are conducted by the clients. In this work, we propose Decentralized Sporadic Federated Learning ($\texttt{DSpodFL}$), a DFL methodology which generalizes the notion of sporadicity in both of these processes, modeling the impact of different forms of heterogeneity that manifest in realistic DFL settings. $\texttt{DSpodFL}$ unifies many of the prominent decentralized optimization methods, e.g., distributed gradient descent (DGD), randomized gossip (RG), and decentralized federated averaging (DFedAvg), under a single modeling framework. We analytically characterize the convergence behavior of $\texttt{DSpodFL}$, showing, among other insights, that we can match a geometric convergence rate to a finite optimality gap under more general assumptions than in existing works. Through experiments, we demonstrate that $\texttt{DSpodFL}$ achieves significantly improved training speeds and robustness to variations in system parameters compared to the state-of-the-art.</li>
</ul>

<h3>Title: Extending RAIM with a Gaussian Mixture of Opportunistic Information</h3>
<ul>
<li><strong>Authors: </strong>Wenjie Liu, Panos Papadimitratos</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03449">https://arxiv.org/abs/2402.03449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03449">https://arxiv.org/pdf/2402.03449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03449]] Extending RAIM with a Gaussian Mixture of Opportunistic Information(https://arxiv.org/abs/2402.03449)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>GNSS are indispensable for various applications, but they are vulnerable to spoofing attacks. The original receiver autonomous integrity monitoring (RAIM) was not designed for securing GNSS. In this context, RAIM was extended with wireless signals, termed signals of opportunity (SOPs), or onboard sensors, typically assumed benign. However, attackers might also manipulate wireless networks, raising the need for a solution that considers untrustworthy SOPs. To address this, we extend RAIM by incorporating all opportunistic information, i.e., measurements from terrestrial infrastructures and onboard sensors, culminating in one function for robust GNSS spoofing detection. The objective is to assess the likelihood of GNSS spoofing by analyzing locations derived from extended RAIM solutions, which include location solutions from GNSS pseudorange subsets and wireless signal subsets of untrusted networks. Our method comprises two pivotal components: subset generation and location fusion. Subsets of ranging information are created and processed through positioning algorithms, producing temporary locations. Onboard sensors provide speed, acceleration, and attitude data, aiding in location filtering based on motion constraints. The filtered locations, modeled with uncertainty, are fused into a composite likelihood function normalized for GNSS spoofing detection. Theoretical assessments of GNSS-only and multi-infrastructure scenarios under uncoordinated and coordinated attacks are conducted. The detection of these attacks is feasible when the number of benign subsets exceeds a specific threshold. A real-world dataset from the Kista area is used for experimental validation. Comparative analysis against baseline methods shows a significant improvement in detection accuracy achieved by our Gaussian Mixture RAIM approach. Moreover, we discuss leveraging RAIM results for plausible location recovery.</li>
</ul>

<h3>Title: Constrained Multiview Representation for Self-supervised Contrastive  Learning</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Dai, Kai Ye, Kun Zhao, Ge Cui, Haoteng Tang, Liang Zhan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03456">https://arxiv.org/abs/2402.03456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03456">https://arxiv.org/pdf/2402.03456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03456]] Constrained Multiview Representation for Self-supervised Contrastive  Learning(https://arxiv.org/abs/2402.03456)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Representation learning constitutes a pivotal cornerstone in contemporary deep learning paradigms, offering a conduit to elucidate distinctive features within the latent space and interpret the deep models. Nevertheless, the inherent complexity of anatomical patterns and the random nature of lesion distribution in medical image segmentation pose significant challenges to the disentanglement of representations and the understanding of salient features. Methods guided by the maximization of mutual information, particularly within the framework of contrastive learning, have demonstrated remarkable success and superiority in decoupling densely intertwined representations. However, the effectiveness of contrastive learning highly depends on the quality of the positive and negative sample pairs, i.e. the unselected average mutual information among multi-views would obstruct the learning strategy so the selection of the views is vital. In this work, we introduce a novel approach predicated on representation distance-based mutual information (MI) maximization for measuring the significance of different views, aiming at conducting more efficient contrastive learning and representation disentanglement. Additionally, we introduce an MI re-ranking strategy for representation selection, benefiting both the continuous MI estimating and representation significance distance measuring. Specifically, we harness multi-view representations extracted from the frequency domain, re-evaluating their significance based on mutual information across varying frequencies, thereby facilitating a multifaceted contrastive learning approach to bolster semantic comprehension. The statistical results under the five metrics demonstrate that our proposed framework proficiently constrains the MI maximization-driven representation selection and steers the multi-view contrastive learning process.</li>
</ul>

<h3>Title: Efficient and Interpretable Traffic Destination Prediction using  Explainable Boosting Machines</h3>
<ul>
<li><strong>Authors: </strong>Yasin Yousif, Jörg Müller</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03457">https://arxiv.org/abs/2402.03457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03457">https://arxiv.org/pdf/2402.03457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03457]] Efficient and Interpretable Traffic Destination Prediction using  Explainable Boosting Machines(https://arxiv.org/abs/2402.03457)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Developing accurate models for traffic trajectory predictions is crucial for achieving fully autonomous driving. Various deep neural network models have been employed to address this challenge, but their black-box nature hinders transparency and debugging capabilities in a deployed system. Glass-box models offer a solution by providing full interpretability through methods like \ac{GAM}. In this study, we evaluate an efficient additive model called \ac{EBM} for traffic prediction on three popular mixed traffic datasets: \ac{SDD}, \ac{InD}, and Argoverse. Our results show that the \ac{EBM} models perform competitively in predicting pedestrian destinations within \ac{SDD} and \ac{InD} while providing modest predictions for vehicle-dominant Argoverse dataset. Additionally, our transparent trained models allow us to analyse feature importance and interactions, as well as provide qualitative examples of predictions explanation. The full training code will be made public upon publication.</li>
</ul>

<h3>Title: Stochastic Modified Flows for Riemannian Stochastic Gradient Descent</h3>
<ul>
<li><strong>Authors: </strong>Benjamin Gess, Sebastian Kassing, Nimit Rana</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, math.PR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03467">https://arxiv.org/abs/2402.03467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03467">https://arxiv.org/pdf/2402.03467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03467]] Stochastic Modified Flows for Riemannian Stochastic Gradient Descent(https://arxiv.org/abs/2402.03467)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is build using the concept of a retraction map, that is, a cost efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient.</li>
</ul>

<h3>Title: Preference-free Alignment Learning with Regularized Relevance Reward</h3>
<ul>
<li><strong>Authors: </strong>Sungdong Kim, Minjoon Seo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03469">https://arxiv.org/abs/2402.03469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03469">https://arxiv.org/pdf/2402.03469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03469]] Preference-free Alignment Learning with Regularized Relevance Reward(https://arxiv.org/abs/2402.03469)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Learning from human preference has been considered key to aligning Large Language Models (LLMs) with human values. However, contrary to popular belief, our preliminary study reveals that reward models trained on human preference datasets tend to give higher scores to long off-topic responses than short on-topic ones. Motivated by this observation, we explore a preference-free approach utilizing `relevance' as a key objective for alignment. On our first attempt, we find that the relevance score obtained by a retriever alone is vulnerable to reward hacking, i.e., overoptimizing to undesired shortcuts, when we utilize the score as a reward for reinforcement learning. To mitigate it, we integrate effective inductive biases into the vanilla relevance to regularize each other, resulting in a mixture of reward functions: Regularized Relevance Reward ($R^3$). $R^3$ significantly improves performance on preference benchmarks by providing a robust reward signal. Notably, $R^3$ does not require any human preference datasets (i.e., preference-free), outperforming open-source reward models in improving human preference. Our analysis demonstrates that $R^3$ has advantages in elevating human preference while minimizing its side effects. Finally, we show the generalizability of $R^3$, consistently improving instruction-tuned models in various backbones and sizes without additional dataset cost. Our code is available at https://github.com/naver-ai/RRR.</li>
</ul>

<h3>Title: The Information of Large Language Model Geometry</h3>
<ul>
<li><strong>Authors: </strong>Zhiquan Tan, Chenghai Li, Weiran Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03471">https://arxiv.org/abs/2402.03471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03471">https://arxiv.org/pdf/2402.03471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03471]] The Information of Large Language Model Geometry(https://arxiv.org/abs/2402.03471)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the information encoded in the embeddings of large language models (LLMs). We conduct simulations to analyze the representation entropy and discover a power law relationship with model sizes. Building upon this observation, we propose a theory based on (conditional) entropy to elucidate the scaling law phenomenon. Furthermore, we delve into the auto-regressive structure of LLMs and examine the relationship between the last token and previous context tokens using information theory and regression techniques. Specifically, we establish a theoretical connection between the information gain of new tokens and ridge regression. Additionally, we explore the effectiveness of Lasso regression in selecting meaningful tokens, which sometimes outperforms the closely related attention weights. Finally, we conduct controlled experiments, and find that information is distributed across tokens, rather than being concentrated in specific "meaningful" tokens alone.</li>
</ul>

<h3>Title: Arabic Synonym BERT-based Adversarial Examples for Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Norah Alshahrani, Saied Alshahrani, Esma Wali, Jeanna Matthews</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03477">https://arxiv.org/abs/2402.03477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03477">https://arxiv.org/pdf/2402.03477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03477]] Arabic Synonym BERT-based Adversarial Examples for Text Classification(https://arxiv.org/abs/2402.03477)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Text classification systems have been proven vulnerable to adversarial text examples, modified versions of the original text examples that are often unnoticed by human eyes, yet can force text classification models to alter their classification. Often, research works quantifying the impact of adversarial text attacks have been applied only to models trained in English. In this paper, we introduce the first word-level study of adversarial attacks in Arabic. Specifically, we use a synonym (word-level) attack using a Masked Language Modeling (MLM) task with a BERT model in a black-box setting to assess the robustness of the state-of-the-art text classification models to adversarial attacks in Arabic. To evaluate the grammatical and semantic similarities of the newly produced adversarial examples using our synonym BERT-based attack, we invite four human evaluators to assess and compare the produced adversarial examples with their original examples. We also study the transferability of these newly produced Arabic adversarial examples to various models and investigate the effectiveness of defense mechanisms against these adversarial examples on the BERT models. We find that fine-tuned BERT models were more susceptible to our synonym attacks than the other Deep Neural Networks (DNN) models like WordCNN and WordLSTM we trained. We also find that fine-tuned BERT models were more susceptible to transferred attacks. We, lastly, find that fine-tuned BERT models successfully regain at least 2% in accuracy after applying adversarial training as an initial defense mechanism.</li>
</ul>

<h3>Title: Hyper-Diffusion: Estimating Epistemic and Aleatoric Uncertainty with a  Single Model</h3>
<ul>
<li><strong>Authors: </strong>Matthew A. Chan, Maria J. Molina, Christopher A. Metzler</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03478">https://arxiv.org/abs/2402.03478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03478">https://arxiv.org/pdf/2402.03478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03478]] Hyper-Diffusion: Estimating Epistemic and Aleatoric Uncertainty with a  Single Model(https://arxiv.org/abs/2402.03478)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Estimating and disentangling epistemic uncertainty (uncertainty that can be reduced with more training data) and aleatoric uncertainty (uncertainty that is inherent to the task at hand) is critically important when applying machine learning (ML) to high-stakes applications such as medical imaging and weather forecasting. Conditional diffusion models' breakthrough ability to accurately and efficiently sample from the posterior distribution of a dataset now makes uncertainty estimation conceptually straightforward: One need only train and sample from a large ensemble of diffusion models. Unfortunately, training such an ensemble becomes computationally intractable as the complexity of the model architecture grows. In this work we introduce a new approach to ensembling, hyper-diffusion, which allows one to accurately estimate epistemic and aleatoric uncertainty with a single model. Unlike existing Monte Carlo dropout based single-model ensembling methods, hyper-diffusion offers the same prediction accuracy as multi-model ensembles. We validate our approach on two distinct tasks: x-ray computed tomography (CT) reconstruction and weather temperature forecasting.</li>
</ul>

<h3>Title: SWAG: Storytelling With Action Guidance</h3>
<ul>
<li><strong>Authors: </strong>Zeeshan Patel, Karim El-Refai, Jonathan Pei, Tianle Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03483">https://arxiv.org/abs/2402.03483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03483">https://arxiv.org/pdf/2402.03483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03483]] SWAG: Storytelling With Action Guidance(https://arxiv.org/abs/2402.03483)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automated long-form story generation typically employs long-context large language models (LLMs) for one-shot creation, which can produce cohesive but not necessarily engaging content. We introduce Storytelling With Action Guidance (SWAG), a novel approach to storytelling with LLMs. Our approach reduces story writing to a search problem through a two-model feedback loop: one LLM generates story content, and another auxiliary LLM is used to choose the next best "action" to steer the story's future direction. Our results show that SWAG can substantially outperform previous end-to-end story generation techniques when evaluated by GPT-4 and through human evaluation, and our SWAG pipeline using only open-source models surpasses GPT-3.5-Turbo.</li>
</ul>

<h3>Title: Early prediction of onset of sepsis in Clinical Setting</h3>
<ul>
<li><strong>Authors: </strong>Fahim Mohammad, Lakshmi Arunachalam, Samanway Sadhu, Boudewijn Aasman, Shweta Garg, Adil Ahmed, Silvie Colman, Meena Arunachalam, Sudhir Kulkarni, Parsa Mirhaji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03486">https://arxiv.org/abs/2402.03486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03486">https://arxiv.org/pdf/2402.03486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03486]] Early prediction of onset of sepsis in Clinical Setting(https://arxiv.org/abs/2402.03486)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study proposes the use of Machine Learning models to predict the early onset of sepsis using deidentified clinical data from Montefiore Medical Center in Bronx, NY, USA. A supervised learning approach was adopted, wherein an XGBoost model was trained utilizing 80\% of the train dataset, encompassing 107 features (including the original and derived features). Subsequently, the model was evaluated on the remaining 20\% of the test data. The model was validated on prospective data that was entirely unseen during the training phase. To assess the model's performance at the individual patient level and timeliness of the prediction, a normalized utility score was employed, a widely recognized scoring methodology for sepsis detection, as outlined in the PhysioNet Sepsis Challenge paper. Metrics such as F1 Score, Sensitivity, Specificity, and Flag Rate were also devised. The model achieved a normalized utility score of 0.494 on test data and 0.378 on prospective data at threshold 0.3. The F1 scores were 80.8\% and 67.1\% respectively for the test data and the prospective data for the same threshold, highlighting its potential to be integrated into clinical decision-making processes effectively. These results bear testament to the model's robust predictive capabilities and its potential to substantially impact clinical decision-making processes.</li>
</ul>

<h3>Title: Partially Stochastic Infinitely Deep Bayesian Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Sergio Calvo-Ordonez, Matthieu Meunier, Francesco Piatti, Yuantao Shi</a></li>
<li><strong>Subjects: </strong>cs.LG, math.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03495">https://arxiv.org/abs/2402.03495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03495">https://arxiv.org/pdf/2402.03495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03495]] Partially Stochastic Infinitely Deep Bayesian Neural Networks(https://arxiv.org/abs/2402.03495)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present Partially Stochastic Infinitely Deep Bayesian Neural Networks, a novel family of architectures that integrates partial stochasticity into the framework of infinitely deep neural networks. Our new class of architectures is designed to improve the limitations of existing architectures around computational efficiency at training and inference time. To do this, we leverage the advantages of partial stochasticity in the infinite-depth limit which include the benefits of full stochasticity e.g. robustness, uncertainty quantification, and memory efficiency, whilst improving their limitations around computational efficiency at training and inference time. We present a variety of architectural configurations, offering flexibility in network design including different methods for weight partition. We also provide mathematical guarantees on the expressivity of our models by establishing that our network family qualifies as Universal Conditional Distribution Approximators. Lastly, empirical evaluations across multiple tasks show that our proposed architectures achieve better downstream task performance and uncertainty quantification than their counterparts while being significantly more efficient.</li>
</ul>

<h3>Title: Can We Remove the Square-Root in Adaptive Gradient Methods? A  Second-Order Perspective</h3>
<ul>
<li><strong>Authors: </strong>Wu Lin, Felix Dangel, Runa Eschenhagen, Juhan Bae, Richard E. Turner, Alireza Makhzani</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03496">https://arxiv.org/abs/2402.03496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03496">https://arxiv.org/pdf/2402.03496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03496]] Can We Remove the Square-Root in Adaptive Gradient Methods? A  Second-Order Perspective(https://arxiv.org/abs/2402.03496)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Adaptive gradient optimizers like Adam(W) are the default training algorithms for many deep learning architectures, such as transformers. Their diagonal preconditioner is based on the gradient outer product which is incorporated into the parameter update via a square root. While these methods are often motivated as approximate second-order methods, the square root represents a fundamental difference. In this work, we investigate how the behavior of adaptive methods changes when we remove the root, i.e. strengthen their second-order motivation. Surprisingly, we find that such square-root-free adaptive methods close the generalization gap to SGD on convolutional architectures, while maintaining their root-based counterpart's performance on transformers. The second-order perspective also has practical benefits for the development of adaptive methods with non-diagonal preconditioner. In contrast to root-based counterparts like Shampoo, they do not require numerically unstable matrix square roots and therefore work well in low precision, which we demonstrate empirically. This raises important questions regarding the currently overlooked role of adaptivity for the success of adaptive methods.</li>
</ul>

<h3>Title: An Inpainting-Infused Pipeline for Attire and Background Replacement</h3>
<ul>
<li><strong>Authors: </strong>Felipe Rodrigues Perche-Mahlow, André Felipe-Zanella, William Alberto Cruz-Castañeda, Marcellus Amadeus</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03501">https://arxiv.org/abs/2402.03501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03501">https://arxiv.org/pdf/2402.03501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03501]] An Inpainting-Infused Pipeline for Attire and Background Replacement(https://arxiv.org/abs/2402.03501)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In recent years, groundbreaking advancements in Generative Artificial Intelligence (GenAI) have triggered a transformative paradigm shift, significantly influencing various domains. In this work, we specifically explore an integrated approach, leveraging advanced techniques in GenAI and computer vision emphasizing image manipulation. The methodology unfolds through several stages, including depth estimation, the creation of inpaint masks based on depth information, the generation and replacement of backgrounds utilizing Stable Diffusion in conjunction with Latent Consistency Models (LCMs), and the subsequent replacement of clothes and application of aesthetic changes through an inpainting pipeline. Experiments conducted in this study underscore the methodology's efficacy, highlighting its potential to produce visually captivating content. The convergence of these advanced techniques allows users to input photographs of individuals and manipulate them to modify clothing and background based on specific prompts without manually input inpainting masks, effectively placing the subjects within the vast landscape of creative imagination.</li>
</ul>

<h3>Title: Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains</h3>
<ul>
<li><strong>Authors: </strong>Sanjana Ramprasad, Kundan Krishna, Zachary C Lipton, Byron C Wallace</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03509">https://arxiv.org/abs/2402.03509</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03509">https://arxiv.org/pdf/2402.03509</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03509]] Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains(https://arxiv.org/abs/2402.03509)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent work has shown that large language models (LLMs) are capable of generating summaries zero-shot (i.e., without explicit supervision) that, under human assessment, are often comparable or even preferred to manually composed reference summaries. However, this prior work has focussed almost exclusively on evaluating news article summarization. How do zero-shot summarizers perform in other (potentially more specialized) domains? In this work we evaluate zero-shot generated summaries across specialized domains including biomedical articles, and legal bills (in addition to standard news benchmarks for reference). We focus especially on the factuality of outputs. We acquire annotations from domain experts to identify inconsistencies in summaries and systematically categorize these errors. We analyze whether the prevalence of a given domain in the pretraining corpus affects extractiveness and faithfulness of generated summaries of articles in this domain. We release all collected annotations to facilitate additional research toward measuring and realizing factually accurate summarization, beyond news articles. The dataset can be downloaded from https://github.com/sanjanaramprasad/zero_shot_faceval_domains</li>
</ul>

<h3>Title: Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical  System for Punctuation Restoration</h3>
<ul>
<li><strong>Authors: </strong>Xiliang Zhu, Chia-Tien Chang, Shayna Gardiner, David Rossouw, Jonas Robertson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03519">https://arxiv.org/abs/2402.03519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03519">https://arxiv.org/pdf/2402.03519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03519]] Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical  System for Punctuation Restoration(https://arxiv.org/abs/2402.03519)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Punctuation restoration is a crucial step after Automatic Speech Recognition (ASR) systems to enhance transcript readability and facilitate subsequent NLP tasks. Nevertheless, conventional lexical-based approaches are inadequate for solving the punctuation restoration task in Spanish, where ambiguity can be often found between unpunctuated declaratives and questions. In this study, we propose a novel hybrid acoustic-lexical punctuation restoration system for Spanish transcription, which consolidates acoustic and lexical signals through a modular process. Our experiment results show that the proposed system can effectively improve F1 score of question marks and overall punctuation restoration on both public and internal Spanish conversational datasets. Additionally, benchmark comparison against LLMs (Large Language Model) indicates the superiority of our approach in accuracy, reliability and latency. Furthermore, we demonstrate that the Word Error Rate (WER) of the ASR module also benefits from our proposed system.</li>
</ul>

<h3>Title: nnMamba: 3D Biomedical Image Segmentation, Classification and Landmark  Detection with State Space Model</h3>
<ul>
<li><strong>Authors: </strong>Haifan Gong, Luoyao Kang, Yitao Wang, Xiang Wan, Haofeng Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03526">https://arxiv.org/abs/2402.03526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03526">https://arxiv.org/pdf/2402.03526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03526]] nnMamba: 3D Biomedical Image Segmentation, Classification and Landmark  Detection with State Space Model(https://arxiv.org/abs/2402.03526)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In the field of biomedical image analysis, the quest for architectures capable of effectively capturing long-range dependencies is paramount, especially when dealing with 3D image segmentation, classification, and landmark detection. Traditional Convolutional Neural Networks (CNNs) struggle with locality respective field, and Transformers have a heavy computational load when applied to high-dimensional medical images. In this paper, we introduce nnMamba, a novel architecture that integrates the strengths of CNNs and the advanced long-range modeling capabilities of State Space Sequence Models (SSMs). nnMamba adds the SSMs to the convolutional residual-block to extract local features and model complex dependencies. For diffirent tasks, we build different blocks to learn the features. Extensive experiments demonstrate nnMamba's superiority over state-of-the-art methods in a suite of challenging tasks, including 3D image segmentation, classification, and landmark detection. nnMamba emerges as a robust solution, offering both the local representation ability of CNNs and the efficient global context processing of SSMs, setting a new standard for long-range dependency modeling in medical image analysis. Code is available at https://github.com/lhaof/nnMamba</li>
</ul>

<h3>Title: Fairness and Privacy Guarantees in Federated Contextual Bandits</h3>
<ul>
<li><strong>Authors: </strong>Sambhav Solanki, Shweta Jain, Sujit Gujar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03531">https://arxiv.org/abs/2402.03531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03531">https://arxiv.org/pdf/2402.03531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03531]] Fairness and Privacy Guarantees in Federated Contextual Bandits(https://arxiv.org/abs/2402.03531)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, fair</a></li>
<li><strong>Abstract: </strong>This paper considers the contextual multi-armed bandit (CMAB) problem with fairness and privacy guarantees in a federated environment. We consider merit-based exposure as the desired fair outcome, which provides exposure to each action in proportion to the reward associated. We model the algorithm's effectiveness using fairness regret, which captures the difference between fair optimal policy and the policy output by the algorithm. Applying fair CMAB algorithm to each agent individually leads to fairness regret linear in the number of agents. We propose that collaborative -- federated learning can be more effective and provide the algorithm Fed-FairX-LinUCB that also ensures differential privacy. The primary challenge in extending the existing privacy framework is designing the communication protocol for communicating required information across agents. A naive protocol can either lead to weaker privacy guarantees or higher regret. We design a novel communication protocol that allows for (i) Sub-linear theoretical bounds on fairness regret for Fed-FairX-LinUCB and comparable bounds for the private counterpart, Priv-FairX-LinUCB (relative to single-agent learning), (ii) Effective use of privacy budget in Priv-FairX-LinUCB. We demonstrate the efficacy of our proposed algorithm with extensive simulations-based experiments. We show that both Fed-FairX-LinUCB and Priv-FairX-LinUCB achieve near-optimal fairness regret.</li>
</ul>

<h3>Title: Regulation Games for Trustworthy Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Yaghini, Patty Liu, Franziska Boenisch, Nicolas Papernot</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03540">https://arxiv.org/abs/2402.03540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03540">https://arxiv.org/pdf/2402.03540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03540]] Regulation Games for Trustworthy Machine Learning(https://arxiv.org/abs/2402.03540)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>Existing work on trustworthy machine learning (ML) often concentrates on individual aspects of trust, such as fairness or privacy. Additionally, many techniques overlook the distinction between those who train ML models and those responsible for assessing their trustworthiness. To address these issues, we propose a framework that views trustworthy ML as a multi-objective multi-agent optimization problem. This naturally lends itself to a game-theoretic formulation we call regulation games. We illustrate a particular game instance, the SpecGame in which we model the relationship between an ML model builder and fairness and privacy regulators. Regulators wish to design penalties that enforce compliance with their specification, but do not want to discourage builders from participation. Seeking such socially optimal (i.e., efficient for all agents) solutions to the game, we introduce ParetoPlay. This novel equilibrium search algorithm ensures that agents remain on the Pareto frontier of their objectives and avoids the inefficiencies of other equilibria. Simulating SpecGame through ParetoPlay can provide policy guidance for ML Regulation. For instance, we show that for a gender classification application, regulators can enforce a differential privacy budget that is on average 4.0 lower if they take the initiative to specify their desired guarantee first.</li>
</ul>

<h3>Title: HAMLET: Graph Transformer Neural Operator for Partial Differential  Equations</h3>
<ul>
<li><strong>Authors: </strong>Andrey Bryutkin, Jiahao Huang, Zhongying Deng, Guang Yang, Carola-Bibiane Schönlieb, Angelica Aviles-Rivero</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03541">https://arxiv.org/abs/2402.03541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03541">https://arxiv.org/pdf/2402.03541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03541]] HAMLET: Graph Transformer Neural Operator for Partial Differential  Equations(https://arxiv.org/abs/2402.03541)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We present a novel graph transformer framework, HAMLET, designed to address the challenges in solving partial differential equations (PDEs) using neural networks. The framework uses graph transformers with modular input encoders to directly incorporate differential equation information into the solution process. This modularity enhances parameter correspondence control, making HAMLET adaptable to PDEs of arbitrary geometries and varied input formats. Notably, HAMLET scales effectively with increasing data complexity and noise, showcasing its robustness. HAMLET is not just tailored to a single type of physical simulation, but can be applied across various domains. Moreover, it boosts model resilience and performance, especially in scenarios with limited data. We demonstrate, through extensive experiments, that our framework is capable of outperforming current techniques for PDEs.</li>
</ul>

<h3>Title: Online Feature Updates Improve Online (Generalized) Label Shift  Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Ruihan Wu, Siddhartha Datta, Yi Su, Dheeraj Baby, Yu-Xiang Wang, Kilian Q. Weinberger</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03545">https://arxiv.org/abs/2402.03545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03545">https://arxiv.org/pdf/2402.03545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03545]] Online Feature Updates Improve Online (Generalized) Label Shift  Adaptation(https://arxiv.org/abs/2402.03545)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>This paper addresses the prevalent issue of label shift in an online setting with missing labels, where data distributions change over time and obtaining timely labels is challenging. While existing methods primarily focus on adjusting or updating the final layer of a pre-trained classifier, we explore the untapped potential of enhancing feature representations using unlabeled data at test-time. Our novel method, Online Label Shift adaptation with Online Feature Updates (OLS-OFU), leverages self-supervised learning to refine the feature extraction process, thereby improving the prediction model. Theoretical analyses confirm that OLS-OFU reduces algorithmic regret by capitalizing on self-supervised learning for feature refinement. Empirical studies on various datasets, under both online label shift and generalized label shift conditions, underscore the effectiveness and robustness of OLS-OFU, especially in cases of domain shifts.</li>
</ul>

<h3>Title: AnaMoDiff: 2D Analogical Motion Diffusion via Disentangled Denoising</h3>
<ul>
<li><strong>Authors: </strong>Maham Tanveer, Yizhi Wang, Ruiqi Wang, Nanxuan Zhao, Ali Mahdavi-Amiri, Hao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03549">https://arxiv.org/abs/2402.03549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03549">https://arxiv.org/pdf/2402.03549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03549]] AnaMoDiff: 2D Analogical Motion Diffusion via Disentangled Denoising(https://arxiv.org/abs/2402.03549)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present AnaMoDiff, a novel diffusion-based method for 2D motion analogies that is applied to raw, unannotated videos of articulated characters. Our goal is to accurately transfer motions from a 2D driving video onto a source character, with its identity, in terms of appearance and natural movement, well preserved, even when there may be significant discrepancies between the source and driving characters in their part proportions and movement speed and styles. Our diffusion model transfers the input motion via a latent optical flow (LOF) network operating in a noised latent space, which is spatially aware, efficient to process compared to the original RGB videos, and artifact-resistant through the diffusion denoising process even amid dense movements. To accomplish both motion analogy and identity preservation, we train our denoising model in a feature-disentangled manner, operating at two noise levels. While identity-revealing features of the source are learned via conventional noise injection, motion features are learned from LOF-warped videos by only injecting noise with large values, with the stipulation that motion properties involving pose and limbs are encoded by higher-level features. Experiments demonstrate that our method achieves the best trade-off between motion analogy and identity preservation.</li>
</ul>

<h3>Title: A security framework for Ethereum smart contracts</h3>
<ul>
<li><strong>Authors: </strong>Antonio López Vivar, Ana Lucila Sandoval Orozco, Luis Javier García Villalba</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03555">https://arxiv.org/abs/2402.03555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03555">https://arxiv.org/pdf/2402.03555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03555]] A security framework for Ethereum smart contracts(https://arxiv.org/abs/2402.03555)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The use of blockchain and smart contracts have not stopped growing in recent years. Like all software that begins to expand its use, it is also beginning to be targeted by hackers who will try to exploit vulnerabilities in both the underlying technology and the smart contract code itself. While many tools already exist for analyzing vulnerabilities in smart contracts, the heterogeneity and variety of approaches and differences in providing the analysis data makes the learning curve for the smart contract developer steep. In this article the authors present ESAF (Ethereum Security Analysis Framework), a framework for analysis of smart contracts that aims to unify and facilitate the task of analyzing smart contract vulnerabilities which can be used as a persistent security monitoring tool for a set of target contracts as well as a classic vulnerability analysis tool among other uses.</li>
</ul>

<h3>Title: Robust Analysis of Multi-Task Learning on a Complex Vision System</h3>
<ul>
<li><strong>Authors: </strong>Dayou Mao, Yuhao Chen, Yifan Wu, Maximilian Gilles, Alexander Wong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03557">https://arxiv.org/abs/2402.03557</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03557">https://arxiv.org/pdf/2402.03557</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03557]] Robust Analysis of Multi-Task Learning on a Complex Vision System(https://arxiv.org/abs/2402.03557)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-task learning (MTL) has been widely studied in the past decade. In particular, dozens of optimization algorithms have been proposed for different settings. While each of them claimed improvement when applied to certain models on certain datasets, there is still lack of deep understanding on the performance in complex real-worlds scenarios. We identify the gaps between research and application and make the following 4 contributions. (1) We comprehensively evaluate a large set of existing MTL optimization algorithms on the MetaGraspNet dataset designed for robotic grasping task, which is complex and has high real-world application values, and conclude the best-performing methods. (2) We empirically compare the method performance when applied on feature-level gradients versus parameter-level gradients over a large set of MTL optimization algorithms, and conclude that this feature-level gradients surrogate is reasonable when there are method-specific theoretical guarantee but not generalizable to all methods. (3) We provide insights on the problem of task interference and show that the existing perspectives of gradient angles and relative gradient norms do not precisely reflect the challenges of MTL, as the rankings of the methods based on these two indicators do not align well with those based on the test-set performance. (4) We provide a novel view of the task interference problem from the perspective of the latent space induced by the feature extractor and provide training monitoring results based on feature disentanglement.</li>
</ul>

<h3>Title: Path Signatures and Graph Neural Networks for Slow Earthquake Analysis:  Better Together?</h3>
<ul>
<li><strong>Authors: </strong>Hans Riess, Manolis Veveakis, Michael M. Zavlanos</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.geo-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03558">https://arxiv.org/abs/2402.03558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03558">https://arxiv.org/pdf/2402.03558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03558]] Path Signatures and Graph Neural Networks for Slow Earthquake Analysis:  Better Together?(https://arxiv.org/abs/2402.03558)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>The path signature, having enjoyed recent success in the machine learning community, is a theoretically-driven method for engineering features from irregular paths. On the other hand, graph neural networks (GNN), neural architectures for processing data on graphs, excel on tasks with irregular domains, such as sensor networks. In this paper, we introduce a novel approach, Path Signature Graph Convolutional Neural Networks (PS-GCNN), integrating path signatures into graph convolutional neural networks (GCNN), and leveraging the strengths of both path signatures, for feature extraction, and GCNNs, for handling spatial interactions. We apply our method to analyze slow earthquake sequences, also called slow slip events (SSE), utilizing data from GPS timeseries, with a case study on a GPS sensor network on the east coast of New Zealand's north island. We also establish benchmarks for our method on simulated stochastic differential equations, which model similar reaction-diffusion phenomenon. Our methodology shows promise for future advancement in earthquake prediction and sensor network analysis.</li>
</ul>

<h3>Title: Projected Generative Diffusion Models for Constraint Satisfaction</h3>
<ul>
<li><strong>Authors: </strong>Jacob K Christopher, Stephen Baek, Ferdinando Fioretto</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03559">https://arxiv.org/abs/2402.03559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03559">https://arxiv.org/pdf/2402.03559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03559]] Projected Generative Diffusion Models for Constraint Satisfaction(https://arxiv.org/abs/2402.03559)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative diffusion models excel at robustly synthesizing coherent content from raw noise through a sequential process. However, their direct application in scenarios requiring outputs to adhere to specific, stringent criteria faces several severe challenges. This paper aims at overcome these challenges and introduces Projected Generative Diffusion Models (PGDM), an approach that recast traditional diffusion models sampling into a constrained-optimization problem. This enables the application of an iterative projections method to ensure that generated data faithfully adheres to specified constraints or physical principles. This paper provides theoretical support for the ability of PGDM to synthesize outputs from a feasible subdistribution under a restricted class of constraints while also providing large empirical evidence in the case of complex non-convex constraints and ordinary differential equations. These capabilities are demonstrated by physics-informed motion in video generation, trajectory optimization in path planning, and morphometric properties adherence in material science.</li>
</ul>

<h3>Title: Distinguishing the Knowable from the Unknowable with Language Models</h3>
<ul>
<li><strong>Authors: </strong>Gustaf Ahdritz, Tian Qin, Nikhil Vyas, Boaz Barak, Benjamin L. Edelman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03563">https://arxiv.org/abs/2402.03563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03563">https://arxiv.org/pdf/2402.03563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03563]] Distinguishing the Knowable from the Unknowable with Language Models(https://arxiv.org/abs/2402.03563)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study the feasibility of identifying epistemic uncertainty (reflecting a lack of knowledge), as opposed to aleatoric uncertainty (reflecting entropy in the underlying distribution), in the outputs of large language models (LLMs) over free-form text. In the absence of ground-truth probabilities, we explore a setting where, in order to (approximately) disentangle a given LLM's uncertainty, a significantly larger model stands in as a proxy for the ground truth. We show that small linear probes trained on the embeddings of frozen, pretrained models accurately predict when larger models will be more confident at the token level and that probes trained on one text domain generalize to others. Going further, we propose a fully unsupervised method that achieves non-trivial accuracy on the same task. Taken together, we interpret these results as evidence that LLMs naturally contain internal representations of different types of uncertainty that could potentially be leveraged to devise more informative indicators of model confidence in diverse practical settings.</li>
</ul>

<h3>Title: Diffusion World Model</h3>
<ul>
<li><strong>Authors: </strong>Zihan Ding, Amy Zhang, Yuandong Tian, Qinqing Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03570">https://arxiv.org/abs/2402.03570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03570">https://arxiv.org/pdf/2402.03570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03570]] Diffusion World Model(https://arxiv.org/abs/2402.03570)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce Diffusion World Model (DWM), a conditional diffusion model capable of predicting multistep future states and rewards concurrently. As opposed to traditional one-step dynamics models, DWM offers long-horizon predictions in a single forward pass, eliminating the need for recursive quires. We integrate DWM into model-based value estimation, where the short-term return is simulated by future trajectories sampled from DWM. In the context of offline reinforcement learning, DWM can be viewed as a conservative value regularization through generative modeling. Alternatively, it can be seen as a data source that enables offline Q-learning with synthetic data. Our experiments on the D4RL dataset confirm the robustness of DWM to long-horizon simulation. In terms of absolute performance, DWM significantly surpasses one-step dynamics models with a $44\%$ performance gain, and achieves state-of-the-art performance.</li>
</ul>

<h3>Title: Generalization Properties of Adversarial Training for $\ell_0$-Bounded  Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Payam Delgosha, Hamed Hassani, Ramtin Pedarsani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03576">https://arxiv.org/abs/2402.03576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03576">https://arxiv.org/pdf/2402.03576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03576]] Generalization Properties of Adversarial Training for $\ell_0$-Bounded  Adversarial Attacks(https://arxiv.org/abs/2402.03576)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>We have widely observed that neural networks are vulnerable to small additive perturbations to the input causing misclassification. In this paper, we focus on the $\ell_0$-bounded adversarial attacks, and aim to theoretically characterize the performance of adversarial training for an important class of truncated classifiers. Such classifiers are shown to have strong performance empirically, as well as theoretically in the Gaussian mixture model, in the $\ell_0$-adversarial setting. The main contribution of this paper is to prove a novel generalization bound for the binary classification setting with $\ell_0$-bounded adversarial perturbation that is distribution-independent. Deriving a generalization bound in this setting has two main challenges: (i) the truncated inner product which is highly non-linear; and (ii) maximization over the $\ell_0$ ball due to adversarial training is non-convex and highly non-smooth. To tackle these challenges, we develop new coding techniques for bounding the combinatorial dimension of the truncated hypothesis class.</li>
</ul>

<h3>Title: A Reinforcement Learning Approach for Dynamic Rebalancing in  Bike-Sharing System</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Liang, Sanjay Dominik Jena, Defeng Liu, Andrea Lodi</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03589">https://arxiv.org/abs/2402.03589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03589">https://arxiv.org/pdf/2402.03589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03589]] A Reinforcement Learning Approach for Dynamic Rebalancing in  Bike-Sharing System(https://arxiv.org/abs/2402.03589)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Bike-Sharing Systems provide eco-friendly urban mobility, contributing to the alleviation of traffic congestion and to healthier lifestyles. Efficiently operating such systems and maintaining high customer satisfaction is challenging due to the stochastic nature of trip demand, leading to full or empty stations. Devising effective rebalancing strategies using vehicles to redistribute bikes among stations is therefore of uttermost importance for operators. As a promising alternative to classical mathematical optimization, reinforcement learning is gaining ground to solve sequential decision-making problems. This paper introduces a spatio-temporal reinforcement learning algorithm for the dynamic rebalancing problem with multiple vehicles. We first formulate the problem as a Multi-agent Markov Decision Process in a continuous time framework. This allows for independent and cooperative vehicle rebalancing, eliminating the impractical restriction of time-discretized models where vehicle departures are synchronized. A comprehensive simulator under the first-arrive-first-serve rule is then developed to facilitate the learning process by computing immediate rewards under diverse demand scenarios. To estimate the value function and learn the rebalancing policy, various Deep Q-Network configurations are tested, minimizing the lost demand. Experiments are carried out on various datasets generated from historical data, affected by both temporal and weather factors. The proposed algorithms outperform benchmarks, including a multi-period Mixed-Integer Programming model, in terms of lost demand. Once trained, it yields immediate decisions, making it suitable for real-time applications. Our work offers practical insights for operators and enriches the integration of reinforcement learning into dynamic rebalancing problems, paving the way for more intelligent and robust urban mobility solutions.</li>
</ul>

<h3>Title: Assessing the Impact of Distribution Shift on Reinforcement Learning  Performance</h3>
<ul>
<li><strong>Authors: </strong>Ted Fujimoto, Joshua Suetterlein, Samrat Chatterjee, Auroop Ganguly</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03590">https://arxiv.org/abs/2402.03590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03590">https://arxiv.org/pdf/2402.03590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03590]] Assessing the Impact of Distribution Shift on Reinforcement Learning  Performance(https://arxiv.org/abs/2402.03590)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Research in machine learning is making progress in fixing its own reproducibility crisis. Reinforcement learning (RL), in particular, faces its own set of unique challenges. Comparison of point estimates, and plots that show successful convergence to the optimal policy during training, may obfuscate overfitting or dependence on the experimental setup. Although researchers in RL have proposed reliability metrics that account for uncertainty to better understand each algorithm's strengths and weaknesses, the recommendations of past work do not assume the presence of out-of-distribution observations. We propose a set of evaluation methods that measure the robustness of RL algorithms under distribution shifts. The tools presented here argue for the need to account for performance over time while the agent is acting in its environment. In particular, we recommend time series analysis as a method of observational RL evaluation. We also show that the unique properties of RL and simulated dynamic environments allow us to make stronger assumptions to justify the measurement of causal impact in our evaluations. We then apply these tools to single-agent and multi-agent environments to show the impact of introducing distribution shifts during test time. We present this methodology as a first step toward rigorous RL evaluation in the presence of distribution shifts.</li>
</ul>

<h3>Title: GRASP: GRAph-Structured Pyramidal Whole Slide Image Representation</h3>
<ul>
<li><strong>Authors: </strong>Ali Khajegili Mirabadi, Graham Archibald, Amirali Darbandsari, Alberto Contreras-Sanz, Ramin Ebrahim Nakhli, Maryam Asadi, Allen Zhang, C. Blake Gilks, Peter Black, Gang Wang, Hossein Farahani, Ali Bashashati</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03592">https://arxiv.org/abs/2402.03592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03592">https://arxiv.org/pdf/2402.03592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03592]] GRASP: GRAph-Structured Pyramidal Whole Slide Image Representation(https://arxiv.org/abs/2402.03592)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Cancer subtyping is one of the most challenging tasks in digital pathology, where Multiple Instance Learning (MIL) by processing gigapixel whole slide images (WSIs) has been in the spotlight of recent research. However, MIL approaches do not take advantage of inter- and intra-magnification information contained in WSIs. In this work, we present GRASP, a novel graph-structured multi-magnification framework for processing WSIs in digital pathology. Our approach is designed to dynamically emulate the pathologist's behavior in handling WSIs and benefits from the hierarchical structure of WSIs. GRASP, which introduces a convergence-based node aggregation instead of traditional pooling mechanisms, outperforms state-of-the-art methods over two distinct cancer datasets by a margin of up to 10% balanced accuracy, while being 7 times smaller than the closest-performing state-of-the-art model in terms of the number of parameters. Our results show that GRASP is dynamic in finding and consulting with different magnifications for subtyping cancers and is reliable and stable across different hyperparameters. The model's behavior has been evaluated by two expert pathologists confirming the interpretability of the model's dynamic. We also provide a theoretical foundation, along with empirical evidence, for our work, explaining how GRASP interacts with different magnifications and nodes in the graph to make predictions. We believe that the strong characteristics yet simple structure of GRASP will encourage the development of interpretable, structure-based designs for WSI representation in digital pathology. Furthermore, we publish two large graph datasets of rare Ovarian and Bladder cancers to contribute to the field.</li>
</ul>

<h3>Title: Identifying Reasons for Contraceptive Switching from Real-World Data  Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Brenda Y. Miao, Christopher YK Williams, Ebenezer Chinedu-Eneh, Travis Zack, Emily Alsentzer, Atul J. Butte, Irene Y. Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03597">https://arxiv.org/abs/2402.03597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03597">https://arxiv.org/pdf/2402.03597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03597]] Identifying Reasons for Contraceptive Switching from Real-World Data  Using Large Language Models(https://arxiv.org/abs/2402.03597)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Prescription contraceptives play a critical role in supporting women's reproductive health. With nearly 50 million women in the United States using contraceptives, understanding the factors that drive contraceptives selection and switching is of significant interest. However, many factors related to medication switching are often only captured in unstructured clinical notes and can be difficult to extract. Here, we evaluate the zero-shot abilities of a recently developed large language model, GPT-4 (via HIPAA-compliant Microsoft Azure API), to identify reasons for switching between classes of contraceptives from the UCSF Information Commons clinical notes dataset. We demonstrate that GPT-4 can accurately extract reasons for contraceptive switching, outperforming baseline BERT-based models with microF1 scores of 0.849 and 0.881 for contraceptive start and stop extraction, respectively. Human evaluation of GPT-4-extracted reasons for switching showed 91.4% accuracy, with minimal hallucinations. Using extracted reasons, we identified patient preference, adverse events, and insurance as key reasons for switching using unsupervised topic modeling approaches. Notably, we also showed using our approach that "weight gain/mood change" and "insurance coverage" are disproportionately found as reasons for contraceptive switching in specific demographic populations. Our code and supplemental data are available at https://github.com/BMiao10/contraceptive-switching.</li>
</ul>

<h3>Title: RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal  LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Tomoyuki Kagaya, Thong Jing Yuan, Yuxuan Lou, Jayashree Karlekar, Sugiri Pranata, Akira Kinose, Koki Oguri, Felix Wick, Yang You</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03610">https://arxiv.org/abs/2402.03610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03610">https://arxiv.org/pdf/2402.03610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03610]] RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal  LLM Agents(https://arxiv.org/abs/2402.03610)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Owing to recent advancements, Large Language Models (LLMs) can now be deployed as agents for increasingly complex decision-making applications in areas including robotics, gaming, and API integration. However, reflecting past experiences in current decision-making processes, an innate human behavior, continues to pose significant challenges. Addressing this, we propose Retrieval-Augmented Planning (RAP) framework, designed to dynamically leverage past experiences corresponding to the current situation and context, thereby enhancing agents' planning capabilities. RAP distinguishes itself by being versatile: it excels in both text-only and multimodal environments, making it suitable for a wide range of tasks. Empirical evaluations demonstrate RAP's effectiveness, where it achieves SOTA performance in textual scenarios and notably enhances multimodal LLM agents' performance for embodied tasks. These results highlight RAP's potential in advancing the functionality and applicability of LLM agents in complex, real-world applications.</li>
</ul>

<h3>Title: Privacy risk in GeoData: A survey</h3>
<ul>
<li><strong>Authors: </strong>Mahrokh Abdollahi Lorestani, Thilina Ranbaduge, Thierry Rakotoarivelo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03612">https://arxiv.org/abs/2402.03612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03612">https://arxiv.org/pdf/2402.03612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03612]] Privacy risk in GeoData: A survey(https://arxiv.org/abs/2402.03612)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>With the ubiquitous use of location-based services, large-scale individual-level location data has been widely collected through location-awareness devices. The exposure of location data constitutes a significant privacy risk to users as it can lead to de-anonymisation, the inference of sensitive information, and even physical threats. Geoprivacy concerns arise on the issues of user identity de-anonymisation and location exposure. In this survey, we analyse different geomasking techniques that have been proposed to protect the privacy of individuals in geodata. We present a taxonomy to characterise these techniques along different dimensions, and conduct a survey of geomasking techniques. We then highlight shortcomings of current techniques and discuss avenues for future research.</li>
</ul>

<h3>Title: Leveraging Large Language Models for Hybrid Workplace Decision Support</h3>
<ul>
<li><strong>Authors: </strong>Yujin Kim, Chin-Chia Hsu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03616">https://arxiv.org/abs/2402.03616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03616">https://arxiv.org/pdf/2402.03616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03616]] Leveraging Large Language Models for Hybrid Workplace Decision Support(https://arxiv.org/abs/2402.03616)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) hold the potential to perform a variety of text processing tasks and provide textual explanations for proposed actions or decisions. In the era of hybrid work, LLMs can provide intelligent decision support for workers who are designing their hybrid work plans. In particular, they can offer suggestions and explanations to workers balancing numerous decision factors, thereby enhancing their work experience. In this paper, we present a decision support model for workspaces in hybrid work environments, leveraging the reasoning skill of LLMs. We first examine LLM's capability of making suitable workspace suggestions. We find that its reasoning extends beyond the guidelines in the prompt and the LLM can manage the trade-off among the available resources in the workspaces. We conduct an extensive user study to understand workers' decision process for workspace choices and evaluate the effectiveness of the system. We observe that a worker's decision could be influenced by the LLM's suggestions and explanations. The participants in our study find the system to be convenient, regardless of whether reasons are provided or not. Our results show that employees can benefit from the LLM-empowered system for their workspace selection in hybrid workplace.</li>
</ul>

<h3>Title: Partially Recentralization Softmax Loss for Vision-Language Models  Robustness</h3>
<ul>
<li><strong>Authors: </strong>Hao Wang, Xin Zhang, Jinzhe Jiang, Yaqian Zhao, Chen Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03627">https://arxiv.org/abs/2402.03627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03627">https://arxiv.org/pdf/2402.03627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03627]] Partially Recentralization Softmax Loss for Vision-Language Models  Robustness(https://arxiv.org/abs/2402.03627)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models make a breakthrough in natural language processing tasks (NLP), multimodal technique becomes extremely popular. However, it has been shown that multimodal NLP are vulnerable to adversarial attacks, where the outputs of a model can be dramatically changed by a perturbation to the input. While several defense techniques have been proposed both in computer vision and NLP models, the multimodal robustness of models have not been fully explored. In this paper, we study the adversarial robustness provided by modifying loss function of pre-trained multimodal models, by restricting top K softmax outputs. Based on the evaluation and scoring, our experiments show that after a fine-tuning, adversarial robustness of pre-trained models can be significantly improved, against popular attacks. Further research should be studying, such as output diversity, generalization and the robustness-performance trade-off of this kind of loss functions. Our code will be available after this paper is accepted</li>
</ul>

<h3>Title: Professional Agents -- Evolving Large Language Models into Autonomous  Experts with Human-Level Competencies</h3>
<ul>
<li><strong>Authors: </strong>Zhixuan Chu, Yan Wang, Feng Zhu, Lu Yu, Longfei Li, Jinjie Gu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03628">https://arxiv.org/abs/2402.03628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03628">https://arxiv.org/pdf/2402.03628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03628]] Professional Agents -- Evolving Large Language Models into Autonomous  Experts with Human-Level Competencies(https://arxiv.org/abs/2402.03628)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of large language models (LLMs) such as ChatGPT, PaLM, and GPT-4 has catalyzed remarkable advances in natural language processing, demonstrating human-like language fluency and reasoning capacities. This position paper introduces the concept of Professional Agents (PAgents), an application framework harnessing LLM capabilities to create autonomous agents with controllable, specialized, interactive, and professional-level competencies. We posit that PAgents can reshape professional services through continuously developed expertise. Our proposed PAgents framework entails a tri-layered architecture for genesis, evolution, and synergy: a base tool layer, a middle agent layer, and a top synergy layer. This paper aims to spur discourse on promising real-world applications of LLMs. We argue the increasing sophistication and integration of PAgents could lead to AI systems exhibiting professional mastery over complex domains, serving critical needs, and potentially achieving artificial general intelligence.</li>
</ul>

<h3>Title: Disparate Impact on Group Accuracy of Linearization for Private  Inference</h3>
<ul>
<li><strong>Authors: </strong>Saswat Das, Marco Romanelli, Ferdinando Fioretto</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03629">https://arxiv.org/abs/2402.03629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03629">https://arxiv.org/pdf/2402.03629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03629]] Disparate Impact on Group Accuracy of Linearization for Private  Inference(https://arxiv.org/abs/2402.03629)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, fair</a></li>
<li><strong>Abstract: </strong>Ensuring privacy-preserving inference on cryptographically secure data is a well-known computational challenge. To alleviate the bottleneck of costly cryptographic computations in non-linear activations, recent methods have suggested linearizing a targeted portion of these activations in neural networks. This technique results in significantly reduced runtimes with often negligible impacts on accuracy. In this paper, we demonstrate that such computational benefits may lead to increased fairness costs. Specifically, we find that reducing the number of ReLU activations disproportionately decreases the accuracy for minority groups compared to majority groups. To explain these observations, we provide a mathematical interpretation under restricted assumptions about the nature of the decision boundary, while also showing the prevalence of this problem across widely used datasets and architectures. Finally, we show how a simple procedure altering the fine-tuning step for linearized models can serve as an effective mitigation strategy.</li>
</ul>

<h3>Title: CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of  Segmentation Anything Model</h3>
<ul>
<li><strong>Authors: </strong>Aoran Xiao, Weihao Xuan, Heli Qi, Yun Xing, Ruijie Ren, Xiaoqin Zhang, Shijian Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03631">https://arxiv.org/abs/2402.03631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03631">https://arxiv.org/pdf/2402.03631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03631]] CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of  Segmentation Anything Model(https://arxiv.org/abs/2402.03631)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The recent Segment Anything Model (SAM) has demonstrated remarkable zero-shot capability and flexible geometric prompting in general image segmentation. However, SAM often struggles when handling various unconventional images, such as aerial, medical, and non-RGB images. This paper presents CAT-SAM, a ConditionAl Tuning network that adapts SAM toward various unconventional target tasks with just few-shot target samples. CAT-SAM freezes the entire SAM and adapts its mask decoder and image encoder simultaneously with a small number of learnable parameters. The core design is a prompt bridge structure that enables decoder-conditioned joint tuning of the heavyweight image encoder and the lightweight mask decoder. The bridging maps the prompt token of the mask decoder to the image encoder, fostering synergic adaptation of the encoder and the decoder with mutual benefits. We develop two representative tuning strategies for the image encoder which leads to two CAT-SAM variants: one injecting learnable prompt tokens in the input space and the other inserting lightweight adapter networks. Extensive experiments over 11 unconventional tasks show that both CAT-SAM variants achieve superior target segmentation performance consistently even under the very challenging one-shot adaptation setup. Project page: \url{https://xiaoaoran.github.io/projects/CAT-SAM}</li>
</ul>

<h3>Title: Lossy Cryptography from Code-Based Assumptions</h3>
<ul>
<li><strong>Authors: </strong>Quang Dao, Aayush Jain</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CC, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03633">https://arxiv.org/abs/2402.03633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03633">https://arxiv.org/pdf/2402.03633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03633]] Lossy Cryptography from Code-Based Assumptions(https://arxiv.org/abs/2402.03633)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Over the past few decades, we have seen a proliferation of advanced cryptographic primitives with lossy or homomorphic properties built from various assumptions such as Quadratic Residuosity, Decisional Diffie-Hellman, and Learning with Errors. These primitives imply hard problems in the complexity class $SZK$ (statistical zero-knowledge); as a consequence, they can only be based on assumptions that are broken in $BPP^{SZK}$. This poses a barrier for building advanced primitives from code-based assumptions, as the only known such assumption is Learning Parity with Noise (LPN) with an extremely low noise rate $\frac{\log^2 n}{n}$, which is broken in quasi-polynomial time. In this work, we propose a new code-based assumption: Dense-Sparse LPN, that falls in the complexity class $BPP^{SZK}$ and is conjectured to be secure against subexponential time adversaries. Our assumption is a variant of LPN that is inspired by McEliece's cryptosystem and random $k\mbox{-}$XOR in average-case complexity. We leverage our assumption to build lossy trapdoor functions (Peikert-Waters STOC 08). This gives the first post-quantum alternative to the lattice-based construction in the original paper. Lossy trapdoor functions, being a fundamental cryptographic tool, are known to enable a broad spectrum of both lossy and non-lossy cryptographic primitives; our construction thus implies these primitives in a generic manner. In particular, we achieve collision-resistant hash functions with plausible subexponential security, improving over a prior construction from LPN with noise rate $\frac{\log^2 n}{n}$ that is only quasi-polynomially secure.</li>
</ul>

<h3>Title: Lens: A Foundation Model for Network Traffic</h3>
<ul>
<li><strong>Authors: </strong>Qineng Wang, Chen Qian, Xiaochang Li, Ziyu Yao, Huajie Shao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03646">https://arxiv.org/abs/2402.03646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03646">https://arxiv.org/pdf/2402.03646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03646]] Lens: A Foundation Model for Network Traffic(https://arxiv.org/abs/2402.03646)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer, generative</a></li>
<li><strong>Abstract: </strong>Network traffic refers to the amount of information being sent and received over the internet or any system that connects computers. Analyzing and understanding network traffic is vital for improving network security and management. However, the analysis of network traffic poses great challenges due to the unique characteristics of data packets, such as heterogeneous headers and encrypted payload lacking semantics. To capture the latent semantics of traffic, a few studies have adopted pre-training techniques based on the Transformer encoder or decoder to learn the representations from large-scale traffic data. However, these methods typically excel only in traffic understanding (classification) or traffic generation tasks. To address this issue, we develop Lens, a foundational network traffic model that leverages the T5 architecture to learn the pre-trained representations from large-scale unlabeled data. Harnessing the strength of the encoder-decoder framework, which captures the global information while preserving the generative ability, our model can better learn the representations from large-scale network traffic. To further enhance pre-training performance, we design a novel loss that integrates three distinct tasks, namely Masked Span Prediction (MSP), Packet Order Prediction (POP), and Homologous Traffic Prediction (HTP). Evaluation results on multiple benchmark datasets demonstrate that the proposed Lens outperforms the baselines in most downstream tasks related to both traffic understanding and traffic generation. Notably, it also requires considerably less labeled data for fine-tuning compared to current methods.</li>
</ul>

<h3>Title: Reviewing FID and SID Metrics on Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Ricardo de Deijn, Aishwarya Batra, Brandon Koch, Naseef Mansoor, Hema Makkena</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03654">https://arxiv.org/abs/2402.03654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03654">https://arxiv.org/pdf/2402.03654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03654]] Reviewing FID and SID Metrics on Generative Adversarial Networks(https://arxiv.org/abs/2402.03654)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The growth of generative adversarial network (GAN) models has increased the ability of image processing and provides numerous industries with the technology to produce realistic image transformations. However, with the field being recently established there are new evaluation metrics that can further this research. Previous research has shown the Fr\'echet Inception Distance (FID) to be an effective metric when testing these image-to-image GANs in real-world applications. Signed Inception Distance (SID), a founded metric in 2023, expands on FID by allowing unsigned distances. This paper uses public datasets that consist of fa\c{c}ades, cityscapes, and maps within Pix2Pix and CycleGAN models. After training these models are evaluated on both inception distance metrics which measure the generating performance of the trained models. Our findings indicate that usage of the metric SID incorporates an efficient and effective metric to complement, or even exceed the ability shown using the FID for the image-to-image GANs</li>
</ul>

<h3>Title: Sentiment-enhanced Graph-based Sarcasm Explanation in Dialogue</h3>
<ul>
<li><strong>Authors: </strong>Kun Ouyang, Liqiang Jing, Xuemeng Song, Meng Liu, Yupeng Hu, Liqiang Nie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03658">https://arxiv.org/abs/2402.03658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03658">https://arxiv.org/pdf/2402.03658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03658]] Sentiment-enhanced Graph-based Sarcasm Explanation in Dialogue(https://arxiv.org/abs/2402.03658)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Sarcasm Explanation in Dialogue (SED) is a new yet challenging task, which aims to generate a natural language explanation for the given sarcastic dialogue that involves multiple modalities (i.e., utterance, video, and audio). Although existing studies have achieved great success based on the generative pretrained language model BART, they overlook exploiting the sentiments residing in the utterance, video and audio, which are vital clues for sarcasm explanation. In fact, it is non-trivial to incorporate sentiments for boosting SED performance, due to three main challenges: 1) diverse effects of utterance tokens on sentiments; 2) gap between video-audio sentiment signals and the embedding space of BART; and 3) various relations among utterances, utterance sentiments, and video-audio sentiments. To tackle these challenges, we propose a novel sEntiment-enhanceD Graph-based multimodal sarcasm Explanation framework, named EDGE. In particular, we first propose a lexicon-guided utterance sentiment inference module, where a heuristic utterance sentiment refinement strategy is devised. We then develop a module named Joint Cross Attention-based Sentiment Inference (JCA-SI) by extending the multimodal sentiment analysis model JCA to derive the joint sentiment label for each video-audio clip. Thereafter, we devise a context-sentiment graph to comprehensively model the semantic relations among the utterances, utterance sentiments, and video-audio sentiments, to facilitate sarcasm explanation generation. Extensive experiments on the publicly released dataset WITS verify the superiority of our model over cutting-edge methods.</li>
</ul>

<h3>Title: Learning to Generate Explainable Stock Predictions using Self-Reflective  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kelvin J.L. Koa, Yunshan Ma, Ritchie Ng, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, q-fin.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03659">https://arxiv.org/abs/2402.03659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03659">https://arxiv.org/pdf/2402.03659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03659]] Learning to Generate Explainable Stock Predictions using Self-Reflective  Large Language Models(https://arxiv.org/abs/2402.03659)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a self-reflective agent and Proximal Policy Optimization (PPO) to let a LLM teach itself how to generate explainable stock predictions in a fully autonomous manner. The reflective agent learns how to explain past stock movements through self-reasoning, while the PPO trainer trains the model to generate the most likely explanations from input texts. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics.</li>
</ul>

<h3>Title: Symbol Correctness in Deep Neural Networks Containing Symbolic Layers</h3>
<ul>
<li><strong>Authors: </strong>Aaron Bembenek, Toby Murray</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03663">https://arxiv.org/abs/2402.03663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03663">https://arxiv.org/pdf/2402.03663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03663]] Symbol Correctness in Deep Neural Networks Containing Symbolic Layers(https://arxiv.org/abs/2402.03663)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>To handle AI tasks that combine perception and logical reasoning, recent work introduces Neurosymbolic Deep Neural Networks (NS-DNNs), which contain -- in addition to traditional neural layers -- symbolic layers: symbolic expressions (e.g., SAT formulas, logic programs) that are evaluated by symbolic solvers during inference. We identify and formalize an intuitive, high-level principle that can guide the design and analysis of NS-DNNs: symbol correctness, the correctness of the intermediate symbols predicted by the neural layers with respect to a (generally unknown) ground-truth symbolic representation of the input data. We demonstrate that symbol correctness is a necessary property for NS-DNN explainability and transfer learning (despite being in general impossible to train for). Moreover, we show that the framework of symbol correctness provides a precise way to reason and communicate about model behavior at neural-symbolic boundaries, and gives insight into the fundamental tradeoffs faced by NS-DNN training algorithms. In doing so, we both identify significant points of ambiguity in prior work, and provide a framework to support further NS-DNN developments.</li>
</ul>

<h3>Title: QuEST: Low-bit Diffusion Model Quantization via Efficient Selective  Finetuning</h3>
<ul>
<li><strong>Authors: </strong>Haoxuan Wang, Yuzhang Shang, Zhihang Yuan, Junyi Wu, Yan Yan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03666">https://arxiv.org/abs/2402.03666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03666">https://arxiv.org/pdf/2402.03666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03666]] QuEST: Low-bit Diffusion Model Quantization via Efficient Selective  Finetuning(https://arxiv.org/abs/2402.03666)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved remarkable success in image generation tasks, yet their practical deployment is restrained by the high memory and time consumption. While quantization paves a way for diffusion model compression and acceleration, existing methods totally fail when the models are quantized to low-bits. In this paper, we unravel three properties in quantized diffusion models that compromise the efficacy of current methods: imbalanced activation distributions, imprecise temporal information, and vulnerability to perturbations of specific modules. To alleviate the intensified low-bit quantization difficulty stemming from the distribution imbalance, we propose finetuning the quantized model to better adapt to the activation distribution. Building on this idea, we identify two critical types of quantized layers: those holding vital temporal information and those sensitive to reduced bit-width, and finetune them to mitigate performance degradation with efficiency. We empirically verify that our approach modifies the activation distribution and provides meaningful temporal information, facilitating easier and more accurate quantization. Our method is evaluated over three high-resolution image generation tasks and achieves state-of-the-art performance under various bit-width settings, as well as being the first method to generate readable images on full 4-bit (i.e. W4A4) Stable Diffusion.</li>
</ul>

<h3>Title: Large Language Models as an Indirect Reasoner: Contrapositive and  Contradiction for Automated Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yanfang Zhang, Yiliu Sun, Yibing Zhan, Dapeng Tao, Dacheng Tao, Chen Gong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03667">https://arxiv.org/abs/2402.03667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03667">https://arxiv.org/pdf/2402.03667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03667]] Large Language Models as an Indirect Reasoner: Contrapositive and  Contradiction for Automated Reasoning(https://arxiv.org/abs/2402.03667)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, increasing attention has been focused drawn on to improve the ability of Large Language Models (LLMs) to perform complex reasoning. However, previous methods, such as Chain-of-Thought and Self-Consistency, mainly follow Direct Reasoning (DR) frameworks, so they will meet difficulty in solving numerous real-world tasks which can hardly be solved via DR. Therefore, to strengthen the reasoning power of LLMs, this paper proposes a novel Indirect Reasoning (IR) method that employs the logic of contrapositives and contradictions to tackle IR tasks such as factual reasoning and mathematic proof. Specifically, our methodology comprises two steps. Firstly, we leverage the logical equivalence of contrapositive to augment the data and rules to enhance the comprehensibility of LLMs. Secondly, we design a set of prompt templates to trigger LLMs to conduct IR based on proof by contradiction that is logically equivalent to the original DR process. Our IR method is simple yet effective and can be straightforwardly integrated with existing DR methods to further boost the reasoning abilities of LLMs. The experimental results on popular LLMs, such as GPT-3.5-turbo and Gemini-pro, show that our IR method enhances the overall accuracy of factual reasoning by 27.33% and mathematical proof by 31.43%, when compared with traditional DR methods. Moreover, the methods combining IR and DR significantly outperform the methods solely using IR or DR, further demonstrating the effectiveness of our strategy.</li>
</ul>

<h3>Title: Minds versus Machines: Rethinking Entailment Verification with Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Soumya Sanyal, Tianyi Xiao, Jiacheng Liu, Wenya Wang, Xiang Ren</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03686">https://arxiv.org/abs/2402.03686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03686">https://arxiv.org/pdf/2402.03686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03686]] Minds versus Machines: Rethinking Entailment Verification with Language  Models(https://arxiv.org/abs/2402.03686)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Humans make numerous inferences in text comprehension to understand discourse. This paper aims to understand the commonalities and disparities in the inference judgments between humans and state-of-the-art Large Language Models (LLMs). Leveraging a comprehensively curated entailment verification benchmark, we evaluate both human and LLM performance across various reasoning categories. Our benchmark includes datasets from three categories (NLI, contextual QA, and rationales) that include multi-sentence premises and different knowledge types, thereby evaluating the inference capabilities in complex reasoning instances. Notably, our findings reveal LLMs' superiority in multi-hop reasoning across extended contexts, while humans excel in tasks necessitating simple deductive reasoning. Leveraging these insights, we introduce a fine-tuned Flan-T5 model that outperforms GPT-3.5 and rivals with GPT-4, offering a robust open-source solution for entailment verification. As a practical application, we showcase the efficacy of our finetuned model in enhancing self-consistency in model-generated explanations, resulting in a 6% performance boost on average across three multiple-choice question-answering datasets.</li>
</ul>

<h3>Title: Pard: Permutation-Invariant Autoregressive Diffusion for Graph  Generation</h3>
<ul>
<li><strong>Authors: </strong>Lingxiao Zhao, Xueying Ding, Leman Akoglu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03687">https://arxiv.org/abs/2402.03687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03687">https://arxiv.org/pdf/2402.03687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03687]] Pard: Permutation-Invariant Autoregressive Diffusion for Graph  Generation(https://arxiv.org/abs/2402.03687)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Graph generation has been dominated by autoregressive models due to their simplicity and effectiveness, despite their sensitivity to ordering. Yet diffusion models have garnered increasing attention, as they offer comparable performance while being permutation-invariant. Current graph diffusion models generate graphs in a one-shot fashion, but they require extra features and thousands of denoising steps to achieve optimal performance. We introduce PARD, a Permutation-invariant Auto Regressive Diffusion model that integrates diffusion models with autoregressive methods. PARD harnesses the effectiveness and efficiency of the autoregressive model while maintaining permutation invariance without ordering sensitivity. Specifically, we show that contrary to sets, elements in a graph are not entirely unordered and there is a unique partial order for nodes and edges. With this partial order, PARD generates a graph in a block-by-block, autoregressive fashion, where each block's probability is conditionally modeled by a shared diffusion model with an equivariant network. To ensure efficiency while being expressive, we further propose a higher-order graph transformer, which integrates transformer with PPGN. Like GPT, we extend the higher-order graph transformer to support parallel training of all blocks. Without any extra features, PARD achieves state-of-the-art performance on molecular and non-molecular datasets, and scales to large datasets like MOSES containing 1.9M molecules.</li>
</ul>

<h3>Title: A Survey of Privacy Threats and Defense in Vertical Federated Learning:  From Model Life Cycle Perspective</h3>
<ul>
<li><strong>Authors: </strong>Lei Yu, Meng Han, Yiming Li, Changting Lin, Yao Zhang, Mingyang Zhang, Yan Liu, Haiqin Weng, Yuseok Jeon, Ka-Ho Chow, Stacy Patterson</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03688">https://arxiv.org/abs/2402.03688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03688">https://arxiv.org/pdf/2402.03688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03688]] A Survey of Privacy Threats and Defense in Vertical Federated Learning:  From Model Life Cycle Perspective(https://arxiv.org/abs/2402.03688)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Vertical Federated Learning (VFL) is a federated learning paradigm where multiple participants, who share the same set of samples but hold different features, jointly train machine learning models. Although VFL enables collaborative machine learning without sharing raw data, it is still susceptible to various privacy threats. In this paper, we conduct the first comprehensive survey of the state-of-the-art in privacy attacks and defenses in VFL. We provide taxonomies for both attacks and defenses, based on their characterizations, and discuss open challenges and future research directions. Specifically, our discussion is structured around the model's life cycle, by delving into the privacy threats encountered during different stages of machine learning and their corresponding countermeasures. This survey not only serves as a resource for the research community but also offers clear guidance and actionable insights for practitioners to safeguard data privacy throughout the model's life cycle.</li>
</ul>

<h3>Title: SHMC-Net: A Mask-guided Feature Fusion Network for Sperm Head Morphology  Classification</h3>
<ul>
<li><strong>Authors: </strong>Nishchal Sapkota, Yejia Zhang, Sirui Li, Peixian Liang, Zhuo Zhao, Danny Z Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03697">https://arxiv.org/abs/2402.03697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03697">https://arxiv.org/pdf/2402.03697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03697]] SHMC-Net: A Mask-guided Feature Fusion Network for Sperm Head Morphology  Classification(https://arxiv.org/abs/2402.03697)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Male infertility accounts for about one-third of global infertility cases. Manual assessment of sperm abnormalities through head morphology analysis encounters issues of observer variability and diagnostic discrepancies among experts. Its alternative, Computer-Assisted Semen Analysis (CASA), suffers from low-quality sperm images, small datasets, and noisy class labels. We propose a new approach for sperm head morphology classification, called SHMC-Net, which uses segmentation masks of sperm heads to guide the morphology classification of sperm images. SHMC-Net generates reliable segmentation masks using image priors, refines object boundaries with an efficient graph-based method, and trains an image network with sperm head crops and a mask network with the corresponding masks. In the intermediate stages of the networks, image and mask features are fused with a fusion scheme to better learn morphological features. To handle noisy class labels and regularize training on small datasets, SHMC-Net applies Soft Mixup to combine mixup augmentation and a loss function. We achieve state-of-the-art results on SCIAN and HuSHeM datasets, outperforming methods that use additional pre-training or costly ensembling techniques.</li>
</ul>

<h3>Title: Improving and Unifying Discrete&Continuous-time Discrete Denoising  Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Lingxiao Zhao, Xueying Ding, Lijun Yu, Leman Akoglu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03701">https://arxiv.org/abs/2402.03701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03701">https://arxiv.org/pdf/2402.03701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03701]] Improving and Unifying Discrete&Continuous-time Discrete Denoising  Diffusion(https://arxiv.org/abs/2402.03701)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Discrete diffusion models have seen a surge of attention with applications on naturally discrete data such as language and graphs. Although discrete-time discrete diffusion has been established for a while, only recently Campbell et al. (2022) introduced the first framework for continuous-time discrete diffusion. However, their training and sampling processes differ significantly from the discrete-time version, necessitating nontrivial approximations for tractability. In this paper, we first present a series of mathematical simplifications of the variational lower bound that enable more accurate and easy-to-optimize training for discrete diffusion. In addition, we derive a simple formulation for backward denoising that enables exact and accelerated sampling, and importantly, an elegant unification of discrete-time and continuous-time discrete diffusion. Thanks to simpler analytical formulations, both forward and now also backward probabilities can flexibly accommodate any noise distribution, including different noise distributions for multi-element objects. Experiments show that our proposed USD3 (for Unified Simplified Discrete Denoising Diffusion) outperform all SOTA baselines on established datasets. We open-source our unified code at https://github.com/LingxiaoShawn/USD3.</li>
</ul>

<h3>Title: WhisperFuzz: White-Box Fuzzing for Detecting and Locating Timing  Vulnerabilities in Processors</h3>
<ul>
<li><strong>Authors: </strong>Pallavi Borkar, Chen Chen, Mohamadreza Rostami, Nikhilesh Singh, Rahul Kande, Ahmad-Reza Sadeghi, Chester Rebeiro, Jeyavijayan Rajendran</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03704">https://arxiv.org/abs/2402.03704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03704">https://arxiv.org/pdf/2402.03704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03704]] WhisperFuzz: White-Box Fuzzing for Detecting and Locating Timing  Vulnerabilities in Processors(https://arxiv.org/abs/2402.03704)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Timing vulnerabilities in processors have emerged as a potent threat. As processors are the foundation of any computing system, identifying these flaws is imperative. Recently fuzzing techniques, traditionally used for detecting software vulnerabilities, have shown promising results for uncovering vulnerabilities in large-scale hardware designs, such as processors. Researchers have adapted black-box or grey-box fuzzing to detect timing vulnerabilities in processors. However, they cannot identify the locations or root causes of these timing vulnerabilities, nor do they provide coverage feedback to enable the designer's confidence in the processor's security. To address the deficiencies of the existing fuzzers, we present WhisperFuzz--the first white-box fuzzer with static analysis--aiming to detect and locate timing vulnerabilities in processors and evaluate the coverage of microarchitectural timing behaviors. WhisperFuzz uses the fundamental nature of processors' timing behaviors, microarchitectural state transitions, to localize timing vulnerabilities. WhisperFuzz automatically extracts microarchitectural state transitions from a processor design at the register-transfer level (RTL) and instruments the design to monitor the state transitions as coverage. Moreover, WhisperFuzz measures the time a design-under-test (DUT) takes to process tests, identifying any minor, abnormal variations that may hint at a timing vulnerability. WhisperFuzz detects 12 new timing vulnerabilities across advanced open-sourced RISC-V processors: BOOM, Rocket Core, and CVA6. Eight of these violate the zero latency requirements of the Zkt extension and are considered serious security vulnerabilities. Moreover, WhisperFuzz also pinpoints the locations of the new and the existing vulnerabilities.</li>
</ul>

<h3>Title: FoolSDEdit: Deceptively Steering Your Edits Towards Targeted  Attribute-aware Distribution</h3>
<ul>
<li><strong>Authors: </strong>Qi Zhou, Dongxia Wang, Tianlin Li, Zhihong Xu, Yang Liu, Kui Ren, Wenhai Wang, Qing Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03705">https://arxiv.org/abs/2402.03705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03705">https://arxiv.org/pdf/2402.03705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03705]] FoolSDEdit: Deceptively Steering Your Edits Towards Targeted  Attribute-aware Distribution(https://arxiv.org/abs/2402.03705)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Guided image synthesis methods, like SDEdit based on the diffusion model, excel at creating realistic images from user inputs such as stroke paintings. However, existing efforts mainly focus on image quality, often overlooking a key point: the diffusion model represents a data distribution, not individual images. This introduces a low but critical chance of generating images that contradict user intentions, raising ethical concerns. For example, a user inputting a stroke painting with female characteristics might, with some probability, get male faces from SDEdit. To expose this potential vulnerability, we aim to build an adversarial attack forcing SDEdit to generate a specific data distribution aligned with a specified attribute (e.g., female), without changing the input's attribute characteristics. We propose the Targeted Attribute Generative Attack (TAGA), using an attribute-aware objective function and optimizing the adversarial noise added to the input stroke painting. Empirical studies reveal that traditional adversarial noise struggles with TAGA, while natural perturbations like exposure and motion blur easily alter generated images' attributes. To execute effective attacks, we introduce FoolSDEdit: We design a joint adversarial exposure and blur attack, adding exposure and motion blur to the stroke painting and optimizing them together. We optimize the execution strategy of various perturbations, framing it as a network architecture search problem. We create the SuperPert, a graph representing diverse execution strategies for different perturbations. After training, we obtain the optimized execution strategy for effective TAGA against SDEdit. Comprehensive experiments on two datasets show our method compelling SDEdit to generate a targeted attribute-aware data distribution, significantly outperforming baselines.</li>
</ul>

<h3>Title: SISP: A Benchmark Dataset for Fine-grained Ship Instance Segmentation in  Panchromatic Satellite Images</h3>
<ul>
<li><strong>Authors: </strong>Pengming Feng, Mingjie Xie, Hongning Liu, Xuanjia Zhao, Guangjun He, Xueliang Zhang, Jian Guan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03708">https://arxiv.org/abs/2402.03708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03708">https://arxiv.org/pdf/2402.03708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03708]] SISP: A Benchmark Dataset for Fine-grained Ship Instance Segmentation in  Panchromatic Satellite Images(https://arxiv.org/abs/2402.03708)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Fine-grained ship instance segmentation in satellite images holds considerable significance for monitoring maritime activities at sea. However, existing datasets often suffer from the scarcity of fine-grained information or pixel-wise localization annotations, as well as the insufficient image diversity and variations, thus limiting the research of this task. To this end, we propose a benchmark dataset for fine-grained Ship Instance Segmentation in Panchromatic satellite images, namely SISP, which contains 56,693 well-annotated ship instances with four fine-grained categories across 10,000 sliced images, and all the images are collected from SuperView-1 satellite with the resolution of 0.5m. Targets in the proposed SISP dataset have characteristics that are consistent with real satellite scenes, such as high class imbalance, various scenes, large variations in target densities and scales, and high inter-class similarity and intra-class diversity, all of which make the SISP dataset more suitable for real-world applications. In addition, we introduce a Dynamic Feature Refinement-assist Instance segmentation network, namely DFRInst, as the benchmark method for ship instance segmentation in satellite images, which can fortify the explicit representation of crucial features, thus improving the performance of ship instance segmentation. Experiments and analysis are performed on the proposed SISP dataset to evaluate the benchmark method and several state-of-the-art methods to establish baselines for facilitating future research. The proposed dataset and source codes will be available at: https://github.com/Justlovesmile/SISP.</li>
</ul>

<h3>Title: Clarify: Improving Model Robustness With Natural Language Corrections</h3>
<ul>
<li><strong>Authors: </strong>Yoonho Lee, Michelle S. Lam, Helena Vasconcelos, Michael S. Bernstein, Chelsea Finn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03715">https://arxiv.org/abs/2402.03715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03715">https://arxiv.org/pdf/2402.03715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03715]] Clarify: Improving Model Robustness With Natural Language Corrections(https://arxiv.org/abs/2402.03715)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In supervised learning, models are trained to extract correlations from a static dataset. This often leads to models that rely on high-level misconceptions. To prevent such misconceptions, we must necessarily provide additional information beyond the training data. Existing methods incorporate forms of additional instance-level supervision, such as labels for spurious features or additional labeled data from a balanced distribution. Such strategies can become prohibitively costly for large-scale datasets since they require additional annotation at a scale close to the original training data. We hypothesize that targeted natural language feedback about a model's misconceptions is a more efficient form of additional supervision. We introduce Clarify, a novel interface and method for interactively correcting model misconceptions. Through Clarify, users need only provide a short text description to describe a model's consistent failure patterns. Then, in an entirely automated way, we use such descriptions to improve the training process by reweighting the training data or gathering additional targeted data. Our user studies show that non-expert users can successfully describe model misconceptions via Clarify, improving worst-group accuracy by an average of 17.1% in two datasets. Additionally, we use Clarify to find and rectify 31 novel hard subpopulations in the ImageNet dataset, improving minority-split accuracy from 21.1% to 28.7%.</li>
</ul>

<h3>Title: Attention-based Shape and Gait Representations Learning for Video-based  Cloth-Changing Person Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Vuong D. Nguyen, Samiha Mirza, Pranav Mantini, Shishir K. Shah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03716">https://arxiv.org/abs/2402.03716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03716">https://arxiv.org/pdf/2402.03716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03716]] Attention-based Shape and Gait Representations Learning for Video-based  Cloth-Changing Person Re-Identification(https://arxiv.org/abs/2402.03716)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current state-of-the-art Video-based Person Re-Identification (Re-ID) primarily relies on appearance features extracted by deep learning models. These methods are not applicable for long-term analysis in real-world scenarios where persons have changed clothes, making appearance information unreliable. In this work, we deal with the practical problem of Video-based Cloth-Changing Person Re-ID (VCCRe-ID) by proposing "Attention-based Shape and Gait Representations Learning" (ASGL) for VCCRe-ID. Our ASGL framework improves Re-ID performance under clothing variations by learning clothing-invariant gait cues using a Spatial-Temporal Graph Attention Network (ST-GAT). Given the 3D-skeleton-based spatial-temporal graph, our proposed ST-GAT comprises multi-head attention modules, which are able to enhance the robustness of gait embeddings under viewpoint changes and occlusions. The ST-GAT amplifies the important motion ranges and reduces the influence of noisy poses. Then, the multi-head learning module effectively reserves beneficial local temporal dynamics of movement. We also boost discriminative power of person representations by learning body shape cues using a GAT. Experiments on two large-scale VCCRe-ID datasets demonstrate that our proposed framework outperforms state-of-the-art methods by 12.2% in rank-1 accuracy and 7.0% in mAP.</li>
</ul>

<h3>Title: Empowering Language Models with Active Inquiry for Deeper Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jing-Cheng Pang, Heng-Bo Fan, Pengyuan Wang, Jia-Hao Xiao, Nan Tang, Si-Hang Yang, Chengxing Jia, Sheng-Jun Huang, Yang Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03719">https://arxiv.org/abs/2402.03719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03719">https://arxiv.org/pdf/2402.03719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03719]] Empowering Language Models with Active Inquiry for Deeper Understanding(https://arxiv.org/abs/2402.03719)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rise of large language models (LLMs) has revolutionized the way that we interact with artificial intelligence systems through natural language. However, LLMs often misinterpret user queries because of their uncertain intention, leading to less helpful responses. In natural human interactions, clarification is sought through targeted questioning to uncover obscure information. Thus, in this paper, we introduce LaMAI (Language Model with Active Inquiry), designed to endow LLMs with this same level of interactive engagement. LaMAI leverages active learning techniques to raise the most informative questions, fostering a dynamic bidirectional dialogue. This approach not only narrows the contextual gap but also refines the output of the LLMs, aligning it more closely with user expectations. Our empirical studies, across a variety of complex datasets where LLMs have limited conversational context, demonstrate the effectiveness of LaMAI. The method improves answer accuracy from 31.9% to 50.9%, outperforming other leading question-answering frameworks. Moreover, in scenarios involving human participants, LaMAI consistently generates responses that are superior or comparable to baseline methods in more than 82% of the cases. The applicability of LaMAI is further evidenced by its successful integration with various LLMs, highlighting its potential for the future of interactive language models.</li>
</ul>

<h3>Title: Similarity-based Neighbor Selection for Graph LLMs</h3>
<ul>
<li><strong>Authors: </strong>Rui Li, Jiwei Li, Jiawei Han, Guoyin Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03720">https://arxiv.org/abs/2402.03720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03720">https://arxiv.org/pdf/2402.03720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03720]] Similarity-based Neighbor Selection for Graph LLMs(https://arxiv.org/abs/2402.03720)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Text-attributed graphs (TAGs) present unique challenges for direct processing by Language Learning Models (LLMs), yet their extensive commonsense knowledge and robust reasoning capabilities offer great promise for node classification in TAGs. Prior research in this field has grappled with issues such as over-squashing, heterophily, and ineffective graph information integration, further compounded by inconsistencies in dataset partitioning and underutilization of advanced LLMs. To address these challenges, we introduce Similarity-based Neighbor Selection (SNS). Using SimCSE and advanced neighbor selection techniques, SNS effectively improves the quality of selected neighbors, thereby improving graph representation and alleviating issues like over-squashing and heterophily. Besides, as an inductive and training-free approach, SNS demonstrates superior generalization and scalability over traditional GNN methods. Our comprehensive experiments, adhering to standard dataset partitioning practices, demonstrate that SNS, through simple prompt interactions with LLMs, consistently outperforms vanilla GNNs and achieves state-of-the-art results on datasets like PubMed in node classification, showcasing LLMs' potential in graph structure understanding. Our research further underscores the significance of graph structure integration in LLM applications and identifies key factors for their success in node classification. Code is available at https://github.com/ruili33/SNS.</li>
</ul>

<h3>Title: Learning Granger Causality from Instance-wise Self-attentive Hawkes  Processes</h3>
<ul>
<li><strong>Authors: </strong>Dongxia Wu, Tsuyoshi Idé, Aurélie Lozano, Georgios Kollias, Jiří Navrátil, Naoki Abe, Yi-An Ma, Rose Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03726">https://arxiv.org/abs/2402.03726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03726">https://arxiv.org/pdf/2402.03726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03726]] Learning Granger Causality from Instance-wise Self-attentive Hawkes  Processes(https://arxiv.org/abs/2402.03726)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction.</li>
</ul>

<h3>Title: Differentially Private High Dimensional Bandits</h3>
<ul>
<li><strong>Authors: </strong>Apurv Shukla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, eess.SY, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03737">https://arxiv.org/abs/2402.03737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03737">https://arxiv.org/pdf/2402.03737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03737]] Differentially Private High Dimensional Bandits(https://arxiv.org/abs/2402.03737)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We consider a high-dimensional stochastic contextual linear bandit problem when the parameter vector is $s_{0}$-sparse and the decision maker is subject to privacy constraints under both central and local models of differential privacy. We present PrivateLASSO, a differentially private LASSO bandit algorithm. PrivateLASSO is based on two sub-routines: (i) a sparse hard-thresholding-based privacy mechanism and (ii) an episodic thresholding rule for identifying the support of the parameter $\theta$. We prove minimax private lower bounds and establish privacy and utility guarantees for PrivateLASSO for the central model under standard assumptions.</li>
</ul>

<h3>Title: AoSRNet: All-in-One Scene Recovery Networks via Multi-knowledge  Integration</h3>
<ul>
<li><strong>Authors: </strong>Yuxu Lu, Dong Yang, Yuan Gao, Ryan Wen Liu, Jun Liu, Yu Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03738">https://arxiv.org/abs/2402.03738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03738">https://arxiv.org/pdf/2402.03738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03738]] AoSRNet: All-in-One Scene Recovery Networks via Multi-knowledge  Integration(https://arxiv.org/abs/2402.03738)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Scattering and attenuation of light in no-homogeneous imaging media or inconsistent light intensity will cause insufficient contrast and color distortion in the collected images, which limits the developments such as vision-driven smart urban, autonomous vehicles, and intelligent robots. In this paper, we propose an all-in-one scene recovery network via multi-knowledge integration (termed AoSRNet) to improve the visibility of imaging devices in typical low-visibility imaging scenes (e.g., haze, sand dust, and low light). It combines gamma correction (GC) and optimized linear stretching (OLS) to create the detail enhancement module (DEM) and color restoration module (CRM). Additionally, we suggest a multi-receptive field extraction module (MEM) to attenuate the loss of image texture details caused by GC nonlinear and OLS linear transformations. Finally, we refine the coarse features generated by DEM, CRM, and MEM through Encoder-Decoder to generate the final restored image. Comprehensive experimental results demonstrate the effectiveness and stability of AoSRNet compared to other state-of-the-art methods. The source code is available at \url{https://github.com/LouisYuxuLu/AoSRNet}.</li>
</ul>

<h3>Title: SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent  Reinforcement Learning Systems</h3>
<ul>
<li><strong>Authors: </strong>Oubo Ma, Yuwen Pu, Linkang Du, Yang Dai, Ruo Wang, Xiaolei Liu, Yingcai Wu, Shouling Ji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03741">https://arxiv.org/abs/2402.03741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03741">https://arxiv.org/pdf/2402.03741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03741]] SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent  Reinforcement Learning Systems(https://arxiv.org/abs/2402.03741)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Recent advances in multi-agent reinforcement learning (MARL) have opened up vast application prospects, including swarm control of drones, collaborative manipulation by robotic arms, and multi-target encirclement. However, potential security threats during the MARL deployment need more attention and thorough investigation. Recent researches reveal that an attacker can rapidly exploit the victim's vulnerabilities and generate adversarial policies, leading to the victim's failure in specific tasks. For example, reducing the winning rate of a superhuman-level Go AI to around 20%. They predominantly focus on two-player competitive environments, assuming attackers possess complete global state observation. In this study, we unveil, for the first time, the capability of attackers to generate adversarial policies even when restricted to partial observations of the victims in multi-agent competitive environments. Specifically, we propose a novel black-box attack (SUB-PLAY), which incorporates the concept of constructing multiple subgames to mitigate the impact of partial observability and suggests the sharing of transitions among subpolicies to improve the exploitative ability of attackers. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under three typical partial observability limitations. Visualization results indicate that adversarial policies induce significantly different activations of the victims' policy networks. Furthermore, we evaluate three potential defenses aimed at exploring ways to mitigate security threats posed by adversarial policies, providing constructive recommendations for deploying MARL in competitive environments.</li>
</ul>

<h3>Title: INSIDE: LLMs' Internal States Retain the Power of Hallucination  Detection</h3>
<ul>
<li><strong>Authors: </strong>Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, Mingyuan Tao, Zhihang Fu, Jieping Ye</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03744">https://arxiv.org/abs/2402.03744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03744">https://arxiv.org/pdf/2402.03744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03744]] INSIDE: LLMs' Internal States Retain the Power of Hallucination  Detection(https://arxiv.org/abs/2402.03744)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Knowledge hallucination have raised widespread concerns for the security and reliability of deployed LLMs. Previous efforts in detecting hallucinations have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, where the semantic information is inevitably lost during the token-decoding procedure. Thus, we propose to explore the dense semantic information retained within LLMs' \textbf{IN}ternal \textbf{S}tates for halluc\textbf{I}nation \textbf{DE}tection (\textbf{INSIDE}). In particular, a simple yet effective \textbf{EigenScore} metric is proposed to better evaluate responses' self-consistency, which exploits the eigenvalues of responses' covariance matrix to measure the semantic consistency/diversity in the dense embedding space. Furthermore, from the perspective of self-consistent hallucination detection, a test time feature clipping approach is explored to truncate extreme activations in the internal states, which reduces overconfident generations and potentially benefits the detection of overconfident hallucinations. Extensive experiments and ablation studies are performed on several popular LLMs and question-answering (QA) benchmarks, showing the effectiveness of our proposal.</li>
</ul>

<h3>Title: Tuning Large Multimodal Models for Videos using Reinforcement Learning  from AI Feedback</h3>
<ul>
<li><strong>Authors: </strong>Daechul Ahn, Yura Choi, Youngjae Yu, Dongyeop Kang, Jonghyun Choi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03746">https://arxiv.org/abs/2402.03746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03746">https://arxiv.org/pdf/2402.03746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03746]] Tuning Large Multimodal Models for Videos using Reinforcement Learning  from AI Feedback(https://arxiv.org/abs/2402.03746)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models have influenced the development of video large multimodal models (VLMMs). The previous approaches for VLMMs involved Supervised Fine-Tuning (SFT) with instruction-tuned datasets, integrating LLM with visual encoders, and adding additional learnable modules. Video and text multimodal alignment remains challenging, primarily due to the deficient volume and quality of multimodal instruction-tune data compared to text-only data. We present a novel alignment strategy that employs multimodal AI system to oversee itself called Reinforcement Learning from AI Feedback (RLAIF), providing self-preference feedback to refine itself and facilitating the alignment of video and text modalities. In specific, we propose context-aware reward modeling by providing detailed video descriptions as context during the generation of preference feedback in order to enrich the understanding of video content. Demonstrating enhanced performance across diverse video benchmarks, our multimodal RLAIF approach, VLM-RLAIF, outperforms existing approaches, including the SFT model. We commit to open-sourcing our code, models, and datasets to foster further research in this area.</li>
</ul>

<h3>Title: Vision Superalignment: Weak-to-Strong Generalization for Vision  Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Jianyuan Guo, Hanting Chen, Chengcheng Wang, Kai Han, Chang Xu, Yunhe Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03749">https://arxiv.org/abs/2402.03749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03749">https://arxiv.org/pdf/2402.03749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03749]] Vision Superalignment: Weak-to-Strong Generalization for Vision  Foundation Models(https://arxiv.org/abs/2402.03749)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models have sparked interest in their extraordinary and near-superhuman capabilities, leading researchers to explore methods for evaluating and optimizing these abilities, which is called superalignment. In this context, our paper delves into the realm of vision foundation models, focusing on the concept of weak-to-strong generalization, which involves using a weaker model to supervise a stronger one, aiming to enhance the latter's capabilities beyond the former's limits. We introduce a novel and adaptively adjustable loss function for weak-to-strong supervision. Our comprehensive experiments span various scenarios, including few-shot learning, transfer learning, noisy label learning, and common knowledge distillation settings. The results are striking: our approach not only exceeds the performance benchmarks set by strong-to-strong generalization but also surpasses the outcomes of fine-tuning strong models with whole datasets. This compelling evidence underscores the significant potential of weak-to-strong generalization, showcasing its capability to substantially elevate the performance of vision foundation models. The code is available at https://github.com/ggjy/vision_weak_to_strong.</li>
</ul>

<h3>Title: Pre-training of Lightweight Vision Transformers on Small Datasets with  Minimally Scaled Images</h3>
<ul>
<li><strong>Authors: </strong>Jen Hong Tan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03752">https://arxiv.org/abs/2402.03752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03752">https://arxiv.org/pdf/2402.03752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03752]] Pre-training of Lightweight Vision Transformers on Small Datasets with  Minimally Scaled Images(https://arxiv.org/abs/2402.03752)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Can a lightweight Vision Transformer (ViT) match or exceed the performance of Convolutional Neural Networks (CNNs) like ResNet on small datasets with small image resolutions? This report demonstrates that a pure ViT can indeed achieve superior performance through pre-training, using a masked auto-encoder technique with minimal image scaling. Our experiments on the CIFAR-10 and CIFAR-100 datasets involved ViT models with fewer than 3.65 million parameters and a multiply-accumulate (MAC) count below 0.27G, qualifying them as 'lightweight' models. Unlike previous approaches, our method attains state-of-the-art performance among similar lightweight transformer-based architectures without significantly scaling up images from CIFAR-10 and CIFAR-100. This achievement underscores the efficiency of our model, not only in handling small datasets but also in effectively processing images close to their original scale.</li>
</ul>

<h3>Title: Enhanced sampling of robust molecular datasets with uncertainty-based  collective variables</h3>
<ul>
<li><strong>Authors: </strong>Aik Rui Tan, Johannes C. B. Dietschreit, Rafael Gomez-Bombarelli</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03753">https://arxiv.org/abs/2402.03753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03753">https://arxiv.org/pdf/2402.03753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03753]] Enhanced sampling of robust molecular datasets with uncertainty-based  collective variables(https://arxiv.org/abs/2402.03753)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Generating a data set that is representative of the accessible configuration space of a molecular system is crucial for the robustness of machine learned interatomic potentials (MLIP). However, the complexity of molecular systems, characterized by intricate potential energy surfaces (PESs) with numerous local minima and energy barriers, presents a significant challenge. Traditional methods of data generation, such as random sampling or exhaustive exploration, are either intractable or may not capture rare, but highly informative configurations. In this study, we propose a method that leverages uncertainty as the collective variable (CV) to guide the acquisition of chemically-relevant data points, focusing on regions of the configuration space where ML model predictions are most uncertain. This approach employs a Gaussian Mixture Model-based uncertainty metric from a single model as the CV for biased molecular dynamics simulations. The effectiveness of our approach in overcoming energy barriers and exploring unseen energy minima, thereby enhancing the data set in an active learning framework, is demonstrated on the alanine dipeptide benchmark system.</li>
</ul>

<h3>Title: Intensive Vision-guided Network for Radiology Report Generation</h3>
<ul>
<li><strong>Authors: </strong>Fudan Zheng, Mengfei Li, Ying Wang, Weijiang Yu, Ruixuan Wang, Zhiguang Chen, Nong Xiao, Yutong Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03754">https://arxiv.org/abs/2402.03754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03754">https://arxiv.org/pdf/2402.03754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03754]] Intensive Vision-guided Network for Radiology Report Generation(https://arxiv.org/abs/2402.03754)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Automatic radiology report generation is booming due to its huge application potential for the healthcare industry. However, existing computer vision and natural language processing approaches to tackle this problem are limited in two aspects. First, when extracting image features, most of them neglect multi-view reasoning in vision and model single-view structure of medical images, such as space-view or channel-view. However, clinicians rely on multi-view imaging information for comprehensive judgment in daily clinical diagnosis. Second, when generating reports, they overlook context reasoning with multi-modal information and focus on pure textual optimization utilizing retrieval-based methods. We aim to address these two issues by proposing a model that better simulates clinicians' perspectives and generates more accurate reports. Given the above limitation in feature extraction, we propose a Globally-intensive Attention (GIA) module in the medical image encoder to simulate and integrate multi-view vision perception. GIA aims to learn three types of vision perception: depth view, space view, and pixel view. On the other hand, to address the above problem in report generation, we explore how to involve multi-modal signals to generate precisely matched reports, i.e., how to integrate previously predicted words with region-aware visual content in next word prediction. Specifically, we design a Visual Knowledge-guided Decoder (VKGD), which can adaptively consider how much the model needs to rely on visual information and previously predicted text to assist next word prediction. Hence, our final Intensive Vision-guided Network (IVGN) framework includes a GIA-guided Visual Encoder and the VKGD. Experiments on two commonly-used datasets IU X-Ray and MIMIC-CXR demonstrate the superior ability of our method compared with other state-of-the-art approaches.</li>
</ul>

<h3>Title: The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs</h3>
<ul>
<li><strong>Authors: </strong>Tianyang Han, Qing Lian, Rui Pan, Renjie Pi, Jipeng Zhang, Shizhe Diao, Yong Lin, Tong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03757">https://arxiv.org/abs/2402.03757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03757">https://arxiv.org/pdf/2402.03757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03757]] The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs(https://arxiv.org/abs/2402.03757)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have recently experienced remarkable progress, where the advent of multi-modal large language models (MLLMs) has endowed LLMs with visual capabilities, leading to impressive performances in various multi-modal tasks. However, those powerful MLLMs such as GPT-4V still fail spectacularly when presented with certain image and text inputs. In this paper, we identify a typical class of inputs that baffles MLLMs, which consist of images that are highly relevant but inconsistent with answers, causing MLLMs to suffer from hallucination. To quantify the effect, we propose CorrelationQA, the first benchmark that assesses the hallucination level given spurious images. This benchmark contains 7,308 text-image pairs across 13 categories. Based on the proposed CorrelationQA, we conduct a thorough analysis on 9 mainstream MLLMs, illustrating that they universally suffer from this instinctive bias to varying degrees. We hope that our curated benchmark and evaluation results aid in better assessments of the MLLMs' robustness in the presence of misleading images. The resource is available in https://github.com/MasaiahHan/CorrelationQA.</li>
</ul>

<h3>Title: MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Heng Zhou, Zhetao Guo, Shuhong Liu, Lechen Zhang, Qihao Wang, Yuxiang Ren, Mingrui Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03762">https://arxiv.org/abs/2402.03762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03762">https://arxiv.org/pdf/2402.03762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03762]] MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction(https://arxiv.org/abs/2402.03762)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural implicit representations have recently been demonstrated in many fields including Simultaneous Localization And Mapping (SLAM). Current neural SLAM can achieve ideal results in reconstructing bounded scenes, but this relies on the input of RGB-D images. Neural-based SLAM based only on RGB images is unable to reconstruct the scale of the scene accurately, and it also suffers from scale drift due to errors accumulated during tracking. To overcome these limitations, we present MoD-SLAM, a monocular dense mapping method that allows global pose optimization and 3D reconstruction in real-time in unbounded scenes. Optimizing scene reconstruction by monocular depth estimation and using loop closure detection to update camera pose enable detailed and precise reconstruction on large scenes. Compared to previous work, our approach is more robust, scalable and versatile. Our experiments demonstrate that MoD-SLAM has more excellent mapping performance than prior neural SLAM methods, especially in large borderless scenes.</li>
</ul>

<h3>Title: AttackNet: Enhancing Biometric Security via Tailored Convolutional  Neural Network Architectures for Liveness Detection</h3>
<ul>
<li><strong>Authors: </strong>Oleksandr Kuznetsov, Dmytro Zakharov, Emanuele Frontoni, Andrea Maranesi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03769">https://arxiv.org/abs/2402.03769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03769">https://arxiv.org/pdf/2402.03769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03769]] AttackNet: Enhancing Biometric Security via Tailored Convolutional  Neural Network Architectures for Liveness Detection(https://arxiv.org/abs/2402.03769)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, biometric, extraction</a></li>
<li><strong>Abstract: </strong>Biometric security is the cornerstone of modern identity verification and authentication systems, where the integrity and reliability of biometric samples is of paramount importance. This paper introduces AttackNet, a bespoke Convolutional Neural Network architecture, meticulously designed to combat spoofing threats in biometric systems. Rooted in deep learning methodologies, this model offers a layered defense mechanism, seamlessly transitioning from low-level feature extraction to high-level pattern discernment. Three distinctive architectural phases form the crux of the model, each underpinned by judiciously chosen activation functions, normalization techniques, and dropout layers to ensure robustness and resilience against adversarial attacks. Benchmarking our model across diverse datasets affirms its prowess, showcasing superior performance metrics in comparison to contemporary models. Furthermore, a detailed comparative analysis accentuates the model's efficacy, drawing parallels with prevailing state-of-the-art methodologies. Through iterative refinement and an informed architectural strategy, AttackNet underscores the potential of deep learning in safeguarding the future of biometric security.</li>
</ul>

<h3>Title: Fed-CVLC: Compressing Federated Learning Communications with  Variable-Length Codes</h3>
<ul>
<li><strong>Authors: </strong>Xiaoxin Su, Yipeng Zhou, Laizhong Cui, John C.S. Lui, Jiangchuan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03770">https://arxiv.org/abs/2402.03770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03770">https://arxiv.org/pdf/2402.03770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03770]] Fed-CVLC: Compressing Federated Learning Communications with  Variable-Length Codes(https://arxiv.org/abs/2402.03770)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>In Federated Learning (FL) paradigm, a parameter server (PS) concurrently communicates with distributed participating clients for model collection, update aggregation, and model distribution over multiple rounds, without touching private data owned by individual clients. FL is appealing in preserving data privacy; yet the communication between the PS and scattered clients can be a severe bottleneck. Model compression algorithms, such as quantization and sparsification, have been suggested but they generally assume a fixed code length, which does not reflect the heterogeneity and variability of model updates. In this paper, through both analysis and experiments, we show strong evidences that variable-length is beneficial for compression in FL. We accordingly present Fed-CVLC (Federated Learning Compression with Variable-Length Codes), which fine-tunes the code length in response of the dynamics of model updates. We develop optimal tuning strategy that minimizes the loss function (equivalent to maximizing the model utility) subject to the budget for communication. We further demonstrate that Fed-CVLC is indeed a general compression design that bridges quantization and sparsification, with greater flexibility. Extensive experiments have been conducted with public datasets to demonstrate that Fed-CVLC remarkably outperforms state-of-the-art baselines, improving model utility by 1.50%-5.44%, or shrinking communication traffic by 16.67%-41.61%.</li>
</ul>

<h3>Title: Reinforcement Learning from Bagged Reward: A Transformer-based Approach  for Instance-Level Reward Redistribution</h3>
<ul>
<li><strong>Authors: </strong>Yuting Tang, Xin-Qiang Cai, Yao-Xiang Ding, Qiyu Wu, Guoqing Liu, Masashi Sugiyama</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03771">https://arxiv.org/abs/2402.03771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03771">https://arxiv.org/pdf/2402.03771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03771]] Reinforcement Learning from Bagged Reward: A Transformer-based Approach  for Instance-Level Reward Redistribution(https://arxiv.org/abs/2402.03771)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In reinforcement Learning (RL), an instant reward signal is generated for each action of the agent, such that the agent learns to maximize the cumulative reward to obtain the optimal policy. However, in many real-world applications, the instant reward signals are not obtainable by the agent. Instead, the learner only obtains rewards at the ends of bags, where a bag is defined as a partial sequence of a complete trajectory. In this situation, the learner has to face the significant difficulty of exploring the unknown instant rewards in the bags, which could not be addressed by existing approaches, including those trajectory-based approaches that consider only complete trajectories and ignore the inner reward distributions. To formally study this situation, we introduce a novel RL setting termed Reinforcement Learning from Bagged Rewards (RLBR), where only the bagged rewards of sequences can be obtained. We provide the theoretical study to establish the connection between RLBR and standard RL in Markov Decision Processes (MDPs). To effectively explore the reward distributions within the bagged rewards, we propose a Transformer-based reward model, the Reward Bag Transformer (RBT), which uses the self-attention mechanism for interpreting the contextual nuances and temporal dependencies within each bag. Extensive experimental analyses demonstrate the superiority of our method, particularly in its ability to mimic the original MDP's reward distribution, highlighting its proficiency in contextual understanding and adaptability to environmental dynamics.</li>
</ul>

<h3>Title: Learning a Decision Tree Algorithm with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Yufan Zhuang, Liyuan Liu, Chandan Singh, Jingbo Shang, Jianfeng Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03774">https://arxiv.org/abs/2402.03774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03774">https://arxiv.org/pdf/2402.03774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03774]] Learning a Decision Tree Algorithm with Transformers(https://arxiv.org/abs/2402.03774)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Decision trees are renowned for their interpretability capability to achieve high predictive performance, especially on tabular data. Traditionally, they are constructed through recursive algorithms, where they partition the data at every node in a tree. However, identifying the best partition is challenging, as decision trees optimized for local segments may not bring global generalization. To address this, we introduce MetaTree, which trains a transformer-based model on filtered outputs from classical algorithms to produce strong decision trees for classification. Specifically, we fit both greedy decision trees and optimized decision trees on a large number of datasets. We then train MetaTree to produce the trees that achieve strong generalization performance. This training enables MetaTree to not only emulate these algorithms, but also to intelligently adapt its strategy according to the context, thereby achieving superior generalization performance.</li>
</ul>

<h3>Title: Large Language Models As MOOCs Graders</h3>
<ul>
<li><strong>Authors: </strong>Shahriar Golchin, Nikhil Garuda, Christopher Impey, Matthew Wenger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03776">https://arxiv.org/abs/2402.03776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03776">https://arxiv.org/pdf/2402.03776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03776]] Large Language Models As MOOCs Graders(https://arxiv.org/abs/2402.03776)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Massive open online courses (MOOCs) unlock the doors to free education for anyone around the globe with access to a computer and the internet. Despite this democratization of learning, the massive enrollment in these courses means it is almost impossible for one instructor to assess every student's writing assignment. As a result, peer grading, often guided by a straightforward rubric, is the method of choice. While convenient, peer grading often falls short in terms of reliability and validity. In this study, using 18 distinct settings, we explore the feasibility of leveraging large language models (LLMs) to replace peer grading in MOOCs. Specifically, we focus on two state-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses: Introductory Astronomy, Astrobiology, and the History and Philosophy of Astronomy. To instruct LLMs, we use three different prompts based on a variant of the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique: Zero-shot-CoT combined with instructor-provided correct answers; Zero-shot-CoT in conjunction with both instructor-formulated answers and rubrics; and Zero-shot-CoT with instructor-offered correct answers and LLM-generated rubrics. Our results show that Zero-shot-CoT, when integrated with instructor-provided answers and rubrics, produces grades that are more aligned with those assigned by instructors compared to peer grading. However, the History and Philosophy of Astronomy course proves to be more challenging in terms of grading as opposed to other courses. Finally, our study reveals a promising direction for automating grading systems for MOOCs, especially in subjects with well-defined rubrics.</li>
</ul>

<h3>Title: Exposing propaganda: an analysis of stylistic cues comparing human  annotations and machine classification</h3>
<ul>
<li><strong>Authors: </strong>Géraud Faye, Benjamin Icard, Morgane Casanova, Julien Chanson, François Maine, François Bancilhon, Guillaume Gadek, Guillaume Gravier, Paul Égré</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03780">https://arxiv.org/abs/2402.03780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03780">https://arxiv.org/pdf/2402.03780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03780]] Exposing propaganda: an analysis of stylistic cues comparing human  annotations and machine classification(https://arxiv.org/abs/2402.03780)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>This paper investigates the language of propaganda and its stylistic features. It presents the PPN dataset, standing for Propagandist Pseudo-News, a multisource, multilingual, multimodal dataset composed of news articles extracted from websites identified as propaganda sources by expert agencies. A limited sample from this set was randomly mixed with papers from the regular French press, and their URL masked, to conduct an annotation-experiment by humans, using 11 distinct labels. The results show that human annotators were able to reliably discriminate between the two types of press across each of the labels. We propose different NLP techniques to identify the cues used by the annotators, and to compare them with machine classification. They include the analyzer VAGO to measure discourse vagueness and subjectivity, a TF-IDF to serve as a baseline, and four different classifiers: two RoBERTa-based models, CATS using syntax, and one XGBoost combining syntactic and semantic features. Keywords: Propaganda, Fake News, Explainability, AI alignment, Vagueness, Subjectivity, Exaggeration, Stylistic analysis</li>
</ul>

<h3>Title: AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality  Prediction</h3>
<ul>
<li><strong>Authors: </strong>Kethmi Hirushini Hettige, Jiahao Ji, Shili Xiang, Cheng Long, Gao Cong, Jingyuan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.app-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03784">https://arxiv.org/abs/2402.03784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03784">https://arxiv.org/pdf/2402.03784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03784]] AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality  Prediction(https://arxiv.org/abs/2402.03784)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion</a></li>
<li><strong>Abstract: </strong>Air quality prediction and modelling plays a pivotal role in public health and environment management, for individuals and authorities to make informed decisions. Although traditional data-driven models have shown promise in this domain, their long-term prediction accuracy can be limited, especially in scenarios with sparse or incomplete data and they often rely on black-box deep learning structures that lack solid physical foundation leading to reduced transparency and interpretability in predictions. To address these limitations, this paper presents a novel approach named Physics guided Neural Network for Air Quality Prediction (AirPhyNet). Specifically, we leverage two well-established physics principles of air particle movement (diffusion and advection) by representing them as differential equation networks. Then, we utilize a graph structure to integrate physics knowledge into a neural network architecture and exploit latent representations to capture spatio-temporal relationships within the air quality data. Experiments on two real-world benchmark datasets demonstrate that AirPhyNet outperforms state-of-the-art models for different testing scenarios including different lead time (24h, 48h, 72h), sparse data and sudden change prediction, achieving reduction in prediction errors up to 10%. Moreover, a case study further validates that our model captures underlying physical processes of particle movement and generates accurate predictions with real physical meaning.</li>
</ul>

<h3>Title: Energy-based Domain-Adaptive Segmentation with Depth Guidance</h3>
<ul>
<li><strong>Authors: </strong>Jinjing Zhu, Zhedong Hu, Tae-Kyun Kim, Lin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03795">https://arxiv.org/abs/2402.03795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03795">https://arxiv.org/pdf/2402.03795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03795]] Energy-based Domain-Adaptive Segmentation with Depth Guidance(https://arxiv.org/abs/2402.03795)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent endeavors have been made to leverage self-supervised depth estimation as guidance in unsupervised domain adaptation (UDA) for semantic segmentation. Prior arts, however, overlook the discrepancy between semantic and depth features, as well as the reliability of feature fusion, thus leading to suboptimal segmentation performance. To address this issue, we propose a novel UDA framework called SMART (croSs doMain semAntic segmentation based on eneRgy esTimation) that utilizes Energy-Based Models (EBMs) to obtain task-adaptive features and achieve reliable feature fusion for semantic segmentation with self-supervised depth estimates. Our framework incorporates two novel components: energy-based feature fusion (EB2F) and energy-based reliable fusion Assessment (RFA) modules. The EB2F module produces task-adaptive semantic and depth features by explicitly measuring and reducing their discrepancy using Hopfield energy for better feature fusion. The RFA module evaluates the reliability of the feature fusion using an energy score to improve the effectiveness of depth guidance. Extensive experiments on two datasets demonstrate that our method achieves significant performance gains over prior works, validating the effectiveness of our energy-based learning approach.</li>
</ul>

<h3>Title: ReLU$^2$ Wins: Discovering Efficient Activation Functions for Sparse  LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zhengyan Zhang, Yixin Song, Guanghui Yu, Xu Han, Yankai Lin, Chaojun Xiao, Chenyang Song, Zhiyuan Liu, Zeyu Mi, Maosong Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03804">https://arxiv.org/abs/2402.03804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03804">https://arxiv.org/pdf/2402.03804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03804]] ReLU$^2$ Wins: Discovering Efficient Activation Functions for Sparse  LLMs(https://arxiv.org/abs/2402.03804)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sparse computation offers a compelling solution for the inference of Large Language Models (LLMs) in low-resource scenarios by dynamically skipping the computation of inactive neurons. While traditional approaches focus on ReLU-based LLMs, leveraging zeros in activation values, we broaden the scope of sparse LLMs beyond zero activation values. We introduce a general method that defines neuron activation through neuron output magnitudes and a tailored magnitude threshold, demonstrating that non-ReLU LLMs also exhibit sparse activation. To find the most efficient activation function for sparse computation, we propose a systematic framework to examine the sparsity of LLMs from three aspects: the trade-off between sparsity and performance, the predictivity of sparsity, and the hardware affinity. We conduct thorough experiments on LLMs utilizing different activation functions, including ReLU, SwiGLU, ReGLU, and ReLU$^2$. The results indicate that models employing ReLU$^2$ excel across all three evaluation aspects, highlighting its potential as an efficient activation function for sparse LLMs. We will release the code to facilitate future research.</li>
</ul>

<h3>Title: Expediting In-Network Federated Learning by Voting-Based Consensus Model  Compression</h3>
<ul>
<li><strong>Authors: </strong>Xiaoxin Su, Yipeng Zhou, Laizhong Cui, Song Guo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03815">https://arxiv.org/abs/2402.03815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03815">https://arxiv.org/pdf/2402.03815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03815]] Expediting In-Network Federated Learning by Voting-Based Consensus Model  Compression(https://arxiv.org/abs/2402.03815)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Recently, federated learning (FL) has gained momentum because of its capability in preserving data privacy. To conduct model training by FL, multiple clients exchange model updates with a parameter server via Internet. To accelerate the communication speed, it has been explored to deploy a programmable switch (PS) in lieu of the parameter server to coordinate clients. The challenge to deploy the PS in FL lies in its scarce memory space, prohibiting running memory consuming aggregation algorithms on the PS. To overcome this challenge, we propose Federated Learning in-network Aggregation with Compression (FediAC) algorithm, consisting of two phases: client voting and model aggregating. In the former phase, clients report their significant model update indices to the PS to estimate global significant model updates. In the latter phase, clients upload global significant model updates to the PS for aggregation. FediAC consumes much less memory space and communication traffic than existing works because the first phase can guarantee consensus compression across clients. The PS easily aligns model update indices to swiftly complete aggregation in the second phase. Finally, we conduct extensive experiments by using public datasets to demonstrate that FediAC remarkably surpasses the state-of-the-art baselines in terms of model accuracy and communication traffic.</li>
</ul>

<h3>Title: OASim: an Open and Adaptive Simulator based on Neural Rendering for  Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Guohang Yan, Jiahao Pi, Jianfei Guo, Zhaotong Luo, Min Dou, Nianchen Deng, Qiusheng Huang, Daocheng Fu, Licheng Wen, Pinlong Cai, Xing Gao, Xinyu Cai, Bo Zhang, Xuemeng Yang, Yeqi Bai, Hongbin Zhou, Botian Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03830">https://arxiv.org/abs/2402.03830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03830">https://arxiv.org/pdf/2402.03830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03830]] OASim: an Open and Adaptive Simulator based on Neural Rendering for  Autonomous Driving(https://arxiv.org/abs/2402.03830)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>With deep learning and computer vision technology development, autonomous driving provides new solutions to improve traffic safety and efficiency. The importance of building high-quality datasets is self-evident, especially with the rise of end-to-end autonomous driving algorithms in recent years. Data plays a core role in the algorithm closed-loop system. However, collecting real-world data is expensive, time-consuming, and unsafe. With the development of implicit rendering technology and in-depth research on using generative models to produce data at scale, we propose OASim, an open and adaptive simulator and autonomous driving data generator based on implicit neural rendering. It has the following characteristics: (1) High-quality scene reconstruction through neural implicit surface reconstruction technology. (2) Trajectory editing of the ego vehicle and participating vehicles. (3) Rich vehicle model library that can be freely selected and inserted into the scene. (4) Rich sensors model library where you can select specified sensors to generate data. (5) A highly customizable data generation system can generate data according to user needs. We demonstrate the high quality and fidelity of the generated data through perception performance evaluation on the Carla simulator and real-world data acquisition. Code is available at https://github.com/PJLab-ADG/OASim.</li>
</ul>

<h3>Title: Rethinking Skill Extraction in the Job Market Domain using Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Khanh Cao Nguyen, Mike Zhang, Syrielle Montariol, Antoine Bosselut</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03832">https://arxiv.org/abs/2402.03832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03832">https://arxiv.org/pdf/2402.03832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03832]] Rethinking Skill Extraction in the Job Market Domain using Large  Language Models(https://arxiv.org/abs/2402.03832)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Skill Extraction involves identifying skills and qualifications mentioned in documents such as job postings and resumes. The task is commonly tackled by training supervised models using a sequence labeling approach with BIO tags. However, the reliance on manually annotated data limits the generalizability of such approaches. Moreover, the common BIO setting limits the ability of the models to capture complex skill patterns and handle ambiguous mentions. In this paper, we explore the use of in-context learning to overcome these challenges, on a benchmark of 6 uniformized skill extraction datasets. Our approach leverages the few-shot learning capabilities of large language models (LLMs) to identify and extract skills from sentences. We show that LLMs, despite not being on par with traditional supervised models in terms of performance, can better handle syntactically complex skill mentions in skill extraction tasks.</li>
</ul>

<h3>Title: Enhanced Security and Efficiency in Blockchain with Aggregated  Zero-Knowledge Proof Mechanisms</h3>
<ul>
<li><strong>Authors: </strong>Oleksandr Kuznetsov, Alex Rusnak, Anton Yezhov, Dzianis Kanonik, Kateryna Kuznetsova, Stanislav Karashchuk</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03834">https://arxiv.org/abs/2402.03834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03834">https://arxiv.org/pdf/2402.03834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03834]] Enhanced Security and Efficiency in Blockchain with Aggregated  Zero-Knowledge Proof Mechanisms(https://arxiv.org/abs/2402.03834)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Blockchain technology has emerged as a revolutionary tool in ensuring data integrity and security in digital transactions. However, the current approaches to data verification in blockchain systems, particularly in Ethereum, face challenges in terms of efficiency and computational overhead. The traditional use of Merkle Trees and cryptographic hash functions, while effective, leads to significant resource consumption, especially for large datasets. This highlights a gap in existing research: the need for more efficient methods of data verification in blockchain networks. Our study addresses this gap by proposing an innovative aggregation scheme for Zero-Knowledge Proofs within the structure of Merkle Trees. We develop a system that significantly reduces the size of the proof and the computational resources needed for its generation and verification. Our approach represents a paradigm shift in blockchain data verification, balancing security with efficiency. We conducted extensive experimental evaluations using real Ethereum block data to validate the effectiveness of our proposed scheme. The results demonstrate a drastic reduction in proof size and computational requirements compared to traditional methods, making the verification process more efficient and economically viable. Our contribution fills a critical research void, offering a scalable and secure solution for blockchain data verification. The implications of our work are far-reaching, enhancing the overall performance and adaptability of blockchain technology in various applications, from financial transactions to supply chain management.</li>
</ul>

<h3>Title: A new method for optical steel rope non-destructive damage detection</h3>
<ul>
<li><strong>Authors: </strong>Yunqing Bao, Bin Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03843">https://arxiv.org/abs/2402.03843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03843">https://arxiv.org/pdf/2402.03843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03843]] A new method for optical steel rope non-destructive damage detection(https://arxiv.org/abs/2402.03843)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents a novel algorithm for non-destructive damage detection for steel ropes in high-altitude environments (aerial ropeway). The algorithm comprises two key components: First, a segmentation model named RGBD-UNet is designed to accurately extract steel ropes from complex backgrounds. This model is equipped with the capability to process and combine color and depth information through the proposed CMA module. Second, a detection model named VovNetV3.5 is developed to differentiate between normal and abnormal steel ropes. It integrates the VovNet architecture with a DBB module to enhance performance. Besides, a novel background augmentation method is proposed to enhance the generalization ability of the segmentation model. Datasets containing images of steel ropes in different scenarios are created for the training and testing of both the segmentation and detection models. Experiments demonstrate a significant improvement over baseline models. On the proposed dataset, the highest accuracy achieved by the detection model reached 0.975, and the maximum F-measure achieved by the segmentation model reached 0.948.</li>
</ul>

<h3>Title: On gauge freedom, conservativity and intrinsic dimensionality estimation  in diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Christian Horvat, Jean-Pascal Pfister</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03845">https://arxiv.org/abs/2402.03845</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03845">https://arxiv.org/pdf/2402.03845</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03845]] On gauge freedom, conservativity and intrinsic dimensionality estimation  in diffusion models(https://arxiv.org/abs/2402.03845)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models are generative models that have recently demonstrated impressive performances in terms of sampling quality and density estimation in high dimensions. They rely on a forward continuous diffusion process and a backward continuous denoising process, which can be described by a time-dependent vector field and is used as a generative model. In the original formulation of the diffusion model, this vector field is assumed to be the score function (i.e. it is the gradient of the log-probability at a given time in the diffusion process). Curiously, on the practical side, most studies on diffusion models implement this vector field as a neural network function and do not constrain it be the gradient of some energy function (that is, most studies do not constrain the vector field to be conservative). Even though some studies investigated empirically whether such a constraint will lead to a performance gain, they lead to contradicting results and failed to provide analytical results. Here, we provide three analytical results regarding the extent of the modeling freedom of this vector field. {Firstly, we propose a novel decomposition of vector fields into a conservative component and an orthogonal component which satisfies a given (gauge) freedom. Secondly, from this orthogonal decomposition, we show that exact density estimation and exact sampling is achieved when the conservative component is exactly equals to the true score and therefore conservativity is neither necessary nor sufficient to obtain exact density estimation and exact sampling. Finally, we show that when it comes to inferring local information of the data manifold, constraining the vector field to be conservative is desirable.</li>
</ul>

<h3>Title: ANLS* -- A Universal Document Processing Metric for Generative Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>David Peer, Philemon Schöpf, Volckmar Nebendahl, Alexander Rietzler, Sebastian Stabinger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03848">https://arxiv.org/abs/2402.03848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03848">https://arxiv.org/pdf/2402.03848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03848]] ANLS* -- A Universal Document Processing Metric for Generative Large  Language Models(https://arxiv.org/abs/2402.03848)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>Traditionally, discriminative models have been the predominant choice for tasks like document classification and information extraction. These models make predictions that fall into a limited number of predefined classes, facilitating a binary true or false evaluation and enabling the direct calculation of metrics such as the F1 score. However, recent advancements in generative large language models (GLLMs) have prompted a shift in the field due to their enhanced zero-shot capabilities, which eliminate the need for a downstream dataset and computationally expensive fine-tuning. However, evaluating GLLMs presents a challenge as the binary true or false evaluation used for discriminative models is not applicable to the predictions made by GLLMs. This paper introduces a new metric for generative models called ANLS* for evaluating a wide variety of tasks, including information extraction and classification tasks. The ANLS* metric extends existing ANLS metrics as a drop-in-replacement and is still compatible with previously reported ANLS scores. An evaluation of 7 different datasets and 3 different GLLMs using the ANLS* metric is also provided, demonstrating the importance of the proposed metric. We also benchmark a novel approach to generate prompts for documents, called SFT, against other prompting techniques such as LATIN. In 15 out of 21 cases, SFT outperforms other techniques and improves the state-of-the-art, sometimes by as much as $15$ percentage points. Sources are available at https://github.com/deepopinion/anls_star_metric</li>
</ul>

<h3>Title: Position Paper: Toward New Frameworks for Studying Model Representations</h3>
<ul>
<li><strong>Authors: </strong>Satvik Golechha, James Dao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03855">https://arxiv.org/abs/2402.03855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03855">https://arxiv.org/pdf/2402.03855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03855]] Position Paper: Toward New Frameworks for Studying Model Representations(https://arxiv.org/abs/2402.03855)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Mechanistic interpretability (MI) aims to understand AI models by reverse-engineering the exact algorithms neural networks learn. Most works in MI so far have studied behaviors and capabilities that are trivial and token-aligned. However, most capabilities are not that trivial, which advocates for the study of hidden representations inside these networks as the unit of analysis. We do a literature review, formalize representations for features and behaviors, highlight their importance and evaluation, and perform some basic exploration in the mechanistic interpretability of representations. With discussion and exploratory results, we justify our position that studying representations is an important and under-studied field, and that currently established methods in MI are not sufficient to understand representations, thus pushing for the research community to work toward new frameworks for studying representations.</li>
</ul>

<h3>Title: Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Spyridon Mouselinos, Henryk Michalewski, Mateusz Malinowski</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03877">https://arxiv.org/abs/2402.03877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03877">https://arxiv.org/pdf/2402.03877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03877]] Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large  Language Models(https://arxiv.org/abs/2402.03877)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs' abilities in constructive geometric problem-solving one of the most fundamental steps in the development of human mathematical reasoning. Our work reveals notable challenges that the state-of-the-art LLMs face in this domain despite many successes in similar areas. LLMs exhibit biases in target variable selection and struggle with 2D spatial relationships, often misrepresenting and hallucinating objects and their placements. To this end, we introduce a framework that formulates an LLMs-based multi-agents system that enhances their existing reasoning potential by conducting an internal dialogue. This work underscores LLMs' current limitations in geometric reasoning and improves geometric reasoning capabilities through self-correction, collaboration, and diverse role specializations.</li>
</ul>

<h3>Title: DistiLLM: Towards Streamlined Distillation for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jongwoo Ko, Sungnyun Kim, Tianyi Chen, Se-Young Yun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03898">https://arxiv.org/abs/2402.03898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03898">https://arxiv.org/pdf/2402.03898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03898]] DistiLLM: Towards Streamlined Distillation for Large Language Models(https://arxiv.org/abs/2402.03898)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge distillation (KD) is widely used for compressing a teacher model to a smaller student model, reducing its inference cost and memory footprint while preserving model capabilities. However, current KD methods for auto-regressive sequence models (e.g., large language models) suffer from missing a standardized objective function. Moreover, the recent use of student-generated outputs to address training-inference mismatches has significantly escalated computational costs. To tackle these issues, we introduce DistiLLM, a more effective and efficient KD framework for auto-regressive language models. DistiLLM comprises two components: (1) a novel skew Kullback-Leibler divergence loss, where we unveil and leverage its theoretical properties, and (2) an adaptive off-policy approach designed to enhance the efficiency in utilizing student-generated outputs. Extensive experiments, including instruction-following tasks, demonstrate the effectiveness of DistiLLM in building high-performing student models while achieving up to 4.3$\times$ speedup compared to recent KD methods.</li>
</ul>

<h3>Title: EscherNet: A Generative Model for Scalable View Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Xin Kong, Shikun Liu, Xiaoyang Lyu, Marwan Taher, Xiaojuan Qi, Andrew J. Davison</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03908">https://arxiv.org/abs/2402.03908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03908">https://arxiv.org/pdf/2402.03908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03908]] EscherNet: A Generative Model for Scalable View Synthesis(https://arxiv.org/abs/2402.03908)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce EscherNet, a multi-view conditioned diffusion model for view synthesis. EscherNet learns implicit and generative 3D representations coupled with a specialised camera positional encoding, allowing precise and continuous relative control of the camera transformation between an arbitrary number of reference and target views. EscherNet offers exceptional generality, flexibility, and scalability in view synthesis -- it can generate more than 100 consistent target views simultaneously on a single consumer-grade GPU, despite being trained with a fixed number of 3 reference views to 3 target views. As a result, EscherNet not only addresses zero-shot novel view synthesis, but also naturally unifies single- and multi-image 3D reconstruction, combining these diverse tasks into a single, cohesive framework. Our extensive experiments demonstrate that EscherNet achieves state-of-the-art performance in multiple benchmarks, even when compared to methods specifically tailored for each individual problem. This remarkable versatility opens up new directions for designing scalable neural architectures for 3D vision. Project page: \url{https://kxhit.github.io/EscherNet}.</li>
</ul>

<h3>Title: Large Language Models to Enhance Bayesian Optimization</h3>
<ul>
<li><strong>Authors: </strong>Tennison Liu, Nicolás Astorga, Nabeel Seedat, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03921">https://arxiv.org/abs/2402.03921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03921">https://arxiv.org/pdf/2402.03921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03921]] Large Language Models to Enhance Bayesian Optimization(https://arxiv.org/abs/2402.03921)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Bayesian optimization (BO) is a powerful approach for optimizing complex and expensive-to-evaluate black-box functions. Its importance is underscored in many applications, notably including hyperparameter tuning, but its efficacy depends on efficiently balancing exploration and exploitation. While there has been substantial progress in BO methods, striking this balance still remains a delicate process. In this light, we present \texttt{LLAMBO}, a novel approach that integrates the capabilities of large language models (LLM) within BO. At a high level, we frame the BO problem in natural language terms, enabling LLMs to iteratively propose promising solutions conditioned on historical evaluations. More specifically, we explore how combining contextual understanding, few-shot learning proficiency, and domain knowledge of LLMs can enhance various components of model-based BO. Our findings illustrate that \texttt{LLAMBO} is effective at zero-shot warmstarting, and improves surrogate modeling and candidate sampling, especially in the early stages of search when observations are sparse. Our approach is performed in context and does not require LLM finetuning. Additionally, it is modular by design, allowing individual components to be integrated into existing BO frameworks, or function cohesively as an end-to-end method. We empirically validate \texttt{LLAMBO}'s efficacy on the problem of hyperparameter tuning, highlighting strong empirical performance across a range of diverse benchmarks, proprietary, and synthetic tasks.</li>
</ul>

<h3>Title: Return-Aligned Decision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Tsunehiko Tanaka, Kenshi Abe, Kaito Ariu, Tetsuro Morimura, Edgar Simo-Serra</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03923">https://arxiv.org/abs/2402.03923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03923">https://arxiv.org/pdf/2402.03923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03923]] Return-Aligned Decision Transformer(https://arxiv.org/abs/2402.03923)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Traditional approaches in offline reinforcement learning aim to learn the optimal policy that maximizes the cumulative reward, also known as return. However, as applications broaden, it becomes increasingly crucial to train agents that not only maximize the returns, but align the actual return with a specified target return, giving control over the agent's performance. Decision Transformer (DT) optimizes a policy that generates actions conditioned on the target return through supervised learning and is equipped with a mechanism to control the agent using the target return. Despite being designed to align the actual return with the target return, we have empirically identified a discrepancy between the actual return and the target return in DT. In this paper, we propose Return-Aligned Decision Transformer (RADT), designed to effectively align the actual return with the target return. Our model decouples returns from the conventional input sequence, which typically consists of returns, states, and actions, to enhance the relationships between returns and states, as well as returns and actions. Extensive experiments show that RADT reduces the discrepancies between the actual return and the target return of DT-based methods.</li>
</ul>

<h3>Title: Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in  Closed-Source LLMs</h3>
<ul>
<li><strong>Authors: </strong>Simone Balloccu, Patrícia Schmidtová, Mateusz Lango, Ondřej Dušek</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03927">https://arxiv.org/abs/2402.03927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03927">https://arxiv.org/pdf/2402.03927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03927]] Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in  Closed-Source LLMs(https://arxiv.org/abs/2402.03927)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Natural Language Processing (NLP) research is increasingly focusing on the use of Large Language Models (LLMs), with some of the most popular ones being either fully or partially closed-source. The lack of access to model details, especially regarding training data, has repeatedly raised concerns about data contamination among researchers. Several attempts have been made to address this issue, but they are limited to anecdotal evidence and trial and error. Additionally, they overlook the problem of \emph{indirect} data leaking, where models are iteratively improved by using data coming from users. In this work, we conduct the first systematic analysis of work using OpenAI's GPT-3.5 and GPT-4, the most prominently used LLMs today, in the context of data contamination. By analysing 255 papers and considering OpenAI's data usage policy, we extensively document the amount of data leaked to these models during the first year after the model's release. We report that these models have been globally exposed to $\sim$4.7M samples from 263 benchmarks. At the same time, we document a number of evaluation malpractices emerging in the reviewed papers, such as unfair or missing baseline comparisons and reproducibility issues. We release our results as a collaborative project on https://leak-llm.github.io/, where other researchers can contribute to our efforts.</li>
</ul>

<h3>Title: Discovery of the Hidden World with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chenxi Liu, Yongqiang Chen, Tongliang Liu, Mingming Gong, James Cheng, Bo Han, Kun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03941">https://arxiv.org/abs/2402.03941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03941">https://arxiv.org/pdf/2402.03941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03941]] Discovery of the Hidden World with Large Language Models(https://arxiv.org/abs/2402.03941)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Science originates with discovering new causal knowledge from a combination of known facts and observations. Traditional causal discovery approaches mainly rely on high-quality measured variables, usually given by human experts, to find causal relations. However, the causal variables are usually unavailable in a wide range of real-world applications. The rise of large language models (LLMs) that are trained to learn rich knowledge from the massive observations of the world, provides a new opportunity to assist with discovering high-level hidden variables from the raw observational data. Therefore, we introduce COAT: Causal representatiOn AssistanT. COAT incorporates LLMs as a factor proposer that extracts the potential causal factors from unstructured data. Moreover, LLMs can also be instructed to provide additional information used to collect data values (e.g., annotation criteria) and to further parse the raw unstructured data into structured data. The annotated data will be fed to a causal learning module (e.g., the FCI algorithm) that provides both rigorous explanations of the data, as well as useful feedback to further improve the extraction of causal factors by LLMs. We verify the effectiveness of COAT in uncovering the underlying causal system with two case studies of review rating analysis and neuropathic diagnosis.</li>
</ul>

<h3>Title: IMUSIC: IMU-based Facial Expression Capture</h3>
<ul>
<li><strong>Authors: </strong>Youjia Wang, Yiwen Wu, Ruiqian Li, Hengan Zhou, Hongyang Lin, Yingwenqi Jiang, Yingsheng Zhu, Guanpeng Long, Jingya Wang, Lan Xu, Jingyi Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03944">https://arxiv.org/abs/2402.03944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03944">https://arxiv.org/pdf/2402.03944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03944]] IMUSIC: IMU-based Facial Expression Capture(https://arxiv.org/abs/2402.03944)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>For facial motion capture and analysis, the dominated solutions are generally based on visual cues, which cannot protect privacy and are vulnerable to occlusions. Inertial measurement units (IMUs) serve as potential rescues yet are mainly adopted for full-body motion capture. In this paper, we propose IMUSIC to fill the gap, a novel path for facial expression capture using purely IMU signals, significantly distant from previous visual solutions.The key design in our IMUSIC is a trilogy. We first design micro-IMUs to suit facial capture, companion with an anatomy-driven IMU placement scheme. Then, we contribute a novel IMU-ARKit dataset, which provides rich paired IMU/visual signals for diverse facial expressions and performances. Such unique multi-modality brings huge potential for future directions like IMU-based facial behavior analysis. Moreover, utilizing IMU-ARKit, we introduce a strong baseline approach to accurately predict facial blendshape parameters from purely IMU signals. Specifically, we tailor a Transformer diffusion model with a two-stage training strategy for this novel tracking task. The IMUSIC framework empowers us to perform accurate facial capture in scenarios where visual methods falter and simultaneously safeguard user privacy. We conduct extensive experiments about both the IMU configuration and technical components to validate the effectiveness of our IMUSIC approach. Notably, IMUSIC enables various potential and novel applications, i.e., privacy-protecting facial capture, hybrid capture against occlusions, or detecting minute facial movements that are often invisible through visual cues. We will release our dataset and implementations to enrich more possibilities of facial capture and analysis in our community.</li>
</ul>

<h3>Title: Boosting Adversarial Transferability across Model Genus by  Deformation-Constrained Warping</h3>
<ul>
<li><strong>Authors: </strong>Qinliang Lin, Cheng Luo, Zenghao Niu, Xilin He, Weicheng Xie, Yuanbo Hou, Linlin Shen, Siyang Song</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03951">https://arxiv.org/abs/2402.03951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03951">https://arxiv.org/pdf/2402.03951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03951]] Boosting Adversarial Transferability across Model Genus by  Deformation-Constrained Warping(https://arxiv.org/abs/2402.03951)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>Adversarial examples generated by a surrogate model typically exhibit limited transferability to unknown target systems. To address this problem, many transferability enhancement approaches (e.g., input transformation and model augmentation) have been proposed. However, they show poor performances in attacking systems having different model genera from the surrogate model. In this paper, we propose a novel and generic attacking strategy, called Deformation-Constrained Warping Attack (DeCoWA), that can be effectively applied to cross model genus attack. Specifically, DeCoWA firstly augments input examples via an elastic deformation, namely Deformation-Constrained Warping (DeCoW), to obtain rich local details of the augmented input. To avoid severe distortion of global semantics led by random deformation, DeCoW further constrains the strength and direction of the warping transformation by a novel adaptive control strategy. Extensive experiments demonstrate that the transferable examples crafted by our DeCoWA on CNN surrogates can significantly hinder the performance of Transformers (and vice versa) on various tasks, including image classification, video action recognition, and audio recognition. Code is made available at https://github.com/LinQinLiang/DeCoWA.</li>
</ul>

<h3>Title: In-context learning agents are asymmetric belief updaters</h3>
<ul>
<li><strong>Authors: </strong>Johannes A. Schubert, Akshay K. Jagadish, Marcel Binz, Eric Schulz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03969">https://arxiv.org/abs/2402.03969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03969">https://arxiv.org/pdf/2402.03969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03969]] In-context learning agents are asymmetric belief updaters(https://arxiv.org/abs/2402.03969)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study the in-context learning dynamics of large language models (LLMs) using three instrumental learning tasks adapted from cognitive psychology. We find that LLMs update their beliefs in an asymmetric manner and learn more from better-than-expected outcomes than from worse-than-expected ones. Furthermore, we show that this effect reverses when learning about counterfactual feedback and disappears when no agency is implied. We corroborate these findings by investigating idealized in-context learning agents derived through meta-reinforcement learning, where we observe similar patterns. Taken together, our results contribute to our understanding of how in-context learning works by highlighting that the framing of a problem significantly influences how learning occurs, a phenomenon also observed in human cognition.</li>
</ul>

<h3>Title: Tabular Data: Is Attention All You Need?</h3>
<ul>
<li><strong>Authors: </strong>Guri Zabërgja, Arlind Kadra, Josif Grabocka</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03970">https://arxiv.org/abs/2402.03970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03970">https://arxiv.org/pdf/2402.03970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03970]] Tabular Data: Is Attention All You Need?(https://arxiv.org/abs/2402.03970)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep Learning has revolutionized the field of AI and led to remarkable achievements in applications involving image and text data. Unfortunately, there is inconclusive evidence on the merits of neural networks for structured tabular data. In this paper, we introduce a large-scale empirical study comparing neural networks against gradient-boosted decision trees on tabular data, but also transformer-based architectures against traditional multi-layer perceptrons (MLP) with residual connections. In contrast to prior work, our empirical findings indicate that neural networks are competitive against decision trees. Furthermore, we assess that transformer-based architectures do not outperform simpler variants of traditional MLP architectures on tabular datasets. As a result, this paper helps the research and practitioner communities make informed choices on deploying neural networks on future tabular data applications.</li>
</ul>

<h3>Title: Humans Beat Deep Networks at Recognizing Objects in Unusual Poses, Given  Enough Time</h3>
<ul>
<li><strong>Authors: </strong>Netta Ollikka, Amro Abbas, Andrea Perin, Markku Kilpeläinen, Stéphane Deny</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03973">https://arxiv.org/abs/2402.03973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03973">https://arxiv.org/pdf/2402.03973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03973]] Humans Beat Deep Networks at Recognizing Objects in Unusual Poses, Given  Enough Time(https://arxiv.org/abs/2402.03973)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning is closing the gap with humans on several object recognition benchmarks. Here we investigate this gap in the context of challenging images where objects are seen from unusual viewpoints. We find that humans excel at recognizing objects in unusual poses, in contrast with state-of-the-art pretrained networks (EfficientNet, SWAG, ViT, SWIN, BEiT, ConvNext) which are systematically brittle in this condition. Remarkably, as we limit image exposure time, human performance degrades to the level of deep networks, suggesting that additional mental processes (requiring additional time) take place when humans identify objects in unusual poses. Finally, our analysis of error patterns of humans vs. networks reveals that even time-limited humans are dissimilar to feed-forward deep networks. We conclude that more work is needed to bring computer vision systems to the level of robustness of the human visual system. Understanding the nature of the mental processes taking place during extra viewing time may be key to attain such robustness.</li>
</ul>

<h3>Title: Controllable Diverse Sampling for Diffusion Based Motion Behavior  Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Yiming Xu, Hao Cheng, Monika Sester</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03981">https://arxiv.org/abs/2402.03981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03981">https://arxiv.org/pdf/2402.03981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03981]] Controllable Diverse Sampling for Diffusion Based Motion Behavior  Forecasting(https://arxiv.org/abs/2402.03981)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>In autonomous driving tasks, trajectory prediction in complex traffic environments requires adherence to real-world context conditions and behavior multimodalities. Existing methods predominantly rely on prior assumptions or generative models trained on curated data to learn road agents' stochastic behavior bounded by scene constraints. However, they often face mode averaging issues due to data imbalance and simplistic priors, and could even suffer from mode collapse due to unstable training and single ground truth supervision. These issues lead the existing methods to a loss of predictive diversity and adherence to the scene constraints. To address these challenges, we introduce a novel trajectory generator named Controllable Diffusion Trajectory (CDT), which integrates map information and social interactions into a Transformer-based conditional denoising diffusion model to guide the prediction of future trajectories. To ensure multimodality, we incorporate behavioral tokens to direct the trajectory's modes, such as going straight, turning right or left. Moreover, we incorporate the predicted endpoints as an alternative behavioral token into the CDT model to facilitate the prediction of accurate trajectories. Extensive experiments on the Argoverse 2 benchmark demonstrate that CDT excels in generating diverse and scene-compliant trajectories in complex urban settings.</li>
</ul>

<h3>Title: Space Group Constrained Crystal Generation</h3>
<ul>
<li><strong>Authors: </strong>Rui Jiao, Wenbing Huang, Yu Liu, Deli Zhao, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.03992">https://arxiv.org/abs/2402.03992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.03992">https://arxiv.org/pdf/2402.03992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.03992]] Space Group Constrained Crystal Generation(https://arxiv.org/abs/2402.03992)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Crystals are the foundation of numerous scientific and industrial applications. While various learning-based approaches have been proposed for crystal generation, existing methods seldom consider the space group constraint which is crucial in describing the geometry of crystals and closely relevant to many desirable properties. However, considering space group constraint is challenging owing to its diverse and nontrivial forms. In this paper, we reduce the space group constraint into an equivalent formulation that is more tractable to be handcrafted into the generation process. In particular, we translate the space group constraint into two parts: the basis constraint of the invariant logarithmic space of the lattice matrix and the Wyckoff position constraint of the fractional coordinates. Upon the derived constraints, we then propose DiffCSP++, a novel diffusion model that has enhanced a previous work DiffCSP by further taking space group constraint into account. Experiments on several popular datasets verify the benefit of the involvement of the space group constraint, and show that our DiffCSP++ achieves promising performance on crystal structure prediction, ab initio crystal generation and controllable generation with customized space groups.</li>
</ul>

<h3>Title: Understanding the Effect of Noise in LLM Training Data with Algorithmic  Chains of Thought</h3>
<ul>
<li><strong>Authors: </strong>Alex Havrilla, Maia Iyer</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04004">https://arxiv.org/abs/2402.04004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04004">https://arxiv.org/pdf/2402.04004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04004]] Understanding the Effect of Noise in LLM Training Data with Algorithmic  Chains of Thought(https://arxiv.org/abs/2402.04004)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>During both pretraining and fine-tuning, Large Language Models (\textbf{LLMs}) are trained on trillions of tokens of text of widely varying quality. Both phases of training typically involve heuristically filtering out ``low-quality'' or \textit{noisy} training samples, yet little is known quantitatively about how the type or intensity of noise affects downstream performance. In this work, we study how noise in chain of thought (\textbf{CoT}) impacts task performance in the highly-controlled setting of algorithmically solvable tasks. First, we develop the Traced Integer (\textbf{TInt}) framework to generate highly customizable noised execution traces for any arithmetic function on lists of integers. We then define two types of noise: \textit{static} noise, a local form of noise which is applied after the CoT trace is computed, and \textit{dynamic} noise, a global form of noise which propagates errors in the trace as it is computed. We then evaluate the test performance of pretrained models both prompted and fine-tuned on noised datasets with varying levels of dataset contamination and intensity. We find fine-tuned models are extremely robust to high levels of static noise but struggle significantly more with lower levels of dynamic noise. In contrast, few-shot prompted models appear more sensitive to even static noise. We conclude with a discussion of how our findings impact noise filtering best-practices, in particular emphasizing the importance of removing samples containing destructive dynamic noise with global errors.</li>
</ul>

<h3>Title: Efficient Availability Attacks against Supervised and Contrastive  Learning Simultaneously</h3>
<ul>
<li><strong>Authors: </strong>Yihan Wang, Yifan Zhu, Xiao-Shan Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04010">https://arxiv.org/abs/2402.04010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04010">https://arxiv.org/pdf/2402.04010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04010]] Efficient Availability Attacks against Supervised and Contrastive  Learning Simultaneously(https://arxiv.org/abs/2402.04010)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>Availability attacks can prevent the unauthorized use of private data and commercial datasets by generating imperceptible noise and making unlearnable examples before release. Ideally, the obtained unlearnability prevents algorithms from training usable models. When supervised learning (SL) algorithms have failed, a malicious data collector possibly resorts to contrastive learning (CL) algorithms to bypass the protection. Through evaluation, we have found that most of the existing methods are unable to achieve both supervised and contrastive unlearnability, which poses risks to data protection. Different from recent methods based on contrastive error minimization, we employ contrastive-like data augmentations in supervised error minimization or maximization frameworks to obtain attacks effective for both SL and CL. Our proposed AUE and AAP attacks achieve state-of-the-art worst-case unlearnability across SL and CL algorithms with less computation consumption, showcasing prospects in real-world applications.</li>
</ul>

<h3>Title: Privacy Leakage on DNNs: A Survey of Model Inversion Attacks and  Defenses</h3>
<ul>
<li><strong>Authors: </strong>Hao Fang, Yixiang Qiu, Hongyao Yu, Wenbo Yu, Jiawei Kong, Baoli Chong, Bin Chen, Xuan Wang, Shu-Tao Xia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04013">https://arxiv.org/abs/2402.04013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04013">https://arxiv.org/pdf/2402.04013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04013]] Privacy Leakage on DNNs: A Survey of Model Inversion Attacks and  Defenses(https://arxiv.org/abs/2402.04013)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack</a></li>
<li><strong>Abstract: </strong>Model Inversion (MI) attacks aim to disclose private information about the training data by abusing access to the pre-trained models. These attacks enable adversaries to reconstruct high-fidelity data that closely aligns with the private training data, which has raised significant privacy concerns. Despite the rapid advances in the field, we lack a comprehensive overview of existing MI attacks and defenses. To fill this gap, this paper thoroughly investigates this field and presents a holistic survey. Firstly, our work briefly reviews the traditional MI on machine learning scenarios. We then elaborately analyze and compare numerous recent attacks and defenses on \textbf{D}eep \textbf{N}eural \textbf{N}etworks (DNNs) across multiple modalities and learning tasks.</li>
</ul>

<h3>Title: Polyp-DDPM: Diffusion-Based Semantic Polyp Synthesis for Enhanced  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zolnamar Dorjsembe, Hsing-Kuo Pao, Furen Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04031">https://arxiv.org/abs/2402.04031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04031">https://arxiv.org/pdf/2402.04031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04031]] Polyp-DDPM: Diffusion-Based Semantic Polyp Synthesis for Enhanced  Segmentation(https://arxiv.org/abs/2402.04031)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>This study introduces Polyp-DDPM, a diffusion-based method for generating realistic images of polyps conditioned on masks, aimed at enhancing the segmentation of gastrointestinal (GI) tract polyps. Our approach addresses the challenges of data limitations, high annotation costs, and privacy concerns associated with medical images. By conditioning the diffusion model on segmentation masks-binary masks that represent abnormal areas-Polyp-DDPM outperforms state-of-the-art methods in terms of image quality (achieving a Frechet Inception Distance (FID) score of 78.47, compared to scores above 83.79) and segmentation performance (achieving an Intersection over Union (IoU) of 0.7156, versus less than 0.6694 for synthetic images from baseline models and 0.7067 for real data). Our method generates a high-quality, diverse synthetic dataset for training, thereby enhancing polyp segmentation models to be comparable with real images and offering greater data augmentation capabilities to improve segmentation models. The source code and pretrained weights for Polyp-DDPM are made publicly available at https://github.com/mobaidoctor/polyp-ddpm.</li>
</ul>

<h3>Title: On provable privacy vulnerabilities of graph representations</h3>
<ul>
<li><strong>Authors: </strong>Ruofan Wu, Guanhua Fang, Qiying Pan, Mingyang Zhang, Tengfei Liu, Weiqiang Wang, Wenbiao Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04033">https://arxiv.org/abs/2402.04033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04033">https://arxiv.org/pdf/2402.04033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04033]] On provable privacy vulnerabilities of graph representations(https://arxiv.org/abs/2402.04033)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack</a></li>
<li><strong>Abstract: </strong>Graph representation learning (GRL) is critical for extracting insights from complex network structures, but it also raises security concerns due to potential privacy vulnerabilities in these representations. This paper investigates the structural vulnerabilities in graph neural models where sensitive topological information can be inferred through edge reconstruction attacks. Our research primarily addresses the theoretical underpinnings of cosine-similarity-based edge reconstruction attacks (COSERA), providing theoretical and empirical evidence that such attacks can perfectly reconstruct sparse Erdos Renyi graphs with independent random features as graph size increases. Conversely, we establish that sparsity is a critical factor for COSERA's effectiveness, as demonstrated through analysis and experiments on stochastic block models. Finally, we explore the resilience of (provably) private graph representations produced via noisy aggregation (NAG) mechanism against COSERA. We empirically delineate instances wherein COSERA demonstrates both efficacy and deficiency in its capacity to function as an instrument for elucidating the trade-off between privacy and utility.</li>
</ul>

<h3>Title: Systematic Biases in LLM Simulations of Debates</h3>
<ul>
<li><strong>Authors: </strong>Amir Taubenfeld, Yaniv Dover, Roi Reichart, Ariel Goldstein</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04049">https://arxiv.org/abs/2402.04049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04049">https://arxiv.org/pdf/2402.04049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04049]] Systematic Biases in LLM Simulations of Debates(https://arxiv.org/abs/2402.04049)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in natural language processing, especially the emergence of Large Language Models (LLMs), have opened exciting possibilities for constructing computational simulations designed to replicate human behavior accurately. However, LLMs are complex statistical learners without straightforward deductive rules, making them prone to unexpected behaviors. In this study, we highlight the limitations of LLMs in simulating human interactions, particularly focusing on LLMs' ability to simulate political debates. Our findings indicate a tendency for LLM agents to conform to the model's inherent social biases despite being directed to debate from certain political perspectives. This tendency results in behavioral patterns that seem to deviate from well-established social dynamics among humans. We reinforce these observations using an automatic self-fine-tuning method, which enables us to manipulate the biases within the LLM and demonstrate that agents subsequently align with the altered biases. These results underscore the need for further research to develop methods that help agents overcome these biases, a critical step toward creating more realistic simulations.</li>
</ul>

<h3>Title: Multi-class Road Defect Detection and Segmentation using Spatial and  Channel-wise Attention for Autonomous Road Repairing</h3>
<ul>
<li><strong>Authors: </strong>Jongmin Yu, Chen Bene Chi, Sebastiano Fichera, Paolo Paoletti, Devansh Mehta, Shan Luo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04064">https://arxiv.org/abs/2402.04064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04064">https://arxiv.org/pdf/2402.04064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04064]] Multi-class Road Defect Detection and Segmentation using Spatial and  Channel-wise Attention for Autonomous Road Repairing(https://arxiv.org/abs/2402.04064)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Road pavement detection and segmentation are critical for developing autonomous road repair systems. However, developing an instance segmentation method that simultaneously performs multi-class defect detection and segmentation is challenging due to the textural simplicity of road pavement image, the diversity of defect geometries, and the morphological ambiguity between classes. We propose a novel end-to-end method for multi-class road defect detection and segmentation. The proposed method comprises multiple spatial and channel-wise attention blocks available to learn global representations across spatial and channel-wise dimensions. Through these attention blocks, more globally generalised representations of morphological information (spatial characteristics) of road defects and colour and depth information of images can be learned. To demonstrate the effectiveness of our framework, we conducted various ablation studies and comparisons with prior methods on a newly collected dataset annotated with nine road defect classes. The experiments show that our proposed method outperforms existing state-of-the-art methods for multi-class road defect detection and segmentation methods.</li>
</ul>

<h3>Title: Iterative Prompt Refinement for Radiation Oncology Symptom Extraction  Using Teacher-Student Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Reza Khanmohammadi, Ahmed I Ghanem, Kyle Verdecchia, Ryan Hall, Mohamed Elshaikh, Benjamin Movsas, Hassan Bagher-Ebadian, Indrin Chetty, Mohammad M. Ghassemi, Kundan Thind</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04075">https://arxiv.org/abs/2402.04075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04075">https://arxiv.org/pdf/2402.04075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04075]] Iterative Prompt Refinement for Radiation Oncology Symptom Extraction  Using Teacher-Student Large Language Models(https://arxiv.org/abs/2402.04075)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This study introduces a novel teacher-student architecture utilizing Large Language Models (LLMs) to improve prostate cancer radiotherapy symptom extraction from clinical notes. Mixtral, the student model, initially extracts symptoms, followed by GPT-4, the teacher model, which refines prompts based on Mixtral's performance. This iterative process involved 294 single symptom clinical notes across 12 symptoms, with up to 16 rounds of refinement per epoch. Results showed significant improvements in extracting symptoms from both single and multi-symptom notes. For 59 single symptom notes, accuracy increased from 0.51 to 0.71, precision from 0.52 to 0.82, recall from 0.52 to 0.72, and F1 score from 0.49 to 0.73. In 375 multi-symptom notes, accuracy rose from 0.24 to 0.43, precision from 0.6 to 0.76, recall from 0.24 to 0.43, and F1 score from 0.20 to 0.44. These results demonstrate the effectiveness of advanced prompt engineering in LLMs for radiation oncology use.</li>
</ul>

<h3>Title: Entropy-regularized Diffusion Policy with Q-Ensembles for Offline  Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ruoqi Zhang, Ziwei Luo, Jens Sjölund, Thomas B. Schön, Per Mattsson</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04080">https://arxiv.org/abs/2402.04080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04080">https://arxiv.org/pdf/2402.04080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04080]] Entropy-regularized Diffusion Policy with Q-Ensembles for Offline  Reinforcement Learning(https://arxiv.org/abs/2402.04080)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>This paper presents advanced techniques of training diffusion policies for offline reinforcement learning (RL). At the core is a mean-reverting stochastic differential equation (SDE) that transfers a complex action distribution into a standard Gaussian and then samples actions conditioned on the environment state with a corresponding reverse-time SDE, like a typical diffusion policy. We show that such an SDE has a solution that we can use to calculate the log probability of the policy, yielding an entropy regularizer that improves the exploration of offline datasets. To mitigate the impact of inaccurate value functions from out-of-distribution data points, we further propose to learn the lower confidence bound of Q-ensembles for more robust policy improvement. By combining the entropy-regularized diffusion policy with Q-ensembles in offline RL, our method achieves state-of-the-art performance on most tasks in D4RL benchmarks. Code is available at \href{https://github.com/ruoqizzz/Entropy-Regularized-Diffusion-Policy-with-QEnsemble}{https://github.com/ruoqizzz/Entropy-Regularized-Diffusion-Policy-with-QEnsemble}.</li>
</ul>

<h3>Title: Provably learning a multi-head attention layer</h3>
<ul>
<li><strong>Authors: </strong>Sitan Chen, Yuanzhi Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04084">https://arxiv.org/abs/2402.04084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04084">https://arxiv.org/pdf/2402.04084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04084]] Provably learning a multi-head attention layer(https://arxiv.org/abs/2402.04084)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The multi-head attention layer is one of the key components of the transformer architecture that sets it apart from traditional feed-forward models. Given a sequence length $k$, attention matrices $\mathbf{\Theta}_1,\ldots,\mathbf{\Theta}_m\in\mathbb{R}^{d\times d}$, and projection matrices $\mathbf{W}_1,\ldots,\mathbf{W}_m\in\mathbb{R}^{d\times d}$, the corresponding multi-head attention layer $F: \mathbb{R}^{k\times d}\to \mathbb{R}^{k\times d}$ transforms length-$k$ sequences of $d$-dimensional tokens $\mathbf{X}\in\mathbb{R}^{k\times d}$ via $F(\mathbf{X}) \triangleq \sum^m_{i=1} \mathrm{softmax}(\mathbf{X}\mathbf{\Theta}_i\mathbf{X}^\top)\mathbf{X}\mathbf{W}_i$. In this work, we initiate the study of provably learning a multi-head attention layer from random examples and give the first nontrivial upper and lower bounds for this problem: - Provided $\{\mathbf{W}_i, \mathbf{\Theta}_i\}$ satisfy certain non-degeneracy conditions, we give a $(dk)^{O(m^3)}$-time algorithm that learns $F$ to small error given random labeled examples drawn uniformly from $\{\pm 1\}^{k\times d}$. - We prove computational lower bounds showing that in the worst case, exponential dependence on $m$ is unavoidable. We focus on Boolean $\mathbf{X}$ to mimic the discrete nature of tokens in large language models, though our techniques naturally extend to standard continuous settings, e.g. Gaussian. Our algorithm, which is centered around using examples to sculpt a convex body containing the unknown parameters, is a significant departure from existing provable algorithms for learning feedforward networks, which predominantly exploit algebraic and rotation invariance properties of the Gaussian distribution. In contrast, our analysis is more flexible as it primarily relies on various upper and lower tail bounds for the input distribution and "slices" thereof.</li>
</ul>

<h3>Title: The Use of a Large Language Model for Cyberbullying Detection</h3>
<ul>
<li><strong>Authors: </strong>Bayode Ogunleye, Babitha Dharmaraj</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04088">https://arxiv.org/abs/2402.04088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04088">https://arxiv.org/pdf/2402.04088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04088]] The Use of a Large Language Model for Cyberbullying Detection(https://arxiv.org/abs/2402.04088)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The dominance of social media has added to the channels of bullying for perpetrators. Unfortunately, cyberbullying (CB) is the most prevalent phenomenon in todays cyber world, and is a severe threat to the mental and physical health of citizens. This opens the need to develop a robust system to prevent bullying content from online forums, blogs, and social media platforms to manage the impact in our society. Several machine learning (ML) algorithms have been proposed for this purpose. However, their performances are not consistent due to high class imbalance and generalisation issues. In recent years, large language models (LLMs) like BERT and RoBERTa have achieved state-of-the-art (SOTA) results in several natural language processing (NLP) tasks. Unfortunately, the LLMs have not been applied extensively for CB detection. In our paper, we explored the use of these models for cyberbullying (CB) detection. We have prepared a new dataset (D2) from existing studies (Formspring and Twitter). Our experimental results for dataset D1 and D2 showed that RoBERTa outperformed other models.</li>
</ul>

<h3>Title: Analysis of Deep Image Prior and Exploiting Self-Guidance for Image  Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Shijun Liang, Evan Bell, Qing Qu, Rongrong Wang, Saiprasad Ravishankar</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04097">https://arxiv.org/abs/2402.04097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04097">https://arxiv.org/pdf/2402.04097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04097]] Analysis of Deep Image Prior and Exploiting Self-Guidance for Image  Reconstruction(https://arxiv.org/abs/2402.04097)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The ability of deep image prior (DIP) to recover high-quality images from incomplete or corrupted measurements has made it popular in inverse problems in image restoration and medical imaging including magnetic resonance imaging (MRI). However, conventional DIP suffers from severe overfitting and spectral bias effects.In this work, we first provide an analysis of how DIP recovers information from undersampled imaging measurements by analyzing the training dynamics of the underlying networks in the kernel regime for different architectures.This study sheds light on important underlying properties for DIP-based recovery.Current research suggests that incorporating a reference image as network input can enhance DIP's performance in image reconstruction compared to using random inputs. However, obtaining suitable reference images requires supervision, and raises practical difficulties. In an attempt to overcome this obstacle, we further introduce a self-driven reconstruction process that concurrently optimizes both the network weights and the input while eliminating the need for training data. Our method incorporates a novel denoiser regularization term which enables robust and stable joint estimation of both the network input and reconstructed image.We demonstrate that our self-guided method surpasses both the original DIP and modern supervised methods in terms of MR image reconstruction performance and outperforms previous DIP-based schemes for image inpainting.</li>
</ul>

<h3>Title: VRMM: A Volumetric Relightable Morphable Head Model</h3>
<ul>
<li><strong>Authors: </strong>Haotian Yang, Mingwu Zheng, Chongyang Ma, Yu-Kun Lai, Pengfei Wan, Haibin Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04101">https://arxiv.org/abs/2402.04101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04101">https://arxiv.org/pdf/2402.04101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04101]] VRMM: A Volumetric Relightable Morphable Head Model(https://arxiv.org/abs/2402.04101)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce the Volumetric Relightable Morphable Model (VRMM), a novel volumetric and parametric facial prior for 3D face modeling. While recent volumetric prior models offer improvements over traditional methods like 3D Morphable Models (3DMMs), they face challenges in model learning and personalized reconstructions. Our VRMM overcomes these by employing a novel training framework that efficiently disentangles and encodes latent spaces of identity, expression, and lighting into low-dimensional representations. This framework, designed with self-supervised learning, significantly reduces the constraints for training data, making it more feasible in practice. The learned VRMM offers relighting capabilities and encompasses a comprehensive range of expressions. We demonstrate the versatility and effectiveness of VRMM through various applications like avatar generation, facial reconstruction, and animation. Additionally, we address the common issue of overfitting in generative volumetric models with a novel prior-preserving personalization framework based on VRMM. Such an approach enables accurate 3D face reconstruction from even a single portrait input. Our experiments showcase the potential of VRMM to significantly enhance the field of 3D face modeling.</li>
</ul>

<h3>Title: An Exploration of Clustering Algorithms for Customer Segmentation in the  UK Retail Market</h3>
<ul>
<li><strong>Authors: </strong>Jeen Mary John, Olamilekan Shobayo, Bayode Ogunleye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04103">https://arxiv.org/abs/2402.04103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04103">https://arxiv.org/pdf/2402.04103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04103]] An Exploration of Clustering Algorithms for Customer Segmentation in the  UK Retail Market(https://arxiv.org/abs/2402.04103)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recently, peoples awareness of online purchases has significantly risen. This has given rise to online retail platforms and the need for a better understanding of customer purchasing behaviour. Retail companies are pressed with the need to deal with a high volume of customer purchases, which requires sophisticated approaches to perform more accurate and efficient customer segmentation. Customer segmentation is a marketing analytical tool that aids customer-centric service and thus enhances profitability. In this paper, we aim to develop a customer segmentation model to improve decision-making processes in the retail market industry. To achieve this, we employed a UK-based online retail dataset obtained from the UCI machine learning repository. The retail dataset consists of 541,909 customer records and eight features. Our study adopted the RFM (recency, frequency, and monetary) framework to quantify customer values. Thereafter, we compared several state-of-the-art (SOTA) clustering algorithms, namely, K-means clustering, the Gaussian mixture model (GMM), density-based spatial clustering of applications with noise (DBSCAN), agglomerative clustering, and balanced iterative reducing and clustering using hierarchies (BIRCH). The results showed the GMM outperformed other approaches, with a Silhouette Score of 0.80.</li>
</ul>

<h3>Title: Scientific Language Modeling: A Quantitative Review of Large Language  Models in Molecular Science</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Liu, Jun Tao, Zhixiang Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04119">https://arxiv.org/abs/2402.04119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04119">https://arxiv.org/pdf/2402.04119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04119]] Scientific Language Modeling: A Quantitative Review of Large Language  Models in Molecular Science(https://arxiv.org/abs/2402.04119)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Efficient molecular modeling and design are crucial for the discovery and exploration of novel molecules, and the incorporation of deep learning methods has revolutionized this field. In particular, large language models (LLMs) offer a fresh approach to tackle scientific problems from a natural language processing (NLP) perspective, introducing a research paradigm called scientific language modeling (SLM). However, two key issues remain: how to quantify the match between model and data modalities and how to identify the knowledge-learning preferences of models. To address these challenges, we propose a multi-modal benchmark, named ChEBI-20-MM, and perform 1263 experiments to assess the model's compatibility with data modalities and knowledge acquisition. Through the modal transition probability matrix, we provide insights into the most suitable modalities for tasks. Furthermore, we introduce a statistically interpretable approach to discover context-specific knowledge mapping by localized feature filtering. Our pioneering analysis offers an exploration of the learning mechanism and paves the way for advancing SLM in molecular science.</li>
</ul>

<h3>Title: U-shaped Vision Mamba for Single Image Dehazing</h3>
<ul>
<li><strong>Authors: </strong>Zhuoran Zheng, Chen Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04139">https://arxiv.org/abs/2402.04139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04139">https://arxiv.org/pdf/2402.04139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04139]] U-shaped Vision Mamba for Single Image Dehazing(https://arxiv.org/abs/2402.04139)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Currently, Transformer is the most popular architecture for image dehazing, but due to its large computational complexity, its ability to handle long-range dependency is limited on resource-constrained devices. To tackle this challenge, we introduce the U-shaped Vision Mamba (UVM-Net), an efficient single-image dehazing network. Inspired by the State Space Sequence Models (SSMs), a new deep sequence model known for its power to handle long sequences, we design a Bi-SSM block that integrates the local feature extraction ability of the convolutional layer with the ability of the SSM to capture long-range dependencies. Extensive experimental results demonstrate the effectiveness of our method. Our method provides a more highly efficient idea of long-range dependency modeling for image dehazing as well as other image restoration tasks. The URL of the code is \url{https://github.com/zzr-idam}.</li>
</ul>

<h3>Title: Attention with Markov: A Framework for Principled Analysis of  Transformers via Markov Chains</h3>
<ul>
<li><strong>Authors: </strong>Ashok Vardhan Makkuva, Marco Bondaschi, Adway Girish, Alliot Nagle, Martin Jaggi, Hyeji Kim, Michael Gastpar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.IT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04161">https://arxiv.org/abs/2402.04161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04161">https://arxiv.org/pdf/2402.04161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04161]] Attention with Markov: A Framework for Principled Analysis of  Transformers via Markov Chains(https://arxiv.org/abs/2402.04161)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>In recent years, attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. A key ingredient behind their success is the generative pretraining procedure, during which these models are trained on a large text corpus in an auto-regressive manner. To shed light on this phenomenon, we propose a new framework that allows both theory and systematic experiments to study the sequential modeling capabilities of transformers through the lens of Markov chains. Inspired by the Markovianity of natural languages, we model the data as a Markovian source and utilize this framework to systematically study the interplay between the data-distributional properties, the transformer architecture, the learnt distribution, and the final model performance. In particular, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima and bad local minima contingent upon the specific data characteristics and the transformer architecture. Backed by experiments, we demonstrate that our theoretical findings are in congruence with the empirical results. We further investigate these findings in the broader context of higher order Markov chains and deeper architectures, and outline open problems in this arena. Code is available at \url{https://github.com/Bond1995/Markov}.</li>
</ul>

<h3>Title: Mind the Gap: Securely modeling cyber risk based on security deviations  from a peer group</h3>
<ul>
<li><strong>Authors: </strong>Taylor Reynolds, Sarah Scheffler, Daniel J. Weitzner, Angelina Wu</a></li>
<li><strong>Subjects: </strong>cs.CR, econ.GN, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04166">https://arxiv.org/abs/2402.04166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04166">https://arxiv.org/pdf/2402.04166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04166]] Mind the Gap: Securely modeling cyber risk based on security deviations  from a peer group(https://arxiv.org/abs/2402.04166)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense</a></li>
<li><strong>Abstract: </strong>There are two strategic and longstanding questions about cyber risk that organizations largely have been unable to answer: What is an organization's estimated risk exposure and how does its security compare with peers? Answering both requires industry-wide data on security posture, incidents, and losses that, until recently, have been too sensitive for organizations to share. Now, privacy enhancing technologies (PETs) such as cryptographic computing can enable the secure computation of aggregate cyber risk metrics from a peer group of organizations while leaving sensitive input data undisclosed. As these new aggregate data become available, analysts need ways to integrate them into cyber risk models that can produce more reliable risk assessments and allow comparison to a peer group. This paper proposes a new framework for benchmarking cyber posture against peers and estimating cyber risk within specific economic sectors using the new variables emerging from secure computations. We introduce a new top-line variable called the Defense Gap Index representing the weighted security gap between an organization and its peers that can be used to forecast an organization's own security risk based on historical industry data. We apply this approach in a specific sector using data collected from 25 large firms, in partnership with an industry ISAO, to build an industry risk model and provide tools back to participants to estimate their own risk exposure and privately compare their security posture with their peers.</li>
</ul>

<h3>Title: COPS: A Compact On-device Pipeline for real-time Smishing detection</h3>
<ul>
<li><strong>Authors: </strong>Harichandana B S S, Sumit Kumar, Manjunath Bhimappa Ujjinakoppa, Barath Raj Kandur Raja</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04173">https://arxiv.org/abs/2402.04173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04173">https://arxiv.org/pdf/2402.04173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04173]] COPS: A Compact On-device Pipeline for real-time Smishing detection(https://arxiv.org/abs/2402.04173)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Smartphones have become indispensable in our daily lives and can do almost everything, from communication to online shopping. However, with the increased usage, cybercrime aimed at mobile devices is rocketing. Smishing attacks, in particular, have observed a significant upsurge in recent years. This problem is further exacerbated by the perpetrator creating new deceptive websites daily, with an average life cycle of under 15 hours. This renders the standard practice of keeping a database of malicious URLs ineffective. To this end, we propose a novel on-device pipeline: COPS that intelligently identifies features of fraudulent messages and URLs to alert the user in real-time. COPS is a lightweight pipeline with a detection module based on the Disentangled Variational Autoencoder of size 3.46MB for smishing and URL phishing detection, and we benchmark it on open datasets. We achieve an accuracy of 98.15% and 99.5%, respectively, for both tasks, with a false negative and false positive rate of a mere 0.037 and 0.015, outperforming previous works with the added advantage of ensuring real-time alerts on resource-constrained devices.</li>
</ul>

<h3>Title: Scaling Laws for Downstream Task Performance of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Berivan Isik, Natalia Ponomareva, Hussein Hazimeh, Dimitris Paparas, Sergei Vassilvitskii, Sanmi Koyejo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04177">https://arxiv.org/abs/2402.04177</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04177">https://arxiv.org/pdf/2402.04177</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04177]] Scaling Laws for Downstream Task Performance of Large Language Models(https://arxiv.org/abs/2402.04177)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scaling laws provide important insights that can guide the design of large language models (LLMs). Existing work has primarily focused on studying scaling laws for pretraining (upstream) loss. However, in transfer learning settings, in which LLMs are pretrained on an unsupervised dataset and then finetuned on a downstream task, we often also care about the downstream performance. In this work, we study the scaling behavior in a transfer learning setting, where LLMs are finetuned for machine translation tasks. Specifically, we investigate how the choice of the pretraining data and its size affect downstream performance (translation quality) as judged by two metrics: downstream cross-entropy and BLEU score. Our experiments indicate that the size of the finetuning dataset and the distribution alignment between the pretraining and downstream data significantly influence the scaling behavior. With sufficient alignment, both downstream cross-entropy and BLEU score improve monotonically with more pretraining data. In such cases, we show that it is possible to predict the downstream BLEU score with good accuracy using a log-law. However, there are also cases where moderate misalignment causes the BLEU score to fluctuate or get worse with more pretraining, whereas downstream cross-entropy monotonically improves. By analyzing these observations, we provide new practical insights for choosing appropriate pretraining data.</li>
</ul>

<h3>Title: SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection  with Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yichen Shi, Yuhao Gao, Yingxin Lai, Hongyang Wang, Jun Feng, Lei He, Jun Wan, Changsheng Chen, Zitong Yu, Xiaochun Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04178">https://arxiv.org/abs/2402.04178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04178">https://arxiv.org/pdf/2402.04178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04178]] SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection  with Multimodal Large Language Models(https://arxiv.org/abs/2402.04178)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, interpretability, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have demonstrated remarkable problem-solving capabilities in various vision fields (e.g., generic object recognition and grounding) based on strong visual semantic representation and language reasoning ability. However, whether MLLMs are sensitive to subtle visual spoof/forged clues and how they perform in the domain of face attack detection (e.g., face spoofing and forgery detection) is still unexplored. In this paper, we introduce a new benchmark, namely SHIELD, to evaluate the ability of MLLMs on face spoofing and forgery detection. Specifically, we design true/false and multiple-choice questions to evaluate multimodal face data in these two face security tasks. For the face anti-spoofing task, we evaluate three different modalities (i.e., RGB, infrared, depth) under four types of presentation attacks (i.e., print attack, replay attack, rigid mask, paper mask). For the face forgery detection task, we evaluate GAN-based and diffusion-based data with both visual and acoustic modalities. Each question is subjected to both zero-shot and few-shot tests under standard and chain of thought (COT) settings. The results indicate that MLLMs hold substantial potential in the face security domain, offering advantages over traditional specific models in terms of interpretability, multimodal flexible reasoning, and joint face spoof and forgery detection. Additionally, we develop a novel Multi-Attribute Chain of Thought (MA-COT) paradigm for describing and judging various task-specific and task-irrelevant attributes of face images, which provides rich task-related knowledge for subtle spoof/forged clue mining. Extensive experiments in separate face anti-spoofing, separate face forgery detection, and joint detection tasks demonstrate the effectiveness of the proposed MA-COT. The project is available at https$:$//github.com/laiyingxin2/SHIELD</li>
</ul>

<h3>Title: Instance by Instance: An Iterative Framework for Multi-instance 3D  Registration</h3>
<ul>
<li><strong>Authors: </strong>Xinyue Cao, Xiyu Zhang, Yuxin Cheng, Zhaoshuai Qi, Yanning Zhang, Jiaqi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04195">https://arxiv.org/abs/2402.04195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04195">https://arxiv.org/pdf/2402.04195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04195]] Instance by Instance: An Iterative Framework for Multi-instance 3D  Registration(https://arxiv.org/abs/2402.04195)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-instance registration is a challenging problem in computer vision and robotics, where multiple instances of an object need to be registered in a standard coordinate system. In this work, we propose the first iterative framework called instance-by-instance (IBI) for multi-instance 3D registration (MI-3DReg). It successively registers all instances in a given scenario, starting from the easiest and progressing to more challenging ones. Throughout the iterative process, outliers are eliminated continuously, leading to an increasing inlier rate for the remaining and more challenging instances. Under the IBI framework, we further propose a sparse-to-dense-correspondence-based multi-instance registration method (IBI-S2DC) to achieve robust MI-3DReg. Experiments on the synthetic and real datasets have demonstrated the effectiveness of IBI and suggested the new state-of-the-art performance of IBI-S2DC, e.g., our MHF1 is 12.02%/12.35% higher than the existing state-of-the-art method ECC on the synthetic/real datasets.</li>
</ul>

<h3>Title: Variational Shapley Network: A Probabilistic Approach to Self-Explaining  Shapley values with Uncertainty Quantification</h3>
<ul>
<li><strong>Authors: </strong>Mert Ketenci, Iñigo Urteaga, Victor Alfonso Rodriguez, Noémie Elhadad, Adler Perotte</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04211">https://arxiv.org/abs/2402.04211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04211">https://arxiv.org/pdf/2402.04211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04211]] Variational Shapley Network: A Probabilistic Approach to Self-Explaining  Shapley values with Uncertainty Quantification(https://arxiv.org/abs/2402.04211)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Shapley values have emerged as a foundational tool in machine learning (ML) for elucidating model decision-making processes. Despite their widespread adoption and unique ability to satisfy essential explainability axioms, computational challenges persist in their estimation when ($i$) evaluating a model over all possible subset of input feature combinations, ($ii$) estimating model marginals, and ($iii$) addressing variability in explanations. We introduce a novel, self-explaining method that simplifies the computation of Shapley values significantly, requiring only a single forward pass. Recognizing the deterministic treatment of Shapley values as a limitation, we explore incorporating a probabilistic framework to capture the inherent uncertainty in explanations. Unlike alternatives, our technique does not rely directly on the observed data space to estimate marginals; instead, it uses adaptable baseline values derived from a latent, feature-specific embedding space, generated by a novel masked neural network architecture. Evaluations on simulated and real datasets underscore our technique's robust predictive and explanatory performance.</li>
</ul>

<h3>Title: LIPSTICK: Corruptibility-Aware and Explainable Graph Neural  Network-based Oracle-Less Attack on Logic Locking</h3>
<ul>
<li><strong>Authors: </strong>Yeganeh Aghamohammadi, Amin Rezaei</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04235">https://arxiv.org/abs/2402.04235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04235">https://arxiv.org/pdf/2402.04235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04235]] LIPSTICK: Corruptibility-Aware and Explainable Graph Neural  Network-based Oracle-Less Attack on Logic Locking(https://arxiv.org/abs/2402.04235)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In a zero-trust fabless paradigm, designers are increasingly concerned about hardware-based attacks on the semiconductor supply chain. Logic locking is a design-for-trust method that adds extra key-controlled gates in the circuits to prevent hardware intellectual property theft and overproduction. While attackers have traditionally relied on an oracle to attack logic-locked circuits, machine learning attacks have shown the ability to retrieve the secret key even without access to an oracle. In this paper, we first examine the limitations of state-of-the-art machine learning attacks and argue that the use of key hamming distance as the sole model-guiding structural metric is not always useful. Then, we develop, train, and test a corruptibility-aware graph neural network-based oracle-less attack on logic locking that takes into consideration both the structure and the behavior of the circuits. Our model is explainable in the sense that we analyze what the machine learning model has interpreted in the training process and how it can perform a successful attack. Chip designers may find this information beneficial in securing their designs while avoiding incremental fixes.</li>
</ul>

<h3>Title: CAST: Clustering Self-Attention using Surrogate Tokens for Efficient  Transformers</h3>
<ul>
<li><strong>Authors: </strong>Adjorn van Engelenhoven, Nicola Strisciuglio, Estefanía Talavera</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04239">https://arxiv.org/abs/2402.04239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04239">https://arxiv.org/pdf/2402.04239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04239]] CAST: Clustering Self-Attention using Surrogate Tokens for Efficient  Transformers(https://arxiv.org/abs/2402.04239)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The Transformer architecture has shown to be a powerful tool for a wide range of tasks. It is based on the self-attention mechanism, which is an inherently computationally expensive operation with quadratic computational complexity: memory usage and compute time increase quadratically with the length of the input sequences, thus limiting the application of Transformers. In this work, we propose a novel Clustering self-Attention mechanism using Surrogate Tokens (CAST), to optimize the attention computation and achieve efficient transformers. CAST utilizes learnable surrogate tokens to construct a cluster affinity matrix, used to cluster the input sequence and generate novel cluster summaries. The self-attention from within each cluster is then combined with the cluster summaries of other clusters, enabling information flow across the entire input sequence. CAST improves efficiency by reducing the complexity from $O(N^2)$ to $O(\alpha N)$ where N is the sequence length, and {\alpha} is constant according to the number of clusters and samples per cluster. We show that CAST performs better than or comparable to the baseline Transformers on long-range sequence modeling tasks, while also achieving higher results on time and memory efficiency than other efficient transformers.</li>
</ul>

<h3>Title: Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning  Tasks</h3>
<ul>
<li><strong>Authors: </strong>Jongho Park, Jaeseung Park, Zheyang Xiong, Nayoung Lee, Jaewoong Cho, Samet Oymak, Kangwook Lee, Dimitris Papailiopoulos</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04248">https://arxiv.org/abs/2402.04248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04248">https://arxiv.org/pdf/2402.04248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04248]] Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning  Tasks(https://arxiv.org/abs/2402.04248)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>State-space models (SSMs), such as Mamba Gu & Dao (2034), have been proposed as alternatives to Transformer networks in language modeling, by incorporating gating, convolutions, and input-dependent token selection to mitigate the quadratic cost of multi-head attention. Although SSMs exhibit competitive performance, their in-context learning (ICL) capabilities, a remarkable emergent property of modern language models that enables task execution without parameter optimization, remain underexplored compared to Transformers. In this study, we evaluate the ICL performance of SSMs, focusing on Mamba, against Transformer models across various tasks. Our results show that SSMs perform comparably to Transformers in standard regression ICL tasks, while outperforming them in tasks like sparse parity learning. However, SSMs fall short in tasks involving non-standard retrieval functionality. To address these limitations, we introduce a hybrid model, \variant, that combines Mamba with attention blocks, surpassing individual models in tasks where they struggle independently. Our findings suggest that hybrid architectures offer promising avenues for enhancing ICL in language models.</li>
</ul>

<h3>Title: HarmBench: A Standardized Evaluation Framework for Automated Red Teaming  and Robust Refusal</h3>
<ul>
<li><strong>Authors: </strong>Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo Li, David Forsyth, Dan Hendrycks</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04249">https://arxiv.org/abs/2402.04249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04249">https://arxiv.org/pdf/2402.04249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04249]] HarmBench: A Standardized Evaluation Framework for Automated Red Teaming  and Robust Refusal(https://arxiv.org/abs/2402.04249)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Automated red teaming holds substantial promise for uncovering and mitigating the risks associated with the malicious use of large language models (LLMs), yet the field lacks a standardized evaluation framework to rigorously assess new methods. To address this issue, we introduce HarmBench, a standardized evaluation framework for automated red teaming. We identify several desirable properties previously unaccounted for in red teaming evaluations and systematically design HarmBench to meet these criteria. Using HarmBench, we conduct a large-scale comparison of 18 red teaming methods and 33 target LLMs and defenses, yielding novel insights. We also introduce a highly efficient adversarial training method that greatly enhances LLM robustness across a wide range of attacks, demonstrating how HarmBench enables codevelopment of attacks and defenses. We open source HarmBench at https://github.com/centerforaisafety/HarmBench.</li>
</ul>

<h3>Title: AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls</h3>
<ul>
<li><strong>Authors: </strong>Yu Du, Fangyun Wei, Hongyang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.04253">https://arxiv.org/abs/2402.04253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.04253">https://arxiv.org/pdf/2402.04253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.04253]] AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls(https://arxiv.org/abs/2402.04253)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries. We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries. AnyTool primarily incorporates three elements: an API retriever with a hierarchical structure, a solver aimed at resolving user queries using a selected set of API candidates, and a self-reflection mechanism, which re-activates AnyTool if the initial solution proves impracticable. AnyTool is powered by the function calling feature of GPT-4, eliminating the need for training external modules. We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate. By revising the evaluation protocol to better reflect practical application scenarios, we introduce an additional benchmark, termed AnyToolBench. Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. For instance, AnyTool outperforms ToolLLM by +35.4% in terms of average pass rate on ToolBench. Code will be available at https://github.com/dyabel/AnyTool.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
