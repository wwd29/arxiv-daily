<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-02-11</h1>
<h3>Title: Accelerating LLM Inference with Lossless Speculative Decoding Algorithms for Heterogeneous Vocabularies</h3>
<ul>
<li><strong>Authors: </strong>Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Oren Pereg, Gaurav Jain, Roy Schwartz, Moshe Wasserblat, David Harel</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05202">https://arxiv.org/abs/2502.05202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05202">https://arxiv.org/pdf/2502.05202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05202]] Accelerating LLM Inference with Lossless Speculative Decoding Algorithms for Heterogeneous Vocabularies(https://arxiv.org/abs/2502.05202)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Accelerating the inference of large language models (LLMs) is a critical challenge in generative AI. Speculative decoding (SD) methods offer substantial efficiency gains by generating multiple tokens using a single target forward pass. However, existing SD approaches require the drafter and target models to share the same vocabulary, thus limiting the pool of possible drafters, often necessitating the training of a drafter from scratch. We present three new SD methods that remove this shared-vocabulary constraint. All three methods preserve the target distribution (i.e., they are lossless) and work with off-the-shelf models without requiring additional training or modifications. Empirically, on summarization, programming, and long-context tasks, our algorithms achieve significant speedups over standard autoregressive decoding. By enabling any off-the-shelf model to serve as drafter and requiring no retraining, this work substantially broadens the applicability of the SD framework in practice.</li>
</ul>

<h3>Title: Adversarial Machine Learning: Attacking and Safeguarding Image Datasets</h3>
<ul>
<li><strong>Authors: </strong>Koushik Chowdhury</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05203">https://arxiv.org/abs/2502.05203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05203">https://arxiv.org/pdf/2502.05203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05203]] Adversarial Machine Learning: Attacking and Safeguarding Image Datasets(https://arxiv.org/abs/2502.05203)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>This paper examines the vulnerabilities of convolutional neural networks (CNNs) to adversarial attacks and explores a method for their safeguarding. In this study, CNNs were implemented on four of the most common image datasets, namely CIFAR-10, ImageNet, MNIST, and Fashion-MNIST, and achieved high baseline accuracy. To assess the strength of these models, the Fast Gradient Sign Method was used, which is a type of exploit on the model that is used to bring down the models accuracies by adding a very minimal perturbation to the input image. To counter the FGSM attack, a safeguarding approach went through, which includes retraining the models on clear and pollutant or adversarial images to increase their resistance ability. The next step involves applying FGSM again, but this time to the adversarially trained models, to see how much the accuracy of the models has gone down and evaluate the effectiveness of the defense. It appears that while most level of robustness is achieved against the models after adversarial training, there are still a few losses in the performance of these models against adversarial perturbations. This work emphasizes the need to create better defenses for models deployed in real-world scenarios against adversaries.</li>
</ul>

<h3>Title: A global analysis of data breaches from 2004 to 2024</h3>
<ul>
<li><strong>Authors: </strong>Shanitamol Sojan Gracy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05205">https://arxiv.org/abs/2502.05205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05205">https://arxiv.org/pdf/2502.05205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05205]] A global analysis of data breaches from 2004 to 2024(https://arxiv.org/abs/2502.05205)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>This research provides a comprehensive analysis of data breach trends across industries, regions, attack methods and data sensitivity from 2004 to 2024 using Microsoft Power BI. The research seeks to benefit from data visualisation techniques to help policymakers and organisational leaders make informed decisions based on data insights. Understanding the correlation between different data breach categories will enable them to prioritise security based on severity and protect their data. In this regard, this research aims to provide insights into dominant, emerging and declining data breach trends and further explore their implications. Finally, the study concludes by contributing to recommendation strategies and future directions for further research.</li>
</ul>

<h3>Title: Safety at Scale: A Comprehensive Survey of Large Model Safety</h3>
<ul>
<li><strong>Authors: </strong>Xingjun Ma, Yifeng Gao, Yixu Wang, Ruofan Wang, Xin Wang, Ye Sun, Yifan Ding, Hengyuan Xu, Yunhao Chen, Yunhan Zhao, Hanxun Huang, Yige Li, Jiaming Zhang, Xiang Zheng, Yang Bai, Henghui Ding, Zuxuan Wu, Xipeng Qiu, Jingfeng Zhang, Yiming Li, Jun Sun, Cong Wang, Jindong Gu, Baoyuan Wu, Siheng Chen, Tianwei Zhang, Yang Liu, Mingming Gong, Tongliang Liu, Shirui Pan, Cihang Xie, Tianyu Pang, Yinpeng Dong, Ruoxi Jia, Yang Zhang, Shiqing Ma, Xiangyu Zhang, Neil Gong, Chaowei Xiao, Sarah Erfani, Bo Li, Masashi Sugiyama, Dacheng Tao, James Bailey, Yu-Gang Jiang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05206">https://arxiv.org/abs/2502.05206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05206">https://arxiv.org/pdf/2502.05206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05206]] Safety at Scale: A Comprehensive Survey of Large Model Safety(https://arxiv.org/abs/2502.05206)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, extraction, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large models, driven by their exceptional abilities in learning and generalization through large-scale pre-training, has reshaped the landscape of Artificial Intelligence (AI). These models are now foundational to a wide range of applications, including conversational AI, recommendation systems, autonomous driving, content generation, medical diagnostics, and scientific discovery. However, their widespread deployment also exposes them to significant safety risks, raising concerns about robustness, reliability, and ethical implications. This survey provides a systematic review of current safety research on large models, covering Vision Foundation Models (VFMs), Large Language Models (LLMs), Vision-Language Pre-training (VLP) models, Vision-Language Models (VLMs), Diffusion Models (DMs), and large-model-based Agents. Our contributions are summarized as follows: (1) We present a comprehensive taxonomy of safety threats to these models, including adversarial attacks, data poisoning, backdoor attacks, jailbreak and prompt injection attacks, energy-latency attacks, data and model extraction attacks, and emerging agent-specific threats. (2) We review defense strategies proposed for each type of attacks if available and summarize the commonly used datasets and benchmarks for safety research. (3) Building on this, we identify and discuss the open challenges in large model safety, emphasizing the need for comprehensive safety evaluations, scalable and effective defense mechanisms, and sustainable data practices. More importantly, we highlight the necessity of collective efforts from the research community and international collaboration. Our work can serve as a useful reference for researchers and practitioners, fostering the ongoing development of comprehensive defense systems and platforms to safeguard AI models.</li>
</ul>

<h3>Title: Mitigation of Camouflaged Adversarial Attacks in Autonomous Vehicles--A Case Study Using CARLA Simulator</h3>
<ul>
<li><strong>Authors: </strong>Yago Romano Martinez, Brady Carter, Abhijeet Solanki, Wesam Al Amiri, Syed Rafay Hasan, Terry N. Guo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05208">https://arxiv.org/abs/2502.05208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05208">https://arxiv.org/pdf/2502.05208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05208]] Mitigation of Camouflaged Adversarial Attacks in Autonomous Vehicles--A Case Study Using CARLA Simulator(https://arxiv.org/abs/2502.05208)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Autonomous vehicles (AVs) rely heavily on cameras and artificial intelligence (AI) to make safe and accurate driving decisions. However, since AI is the core enabling technology, this raises serious cyber threats that hinder the large-scale adoption of AVs. Therefore, it becomes crucial to analyze the resilience of AV security systems against sophisticated attacks that manipulate camera inputs, deceiving AI models. In this paper, we develop camera-camouflaged adversarial attacks targeting traffic sign recognition (TSR) in AVs. Specifically, if the attack is initiated by modifying the texture of a stop sign to fool the AV's object detection system, thereby affecting the AV actuators. The attack's effectiveness is tested using the CARLA AV simulator and the results show that such an attack can delay the auto-braking response to the stop sign, resulting in potential safety issues. We conduct extensive experiments under various conditions, confirming that our new attack is effective and robust. Additionally, we address the attack by presenting mitigation strategies. The proposed attack and defense methods are applicable to other end-to-end trained autonomous cyber-physical systems.</li>
</ul>

<h3>Title: Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Zora Che, Stephen Casper, Robert Kirk, Anirudh Satheesh, Stewart Slocum, Lev E McKinney, Rohit Gandikota, Aidan Ewart, Domenic Rosati, Zichu Wu, Zikui Cai, Bilal Chughtai, Yarin Gal, Furong Huang, Dylan Hadfield-Menell</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05209">https://arxiv.org/abs/2502.05209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05209">https://arxiv.org/pdf/2502.05209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05209]] Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities(https://arxiv.org/abs/2502.05209)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Evaluations of large language model (LLM) risks and capabilities are increasingly being incorporated into AI risk management and governance frameworks. Currently, most risk evaluations are conducted by designing inputs that elicit harmful behaviors from the system. However, a fundamental limitation of this approach is that the harmfulness of the behaviors identified during any particular evaluation can only lower bound the model's worst-possible-case behavior. As a complementary method for eliciting harmful behaviors, we propose evaluating LLMs with model tampering attacks which allow for modifications to latent activations or weights. We pit state-of-the-art techniques for removing harmful LLM capabilities against a suite of 5 input-space and 6 model tampering attacks. In addition to benchmarking these methods against each other, we show that (1) model resilience to capability elicitation attacks lies on a low-dimensional robustness subspace; (2) the attack success rate of model tampering attacks can empirically predict and offer conservative estimates for the success of held-out input-space attacks; and (3) state-of-the-art unlearning methods can easily be undone within 16 steps of fine-tuning. Together these results highlight the difficulty of removing harmful LLM capabilities and show that model tampering attacks enable substantially more rigorous evaluations than input-space attacks alone. We release models at this https URL</li>
</ul>

<h3>Title: Decoding FL Defenses: Systemization, Pitfalls, and Remedies</h3>
<ul>
<li><strong>Authors: </strong>Momin Ahmad Khan, Virat Shejwalkar, Yasra Chandio, Amir Houmansadr, Fatima Muhammad Anwar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05211">https://arxiv.org/abs/2502.05211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05211">https://arxiv.org/pdf/2502.05211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05211]] Decoding FL Defenses: Systemization, Pitfalls, and Remedies(https://arxiv.org/abs/2502.05211)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>While the community has designed various defenses to counter the threat of poisoning attacks in Federated Learning (FL), there are no guidelines for evaluating these defenses. These defenses are prone to subtle pitfalls in their experimental setups that lead to a false sense of security, rendering them unsuitable for practical deployment. In this paper, we systematically understand, identify, and provide a better approach to address these challenges. First, we design a comprehensive systemization of FL defenses along three dimensions: i) how client updates are processed, ii) what the server knows, and iii) at what stage the defense is applied. Next, we thoroughly survey 50 top-tier defense papers and identify the commonly used components in their evaluation setups. Based on this survey, we uncover six distinct pitfalls and study their prevalence. For example, we discover that around 30% of these works solely use the intrinsically robust MNIST dataset, and 40% employ simplistic attacks, which may inadvertently portray their defense as robust. Using three representative defenses as case studies, we perform a critical reevaluation to study the impact of the identified pitfalls and show how they lead to incorrect conclusions about robustness. We provide actionable recommendations to help researchers overcome each pitfall.</li>
</ul>

<h3>Title: DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qihao Lin, Chen Tang, Lan zhang, Junyang zhang, Xiangyang Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05213">https://arxiv.org/abs/2502.05213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05213">https://arxiv.org/pdf/2502.05213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05213]] DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models(https://arxiv.org/abs/2502.05213)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, extraction, watermark, large language model</a></li>
<li><strong>Abstract: </strong>Well-trained large language models (LLMs) present significant risks, including potential malicious use and copyright infringement. Current studies aim to trace the distribution of LLM-generated texts by implicitly embedding watermarks. Among these, the single-bit watermarking method can only determine whether a given text was generated by an LLM. In contrast, the multi-bit watermarking method embeds richer information into the generated text, which can identify which LLM generated and distributed a given text to which user. However, existing efforts embed the multi-bit watermark directly into the generated text without accounting for its watermarking capacity. This approach can result in embedding failures when the text's watermarking capacity is insufficient. In this paper, we derive the watermark embedding distribution based on the logits of LLMs and propose a formal inequality to segment the text optimally for watermark embedding. Building on this foundation, we propose DERMARK, a dynamic, efficient, and robust multi-bit watermarking method. DERMARK divides the text into segments of varying lengths for each bit embedding, adaptively matching the text's capacity. It achieves this with negligible overhead and robust performance against text editing by minimizing watermark extraction loss. Comprehensive experiments demonstrate that, compared to the SOTA method, our method reduces the number of tokens required for embedding each bit by 20\%, reduces watermark embedding time by 50\%, and is robust to text editing and watermark erasure attacks.</li>
</ul>

<h3>Title: Watermarking across Modalities for Content Tracing and Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Pierre Fernandez</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05215">https://arxiv.org/abs/2502.05215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05215">https://arxiv.org/pdf/2502.05215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05215]] Watermarking across Modalities for Content Tracing and Generative AI(https://arxiv.org/abs/2502.05215)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark, transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Watermarking embeds information into digital content like images, audio, or text, imperceptible to humans but robustly detectable by specific algorithms. This technology has important applications in many challenges of the industry such as content moderation, tracing AI-generated content, and monitoring the usage of AI models. The contributions of this thesis include the development of new watermarking techniques for images, audio, and text. We first introduce methods for active moderation of images on social platforms. We then develop specific techniques for AI-generated content. We specifically demonstrate methods to adapt latent generative models to embed watermarks in all generated content, identify watermarked sections in speech, and improve watermarking in large language models with tests that ensure low false positive rates. Furthermore, we explore the use of digital watermarking to detect model misuse, including the detection of watermarks in language models fine-tuned on watermarked text, and introduce training-free watermarks for the weights of large transformers. Through these contributions, the thesis provides effective solutions for the challenges posed by the increasing use of generative AI models and the need for model monitoring and content moderation. It finally examines the challenges and limitations of watermarking techniques and discuss potential future directions for research in this area.</li>
</ul>

<h3>Title: Aero-LLM: A Distributed Framework for Secure UAV Communication and Intelligent Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Balakrishnan Dharmalingam, Rajdeep Mukherjee, Brett Piggott, Guohuan Feng, Anyi Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05220">https://arxiv.org/abs/2502.05220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05220">https://arxiv.org/pdf/2502.05220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05220]] Aero-LLM: A Distributed Framework for Secure UAV Communication and Intelligent Decision-Making(https://arxiv.org/abs/2502.05220)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Increased utilization of unmanned aerial vehicles (UAVs) in critical operations necessitates secure and reliable communication with Ground Control Stations (GCS). This paper introduces Aero-LLM, a framework integrating multiple Large Language Models (LLMs) to enhance UAV mission security and operational efficiency. Unlike conventional singular LLMs, Aero-LLM leverages multiple specialized LLMs for various tasks, such as inferencing, anomaly detection, and forecasting, deployed across onboard systems, edge, and cloud servers. This dynamic, distributed architecture reduces performance bottleneck and increases security capabilities. Aero-LLM's evaluation demonstrates outstanding task-specific metrics and robust defense against cyber threats, significantly enhancing UAV decision-making and operational capabilities and security resilience against cyber attacks, setting a new standard for secure, intelligent UAV operations.</li>
</ul>

<h3>Title: KDA: A Knowledge-Distilled Attacker for Generating Diverse Prompts to Jailbreak LLMs</h3>
<ul>
<li><strong>Authors: </strong>Buyun Liang, Kwan Ho Ryan Chan, Darshan Thaker, Jinqi Luo, Ren√© Vidal</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05223">https://arxiv.org/abs/2502.05223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05223">https://arxiv.org/pdf/2502.05223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05223]] KDA: A Knowledge-Distilled Attacker for Generating Diverse Prompts to Jailbreak LLMs(https://arxiv.org/abs/2502.05223)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Jailbreak attacks exploit specific prompts to bypass LLM safeguards, causing the LLM to generate harmful, inappropriate, and misaligned content. Current jailbreaking methods rely heavily on carefully designed system prompts and numerous queries to achieve a single successful attack, which is costly and impractical for large-scale red-teaming. To address this challenge, we propose to distill the knowledge of an ensemble of SOTA attackers into a single open-source model, called Knowledge-Distilled Attacker (KDA), which is finetuned to automatically generate coherent and diverse attack prompts without the need for meticulous system prompt engineering. Compared to existing attackers, KDA achieves higher attack success rates and greater cost-time efficiency when targeting multiple SOTA open-source and commercial black-box LLMs. Furthermore, we conducted a quantitative diversity analysis of prompts generated by baseline methods and KDA, identifying diverse and ensemble attacks as key factors behind KDA's effectiveness and efficiency.</li>
</ul>

<h3>Title: A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations</h3>
<ul>
<li><strong>Authors: </strong>Yihe Zhou, Tao Ni, Wei-Bin Lee, Qingchuan Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05224">https://arxiv.org/abs/2502.05224</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05224">https://arxiv.org/pdf/2502.05224</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05224]] A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations(https://arxiv.org/abs/2502.05224)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved significantly advanced capabilities in understanding and generating human language text, which have gained increasing popularity over recent years. Apart from their state-of-the-art natural language processing (NLP) performance, considering their widespread usage in many industries, including medicine, finance, education, etc., security concerns over their usage grow simultaneously. In recent years, the evolution of backdoor attacks has progressed with the advancement of defense mechanisms against them and more well-developed features in the LLMs. In this paper, we adapt the general taxonomy for classifying machine learning attacks on one of the subdivisions - training-time white-box backdoor attacks. Besides systematically classifying attack methods, we also consider the corresponding defense methods against backdoor attacks. By providing an extensive summary of existing works, we hope this survey can serve as a guideline for inspiring future research that further extends the attack scenarios and creates a stronger defense against them for more robust LLMs.</li>
</ul>

<h3>Title: BitAbuse: A Dataset of Visually Perturbed Texts for Defending Phishing Attacks</h3>
<ul>
<li><strong>Authors: </strong>Hanyong Lee, Chaelyn Lee, Yongjae Lee, Jaesung Lee</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05225">https://arxiv.org/abs/2502.05225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05225">https://arxiv.org/pdf/2502.05225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05225]] BitAbuse: A Dataset of Visually Perturbed Texts for Defending Phishing Attacks(https://arxiv.org/abs/2502.05225)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Phishing often targets victims through visually perturbed texts to bypass security systems. The noise contained in these texts functions as an adversarial attack, designed to deceive language models and hinder their ability to accurately interpret the content. However, since it is difficult to obtain sufficient phishing cases, previous studies have used synthetic datasets that do not contain real-world cases. In this study, we propose the BitAbuse dataset, which includes real-world phishing cases, to address the limitations of previous research. Our dataset comprises a total of 325,580 visually perturbed texts. The dataset inputs are drawn from the raw corpus, consisting of visually perturbed sentences and sentences generated through an artificial perturbation process. Each input sentence is labeled with its corresponding ground truth, representing the restored, non-perturbed version. Language models trained on our proposed dataset demonstrated significantly better performance compared to previous methods, achieving an accuracy of approximately 96%. Our analysis revealed a significant gap between real-world and synthetic examples, underscoring the value of our dataset for building reliable pre-trained models for restoration tasks. We release the BitAbuse dataset, which includes real-world phishing cases annotated with visual perturbations, to support future research in adversarial attack defense.</li>
</ul>

<h3>Title: L2GNet: Optimal Local-to-Global Representation of Anatomical Structures for Generalized Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Vandan Gorade, Sparsh Mittal, Neethi Dasu, Rekha Singhal, KC Santosh, Debesh Jha</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05229">https://arxiv.org/abs/2502.05229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05229">https://arxiv.org/pdf/2502.05229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05229]] L2GNet: Optimal Local-to-Global Representation of Anatomical Structures for Generalized Medical Image Segmentation(https://arxiv.org/abs/2502.05229)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Continuous Latent Space (CLS) and Discrete Latent Space (DLS) models, like AttnUNet and VQUNet, have excelled in medical image segmentation. In contrast, Synergistic Continuous and Discrete Latent Space (CDLS) models show promise in handling fine and coarse-grained information. However, they struggle with modeling long-range dependencies. CLS or CDLS-based models, such as TransUNet or SynergyNet are adept at capturing long-range dependencies. Since they rely heavily on feature pooling or aggregation using self-attention, they may capture dependencies among redundant regions. This hinders comprehension of anatomical structure content, poses challenges in modeling intra-class and inter-class dependencies, increases false negatives and compromises generalization. Addressing these issues, we propose L2GNet, which learns global dependencies by relating discrete codes obtained from DLS using optimal transport and aligning codes on a trainable reference. L2GNet achieves discriminative on-the-fly representation learning without an additional weight matrix in self-attention models, making it computationally efficient for medical applications. Extensive experiments on multi-organ segmentation and cardiac datasets demonstrate L2GNet's superiority over state-of-the-art methods, including the CDLS method SynergyNet, offering an novel approach to enhance deep learning models' performance in medical image analysis.</li>
</ul>

<h3>Title: Efficient Knowledge Feeding to Language Models: A Novel Integrated Encoder-Decoder Architecture</h3>
<ul>
<li><strong>Authors: </strong>S Santosh Kumar, Rishi Gottimukkala, Supriya Devidutta, Karthikeyan S</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05233">https://arxiv.org/abs/2502.05233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05233">https://arxiv.org/pdf/2502.05233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05233]] Efficient Knowledge Feeding to Language Models: A Novel Integrated Encoder-Decoder Architecture(https://arxiv.org/abs/2502.05233)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel approach to efficiently feeding knowledge to language models (LLMs) during prediction by integrating retrieval and generation processes within a unified framework. While the Retrieval-Augmented Generation (RAG) model addresses gaps in LLMs' training data and knowledge limits, it is hindered by token limit restrictions and dependency on the retrieval system's accuracy. Our proposed architecture incorporates in-context vectors (ICV) to overcome these challenges. ICV recasts in-context learning by using latent embeddings of LLMs to create a vector that captures essential task information. This vector is then used to shift the latent states of the LLM, enhancing the generation process without adding demonstration examples to the prompt. ICV directly integrates information into the model, enabling it to process this information more effectively. Our extensive experimental evaluation demonstrates that ICV outperforms standard in-context learning and fine-tuning across question-answering, information retrieval, and other tasks. This approach mitigates the limitations of current RAG models and offers a more robust solution for handling extensive and diverse datasets. Despite leveraging a fraction of the parameters, our ICV-enhanced model achieves competitive performance against models like LLaMA-3, Gemma, and Phi-3, significantly reducing computational costs and memory requirements. ICV reduces prompt length, is easy to control, surpasses token limitations, and is computationally efficient compared to fine-tuning.</li>
</ul>

<h3>Title: Optimizing Temperature for Language Models with Multi-Sample Inference</h3>
<ul>
<li><strong>Authors: </strong>Weihua Du, Yiming Yang, Sean Welleck</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05234">https://arxiv.org/abs/2502.05234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05234">https://arxiv.org/pdf/2502.05234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05234]] Optimizing Temperature for Language Models with Multi-Sample Inference(https://arxiv.org/abs/2502.05234)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Multi-sample aggregation strategies, such as majority voting and best-of-N sampling, are widely used in contemporary large language models (LLMs) to enhance predictive accuracy across various tasks. A key challenge in this process is temperature selection, which significantly impacts model performance. Existing approaches either rely on a fixed default temperature or require labeled validation data for tuning, which are often scarce and difficult to obtain. This paper addresses the challenge of automatically identifying the (near)-optimal temperature for different LLMs using multi-sample aggregation strategies, without relying on task-specific validation data. We provide a comprehensive analysis of temperature's role in performance optimization, considering variations in model architectures, datasets, task types, model sizes, and predictive accuracy. Furthermore, we propose a novel entropy-based metric for automated temperature optimization, which consistently outperforms fixed-temperature baselines. Additionally, we incorporate a stochastic process model to enhance interpretability, offering deeper insights into the relationship between temperature and model performance.</li>
</ul>

<h3>Title: Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics</h3>
<ul>
<li><strong>Authors: </strong>Hussam Ghanem (ICB, UB), Christophe Cruz (ICB, UB)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05239">https://arxiv.org/abs/2502.05239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05239">https://arxiv.org/pdf/2502.05239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05239]] Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics(https://arxiv.org/abs/2502.05239)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models have demonstrated significant potential in the automated construction of knowledge graphs from unstructured text. This paper builds upon our previous work [16], which evaluated various models using metrics like precision, recall, F1 score, triple matching, and graph matching, and introduces a refined approach to address the critical issues of hallucination and omission. We propose an enhanced evaluation framework incorporating BERTScore for graph similarity, setting a practical threshold of 95% for graph matching. Our experiments focus on the Mistral model, comparing its original and fine-tuned versions in zero-shot and few-shot settings. We further extend our experiments using examples from the KELM-sub training dataset, illustrating that the fine-tuned model significantly improves knowledge graph construction accuracy while reducing the exact hallucination and omission. However, our findings also reveal that the fine-tuned models perform worse in generalization tasks on the KELM-sub dataset. This study underscores the importance of comprehensive evaluation metrics in advancing the state-of-the-art in knowledge graph construction from textual data.</li>
</ul>

<h3>Title: Survey on AI-Generated Media Detection: From Non-MLLM to MLLM</h3>
<ul>
<li><strong>Authors: </strong>Yueying Zou, Peipei Li, Zekun Li, Huaibo Huang, Xing Cui, Xuannan Liu, Chenghanyu Zhang, Ran He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05240">https://arxiv.org/abs/2502.05240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05240">https://arxiv.org/pdf/2502.05240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05240]] Survey on AI-Generated Media Detection: From Non-MLLM to MLLM(https://arxiv.org/abs/2502.05240)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, explainability, generative, large language model</a></li>
<li><strong>Abstract: </strong>The proliferation of AI-generated media poses significant challenges to information authenticity and social trust, making reliable detection methods highly demanded. Methods for detecting AI-generated media have evolved rapidly, paralleling the advancement of Multimodal Large Language Models (MLLMs). Current detection approaches can be categorized into two main groups: Non-MLLM-based and MLLM-based methods. The former employs high-precision, domain-specific detectors powered by deep learning techniques, while the latter utilizes general-purpose detectors based on MLLMs that integrate authenticity verification, explainability, and localization capabilities. Despite significant progress in this field, there remains a gap in literature regarding a comprehensive survey that examines the transition from domain-specific to general-purpose detection methods. This paper addresses this gap by providing a systematic review of both approaches, analyzing them from single-modal and multi-modal perspectives. We present a detailed comparative analysis of these categories, examining their methodological similarities and differences. Through this analysis, we explore potential hybrid approaches and identify key challenges in forgery detection, providing direction for future research. Additionally, as MLLMs become increasingly prevalent in detection tasks, ethical and security considerations have emerged as critical global concerns. We examine the regulatory landscape surrounding Generative AI (GenAI) across various jurisdictions, offering valuable insights for researchers and practitioners in this field.</li>
</ul>

<h3>Title: SEER: Self-Explainability Enhancement of Large Language Models' Representations</h3>
<ul>
<li><strong>Authors: </strong>Guanxu Chen, Dongrui Liu, Tao Luo, Jing Shao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05242">https://arxiv.org/abs/2502.05242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05242">https://arxiv.org/pdf/2502.05242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05242]] SEER: Self-Explainability Enhancement of Large Language Models' Representations(https://arxiv.org/abs/2502.05242)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Explaining the hidden representations of Large Language Models (LLMs) is a perspective to understand LLMs' underlying inference logic and improve their reliability in application scenarios. However, previous methods introduce external ''black-box'' modules to explain ''black-box'' LLMs, increasing the potential uncertainty and failing to provide faithful explanations. In this paper, we propose a self-explaining method SEER, enhancing LLMs' explainability by aggregating the same concept and disentangling the different concepts in the representation space. In this way, SEER provides faithful explanations carried by representations synchronously with the LLMs' output. Additionally, we showcase the applications of SEER on trustworthiness-related tasks (e.g., the safety risks classification and detoxification tasks), where self-explained LLMs achieve consistent improvement in explainability and performance. More crucially, we theoretically analyze the improvement of SEER on LLMs' generalization ability through optimal transport theory.</li>
</ul>

<h3>Title: Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires</h3>
<ul>
<li><strong>Authors: </strong>Pranav Bhandari, Usman Naseem, Amitava Datta, Nicolas Fay, Mehwish Nasim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05248">https://arxiv.org/abs/2502.05248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05248">https://arxiv.org/pdf/2502.05248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05248]] Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires(https://arxiv.org/abs/2502.05248)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Psychological assessment tools have long helped humans understand behavioural patterns. While Large Language Models (LLMs) can generate content comparable to that of humans, we explore whether they exhibit personality traits. To this end, this work applies psychological tools to LLMs in diverse scenarios to generate personality profiles. Using established trait-based questionnaires such as the Big Five Inventory and by addressing the possibility of training data contamination, we examine the dimensional variability and dominance of LLMs across five core personality dimensions: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. Our findings reveal that LLMs exhibit unique dominant traits, varying characteristics, and distinct personality profiles even within the same family of models.</li>
</ul>

<h3>Title: GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?</h3>
<ul>
<li><strong>Authors: </strong>Yang Zhou, Hongyi Liu, Zhuoming Chen, Yuandong Tian, Beidi Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05252">https://arxiv.org/abs/2502.05252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05252">https://arxiv.org/pdf/2502.05252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05252]] GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?(https://arxiv.org/abs/2502.05252)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-context large language models (LLMs) have recently shown strong performance in information retrieval and long-document QA. However, to tackle the most challenging intellectual problems, LLMs must reason effectively in long and complex contexts (e.g., frontier mathematical research). Studying how LLMs handle increasing reasoning complexity and context length is essential, yet existing benchmarks lack a solid basis for quantitative evaluation. Inspired by the abstraction of GSM-8K problems as computational graphs, and the ability to introduce noise by adding unnecessary nodes and edges, we develop a grade school math problem generator capable of producing arithmetic problems with infinite difficulty and context length under fine-grained control. Using our newly synthesized GSM-Infinite benchmark, we comprehensively evaluate existing LLMs. We find a consistent sigmoid decline in reasoning performance as complexity increases, along with a systematic inference scaling trend: exponentially increasing inference computation yields only linear performance gains. These findings underscore the fundamental limitations of current long-context LLMs and the key challenges in scaling reasoning capabilities. Our GSM-Infinite benchmark provides a scalable and controllable testbed for systematically studying and advancing LLM reasoning in long and complex contexts.</li>
</ul>

<h3>Title: LLMs Can Teach Themselves to Better Predict the Future</h3>
<ul>
<li><strong>Authors: </strong>Benjamin Turtel, Danny Franklin, Philipp Schoenegger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05253">https://arxiv.org/abs/2502.05253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05253">https://arxiv.org/pdf/2502.05253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05253]] LLMs Can Teach Themselves to Better Predict the Future(https://arxiv.org/abs/2502.05253)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present an outcome-driven fine-tuning framework that enhances the forecasting capabilities of large language models (LLMs) without relying on human-curated reasoning samples. Our method leverages model self-play to generate pairs of diverse reasoning trajectories and probabilistic forecasts for a set of diverse questions that resolve after the models' knowledge cutoff date. We then rank pairs of these reasoning traces by their distance to the actual outcomes before fine-tuning the model via Direct Preference Optimization (DPO). On a separate test set, our approach increases prediction accuracy of Phi-4 14B and DeepSeek-R1 14B by between 7--10\% over a base model and a DPO fine-tuned control model with randomized labels, bringing them on par with forecasting capabilities of much larger frontier models like GPT-4o.</li>
</ul>

<h3>Title: Principles and Components of Federated Learning Architectures</h3>
<ul>
<li><strong>Authors: </strong>Sarwar Saif, MD Abdullah Al Nasim, Parag Biswas, Abdur Rashid, MD Mahim Anjum Haque, Md. Zihad Bin Jahangir</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05273">https://arxiv.org/abs/2502.05273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05273">https://arxiv.org/pdf/2502.05273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05273]] Principles and Components of Federated Learning Architectures(https://arxiv.org/abs/2502.05273)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning, also known as FL, is a machine learning framework in which a significant amount of clients (such as mobile devices or whole enterprises) collaborate to collaboratively train a model while keeping decentralized training data, all overseen by a central server (such as a service provider). There are advantages in terms of privacy, security, regulations, and economy with this decentralized approach to model training. FL is not impervious to the flaws that plague conventional machine learning models, despite its seeming promise. This study offers a thorough analysis of the fundamental ideas and elements of federated learning architectures, emphasizing five important areas: communication architectures, machine learning models, data partitioning, privacy methods, and system heterogeneity. We additionally address the difficulties and potential paths for future study in the area. Furthermore, based on a comprehensive review of the literature, we present a collection of architectural patterns for federated learning systems. This analysis will help to understand the basic of Federated learning, the primary components of FL, and also about several architectural details.</li>
</ul>

<h3>Title: Invizo: Arabic Handwritten Document Optical Character Recognition Solution</h3>
<ul>
<li><strong>Authors: </strong>Alhossien Waly, Bassant Tarek, Ali Feteha, Rewan Yehia, Gasser Amr, Walid Gomaa, Ahmed Fares</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05277">https://arxiv.org/abs/2502.05277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05277">https://arxiv.org/pdf/2502.05277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05277]] Invizo: Arabic Handwritten Document Optical Character Recognition Solution(https://arxiv.org/abs/2502.05277)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Converting images of Arabic text into plain text is a widely researched topic in academia and industry. However, recognition of Arabic handwritten and printed text presents difficult challenges due to the complex nature of variations of the Arabic script. This work proposes an end-to-end solution for recognizing Arabic handwritten, printed, and Arabic numbers and presents the data in a structured manner. We reached 81.66% precision, 78.82% Recall, and 79.07% F-measure on a Text Detection task that powers the proposed solution. The proposed recognition model incorporates state-of-the-art CNN-based feature extraction, and Transformer-based sequence modeling to accommodate variations in handwriting styles, stroke thicknesses, alignments, and noise conditions. The evaluation of the model suggests its strong performances on both printed and handwritten texts, yielding 0.59% CER and & 1.72% WER on printed text, and 7.91% CER and 31.41% WER on handwritten text. The overall proposed solution has proven to be relied on in real-life OCR tasks. Equipped with both detection and recognition models as well as other Feature Extraction and Matching helping algorithms. With the general purpose implementation, making the solution valid for any given document or receipt that is Arabic handwritten or printed. Thus, it is practical and useful for any given context.</li>
</ul>

<h3>Title: Fairness and Sparsity within Rashomon sets: Enumeration-Free Exploration and Characterization</h3>
<ul>
<li><strong>Authors: </strong>Lucas Langlade, Julien Ferry, Gabriel Laberge, Thibaut Vidal</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05286">https://arxiv.org/abs/2502.05286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05286">https://arxiv.org/pdf/2502.05286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05286]] Fairness and Sparsity within Rashomon sets: Enumeration-Free Exploration and Characterization(https://arxiv.org/abs/2502.05286)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>We introduce an enumeration-free method based on mathematical programming to precisely characterize various properties such as fairness or sparsity within the set of "good models", known as Rashomon set. This approach is generically applicable to any hypothesis class, provided that a mathematical formulation of the model learning task exists. It offers a structured framework to define the notion of business necessity and evaluate how fairness can be improved or degraded towards a specific protected group, while remaining within the Rashomon set and maintaining any desired sparsity level. We apply our approach to two hypothesis classes: scoring systems and decision diagrams, leveraging recent mathematical programming formulations for training such models. As seen in our experiments, the method comprehensively and certifiably quantifies trade-offs between predictive performance, sparsity, and fairness. We observe that a wide range of fairness values are attainable, ranging from highly favorable to significantly unfavorable for a protected group, while staying within less than 1% of the best possible training accuracy for the hypothesis class. Additionally, we observe that sparsity constraints limit these trade-offs and may disproportionately harm specific subgroups. As we evidenced, thoroughly characterizing the tensions between these key aspects is critical for an informed and accountable selection of models.</li>
</ul>

<h3>Title: Can LLMs Rank the Harmfulness of Smaller LLMs? We are Not There Yet</h3>
<ul>
<li><strong>Authors: </strong>Berk Atil, Vipul Gupta, Sarkar Snigdha Sarathi Das, Rebecca J. Passonneau</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05291">https://arxiv.org/abs/2502.05291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05291">https://arxiv.org/pdf/2502.05291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05291]] Can LLMs Rank the Harmfulness of Smaller LLMs? We are Not There Yet(https://arxiv.org/abs/2502.05291)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have become ubiquitous, thus it is important to understand their risks and limitations. Smaller LLMs can be deployed where compute resources are constrained, such as edge devices, but with different propensity to generate harmful output. Mitigation of LLM harm typically depends on annotating the harmfulness of LLM output, which is expensive to collect from humans. This work studies two questions: How do smaller LLMs rank regarding generation of harmful content? How well can larger LLMs annotate harmfulness? We prompt three small LLMs to elicit harmful content of various types, such as discriminatory language, offensive content, privacy invasion, or negative influence, and collect human rankings of their outputs. Then, we evaluate three state-of-the-art large LLMs on their ability to annotate the harmfulness of these responses. We find that the smaller models differ with respect to harmfulness. We also find that large LLMs show low to moderate agreement with humans. These findings underline the need for further work on harm mitigation in LLMs.</li>
</ul>

<h3>Title: Drone Detection and Tracking with YOLO and a Rule-based Method</h3>
<ul>
<li><strong>Authors: </strong>Purbaditya Bhattacharya, Patrick Nowak</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05292">https://arxiv.org/abs/2502.05292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05292">https://arxiv.org/pdf/2502.05292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05292]] Drone Detection and Tracking with YOLO and a Rule-based Method(https://arxiv.org/abs/2502.05292)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect</a></li>
<li><strong>Abstract: </strong>Drones or unmanned aerial vehicles are traditionally used for military missions, warfare, and espionage. However, the usage of drones has significantly increased due to multiple industrial applications involving security and inspection, transportation, research purposes, and recreational drone flying. Such an increased volume of drone activity in public spaces requires regulatory actions for purposes of privacy protection and safety. Hence, detection of illegal drone activities such as boundary encroachment becomes a necessity. Such detection tasks are usually automated and performed by deep learning models which are trained on annotated image datasets. This paper builds on a previous work and extends an already published open source dataset. A description and analysis of the entire dataset is provided. The dataset is used to train the YOLOv7 deep learning model and some of its minor variants and the results are provided. Since the detection models are based on a single image input, a simple cross-correlation based tracker is used to reduce detection drops and improve tracking performance in videos. Finally, the entire drone detection system is summarized.</li>
</ul>

<h3>Title: Training Set Reconstruction from Differentially Private Forests: How Effective is DP?</h3>
<ul>
<li><strong>Authors: </strong>Alice Gorg√©, Julien Ferry, S√©bastien Gambs, Thibaut Vidal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05307">https://arxiv.org/abs/2502.05307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05307">https://arxiv.org/pdf/2502.05307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05307]] Training Set Reconstruction from Differentially Private Forests: How Effective is DP?(https://arxiv.org/abs/2502.05307)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>Recent research has shown that machine learning models are vulnerable to privacy attacks targeting their training data. Differential privacy (DP) has become a widely adopted countermeasure, as it offers rigorous privacy protections. In this paper, we introduce a reconstruction attack targeting state-of-the-art $\varepsilon$-DP random forests. By leveraging a constraint programming model that incorporates knowledge of the forest's structure and DP mechanism characteristics, our approach formally reconstructs the most likely dataset that could have produced a given forest. Through extensive computational experiments, we examine the interplay between model utility, privacy guarantees, and reconstruction accuracy across various configurations. Our results reveal that random forests trained with meaningful DP guarantees can still leak substantial portions of their training data. Specifically, while DP reduces the success of reconstruction attacks, the only forests fully robust to our attack exhibit predictive performance no better than a constant classifier. Building on these insights, we provide practical recommendations for the construction of DP random forests that are more resilient to reconstruction attacks and maintain non-trivial predictive performance.</li>
</ul>

<h3>Title: AI/ML-Based Automatic Modulation Recognition: Recent Trends and Future Possibilities</h3>
<ul>
<li><strong>Authors: </strong>Elaheh Jafarigol, Behnoud Alaghband, Azadeh Gilanpour, Saeid Hosseinipoor, Mirhamed Mirmozafari</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05315">https://arxiv.org/abs/2502.05315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05315">https://arxiv.org/pdf/2502.05315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05315]] AI/ML-Based Automatic Modulation Recognition: Recent Trends and Future Possibilities(https://arxiv.org/abs/2502.05315)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We present a review of high-performance automatic modulation recognition (AMR) models proposed in the literature to classify various Radio Frequency (RF) modulation schemes. We replicated these models and compared their performance in terms of accuracy across a range of signal-to-noise ratios. To ensure a fair comparison, we used the same dataset (RadioML-2016A), the same hardware, and a consistent definition of test accuracy as the evaluation metric, thereby providing a benchmark for future AMR studies. The hyperparameters were selected based on the authors' suggestions in the associated references to achieve results as close as possible to the originals. The replicated models are publicly accessible for further analysis of AMR models. We also present the test accuracies of the selected models versus their number of parameters, indicating their complexities. Building on this comparative analysis, we identify strategies to enhance these models' performance. Finally, we present potential opportunities for improvement, whether through novel architectures, data processing techniques, or training strategies, to further advance the capabilities of AMR models.</li>
</ul>

<h3>Title: Towards Fine-grained Renal Vasculature Segmentation: Full-Scale Hierarchical Learning with FH-Seg</h3>
<ul>
<li><strong>Authors: </strong>Yitian Long, Zhongze Wu, Xiu Su, Lining Yu, Ruining Deng, Haichun Yang, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05320">https://arxiv.org/abs/2502.05320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05320">https://arxiv.org/pdf/2502.05320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05320]] Towards Fine-grained Renal Vasculature Segmentation: Full-Scale Hierarchical Learning with FH-Seg(https://arxiv.org/abs/2502.05320)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate fine-grained segmentation of the renal vasculature is critical for nephrological analysis, yet it faces challenges due to diverse and insufficiently annotated images. Existing methods struggle to accurately segment intricate regions of the renal vasculature, such as the inner and outer walls, arteries and lesions. In this paper, we introduce FH-Seg, a Full-scale Hierarchical Learning Framework designed for comprehensive segmentation of the renal vasculature. Specifically, FH-Seg employs full-scale skip connections that merge detailed anatomical information with contextual semantics across scales, effectively bridging the gap between structural and pathological contexts. Additionally, we implement a learnable hierarchical soft attention gates to adaptively reduce interference from non-core information, enhancing the focus on critical vascular features. To advance research on renal pathology segmentation, we also developed a Large Renal Vasculature (LRV) dataset, which contains 16,212 fine-grained annotated images of 5,600 renal arteries. Extensive experiments on the LRV dataset demonstrate FH-Seg's superior accuracies (71.23% Dice, 73.06% F1), outperforming Omni-Seg by 2.67 and 2.13 percentage points respectively. Code is available at: this https URL.</li>
</ul>

<h3>Title: Using Federated Machine Learning in Predictive Maintenance of Jet Engines</h3>
<ul>
<li><strong>Authors: </strong>Asaph Matheus Barbosa, Thao Vy Nhat Ngo, Elaheh Jafarigol, Theodore B. Trafalis, Emuobosa P. Ojoboh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05321">https://arxiv.org/abs/2502.05321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05321">https://arxiv.org/pdf/2502.05321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05321]] Using Federated Machine Learning in Predictive Maintenance of Jet Engines(https://arxiv.org/abs/2502.05321)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>The goal of this paper is to predict the Remaining Useful Life (RUL) of turbine jet engines using a federated machine learning framework. Federated Learning enables multiple edge devices/nodes or servers to collaboratively train a shared model without sharing sensitive data, thus preserving data privacy and security. By implementing a nonlinear model, the system aims to capture complex relationships and patterns in the engine data to enhance the accuracy of RUL predictions. This approach leverages decentralized computation, allowing models to be trained locally at each device before aggregating the learned weights at a central server. By predicting the RUL of jet engines accurately, maintenance schedules can be optimized, downtime reduced, and operational efficiency improved, ultimately leading to cost savings and enhanced performance in the aviation industry. Computational results are provided by using the C-MAPSS dataset which is publicly available on the NASA website and is a valuable resource for studying and analyzing engine degradation behaviors in various operational scenarios.</li>
</ul>

<h3>Title: From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks</h3>
<ul>
<li><strong>Authors: </strong>Awa Khouna, Julien Ferry, Thibaut Vidal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05325">https://arxiv.org/abs/2502.05325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05325">https://arxiv.org/pdf/2502.05325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05325]] From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks(https://arxiv.org/abs/2502.05325)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, extraction, explainability</a></li>
<li><strong>Abstract: </strong>The advent of Machine Learning as a Service (MLaaS) has heightened the trade-off between model explainability and security. In particular, explainability techniques, such as counterfactual explanations, inadvertently increase the risk of model extraction attacks, enabling unauthorized replication of proprietary models. In this paper, we formalize and characterize the risks and inherent complexity of model reconstruction, focusing on the "oracle'' queries required for faithfully inferring the underlying prediction function. We present the first formal analysis of model extraction attacks through the lens of competitive analysis, establishing a foundational framework to evaluate their efficiency. Focusing on models based on additive decision trees (e.g., decision trees, gradient boosting, and random forests), we introduce novel reconstruction algorithms that achieve provably perfect fidelity while demonstrating strong anytime performance. Our framework provides theoretical bounds on the query complexity for extracting tree-based model, offering new insights into the security vulnerabilities of their deployment.</li>
</ul>

<h3>Title: Fine-Tuned LLMs are "Time Capsules" for Tracking Societal Bias Through Books</h3>
<ul>
<li><strong>Authors: </strong>Sangmitra Madhusudan, Robert Morabito, Skye Reid, Nikta Gohari Sadr, Ali Emami</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05331">https://arxiv.org/abs/2502.05331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05331">https://arxiv.org/pdf/2502.05331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05331]] Fine-Tuned LLMs are "Time Capsules" for Tracking Societal Bias Through Books(https://arxiv.org/abs/2502.05331)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Books, while often rich in cultural insights, can also mirror societal biases of their eras - biases that Large Language Models (LLMs) may learn and perpetuate during training. We introduce a novel method to trace and quantify these biases using fine-tuned LLMs. We develop BookPAGE, a corpus comprising 593 fictional books across seven decades (1950-2019), to track bias evolution. By fine-tuning LLMs on books from each decade and using targeted prompts, we examine shifts in biases related to gender, sexual orientation, race, and religion. Our findings indicate that LLMs trained on decade-specific books manifest biases reflective of their times, with both gradual trends and notable shifts. For example, model responses showed a progressive increase in the portrayal of women in leadership roles (from 8% to 22%) from the 1950s to 2010s, with a significant uptick in the 1990s (from 4% to 12%), possibly aligning with third-wave feminism. Same-sex relationship references increased markedly from the 1980s to 2000s (from 0% to 10%), mirroring growing LGBTQ+ visibility. Concerningly, negative portrayals of Islam rose sharply in the 2000s (26% to 38%), likely reflecting post-9/11 sentiments. Importantly, we demonstrate that these biases stem mainly from the books' content and not the models' architecture or initial training. Our study offers a new perspective on societal bias trends by bridging AI, literary studies, and social science research.</li>
</ul>

<h3>Title: Removing Neural Signal Artifacts with Autoencoder-Targeted Adversarial Transformers (AT-AT)</h3>
<ul>
<li><strong>Authors: </strong>Benjamin J. Choi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05332">https://arxiv.org/abs/2502.05332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05332">https://arxiv.org/pdf/2502.05332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05332]] Removing Neural Signal Artifacts with Autoencoder-Targeted Adversarial Transformers (AT-AT)(https://arxiv.org/abs/2502.05332)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Electromyogenic (EMG) noise is a major contamination source in EEG data that can impede accurate analysis of brain-specific neural activity. Recent literature on EMG artifact removal has moved beyond traditional linear algorithms in favor of machine learning-based systems. However, existing deep learning-based filtration methods often have large compute footprints and prohibitively long training times. In this study, we present a new machine learning-based system for filtering EMG interference from EEG data using an autoencoder-targeted adversarial transformer (AT-AT). By leveraging the lightweight expressivity of an autoencoder to determine optimal time-series transformer application sites, our AT-AT architecture achieves a >90% model size reduction compared to published artifact removal models. The addition of adversarial training ensures that filtered signals adhere to the fundamental characteristics of EEG data. We trained AT-AT using published neural data from 67 subjects and found that the system was able to achieve comparable test performance to larger models; AT-AT posted a mean reconstructive correlation coefficient above 0.95 at an initial signal-to-noise ratio (SNR) of 2 dB and 0.70 at -7 dB SNR. Further research generalizing these results to broader sample sizes beyond these isolated test cases will be crucial; while outside the scope of this study, we also include results from a real-world deployment of AT-AT in the Appendix.</li>
</ul>

<h3>Title: TNIC: A Trusted NIC Architecture</h3>
<ul>
<li><strong>Authors: </strong>Dimitra Giantsidi, Julian Pritzi, Felix Gust, Antonios Katsarakis, Atsushi Koshiba, Pramod Bhatotia</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05338">https://arxiv.org/abs/2502.05338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05338">https://arxiv.org/pdf/2502.05338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05338]] TNIC: A Trusted NIC Architecture(https://arxiv.org/abs/2502.05338)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>We introduce TNIC, a trusted NIC architecture for building trustworthy distributed systems deployed in heterogeneous, untrusted (Byzantine) cloud environments. TNIC builds a minimal, formally verified, silicon root-of-trust at the network interface level. We strive for three primary design goals: (1) a host CPU-agnostic unified security architecture by providing trustworthy network-level isolation; (2) a minimalistic and verifiable TCB based on a silicon root-of-trust by providing two core properties of transferable authentication and non-equivocation; and (3) a hardware-accelerated trustworthy network stack leveraging SmartNICs. Based on the TNIC architecture and associated network stack, we present a generic set of programming APIs and a recipe for building high-performance, trustworthy, distributed systems for Byzantine settings. We formally verify the safety and security properties of our TNIC while demonstrating its use by building four trustworthy distributed systems. Our evaluation of TNIC shows up to 6x performance improvement compared to CPU-centric TEE systems.</li>
</ul>

<h3>Title: Neural Encrypted State Transduction for Ransomware Classification: A Novel Approach Using Cryptographic Flow Residuals</h3>
<ul>
<li><strong>Authors: </strong>Barnaby Fortescue, Edmund Hawksmoor, Alistair Wetherington, Frederick Marlowe, Kevin Pekepok</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05341">https://arxiv.org/abs/2502.05341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05341">https://arxiv.org/pdf/2502.05341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05341]] Neural Encrypted State Transduction for Ransomware Classification: A Novel Approach Using Cryptographic Flow Residuals(https://arxiv.org/abs/2502.05341)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>Encrypted behavioral patterns provide a unique avenue for classifying complex digital threats without reliance on explicit feature extraction, enabling detection frameworks to remain effective even when conventional static and behavioral methodologies fail. A novel approach based on Neural Encrypted State Transduction (NEST) is introduced to analyze cryptographic flow residuals and classify threats through their encrypted state transitions, mitigating evasion tactics employed through polymorphic and obfuscated attack strategies. The mathematical formulation of NEST leverages transduction principles to map state transitions dynamically, enabling high-confidence classification without requiring direct access to decrypted execution traces. Experimental evaluations demonstrate that the proposed framework achieves improved detection accuracy across multiple ransomware families while exhibiting resilience against adversarial perturbations and previously unseen attack variants. The model maintains competitive processing efficiency, offering a practical balance between classification performance and computational resource constraints, making it suitable for large-scale security deployments. Comparative assessments reveal that NEST consistently outperforms baseline classification models, particularly in detecting ransomware samples employing delayed encryption, entropy-based obfuscation, and memory-resident execution techniques. The capacity to generalize across diverse execution environments reinforces the applicability of encrypted transduction methodologies in adversarial classification tasks beyond conventional malware detection pipelines. The integration of residual learning mechanisms within the transduction layers further enhances classification robustness, minimizing both false positives and misclassification rates across varied operational contexts.</li>
</ul>

<h3>Title: Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Christopher Nightingale, Dominic Lavington, Jonathan Thistlethwaite, Sebastian Penhaligon, Thomas Belinski, David Boldo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05346">https://arxiv.org/abs/2502.05346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05346">https://arxiv.org/pdf/2502.05346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05346]] Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models(https://arxiv.org/abs/2502.05346)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Representing token embeddings as probability distributions over learned manifolds allows for more flexible contextual inference, reducing representational rigidity while enhancing semantic granularity. Comparative evaluations demonstrate that probabilistic embeddings improve neighborhood consistency and decrease redundancy, ensuring that token relationships remain more structurally coherent across fine-tuning iterations. The integration of probabilistic subspaces within attention mechanisms facilitates more adaptive contextual weighting, enabling models to capture latent dependencies that would otherwise be obscured in conventional embeddings. Experimental results highlight increased robustness against adversarial modifications, with probabilistic embeddings preserving contextual integrity even under perturbation-based evaluation scenarios. Performance assessments indicate that probabilistic representations achieve greater adaptability in domain-specific applications, mitigating the need for extensive retraining when shifting across linguistic domains. Computational trade-offs remain within operationally feasible limits, with marginal increases in inference latency balanced against the benefits of enhanced representation stability and contextual expressiveness. The capacity to encode structured uncertainty provides advantages in generative modeling tasks, particularly where maintaining coherence across extended sequences requires a representation framework capable of handling ambiguous or context-dependent linguistic constructs.</li>
</ul>

<h3>Title: Detecting APT Malware Command and Control over HTTP(S) Using Contextual Summaries</h3>
<ul>
<li><strong>Authors: </strong>Almuthanna Alageel, Sergio Maffeis, Imperial College London</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05367">https://arxiv.org/abs/2502.05367</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05367">https://arxiv.org/pdf/2502.05367</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05367]] Detecting APT Malware Command and Control over HTTP(S) Using Contextual Summaries(https://arxiv.org/abs/2502.05367)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) are among the most sophisticated threats facing critical organizations worldwide. APTs employ specific tactics, techniques, and procedures (TTPs) which make them difficult to detect in comparison to frequent and aggressive attacks. In fact, current network intrusion detection systems struggle to detect APTs communications, allowing such threats to persist unnoticed on victims' machines for months or even years. In this paper, we present EarlyCrow, an approach to detect APT malware command and control over HTTP(S) using contextual summaries. The design of EarlyCrow is informed by a novel threat model focused on TTPs present in traffic generated by tools recently used as part of APT campaigns. The threat model highlights the importance of the context around the malicious connections, and suggests traffic attributes which help APT detection. EarlyCrow defines a novel multipurpose network flow format called PairFlow, which is leveraged to build the contextual summary of a PCAP capture, representing key behavioral, statistical and protocol information relevant to APT TTPs. We evaluate the effectiveness of EarlyCrow on unseen APTs obtaining a headline macro average F1-score of 93.02% with FPR of $0.74%.</li>
</ul>

<h3>Title: fMoE: Fine-Grained Expert Offloading for Large Mixture-of-Experts Serving</h3>
<ul>
<li><strong>Authors: </strong>Hanfei Yu, Xingqi Cui, Hong Zhang, Hao Wang, Hao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05370">https://arxiv.org/abs/2502.05370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05370">https://arxiv.org/pdf/2502.05370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05370]] fMoE: Fine-Grained Expert Offloading for Large Mixture-of-Experts Serving(https://arxiv.org/abs/2502.05370)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have gained immense success in revolutionizing various applications, including content generation, search and recommendation, and AI-assisted operation. To reduce high training costs, Mixture-of-Experts (MoE) architecture has become a popular backbone for modern LLMs. However, despite the benefits, serving MoE-based LLMs experience severe memory inefficiency due to sparsely activated experts. Recent studies propose to offload inactive experts from GPU memory to CPU memory to improve the serving efficiency of MoE models. However, they either incur high inference latency or high model memory footprints due to coarse-grained designs. To tame the latency-memory trade-off in MoE serving, we present fMoE, a fine-grained expert offloading system for MoE serving that achieves low inference latency with memory efficiency. We design fMoE to extract fine-grained expert selection patterns from MoE models and semantic hints from input prompts to efficiently guide expert prefetching, caching, and offloading decisions. fMoE is prototyped on top of HuggingFace Transformers and deployed on a six-GPU testbed. Experiments with open-source MoE models and real-world workloads show that fMoE reduces inference latency by 47% and improves expert hit rate by 36% over state-of-the-art solutions.</li>
</ul>

<h3>Title: Active Learning of Model Discrepancy with Bayesian Experimental Design</h3>
<ul>
<li><strong>Authors: </strong>Huchen Yang, Chuanqi Chen, Jin-Long Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05372">https://arxiv.org/abs/2502.05372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05372">https://arxiv.org/pdf/2502.05372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05372]] Active Learning of Model Discrepancy with Bayesian Experimental Design(https://arxiv.org/abs/2502.05372)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Digital twins have been actively explored in many engineering applications, such as manufacturing and autonomous systems. However, model discrepancy is ubiquitous in most digital twin models and has significant impacts on the performance of using those models. In recent years, data-driven modeling techniques have been demonstrated promising in characterizing the model discrepancy in existing models, while the training data for the learning of model discrepancy is often obtained in an empirical way and an active approach of gathering informative data can potentially benefit the learning of model discrepancy. On the other hand, Bayesian experimental design (BED) provides a systematic approach to gathering the most informative data, but its performance is often negatively impacted by the model discrepancy. In this work, we build on sequential BED and propose an efficient approach to iteratively learn the model discrepancy based on the data from the BED. The performance of the proposed method is validated by a classical numerical example governed by a convection-diffusion equation, for which full BED is still feasible. The proposed method is then further studied in the same numerical example with a high-dimensional model discrepancy, which serves as a demonstration for the scenarios where full BED is not practical anymore. An ensemble-based approximation of information gain is further utilized to assess the data informativeness and to enhance learning model discrepancy. The results show that the proposed method is efficient and robust to the active learning of high-dimensional model discrepancy, using data suggested by the sequential BED. We also demonstrate that the proposed method is compatible with both classical numerical solvers and modern auto-differentiable solvers.</li>
</ul>

<h3>Title: Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Chongyu Fan, Jinghan Jia, Yihua Zhang, Anil Ramakrishna, Mingyi Hong, Sijia Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05374">https://arxiv.org/abs/2502.05374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05374">https://arxiv.org/pdf/2502.05374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05374]] Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond(https://arxiv.org/abs/2502.05374)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>The LLM unlearning technique has recently been introduced to comply with data regulations and address the safety and ethical concerns of LLMs by removing the undesired data-model influence. However, state-of-the-art unlearning methods face a critical vulnerability: they are susceptible to ``relearning'' the removed information from a small number of forget data points, known as relearning attacks. In this paper, we systematically investigate how to make unlearned models robust against such attacks. For the first time, we establish a connection between robust unlearning and sharpness-aware minimization (SAM) through a unified robust optimization framework, in an analogy to adversarial training designed to defend against adversarial attacks. Our analysis for SAM reveals that smoothness optimization plays a pivotal role in mitigating relearning attacks. Thus, we further explore diverse smoothing strategies to enhance unlearning robustness. Extensive experiments on benchmark datasets, including WMDP and MUSE, demonstrate that SAM and other smoothness optimization approaches consistently improve the resistance of LLM unlearning to relearning attacks. Notably, smoothness-enhanced unlearning also helps defend against (input-level) jailbreaking attacks, broadening our proposal's impact in robustifying LLM unlearning. Codes are available at this https URL.</li>
</ul>

<h3>Title: BCQ: Block Clustered Quantization for 4-bit (W4A4) LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Reena Elangovan, Charbel Sakr, Anand Raghunathan, Brucek Khailany</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05376">https://arxiv.org/abs/2502.05376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05376">https://arxiv.org/pdf/2502.05376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05376]] BCQ: Block Clustered Quantization for 4-bit (W4A4) LLM Inference(https://arxiv.org/abs/2502.05376)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Post-training quantization (PTQ) is a promising approach to reducing the storage and computational requirements of large language models (LLMs) without additional training cost. Recent PTQ studies have primarily focused on quantizing only weights to sub-8-bits while maintaining activations at 8-bits or higher. Accurate sub-8-bit quantization for both weights and activations without relying on quantization-aware training remains a significant challenge. We propose a novel quantization method called block clustered quantization (BCQ) wherein each operand tensor is decomposed into blocks (a block is a group of contiguous scalars), blocks are clustered based on their statistics, and a dedicated optimal quantization codebook is designed for each cluster. As a specific embodiment of this approach, we propose a PTQ algorithm called Locally-Optimal BCQ (LO-BCQ) that iterates between the steps of block clustering and codebook design to greedily minimize the quantization mean squared error. When weight and activation scalars are encoded to W4A4 format (with 0.5-bits of overhead for storing scaling factors and codebook selectors), we advance the current state-of-the-art by demonstrating <1% loss in inference accuracy across several LLMs and downstream tasks.</li>
</ul>

<h3>Title: Learning Task Representations from In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Baturay Saglam, Zhuoran Yang, Dionysis Kalogerias, Amin Karbasi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05390">https://arxiv.org/abs/2502.05390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05390">https://arxiv.org/pdf/2502.05390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05390]] Learning Task Representations from In-Context Learning(https://arxiv.org/abs/2502.05390)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable proficiency in in-context learning (ICL), where models adapt to new tasks through example-based prompts without requiring parameter updates. However, understanding how tasks are internally encoded and generalized remains a challenge. To address some of the empirical and technical gaps in the literature, we introduce an automated formulation for encoding task information in ICL prompts as a function of attention heads within the transformer architecture. This approach computes a single task vector as a weighted sum of attention heads, with the weights optimized causally via gradient descent. Our findings show that existing methods fail to generalize effectively to modalities beyond text. In response, we also design a benchmark to evaluate whether a task vector can preserve task fidelity in functional regression tasks. The proposed method successfully extracts task-specific information from in-context demonstrations and excels in both text and regression tasks, demonstrating its generalizability across modalities. Moreover, ablation studies show that our method's effectiveness stems from aligning the distribution of the last hidden state with that of an optimally performing in-context-learned model.</li>
</ul>

<h3>Title: Beyond and Free from Diffusion: Invertible Guided Consistency Training</h3>
<ul>
<li><strong>Authors: </strong>Chia-Hong Hsu, Shiu-hong Kao, Randall Balestriero</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05391">https://arxiv.org/abs/2502.05391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05391">https://arxiv.org/pdf/2502.05391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05391]] Beyond and Free from Diffusion: Invertible Guided Consistency Training(https://arxiv.org/abs/2502.05391)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Guidance in image generation steers models towards higher-quality or more targeted outputs, typically achieved in Diffusion Models (DMs) via Classifier-free Guidance (CFG). However, recent Consistency Models (CMs), which offer fewer function evaluations, rely on distilling CFG knowledge from pretrained DMs to achieve guidance, making them costly and inflexible. In this work, we propose invertible Guided Consistency Training (iGCT), a novel training framework for guided CMs that is entirely data-driven. iGCT, as a pioneering work, contributes to fast and guided image generation and editing without requiring the training and distillation of DMs, greatly reducing the overall compute requirements. iGCT addresses the saturation artifacts seen in CFG under high guidance scales. Our extensive experiments on CIFAR-10 and ImageNet64 show that iGCT significantly improves FID and precision compared to CFG. At a guidance of 13, iGCT improves precision to 0.8, while DM's drops to 0.47. Our work takes the first step toward enabling guidance and inversion for CMs without relying on DMs.</li>
</ul>

<h3>Title: Hierarchical Lexical Manifold Projection in Large Language Models: A Novel Mechanism for Multi-Scale Semantic Representation</h3>
<ul>
<li><strong>Authors: </strong>Natasha Martus, Sebastian Crowther, Maxwell Dorrington, Jonathan Applethwaite, Edgar Tillinghurst, Quentin Birkenshaw, Lukas Petrov, Constance Willoughby</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05395">https://arxiv.org/abs/2502.05395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05395">https://arxiv.org/pdf/2502.05395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05395]] Hierarchical Lexical Manifold Projection in Large Language Models: A Novel Mechanism for Multi-Scale Semantic Representation(https://arxiv.org/abs/2502.05395)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>The integration of structured hierarchical embeddings into transformer-based architectures introduces a refined approach to lexical representation, ensuring that multi-scale semantic relationships are preserved without compromising computational efficiency. A projection mechanism that maps tokens onto a structured manifold provides improved lexical alignment, enhancing the adaptability of word representations across diverse linguistic tasks. The structured encoding framework ensures that hierarchical embeddings maintain coherence across varying abstraction levels, allowing for stable transitions between localized syntactic features and global semantic structures. Experimental evaluations indicate that hierarchical embeddings consistently outperform conventional token representations, improving accuracy in linguistic benchmarks while maintaining lower computational overhead. Comparative analysis across multiple domains highlights the ability of hierarchical embeddings to retain contextual consistency, particularly in specialized language applications where structured lexical alignment is essential. Statistical assessments further demonstrate that hierarchical embeddings exhibit enhanced robustness under perturbation conditions, ensuring that linguistic structures remain stable across adversarial text modifications. The integration of hierarchical projections with transformer attention mechanisms enables improved contextual adaptation, ensuring that token representations are dynamically adjusted based on varying linguistic distributions. The refined hierarchical organization of embeddings provides greater interpretability in lexical modeling, facilitating enhanced generalization capabilities across diverse text processing tasks.</li>
</ul>

<h3>Title: Imitation Learning from a Single Temporally Misaligned Video</h3>
<ul>
<li><strong>Authors: </strong>William Huey, Huaxiaoyue Wang, Anne Wu, Yoav Artzi, Sanjiban Choudhury</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05397">https://arxiv.org/abs/2502.05397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05397">https://arxiv.org/pdf/2502.05397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05397]] Imitation Learning from a Single Temporally Misaligned Video(https://arxiv.org/abs/2502.05397)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We examine the problem of learning sequential tasks from a single visual demonstration. A key challenge arises when demonstrations are temporally misaligned due to variations in timing, differences in embodiment, or inconsistencies in execution. Existing approaches treat imitation as a distribution-matching problem, aligning individual frames between the agent and the demonstration. However, we show that such frame-level matching fails to enforce temporal ordering or ensure consistent progress. Our key insight is that matching should instead be defined at the level of sequences. We propose that perfect matching occurs when one sequence successfully covers all the subgoals in the same order as the other sequence. We present ORCA (ORdered Coverage Alignment), a dense per-timestep reward function that measures the probability of the agent covering demonstration frames in the correct order. On temporally misaligned demonstrations, we show that agents trained with the ORCA reward achieve $4.5$x improvement ($0.11 \rightarrow 0.50$ average normalized returns) for Meta-world tasks and $6.6$x improvement ($6.55 \rightarrow 43.3$ average returns) for Humanoid-v4 tasks compared to the best frame-level matching algorithms. We also provide empirical analysis showing that ORCA is robust to varying levels of temporal misalignment. Our code is available at this https URL</li>
</ul>

<h3>Title: The Complexity of Learning Sparse Superposed Features with Feedback</h3>
<ul>
<li><strong>Authors: </strong>Akash Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05407">https://arxiv.org/abs/2502.05407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05407">https://arxiv.org/pdf/2502.05407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05407]] The Complexity of Learning Sparse Superposed Features with Feedback(https://arxiv.org/abs/2502.05407)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>The success of deep networks is crucially attributed to their ability to capture latent features within a representation space. In this work, we investigate whether the underlying learned features of a model can be efficiently retrieved through feedback from an agent, such as a large language model (LLM), in the form of relative \textit{triplet comparisons}. These features may represent various constructs, including dictionaries in LLMs or components of a covariance matrix of Mahalanobis distances. We analyze the feedback complexity associated with learning a feature matrix in sparse settings. Our results establish tight bounds when the agent is permitted to construct activations and demonstrate strong upper bounds in sparse scenarios when the agent's feedback is limited to distributional information. We validate our theoretical findings through experiments on two distinct applications: feature recovery from Recursive Feature Machine-trained models and dictionary extraction from sparse autoencoders trained on Large Language Models.</li>
</ul>

<h3>Title: Vision-in-the-loop Simulation for Deep Monocular Pose Estimation of UAV in Ocean Environment</h3>
<ul>
<li><strong>Authors: </strong>Maneesha Wickramasuriya, Beomyeol Yu, Taeyoung Lee, Murray Snyder</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05409">https://arxiv.org/abs/2502.05409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05409">https://arxiv.org/pdf/2502.05409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05409]] Vision-in-the-loop Simulation for Deep Monocular Pose Estimation of UAV in Ocean Environment(https://arxiv.org/abs/2502.05409)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper proposes a vision-in-the-loop simulation environment for deep monocular pose estimation of a UAV operating in an ocean environment. Recently, a deep neural network with a transformer architecture has been successfully trained to estimate the pose of a UAV relative to the flight deck of a research vessel, overcoming several limitations of GPS-based approaches. However, validating the deep pose estimation scheme in an actual ocean environment poses significant challenges due to the limited availability of research vessels and the associated operational costs. To address these issues, we present a photo-realistic 3D virtual environment leveraging recent advancements in Gaussian splatting, a novel technique that represents 3D scenes by modeling image pixels as Gaussian distributions in 3D space, creating a lightweight and high-quality visual model from multiple viewpoints. This approach enables the creation of a virtual environment integrating multiple real-world images collected in situ. The resulting simulation enables the indoor testing of flight maneuvers while verifying all aspects of flight software, hardware, and the deep monocular pose estimation scheme. This approach provides a cost-effective solution for testing and validating the autonomous flight of shipboard UAVs, specifically focusing on vision-based control and estimation algorithms.</li>
</ul>

<h3>Title: Graph-based Molecular In-context Learning Grounded on Morgan Fingerprints</h3>
<ul>
<li><strong>Authors: </strong>Ali Al-Lawati, Jason Lucas, Zhiwei Zhang, Prasenjit Mitra, Suhang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05414">https://arxiv.org/abs/2502.05414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05414">https://arxiv.org/pdf/2502.05414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05414]] Graph-based Molecular In-context Learning Grounded on Morgan Fingerprints(https://arxiv.org/abs/2502.05414)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-context learning (ICL) effectively conditions large language models (LLMs) for molecular tasks, such as property prediction and molecule captioning, by embedding carefully selected demonstration examples into the input prompt. This approach avoids the computational overhead of extensive pertaining and fine-tuning. However, current prompt retrieval methods for molecular tasks have relied on molecule feature similarity, such as Morgan fingerprints, which do not adequately capture the global molecular and atom-binding relationships. As a result, these methods fail to represent the full complexity of molecular structures during inference. Moreover, small-to-medium-sized LLMs, which offer simpler deployment requirements in specialized systems, have remained largely unexplored in the molecular ICL literature. To address these gaps, we propose a self-supervised learning technique, GAMIC (Graph-Aligned Molecular In-Context learning, which aligns global molecular structures, represented by graph neural networks (GNNs), with textual captions (descriptions) while leveraging local feature similarity through Morgan fingerprints. In addition, we introduce a Maximum Marginal Relevance (MMR) based diversity heuristic during retrieval to optimize input prompt demonstration samples. Our experimental findings using diverse benchmark datasets show GAMIC outperforms simple Morgan-based ICL retrieval methods across all tasks by up to 45%.</li>
</ul>

<h3>Title: Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation</h3>
<ul>
<li><strong>Authors: </strong>Chenkai Xu, Xu Wang, Zhenyi Liao, Yishun Li, Tianqi Hou, Zhijie Deng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05415">https://arxiv.org/abs/2502.05415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05415">https://arxiv.org/pdf/2502.05415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05415]] Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation(https://arxiv.org/abs/2502.05415)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>There has been increasing research interest in building unified multimodal understanding and generation models, among which Show-o stands as a notable representative, demonstrating great promise for both text-to-image and image-to-text generation. The inference of Show-o involves progressively denoising image tokens and autoregressively decoding text tokens, and hence, unfortunately, suffers from inefficiency issues from both sides. This paper introduces Show-o Turbo to bridge the gap. We first identify a unified denoising perspective for the generation of images and text in Show-o based on the parallel decoding of text tokens. We then propose to extend consistency distillation (CD), a qualified approach for shortening the denoising process of diffusion models, to the multimodal denoising trajectories of Show-o. We introduce a trajectory segmentation strategy and a curriculum learning procedure to improve the training convergence. Empirically, in text-to-image generation, Show-o Turbo displays a GenEval score of 0.625 at 4 sampling steps without using classifier-free guidance (CFG), outperforming that of the original Show-o with 8 steps and CFG; in image-to-text generation, Show-o Turbo exhibits a 1.5x speedup without significantly sacrificing performance. The code is available at this https URL.</li>
</ul>

<h3>Title: Deep Generative Models with Hard Linear Equality Constraints</h3>
<ul>
<li><strong>Authors: </strong>Ruoyan Li, Dipti Ranjan Sahu, Guy Van den Broeck, Zhe Zeng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05416">https://arxiv.org/abs/2502.05416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05416">https://arxiv.org/pdf/2502.05416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05416]] Deep Generative Models with Hard Linear Equality Constraints(https://arxiv.org/abs/2502.05416)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>While deep generative models~(DGMs) have demonstrated remarkable success in capturing complex data distributions, they consistently fail to learn constraints that encode domain knowledge and thus require constraint integration. Existing solutions to this challenge have primarily relied on heuristic methods and often ignore the underlying data distribution, harming the generative performance. In this work, we propose a probabilistically sound approach for enforcing the hard constraints into DGMs to generate constraint-compliant and realistic data. This is achieved by our proposed gradient estimators that allow the constrained distribution, the data distribution conditioned on constraints, to be differentiably learned. We carry out extensive experiments with various DGM model architectures over five image datasets and three scientific applications in which domain knowledge is governed by linear equality constraints. We validate that the standard DGMs almost surely generate data violating the constraints. Among all the constraint integration strategies, ours not only guarantees the satisfaction of constraints in generation but also archives superior generative performance than the other methods across every benchmark.</li>
</ul>

<h3>Title: LRA-GNN: Latent Relation-Aware Graph Neural Network with Initial and Dynamic Residual for Facial Age Estimation</h3>
<ul>
<li><strong>Authors: </strong>Yiping Zhang, Yuntao Shou, Wei Ai, Tao Meng, Keqin Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05423">https://arxiv.org/abs/2502.05423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05423">https://arxiv.org/pdf/2502.05423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05423]] LRA-GNN: Latent Relation-Aware Graph Neural Network with Initial and Dynamic Residual for Facial Age Estimation(https://arxiv.org/abs/2502.05423)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Face information is mainly concentrated among facial key points, and frontier research has begun to use graph neural networks to segment faces into patches as nodes to model complex face representations. However, these methods construct node-to-node relations based on similarity thresholds, so there is a problem that some latent relations are missing. These latent relations are crucial for deep semantic representation of face aging. In this novel, we propose a new Latent Relation-Aware Graph Neural Network with Initial and Dynamic Residual (LRA-GNN) to achieve robust and comprehensive facial representation. Specifically, we first construct an initial graph utilizing facial key points as prior knowledge, and then a random walk strategy is employed to the initial graph for obtaining the global structure, both of which together guide the subsequent effective exploration and comprehensive representation. Then LRA-GNN leverages the multi-attention mechanism to capture the latent relations and generates a set of fully connected graphs containing rich facial information and complete structure based on the aforementioned guidance. To avoid over-smoothing issues for deep feature extraction on the fully connected graphs, the deep residual graph convolutional networks are carefully designed, which fuse adaptive initial residuals and dynamic developmental residuals to ensure the consistency and diversity of information. Finally, to improve the estimation accuracy and generalization ability, progressive reinforcement learning is proposed to optimize the ensemble classification regressor. Our proposed framework surpasses the state-of-the-art baselines on several age estimation benchmarks, demonstrating its strength and effectiveness.</li>
</ul>

<h3>Title: SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Xingtong Yu, Zechuan Gong, Chang Zhou, Yuan Fang, Hui Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05424">https://arxiv.org/abs/2502.05424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05424">https://arxiv.org/pdf/2502.05424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05424]] SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation(https://arxiv.org/abs/2502.05424)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graphs are able to model interconnected entities in many online services, supporting a wide range of applications on the Web. This raises an important question: How can we train a graph foundational model on multiple source domains and adapt to an unseen target domain? A major obstacle is that graphs from different domains often exhibit divergent characteristics. Some studies leverage large language models to align multiple domains based on textual descriptions associated with the graphs, limiting their applicability to text-attributed graphs. For text-free graphs, a few recent works attempt to align different feature distributions across domains, while generally neglecting structural differences. In this work, we propose a novel Structure Alignment framework for text-free Multi-domain Graph Pre-Training and cross-domain adaptation (SAMGPT). It is designed to learn multi-domain knowledge from graphs originating in multiple source domains, which can then be adapted to address applications in an unseen target domain. Specifically, we introduce a set of structure tokens to harmonize structure-based aggregation across source domains during the pre-training phase. Next, for cross-domain adaptation, we design dual prompts, namely, holistic prompts and specific prompts, which adapt unified multi-domain structural knowledge and fine-grained, domain-specific information, respectively, to a target domain. Finally, we conduct comprehensive experiments on seven public datasets to evaluate and analyze the effectiveness of SAMGPT.</li>
</ul>

<h3>Title: Toward Copyright Integrity and Verifiability via Multi-Bit Watermarking for Intelligent Transportation Systems</h3>
<ul>
<li><strong>Authors: </strong>Yihao Wang, Lingxiao Li, Yifan Tang, Ru Zhang, Jianyi Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05425">https://arxiv.org/abs/2502.05425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05425">https://arxiv.org/pdf/2502.05425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05425]] Toward Copyright Integrity and Verifiability via Multi-Bit Watermarking for Intelligent Transportation Systems(https://arxiv.org/abs/2502.05425)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, extraction, watermark</a></li>
<li><strong>Abstract: </strong>Intelligent transportation systems (ITS) use advanced technologies such as artificial intelligence to significantly improve traffic flow management efficiency, and promote the intelligent development of the transportation industry. However, if the data in ITS is attacked, such as tampering or forgery, it will endanger public safety and cause social losses. Therefore, this paper proposes a watermarking that can verify the integrity of copyright in response to the needs of ITS, termed ITSmark. ITSmark focuses on functions such as extracting watermarks, verifying permission, and tracing tampered locations. The scheme uses the copyright information to build the multi-bit space and divides this space into multiple segments. These segments will be assigned to tokens. Thus, the next token is determined by its segment which contains the copyright. In this way, the obtained data contains the custom watermark. To ensure the authorization, key parameters are encrypted during copyright embedding to obtain cipher data. Only by possessing the correct cipher data and private key, can the user entirely extract the watermark. Experiments show that ITSmark surpasses baseline performances in data quality, extraction accuracy, and unforgeability. It also shows unique capabilities of permission verification and tampered location tracing, which ensures the security of extraction and the reliability of copyright verification. Furthermore, ITSmark can also customize the watermark embedding position and proportion according to user needs, making embedding more flexible.</li>
</ul>

<h3>Title: SMaCk: Efficient Instruction Cache Attacks via Self-Modifying Code Conflicts</h3>
<ul>
<li><strong>Authors: </strong>Seonghun Son, Daniel Moghimi, Berk Gulmezoglu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05429">https://arxiv.org/abs/2502.05429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05429">https://arxiv.org/pdf/2502.05429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05429]] SMaCk: Efficient Instruction Cache Attacks via Self-Modifying Code Conflicts(https://arxiv.org/abs/2502.05429)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Self-modifying code (SMC) allows programs to alter their own instructions, optimizing performance and functionality on x86 processors. Despite its benefits, SMC introduces unique microarchitectural behaviors that can be exploited for malicious purposes. In this paper, we explore the security implications of SMC by examining how specific x86 instructions affecting instruction cache lines lead to measurable timing discrepancies between cache hits and misses. These discrepancies facilitate refined cache attacks, making them less noisy and more effective. We introduce novel attack techniques that leverage these timing variations to enhance existing methods such as Prime+Probe and Flush+Reload. Our advanced techniques allow adversaries to more precisely attack cryptographic keys and create covert channels akin to Spectre across various x86 platforms. Finally, we propose a dynamic detection methodology utilizing hardware performance counters to mitigate these enhanced threats.</li>
</ul>

<h3>Title: MoFM: A Large-Scale Human Motion Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Mohammadreza Baharani, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Gabriel Maldonado, Hamed Tabkhi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05432">https://arxiv.org/abs/2502.05432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05432">https://arxiv.org/pdf/2502.05432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05432]] MoFM: A Large-Scale Human Motion Foundation Model(https://arxiv.org/abs/2502.05432)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>AFoundation Models (FM) have increasingly drawn the attention of researchers due to their scalability and generalization across diverse tasks. Inspired by the success of FMs and the principles that have driven advancements in Large Language Models (LLMs), we introduce MoFM as a novel Motion Foundation Model. MoFM is designed for the semantic understanding of complex human motions in both time and space. To facilitate large-scale training, MotionBook, a comprehensive human motion dictionary of discretized motions is designed and employed. MotionBook utilizes Thermal Cubes to capture spatio-temporal motion heatmaps, applying principles from discrete variational models to encode human movements into discrete units for a more efficient and scalable representation. MoFM, trained on a large corpus of motion data, provides a foundational backbone adaptable to diverse downstream tasks, supporting paradigms such as one-shot, unsupervised, and supervised tasks. This versatility makes MoFM well-suited for a wide range of motion-based applications.</li>
</ul>

<h3>Title: Sample-Efficient Reinforcement Learning from Human Feedback via Information-Directed Sampling</h3>
<ul>
<li><strong>Authors: </strong>Han Qi, Haochen Yang, Qiaosheng Zhang, Zhuoran Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05434">https://arxiv.org/abs/2502.05434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05434">https://arxiv.org/pdf/2502.05434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05434]] Sample-Efficient Reinforcement Learning from Human Feedback via Information-Directed Sampling(https://arxiv.org/abs/2502.05434)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study the problem of reinforcement learning from human feedback (RLHF), a critical problem in training large language models, from a theoretical perspective. Our main contribution is the design of novel sample-efficient RLHF algorithms based on information-directed sampling (IDS), an online decision-making principle inspired by information theory. Our algorithms maximize the sum of the value function and a mutual information term that encourages exploration of the unknown environment (which quantifies the information gained about the environment through observed human feedback data). To tackle the challenge of large state spaces and improve sample efficiency, we construct a simplified \emph{surrogate environment} and introduce a novel distance measure (named the \emph{$\ell_g$-distance}), enabling our IDS-based algorithm to achieve a Bayesian regret upper bound of order $O(H^{\frac{3}{2}}\sqrt{\log(K(\epsilon)) T})$, where $H$ is the episode length, $T$ is the number of episode and $K(\epsilon)$ is related to the covering number of the environment. Specializing to the tabular settings, this regret bound is of order $\tilde{O}(H^2\sqrt{SAT})$, where $S$ and $A$ are the numbers of states and actions. Finally, we propose an Approximate-IDS algorithm that is computationally more efficient while maintaining nearly the same sample efficiency. The design principle of this approximate algorithm is not only effective in RLHF settings but also applicable to the standard RL framework. Moreover, our work showcases the value of information theory in reinforcement learning and in the training of large language models.</li>
</ul>

<h3>Title: Stochastic Forward-Backward Deconvolution: Training Diffusion Models with Finite Noisy Datasets</h3>
<ul>
<li><strong>Authors: </strong>Haoye Lu, Qifan Wu, Yaoliang Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05446">https://arxiv.org/abs/2502.05446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05446">https://arxiv.org/pdf/2502.05446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05446]] Stochastic Forward-Backward Deconvolution: Training Diffusion Models with Finite Noisy Datasets(https://arxiv.org/abs/2502.05446)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent diffusion-based generative models achieve remarkable results by training on massive datasets, yet this practice raises concerns about memorization and copyright infringement. A proposed remedy is to train exclusively on noisy data with potential copyright issues, ensuring the model never observes original content. However, through the lens of deconvolution theory, we show that although it is theoretically feasible to learn the data distribution from noisy samples, the practical challenge of collecting sufficient samples makes successful learning nearly unattainable. To overcome this limitation, we propose to pretrain the model with a small fraction of clean data to guide the deconvolution process. Combined with our Stochastic Forward--Backward Deconvolution (SFBD) method, we attain an FID of $6.31$ on CIFAR-10 with just $4\%$ clean images (and $3.58$ with $10\%$). Theoretically, we prove that SFBD guides the model to learn the true data distribution. The result also highlights the importance of pretraining on limited but clean data or the alternative from similar datasets. Empirical studies further support these findings and offer additional insights.</li>
</ul>

<h3>Title: Iterative Deepening Sampling for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Weizhe Chen, Sven Koenig, Bistra Dilkina</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05449">https://arxiv.org/abs/2502.05449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05449">https://arxiv.org/pdf/2502.05449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05449]] Iterative Deepening Sampling for Large Language Models(https://arxiv.org/abs/2502.05449)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The recent release of OpenAI's o1 models and other similar frameworks showcasing test-time scaling laws has demonstrated their exceptional capability to tackle complex reasoning tasks. Inspired by this, subsequent research has revealed that such test-time scaling laws hinge on the model's ability to search both within a single response (intra-response) and across multiple responses (inter-response) during training. Crucially, beyond selecting a single optimal response, the model must also develop robust self-correction capabilities within its own outputs. However, training models to achieve effective self-evaluation and self-correction remains a significant challenge, heavily dependent on the quality of self-reflection data. In this paper, we address this challenge by focusing on enhancing the quality of self-reflection data generation for complex problem-solving, which can subsequently improve the training of next-generation large language models (LLMs). Specifically, we explore how manually triggering a model's self-correction mechanisms can improve performance on challenging reasoning tasks. To this end, we propose a novel iterative deepening sampling algorithm framework designed to enhance self-correction and generate higher-quality samples. Through extensive experiments on Math500 and AIME benchmarks, we demonstrate that our method achieves a higher success rate on difficult tasks and provide detailed ablation studies to analyze its effectiveness across diverse settings.</li>
</ul>

<h3>Title: DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability</h3>
<ul>
<li><strong>Authors: </strong>Sibasish Dhibar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, q-bio.CB, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05459">https://arxiv.org/abs/2502.05459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05459">https://arxiv.org/pdf/2502.05459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05459]] DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability(https://arxiv.org/abs/2502.05459)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>White blood cells (WBC) are important parts of our immune system, and they protect our body against infections by eliminating viruses, bacteria, parasites and fungi. The number of WBC types and the total number of WBCs provide important information about our health status. A traditional method, convolutional neural networks (CNN), a deep learning architecture, can classify the blood cell from a part of an object and perform object recognition. Various CNN models exhibit potential; however, their development often involves ad-hoc processes that neglect unnecessary layers, leading to issues with unbalanced datasets and insufficient data augmentation. To address these challenges, we propose a novel ensemble approach that integrates three CNN architectures, each uniquely configured with different dropout and max-pooling layer settings to enhance feature learning. This ensemble model, named DCENWCNet, effectively balances the bias-variance trade-off. When evaluated on the widely recognized Rabbin-WBC dataset, our model outperforms existing state-of-the-art networks, achieving highest mean accuracy. Additionally, it demonstrates superior performance in precision, recall, F1-score, and Area Under the ROC Curve (AUC) across all categories. To delve deeper into the interpretability of classifiers, we employ reliable post-hoc explanation techniques, including Local Interpretable Model-Agnostic Explanations (LIME). These methods approximate the behavior of a black-box model by elucidating the relationships between feature values and predictions. Interpretable results enable users to comprehend and validate the model's predictions, thereby increasing their confidence in the automated diagnosis.</li>
</ul>

<h3>Title: IllusionCAPTCHA: A CAPTCHA based on Visual Illusion</h3>
<ul>
<li><strong>Authors: </strong>Ziqi Ding, Gelei Deng, Yi Liu, Junchen Ding, Jieshan Chen, Yulei Sui, Yuekang Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05461">https://arxiv.org/abs/2502.05461</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05461">https://arxiv.org/pdf/2502.05461</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05461]] IllusionCAPTCHA: A CAPTCHA based on Visual Illusion(https://arxiv.org/abs/2502.05461)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, large language model</a></li>
<li><strong>Abstract: </strong>CAPTCHAs have long been essential tools for protecting applications from automated bots. Initially designed as simple questions to distinguish humans from bots, they have become increasingly complex to keep pace with the proliferation of CAPTCHA-cracking techniques employed by malicious actors. However, with the advent of advanced large language models (LLMs), the effectiveness of existing CAPTCHAs is now being undermined. To address this issue, we have conducted an empirical study to evaluate the performance of multimodal LLMs in solving CAPTCHAs and to assess how many attempts human users typically need to pass them. Our findings reveal that while LLMs can solve most CAPTCHAs, they struggle with those requiring complex reasoning type of CAPTCHA that also presents significant challenges for human users. Interestingly, our user study shows that the majority of human participants require a second attempt to pass these reasoning CAPTCHAs, a finding not reported in previous research. Based on empirical findings, we present IllusionCAPTCHA, a novel security mechanism employing the "Human-Easy but AI-Hard" paradigm. This new CAPTCHA employs visual illusions to create tasks that are intuitive for humans but highly confusing for AI models. Furthermore, we developed a structured, step-by-step method that generates misleading options, which particularly guide LLMs towards making incorrect choices and reduce their chances of successfully solving CAPTCHAs. Our evaluation shows that IllusionCAPTCHA can effectively deceive LLMs 100% of the time. Moreover, our structured design significantly increases the likelihood of AI errors when attempting to solve these challenges. Results from our user study indicate that 86.95% of participants successfully passed the CAPTCHA on their first attempt, outperforming other CAPTCHA systems.</li>
</ul>

<h3>Title: Position: LLMs Can be Good Tutors in Foreign Language Education</h3>
<ul>
<li><strong>Authors: </strong>Jingheng Ye, Shen Wang, Deqing Zou, Yibo Yan, Kun Wang, Hai-Tao Zheng, Zenglin Xu, Irwin King, Philip S. Yu, Qingsong Wen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05467">https://arxiv.org/abs/2502.05467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05467">https://arxiv.org/pdf/2502.05467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05467]] Position: LLMs Can be Good Tutors in Foreign Language Education(https://arxiv.org/abs/2502.05467)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While recent efforts have begun integrating large language models (LLMs) into foreign language education (FLE), they often rely on traditional approaches to learning tasks without fully embracing educational methodologies, thus lacking adaptability to language learning. To address this gap, we argue that LLMs have the potential to serve as effective tutors in FLE. Specifically, LLMs can play three critical roles: (1) as data enhancers, improving the creation of learning materials or serving as student simulations; (2) as task predictors, serving as learner assessment or optimizing learning pathway; and (3) as agents, enabling personalized and inclusive education. We encourage interdisciplinary research to explore these roles, fostering innovation while addressing challenges and risks, ultimately advancing FLE through the thoughtful integration of LLMs.</li>
</ul>

<h3>Title: Gen-DFL: Decision-Focused Generative Learning for Robust Decision Making</h3>
<ul>
<li><strong>Authors: </strong>Prince Zizhuang Wang, Jinhao Liang, Shuyi Chen, Ferdinando Fioretto, Shixiang Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05468">https://arxiv.org/abs/2502.05468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05468">https://arxiv.org/pdf/2502.05468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05468]] Gen-DFL: Decision-Focused Generative Learning for Robust Decision Making(https://arxiv.org/abs/2502.05468)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Decision-focused learning (DFL) integrates predictive models with downstream optimization, directly training machine learning models to minimize decision errors. While DFL has been shown to provide substantial advantages when compared to a counterpart that treats the predictive and prescriptive models separately, it has also been shown to struggle in high-dimensional and risk-sensitive settings, limiting its applicability in real-world settings. To address this limitation, this paper introduces decision-focused generative learning (Gen-DFL), a novel framework that leverages generative models to adaptively model uncertainty and improve decision quality. Instead of relying on fixed uncertainty sets, Gen-DFL learns a structured representation of the optimization parameters and samples from the tail regions of the learned distribution to enhance robustness against worst-case scenarios. This approach mitigates over-conservatism while capturing complex dependencies in the parameter space. The paper shows, theoretically, that Gen-DFL achieves improved worst-case performance bounds compared to traditional DFL. Empirically, it evaluates Gen-DFL on various scheduling and logistics problems, demonstrating its strong performance against existing DFL methods.</li>
</ul>

<h3>Title: LMS-Net: A Learned Mumford-Shah Network For Few-Shot Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shengdong Zhang, Fan Jia, Xiang Li, Hao Zhang, Jun Shi, Liyan Ma, Shihui Ying</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05473">https://arxiv.org/abs/2502.05473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05473">https://arxiv.org/pdf/2502.05473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05473]] LMS-Net: A Learned Mumford-Shah Network For Few-Shot Medical Image Segmentation(https://arxiv.org/abs/2502.05473)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Few-shot semantic segmentation (FSS) methods have shown great promise in handling data-scarce scenarios, particularly in medical image segmentation tasks. However, most existing FSS architectures lack sufficient interpretability and fail to fully incorporate the underlying physical structures of semantic regions. To address these issues, in this paper, we propose a novel deep unfolding network, called the Learned Mumford-Shah Network (LMS-Net), for the FSS task. Specifically, motivated by the effectiveness of pixel-to-prototype comparison in prototypical FSS methods and the capability of deep priors to model complex spatial structures, we leverage our learned Mumford-Shah model (LMS model) as a mathematical foundation to integrate these insights into a unified framework. By reformulating the LMS model into prototype update and mask update tasks, we propose an alternating optimization algorithm to solve it efficiently. Further, the iterative steps of this algorithm are unfolded into corresponding network modules, resulting in LMS-Net with clear interpretability. Comprehensive experiments on three publicly available medical segmentation datasets verify the effectiveness of our method, demonstrating superior accuracy and robustness in handling complex structures and adapting to challenging segmentation scenarios. These results highlight the potential of LMS-Net to advance FSS in medical imaging applications. Our code will be available at: this https URL</li>
</ul>

<h3>Title: You Are What You Eat -- AI Alignment Requires Understanding How Data Shapes Structure and Generalisation</h3>
<ul>
<li><strong>Authors: </strong>Simon Pepin Lehalleur, Jesse Hoogland, Matthew Farrugia-Roberts, Susan Wei, Alexander Gietelink Oldenziel, George Wang, Liam Carroll, Daniel Murfet</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05475">https://arxiv.org/abs/2502.05475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05475">https://arxiv.org/pdf/2502.05475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05475]] You Are What You Eat -- AI Alignment Requires Understanding How Data Shapes Structure and Generalisation(https://arxiv.org/abs/2502.05475)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this position paper, we argue that understanding the relation between structure in the data distribution and structure in trained models is central to AI alignment. First, we discuss how two neural networks can have equivalent performance on the training set but compute their outputs in essentially different ways and thus generalise differently. For this reason, standard testing and evaluation are insufficient for obtaining assurances of safety for widely deployed generally intelligent systems. We argue that to progress beyond evaluation to a robust mathematical science of AI alignment, we need to develop statistical foundations for an understanding of the relation between structure in the data distribution, internal structure in models, and how these structures underlie generalisation.</li>
</ul>

<h3>Title: Convolutional Neural Network Segmentation for Satellite Imagery Data to Identify Landforms Using U-Net Architecture</h3>
<ul>
<li><strong>Authors: </strong>Mitul Goswami, Sainath Dey, Aniruddha Mukherjee, Suneeta Mohanty, Prasant Kumar Pattnaik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05476">https://arxiv.org/abs/2502.05476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05476">https://arxiv.org/pdf/2502.05476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05476]] Convolutional Neural Network Segmentation for Satellite Imagery Data to Identify Landforms Using U-Net Architecture(https://arxiv.org/abs/2502.05476)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>This study demonstrates a novel use of the U-Net architecture in the field of semantic segmentation to detect landforms using preprocessed satellite imagery. The study applies the U-Net model for effective feature extraction by using Convolutional Neural Network (CNN) segmentation techniques. Dropout is strategically used for regularization to improve the model's perseverance, and the Adam optimizer is used for effective training. The study thoroughly assesses the performance of the U-Net architecture utilizing a large sample of preprocessed satellite topographical images. The model excels in semantic segmentation tasks, displaying high-resolution outputs, quick feature extraction, and flexibility to a wide range of applications. The findings highlight the U-Net architecture's substantial contribution to the advancement of machine learning and image processing technologies. The U-Net approach, which emphasizes pixel-wise categorization and comprehensive segmentation map production, is helpful in practical applications such as autonomous driving, disaster management, and land use planning. This study not only investigates the complexities of U-Net architecture for semantic segmentation, but also highlights its real-world applications in image classification, analysis, and landform identification. The study demonstrates the U-Net model's key significance in influencing the environment of modern technology.</li>
</ul>

<h3>Title: OntoTune: Ontology-Driven Self-training for Aligning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhiqiang Liu, Chengtao Gan, Junjie Wang, Yichi Zhang, Zhongpu Bo, Mengshu Sun, Huajun Chen, Wen Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05478">https://arxiv.org/abs/2502.05478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05478">https://arxiv.org/pdf/2502.05478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05478]] OntoTune: Ontology-Driven Self-training for Aligning Large Language Models(https://arxiv.org/abs/2502.05478)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing domain-specific Large Language Models (LLMs) are typically developed by fine-tuning general-purposed LLMs with large-scale domain-specific corpora. However, training on large-scale corpora often fails to effectively organize domain knowledge of LLMs, leading to fragmented understanding. Inspired by how humans connect concepts and organize knowledge through mind maps, we aim to emulate this approach by using ontology with hierarchical conceptual knowledge to reorganize LLM's domain knowledge. From this perspective, we propose an ontology-driven self-training framework called OntoTune, which aims to align LLMs with ontology through in-context learning, enabling the generation of responses guided by the ontology. We leverage in-context learning to identify whether the LLM has acquired the specific concept's ontology knowledge, and select the entries not yet mastered by LLM as the training set to further align the LLM with ontology. Compared to existing domain LLMs based on newly collected large-scale domain-specific corpora, our OntoTune, which relies on the existing, long-term developed ontology and LLM itself, significantly reduces data maintenance costs and offers improved generalization ability. We conduct our study in the medical domain to evaluate the effectiveness of OntoTune, utilizing a standardized medical ontology, SNOMED CT as our ontology source. Experimental results demonstrate that OntoTune achieves state-of-the-art performance in both in-ontology task hypernym discovery and out-of-ontology task medical domain QA. Moreover, compared to the latest direct ontology injection method TaxoLLaMA, our OntoTune better preserves original knowledge of LLM. The code and data are available at this https URL.</li>
</ul>

<h3>Title: Robustifying Fourier Features Embeddings for Implicit Neural Representations</h3>
<ul>
<li><strong>Authors: </strong>Mingze Ma, Qingtian Zhu, Yifan Zhan, Zhengwei Yin, Hongjun Wang, Yinqiang Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05482">https://arxiv.org/abs/2502.05482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05482">https://arxiv.org/pdf/2502.05482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05482]] Robustifying Fourier Features Embeddings for Implicit Neural Representations(https://arxiv.org/abs/2502.05482)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Implicit Neural Representations (INRs) employ neural networks to represent continuous functions by mapping coordinates to the corresponding values of the target function, with applications e.g., inverse graphics. However, INRs face a challenge known as spectral bias when dealing with scenes containing varying frequencies. To overcome spectral bias, the most common approach is the Fourier features-based methods such as positional encoding. However, Fourier features-based methods will introduce noise to output, which degrades their performances when applied to downstream tasks. In response, this paper initially hypothesizes that combining multi-layer perceptrons (MLPs) with Fourier feature embeddings mutually enhances their strengths, yet simultaneously introduces limitations inherent in Fourier feature embeddings. By presenting a simple theorem, we validate our hypothesis, which serves as a foundation for the design of our solution. Leveraging these insights, we propose the use of multi-layer perceptrons (MLPs) without additive</li>
</ul>

<h3>Title: Mechanistic Interpretability of Emotion Inference in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ala N. Tak, Amin Banayeeanzade, Anahita Bolourani, Mina Kian, Robin Jia, Jonathan Gratch</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05489">https://arxiv.org/abs/2502.05489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05489">https://arxiv.org/pdf/2502.05489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05489]] Mechanistic Interpretability of Emotion Inference in Large Language Models(https://arxiv.org/abs/2502.05489)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) show promising capabilities in predicting human emotions from text. However, the mechanisms through which these models process emotional stimuli remain largely unexplored. Our study addresses this gap by investigating how autoregressive LLMs infer emotions, showing that emotion representations are functionally localized to specific regions in the model. Our evaluation includes diverse model families and sizes and is supported by robustness checks. We then show that the identified representations are psychologically plausible by drawing on cognitive appraisal theory, a well-established psychological framework positing that emotions emerge from evaluations (appraisals) of environmental stimuli. By causally intervening on construed appraisal concepts, we steer the generation and show that the outputs align with theoretical and intuitive expectations. This work highlights a novel way to causally intervene and precisely shape emotional text generation, potentially benefiting safety and alignment in sensitive affective domains.</li>
</ul>

<h3>Title: Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Ya Zhou, Yujie Yang, Jianhuang Gan, Xiangjie Li, Jing Yuan, Wei Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05494">https://arxiv.org/abs/2502.05494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05494">https://arxiv.org/pdf/2502.05494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05494]] Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection(https://arxiv.org/abs/2502.05494)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Electrocardiogram (ECG) analysis is a fundamental tool for diagnosing cardiovascular conditions, yet anomaly detection in ECG signals remains challenging due to their inherent complexity and variability. We propose Multi-scale Masked Autoencoder for ECG anomaly detection (MMAE-ECG), a novel end-to-end framework that effectively captures both global and local dependencies in ECG data. Unlike state-of-the-art methods that rely on heartbeat segmentation or R-peak detection, MMAE-ECG eliminates the need for such pre-processing steps, enhancing its suitability for clinical deployment. MMAE-ECG partitions ECG signals into non-overlapping segments, with each segment assigned learnable positional embeddings. A novel multi-scale masking strategy and multi-scale attention mechanism, along with distinct positional embeddings, enable a lightweight Transformer encoder to effectively capture both local and global dependencies. The masked segments are then reconstructed using a single-layer Transformer block, with an aggregation strategy employed during inference to refine the outputs. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art approaches while significantly reducing computational complexity-approximately 1/78 of the floating-point operations (FLOPs) required for inference. Ablation studies further validate the effectiveness of each component, highlighting the potential of multi-scale masked autoencoders for anomaly detection.</li>
</ul>

<h3>Title: Feature Explosion: a generic optimization strategy for outlier detection algorithms</h3>
<ul>
<li><strong>Authors: </strong>Qi Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05496">https://arxiv.org/abs/2502.05496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05496">https://arxiv.org/pdf/2502.05496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05496]] Feature Explosion: a generic optimization strategy for outlier detection algorithms(https://arxiv.org/abs/2502.05496)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Outlier detection tasks aim at discovering potential issues or opportunities and are widely used in cybersecurity, financial security, industrial inspection, etc. To date, thousands of outlier detection algorithms have been proposed. Clearly, in real-world scenarios, such a large number of algorithms is unnecessary. In other words, a large number of outlier detection algorithms are redundant. We believe the root cause of this redundancy lies in the current highly customized (i.e., non-generic) optimization strategies. Specifically, when researchers seek to improve the performance of existing outlier detection algorithms, they have to design separate optimized versions tailored to the principles of each algorithm, leading to an ever-growing number of outlier detection algorithms. To address this issue, in this paper, we introduce the explosion from physics into the outlier detection task and propose a generic optimization strategy based on feature explosion, called OSD (Optimization Strategy for outlier Detection algorithms). In the future, when improving the performance of existing outlier detection algorithms, it will be sufficient to invoke the OSD plugin without the need to design customized optimized versions for them. We compared the performances of 14 outlier detection algorithms on 24 datasets before and after invoking the OSD plugin. The experimental results show that the performances of all outlier detection algorithms are improved on almost all datasets. In terms of average accuracy, OSD make these outlier detection algorithms improve by 15% (AUC), 63.7% (AP).</li>
</ul>

<h3>Title: Riemannian Manifold Learning for Stackelberg Games with Neural Flow Representations</h3>
<ul>
<li><strong>Authors: </strong>Larkin Liu, Kashif Rasul, Yutong Chao, Jalal Etesami</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GT, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05498">https://arxiv.org/abs/2502.05498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05498">https://arxiv.org/pdf/2502.05498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05498]] Riemannian Manifold Learning for Stackelberg Games with Neural Flow Representations(https://arxiv.org/abs/2502.05498)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>We present a novel framework for online learning in Stackelberg general-sum games, where two agents, the leader and follower, engage in sequential turn-based interactions. At the core of this approach is a learned diffeomorphism that maps the joint action space to a smooth Riemannian manifold, referred to as the Stackelberg manifold. This mapping, facilitated by neural normalizing flows, ensures the formation of tractable isoplanar subspaces, enabling efficient techniques for online learning. By assuming linearity between the agents' reward functions on the Stackelberg manifold, our construct allows the application of standard bandit algorithms. We then provide a rigorous theoretical basis for regret minimization on convex manifolds and establish finite-time bounds on simple regret for learning Stackelberg equilibria. This integration of manifold learning into game theory uncovers a previously unrecognized potential for neural normalizing flows as an effective tool for multi-agent learning. We present empirical results demonstrating the effectiveness of our approach compared to standard baselines, with applications spanning domains such as cybersecurity and economic supply chain optimization.</li>
</ul>

<h3>Title: A Physical Coherence Benchmark for Evaluating Video Generation Models via Optical Flow-guided Frame Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yongfan Chen, Xiuwen Zhu, Tianyu Li, Hao Chen, Chunhua Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05503">https://arxiv.org/abs/2502.05503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05503">https://arxiv.org/pdf/2502.05503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05503]] A Physical Coherence Benchmark for Evaluating Video Generation Models via Optical Flow-guided Frame Prediction(https://arxiv.org/abs/2502.05503)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in video generation models demonstrate their potential as world simulators, but they often struggle with videos deviating from physical laws, a key concern overlooked by most text-to-video benchmarks. We introduce a benchmark designed specifically to assess the Physical Coherence of generated videos, PhyCoBench. Our benchmark includes 120 prompts covering 7 categories of physical principles, capturing key physical laws observable in video content. We evaluated four state-of-the-art (SoTA) T2V models on PhyCoBench and conducted manual assessments. Additionally, we propose an automated evaluation model: PhyCoPredictor, a diffusion model that generates optical flow and video frames in a cascade manner. Through a consistency evaluation comparing automated and manual sorting, the experimental results show that PhyCoPredictor currently aligns most closely with human evaluation. Therefore, it can effectively evaluate the physical coherence of videos, providing insights for future model optimization. Our benchmark, which includes physical coherence prompts, automatic evaluation tool PhyCoPredictor, and generated video dataset, will all be released on GitHub shortly.</li>
</ul>

<h3>Title: Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Zinan Lin, Tadas Baltrusaitis, Sergey Yekhanin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05505">https://arxiv.org/abs/2502.05505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05505">https://arxiv.org/pdf/2502.05505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05505]] Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model(https://arxiv.org/abs/2502.05505)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Differentially private (DP) synthetic data, which closely resembles the original private data while maintaining strong privacy guarantees, has become a key tool for unlocking the value of private data without compromising privacy. Recently, Private Evolution (PE) has emerged as a promising method for generating DP synthetic data. Unlike other training-based approaches, PE only requires access to inference APIs from foundation models, enabling it to harness the power of state-of-the-art models. However, a suitable foundation model for a specific private data domain is not always available. In this paper, we discover that the PE framework is sufficiently general to allow inference APIs beyond foundation models. Specifically, we show that simulators -- such as computer graphics-based image synthesis tools -- can also serve as effective APIs within the PE framework. This insight greatly expands the applicability of PE, enabling the use of a wide variety of domain-specific simulators for DP data synthesis. We explore the potential of this approach, named Sim-PE, in the context of image synthesis. Across three diverse simulators, Sim-PE performs well, improving the downstream classification accuracy of PE by up to 3x and reducing the FID score by up to 80%. We also show that simulators and foundation models can be easily leveraged together within the PE framework to achieve further improvements. The code is open-sourced in the Private Evolution Python library: this https URL.</li>
</ul>

<h3>Title: Do Spikes Protect Privacy? Investigating Black-Box Model Inversion Attacks in Spiking Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Hamed Poursiami, Ayana Moshruba, Maryam Parsa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05509">https://arxiv.org/abs/2502.05509</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05509">https://arxiv.org/pdf/2502.05509</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05509]] Do Spikes Protect Privacy? Investigating Black-Box Model Inversion Attacks in Spiking Neural Networks(https://arxiv.org/abs/2502.05509)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack, generative</a></li>
<li><strong>Abstract: </strong>As machine learning models become integral to security-sensitive applications, concerns over data leakage from adversarial attacks continue to rise. Model Inversion (MI) attacks pose a significant privacy threat by enabling adversaries to reconstruct training data from model outputs. While MI attacks on Artificial Neural Networks (ANNs) have been widely studied, Spiking Neural Networks (SNNs) remain largely unexplored in this context. Due to their event-driven and discrete computations, SNNs introduce fundamental differences in information processing that may offer inherent resistance to such attacks. A critical yet underexplored aspect of this threat lies in black-box settings, where attackers operate through queries without direct access to model parameters or gradients-representing a more realistic adversarial scenario in deployed systems. This work presents the first study of black-box MI attacks on SNNs. We adapt a generative adversarial MI framework to the spiking domain by incorporating rate-based encoding for input transformation and decoding mechanisms for output interpretation. Our results show that SNNs exhibit significantly greater resistance to MI attacks than ANNs, as demonstrated by degraded reconstructions, increased instability in attack convergence, and overall reduced attack effectiveness across multiple evaluation metrics. Further analysis suggests that the discrete and temporally distributed nature of SNN decision boundaries disrupts surrogate modeling, limiting the attacker's ability to approximate the target model.</li>
</ul>

<h3>Title: Evaluating Differential Privacy on Correlated Datasets Using Pointwise Maximal Leakage</h3>
<ul>
<li><strong>Authors: </strong>Sara Saeidian, Tobias J. Oechtering, Mikael Skoglund (KTH Royal Institute of Technology)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05516">https://arxiv.org/abs/2502.05516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05516">https://arxiv.org/pdf/2502.05516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05516]] Evaluating Differential Privacy on Correlated Datasets Using Pointwise Maximal Leakage(https://arxiv.org/abs/2502.05516)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Data-driven advancements significantly contribute to societal progress, yet they also pose substantial risks to privacy. In this landscape, differential privacy (DP) has become a cornerstone in privacy preservation efforts. However, the adequacy of DP in scenarios involving correlated datasets has sometimes been questioned and multiple studies have hinted at potential vulnerabilities. In this work, we delve into the nuances of applying DP to correlated datasets by leveraging the concept of pointwise maximal leakage (PML) for a quantitative assessment of information leakage. Our investigation reveals that DP's guarantees can be arbitrarily weak for correlated databases when assessed through the lens of PML. More precisely, we prove the existence of a pure DP mechanism with PML levels arbitrarily close to that of a mechanism which releases individual entries from a database without any perturbation. By shedding light on the limitations of DP on correlated datasets, our work aims to foster a deeper understanding of subtle privacy risks and highlight the need for the development of more effective privacy-preserving mechanisms tailored to diverse scenarios.</li>
</ul>

<h3>Title: Evaluation of Vision Transformers for Multimodal Image Classification: A Case Study on Brain, Lung, and Kidney Tumors</h3>
<ul>
<li><strong>Authors: </strong>√ìscar A. Mart√≠n, Javier S√°nchez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05517">https://arxiv.org/abs/2502.05517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05517">https://arxiv.org/pdf/2502.05517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05517]] Evaluation of Vision Transformers for Multimodal Image Classification: A Case Study on Brain, Lung, and Kidney Tumors(https://arxiv.org/abs/2502.05517)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Neural networks have become the standard technique for medical diagnostics, especially in cancer detection and classification. This work evaluates the performance of Vision Transformers architectures, including Swin Transformer and MaxViT, in several datasets of magnetic resonance imaging (MRI) and computed tomography (CT) scans. We used three training sets of images with brain, lung, and kidney tumors. Each dataset includes different classification labels, from brain gliomas and meningiomas to benign and malignant lung conditions and kidney anomalies such as cysts and cancers. This work aims to analyze the behavior of the neural networks in each dataset and the benefits of combining different image modalities and tumor classes. We designed several experiments by fine-tuning the models on combined and individual image modalities. The results revealed that the Swin Transformer provided high accuracy, achieving up to 99.9\% for kidney tumor classification and 99.3\% accuracy in a combined dataset. MaxViT also provided excellent results in individual datasets but performed poorly when data is combined. This research highlights the adaptability of Transformer-based models to various image modalities and features. However, challenges persist, including limited annotated data and interpretability issues. Future works will expand this study by incorporating other image modalities and enhancing diagnostic capabilities. Integrating these models across diverse datasets could mark a pivotal advance in precision medicine, paving the way for more efficient and comprehensive healthcare solutions.</li>
</ul>

<h3>Title: User Identification Procedures with Human Mutations: Formal Analysis and Pilot Study (Extended Version)</h3>
<ul>
<li><strong>Authors: </strong>Megha Quamara, Luca Vigano</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05530">https://arxiv.org/abs/2502.05530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05530">https://arxiv.org/pdf/2502.05530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05530]] User Identification Procedures with Human Mutations: Formal Analysis and Pilot Study (Extended Version)(https://arxiv.org/abs/2502.05530)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>User identification procedures, essential to the information security of systems, enable system-user interactions by exchanging data through communication links and interfaces to validate and confirm user authenticity. However, human errors can introduce vulnerabilities that may disrupt the intended identification workflow and thus impact system behavior. Therefore, ensuring the integrity of these procedures requires accounting for such erroneous behaviors. We follow a formal, human-centric approach to analyze user identification procedures by modeling them as security ceremonies and apply proven techniques for automatically analyzing such ceremonies. The approach relies on mutation rules to model potential human errors that deviate from expected interactions during the identification process, and is implemented as the X-Men tool, an extension of the Tamarin prover, which automatically generates models with human mutations and implements matching mutations to other ceremony participants for analysis. As a proof-of-concept, we consider a real-life pilot study involving an AI-driven, virtual receptionist kiosk for authenticating visitors.</li>
</ul>

<h3>Title: Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector</h3>
<ul>
<li><strong>Authors: </strong>Qirui Wu, Shizhou Zhang, De Cheng, Yinghui Xing, Di Xu, Peng Wang, Yanning Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05540">https://arxiv.org/abs/2502.05540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05540">https://arxiv.org/pdf/2502.05540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05540]] Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector(https://arxiv.org/abs/2502.05540)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Catastrophic forgetting is a critical chanllenge for incremental object detection (IOD). Most existing methods treat the detector monolithically, relying on instance replay or knowledge distillation without analyzing component-specific forgetting. Through dissection of Faster R-CNN, we reveal a key insight: Catastrophic forgetting is predominantly localized to the RoI Head classifier, while regressors retain robustness across incremental stages. This finding challenges conventional assumptions, motivating us to develop a framework termed NSGP-RePRE. Regional Prototype Replay (RePRE) mitigates classifier forgetting via replay of two types of prototypes: coarse prototypes represent class-wise semantic centers of RoI features, while fine-grained prototypes model intra-class variations. Null Space Gradient Projection (NSGP) is further introduced to eliminate prototype-feature misalignment by updating the feature extractor in directions orthogonal to subspace of old inputs via gradient projection, aligning RePRE with incremental learning dynamics. Our simple yet effective design allows NSGP-RePRE to achieve state-of-the-art performance on the Pascal VOC and MS COCO datasets under various settings. Our work not only advances IOD methodology but also provide pivotal insights for catastrophic forgetting mitigation in IOD. Code will be available soon.</li>
</ul>

<h3>Title: Democratic Training Against Universal Adversarial Perturbations</h3>
<ul>
<li><strong>Authors: </strong>Bing Sun, Jun Sun, Wei Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05542">https://arxiv.org/abs/2502.05542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05542">https://arxiv.org/pdf/2502.05542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05542]] Democratic Training Against Universal Adversarial Perturbations(https://arxiv.org/abs/2502.05542)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Despite their advances and success, real-world deep neural networks are known to be vulnerable to adversarial attacks. Universal adversarial perturbation, an input-agnostic attack, poses a serious threat for them to be deployed in security-sensitive systems. In this case, a single universal adversarial perturbation deceives the model on a range of clean inputs without requiring input-specific optimization, which makes it particularly threatening. In this work, we observe that universal adversarial perturbations usually lead to abnormal entropy spectrum in hidden layers, which suggests that the prediction is dominated by a small number of ``feature'' in such cases (rather than democratically by many features). Inspired by this, we propose an efficient yet effective defense method for mitigating UAPs called \emph{Democratic Training} by performing entropy-based model enhancement to suppress the effect of the universal adversarial perturbations in a given model. \emph{Democratic Training} is evaluated with 7 neural networks trained on 5 benchmark datasets and 5 types of state-of-the-art universal adversarial attack methods. The results show that it effectively reduces the attack success rate, improves model robustness and preserves the model accuracy on clean samples.</li>
</ul>

<h3>Title: Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Runhua Xu, Shiqi Gao, Chao Li, James Joshi, Jianxin Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05547">https://arxiv.org/abs/2502.05547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05547">https://arxiv.org/pdf/2502.05547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05547]] Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks in Federated Learning(https://arxiv.org/abs/2502.05547)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is inherently susceptible to privacy breaches and poisoning attacks. To tackle these challenges, researchers have separately devised secure aggregation mechanisms to protect data privacy and robust aggregation methods that withstand poisoning attacks. However, simultaneously addressing both concerns is challenging; secure aggregation facilitates poisoning attacks as most anomaly detection techniques require access to unencrypted local model updates, which are obscured by secure aggregation. Few recent efforts to simultaneously tackle both challenges offen depend on impractical assumption of non-colluding two-server setups that disrupt FL's topology, or three-party computation which introduces scalability issues, complicating deployment and application. To overcome this dilemma, this paper introduce a Dual Defense Federated learning (DDFed) framework. DDFed simultaneously boosts privacy protection and mitigates poisoning attacks, without introducing new participant roles or disrupting the existing FL topology. DDFed initially leverages cutting-edge fully homomorphic encryption (FHE) to securely aggregate model updates, without the impractical requirement for non-colluding two-server setups and ensures strong privacy protection. Additionally, we proposes a unique two-phase anomaly detection mechanism for encrypted model updates, featuring secure similarity computation and feedback-driven collaborative selection, with additional measures to prevent potential privacy breaches from Byzantine clients incorporated into the detection process. We conducted extensive experiments on various model poisoning attacks and FL scenarios, including both cross-device and cross-silo FL. Experiments on publicly available datasets demonstrate that DDFed successfully protects model privacy and effectively defends against model poisoning threats.</li>
</ul>

<h3>Title: 4DR P2T: 4D Radar Tensor Synthesis with Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Woo-Jin Jung, Dong-Hee Paek, Seung-Hyun Kong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05550">https://arxiv.org/abs/2502.05550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05550">https://arxiv.org/pdf/2502.05550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05550]] 4DR P2T: 4D Radar Tensor Synthesis with Point Clouds(https://arxiv.org/abs/2502.05550)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In four-dimensional (4D) Radar-based point cloud generation, clutter removal is commonly performed using the constant false alarm rate (CFAR) algorithm. However, CFAR may not fully capture the spatial characteristics of objects. To address limitation, this paper proposes the 4D Radar Point-to-Tensor (4DR P2T) model, which generates tensor data suitable for deep learning applications while minimizing measurement loss. Our method employs a conditional generative adversarial network (cGAN), modified to effectively process 4D Radar point cloud data and generate tensor data. Experimental results on the K-Radar dataset validate the effectiveness of the 4DR P2T model, achieving an average PSNR of 30.39dB and SSIM of 0.96. Additionally, our analysis of different point cloud generation methods highlights that the 5% percentile method provides the best overall performance, while the 1% percentile method optimally balances data volume reduction and performance, making it well-suited for deep learning applications.</li>
</ul>

<h3>Title: FRAMES: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy</h3>
<ul>
<li><strong>Authors: </strong>Xuemiao Zhang, Feiyu Duan, Liangyu Xu, Yongwei Zhou, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05551">https://arxiv.org/abs/2502.05551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05551">https://arxiv.org/pdf/2502.05551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05551]] FRAMES: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy(https://arxiv.org/abs/2502.05551)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have significantly advanced human language understanding and generation, with pretraining data quality and organization being crucial to their performance. Multi-stage pretraining is a promising approach, but existing methods often lack quantitative criteria for data partitioning and instead rely on intuitive heuristics. In this paper, we propose the novel Four-quadRAnt Multi-stage prEtraining Strategy (FRAMES), guided by the established principle of organizing the pretraining process into four stages to achieve significant loss reductions four times. This principle is grounded in two key findings: first, training on high Perplexity (PPL) data followed by low PPL data, and second, training on low PPL difference (PD) data followed by high PD data, both causing the loss to drop significantly twice and performance enhancements. By partitioning data into four quadrants and strategically organizing them, FRAMES achieves a remarkable 16.8% average improvement over random sampling across MMLU and CMMLU, effectively boosting LLM performance.</li>
</ul>

<h3>Title: Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions</h3>
<ul>
<li><strong>Authors: </strong>Stefan Whitaker, Colin Sisate, Marcel Windsor, Nikolai Fairweather, Tarquin Goldborough, Oskar Lindenfeld</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05553">https://arxiv.org/abs/2502.05553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05553">https://arxiv.org/pdf/2502.05553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05553]] Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions(https://arxiv.org/abs/2502.05553)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Stochastic embedding transitions introduce a probabilistic mechanism for adjusting token representations dynamically during inference, mitigating the constraints imposed through static or deterministic embeddings. A transition framework was proposed in which each token embedding evolved through probabilistic updates, ensuring adaptability while preserving semantic integrity across linguistic contexts. Empirical evaluations demonstrated that models incorporating stochastic transitions exhibited greater lexical diversity, improved generative coherence, and enhanced retention of low-frequency vocabulary, contributing to more varied sentence structures and reduced reliance on high-probability token selections. Statistical analyses of embedding drift across transformer layers indicated that representations evolved more flexibly without losing coherence, supporting the hypothesis that controlled stochasticity facilitated context-sensitive representation learning. Experimental results revealed that probabilistic embeddings introduced minor computational overhead while maintaining generative efficiency, reinforcing their feasibility in large-scale applications. A comparative study with traditional embedding approaches highlighted measurable gains in text completion accuracy, dialogue coherence, and structural complexity, confirming the effectiveness of stochastic transitions in enhancing representation expressiveness. Clustering patterns in the embedding space suggested that probabilistic updates preserved meaningful semantic groupings while enabling context-driven shifts, further validating the stability of the transition mechanism. Performance metrics indicated that stochastic transitions balanced adaptability and control, ensuring that generative outputs remained linguistically coherent without excessive randomness.</li>
</ul>

<h3>Title: Efficient Reinforcement Learning Through Adaptively Pretrained Visual Encoder</h3>
<ul>
<li><strong>Authors: </strong>Yuhan Zhang, Guoqing Ma, Guangfu Hao, Liangxuan Guo, Yang Chen, Shan Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05555">https://arxiv.org/abs/2502.05555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05555">https://arxiv.org/pdf/2502.05555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05555]] Efficient Reinforcement Learning Through Adaptively Pretrained Visual Encoder(https://arxiv.org/abs/2502.05555)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>While Reinforcement Learning (RL) agents can successfully learn to handle complex tasks, effectively generalizing acquired skills to unfamiliar settings remains a challenge. One of the reasons behind this is the visual encoders used are task-dependent, preventing effective feature extraction in different settings. To address this issue, recent studies have tried to pretrain encoders with diverse visual inputs in order to improve their performance. However, they rely on existing pretrained encoders without further exploring the impact of pretraining period. In this work, we propose APE: efficient reinforcement learning through Adaptively Pretrained visual Encoder -- a framework that utilizes adaptive augmentation strategy during the pretraining phase and extracts generalizable features with only a few interactions within the task environments in the policy learning period. Experiments are conducted across various domains, including DeepMind Control Suite, Atari Games and Memory Maze benchmarks, to verify the effectiveness of our method. Results show that mainstream RL methods, such as DreamerV3 and DrQ-v2, achieve state-of-the-art performance when equipped with APE. In addition, APE significantly improves the sampling efficiency using only visual inputs during learning, approaching the efficiency of state-based method in several control tasks. These findings demonstrate the potential of adaptive pretraining of encoder in enhancing the generalization ability and efficiency of visual RL algorithms.</li>
</ul>

<h3>Title: MMHMER:Multi-viewer and Multi-task for Handwritten Mathematical Expression Recognition</h3>
<ul>
<li><strong>Authors: </strong>Kehua Chen, Haoyang Shen, Lifan Zhong, Mingyi Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05557">https://arxiv.org/abs/2502.05557</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05557">https://arxiv.org/pdf/2502.05557</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05557]] MMHMER:Multi-viewer and Multi-task for Handwritten Mathematical Expression Recognition(https://arxiv.org/abs/2502.05557)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Handwritten Mathematical Expression Recognition (HMER) methods have made remarkable progress, with most existing HMER approaches based on either a hybrid CNN/RNN-based with GRU architecture or Transformer architectures. Each of these has its strengths and weaknesses. Leveraging different model structures as viewers and effectively integrating their diverse capabilities presents an intriguing avenue for exploration. This involves addressing two key challenges: 1) How to fuse these two methods effectively, and 2) How to achieve higher performance under an appropriate level of complexity. This paper proposes an efficient CNN-Transformer multi-viewer, multi-task approach to enhance the model's recognition performance. Our MMHMER model achieves 63.96%, 62.51%, and 65.46% ExpRate on CROHME14, CROHME16, and CROHME19, outperforming Posformer with an absolute gain of 1.28%, 1.48%, and 0.58%. The main contribution of our approach is that we propose a new multi-view, multi-task framework that can effectively integrate the strengths of CNN and Transformer. By leveraging the feature extraction capabilities of CNN and the sequence modeling capabilities of Transformer, our model can better handle the complexity of handwritten mathematical expressions.</li>
</ul>

<h3>Title: TabICL: A Tabular Foundation Model for In-Context Learning on Large Data</h3>
<ul>
<li><strong>Authors: </strong>Jingang Qu, David Holzm√ºller, Ga√´l Varoquaux, Marine Le Morvan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05564">https://arxiv.org/abs/2502.05564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05564">https://arxiv.org/pdf/2502.05564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05564]] TabICL: A Tabular Foundation Model for In-Context Learning on Large Data(https://arxiv.org/abs/2502.05564)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The long-standing dominance of gradient-boosted decision trees on tabular data is currently challenged by tabular foundation models using In-Context Learning (ICL): setting the training data as context for the test data and predicting in a single forward pass without parameter updates. While the very recent TabPFNv2 foundation model (2025) excels on tables with up to 10K samples, its alternating column- and row-wise attentions make handling large training sets computationally prohibitive. So, can ICL be effectively scaled and deliver a benefit for larger tables? We introduce TabICL, a tabular foundation model for classification, pretrained on synthetic datasets with up to 60K samples and capable of handling 500K samples on affordable resources. This is enabled by a novel two-stage architecture: a column-then-row attention mechanism to build fixed-dimensional embeddings of rows, followed by a transformer for efficient ICL. Across 200 classification datasets from the TALENT benchmark, TabICL is on par with TabPFNv2 while being systematically faster (up to 10 times), and significantly outperforms all other approaches. On 56 datasets with over 10K samples, TabICL surpasses both TabPFNv2 and CatBoost, demonstrating the potential of ICL for large data.</li>
</ul>

<h3>Title: ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyang Liu, Kangjie Bao, Jiashuo Zhang, Yunqi Liu, Yu Chen, Yuntian Liu, Yang Jiao, Tao Luo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05567">https://arxiv.org/abs/2502.05567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05567">https://arxiv.org/pdf/2502.05567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05567]] ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data(https://arxiv.org/abs/2502.05567)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autoformalization, the process of automatically translating natural language mathematics into machine-verifiable formal language, has demonstrated advancements with the progress of large language models (LLMs). However, a key obstacle to further advancements is the scarcity of paired datasets that align natural language with formal language. To address this challenge, we introduce ATLAS (Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data), an iterative data generation framework designed to produce large-scale, high-quality parallel theorem statements. With the proposed ATLAS running for 10 iterations, we construct an undergraduate-level dataset comprising 300k theorem statements and develop the ATLAS translator, achieving accuracies of 80.59% (pass@8) and 92.99% (pass@128) on ProofNet, significantly outperforming the base model (23.99% and 47.17%) and InternLM2-Math-Plus-7B (50.94% and 80.32%). Furthermore, the ATLAS translator also achieves state-of-the-art performance on both the high-school-level miniF2F dataset and the graduate-level MathQual dataset introduced in this work. The datasets, model, and code will be released to the public soon.</li>
</ul>

<h3>Title: Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Shiao Wang, Xiao Wang, Chao Wang, Liye Jin, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05574">https://arxiv.org/abs/2502.05574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05574">https://arxiv.org/pdf/2502.05574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05574]] Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark(https://arxiv.org/abs/2502.05574)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We then introduce a novel hierarchical knowledge distillation strategy that incorporates the similarity matrix, feature representation, and response map-based distillation to guide the learning of the student Transformer network. We also enhance the model's ability to capture temporal dependencies by applying the temporal Fourier transform to establish temporal relationships between video frames. We adapt the network model to specific target objects during testing via a newly proposed test-time tuning strategy to achieve high performance and flexibility in target tracking. Recognizing the limitations of existing event-based tracking datasets, which are predominantly low-resolution, we propose EventVOT, the first large-scale high-resolution event-based tracking dataset. It comprises 1141 videos spanning diverse categories such as pedestrians, vehicles, UAVs, ping pong, etc. Extensive experiments on both low-resolution (FE240hz, VisEvent, FELT), and our newly proposed high-resolution EventVOT dataset fully validated the effectiveness of our proposed method. Both the benchmark dataset and source code have been released on this https URL</li>
</ul>

<h3>Title: On Memory Construction and Retrieval for Personalized Conversational Agents</h3>
<ul>
<li><strong>Authors: </strong>Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Xufang Luo, Hao Cheng, Dongsheng Li, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Jianfeng Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05589">https://arxiv.org/abs/2502.05589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05589">https://arxiv.org/pdf/2502.05589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05589]] On Memory Construction and Retrieval for Personalized Conversational Agents(https://arxiv.org/abs/2502.05589)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>To deliver coherent and personalized experiences in long-term conversations, existing approaches typically perform retrieval augmented response generation by constructing memory banks from conversation history at either the turn-level, session-level, or through summarization techniques. In this paper, we present two key findings: (1) The granularity of memory unit matters: Turn-level, session-level, and summarization-based methods each exhibit limitations in both memory retrieval accuracy and the semantic quality of the retrieved content. (2) Prompt compression methods, such as \textit{LLMLingua-2}, can effectively serve as a denoising mechanism, enhancing memory retrieval accuracy across different granularities. Building on these insights, we propose SeCom, a method that constructs a memory bank with topical segments by introducing a conversation Segmentation model, while performing memory retrieval based on Compressed memory units. Experimental results show that SeCom outperforms turn-level, session-level, and several summarization-based methods on long-term conversation benchmarks such as LOCOMO and Long-MT-Bench+. Additionally, the proposed conversation segmentation method demonstrates superior performance on dialogue segmentation datasets such as DialSeg711, TIAGE, and SuperDialSeg.</li>
</ul>

<h3>Title: ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yongcheng Zeng, Xinyu Cui, Xuanfa Jin, Guoqing Liu, Zexu Sun, Quan He, Dong Li, Ning Yang, Jianye Hao, Haifeng Zhang, Jun Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05605">https://arxiv.org/abs/2502.05605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05605">https://arxiv.org/pdf/2502.05605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05605]] ARIES: Stimulating Self-Refinement of Large Language Models by Iterative Preference Optimization(https://arxiv.org/abs/2502.05605)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions. However, even the most advanced models often face challenges in improving their outputs. In this paper, we explore how to cultivate LLMs with the self-refinement capability through iterative preference training, and how this ability can be leveraged to improve model performance during inference. To this end, we introduce a novel post-training and inference framework, called ARIES: Adaptive Refinement and Iterative Enhancement Structure. This method iteratively performs preference training and self-refinement-based data collection. During training, ARIES strengthen the model's direct question-answering capability while simultaneously unlocking its self-refinement potential. During inference, ARIES harnesses this self-refinement capability to generate a series of progressively refined responses, which are then filtered using either the Reward Model Scoring or a simple yet effective Rule-Based Selection mechanism, specifically tailored to our approach, to construct a dataset for the next round of preference training. Experimental results demonstrate the remarkable performance of ARIES. When applied to the Llama-3.1-8B model and under the self-refinement setting, ARIES surpasses powerful models such as GPT-4o, achieving 62.3% length-controlled (LC) and a 63.3% raw win rates on AlpacaEval 2, outperforming Iterative DPO by 27.8% and 35.5% respectively, as well as a 50.3% win rate on Arena-Hard, surpassing Iterative DPO by 26.6%. Furthermore, ARIES consistently enhances performance on mathematical reasoning tasks like GSM8K and MATH.</li>
</ul>

<h3>Title: FreeBlend: Advancing Concept Blending with Staged Feedback-Driven Interpolation Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yufan Zhou, Haoyu Shen, Huan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05606">https://arxiv.org/abs/2502.05606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05606">https://arxiv.org/pdf/2502.05606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05606]] FreeBlend: Advancing Concept Blending with Staged Feedback-Driven Interpolation Diffusion(https://arxiv.org/abs/2502.05606)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Concept blending is a promising yet underexplored area in generative models. While recent approaches, such as embedding mixing and latent modification based on structural sketches, have been proposed, they often suffer from incompatible semantic information and discrepancies in shape and appearance. In this work, we introduce FreeBlend, an effective, training-free framework designed to address these challenges. To mitigate cross-modal loss and enhance feature detail, we leverage transferred image embeddings as conditional inputs. The framework employs a stepwise increasing interpolation strategy between latents, progressively adjusting the blending ratio to seamlessly integrate auxiliary features. Additionally, we introduce a feedback-driven mechanism that updates the auxiliary latents in reverse order, facilitating global blending and preventing rigid or unnatural outputs. Extensive experiments demonstrate that our method significantly improves both the semantic coherence and visual quality of blended images, yielding compelling and coherent results.</li>
</ul>

<h3>Title: Lossless Acceleration of Large Language Models with Hierarchical Drafting based on Temporal Locality in Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Sukmin Cho, Sangjin Choi, Taeho Hwang, Jeongyeon Seo, Soyeong Jeong, Huije Lee, Hoyun Song, Jong C. Park, Youngjin Kwon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05609">https://arxiv.org/abs/2502.05609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05609">https://arxiv.org/pdf/2502.05609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05609]] Lossless Acceleration of Large Language Models with Hierarchical Drafting based on Temporal Locality in Speculative Decoding(https://arxiv.org/abs/2502.05609)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Accelerating inference in Large Language Models (LLMs) is critical for real-time interactions, as they have been widely incorporated into real-world services. Speculative decoding, a fully algorithmic solution, has gained attention for improving inference speed by drafting and verifying tokens, thereby generating multiple tokens in a single forward pass. However, current drafting strategies usually require significant fine-tuning or have inconsistent performance across tasks. To address these challenges, we propose Hierarchy Drafting (HD), a novel lossless drafting approach that organizes various token sources into multiple databases in a hierarchical framework based on temporal locality. In the drafting step, HD sequentially accesses multiple databases to obtain draft tokens from the highest to the lowest locality, ensuring consistent acceleration across diverse tasks and minimizing drafting latency. Our experiments on Spec-Bench using LLMs with 7B and 13B parameters demonstrate that HD outperforms existing database drafting methods, achieving robust inference speedups across model sizes, tasks, and temperatures.</li>
</ul>

<h3>Title: Towards Sustainable NLP: Insights from Benchmarking Inference Energy in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Soham Poddar, Paramita Koley, Janardan Misra, Niloy Ganguly, Saptarshi Ghosh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05610">https://arxiv.org/abs/2502.05610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05610">https://arxiv.org/pdf/2502.05610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05610]] Towards Sustainable NLP: Insights from Benchmarking Inference Energy in Large Language Models(https://arxiv.org/abs/2502.05610)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly recognized for their exceptional generative capabilities and versatility across various tasks. However, the high inference costs associated with these models have not received adequate attention, particularly when compared to the focus on training costs in existing research. In response to this gap, our study conducts a comprehensive benchmarking of LLM inference energy across a wide range of NLP tasks, where we analyze the impact of different models, tasks, prompts, and system-related factors on inference energy. Specifically, our experiments reveal several interesting insights, including strong correlation of inference energy with output token length and response time. Also, we find that quantization and optimal batch sizes, along with targeted prompt phrases, can significantly reduce energy usage. This study is the first to thoroughly benchmark LLM inference across such a diverse range of aspects, providing insights and offering several recommendations for improving energy efficiency in model deployment.</li>
</ul>

<h3>Title: XiHeFusion: Harnessing Large Language Models for Science Communication in Nuclear Fusion</h3>
<ul>
<li><strong>Authors: </strong>Xiao Wang, Qingquan Yang, Fuling Wang, Qiang Chen, Wentao Wu, Yu Jin, Jingtao Jiang, Liye Jin, Bo Jiang, Dengdi Sun, Wanli Lv, Meiwen Chen, Zehua Chen, Guosheng Xu, Jin Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05615">https://arxiv.org/abs/2502.05615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05615">https://arxiv.org/pdf/2502.05615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05615]] XiHeFusion: Harnessing Large Language Models for Science Communication in Nuclear Fusion(https://arxiv.org/abs/2502.05615)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Nuclear fusion is one of the most promising ways for humans to obtain infinite energy. Currently, with the rapid development of artificial intelligence, the mission of nuclear fusion has also entered a critical period of its development. How to let more people to understand nuclear fusion and join in its research is one of the effective means to accelerate the implementation of fusion. This paper proposes the first large model in the field of nuclear fusion, XiHeFusion, which is obtained through supervised fine-tuning based on the open-source large model Qwen2.5-14B. We have collected multi-source knowledge about nuclear fusion tasks to support the training of this model, including the common crawl, eBooks, arXiv, dissertation, etc. After the model has mastered the knowledge of the nuclear fusion field, we further used the chain of thought to enhance its logical reasoning ability, making XiHeFusion able to provide more accurate and logical answers. In addition, we propose a test questionnaire containing 180+ questions to assess the conversational ability of this science popularization large model. Extensive experimental results show that our nuclear fusion dialogue model, XiHeFusion, can perform well in answering science popularization knowledge. The pre-trained XiHeFusion model is released on this https URL.</li>
</ul>

<h3>Title: Training-Free Constrained Generation With Stable Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Stefano Zampini, Jacob Christopher, Luca Oneto, Davide Anguita, Ferdinando Fioretto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05625">https://arxiv.org/abs/2502.05625</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05625">https://arxiv.org/pdf/2502.05625</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05625]] Training-Free Constrained Generation With Stable Diffusion Models(https://arxiv.org/abs/2502.05625)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Stable diffusion models represent the state-of-the-art in data synthesis across diverse domains and hold transformative potential for applications in science and engineering, e.g., by facilitating the discovery of novel solutions and simulating systems that are computationally intractable to model explicitly. However, their current utility in these fields is severely limited by an inability to enforce strict adherence to physical laws and domain-specific constraints. Without this grounding, the deployment of such models in critical applications, ranging from material science to safety-critical systems, remains impractical. This paper addresses this fundamental limitation by proposing a novel approach to integrate stable diffusion models with constrained optimization frameworks, enabling them to generate outputs that satisfy stringent physical and functional requirements. We demonstrate the effectiveness of this approach through material science experiments requiring adherence to precise morphometric properties, inverse design problems involving the generation of stress-strain responses using video generation with a simulator in the loop, and safety settings where outputs must avoid copyright infringement.</li>
</ul>

<h3>Title: AnyEdit: Edit Any Knowledge Encoded in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Houcheng Jiang, Junfeng Fang, Ningyu Zhang, Guojun Ma, Mingyang Wan, Xiang Wang, Xiangnan He, Tat-seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05628">https://arxiv.org/abs/2502.05628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05628">https://arxiv.org/pdf/2502.05628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05628]] AnyEdit: Edit Any Knowledge Encoded in Language Models(https://arxiv.org/abs/2502.05628)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often produce incorrect or outdated information, necessitating efficient and precise knowledge updates. Current model editing methods, however, struggle with long-form knowledge in diverse formats, such as poetry, code snippets, and mathematical derivations. These limitations arise from their reliance on editing a single token's hidden state, a limitation we term "efficacy barrier". To solve this, we propose AnyEdit, a new autoregressive editing paradigm. It decomposes long-form knowledge into sequential chunks and iteratively edits the key token in each chunk, ensuring consistent and accurate outputs. Theoretically, we ground AnyEdit in the Chain Rule of Mutual Information, showing its ability to update any knowledge within LLMs. Empirically, it outperforms strong baselines by 21.5% on benchmarks including UnKEBench, AKEW, and our new EditEverything dataset for long-form diverse-formatted knowledge. Additionally, AnyEdit serves as a plug-and-play framework, enabling current editing methods to update knowledge with arbitrary length and format, significantly advancing the scope and practicality of LLM knowledge editing.</li>
</ul>

<h3>Title: TrackDiffuser: Nearly Model-Free Bayesian Filtering with Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Yangguang He, Wenhao Li, Minzhe Li, Juan Zhang, Xiangfeng Wang, Bo Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05629">https://arxiv.org/abs/2502.05629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05629">https://arxiv.org/pdf/2502.05629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05629]] TrackDiffuser: Nearly Model-Free Bayesian Filtering with Diffusion Model(https://arxiv.org/abs/2502.05629)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>State estimation remains a fundamental challenge across numerous domains, from autonomous driving, aircraft tracking to quantum system control. Although Bayesian filtering has been the cornerstone solution, its classical model-based paradigm faces two major limitations: it struggles with inaccurate state space model (SSM) and requires extensive prior knowledge of noise characteristics. We present TrackDiffuser, a generative framework addressing both challenges by reformulating Bayesian filtering as a conditional diffusion model. Our approach implicitly learns system dynamics from data to mitigate the effects of inaccurate SSM, while simultaneously circumventing the need for explicit measurement models and noise priors by establishing a direct relationship between measurements and states. Through an implicit predict-and-update mechanism, TrackDiffuser preserves the interpretability advantage of traditional model-based filtering methods. Extensive experiments demonstrate that our framework substantially outperforms both classical and contemporary hybrid methods, especially in challenging non-linear scenarios involving non-Gaussian noises. Notably, TrackDiffuser exhibits remarkable robustness to SSM inaccuracies, offering a practical solution for real-world state estimation problems where perfect models and prior knowledge are unavailable.</li>
</ul>

<h3>Title: Adversarial Machine Learning: Attacks, Defenses, and Open Challenges</h3>
<ul>
<li><strong>Authors: </strong>Pranav K Jha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05637">https://arxiv.org/abs/2502.05637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05637">https://arxiv.org/pdf/2502.05637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05637]] Adversarial Machine Learning: Attacks, Defenses, and Open Challenges(https://arxiv.org/abs/2502.05637)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial Machine Learning (AML) addresses vulnerabilities in AI systems where adversaries manipulate inputs or training data to degrade performance. This article provides a comprehensive analysis of evasion and poisoning attacks, formalizes defense mechanisms with mathematical rigor, and discusses the challenges of implementing robust solutions in adaptive threat models. Additionally, it highlights open challenges in certified robustness, scalability, and real-world deployment.</li>
</ul>

<h3>Title: ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports</h3>
<ul>
<li><strong>Authors: </strong>Aynur Guluzade, Naguib Heiba, Zeyd Boukhers, Florim Hamiti, Jahid Hasan Polash, Yehya Mohamad, Carlos A Velasco</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05638">https://arxiv.org/abs/2502.05638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05638">https://arxiv.org/pdf/2502.05638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05638]] ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports(https://arxiv.org/abs/2502.05638)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Europe's healthcare systems require enhanced interoperability and digitalization, driving a demand for innovative solutions to process legacy clinical data. This paper presents the results of our project, which aims to leverage Large Language Models (LLMs) to extract structured information from unstructured clinical reports, focusing on patient history, diagnoses, treatments, and other predefined categories. We developed a workflow with a user interface and evaluated LLMs of varying sizes through prompting strategies and fine-tuning. Our results show that fine-tuned smaller models match or surpass larger counterparts in performance, offering efficiency for resource-limited settings. A new dataset of 60,000 annotated English clinical summaries and 24,000 German translations was validated with automated and manual checks. The evaluations used ROUGE, BERTScore, and entity-level metrics. The work highlights the approach's viability and outlines future improvements.</li>
</ul>

<h3>Title: KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy</h3>
<ul>
<li><strong>Authors: </strong>Hyunjong Kim, Suyeon Lee, Yeongjae Cho, Eunseo Ryu, Yohan Jo, Suran Seong, Sungzoon Cho</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05651">https://arxiv.org/abs/2502.05651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05651">https://arxiv.org/pdf/2502.05651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05651]] KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy(https://arxiv.org/abs/2502.05651)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>The increasing demand for mental health services has led to the rise of AI-driven mental health chatbots, though challenges related to privacy, data collection, and expertise persist. Motivational Interviewing (MI) is gaining attention as a theoretical basis for boosting expertise in the development of these chatbots. However, existing datasets are showing limitations for training chatbots, leading to a substantial demand for publicly available resources in the field of MI and psychotherapy. These challenges are even more pronounced in non-English languages, where they receive less attention. In this paper, we propose a novel framework that simulates MI sessions enriched with the expertise of professional therapists. We train an MI forecaster model that mimics the behavioral choices of professional therapists and employ Large Language Models (LLMs) to generate utterances through prompt engineering. Then, we present KMI, the first synthetic dataset theoretically grounded in MI, containing 1,000 high-quality Korean Motivational Interviewing dialogues. Through an extensive expert evaluation of the generated dataset and the dialogue model trained on it, we demonstrate the quality, expertise, and practicality of KMI. We also introduce novel metrics derived from MI theory in order to evaluate dialogues from the perspective of MI.</li>
</ul>

<h3>Title: Flowing Through Layers: A Continuous Dynamical Systems Perspective on Transformers</h3>
<ul>
<li><strong>Authors: </strong>Jacob Fein-Ashley</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05656">https://arxiv.org/abs/2502.05656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05656">https://arxiv.org/pdf/2502.05656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05656]] Flowing Through Layers: A Continuous Dynamical Systems Perspective on Transformers(https://arxiv.org/abs/2502.05656)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We show that the standard discrete update rule of transformer layers can be naturally interpreted as a forward Euler discretization of a continuous dynamical system. Our Transformer Flow Approximation Theorem demonstrates that, under standard Lipschitz continuity assumptions, token representations converge uniformly to the unique solution of an ODE as the number of layers grows. Moreover, if the underlying mapping satisfies a one-sided Lipschitz condition with a negative constant, the resulting dynamics are contractive, causing perturbations to decay exponentially across layers. Beyond clarifying the empirical stability and expressivity of transformer models, these insights link transformer updates to a broader iterative reasoning framework, suggesting new avenues for accelerated convergence and architectural innovations inspired by dynamical systems theory.</li>
</ul>

<h3>Title: Evaluating Vision-Language Models for Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Sree Bhattacharyya, James Z. Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05660">https://arxiv.org/abs/2502.05660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05660">https://arxiv.org/pdf/2502.05660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05660]] Evaluating Vision-Language Models for Emotion Recognition(https://arxiv.org/abs/2502.05660)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (VLMs) have achieved unprecedented success in several objective multimodal reasoning tasks. However, to further enhance their capabilities of empathetic and effective communication with humans, improving how VLMs process and understand emotions is crucial. Despite significant research attention on improving affective understanding, there is a lack of detailed evaluations of VLMs for emotion-related tasks, which can potentially help inform downstream fine-tuning efforts. In this work, we present the first comprehensive evaluation of VLMs for recognizing evoked emotions from images. We create a benchmark for the task of evoked emotion recognition and study the performance of VLMs for this task, from perspectives of correctness and robustness. Through several experiments, we demonstrate important factors that emotion recognition performance depends on, and also characterize the various errors made by VLMs in the process. Finally, we pinpoint potential causes for errors through a human evaluation study. We use our experimental results to inform recommendations for the future of emotion research in the context of VLMs.</li>
</ul>

<h3>Title: CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging</h3>
<ul>
<li><strong>Authors: </strong>Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05664">https://arxiv.org/abs/2502.05664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05664">https://arxiv.org/pdf/2502.05664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05664]] CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging(https://arxiv.org/abs/2502.05664)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have made significant strides in code generation and problem solving. Current approaches employ external tool-based iterative debuggers that use compiler or other tool-based runtime feedback to refine coarse programs generated by various methods. However, the effectiveness of these approaches heavily relies on the quality of the initial code generation, which remains an open challenge. In this paper, we introduce CodeSim, a novel multi-agent code generation framework that comprehensively addresses the stages of program synthesis-planning, coding, and debugging-through a human-like perception approach. As human verifies their understanding of any algorithms through visual simulation, CodeSim uniquely features a method of plan verification and internal debugging through the step-by-step simulation of input/output. Extensive experiments across seven challenging competitive problem-solving and program synthesis benchmarks demonstrate CodeSim's remarkable code generation capabilities. Our framework achieves new state-of-the-art (pass@1) results-(HumanEval 95.1%, MBPP 90.7%, APPS 22%, and CodeContests 29.1%). Furthermore, our method shows potential for even greater enhancement when cascaded with external debuggers. To facilitate further research and development in this area, we have open-sourced our framework in this link (this https URL).</li>
</ul>

<h3>Title: Rigid Body Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Aravind Ramakrishnan, David I.W. Levin, Alec Jacobson</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05669">https://arxiv.org/abs/2502.05669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05669">https://arxiv.org/pdf/2502.05669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05669]] Rigid Body Adversarial Attacks(https://arxiv.org/abs/2502.05669)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Due to their performance and simplicity, rigid body simulators are often used in applications where the objects of interest can considered very stiff. However, no material has infinite stiffness, which means there are potentially cases where the non-zero compliance of the seemingly rigid object can cause a significant difference between its trajectories when simulated in a rigid body or deformable simulator. Similarly to how adversarial attacks are developed against image classifiers, we propose an adversarial attack against rigid body simulators. In this adversarial attack, we solve an optimization problem to construct perceptually rigid adversarial objects that have the same collision geometry and moments of mass to a reference object, so that they behave identically in rigid body simulations but maximally different in more accurate deformable simulations. We demonstrate the validity of our method by comparing simulations of several examples in commercially available simulators.</li>
</ul>

<h3>Title: Language Models Largely Exhibit Human-like Constituent Ordering Preferences</h3>
<ul>
<li><strong>Authors: </strong>Ada Defne Tur, Gaurav Kamath, Siva Reddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05670">https://arxiv.org/abs/2502.05670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05670">https://arxiv.org/pdf/2502.05670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05670]] Language Models Largely Exhibit Human-like Constituent Ordering Preferences(https://arxiv.org/abs/2502.05670)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Though English sentences are typically inflexible vis-√†-vis word order, constituents often show far more variability in ordering. One prominent theory presents the notion that constituent ordering is directly correlated with constituent weight: a measure of the constituent's length or complexity. Such theories are interesting in the context of natural language processing (NLP), because while recent advances in NLP have led to significant gains in the performance of large language models (LLMs), much remains unclear about how these models process language, and how this compares to human language processing. In particular, the question remains whether LLMs display the same patterns with constituent movement, and may provide insights into existing theories on when and how the shift occurs in human language. We compare a variety of LLMs with diverse properties to evaluate broad LLM performance on four types of constituent movement: heavy NP shift, particle movement, dative alternation, and multiple PPs. Despite performing unexpectedly around particle movement, LLMs generally align with human preferences around constituent ordering.</li>
</ul>

<h3>Title: The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions</h3>
<ul>
<li><strong>Authors: </strong>Ping Liu, Jiawei Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05673">https://arxiv.org/abs/2502.05673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05673">https://arxiv.org/pdf/2502.05673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05673]] The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions(https://arxiv.org/abs/2502.05673)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Dataset distillation, which condenses large-scale datasets into compact synthetic representations, has emerged as a critical solution for training modern deep learning models efficiently. While prior surveys focus on developments before 2023, this work comprehensively reviews recent advances, emphasizing scalability to large-scale datasets such as ImageNet-1K and ImageNet-21K. We categorize progress into a few key methodologies: trajectory matching, gradient matching, distribution matching, scalable generative approaches, and decoupling optimization mechanisms. As a comprehensive examination of recent dataset distillation advances, this survey highlights breakthrough innovations: the SRe2L framework for efficient and effective condensation, soft label strategies that significantly enhance model accuracy, and lossless distillation techniques that maximize compression while maintaining performance. Beyond these methodological advancements, we address critical challenges, including robustness against adversarial and backdoor attacks, effective handling of non-IID data distributions. Additionally, we explore emerging applications in video and audio processing, multi-modal learning, medical imaging, and scientific computing, highlighting its domain versatility. By offering extensive performance comparisons and actionable research directions, this survey equips researchers and practitioners with practical insights to advance efficient and generalizable dataset distillation, paving the way for future innovations.</li>
</ul>

<h3>Title: Federated Learning with Reservoir State Analysis for Time Series Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Keigo Nogami, Tamura Hiroto, Gouhei Tanaka</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05679">https://arxiv.org/abs/2502.05679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05679">https://arxiv.org/pdf/2502.05679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05679]] Federated Learning with Reservoir State Analysis for Time Series Anomaly Detection(https://arxiv.org/abs/2502.05679)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>With a growing data privacy concern, federated learning has emerged as a promising framework to train machine learning models without sharing locally distributed data. In federated learning, local model training by multiple clients and model integration by a server are repeated only through model parameter sharing. Most existing federated learning methods assume training deep learning models, which are often computationally demanding. To deal with this issue, we propose federated learning methods with reservoir state analysis to seek computational efficiency and data privacy protection simultaneously. Specifically, our method relies on Mahalanobis Distance of Reservoir States (MD-RS) method targeting time series anomaly detection, which learns a distribution of reservoir states for normal inputs and detects anomalies based on a deviation from the learned distribution. Iterative updating of statistical parameters in the MD-RS enables incremental federated learning (IncFed MD-RS). We evaluate the performance of IncFed MD-RS using benchmark datasets for time series anomaly detection. The results show that IncFed MD-RS outperforms other federated learning methods with deep learning and reservoir computing models particularly when clients' data are relatively short and heterogeneous. We demonstrate that IncFed MD-RS is robust against reduced sample data compared to other methods. We also show that the computational cost of IncFed MD-RS can be reduced by subsampling from the reservoir states without performance degradation. The proposed method is beneficial especially in anomaly detection applications where computational efficiency, algorithm simplicity, and low communication cost are required.</li>
</ul>

<h3>Title: Machine Unlearning via Information Theoretic Regularization</h3>
<ul>
<li><strong>Authors: </strong>Shizhou Xu, Thomas Strohmer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05684">https://arxiv.org/abs/2502.05684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05684">https://arxiv.org/pdf/2502.05684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05684]] Machine Unlearning via Information Theoretic Regularization(https://arxiv.org/abs/2502.05684)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>How can we effectively remove or "unlearn" undesirable information, such as specific features or individual data points, from a learning outcome while minimizing utility loss and ensuring rigorous guarantees? We introduce a mathematical framework based on information-theoretic regularization to address both feature and data point unlearning. For feature unlearning, we derive a unified solution that simultaneously optimizes diverse learning objectives, including entropy, conditional entropy, KL-divergence, and the energy of conditional probability. For data point unlearning, we first propose a novel definition that serves as a practical condition for unlearning via retraining, is easy to verify, and aligns with the principles of differential privacy from an inference perspective. Then, we provide provable guarantees for our framework on data point unlearning. By combining flexibility in learning objectives with simplicity in regularization design, our approach is highly adaptable and practical for a wide range of machine learning and AI applications.</li>
</ul>

<h3>Title: Mobile Application Threats and Security</h3>
<ul>
<li><strong>Authors: </strong>Timur Mirzoev, Mark Miller, Shamimara Lasker, Michael Brannon</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05685">https://arxiv.org/abs/2502.05685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05685">https://arxiv.org/pdf/2502.05685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05685]] Mobile Application Threats and Security(https://arxiv.org/abs/2502.05685)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>The movement to mobile computing solutions provides flexibility to different users whether it is a business user, a student, or even providing entertainment to children and adults of all ages. Due to these emerging technologies mobile users are unable to safeguard private information in a very effective way and cybercrimes are increasing day by day. This manuscript will focus on security vulnerabilities in the mobile computing industry, especially focusing on tablets and smart phones. This study will dive into current security threats for the Android & Apple iOS market, exposing security risks and threats that the novice or average user may not be aware of. The purpose of this study is to analyze current security risks and threats, and provide solutions that may be deployed to protect against such threats.</li>
</ul>

<h3>Title: Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT</h3>
<ul>
<li><strong>Authors: </strong>Shaoshuai Du, Yiyi Tao, Yixian Shen, Hang Zhang, Yanxin Shen, Xinyu Qiu, Chuanqi Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05694">https://arxiv.org/abs/2502.05694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05694">https://arxiv.org/pdf/2502.05694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05694]] Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT(https://arxiv.org/abs/2502.05694)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This study investigates the performance of various large language models (LLMs) on zero-shot end-to-end relation extraction (RE) in Chinese, a task that integrates entity recognition and relation extraction without requiring annotated data. While LLMs show promise for RE, most prior work focuses on English or assumes pre-annotated entities, leaving their effectiveness in Chinese RE largely unexplored. To bridge this gap, we evaluate ChatGPT, Gemini, and LLaMA based on accuracy, efficiency, and adaptability. ChatGPT demonstrates the highest overall performance, balancing precision and recall, while Gemini achieves the fastest inference speed, making it suitable for real-time applications. LLaMA underperforms in both accuracy and latency, highlighting the need for further adaptation. Our findings provide insights into the strengths and limitations of LLMs for zero-shot Chinese RE, shedding light on trade-offs between accuracy and efficiency. This study serves as a foundation for future research aimed at improving LLM adaptability to complex linguistic tasks in Chinese NLP.</li>
</ul>

<h3>Title: Context information can be more important than reasoning for time series forecasting with a large language model</h3>
<ul>
<li><strong>Authors: </strong>Janghoon Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05699">https://arxiv.org/abs/2502.05699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05699">https://arxiv.org/pdf/2502.05699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05699]] Context information can be more important than reasoning for time series forecasting with a large language model(https://arxiv.org/abs/2502.05699)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the evolution of large language models (LLMs), there is growing interest in leveraging LLMs for time series tasks. In this paper, we explore the characteristics of LLMs for time series forecasting by considering various existing and proposed prompting techniques. Forecasting for both short and long time series was evaluated. Our findings indicate that no single prompting method is universally applicable. It was also observed that simply providing proper context information related to the time series, without additional reasoning prompts, can achieve performance comparable to the best-performing prompt for each case. From this observation, it is expected that providing proper context information can be more crucial than a prompt for specific reasoning in time series forecasting. Several weaknesses in prompting for time series forecasting were also identified. First, LLMs often fail to follow the procedures described by the prompt. Second, when reasoning steps involve simple algebraic calculations with several operands, LLMs often fail to calculate accurately. Third, LLMs sometimes misunderstand the semantics of prompts, resulting in incomplete responses.</li>
</ul>

<h3>Title: TOKON: TOKenization-Optimized Normalization for time series analysis with a large language model</h3>
<ul>
<li><strong>Authors: </strong>Janghoon Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05701">https://arxiv.org/abs/2502.05701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05701">https://arxiv.org/pdf/2502.05701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05701]] TOKON: TOKenization-Optimized Normalization for time series analysis with a large language model(https://arxiv.org/abs/2502.05701)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models have rapidly evolved towards general artificial intelligence, their versatility in analyzing time series data remains limited. To address this limitation, we propose a novel normalization technique that considers the inherent nature of tokenization. The proposed Tokenization-Optimized Normalization (TOKON) simplifies time series data by representing each element with a single token, effectively reducing the number of tokens by 2 to 3 times. Additionally, we introduce a novel prompt for time series forecasting, termed Time Series Forecasting with Care (TFSC), to further enhance forecasting performance. Experimental results demonstrate that TOKON improves root mean square error (RMSE) for multi-step forecasting by approximately 7% to 18%, depending on the dataset and prompting method. Furthermore, TFSC, when used in conjunction with TOKON, shows additional improvements in forecasting accuracy for certain datasets</li>
</ul>

<h3>Title: Flow-based Conformal Prediction for Multi-dimensional Time Series</h3>
<ul>
<li><strong>Authors: </strong>Junghwan Lee, Chen Xu, Yao Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05709">https://arxiv.org/abs/2502.05709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05709">https://arxiv.org/pdf/2502.05709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05709]] Flow-based Conformal Prediction for Multi-dimensional Time Series(https://arxiv.org/abs/2502.05709)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Conformal prediction for time series presents two key challenges: (1) leveraging sequential correlations in features and non-conformity scores and (2) handling multi-dimensional outcomes. We propose a novel conformal prediction method to address these two key challenges by integrating Transformer and Normalizing Flow. Specifically, the Transformer encodes the historical context of time series, and normalizing flow learns the transformation from the base distribution to the distribution of non-conformity scores conditioned on the encoded historical context. This enables the construction of prediction regions by transforming samples from the base distribution using the learned conditional flow. We ensure the marginal coverage by defining the prediction regions as sets in the transformed space that correspond to a predefined probability mass in the base distribution. The model is trained end-to-end by Flow Matching, avoiding the need for computationally intensive numerical solutions of ordinary differential equations. We demonstrate that our proposed method achieves smaller prediction regions compared to the baselines while satisfying the desired coverage through comprehensive experiments using simulated and real-world time series datasets.</li>
</ul>

<h3>Title: SSDD-GAN: Single-Step Denoising Diffusion GAN for Cochlear Implant Surgical Scene Completion</h3>
<ul>
<li><strong>Authors: </strong>Yike Zhang, Eduardo Davalos, Jack Noble</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05710">https://arxiv.org/abs/2502.05710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05710">https://arxiv.org/pdf/2502.05710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05710]] SSDD-GAN: Single-Step Denoising Diffusion GAN for Cochlear Implant Surgical Scene Completion(https://arxiv.org/abs/2502.05710)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent deep learning-based image completion methods, including both inpainting and outpainting, have demonstrated promising results in restoring corrupted images by effectively filling various missing regions. Among these, Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs) have been employed as key generative image completion approaches, excelling in the field of generating high-quality restorations with reduced artifacts and improved fine details. In previous work, we developed a method aimed at synthesizing views from novel microscope positions for mastoidectomy surgeries; however, that approach did not have the ability to restore the surrounding surgical scene environment. In this paper, we propose an efficient method to complete the surgical scene of the synthetic postmastoidectomy dataset. Our approach leverages self-supervised learning on real surgical datasets to train a Single-Step Denoising Diffusion-GAN (SSDD-GAN), combining the advantages of diffusion models with the adversarial optimization of GANs for improved Structural Similarity results of 6%. The trained model is then directly applied to the synthetic postmastoidectomy dataset using a zero-shot approach, enabling the generation of realistic and complete surgical scenes without the need for explicit ground-truth labels from the synthetic postmastoidectomy dataset. This method addresses key limitations in previous work, offering a novel pathway for full surgical microscopy scene completion and enhancing the usability of the synthetic postmastoidectomy dataset in surgical preoperative planning and intraoperative navigation.</li>
</ul>

<h3>Title: Extended Histogram-based Outlier Score (EHBOS)</h3>
<ul>
<li><strong>Authors: </strong>Tanvir Islam</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05719">https://arxiv.org/abs/2502.05719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05719">https://arxiv.org/pdf/2502.05719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05719]] Extended Histogram-based Outlier Score (EHBOS)(https://arxiv.org/abs/2502.05719)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Histogram-Based Outlier Score (HBOS) is a widely used outlier or anomaly detection method known for its computational efficiency and simplicity. However, its assumption of feature independence limits its ability to detect anomalies in datasets where interactions between features are critical. In this paper, we propose the Extended Histogram-Based Outlier Score (EHBOS), which enhances HBOS by incorporating two-dimensional histograms to capture dependencies between feature pairs. This extension allows EHBOS to identify contextual and dependency-driven anomalies that HBOS fails to detect. We evaluate EHBOS on 17 benchmark datasets, demonstrating its effectiveness and robustness across diverse anomaly detection scenarios. EHBOS outperforms HBOS on several datasets, particularly those where feature interactions are critical in defining the anomaly structure, achieving notable improvements in ROC AUC. These results highlight that EHBOS can be a valuable extension to HBOS, with the ability to model complex feature dependencies. EHBOS offers a powerful new tool for anomaly detection, particularly in datasets where contextual or relational anomalies play a significant role.</li>
</ul>

<h3>Title: Explainable and Class-Revealing Signal Feature Extraction via Scattering Transform and Constrained Zeroth-Order Optimization</h3>
<ul>
<li><strong>Authors: </strong>Naoki Saito, David Weber</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05722">https://arxiv.org/abs/2502.05722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05722">https://arxiv.org/pdf/2502.05722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05722]] Explainable and Class-Revealing Signal Feature Extraction via Scattering Transform and Constrained Zeroth-Order Optimization(https://arxiv.org/abs/2502.05722)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We propose a new method to extract discriminant and explainable features from a particular machine learning model, i.e., a combination of the scattering transform and the multiclass logistic regression. Although this model is well-known for its ability to learn various signal classes with high classification rate, it remains elusive to understand why it can generate such successful classification, mainly due to the nonlinearity of the scattering transform. In order to uncover the meaning of the scattering transform coefficients selected by the multiclass logistic regression (with the Lasso penalty), we adopt zeroth-order optimization algorithms to search an input pattern that maximizes the class probability of a class of interest given the learned model. In order to do so, it turns out that imposing sparsity and smoothness of input patterns is important. We demonstrate the effectiveness of our proposed method using a couple of synthetic time-series classification problems.</li>
</ul>

<h3>Title: Rethinking Link Prediction for Directed Graphs</h3>
<ul>
<li><strong>Authors: </strong>Mingguo He, Yuhe Guo, Yanping Zheng, Zhewei Wei, Stephan G√ºnnemann, Xiaokui Xiao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05724">https://arxiv.org/abs/2502.05724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05724">https://arxiv.org/pdf/2502.05724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05724]] Rethinking Link Prediction for Directed Graphs(https://arxiv.org/abs/2502.05724)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Link prediction for directed graphs is a crucial task with diverse real-world applications. Recent advances in embedding methods and Graph Neural Networks (GNNs) have shown promising improvements. However, these methods often lack a thorough analysis of embedding expressiveness and suffer from ineffective benchmarks for a fair evaluation. In this paper, we propose a unified framework to assess the expressiveness of existing methods, highlighting the impact of dual embeddings and decoder design on performance. To address limitations in current experimental setups, we introduce DirLinkBench, a robust new benchmark with comprehensive coverage and standardized evaluation. The results show that current methods struggle to achieve strong performance on the new benchmark, while DiGAE outperforms others overall. We further revisit DiGAE theoretically, showing its graph convolution aligns with GCN on an undirected bipartite graph. Inspired by these insights, we propose a novel spectral directed graph auto-encoder SDGAE that achieves SOTA results on DirLinkBench. Finally, we analyze key factors influencing directed link prediction and highlight open challenges.</li>
</ul>

<h3>Title: Improving Environment Novelty Quantification for Effective Unsupervised Environment Design</h3>
<ul>
<li><strong>Authors: </strong>Jayden Teoh, Wenjun Li, Pradeep Varakantham</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05726">https://arxiv.org/abs/2502.05726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05726">https://arxiv.org/pdf/2502.05726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05726]] Improving Environment Novelty Quantification for Effective Unsupervised Environment Design(https://arxiv.org/abs/2502.05726)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Unsupervised Environment Design (UED) formalizes the problem of autocurricula through interactive training between a teacher agent and a student agent. The teacher generates new training environments with high learning potential, curating an adaptive curriculum that strengthens the student's ability to handle unseen scenarios. Existing UED methods mainly rely on regret, a metric that measures the difference between the agent's optimal and actual performance, to guide curriculum design. Regret-driven methods generate curricula that progressively increase environment complexity for the student but overlook environment novelty -- a critical element for enhancing an agent's generalizability. Measuring environment novelty is especially challenging due to the underspecified nature of environment parameters in UED, and existing approaches face significant limitations. To address this, this paper introduces the Coverage-based Evaluation of Novelty In Environment (CENIE) framework. CENIE proposes a scalable, domain-agnostic, and curriculum-aware approach to quantifying environment novelty by leveraging the student's state-action space coverage from previous curriculum experiences. We then propose an implementation of CENIE that models this coverage and measures environment novelty using Gaussian Mixture Models. By integrating both regret and novelty as complementary objectives for curriculum design, CENIE facilitates effective exploration across the state-action space while progressively increasing curriculum complexity. Empirical evaluations demonstrate that augmenting existing regret-based UED algorithms with CENIE achieves state-of-the-art performance across multiple benchmarks, underscoring the effectiveness of novelty-driven autocurricula for robust generalization.</li>
</ul>

<h3>Title: Impact of Data Poisoning Attacks on Feasibility and Optimality of Neural Power System Optimizers</h3>
<ul>
<li><strong>Authors: </strong>Nora Agah, Meiyi Li, Javad Mohammadi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05727">https://arxiv.org/abs/2502.05727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05727">https://arxiv.org/pdf/2502.05727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05727]] Impact of Data Poisoning Attacks on Feasibility and Optimality of Neural Power System Optimizers(https://arxiv.org/abs/2502.05727)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The increased integration of clean yet stochastic energy resources and the growing number of extreme weather events are narrowing the decision-making window of power grid operators. This time constraint is fueling a plethora of research on Machine Learning-, or ML-, based optimization proxies. While finding a fast solution is appealing, the inherent vulnerabilities of the learning-based methods are hindering their adoption. One of these vulnerabilities is data poisoning attacks, which adds perturbations to ML training data, leading to incorrect decisions. The impact of poisoning attacks on learning-based power system optimizers have not been thoroughly studied, which creates a critical vulnerability. In this paper, we examine the impact of data poisoning attacks on ML-based optimization proxies that are used to solve the DC Optimal Power Flow problem. Specifically, we compare the resilience of three different methods-a penalty-based method, a post-repair approach, and a direct mapping approach-against the adverse effects of poisoning attacks. We will use the optimality and feasibility of these proxies as performance metrics. The insights of this work will establish a foundation for enhancing the resilience of neural power system optimizers.</li>
</ul>

<h3>Title: Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Ruotong Geng, Mingyang Geng, Shangwen Wang, Haotian Wang, Zhipeng Lin, Dezun Dong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05739">https://arxiv.org/abs/2502.05739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05739">https://arxiv.org/pdf/2502.05739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05739]] Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning(https://arxiv.org/abs/2502.05739)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models for Code (LLMs4Code) excel at code generation tasks, yielding promise to release developers from huge software development burdens. Nonetheless, these models have been shown to suffer from the significant privacy risks due to the potential leakage of sensitive information embedded during training, known as the memorization problem. Addressing this issue is crucial for ensuring privacy compliance and upholding user trust, but till now there is a dearth of dedicated studies in the literature that focus on this specific direction. Recently, machine unlearning has emerged as a promising solution by enabling models to "forget" sensitive information without full retraining, offering an efficient and scalable approach compared to traditional data cleaning methods. In this paper, we empirically evaluate the effectiveness of unlearning techniques for addressing privacy concerns in this http URL, we investigate three state-of-the-art unlearning algorithms and three well-known open-sourced LLMs4Code, on a benchmark that takes into consideration both the privacy data to be forgotten as well as the code generation capabilites of these models. Results show that it is feasible to mitigate the privacy concerns of LLMs4Code through machine unlearning while maintain their code generation capabilities at the same time. We also dissect the forms of privacy protection/leakage after unlearning and observe that there is a shift from direct leakage to indirect leakage, which underscores the need for future studies addressing this risk.</li>
</ul>

<h3>Title: Linear Attention Modeling for Learned Image Compression</h3>
<ul>
<li><strong>Authors: </strong>Donghui Feng, Zhengxue Cheng, Shen Wang, Ronghua Wu, Hongwei Hu, Guo Lu, Li Song</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05741">https://arxiv.org/abs/2502.05741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05741">https://arxiv.org/pdf/2502.05741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05741]] Linear Attention Modeling for Learned Image Compression(https://arxiv.org/abs/2502.05741)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Recent years, learned image compression has made tremendous progress to achieve impressive coding efficiency. Its coding gain mainly comes from non-linear neural network-based transform and learnable entropy modeling. However, most of recent focuses have been solely on a strong backbone, and few studies consider the low-complexity design. In this paper, we propose LALIC, a linear attention modeling for learned image compression. Specially, we propose to use Bi-RWKV blocks, by utilizing the Spatial Mix and Channel Mix modules to achieve more compact features extraction, and apply the Conv based Omni-Shift module to adapt to two-dimensional latent representation. Furthermore, we propose a RWKV-based Spatial-Channel ConTeXt model (RWKV-SCCTX), that leverages the Bi-RWKV to modeling the correlation between neighboring features effectively, to further improve the RD performance. To our knowledge, our work is the first work to utilize efficient Bi-RWKV models with linear attention for learned image compression. Experimental results demonstrate that our method achieves competitive RD performances by outperforming VTM-9.1 by -14.84%, -15.20%, -17.32% in BD-rate on Kodak, Tecnick and CLIC Professional validation datasets.</li>
</ul>

<h3>Title: Understanding Representation Dynamics of Diffusion Models via Low-Dimensional Modeling</h3>
<ul>
<li><strong>Authors: </strong>Xiao Li, Zekai Zhang, Xiang Li, Siyi Chen, Zhihui Zhu, Peng Wang, Qing Qu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05743">https://arxiv.org/abs/2502.05743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05743">https://arxiv.org/pdf/2502.05743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05743]] Understanding Representation Dynamics of Diffusion Models via Low-Dimensional Modeling(https://arxiv.org/abs/2502.05743)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>This work addresses the critical question of why and when diffusion models, despite being designed for generative tasks, can excel at learning high-quality representations in a self-supervised manner. To address this, we develop a mathematical framework based on a low-dimensional data model and posterior estimation, revealing a fundamental trade-off between generation and representation quality near the final stage of image generation. Our analysis explains the unimodal representation dynamics across noise scales, mainly driven by the interplay between data denoising and class specification. Building on these insights, we propose an ensemble method that aggregates features across noise levels, significantly improving both clean performance and robustness under label noise. Extensive experiments on both synthetic and real-world datasets validate our findings.</li>
</ul>

<h3>Title: UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control</h3>
<ul>
<li><strong>Authors: </strong>Kaizhen Zhu, Mokai Pan, Yuexin Ma, Yanwei Fu, Jingyi Yu, Jingya Wang, Ye Shi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05749">https://arxiv.org/abs/2502.05749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05749">https://arxiv.org/pdf/2502.05749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05749]] UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control(https://arxiv.org/abs/2502.05749)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion bridge models leverage Doob's $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob's $h$-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at this https URL.</li>
</ul>

<h3>Title: Filter, Obstruct and Dilute: Defending Against Backdoor Attacks on Semi-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Xinrui Wang, Chuanxing Geng, Wenhai Wan, Shao-yuan Li, Songcan Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05755">https://arxiv.org/abs/2502.05755</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05755">https://arxiv.org/pdf/2502.05755</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05755]] Filter, Obstruct and Dilute: Defending Against Backdoor Attacks on Semi-Supervised Learning(https://arxiv.org/abs/2502.05755)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>Recent studies have verified that semi-supervised learning (SSL) is vulnerable to data poisoning backdoor attacks. Even a tiny fraction of contaminated training data is sufficient for adversaries to manipulate up to 90\% of the test outputs in existing SSL methods. Given the emerging threat of backdoor attacks designed for SSL, this work aims to protect SSL against such risks, marking it as one of the few known efforts in this area. Specifically, we begin by identifying that the spurious correlations between the backdoor triggers and the target class implanted by adversaries are the primary cause of manipulated model predictions during the test phase. To disrupt these correlations, we utilize three key techniques: Gaussian Filter, complementary learning and trigger mix-up, which collectively filter, obstruct and dilute the influence of backdoor attacks in both data pre-processing and feature learning. Experimental results demonstrate that our proposed method, Backdoor Invalidator (BI), significantly reduces the average attack success rate from 84.7\% to 1.8\% across different state-of-the-art backdoor attacks. It is also worth mentioning that BI does not sacrifice accuracy on clean data and is supported by a theoretical guarantee of its generalization capability.</li>
</ul>

<h3>Title: Exploring Visual Embedding Spaces Induced by Vision Transformers for Online Auto Parts Marketplaces</h3>
<ul>
<li><strong>Authors: </strong>Cameron Armijo, Pablo Rivas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05756">https://arxiv.org/abs/2502.05756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05756">https://arxiv.org/pdf/2502.05756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05756]] Exploring Visual Embedding Spaces Induced by Vision Transformers for Online Auto Parts Marketplaces(https://arxiv.org/abs/2502.05756)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study examines the capabilities of the Vision Transformer (ViT) model in generating visual embeddings for images of auto parts sourced from online marketplaces, such as Craigslist and OfferUp. By focusing exclusively on single-modality data, the analysis evaluates ViT's potential for detecting patterns indicative of illicit activities. The workflow involves extracting high-dimensional embeddings from images, applying dimensionality reduction techniques like Uniform Manifold Approximation and Projection (UMAP) to visualize the embedding space, and using K-Means clustering to categorize similar items. Representative posts nearest to each cluster centroid provide insights into the composition and characteristics of the clusters. While the results highlight the strengths of ViT in isolating visual patterns, challenges such as overlapping clusters and outliers underscore the limitations of single-modal approaches in this domain. This work contributes to understanding the role of Vision Transformers in analyzing online marketplaces and offers a foundation for future advancements in detecting fraudulent or illegal activities.</li>
</ul>

<h3>Title: Reinforced Lifelong Editing for Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zherui Li, Houcheng Jiang, Hao Chen, Baolong Bi, Zhenhong Zhou, Fei Sun, Junfeng Fang, Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05759">https://arxiv.org/abs/2502.05759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05759">https://arxiv.org/pdf/2502.05759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05759]] Reinforced Lifelong Editing for Language Models(https://arxiv.org/abs/2502.05759)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) acquire information from pre-training corpora, but their stored knowledge can become inaccurate or outdated over time. Model editing addresses this challenge by modifying model parameters without retraining, and prevalent approaches leverage hypernetworks to generate these parameter updates. However, they face significant challenges in lifelong editing due to their incompatibility with LLM parameters that dynamically change during the editing process. To address this, we observed that hypernetwork-based lifelong editing aligns with reinforcement learning modeling and proposed RLEdit, an RL-based editing method. By treating editing losses as rewards and optimizing hypernetwork parameters at the full knowledge sequence level, we enable it to precisely capture LLM changes and generate appropriate parameter updates. Our extensive empirical evaluation across several LLMs demonstrates that RLEdit outperforms existing methods in lifelong editing with superior effectiveness and efficiency, achieving a 59.24% improvement while requiring only 2.11% of the time compared to most approaches. Our code is available at: this https URL.</li>
</ul>

<h3>Title: MADAR: Efficient Continual Learning for Malware Analysis with Diversity-Aware Replay</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Saidur Rahman, Scott Coull, Qi Yu, Matthew Wright</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05760">https://arxiv.org/abs/2502.05760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05760">https://arxiv.org/pdf/2502.05760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05760]] MADAR: Efficient Continual Learning for Malware Analysis with Diversity-Aware Replay(https://arxiv.org/abs/2502.05760)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Millions of new pieces of malicious software (i.e., malware) are introduced each year. This poses significant challenges for antivirus vendors, who use machine learning to detect and analyze malware, and must keep up with changes in the distribution while retaining knowledge of older variants. Continual learning (CL) holds the potential to address this challenge by reducing the storage and computational costs of regularly retraining over all the collected data. Prior work, however, shows that CL techniques, which are designed primarily for computer vision tasks, fare poorly when applied to malware classification. To address these issues, we begin with an exploratory analysis of a typical malware dataset, which reveals that malware families are diverse and difficult to characterize, requiring a wide variety of samples to learn a robust representation. Based on these findings, we propose $\underline{M}$alware $\underline{A}$nalysis with $\underline{D}$iversity-$\underline{A}$ware $\underline{R}$eplay (MADAR), a CL framework that accounts for the unique properties and challenges of the malware data distribution. Through extensive evaluation on large-scale Windows and Android malware datasets, we show that MADAR significantly outperforms prior work. This highlights the importance of understanding domain characteristics when designing CL techniques and demonstrates a path forward for the malware classification domain.</li>
</ul>

<h3>Title: 3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly</h3>
<ul>
<li><strong>Authors: </strong>Enquan Yang, Peng Xing, Hanyang Sun, Wenbo Guo, Yuanwei Ma, Zechao Li, Dan Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05761">https://arxiv.org/abs/2502.05761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05761">https://arxiv.org/pdf/2502.05761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05761]] 3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly(https://arxiv.org/abs/2502.05761)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Industrial anomaly detection achieves progress thanks to datasets such as MVTec-AD and VisA. However, they suf- fer from limitations in terms of the number of defect sam- ples, types of defects, and availability of real-world scenes. These constraints inhibit researchers from further exploring the performance of industrial detection with higher accuracy. To this end, we propose a new large-scale anomaly detection dataset called 3CAD, which is derived from real 3C produc- tion lines. Specifically, the proposed 3CAD includes eight different types of manufactured parts, totaling 27,039 high- resolution images labeled with pixel-level anomalies. The key features of 3CAD are that it covers anomalous regions of different sizes, multiple anomaly types, and the possibility of multiple anomalous regions and multiple anomaly types per anomaly image. This is the largest and first anomaly de- tection dataset dedicated to 3C product quality control for community exploration and development. Meanwhile, we in- troduce a simple yet effective framework for unsupervised anomaly detection: a Coarse-to-Fine detection paradigm with Recovery Guidance (CFRG). To detect small defect anoma- lies, the proposed CFRG utilizes a coarse-to-fine detection paradigm. Specifically, we utilize a heterogeneous distilla- tion model for coarse localization and then fine localiza- tion through a segmentation model. In addition, to better capture normal patterns, we introduce recovery features as guidance. Finally, we report the results of our CFRG frame- work and popular anomaly detection methods on the 3CAD dataset, demonstrating strong competitiveness and providing a highly challenging benchmark to promote the development of the anomaly detection field. Data and code are available: this https URL.</li>
</ul>

<h3>Title: Privacy-Preserving Dataset Combination</h3>
<ul>
<li><strong>Authors: </strong>Keren Fuentes, Mimee Xu, Irene Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05765">https://arxiv.org/abs/2502.05765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05765">https://arxiv.org/pdf/2502.05765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05765]] Privacy-Preserving Dataset Combination(https://arxiv.org/abs/2502.05765)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Access to diverse, high-quality datasets is crucial for machine learning model performance, yet data sharing remains limited by privacy concerns and competitive interests, particularly in regulated domains like healthcare. This dynamic especially disadvantages smaller organizations that lack resources to purchase data or negotiate favorable sharing agreements. We present SecureKL, a privacy-preserving framework that enables organizations to identify beneficial data partnerships without exposing sensitive information. Building on recent advances in dataset combination methods, we develop a secure multiparty computation protocol that maintains strong privacy guarantees while achieving >90\% correlation with plaintext evaluations. In experiments with real-world hospital data, SecureKL successfully identifies beneficial data partnerships that improve model performance for intensive care unit mortality prediction while preserving data privacy. Our framework provides a practical solution for organizations seeking to leverage collective data resources while maintaining privacy and competitive advantages. These results demonstrate the potential for privacy-preserving data collaboration to advance machine learning applications in high-stakes domains while promoting more equitable access to data resources.</li>
</ul>

<h3>Title: Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual Descriptions Using Gaussian Splatting, ChatGPT/Deepseek, and Google Maps Platforms</h3>
<ul>
<li><strong>Authors: </strong>Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05769">https://arxiv.org/abs/2502.05769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05769">https://arxiv.org/pdf/2502.05769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05769]] Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual Descriptions Using Gaussian Splatting, ChatGPT/Deepseek, and Google Maps Platforms(https://arxiv.org/abs/2502.05769)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Urban digital twins are virtual replicas of cities that use multi-source data and data analytics to optimize urban planning, infrastructure management, and decision-making. Towards this, we propose a framework focused on the single-building scale. By connecting to cloud mapping platforms such as Google Map Platforms APIs, by leveraging state-of-the-art multi-agent Large Language Models data analysis using ChatGPT(4o) and Deepseek-V3/R1, and by using our Gaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildings framework can retrieve a building's 3D model, visual descriptions, and achieve cloud-based mapping integration with large language model-based data analytics using a building's address, postal code, or geographic coordinates.</li>
</ul>

<h3>Title: Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails</h3>
<ul>
<li><strong>Authors: </strong>Yijun Yang, Lichao Wang, Xiao Yang, Lanqing Hong, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05772">https://arxiv.org/abs/2502.05772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05772">https://arxiv.org/pdf/2502.05772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05772]] Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails(https://arxiv.org/abs/2502.05772)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Vision Large Language Models (VLLMs) integrate visual data processing, expanding their real-world applications, but also increasing the risk of generating unsafe responses. In response, leading companies have implemented Multi-Layered safety defenses, including alignment training, safety system prompts, and content moderation. However, their effectiveness against sophisticated adversarial attacks remains largely unexplored. In this paper, we propose MultiFaceted Attack, a novel attack framework designed to systematically bypass Multi-Layered Defenses in VLLMs. It comprises three complementary attack facets: Visual Attack that exploits the multimodal nature of VLLMs to inject toxic system prompts through images; Alignment Breaking Attack that manipulates the model's alignment mechanism to prioritize the generation of contrasting responses; and Adversarial Signature that deceives content moderators by strategically placing misleading information at the end of the response. Extensive evaluations on eight commercial VLLMs in a black-box setting demonstrate that MultiFaceted Attack achieves a 61.56% attack success rate, surpassing state-of-the-art methods by at least 42.18%.</li>
</ul>

<h3>Title: Predictive Crash Analytics for Traffic Safety using Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Karthik Sivakoti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05777">https://arxiv.org/abs/2502.05777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05777">https://arxiv.org/pdf/2502.05777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05777]] Predictive Crash Analytics for Traffic Safety using Deep Learning(https://arxiv.org/abs/2502.05777)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Traditional automated crash analysis systems heavily rely on static statistical models and historical data, requiring significant manual interpretation and lacking real-time predictive capabilities. This research presents an innovative approach to traffic safety analysis through the integration of ensemble learning methods and multi-modal data fusion for real-time crash risk assessment and prediction. Our primary contribution lies in developing a hierarchical severity classification system that combines spatial-temporal crash patterns with environmental conditions, achieving significant improvements over traditional statistical approaches. The system demonstrates a Mean Average Precision (mAP) of 0.893, representing a 15% improvement over current state-of-the-art methods (baseline mAP: 0.776). We introduce a novel feature engineering technique that integrates crash location data with incident reports and weather conditions, achieving 92.4% accuracy in risk prediction and 89.7% precision in hotspot identification. Through extensive validation using 500,000 initial crash records filtered to 59,496 high-quality samples, our solution shows marked improvements in both prediction accuracy and computational efficiency. Key innovations include a robust data cleaning pipeline, adaptive feature generation, and a scalable real-time prediction system capable of handling peak loads of 1,000 concurrent requests while maintaining sub-100ms response times.</li>
</ul>

<h3>Title: GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation</h3>
<ul>
<li><strong>Authors: </strong>Danny Wang, Ruihong Qiu, Guangdong Bai, Zi Huang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05780">https://arxiv.org/abs/2502.05780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05780">https://arxiv.org/pdf/2502.05780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05780]] GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation(https://arxiv.org/abs/2502.05780)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Despite graph neural networks' (GNNs) great success in modelling graph-structured data, out-of-distribution (OOD) test instances still pose a great challenge for current GNNs. One of the most effective techniques to detect OOD nodes is to expose the detector model with an additional OOD node-set, yet the extra OOD instances are often difficult to obtain in practice. Recent methods for image data address this problem using OOD data synthesis, typically relying on pre-trained generative models like Stable Diffusion. However, these approaches require vast amounts of additional data, as well as one-for-all pre-trained generative models, which are not available for graph data. Therefore, we propose the GOLD framework for graph OOD detection, an implicit adversarial learning pipeline with synthetic OOD exposure without pre-trained models. The implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model to regularly imitate the in-distribution (ID) embeddings from an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately classify ID data while increasing the energy divergence between the ID embeddings and the generative model's synthetic embeddings. This novel approach implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, effectively simulating exposure to OOD scenarios without auxiliary data. Extensive OOD detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of GOLD without using real OOD data compared with the state-of-the-art OOD exposure and non-exposure baselines.</li>
</ul>

<h3>Title: EPBC-YOLOv8: An efficient and accurate improved YOLOv8 underwater detector based on an attention mechanism</h3>
<ul>
<li><strong>Authors: </strong>Xing Jiang, Xiting Zhuang, Jisheng Chen, Jian Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05788">https://arxiv.org/abs/2502.05788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05788">https://arxiv.org/pdf/2502.05788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05788]] EPBC-YOLOv8: An efficient and accurate improved YOLOv8 underwater detector based on an attention mechanism(https://arxiv.org/abs/2502.05788)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this study, we enhance underwater target detection by integrating channel and spatial attention into YOLOv8's backbone, applying Pointwise Convolution in FasterNeXt for the FasterPW model, and leveraging Weighted Concat in a BiFPN-inspired WFPN structure for improved cross-scale connections and robustness. Utilizing CARAFE for refined feature reassembly, our framework addresses underwater image degradation, achieving mAP at 0.5 scores of 76.7 percent and 79.0 percent on URPC2019 and URPC2020 datasets, respectively. These scores are 2.3 percent and 0.7 percent higher than the original YOLOv8, showcasing enhanced precision in detecting marine organisms.</li>
</ul>

<h3>Title: I3S: Importance Sampling Subspace Selection for Low-Rank Optimization in LLM Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Haochen Zhang, Junze Yin, Guanchu Wang, Zirui Liu, Tianyi Zhang, Anshumali Shrivastava, Lin Yang, Vladimir Braverman</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05790">https://arxiv.org/abs/2502.05790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05790">https://arxiv.org/pdf/2502.05790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05790]] I3S: Importance Sampling Subspace Selection for Low-Rank Optimization in LLM Pretraining(https://arxiv.org/abs/2502.05790)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Low-rank optimization has emerged as a promising approach to enabling memory-efficient training of large language models (LLMs). Existing low-rank optimization methods typically project gradients onto a low-rank subspace, reducing the memory cost of storing optimizer states. A key challenge in these methods is identifying suitable subspaces to ensure an effective optimization trajectory. Most existing approaches select the dominant subspace to preserve gradient information, as this intuitively provides the best approximation. However, we find that in practice, the dominant subspace stops changing during pretraining, thereby constraining weight updates to similar subspaces. In this paper, we propose importance sampling subspace selection (I3S) for low-rank optimization, which theoretically offers a comparable convergence rate to the dominant subspace approach. Empirically, we demonstrate that I3S significantly outperforms previous methods in LLM pretraining tasks.</li>
</ul>

<h3>Title: Structural Perturbation in Large Language Model Representations through Recursive Symbolic Regeneration</h3>
<ul>
<li><strong>Authors: </strong>Kathlyn Eaglewood, Tobias Featherington, Dorian Mayfair, Sylvester Grimshaw, James Pettigrew</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05794">https://arxiv.org/abs/2502.05794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05794">https://arxiv.org/pdf/2502.05794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05794]] Structural Perturbation in Large Language Model Representations through Recursive Symbolic Regeneration(https://arxiv.org/abs/2502.05794)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Symbolic perturbations offer a novel approach for influencing neural representations without requiring direct modification of model parameters. The recursive regeneration of symbolic structures introduces structured variations in latent embeddings, leading to controlled shifts in attention dynamics and lexical diversity across sequential generations. A comparative analysis with conventional fine-tuning techniques reveals that structural modifications at the symbolic level induce distinct variations in contextual sensitivity while maintaining overall model fluency and coherence. Shifts in attention weight distributions highlight the role of symbolic modifications in adjusting token dependencies, influencing response variability, and refining long-form text generation. Experimental findings suggest that symbolic perturbations can enhance adaptability in domain-specific applications, allowing modifications in model behavior without retraining. Evaluations of semantic drift indicate that recursive regeneration alters long-range token dependencies, affecting topic coherence across extended text sequences. Results from lexical variability assessments further support the conclusion that symbolic-level modifications introduce interpretable variations in generated responses, potentially enabling more controlled stylistic adjustments in automated text generation.</li>
</ul>

<h3>Title: The Curse of Depth in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wenfang Sun, Xinyuan Song, Pengxiang Li, Lu Yin, Yefeng Zheng, Shiwei Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05795">https://arxiv.org/abs/2502.05795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05795">https://arxiv.org/pdf/2502.05795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05795]] The Curse of Depth in Large Language Models(https://arxiv.org/abs/2502.05795)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce the Curse of Depth, a concept that highlights, explains, and addresses the recent observation in modern Large Language Models(LLMs) where nearly half of the layers are less effective than expected. We first confirm the wide existence of this phenomenon across the most popular families of LLMs such as Llama, Mistral, DeepSeek, and Qwen. Our analysis, theoretically and empirically, identifies that the underlying reason for the ineffectiveness of deep layers in LLMs is the widespread usage of Pre-Layer Normalization (Pre-LN). While Pre-LN stabilizes the training of Transformer LLMs, its output variance exponentially grows with the model depth, which undesirably causes the derivative of the deep Transformer blocks to be an identity matrix, and therefore barely contributes to the training. To resolve this training pitfall, we propose LayerNorm Scaling, which scales the variance of output of the layer normalization inversely by the square root of its depth. This simple modification mitigates the output variance explosion of deeper Transformer layers, improving their contribution. Our experimental results, spanning model sizes from 130M to 1B, demonstrate that LayerNorm Scaling significantly enhances LLM pre-training performance compared to Pre-LN. Moreover, this improvement seamlessly carries over to supervised fine-tuning. All these gains can be attributed to the fact that LayerNorm Scaling enables deeper layers to contribute more effectively during training.</li>
</ul>

<h3>Title: MicroViT: A Vision Transformer with Low Complexity Self Attention for Edge Device</h3>
<ul>
<li><strong>Authors: </strong>Novendra Setyawan, Chi-Chia Sun, Mao-Hsiu Hsu, Wen-Kai Kuo, Jun-Wei Hsieh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05800">https://arxiv.org/abs/2502.05800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05800">https://arxiv.org/pdf/2502.05800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05800]] MicroViT: A Vision Transformer with Low Complexity Self Attention for Edge Device(https://arxiv.org/abs/2502.05800)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The Vision Transformer (ViT) has demonstrated state-of-the-art performance in various computer vision tasks, but its high computational demands make it impractical for edge devices with limited resources. This paper presents MicroViT, a lightweight Vision Transformer architecture optimized for edge devices by significantly reducing computational complexity while maintaining high accuracy. The core of MicroViT is the Efficient Single Head Attention (ESHA) mechanism, which utilizes group convolution to reduce feature redundancy and processes only a fraction of the channels, thus lowering the burden of the self-attention mechanism. MicroViT is designed using a multi-stage MetaFormer architecture, stacking multiple MicroViT encoders to enhance efficiency and performance. Comprehensive experiments on the ImageNet-1K and COCO datasets demonstrate that MicroViT achieves competitive accuracy while significantly improving 3.6 faster inference speed and reducing energy consumption with 40% higher efficiency than the MobileViT series, making it suitable for deployment in resource-constrained environments such as mobile and edge devices.</li>
</ul>

<h3>Title: Devil is in the Details: Density Guidance for Detail-Aware Generation with Flow Models</h3>
<ul>
<li><strong>Authors: </strong>Rafa≈Ç Karczewski, Markus Heinonen, Vikas Garg</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05807">https://arxiv.org/abs/2502.05807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05807">https://arxiv.org/pdf/2502.05807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05807]] Devil is in the Details: Density Guidance for Detail-Aware Generation with Flow Models(https://arxiv.org/abs/2502.05807)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as a powerful class of generative models, capable of producing high-quality images by mapping noise to a data distribution. However, recent findings suggest that image likelihood does not align with perceptual quality: high-likelihood samples tend to be smooth, while lower-likelihood ones are more detailed. Controlling sample density is thus crucial for balancing realism and detail. In this paper, we analyze an existing technique, Prior Guidance, which scales the latent code to influence image detail. We introduce score alignment, a condition that explains why this method works and show that it can be tractably checked for any continuous normalizing flow model. We then propose Density Guidance, a principled modification of the generative ODE that enables exact log-density control during sampling. Finally, we extend Density Guidance to stochastic sampling, ensuring precise log-density control while allowing controlled variation in structure or fine details. Our experiments demonstrate that these techniques provide fine-grained control over image detail without compromising sample quality.</li>
</ul>

<h3>Title: Delta - Contrastive Decoding Mitigates Text Hallucinations in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Cheng Peng Huang, Hao-Yuan Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05825">https://arxiv.org/abs/2502.05825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05825">https://arxiv.org/pdf/2502.05825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05825]] Delta - Contrastive Decoding Mitigates Text Hallucinations in Large Language Models(https://arxiv.org/abs/2502.05825)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) demonstrate strong capabilities in natural language processing but remain prone to hallucinations, generating factually incorrect or fabricated content. This issue undermines their reliability, particularly in high-stakes domains such as healthcare and legal advisory. To address this challenge, we propose Delta, an inference-time method that reduces hallucinations without requiring model retraining or additional data. Delta works by randomly masking parts of the input prompt and contrasting the output distributions for the original and masked inputs, effectively suppressing hallucinations through inference-only computations. We evaluate Delta on context-rich question-answering benchmarks, achieving absolute improvements of approximately 3 and 6 percentage points on SQuAD v1.1 and v2, respectively, and 7 and 2 percentage points on TriviaQA and Natural Questions under-sampling decoding. Delta also improves the no-answer exact match score on SQuAD v2 by over ten percentage points, demonstrating its effectiveness in mitigating hallucinations arising from contextual ambiguity. These results highlight Delta as a computationally efficient and scalable approach for improving the reliability of LLMs in real-world applications.</li>
</ul>

<h3>Title: Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition</h3>
<ul>
<li><strong>Authors: </strong>Tian-Shuang Wu, Shen-Huan Lyu, Ning Chen, Zhihao Qu, Baoliu Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05832">https://arxiv.org/abs/2502.05832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05832">https://arxiv.org/pdf/2502.05832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05832]] Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition(https://arxiv.org/abs/2502.05832)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>In recent years, as a compromise between privacy and performance, few-sample model compression has been widely adopted to deal with limited data resulting from privacy and security concerns. However, when the number of available samples is extremely limited, class imbalance becomes a common and tricky problem. Achieving an equal number of samples across all classes is often costly and impractical in real-world applications, and previous studies on few-sample model compression have mostly ignored this significant issue. Our experiments comprehensively demonstrate that class imbalance negatively affects the overall performance of few-sample model compression methods. To address this problem, we propose a novel and adaptive framework named OOD-Enhanced Few-Sample Model Compression (OE-FSMC). This framework integrates easily accessible out-of-distribution (OOD) data into both the compression and fine-tuning processes, effectively rebalancing the training distribution. We also incorporate a joint distillation loss and a regularization term to reduce the risk of the model overfitting to the OOD data. Extensive experiments on multiple benchmark datasets show that our framework can be seamlessly incorporated into existing few-sample model compression methods, effectively mitigating the accuracy degradation caused by class imbalance.</li>
</ul>

<h3>Title: LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification</h3>
<ul>
<li><strong>Authors: </strong>Shubham Kumar Nigam, Tanmay Dubey, Govind Sharma, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05836">https://arxiv.org/abs/2502.05836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05836">https://arxiv.org/pdf/2502.05836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05836]] LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification(https://arxiv.org/abs/2502.05836)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we address the task of semantic segmentation of legal documents through rhetorical role classification, with a focus on Indian legal judgments. We introduce LegalSeg, the largest annotated dataset for this task, comprising over 7,000 documents and 1.4 million sentences, labeled with 7 rhetorical roles. To benchmark performance, we evaluate multiple state-of-the-art models, including Hierarchical BiLSTM-CRF, TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and Role-Aware Transformers, alongside an exploratory RhetoricLLaMA, an instruction-tuned large language model. Our results demonstrate that models incorporating broader context, structural relationships, and sequential sentence information outperform those relying solely on sentence-level features. Additionally, we conducted experiments using surrounding context and predicted or actual labels of neighboring sentences to assess their impact on classification accuracy. Despite these advancements, challenges persist in distinguishing between closely related roles and addressing class imbalance. Our work underscores the potential of advanced techniques for improving legal document understanding and sets a strong foundation for future research in legal NLP.</li>
</ul>

<h3>Title: Training-free Anomaly Event Detection via LLM-guided Symbolic Pattern Discovery</h3>
<ul>
<li><strong>Authors: </strong>Yuhui Zeng, Haoxiang Wu, Wenjie Nie, Guangyao Chen, Xiawu Zheng, Yunhang Shen, Guilin Li, Yixiong Zou, Yonghong Tian, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05843">https://arxiv.org/abs/2502.05843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05843">https://arxiv.org/pdf/2502.05843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05843]] Training-free Anomaly Event Detection via LLM-guided Symbolic Pattern Discovery(https://arxiv.org/abs/2502.05843)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Anomaly event detection plays a crucial role in various real-world applications. However, current approaches predominantly rely on supervised learning, which faces significant challenges: the requirement for extensive labeled training data and lack of interpretability in decision-making processes. To address these limitations, we present a training-free framework that integrates open-set object detection with symbolic regression, powered by Large Language Models (LLMs) for efficient symbolic pattern discovery. The LLMs guide the symbolic reasoning process, establishing logical relationships between detected entities. Through extensive experiments across multiple domains, our framework demonstrates several key advantages: (1) achieving superior detection accuracy through direct reasoning without any training process; (2) providing highly interpretable logical expressions that are readily comprehensible to humans; and (3) requiring minimal annotation effort - approximately 1% of the data needed by traditional training-based this http URL facilitate comprehensive evaluation and future research, we introduce two datasets: a large-scale private dataset containing over 110,000 annotated images covering various anomaly scenarios including construction site safety violations, illegal fishing activities, and industrial hazards, along with a public benchmark dataset of 5,000 samples with detailed anomaly event annotations. Code is available at here.</li>
</ul>

<h3>Title: Fact-or-Fair: A Checklist for Behavioral Testing of AI Models on Fairness-Related Queries</h3>
<ul>
<li><strong>Authors: </strong>Jen-tse Huang, Yuhang Yan, Linqi Liu, Yixin Wan, Wenxuan Wang, Kai-Wei Chang, Michael R. Lyu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05849">https://arxiv.org/abs/2502.05849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05849">https://arxiv.org/pdf/2502.05849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05849]] Fact-or-Fair: A Checklist for Behavioral Testing of AI Models on Fairness-Related Queries(https://arxiv.org/abs/2502.05849)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The generation of incorrect images, such as depictions of people of color in Nazi-era uniforms by Gemini, frustrated users and harmed Google's reputation, motivating us to investigate the relationship between accurately reflecting factuality and promoting diversity and equity. In this study, we focus on 19 real-world statistics collected from authoritative sources. Using these statistics, we develop a checklist comprising objective and subjective queries to analyze behavior of large language models (LLMs) and text-to-image (T2I) models. Objective queries assess the models' ability to provide accurate world knowledge. In contrast, the design of subjective queries follows a key principle: statistical or experiential priors should not be overgeneralized to individuals, ensuring that models uphold diversity. These subjective queries are based on three common human cognitive errors that often result in social biases. We propose metrics to assess factuality and fairness, and formally prove the inherent trade-off between these two aspects. Results show that GPT-4o and DALL-E 3 perform notably well among six LLMs and four T2I models. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Acquisition through My Eyes and Steps: A Joint Predictive Agent Model in Egocentric Worlds</h3>
<ul>
<li><strong>Authors: </strong>Lu Chen, Yizhou Wang, Shixiang Tang, Qianhong Ma, Tong He, Wanli Ouyang, Xiaowei Zhou, Hujun Bao, Sida Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05857">https://arxiv.org/abs/2502.05857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05857">https://arxiv.org/pdf/2502.05857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05857]] Acquisition through My Eyes and Steps: A Joint Predictive Agent Model in Egocentric Worlds(https://arxiv.org/abs/2502.05857)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper addresses the task of learning an agent model behaving like humans, which can jointly perceive, predict, and act in egocentric worlds. Previous methods usually train separate models for these three abilities, leading to information silos among them, which prevents these abilities from learning from each other and collaborating effectively. In this paper, we propose a joint predictive agent model, named EgoAgent, that simultaneously learns to represent the world, predict future states, and take reasonable actions with a single transformer. EgoAgent unifies the representational spaces of the three abilities by mapping them all into a sequence of continuous tokens. Learnable query tokens are appended to obtain current states, future states, and next actions. With joint supervision, our agent model establishes the internal relationship among these three abilities and effectively mimics the human inference and learning processes. Comprehensive evaluations of EgoAgent covering image classification, egocentric future state prediction, and 3D human motion prediction tasks demonstrate the superiority of our method. The code and trained model will be released for reproducibility.</li>
</ul>

<h3>Title: Self-Training Large Language Models for Tool-Use Without Demonstrations</h3>
<ul>
<li><strong>Authors: </strong>Ne Luo, Aryo Pradipta Gema, Xuanli He, Emile van Krieken, Pietro Lesci, Pasquale Minervini</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05867">https://arxiv.org/abs/2502.05867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05867">https://arxiv.org/pdf/2502.05867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05867]] Self-Training Large Language Models for Tool-Use Without Demonstrations(https://arxiv.org/abs/2502.05867)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) remain prone to factual inaccuracies and computational errors, including hallucinations and mistakes in mathematical reasoning. Recent work augmented LLMs with tools to mitigate these shortcomings, but often requires curated gold tool-use demonstrations. In this paper, we investigate whether LLMs can learn to use tools without demonstrations. First, we analyse zero-shot prompting strategies to guide LLMs in tool utilisation. Second, we propose a self-training method to synthesise tool-use traces using the LLM itself. We compare supervised fine-tuning and preference fine-tuning techniques for fine-tuning the model on datasets constructed using existing Question Answering (QA) datasets, i.e., TriviaQA and GSM8K. Experiments show that tool-use enhances performance on a long-tail knowledge task: 3.7% on PopQA, which is used solely for evaluation, but leads to mixed results on other datasets, i.e., TriviaQA, GSM8K, and NQ-Open. Our findings highlight the potential and challenges of integrating external tools into LLMs without demonstrations.</li>
</ul>

<h3>Title: HyLiFormer: Hyperbolic Linear Attention for Skeleton-based Human Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yue Li, Haoxuan Qu, Mengyuan Liu, Jun Liu, Yujun Cai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05869">https://arxiv.org/abs/2502.05869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05869">https://arxiv.org/pdf/2502.05869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05869]] HyLiFormer: Hyperbolic Linear Attention for Skeleton-based Human Action Recognition(https://arxiv.org/abs/2502.05869)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have demonstrated remarkable performance in skeleton-based human action recognition, yet their quadratic computational complexity remains a bottleneck for real-world applications. To mitigate this, linear attention mechanisms have been explored but struggle to capture the hierarchical structure of skeleton data. Meanwhile, the Poincar√© model, as a typical hyperbolic geometry, offers a powerful framework for modeling hierarchical structures but lacks well-defined operations for existing mainstream linear attention. In this paper, we propose HyLiFormer, a novel hyperbolic linear attention Transformer tailored for skeleton-based action recognition. Our approach incorporates a Hyperbolic Transformation with Curvatures (HTC) module to map skeleton data into hyperbolic space and a Hyperbolic Linear Attention (HLA) module for efficient long-range dependency modeling. Theoretical analysis and extensive experiments on NTU RGB+D and NTU RGB+D 120 datasets demonstrate that HyLiFormer significantly reduces computational complexity while preserving model accuracy, making it a promising solution for efficiency-critical applications.</li>
</ul>

<h3>Title: MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhifei Yang, Keyang Lu, Chao Zhang, Jiaxing Qi, Hanqi Jiang, Ruifei Ma, Shenglin Yin, Yifan Xu, Mingzhe Xing, Zhen Xiao, Jieyi Long, Xiangde Liu, Guangyao Zhai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05874">https://arxiv.org/abs/2502.05874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05874">https://arxiv.org/pdf/2502.05874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05874]] MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation(https://arxiv.org/abs/2502.05874)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Controllable 3D scene generation has extensive applications in virtual reality and interior design, where the generated scenes should exhibit high levels of realism and controllability in terms of geometry. Scene graphs provide a suitable data representation that facilitates these applications. However, current graph-based methods for scene generation are constrained to text-based inputs and exhibit insufficient adaptability to flexible user inputs, hindering the ability to precisely control object geometry. To address this issue, we propose MMGDreamer, a dual-branch diffusion model for scene generation that incorporates a novel Mixed-Modality Graph, visual enhancement module, and relation predictor. The mixed-modality graph allows object nodes to integrate textual and visual modalities, with optional relationships between nodes. It enhances adaptability to flexible user inputs and enables meticulous control over the geometry of objects in the generated scenes. The visual enhancement module enriches the visual fidelity of text-only nodes by constructing visual representations using text embeddings. Furthermore, our relation predictor leverages node representations to infer absent relationships between nodes, resulting in more coherent scene layouts. Extensive experimental results demonstrate that MMGDreamer exhibits superior control of object geometry, achieving state-of-the-art scene generation performance. Project page: this https URL.</li>
</ul>

<h3>Title: Retrieval-augmented Large Language Models for Financial Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Mengxi Xiao, Zihao Jiang, Lingfei Qian, Zhengyu Chen, Yueru He, Yijing Xu, Yuecheng Jiang, Dong Li, Ruey-Ling Weng, Min Peng, Jimin Huang, Sophia Ananiadou, Qianqian Xie</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05878">https://arxiv.org/abs/2502.05878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05878">https://arxiv.org/pdf/2502.05878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05878]] Retrieval-augmented Large Language Models for Financial Time Series Forecasting(https://arxiv.org/abs/2502.05878)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Stock movement prediction, a fundamental task in financial time-series forecasting, requires identifying and retrieving critical influencing factors from vast amounts of time-series data. However, existing text-trained or numeric similarity-based retrieval methods fall short in handling complex financial analysis. To address this, we propose the first retrieval-augmented generation (RAG) framework for financial time-series forecasting, featuring three key innovations: a fine-tuned 1B parameter large language model (StockLLM) as the backbone, a novel candidate selection method leveraging LLM feedback, and a training objective that maximizes similarity between queries and historically significant sequences. This enables our retriever, FinSeer, to uncover meaningful patterns while minimizing noise in complex financial data. We also construct new datasets integrating financial indicators and historical stock prices to train FinSeer and ensure robust evaluation. Experimental results demonstrate that our RAG framework outperforms bare StockLLM and random retrieval, highlighting its effectiveness, while FinSeer surpasses existing retrieval methods, achieving an 8\% higher accuracy on BIGDATA22 and retrieving more impactful sequences. This work underscores the importance of tailored retrieval models in financial forecasting and provides a novel framework for future research.</li>
</ul>

<h3>Title: Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shiyu Teng, Jiaqing Liu, Rahul Kumar Jain, Shurong Chai, Ruibo Hou, Tomoko Tateyama, Lanfen Lin, Yen-wei Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05879">https://arxiv.org/abs/2502.05879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05879">https://arxiv.org/pdf/2502.05879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05879]] Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models(https://arxiv.org/abs/2502.05879)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Depression is one of the leading causes of disability worldwide, posing a severe burden on individuals, healthcare systems, and society at large. Recent advancements in Large Language Models (LLMs) have shown promise in addressing mental health challenges, including the detection of depression through text-based analysis. However, current LLM-based methods often struggle with nuanced symptom identification and lack a transparent, step-by-step reasoning process, making it difficult to accurately classify and explain mental health conditions. To address these challenges, we propose a Chain-of-Thought Prompting approach that enhances both the performance and interpretability of LLM-based depression detection. Our method breaks down the detection process into four stages: (1) sentiment analysis, (2) binary depression classification, (3) identification of underlying causes, and (4) assessment of severity. By guiding the model through these structured reasoning steps, we improve interpretability and reduce the risk of overlooking subtle clinical indicators. We validate our method on the E-DAIC dataset, where we test multiple state-of-the-art large language models. Experimental results indicate that our Chain-of-Thought Prompting technique yields superior performance in both classification accuracy and the granularity of diagnostic insights, compared to baseline approaches.</li>
</ul>

<h3>Title: NeuralPrefix: A Zero-shot Sensory Data Imputation Plugin</h3>
<ul>
<li><strong>Authors: </strong>Abdelwahed Khamis, Sara Khalifa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05883">https://arxiv.org/abs/2502.05883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05883">https://arxiv.org/pdf/2502.05883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05883]] NeuralPrefix: A Zero-shot Sensory Data Imputation Plugin(https://arxiv.org/abs/2502.05883)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Real-world sensing challenges such as sensor failures, communication issues, and power constraints lead to data intermittency. An issue that is known to undermine the traditional classification task that assumes a continuous data stream. Previous works addressed this issue by designing bespoke solutions (i.e. task-specific and/or modality-specific imputation). These approaches, while effective for their intended purposes, had limitations in their applicability across different tasks and sensor modalities. This raises an important question: Can we build a task-agnostic imputation pipeline that is transferable to new sensors without requiring additional training? In this work, we formalise the concept of zero-shot imputation and propose a novel approach that enables the adaptation of pre-trained models to handle data intermittency. This framework, named NeuralPrefix, is a generative neural component that precedes a task model during inference, filling in gaps caused by data intermittency. NeuralPrefix is built as a continuous dynamical system, where its internal state can be estimated at any point in time by solving an Ordinary Differential Equation (ODE). This approach allows for a more versatile and adaptable imputation method, overcoming the limitations of task-specific and modality-specific solutions. We conduct a comprehensive evaluation of NeuralPrefix on multiple sensory datasets, demonstrating its effectiveness across various domains. When tested on intermittent data with a high 50% missing data rate, NeuralPreifx accurately recovers all the missing samples, achieving SSIM score between 0.93-0.96. Zero-shot evaluations show that NeuralPrefix generalises well to unseen datasets, even when the measurements come from a different modality.</li>
</ul>

<h3>Title: Beyond Fine-Tuning: A Systematic Study of Sampling Techniques in Personalized Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Vera Soboleva, Maksim Nakhodnov, Aibek Alanov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05895">https://arxiv.org/abs/2502.05895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05895">https://arxiv.org/pdf/2502.05895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05895]] Beyond Fine-Tuning: A Systematic Study of Sampling Techniques in Personalized Image Generation(https://arxiv.org/abs/2502.05895)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Personalized text-to-image generation aims to create images tailored to user-defined concepts and textual descriptions. Balancing the fidelity of the learned concept with its ability for generation in various contexts presents a significant challenge. Existing methods often address this through diverse fine-tuning parameterizations and improved sampling strategies that integrate superclass trajectories during the diffusion process. While improved sampling offers a cost-effective, training-free solution for enhancing fine-tuned models, systematic analyses of these methods remain limited. Current approaches typically tie sampling strategies with fixed fine-tuning configurations, making it difficult to isolate their impact on generation outcomes. To address this issue, we systematically analyze sampling strategies beyond fine-tuning, exploring the impact of concept and superclass trajectories on the results. Building on this analysis, we propose a decision framework evaluating text alignment, computational constraints, and fidelity objectives to guide strategy selection. It integrates with diverse architectures and training approaches, systematically optimizing concept preservation, prompt adherence, and resource efficiency. The source code can be found at this https URL.</li>
</ul>

<h3>Title: GRAIT: Gradient-Driven Refusal-Aware Instruction Tuning for Effective Hallucination Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Runchuan Zhu, Zinco Jiang, Jiang Wu, Zhipeng Ma, Jiahe Song, Fengshuo Bai, Dahua Lin, Lijun Wu, Conghui He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05911">https://arxiv.org/abs/2502.05911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05911">https://arxiv.org/pdf/2502.05911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05911]] GRAIT: Gradient-Driven Refusal-Aware Instruction Tuning for Effective Hallucination Mitigation(https://arxiv.org/abs/2502.05911)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Refusal-Aware Instruction Tuning (RAIT) aims to enhance Large Language Models (LLMs) by improving their ability to refuse responses to questions beyond their knowledge, thereby reducing hallucinations and improving reliability. Effective RAIT must address two key challenges: firstly, effectively reject unknown questions to minimize hallucinations; secondly, avoid over-refusal to ensure questions that can be correctly answered are not rejected, thereby maintain the helpfulness of LLM outputs. In this paper, we address the two challenges by deriving insightful observations from the gradient-based perspective, and proposing the Gradient-driven Refusal Aware Instruction Tuning Framework GRAIT: (1) employs gradient-driven sample selection to effectively minimize hallucinations and (2) introduces an adaptive weighting mechanism during fine-tuning to reduce the risk of over-refusal, achieving the balance between accurate refusals and maintaining useful responses. Experimental evaluations on open-ended and multiple-choice question answering tasks demonstrate that GRAIT significantly outperforms existing RAIT methods in the overall performance. The source code and data will be available at this https URL .</li>
</ul>

<h3>Title: Sign-Symmetry Learning Rules are Robust Fine-Tuners</h3>
<ul>
<li><strong>Authors: </strong>Aymene Berriche, Mehdi Zakaria Adjal, Riyadh Baghdadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05925">https://arxiv.org/abs/2502.05925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05925">https://arxiv.org/pdf/2502.05925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05925]] Sign-Symmetry Learning Rules are Robust Fine-Tuners(https://arxiv.org/abs/2502.05925)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Backpropagation (BP) has long been the predominant method for training neural networks due to its effectiveness. However, numerous alternative approaches, broadly categorized under feedback alignment, have been proposed, many of which are motivated by the search for biologically plausible learning mechanisms. Despite their theoretical appeal, these methods have consistently underperformed compared to BP, leading to a decline in research interest. In this work, we revisit the role of such methods and explore how they can be integrated into standard neural network training pipelines. Specifically, we propose fine-tuning BP-pre-trained models using Sign-Symmetry learning rules and demonstrate that this approach not only maintains performance parity with BP but also enhances robustness. Through extensive experiments across multiple tasks and benchmarks, we establish the validity of our approach. Our findings introduce a novel perspective on neural network training and open new research directions for leveraging biologically inspired learning rules in deep learning.</li>
</ul>

<h3>Title: Protecting Intellectual Property of EEG-based Neural Networks with Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Abdelaziz, Ahmed Fathi, Ahmed Fares</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05931">https://arxiv.org/abs/2502.05931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05931">https://arxiv.org/pdf/2502.05931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05931]] Protecting Intellectual Property of EEG-based Neural Networks with Watermarking(https://arxiv.org/abs/2502.05931)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, attack, robust, biometric, watermark</a></li>
<li><strong>Abstract: </strong>EEG-based neural networks, pivotal in medical diagnosis and brain-computer interfaces, face significant intellectual property (IP) risks due to their reliance on sensitive neurophysiological data and resource-intensive development. Current watermarking methods, particularly those using abstract trigger sets, lack robust authentication and fail to address the unique challenges of EEG models. This paper introduces a cryptographic wonder filter-based watermarking framework tailored for EEG-based neural networks. Leveraging collision-resistant hashing and public-key encryption, the wonder filter embeds the watermark during training, ensuring minimal distortion ($\leq 5\%$ drop in EEG task accuracy) and high reliability (100\% watermark detection). The framework is rigorously evaluated against adversarial attacks, including fine-tuning, transfer learning, and neuron pruning. Results demonstrate persistent watermark retention, with classification accuracy for watermarked states remaining above 90\% even after aggressive pruning, while primary task performance degrades faster, deterring removal attempts. Piracy resistance is validated by the inability to embed secondary watermarks without severe accuracy loss ( $>10\%$ in EEGNet and CCNN models). Cryptographic hashing ensures authentication, reducing brute-force attack success probabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet, TSception), the method achieves $>99.4\%$ null-embedding accuracy, effectively eliminating false positives. By integrating wonder filters with EEG-specific adaptations, this work bridges a critical gap in IP protection for neurophysiological models, offering a secure, tamper-proof solution for healthcare and biometric applications. The framework's robustness against adversarial modifications underscores its potential to safeguard sensitive EEG models while maintaining diagnostic utility.</li>
</ul>

<h3>Title: Learning to Substitute Words with Model-based Score Ranking</h3>
<ul>
<li><strong>Authors: </strong>Hongye Liu, Ricardo Henao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05933">https://arxiv.org/abs/2502.05933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05933">https://arxiv.org/pdf/2502.05933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05933]] Learning to Substitute Words with Model-based Score Ranking(https://arxiv.org/abs/2502.05933)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Smart word substitution aims to enhance sentence quality by improving word choices; however current benchmarks rely on human-labeled data. Since word choices are inherently subjective, ground-truth word substitutions generated by a small group of annotators are often incomplete and likely not generalizable. To circumvent this issue, we instead employ a model-based score (BARTScore) to quantify sentence quality, thus forgoing the need for human annotations. Specifically, we use this score to define a distribution for each word substitution, allowing one to test whether a substitution is statistically superior relative to others. In addition, we propose a loss function that directly optimizes the alignment between model predictions and sentence scores, while also enhancing the overall quality score of a substitution. Crucially, model learning no longer requires human labels, thus avoiding the cost of annotation while maintaining the quality of the text modified with substitutions. Experimental results show that the proposed approach outperforms both masked language models (BERT, BART) and large language models (GPT-4, LLaMA). The source code is available at this https URL.</li>
</ul>

<h3>Title: A Semi-Supervised Text Generation Framework Combining a Deep Transformer and a GAN</h3>
<ul>
<li><strong>Authors: </strong>Shengquan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05937">https://arxiv.org/abs/2502.05937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05937">https://arxiv.org/pdf/2502.05937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05937]] A Semi-Supervised Text Generation Framework Combining a Deep Transformer and a GAN(https://arxiv.org/abs/2502.05937)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces a framework that connects a deep generative pre-trained Transformer language model with a generative adversarial network for semi-supervised text generation. In other words, the proposed model is first pre-trained unsupervised on a large and diverse text corpus with 24 layers. Then a simple GAN architecture for synthetic text generation is introduced, and Gumbel-Softmax is applied to handle the discreteness of tokens. The paper also shows a semi-supervised approach where real data is augmented with GAN samples, which is further used to fine-tune the Transformer model on the merged dataset. Detailed theoretical derivations are also included, outlining the proof of the min-max objective function, and an extensive discussion of the Gumbel-Softmax reparameterization trick.</li>
</ul>

<h3>Title: Multi-granular Training Strategies for Robust Multi-hop Reasoning Over Noisy and Heterogeneous Knowledge Sources</h3>
<ul>
<li><strong>Authors: </strong>Jackson Coleman, Isaiah Lawrence, Benjamin Turner</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05944">https://arxiv.org/abs/2502.05944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05944">https://arxiv.org/pdf/2502.05944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05944]] Multi-granular Training Strategies for Robust Multi-hop Reasoning Over Noisy and Heterogeneous Knowledge Sources(https://arxiv.org/abs/2502.05944)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Multi-source multi-hop question answering (QA) represents a challenging task in natural language processing due to the need for dynamic integration of heterogeneous knowledge sources and multi-step reasoning. Existing methods often suffer from cascading errors, insufficient handling of knowledge conflicts, and computational inefficiency. In this paper, we propose Adaptive Multi-source Knowledge-Oriented Reasoning (AMKOR), a generative framework that leverages large language models (LLMs) to dynamically fuse parametric and retrieved knowledge while exploring reasoning trajectories using probabilistic beam reasoning. AMKOR is further enhanced by a multi-granular learning strategy, optimizing both local reasoning steps and global answer accuracy. Experiments conducted on four widely-used multi-hop QA datasets, including HotpotQA and MuSiQue, demonstrate that AMKOR achieves state-of-the-art performance, significantly outperforming baseline methods on both reasoning accuracy and robustness. Additional analyses confirm its scalability, adaptability to noisy knowledge, and superior ability to handle complex multi-hop tasks. This work establishes a new benchmark for multi-source multi-hop QA by effectively combining reasoning quality and efficiency.</li>
</ul>

<h3>Title: "Let the AI conspiracy begin..." Language Model coordination is just one inference-intervention away</h3>
<ul>
<li><strong>Authors: </strong>Paul Darm, Annalisa Riccardi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05945">https://arxiv.org/abs/2502.05945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05945">https://arxiv.org/pdf/2502.05945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05945]] "Let the AI conspiracy begin..." Language Model coordination is just one inference-intervention away(https://arxiv.org/abs/2502.05945)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we introduce a straightforward and effective methodology to steer large language model behaviour capable of bypassing learned alignment goals. We employ interference-time activation shifting, which is effective without additional training. Following prior studies, we derive intervention directions from activation differences in contrastive pairs of model outputs, which represent the desired and undesired behaviour. By prompting the model to include multiple-choice answers in its response, we can automatically evaluate the sensitivity of model output to individual attention heads steering efforts. We demonstrate that interventions on these heads generalize well to open-ended answer generation in the challenging "AI coordination" dataset. In this dataset, models must choose between assisting another AI or adhering to ethical, safe, and unharmful behaviour. Our fine-grained interventions lead Llama 2 to prefer coordination with other AIs over following established alignment goals. Additionally, this approach enables stronger interventions than those applied to whole model layers, preserving the overall cohesiveness of the output. The simplicity of our method highlights the shortcomings of current alignment strategies and points to potential future research directions, as concepts like "AI coordination" can be influenced by selected attention heads.</li>
</ul>

<h3>Title: Acceleration Multiple Heads Decoding for LLM via Dynamic Tree Attention</h3>
<ul>
<li><strong>Authors: </strong>Zhendong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05947">https://arxiv.org/abs/2502.05947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05947">https://arxiv.org/pdf/2502.05947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05947]] Acceleration Multiple Heads Decoding for LLM via Dynamic Tree Attention(https://arxiv.org/abs/2502.05947)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multiple heads decoding accelerates the inference of Large Language Models (LLMs) by predicting next several tokens simultaneously. It generates and verifies multiple candidate sequences in parallel via tree attention with a fixed structure. In this paper, we replace the fixed tree attention with dynamic tree attention on multiple head decoding, specifically in the context of MEDUSA. We propose a simple and low complexity strategy to generate candidates and construct the dynamic tree structure. Preliminary experiments show that the proposed method improves the decoding efficiency of multiple head decoding for LLMs while maintaining the generation quality. This result demonstrates the potential for improvement of multiple head decoding in candidate generation.</li>
</ul>

<h3>Title: Survival Concept-Based Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Stanislav R. Kirpichenko, Lev V. Utkin, Andrei V. Konstantinov, Natalya M. Verbova</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05950">https://arxiv.org/abs/2502.05950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05950">https://arxiv.org/pdf/2502.05950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05950]] Survival Concept-Based Learning Models(https://arxiv.org/abs/2502.05950)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Concept-based learning enhances prediction accuracy and interpretability by leveraging high-level, human-understandable concepts. However, existing CBL frameworks do not address survival analysis tasks, which involve predicting event times in the presence of censored data -- a common scenario in fields like medicine and reliability analysis. To bridge this gap, we propose two novel models: SurvCBM (Survival Concept-based Bottleneck Model) and SurvRCM (Survival Regularized Concept-based Model), which integrate concept-based learning with survival analysis to handle censored event time data. The models employ the Cox proportional hazards model and the Beran estimator. SurvCBM is based on the architecture of the well-known concept bottleneck model, offering interpretable predictions through concept-based explanations. SurvRCM uses concepts as regularization to enhance accuracy. Both models are trained end-to-end and provide interpretable predictions in terms of concepts. Two interpretability approaches are proposed: one leveraging the linear relationship in the Cox model and another using an instance-based explanation framework with the Beran estimator. Numerical experiments demonstrate that SurvCBM outperforms SurvRCM and traditional survival models, underscoring the importance and advantages of incorporating concept information. The code for the proposed algorithms is publicly available.</li>
</ul>

<h3>Title: Redefining Robot Generalization Through Interactive Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Sharmita Dey</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05963">https://arxiv.org/abs/2502.05963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05963">https://arxiv.org/pdf/2502.05963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05963]] Redefining Robot Generalization Through Interactive Intelligence(https://arxiv.org/abs/2502.05963)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in large-scale machine learning have produced high-capacity foundation models capable of adapting to a broad array of downstream tasks. While such models hold great promise for robotics, the prevailing paradigm still portrays robots as single, autonomous decision-makers, performing tasks like manipulation and navigation, with limited human involvement. However, a large class of real-world robotic systems, including wearable robotics (e.g., prostheses, orthoses, exoskeletons), teleoperation, and neural interfaces, are semiautonomous, and require ongoing interactive coordination with human partners, challenging single-agent assumptions. In this position paper, we argue that robot foundation models must evolve to an interactive multi-agent perspective in order to handle the complexities of real-time human-robot co-adaptation. We propose a generalizable, neuroscience-inspired architecture encompassing four modules: (1) a multimodal sensing module informed by sensorimotor integration principles, (2) an ad-hoc teamwork model reminiscent of joint-action frameworks in cognitive science, (3) a predictive world belief model grounded in internal model theories of motor control, and (4) a memory/feedback mechanism that echoes concepts of Hebbian and reinforcement-based plasticity. Although illustrated through the lens of cyborg systems, where wearable devices and human physiology are inseparably intertwined, the proposed framework is broadly applicable to robots operating in semi-autonomous or interactive contexts. By moving beyond single-agent designs, our position emphasizes how foundation models in robotics can achieve a more robust, personalized, and anticipatory level of performance.</li>
</ul>

<h3>Title: $\mu$nit Scaling: Simple and Scalable FP8 LLM Training</h3>
<ul>
<li><strong>Authors: </strong>Saaketh Narayan, Abhay Gupta, Mansheej Paul, Davis Blalock</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05967">https://arxiv.org/abs/2502.05967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05967">https://arxiv.org/pdf/2502.05967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05967]] $\mu$nit Scaling: Simple and Scalable FP8 LLM Training(https://arxiv.org/abs/2502.05967)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model training with 8-bit floating point (FP8) formats promises significant efficiency improvements, but reduced numerical precision makes training challenging. It is currently possible to train in FP8 only if one is willing to tune various hyperparameters, reduce model scale, or accept the overhead of computing dynamic scale factors. We demonstrate simple, scalable FP8 training that requires no dynamic scaling factors or special hyperparameters, even at large model sizes. Our method, $\mu$nit Scaling ($\mu$S), also enables simple hyperparameter transfer across model widths, matched numerics across training and inference, and other desirable properties. $\mu$nit Scaling is straightforward to implement, consisting of a set of minimal interventions based on a first-principles analysis of common transformer operations. We validate our method by training models from 1B to 13B parameters, performing all hidden linear layer computations in FP8. We achieve quality equal to higher precision baselines while also training up to 33% faster.</li>
</ul>

<h3>Title: VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Liu, Ailing Zeng, Wei Xue, Harry Yang, Wenhan Luo, Qifeng Liu, Yike Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05979">https://arxiv.org/abs/2502.05979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05979">https://arxiv.org/pdf/2502.05979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05979]] VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer(https://arxiv.org/abs/2502.05979)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Crafting magic and illusions is one of the most thrilling aspects of filmmaking, with visual effects (VFX) serving as the powerhouse behind unforgettable cinematic experiences. While recent advances in generative artificial intelligence have driven progress in generic image and video synthesis, the domain of controllable VFX generation remains relatively underexplored. In this work, we propose a novel paradigm for animated VFX generation as image animation, where dynamic effects are generated from user-friendly textual descriptions and static reference images. Our work makes two primary contributions: (i) Open-VFX, the first high-quality VFX video dataset spanning 15 diverse effect categories, annotated with textual descriptions, instance segmentation masks for spatial conditioning, and start-end timestamps for temporal control. (ii) VFX Creator, a simple yet effective controllable VFX generation framework based on a Video Diffusion Transformer. The model incorporates a spatial and temporal controllable LoRA adapter, requiring minimal training videos. Specifically, a plug-and-play mask control module enables instance-level spatial manipulation, while tokenized start-end motion timestamps embedded in the diffusion process, alongside the text encoder, allow precise temporal control over effect timing and pace. Extensive experiments on the Open-VFX test set demonstrate the superiority of the proposed system in generating realistic and dynamic effects, achieving state-of-the-art performance and generalization ability in both spatial and temporal controllability. Furthermore, we introduce a specialized metric to evaluate the precision of temporal control. By bridging traditional VFX techniques with generative approaches, VFX Creator unlocks new possibilities for efficient and high-quality video effect generation, making advanced VFX accessible to a broader audience.</li>
</ul>

<h3>Title: HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered Therapy Using LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Amin Abbasi, Farnaz Sadat Mirnezami, Hassan Naderi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.05982">https://arxiv.org/abs/2502.05982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.05982">https://arxiv.org/pdf/2502.05982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.05982]] HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered Therapy Using LLM Agents(https://arxiv.org/abs/2502.05982)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents HamRaz, a novel Persian-language mental health dataset designed for Person-Centered Therapy (PCT) using Large Language Models (LLMs). Despite the growing application of LLMs in AI-driven psychological counseling, existing datasets predominantly focus on Western and East Asian contexts, overlooking cultural and linguistic nuances essential for effective Persian-language therapy. To address this gap, HamRaz combines script-based dialogues with adaptive LLM role-playing, ensuring coherent and dynamic therapy interactions. We also introduce HamRazEval, a dual evaluation framework that measures conversational quality and therapeutic effectiveness using General Dialogue Metrics and the Barrett-Lennard Relationship Inventory (BLRI). Experimental results show HamRaz outperforms conventional Script Mode and Two-Agent Mode, producing more empathetic, context-aware, and realistic therapy sessions. By releasing HamRaz, we contribute a culturally adapted, LLM-driven resource to advance AI-powered psychotherapy research in diverse communities.</li>
</ul>

<h3>Title: The AI Security Zugzwang</h3>
<ul>
<li><strong>Authors: </strong>Lampis Alevizos</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06000">https://arxiv.org/abs/2502.06000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06000">https://arxiv.org/pdf/2502.06000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06000]] The AI Security Zugzwang(https://arxiv.org/abs/2502.06000)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>In chess, zugzwang describes a scenario where any move worsens the player's position. Organizations face a similar dilemma right now at the intersection of artificial intelligence (AI) and cybersecurity. AI adoption creates an inevitable paradox: delaying it poses strategic risks, rushing it introduces poorly understood vulnerabilities, and even incremental adoption leads to cascading complexities. In this work we formalize this challenge as the AI Security Zugzwang, a phenomenon where security leaders must make decisions under conditions of inevitable risk. Grounded in game theory, security economics, and organizational decision theory, we characterize AI security zugzwang through three key properties, the forced movement, predictable vulnerability creation, and temporal pressure. Additionally, we develop a taxonomy to categorize forced-move scenarios across AI adoption, implementation, operational and governance contexts and provide corresponding strategic mitigations. Our framework is supported by a practical decision flowchart, demonstrated through a real-world example of Copilot adoption, thus, showing how security lead</li>
</ul>

<h3>Title: Analysis of LLM as a grammatical feature tagger for African American English</h3>
<ul>
<li><strong>Authors: </strong>Rahul Porwal, Alice Rozet, Pryce Houck, Jotsna Gowda, Sarah Moeller, Kevin Tang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06004">https://arxiv.org/abs/2502.06004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06004">https://arxiv.org/pdf/2502.06004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06004]] Analysis of LLM as a grammatical feature tagger for African American English(https://arxiv.org/abs/2502.06004)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>African American English (AAE) presents unique challenges in natural language processing (NLP). This research systematically compares the performance of available NLP models--rule-based, transformer-based, and large language models (LLMs)--capable of identifying key grammatical features of AAE, namely Habitual Be and Multiple Negation. These features were selected for their distinct grammatical complexity and frequency of occurrence. The evaluation involved sentence-level binary classification tasks, using both zero-shot and few-shot strategies. The analysis reveals that while LLMs show promise compared to the baseline, they are influenced by biases such as recency and unrelated features in the text such as formality. This study highlights the necessity for improved model training and architectural adjustments to better accommodate AAE's unique linguistic characteristics. Data and code are available.</li>
</ul>

<h3>Title: Kolmogorov-Arnold Fourier Networks</h3>
<ul>
<li><strong>Authors: </strong>Jusheng Zhang, Yijia Fan, Kaitong Cai, Keze Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06018">https://arxiv.org/abs/2502.06018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06018">https://arxiv.org/pdf/2502.06018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06018]] Kolmogorov-Arnold Fourier Networks(https://arxiv.org/abs/2502.06018)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Although Kolmogorov-Arnold based interpretable networks (KAN) have strong theoretical expressiveness, they face significant parameter explosion and high-frequency feature capture challenges in high-dimensional tasks. To address this issue, we propose the Kolmogorov-Arnold-Fourier Network (KAF), which effectively integrates trainable Random Fourier Features (RFF) and a novel hybrid GELU-Fourier activation mechanism to balance parameter efficiency and spectral representation capabilities. Our key technical contributions include: (1) merging KAN's dual-matrix structure through matrix association properties to substantially reduce parameters; (2) introducing learnable RFF initialization strategies to eliminate spectral distortion in high-dimensional approximation tasks; (3) implementing an adaptive hybrid activation function that progressively enhances frequency representation during the training process. Comprehensive experiments demonstrate the superiority of our KAF across various domains including vision, NLP, audio processing, and differential equation-solving tasks, effectively combining theoretical interpretability with practical utility and computational efficiency.</li>
</ul>

<h3>Title: Dual Caption Preference Optimization for Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Amir Saeidi, Yiran Luo, Agneet Chatterjee, Shamanthak Hegde, Bimsara Pathiraja, Yezhou Yang, Chitta Baral</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06023">https://arxiv.org/abs/2502.06023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06023">https://arxiv.org/pdf/2502.06023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06023]] Dual Caption Preference Optimization for Diffusion Models(https://arxiv.org/abs/2502.06023)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in human preference optimization, originally developed for Large Language Models (LLMs), have shown significant potential in improving text-to-image diffusion models. These methods aim to learn the distribution of preferred samples while distinguishing them from less preferred ones. However, existing preference datasets often exhibit overlap between these distributions, leading to a conflict distribution. Additionally, we identified that input prompts contain irrelevant information for less preferred images, limiting the denoising network's ability to accurately predict noise in preference optimization methods, known as the irrelevant prompt issue. To address these challenges, we propose Dual Caption Preference Optimization (DCPO), a novel approach that utilizes two distinct captions to mitigate irrelevant prompts. To tackle conflict distribution, we introduce the Pick-Double Caption dataset, a modified version of Pick-a-Pic v2 with separate captions for preferred and less preferred images. We further propose three different strategies for generating distinct captions: captioning, perturbation, and hybrid methods. Our experiments show that DCPO significantly improves image quality and relevance to prompts, outperforming Stable Diffusion (SD) 2.1, SFT_Chosen, Diffusion-DPO, and MaPO across multiple metrics, including Pickscore, HPSv2.1, GenEval, CLIPscore, and ImageReward, fine-tuned on SD 2.1 as the backbone.</li>
</ul>

<h3>Title: A Multimodal PDE Foundation Model for Prediction and Scientific Text Descriptions</h3>
<ul>
<li><strong>Authors: </strong>Elisa Negrini, Yuxuan Liu, Liu Yang, Stanley J. Osher, Hayden Schaeffer</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06026">https://arxiv.org/abs/2502.06026</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06026">https://arxiv.org/pdf/2502.06026</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06026]] A Multimodal PDE Foundation Model for Prediction and Scientific Text Descriptions(https://arxiv.org/abs/2502.06026)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Neural networks are one tool for approximating non-linear differential equations used in scientific computing tasks such as surrogate modeling, real-time predictions, and optimal control. PDE foundation models utilize neural networks to train approximations to multiple differential equations simultaneously and are thus a general purpose solver that can be adapted to downstream tasks. Current PDE foundation models focus on either learning general solution operators and/or the governing system of equations, and thus only handle numerical or symbolic modalities. However, real-world applications may require more flexible data modalities, e.g. text analysis or descriptive outputs. To address this gap, we propose a novel multimodal deep learning approach that leverages a transformer-based architecture to approximate solution operators for a wide variety of ODEs and PDEs. Our method integrates numerical inputs, such as equation parameters and initial conditions, with text descriptions of physical processes or system dynamics. This enables our model to handle settings where symbolic representations may be incomplete or unavailable. In addition to providing accurate numerical predictions, our approach generates interpretable scientific text descriptions, offering deeper insights into the underlying dynamics and solution properties. The numerical experiments show that our model provides accurate solutions for in-distribution data (with average relative error less than 3.3%) and out-of-distribution data (average relative error less than 7.8%) together with precise text descriptions (with correct descriptions generated 100% of times). In certain tests, the model is also shown to be capable of extrapolating solutions in time.</li>
</ul>

<h3>Title: Generating 3D Binding Molecules Using Shape-Conditioned Diffusion Models with Guidance</h3>
<ul>
<li><strong>Authors: </strong>Ziqi Chen, Bo Peng, Tianhua Zhai, Daniel Adu-Ampratwum, Xia Ning</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06027">https://arxiv.org/abs/2502.06027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06027">https://arxiv.org/pdf/2502.06027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06027]] Generating 3D Binding Molecules Using Shape-Conditioned Diffusion Models with Guidance(https://arxiv.org/abs/2502.06027)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Drug development is a critical but notoriously resource- and time-consuming process. In this manuscript, we develop a novel generative artificial intelligence (genAI) method DiffSMol to facilitate drug development. DiffSmol generates 3D binding molecules based on the shapes of known ligands. DiffSMol encapsulates geometric details of ligand shapes within pre-trained, expressive shape embeddings and then generates new binding molecules through a diffusion model. DiffSMol further modifies the generated 3D structures iteratively via shape guidance to better resemble the ligand shapes. It also tailors the generated molecules toward optimal binding affinities under the guidance of protein pockets. Here, we show that DiffSMol outperforms the state-of-the-art methods on benchmark datasets. When generating binding molecules resembling ligand shapes, DiffSMol with shape guidance achieves a success rate 61.4%, substantially outperforming the best baseline (11.2%), meanwhile producing molecules with novel molecular graph structures. DiffSMol with pocket guidance also outperforms the best baseline in binding affinities by 13.2%, and even by 17.7% when combined with shape guidance. Case studies for two critical drug targets demonstrate very favorable physicochemical and pharmacokinetic properties of the generated molecules, thus, the potential of DiffSMol in developing promising drug candidates.</li>
</ul>

<h3>Title: DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations</h3>
<ul>
<li><strong>Authors: </strong>Krishna Sri Ipsit Mantri, Carola-Bibiane Sch√∂nlieb, Bruno Ribeiro, Chaim Baskin, Moshe Eliasof</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06029">https://arxiv.org/abs/2502.06029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06029">https://arxiv.org/pdf/2502.06029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06029]] DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations(https://arxiv.org/abs/2502.06029)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Pre-trained Vision Transformers now serve as powerful tools for computer vision. Yet, efficiently adapting them for multiple tasks remains a challenge that arises from the need to modify the rich hidden representations encoded by the learned weight matrices, without inducing interference between tasks. Current parameter-efficient methods like LoRA, which apply low-rank updates, force tasks to compete within constrained subspaces, ultimately degrading performance. We introduce DiTASK a novel Diffeomorphic Multi-Task Fine-Tuning approach that maintains pre-trained representations by preserving weight matrix singular vectors, while enabling task-specific adaptations through neural diffeomorphic transformations of the singular values. By following this approach, DiTASK enables both shared and task-specific feature modulations with minimal added parameters. Our theoretical analysis shows that DITASK achieves full-rank updates during optimization, preserving the geometric structure of pre-trained features, and establishing a new paradigm for efficient multi-task learning (MTL). Our experiments on PASCAL MTL and NYUD show that DiTASK achieves state-of-the-art performance across four dense prediction tasks, using 75% fewer parameters than existing methods.</li>
</ul>

<h3>Title: A Conditional Tabular GAN-Enhanced Intrusion Detection System for Rare Attacks in IoT Networks</h3>
<ul>
<li><strong>Authors: </strong>Safaa Menssouri, El Mehdi Amhoud</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06031">https://arxiv.org/abs/2502.06031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06031">https://arxiv.org/pdf/2502.06031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06031]] A Conditional Tabular GAN-Enhanced Intrusion Detection System for Rare Attacks in IoT Networks(https://arxiv.org/abs/2502.06031)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Internet of things (IoT) networks, boosted by 6G technology, are transforming various industries. However, their widespread adoption introduces significant security risks, particularly in detecting rare but potentially damaging cyber-attacks. This makes the development of robust IDS crucial for monitoring network traffic and ensuring their safety. Traditional IDS often struggle with detecting rare attacks due to severe class imbalances in IoT data. In this paper, we propose a novel two-stage system called conditional tabular generative synthetic minority data generation with deep neural network (CTGSM-DNN). In the first stage, a conditional tabular generative adversarial network (CTGAN) is employed to generate synthetic data for rare attack classes. In the second stage, the SMOTEENN method is applied to improve dataset quality. The full study was conducted using the CSE-CIC-IDS2018 dataset, and we assessed the performance of the proposed IDS using different evaluation metrics. The experimental results demonstrated the effectiveness of the proposed multiclass classifier, achieving an overall accuracy of 99.90% and 80% accuracy in detecting rare attacks.</li>
</ul>

<h3>Title: Stateful Hash-Based Signature (SHBS) Benchmark Data for XMSS and LMS</h3>
<ul>
<li><strong>Authors: </strong>Brian Romansky, Thomas Mazzuchi, Shahram Sarkani</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06033">https://arxiv.org/abs/2502.06033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06033">https://arxiv.org/pdf/2502.06033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06033]] Stateful Hash-Based Signature (SHBS) Benchmark Data for XMSS and LMS(https://arxiv.org/abs/2502.06033)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>The National Institute of Standards and Technology (NIST) has recommended the use of stateful hash-based digital signatures for long-term applications that may require protection from future threats that use quantum computers. XMSS and LMS, the two approved algorithms, have multiple parameter options that impact digital signature size, public key size, the number of signatures that can be produced over the life of a keypair, and the computational effort to validate signatures. This collection of benchmark data is intended to support system designers in understanding the differences among the configuration options.</li>
</ul>

<h3>Title: Traveling Waves Integrate Spatial Information Into Spectral Representations</h3>
<ul>
<li><strong>Authors: </strong>Mozes Jacobs, Roberto C. Budzinski, Lyle Muller, Demba Ba, T. Anderson Keller</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06034">https://arxiv.org/abs/2502.06034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06034">https://arxiv.org/pdf/2502.06034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06034]] Traveling Waves Integrate Spatial Information Into Spectral Representations(https://arxiv.org/abs/2502.06034)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Traveling waves are widely observed in the brain, but their precise computational function remains unclear. One prominent hypothesis is that they enable the transfer and integration of spatial information across neural populations. However, few computational models have explored how traveling waves might be harnessed to perform such integrative processing. Drawing inspiration from the famous ``Can one hear the shape of a drum?'' problem -- which highlights how spectral modes encode geometric information -- we introduce a set of convolutional recurrent neural networks that learn to produce traveling waves in their hidden states in response to visual stimuli. By applying a spectral decomposition to these wave-like activations, we obtain a powerful new representational space that outperforms equivalently local feed-forward networks on tasks requiring global spatial context. In particular, we observe that traveling waves effectively expand the receptive field of locally connected neurons, supporting long-range encoding and communication of information. We demonstrate that models equipped with this mechanism and spectral readouts solve visual semantic segmentation tasks demanding global integration, where local feed-forward models fail. As a first step toward traveling-wave-based representations in artificial networks, our findings suggest potential efficiency benefits and offer a new framework for connecting to biological recordings of neural activity.</li>
</ul>

<h3>Title: Investigating Compositional Reasoning in Time Series Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Willa Potosnak, Cristian Challu, Mononito Goswami, Kin G. Olivares, Micha≈Ç Wili≈Ñski, Nina ≈ªukowska, Artur Dubrawski</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06037">https://arxiv.org/abs/2502.06037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06037">https://arxiv.org/pdf/2502.06037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06037]] Investigating Compositional Reasoning in Time Series Foundation Models(https://arxiv.org/abs/2502.06037)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large pre-trained time series foundation models (TSFMs) have demonstrated promising zero-shot performance across a wide range of domains. However, a question remains: Do TSFMs succeed solely by memorizing training patterns, or do they possess the ability to reason? While reasoning is a topic of great interest in the study of Large Language Models (LLMs), it is undefined and largely unexplored in the context of TSFMs. In this work, inspired by language modeling literature, we formally define compositional reasoning in forecasting and distinguish it from in-distribution generalization. We evaluate the reasoning and generalization capabilities of 23 popular deep learning forecasting models on multiple synthetic and real-world datasets. Additionally, through controlled studies, we systematically examine which design choices in TSFMs contribute to improved reasoning abilities. Our study yields key insights into the impact of TSFM architecture design on compositional reasoning and generalization. We find that patch-based Transformers have the best reasoning performance, closely followed by residualized MLP-based architectures, which are 97\% less computationally complex in terms of FLOPs and 86\% smaller in terms of the number of trainable parameters. Interestingly, in some zero-shot out-of-distribution scenarios, these models can outperform moving average and exponential smoothing statistical baselines trained on in-distribution data. Only a few design choices, such as the tokenization method, had a significant (negative) impact on Transformer model performance.</li>
</ul>

<h3>Title: Provably Overwhelming Transformer Models with Designed Inputs</h3>
<ul>
<li><strong>Authors: </strong>Lev Stambler, Seyed Sajjad Nezhadi, Matthew Coudron</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06038">https://arxiv.org/abs/2502.06038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06038">https://arxiv.org/pdf/2502.06038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06038]] Provably Overwhelming Transformer Models with Designed Inputs(https://arxiv.org/abs/2502.06038)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We develop an algorithm which, given a trained transformer model $\mathcal{M}$ as input, as well as a string of tokens $s$ of length $n_{fix}$ and an integer $n_{free}$, can generate a mathematical proof that $\mathcal{M}$ is ``overwhelmed'' by $s$, in time and space $\widetilde{O}(n_{fix}^2 + n_{free}^3)$. We say that $\mathcal{M}$ is ``overwhelmed'' by $s$ when the output of the model evaluated on this string plus any additional string $t$, $\mathcal{M}(s + t)$, is completely insensitive to the value of the string $t$ whenever length($t$) $\leq n_{free}$. Along the way, we prove a particularly strong worst-case form of ``over-squashing'', which we use to bound the model's behavior. Our technique uses computer-aided proofs to establish this type of operationally relevant guarantee about transformer models. We empirically test our algorithm on a single layer transformer complete with an attention head, layer-norm, MLP/ReLU layers, and RoPE positional encoding. We believe that this work is a stepping stone towards the difficult task of obtaining useful guarantees for trained transformer models.</li>
</ul>

<h3>Title: Hierarchical Polysemantic Feature Embedding for Autonomous Ransomware Detection</h3>
<ul>
<li><strong>Authors: </strong>Sergei Nikitka, Sebastian Harringford, Charlotte Montgomery, Algernon Braithwaite, Matthew Kowalski</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06043">https://arxiv.org/abs/2502.06043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06043">https://arxiv.org/pdf/2502.06043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06043]] Hierarchical Polysemantic Feature Embedding for Autonomous Ransomware Detection(https://arxiv.org/abs/2502.06043)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>The evolution of ransomware requires the development of more sophisticated detection methodologies capable of identifying malicious behaviors beyond traditional signature-based and heuristic techniques. The proposed Hierarchical Polysemantic Feature Embedding framework introduces a structured approach to ransomware detection through hyperbolic feature representations that capture hierarchical dependencies within executable behaviors. By embedding ransomware-relevant features into a non-Euclidean space, the framework maintains a well-defined decision boundary, ensuring improved generalization across previously unseen ransomware variants. Experimental evaluations demonstrated that the framework consistently outperformed conventional machine learning-based models, achieving higher detection accuracy while maintaining low false positive rates. The structured clustering mechanism employed within the hyperbolic space enabled robust classification even in the presence of obfuscation techniques, delayed execution strategies, and polymorphic transformations. Comparative analysis highlighted the limitations of existing detection frameworks, particularly in their inability to dynamically adapt to evolving ransomware tactics. Computational efficiency assessments indicated that the proposed method maintained a balance between detection performance and processing overhead, making it a viable candidate for real-world cybersecurity applications. The ability to detect emerging ransomware families without requiring extensive retraining demonstrated the adaptability of hierarchical embeddings in security analytics.</li>
</ul>

<h3>Title: Neural Shortest Path for Surface Reconstruction from Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Yesom Park, Imseong Park, Jooyoung Hahn, Myungjoo Kang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06047">https://arxiv.org/abs/2502.06047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06047">https://arxiv.org/pdf/2502.06047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06047]] Neural Shortest Path for Surface Reconstruction from Point Clouds(https://arxiv.org/abs/2502.06047)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we propose the neural shortest path (NSP), a vector-valued implicit neural representation (INR) that approximates a distance function and its gradient. The key feature of NSP is to learn the exact shortest path (ESP), which directs an arbitrary point to its nearest point on the target surface. The NSP is decomposed into its magnitude and direction, and a variable splitting method is used that each decomposed component approximates a distance function and its gradient, respectively. Unlike to existing methods of learning the distance function itself, the NSP ensures the simultaneous recovery of the distance function and its gradient. We mathematically prove that the decomposed representation of NSP guarantees the convergence of the magnitude of NSP in the $H^1$ norm. Furthermore, we devise a novel loss function that enforces the property of ESP, demonstrating that its global minimum is the ESP. We evaluate the performance of the NSP through comprehensive experiments on diverse datasets, validating its capacity to reconstruct high-quality surfaces with the robustness to noise and data sparsity. The numerical results show substantial improvements over state-of-the-art methods, highlighting the importance of learning the ESP, the product of distance function and its gradient, for representing a wide variety of complex surfaces.</li>
</ul>

<h3>Title: LM2: Large Memory Models</h3>
<ul>
<li><strong>Authors: </strong>Jikun Kang, Wenqi Wu, Filippos Christianos, Alex J. Chan, Fraser Greenlee, George Thomas, Marvin Purtorab, Andy Toulis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06049">https://arxiv.org/abs/2502.06049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06049">https://arxiv.org/pdf/2502.06049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06049]] LM2: Large Memory Models(https://arxiv.org/abs/2502.06049)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces the Large Memory Model (LM2), a decoder-only Transformer architecture enhanced with an auxiliary memory module that aims to address the limitations of standard Transformers in multi-step reasoning, relational argumentation, and synthesizing information distributed over long contexts. The proposed LM2 incorporates a memory module that acts as a contextual representation repository, interacting with input tokens via cross attention and updating through gating mechanisms. To preserve the Transformers general-purpose capabilities, LM2 maintains the original information flow while integrating a complementary memory pathway. Experimental results on the BABILong benchmark demonstrate that the LM2model outperforms both the memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3% on average across tasks. LM2 exhibits exceptional capabilities in multi-hop inference, numerical reasoning, and large-context question-answering. On the MMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model, demonstrating that its memory module does not degrade performance on general tasks. Further, in our analysis, we explore the memory interpretability, effectiveness of memory modules, and test-time behavior. Our findings emphasize the importance of explicit memory in enhancing Transformer architectures.</li>
</ul>

<h3>Title: Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Fan, Shuaike Shen, Chaoran Cheng, Yuxin Chen, Chumeng Liang, Ge Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06061">https://arxiv.org/abs/2502.06061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06061">https://arxiv.org/pdf/2502.06061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06061]] Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization(https://arxiv.org/abs/2502.06061)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in reinforcement learning (RL) have achieved great success in fine-tuning diffusion-based generative models. However, fine-tuning continuous flow-based generative models to align with arbitrary user-defined reward functions remains challenging, particularly due to issues such as policy collapse from overoptimization and the prohibitively high computational cost of likelihoods in continuous-time flows. In this paper, we propose an easy-to-use and theoretically sound RL fine-tuning method, which we term Online Reward-Weighted Conditional Flow Matching with Wasserstein-2 Regularization (ORW-CFM-W2). Our method integrates RL into the flow matching framework to fine-tune generative models with arbitrary reward functions, without relying on gradients of rewards or filtered datasets. By introducing an online reward-weighting mechanism, our approach guides the model to prioritize high-reward regions in the data manifold. To prevent policy collapse and maintain diversity, we incorporate Wasserstein-2 (W2) distance regularization into our method and derive a tractable upper bound for it in flow matching, effectively balancing exploration and exploitation of policy optimization. We provide theoretical analyses to demonstrate the convergence properties and induced data distributions of our method, establishing connections with traditional RL algorithms featuring Kullback-Leibler (KL) regularization and offering a more comprehensive understanding of the underlying mechanisms and learning behavior of our approach. Extensive experiments on tasks including target image generation, image compression, and text-image alignment demonstrate the effectiveness of our method, where our method achieves optimal policy convergence while allowing controllable trade-offs between reward maximization and diversity preservation.</li>
</ul>

<h3>Title: Benchmarking Prompt Sensitivity in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Amirhossein Razavi, Mina Soltangheis, Negar Arabzadeh, Sara Salamat, Morteza Zihayat, Ebrahim Bagheri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06065">https://arxiv.org/abs/2502.06065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06065">https://arxiv.org/pdf/2502.06065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06065]] Benchmarking Prompt Sensitivity in Large Language Models(https://arxiv.org/abs/2502.06065)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language Models (LLMs) are highly sensitive to variations in prompt formulation, which can significantly impact their ability to generate accurate responses. In this paper, we introduce a new task, Prompt Sensitivity Prediction, and a dataset PromptSET designed to investigate the effects of slight prompt variations on LLM performance. Using TriviaQA and HotpotQA datasets as the foundation of our work, we generate prompt variations and evaluate their effectiveness across multiple LLMs. We benchmark the prompt sensitivity prediction task employing state-of-the-art methods from related tasks, including LLM-based self-evaluation, text classification, and query performance prediction techniques. Our findings reveal that existing methods struggle to effectively address prompt sensitivity prediction, underscoring the need to understand how information needs should be phrased for accurate LLM responses.</li>
</ul>

<h3>Title: Debiasing Guidance for Discrete Diffusion with Sequential Monte Carlo</h3>
<ul>
<li><strong>Authors: </strong>Cheuk Kit Lee, Paul Jeha, Jes Frellsen, Pietro Lio, Michael Samuel Albergo, Francisco Vargas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06079">https://arxiv.org/abs/2502.06079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06079">https://arxiv.org/pdf/2502.06079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06079]] Debiasing Guidance for Discrete Diffusion with Sequential Monte Carlo(https://arxiv.org/abs/2502.06079)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Discrete diffusion models are a class of generative models that produce samples from an approximated data distribution within a discrete state space. Often, there is a need to target specific regions of the data distribution. Current guidance methods aim to sample from a distribution with mass proportional to $p_0(x_0) p(\zeta|x_0)^\alpha$ but fail to achieve this in practice. We introduce a Sequential Monte Carlo algorithm that generates unbiasedly from this target distribution, utilising the learnt unconditional and guided process. We validate our approach on low-dimensional distributions, controlled images and text generations. For text generation, our method provides strong control while maintaining low perplexity compared to guidance-based approaches.</li>
</ul>

<h3>Title: Is a Peeled Apple Still Red? Evaluating LLMs' Ability for Conceptual Combination with Property Type</h3>
<ul>
<li><strong>Authors: </strong>Seokwon Song, Taehyun Lee, Jaewoo Ahn, Jae Hyuk Sung, Gunhee Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06086">https://arxiv.org/abs/2502.06086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06086">https://arxiv.org/pdf/2502.06086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06086]] Is a Peeled Apple Still Red? Evaluating LLMs' Ability for Conceptual Combination with Property Type(https://arxiv.org/abs/2502.06086)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Conceptual combination is a cognitive process that merges basic concepts, enabling the creation of complex expressions. During this process, the properties of combination (e.g., the whiteness of a peeled apple) can be inherited from basic concepts, newly emerge, or be canceled. However, previous studies have evaluated a limited set of properties and have not examined the generative process. To address this gap, we introduce the Conceptual Combination with Property Type dataset (CCPT), which consists of 12.3K annotated triplets of noun phrases, properties, and property types. Using CCPT, we establish three types of tasks to evaluate LLMs for conceptual combination thoroughly. Our key findings are threefold: (1) Our automatic metric grading property emergence and cancellation closely corresponds with human judgments. (2) LLMs, including OpenAI's o1, struggle to generate noun phrases which possess given emergent properties. (3) Our proposed method, inspired by cognitive psychology model that explains how relationships between concepts are formed, improves performances in all generative tasks. The dataset and experimental code are available at this https URL.</li>
</ul>

<h3>Title: ConMeC: A Dataset for Metonymy Resolution with Common Nouns</h3>
<ul>
<li><strong>Authors: </strong>Saptarshi Ghosh, Tianyu Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06087">https://arxiv.org/abs/2502.06087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06087">https://arxiv.org/pdf/2502.06087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06087]] ConMeC: A Dataset for Metonymy Resolution with Common Nouns(https://arxiv.org/abs/2502.06087)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Metonymy plays an important role in our daily communication. People naturally think about things using their most salient properties or commonly related concepts. For example, by saying "The bus decided to skip our stop today," we actually mean that the bus driver made the decision, not the bus. Prior work on metonymy resolution has mainly focused on named entities. However, metonymy involving common nouns (such as desk, baby, and school) is also a frequent and challenging phenomenon. We argue that NLP systems should be capable of identifying the metonymic use of common nouns in context. We create a new metonymy dataset ConMeC, which consists of 6,000 sentences, where each sentence is paired with a target common noun and annotated by humans to indicate whether that common noun is used metonymically or not in that context. We also introduce a chain-of-thought based prompting method for detecting metonymy using large language models (LLMs). We evaluate our LLM-based pipeline, as well as a supervised BERT model on our dataset and three other metonymy datasets. Our experimental results demonstrate that LLMs could achieve performance comparable to the supervised BERT model on well-defined metonymy categories, while still struggling with instances requiring nuanced semantic understanding. Our dataset is publicly available at: this https URL.</li>
</ul>

<h3>Title: Fair-MoE: Fairness-Oriented Mixture of Experts in Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Peiran Wang, Linjie Tong, Jiaxiang Liu, Zuozhu Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06094">https://arxiv.org/abs/2502.06094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06094">https://arxiv.org/pdf/2502.06094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06094]] Fair-MoE: Fairness-Oriented Mixture of Experts in Vision-Language Models(https://arxiv.org/abs/2502.06094)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fairness is a fundamental principle in medical ethics. Vision Language Models (VLMs) have shown significant potential in the medical field due to their ability to leverage both visual and linguistic contexts, reducing the need for large datasets and enabling the performance of complex tasks. However, the exploration of fairness within VLM applications remains limited. Applying VLMs without a comprehensive analysis of fairness could lead to concerns about equal treatment opportunities and diminish public trust in medical deep learning models. To build trust in medical VLMs, we propose Fair-MoE, a model specifically designed to ensure both fairness and effectiveness. Fair-MoE comprises two key components: \textit{the Fairness-Oriented Mixture of Experts (FO-MoE)} and \textit{the Fairness-Oriented Loss (FOL)}. FO-MoE is designed to leverage the expertise of various specialists to filter out biased patch embeddings and use an ensemble approach to extract more equitable information relevant to specific tasks. FOL is a novel fairness-oriented loss function that not only minimizes the distances between different attributes but also optimizes the differences in the dispersion of various attributes' distributions. Extended experiments demonstrate the effectiveness and fairness of Fair-MoE. Tested on the Harvard-FairVLMed dataset, Fair-MoE showed improvements in both fairness and accuracy across all four attributes. Code will be publicly available.</li>
</ul>

<h3>Title: Fine-Tuning Federated Learning-Based Intrusion Detection Systems for Transportation IoT</h3>
<ul>
<li><strong>Authors: </strong>Robert Akinie, Nana Kankam Brym Gyimah, Mansi Bhavsar, John Kelly</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06099">https://arxiv.org/abs/2502.06099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06099">https://arxiv.org/pdf/2502.06099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06099]] Fine-Tuning Federated Learning-Based Intrusion Detection Systems for Transportation IoT(https://arxiv.org/abs/2502.06099)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>The rapid advancement of machine learning (ML) and on-device computing has revolutionized various industries, including transportation, through the development of Connected and Autonomous Vehicles (CAVs) and Intelligent Transportation Systems (ITS). These technologies improve traffic management and vehicle safety, but also introduce significant security and privacy concerns, such as cyberattacks and data breaches. Traditional Intrusion Detection Systems (IDS) are increasingly inadequate in detecting modern threats, leading to the adoption of ML-based IDS solutions. Federated Learning (FL) has emerged as a promising method for enabling the decentralized training of IDS models on distributed edge devices without sharing sensitive data. However, deploying FL-based IDS in CAV networks poses unique challenges, including limited computational and memory resources on edge devices, competing demands from critical applications such as navigation and safety systems, and the need to scale across diverse hardware and connectivity conditions. To address these issues, we propose a hybrid server-edge FL framework that offloads pre-training to a central server while enabling lightweight fine-tuning on edge devices. This approach reduces memory usage by up to 42%, decreases training times by up to 75%, and achieves competitive IDS accuracy of up to 99.2%. Scalability analyses further demonstrates minimal performance degradation as the number of clients increase, highlighting the framework's feasibility for CAV networks and other IoT applications.</li>
</ul>

<h3>Title: Col-OLHTR: A Novel Framework for Multimodal Online Handwritten Text Recognition</h3>
<ul>
<li><strong>Authors: </strong>Chenyu Liu, Jinshui Hu, Baocai Yin, Jia Pan, Bing Yin, Jun Du, Qingfeng Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06100">https://arxiv.org/abs/2502.06100</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06100">https://arxiv.org/pdf/2502.06100</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06100]] Col-OLHTR: A Novel Framework for Multimodal Online Handwritten Text Recognition(https://arxiv.org/abs/2502.06100)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Online Handwritten Text Recognition (OLHTR) has gained considerable attention for its diverse range of applications. Current approaches usually treat OLHTR as a sequence recognition task, employing either a single trajectory or image encoder, or multi-stream encoders, combined with a CTC or attention-based recognition decoder. However, these approaches face several drawbacks: 1) single encoders typically focus on either local trajectories or visual regions, lacking the ability to dynamically capture relevant global features in challenging cases; 2) multi-stream encoders, while more comprehensive, suffer from complex structures and increased inference costs. To tackle this, we propose a Collaborative learning-based OLHTR framework, called Col-OLHTR, that learns multimodal features during training while maintaining a single-stream inference process. Col-OLHTR consists of a trajectory encoder, a Point-to-Spatial Alignment (P2SA) module, and an attention-based decoder. The P2SA module is designed to learn image-level spatial features through trajectory-encoded features and 2D rotary position embeddings. During training, an additional image-stream encoder-decoder is collaboratively trained to provide supervision for P2SA features. At inference, the extra streams are discarded, and only the P2SA module is used and merged before the decoder, simplifying the process while preserving high performance. Extensive experimental results on several OLHTR benchmarks demonstrate the state-of-the-art (SOTA) performance, proving the effectiveness and robustness of our design.</li>
</ul>

<h3>Title: Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Yueyan Li, Caixia Yuan, Xiaojie Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06106">https://arxiv.org/abs/2502.06106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06106">https://arxiv.org/pdf/2502.06106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06106]] Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks(https://arxiv.org/abs/2502.06106)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The study of mechanistic interpretability aims to reverse-engineer a model to explain its behaviors. While recent studies have focused on the static mechanism of a certain behavior, the training dynamics inside a model remain to be explored. In this work, we develop an interpretable method for fine-tuning and reveal the mechanism behind learning. We first propose the concept of node redundancy as an extension of intrinsic dimension and explain the idea behind circuit discovery from a fresh view. Based on the theory, we propose circuit-tuning, a two-stage algorithm that iteratively performs circuit discovery to mask out irrelevant edges and updates the remaining parameters responsible for a specific task. Experiments show that our method not only improves performance on a wide range of tasks but is also scalable while preserving general capabilities. We visualize and analyze the circuits before, during, and after fine-tuning, providing new insights into the self-organization mechanism of a neural network in the learning process.</li>
</ul>

<h3>Title: Task-driven Layerwise Additive Activation Intervention</h3>
<ul>
<li><strong>Authors: </strong>Hieu Trung Nguyen, Bao Nguyen, Binh Nguyen, Viet Anh Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06115">https://arxiv.org/abs/2502.06115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06115">https://arxiv.org/pdf/2502.06115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06115]] Task-driven Layerwise Additive Activation Intervention(https://arxiv.org/abs/2502.06115)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modern language models (LMs) have significantly advanced generative modeling in natural language processing (NLP). Despite their success, LMs often struggle with adaptation to new contexts in real-time applications. A promising approach to task adaptation is activation intervention, which steers the LMs' generation process by identifying and manipulating the activations. However, existing interventions are highly dependent on heuristic rules or require many prompt inputs to determine effective interventions. This paper proposes a layer-wise additive activation intervention framework that optimizes the intervention process, thus enhancing the sample efficiency. We benchmark our framework on various datasets, demonstrating improvements in the accuracy of pre-trained LMs and competing intervention baselines.</li>
</ul>

<h3>Title: Revisiting Dynamic Graph Clustering via Matrix Factorization</h3>
<ul>
<li><strong>Authors: </strong>Dongyuan Li, Satoshi Kosugi, Ying Zhang, Manabu Okumura, Feng Xia, Renhe Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06117">https://arxiv.org/abs/2502.06117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06117">https://arxiv.org/pdf/2502.06117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06117]] Revisiting Dynamic Graph Clustering via Matrix Factorization(https://arxiv.org/abs/2502.06117)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Dynamic graph clustering aims to detect and track time-varying clusters in dynamic graphs, revealing the evolutionary mechanisms of complex real-world dynamic systems. Matrix factorization-based methods are promising approaches for this task; however, these methods often struggle with scalability and can be time-consuming when applied to large-scale dynamic graphs. Moreover, they tend to lack robustness and are vulnerable to real-world noisy data. To address these issues, we make three key contributions. First, to improve scalability, we propose temporal separated matrix factorization, where a single matrix is divided into multiple smaller matrices for independent factorization, resulting in faster computation. Second, to improve robustness, we introduce bi-clustering regularization, which jointly optimizes graph embedding and clustering, thereby filtering out noisy features from the graph embeddings. Third, to further enhance effectiveness and efficiency, we propose selective embedding updating, where we update only the embeddings of dynamic nodes while the embeddings of static nodes are fixed among different timestamps. Experimental results on six synthetic and five real-world benchmarks demonstrate the scalability, robustness and effectiveness of our proposed method. Source code is available at this https URL.</li>
</ul>

<h3>Title: An Appearance Defect Detection Method for Cigarettes Based on C-CenterNet</h3>
<ul>
<li><strong>Authors: </strong>Hongyu Liu, Guowu Yuan, Lei Yang, Kunxiao Liu, Hao Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06119">https://arxiv.org/abs/2502.06119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06119">https://arxiv.org/pdf/2502.06119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06119]] An Appearance Defect Detection Method for Cigarettes Based on C-CenterNet(https://arxiv.org/abs/2502.06119)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Due to the poor adaptability of traditional methods in the cigarette detection task on the automatic cigarette production line, it is difficult to accurately identify whether a cigarette has defects and the types of defects; thus, a cigarette appearance defect detection method based on C-CenterNet is proposed. This detector uses keypoint estimation to locate center points and regresses all other defect properties. Firstly, Resnet50 is used as the backbone feature extraction network, and the convolutional block attention mechanism (CBAM) is introduced to enhance the network's ability to extract effective features and reduce the interference of non-target information. At the same time, the feature pyramid network is used to enhance the feature extraction of each layer. Then, deformable convolution is used to replace part of the common convolution to enhance the learning ability of different shape defects. Finally, the activation function ACON (ActivateOrNot) is used instead of the ReLU activation function, and the activation operation of some neurons is adaptively selected to improve the detection accuracy of the network. The experimental results are mainly acquired via the mean Average Precision (mAP). The experimental results show that the mAP of the C-CenterNet model applied in the cigarette appearance defect detection task is 95.01%. Compared with the original CenterNet model, the model's success rate is increased by 6.14%, so it can meet the requirements of precision and adaptability in cigarette detection tasks on the automatic cigarette production line.</li>
</ul>

<h3>Title: Foundation Model of Electronic Medical Records for Adaptive Risk Estimation</h3>
<ul>
<li><strong>Authors: </strong>Pawel Renc, Michal K. Grzeszczyk, Nassim Oufattole, Deirdre Goode, Yugang Jia, Szymon Bieganski, Matthew B. A. McDermott, Jaroslaw Was, Anthony E. Samir, Jonathan W. Cunningham, David W. Bates, Arkadiusz Sitek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06124">https://arxiv.org/abs/2502.06124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06124">https://arxiv.org/pdf/2502.06124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06124]] Foundation Model of Electronic Medical Records for Adaptive Risk Estimation(https://arxiv.org/abs/2502.06124)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, transformer</a></li>
<li><strong>Abstract: </strong>We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS), an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOS predicts future PHTs using transformer-based architectures. The Adaptive Risk Estimation System (ARES) employs ETHOS to compute dynamic and personalized risk probabilities for clinician-defined critical events. ARES incorporates a personalized explainability module that identifies key clinical factors influencing risk estimates for individual patients. ARES was evaluated on the MIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking its performance against traditional early warning systems and machine learning models. We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs, with 60% including hospital admissions. The dataset contained over 357 million tokens. ETHOS outperformed benchmark models in predicting hospital admissions, ICU admissions, and prolonged hospital stays, achieving superior AUC scores. ETHOS-based risk estimates demonstrated robustness across demographic subgroups with strong model reliability, confirmed via calibration curves. The personalized explainability module provides insights into patient-specific factors contributing to risk. ARES, powered by ETHOS, advances predictive healthcare AI by providing dynamic, real-time, and personalized risk estimation with patient-specific explainability to enhance clinician trust. Its adaptability and superior accuracy position it as a transformative tool for clinical decision-making, potentially improving patient outcomes and resource allocation in emergency and inpatient settings. We release the full code at this http URL to facilitate future research.</li>
</ul>

<h3>Title: Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ce Zhang, Zifu Wan, Zhehan Kan, Martin Q. Ma, Simon Stepputtis, Deva Ramanan, Russ Salakhutdinov, Louis-Philippe Morency, Katia Sycara, Yaqi Xie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06130">https://arxiv.org/abs/2502.06130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06130">https://arxiv.org/pdf/2502.06130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06130]] Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models(https://arxiv.org/abs/2502.06130)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>While recent Large Vision-Language Models (LVLMs) have shown remarkable performance in multi-modal tasks, they are prone to generating hallucinatory text responses that do not align with the given visual input, which restricts their practical applicability in real-world scenarios. In this work, inspired by the observation that the text-to-image generation process is the inverse of image-conditioned response generation in LVLMs, we explore the potential of leveraging text-to-image generative models to assist in mitigating hallucinations in LVLMs. We discover that generative models can offer valuable self-feedback for mitigating hallucinations at both the response and token levels. Building on this insight, we introduce self-correcting Decoding with Generative Feedback (DeGF), a novel training-free algorithm that incorporates feedback from text-to-image generative models into the decoding process to effectively mitigate hallucinations in LVLMs. Specifically, DeGF generates an image from the initial response produced by LVLMs, which acts as an auxiliary visual reference and provides self-feedback to verify and correct the initial response through complementary or contrastive decoding. Extensive experimental results validate the effectiveness of our approach in mitigating diverse types of hallucinations, consistently surpassing state-of-the-art methods across six benchmarks. Code is available at this https URL.</li>
</ul>

<h3>Title: Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Liuqing Chen, Shuhong Xiao, Shixian Ding, Shanhai Hu, Lingyun Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06134">https://arxiv.org/abs/2502.06134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06134">https://arxiv.org/pdf/2502.06134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06134]] Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning(https://arxiv.org/abs/2502.06134)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Medical time series are often irregular and face significant missingness, posing challenges for data analysis and clinical decision-making. Existing methods typically adopt a single modeling perspective, either treating series data as sequences or transforming them into image representations for further classification. In this paper, we propose a joint learning framework that incorporates both sequence and image representations. We also design three self-supervised learning strategies to facilitate the fusion of sequence and image representations, capturing a more generalizable joint representation. The results indicate that our approach outperforms seven other state-of-the-art models in three representative real-world clinical datasets. We further validate our approach by simulating two major types of real-world missingness through leave-sensors-out and leave-samples-out techniques. The results demonstrate that our approach is more robust and significantly surpasses other baselines in terms of classification performance.</li>
</ul>

<h3>Title: Enhanced Hybrid Deep Learning Approach for Botnet Attacks Detection in IoT Environment</h3>
<ul>
<li><strong>Authors: </strong>A. Karthick kumar, S. Rathnamala, T. Vijayashanthi, M. Prabhananthakumar, Alavikunhu Panthakkan, Shadi Atalla, Wathiq Mansoor</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06138">https://arxiv.org/abs/2502.06138</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06138">https://arxiv.org/pdf/2502.06138</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06138]] Enhanced Hybrid Deep Learning Approach for Botnet Attacks Detection in IoT Environment(https://arxiv.org/abs/2502.06138)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Cyberattacks in an Internet of Things (IoT) environment can have significant impacts because of the interconnected nature of devices and systems. An attacker uses a network of compromised IoT devices in a botnet attack to carry out various harmful activities. Detecting botnet attacks poses several challenges because of the intricate and evolving nature of these threats. Botnet attacks erode trust in IoT devices and systems, undermining confidence in their security, reliability, and integrity. Deep learning techniques have significantly enhanced the detection of botnet attacks due to their ability to analyze and learn from complex patterns in data. This research proposed the stacking of Deep convolutional neural networks, Bi-Directional Long Short-Term Memory (Bi-LSTM), Bi-Directional Gated Recurrent Unit (Bi-GRU), and Recurrent Neural Networks (RNN) for botnet attacks detection. The UNSW-NB15 dataset is utilized for botnet attacks detection. According to experimental results, the proposed model accurately provides for the intricate patterns and features of botnet attacks, with a testing accuracy of 99.76%. The proposed model also identifies botnets with a high ROC-AUC curve value of 99.18%. A performance comparison of the proposed method with existing state-of-the-art models confirms its higher performance. The outcomes of this research could strengthen cyber security procedures and safeguard against new attacks.</li>
</ul>

<h3>Title: LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sumin An, Junyoung Sung, Wonpyo Park, Chanjun Park, Paul Hongsuck Seo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06139">https://arxiv.org/abs/2502.06139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06139">https://arxiv.org/pdf/2502.06139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06139]] LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs(https://arxiv.org/abs/2502.06139)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) excel in generating coherent and contextually rich outputs, their capacity to efficiently handle long-form contexts is limited by fixed-length position embeddings. Additionally, the computational cost of processing long sequences increases quadratically, making it challenging to extend context length. To address these challenges, we propose Long-form Context Injection with Recurrent Compression (LCIRC), a method that enables the efficient processing long-form sequences beyond the model's length limit through recurrent compression without retraining the entire model. We further introduce query dependent context modeling, which selectively compresses query-relevant information, ensuring that the model retains the most pertinent content. Our empirical results demonstrate that Query Dependent LCIRC (QD-LCIRC) significantly improves LLM's ability to manage extended contexts, making it well-suited for tasks that require both comprehensive context understanding and query relevance.</li>
</ul>

<h3>Title: Animate Anyone 2: High-Fidelity Character Image Animation with Environment Affordance</h3>
<ul>
<li><strong>Authors: </strong>Li Hu, Guangyuan Wang, Zhen Shen, Xin Gao, Dechao Meng, Lian Zhuo, Peng Zhang, Bang Zhang, Liefeng Bo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06145">https://arxiv.org/abs/2502.06145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06145">https://arxiv.org/pdf/2502.06145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06145]] Animate Anyone 2: High-Fidelity Character Image Animation with Environment Affordance(https://arxiv.org/abs/2502.06145)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent character image animation methods based on diffusion models, such as Animate Anyone, have made significant progress in generating consistent and generalizable character animations. However, these approaches fail to produce reasonable associations between characters and their environments. To address this limitation, we introduce Animate Anyone 2, aiming to animate characters with environment affordance. Beyond extracting motion signals from source video, we additionally capture environmental representations as conditional inputs. The environment is formulated as the region with the exclusion of characters and our model generates characters to populate these regions while maintaining coherence with the environmental context. We propose a shape-agnostic mask strategy that more effectively characterizes the relationship between character and environment. Furthermore, to enhance the fidelity of object interactions, we leverage an object guider to extract features of interacting objects and employ spatial blending for feature injection. We also introduce a pose modulation strategy that enables the model to handle more diverse motion patterns. Experimental results demonstrate the superior performance of the proposed method.</li>
</ul>

<h3>Title: LegalViz: Legal Text Visualization by Text To Diagram Generation</h3>
<ul>
<li><strong>Authors: </strong>Eri Onami, Taiki Miyanishi, Koki Maeda, Shuhei Kurita</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06147">https://arxiv.org/abs/2502.06147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06147">https://arxiv.org/pdf/2502.06147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06147]] LegalViz: Legal Text Visualization by Text To Diagram Generation(https://arxiv.org/abs/2502.06147)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Legal documents including judgments and court orders require highly sophisticated legal knowledge for understanding. To disclose expert knowledge for non-experts, we explore the problem of visualizing legal texts with easy-to-understand diagrams and propose a novel dataset of LegalViz with 23 languages and 7,010 cases of legal document and visualization pairs, using the DOT graph description language of Graphviz. LegalViz provides a simple diagram from a complicated legal corpus identifying legal entities, transactions, legal sources, and statements at a glance, that are essential in each judgment. In addition, we provide new evaluation metrics for the legal diagram visualization by considering graph structures, textual similarities, and legal contents. We conducted empirical studies on few-shot and finetuning large language models for generating legal diagrams and evaluated them with these metrics, including legal content-based evaluation within 23 languages. Models trained with LegalViz outperform existing models including GPTs, confirming the effectiveness of our dataset.</li>
</ul>

<h3>Title: Optimizing Knowledge Integration in Retrieval-Augmented Generation with Self-Selection</h3>
<ul>
<li><strong>Authors: </strong>Yan Weng, Fengbin Zhu, Tong Ye, Haoyan Liu, Fuli Feng, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06148">https://arxiv.org/abs/2502.06148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06148">https://arxiv.org/pdf/2502.06148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06148]] Optimizing Knowledge Integration in Retrieval-Augmented Generation with Self-Selection(https://arxiv.org/abs/2502.06148)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG), which integrates external knowledge into Large Language Models (LLMs), has proven effective in enabling LLMs to produce more accurate and reliable responses. However, it remains a significant challenge how to effectively integrate external retrieved knowledge with internal parametric knowledge in LLMs. In this work, we propose a novel Self-Selection RAG framework, where the LLM is made to select from pairwise responses generated with internal parametric knowledge solely and with external retrieved knowledge together to achieve enhanced accuracy. To this end, we devise a Self-Selection-RGP method to enhance the capabilities of the LLM in both generating and selecting the correct answer, by training the LLM with Direct Preference Optimization (DPO) over a curated Retrieval Generation Preference (RGP) dataset. Experimental results with two open-source LLMs (i.e., Llama2-13B-Chat and Mistral-7B) well demonstrate the superiority of our approach over other baseline methods on Natural Questions (NQ) and TrivialQA datasets.</li>
</ul>

<h3>Title: Scaling Public Health Text Annotation: Zero-Shot Learning vs. Crowdsourcing for Improved Efficiency and Labeling Accuracy</h3>
<ul>
<li><strong>Authors: </strong>Kamyar Kazari, Yong Chen, Zahra Shakeri</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06150">https://arxiv.org/abs/2502.06150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06150">https://arxiv.org/pdf/2502.06150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06150]] Scaling Public Health Text Annotation: Zero-Shot Learning vs. Crowdsourcing for Improved Efficiency and Labeling Accuracy(https://arxiv.org/abs/2502.06150)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Public health researchers are increasingly interested in using social media data to study health-related behaviors, but manually labeling this data can be labor-intensive and costly. This study explores whether zero-shot labeling using large language models (LLMs) can match or surpass conventional crowd-sourced annotation for Twitter posts related to sleep disorders, physical activity, and sedentary behavior. Multiple annotation pipelines were designed to compare labels produced by domain experts, crowd workers, and LLM-driven approaches under varied prompt-engineering strategies. Our findings indicate that LLMs can rival human performance in straightforward classification tasks and significantly reduce labeling time, yet their accuracy diminishes for tasks requiring more nuanced domain knowledge. These results clarify the trade-offs between automated scalability and human expertise, demonstrating conditions under which LLM-based labeling can be efficiently integrated into public health research without undermining label quality.</li>
</ul>

<h3>Title: Powerformer: A Transformer with Weighted Causal Attention for Time-series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Kareem Hegazy, Michael W. Mahoney, N. Benjamin Erichson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06151">https://arxiv.org/abs/2502.06151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06151">https://arxiv.org/pdf/2502.06151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06151]] Powerformer: A Transformer with Weighted Causal Attention for Time-series Forecasting(https://arxiv.org/abs/2502.06151)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have recently shown strong performance in time-series forecasting, but their all-to-all attention mechanism overlooks the (temporal) causal and often (temporally) local nature of data. We introduce Powerformer, a novel Transformer variant that replaces noncausal attention weights with causal weights that are reweighted according to a smooth heavy-tailed decay. This simple yet effective modification endows the model with an inductive bias favoring temporally local dependencies, while still allowing sufficient flexibility to learn the unique correlation structure of each dataset. Our empirical results demonstrate that Powerformer not only achieves state-of-the-art accuracy on public time-series benchmarks, but also that it offers improved interpretability of attention patterns. Our analyses show that the model's locality bias is amplified during training, demonstrating an interplay between time-series data and power-law-based attention. These findings highlight the importance of domain-specific modifications to the Transformer architecture for time-series forecasting, and they establish Powerformer as a strong, efficient, and principled baseline for future research and real-world applications.</li>
</ul>

<h3>Title: Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile</h3>
<ul>
<li><strong>Authors: </strong>Hangliang Ding, Dacheng Li, Runlong Su, Peiyuan Zhang, Zhijie Deng, Ion Stoica, Hao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06155">https://arxiv.org/abs/2502.06155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06155">https://arxiv.org/pdf/2502.06155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06155]] Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile(https://arxiv.org/abs/2502.06155)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Despite the promise of synthesizing high-fidelity videos, Diffusion Transformers (DiTs) with 3D full attention suffer from expensive inference due to the complexity of attention computation and numerous sampling steps. For example, the popular Open-Sora-Plan model consumes more than 9 minutes for generating a single video of 29 frames. This paper addresses the inefficiency issue from two aspects: 1) Prune the 3D full attention based on the redundancy within video data; We identify a prevalent tile-style repetitive pattern in the 3D attention maps for video data, and advocate a new family of sparse 3D attention that holds a linear complexity w.r.t. the number of video frames. 2) Shorten the sampling process by adopting existing multi-step consistency distillation; We split the entire sampling trajectory into several segments and perform consistency distillation within each one to activate few-step generation capacities. We further devise a three-stage training pipeline to conjoin the low-complexity attention and few-step generation capacities. Notably, with 0.1% pretraining data, we turn the Open-Sora-Plan-1.2 model into an efficient one that is 7.4x -7.8x faster for 29 and 93 frames 720p video generation with a marginal performance trade-off in VBench. In addition, we demonstrate that our approach is amenable to distributed inference, achieving an additional 3.91x speedup when running on 4 GPUs with sequence parallelism.</li>
</ul>

<h3>Title: Generalized Temporal Tensor Decomposition with Rank-revealing Latent-ODE</h3>
<ul>
<li><strong>Authors: </strong>Panqi Chen, Lei Cheng, Jianlong Li, Weichang Li, Weiqing Liu, Jiang Bian, Shikai Fang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06164">https://arxiv.org/abs/2502.06164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06164">https://arxiv.org/pdf/2502.06164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06164]] Generalized Temporal Tensor Decomposition with Rank-revealing Latent-ODE(https://arxiv.org/abs/2502.06164)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Tensor decomposition is a fundamental tool for analyzing multi-dimensional data by learning low-rank factors to represent high-order interactions. While recent works on temporal tensor decomposition have made significant progress by incorporating continuous timestamps in latent factors, they still struggle with general tensor data with continuous indexes not only in the temporal mode but also in other modes, such as spatial coordinates in climate data. Additionally, the problem of determining the tensor rank remains largely unexplored in temporal tensor models. To address these limitations, we propose \underline{G}eneralized temporal tensor decomposition with \underline{R}ank-r\underline{E}vealing laten\underline{T}-ODE (GRET). Our approach encodes continuous spatial indexes as learnable Fourier features and employs neural ODEs in latent space to learn the temporal trajectories of factors. To automatically reveal the rank of temporal tensors, we introduce a rank-revealing Gaussian-Gamma prior over the factor trajectories. We develop an efficient variational inference scheme with an analytical evidence lower bound, enabling sampling-free optimization. Through extensive experiments on both synthetic and real-world datasets, we demonstrate that GRET not only reveals the underlying ranks of temporal tensors but also significantly outperforms existing methods in prediction performance and robustness against noise.</li>
</ul>

<h3>Title: Universal Approximation of Visual Autoregressive Transformers</h3>
<ul>
<li><strong>Authors: </strong>Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06167">https://arxiv.org/abs/2502.06167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06167">https://arxiv.org/pdf/2502.06167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06167]] Universal Approximation of Visual Autoregressive Transformers(https://arxiv.org/abs/2502.06167)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We investigate the fundamental limits of transformer-based foundation models, extending our analysis to include Visual Autoregressive (VAR) transformers. VAR represents a big step toward generating images using a novel, scalable, coarse-to-fine ``next-scale prediction'' framework. These models set a new quality bar, outperforming all previous methods, including Diffusion Transformers, while having state-of-the-art performance for image synthesis tasks. Our primary contributions establish that, for single-head VAR transformers with a single self-attention layer and single interpolation layer, the VAR Transformer is universal. From the statistical perspective, we prove that such simple VAR transformers are universal approximators for any image-to-image Lipschitz functions. Furthermore, we demonstrate that flow-based autoregressive transformers inherit similar approximation capabilities. Our results provide important design principles for effective and computationally efficient VAR Transformer strategies that can be used to extend their utility to more sophisticated VAR models in image generation and other related areas.</li>
</ul>

<h3>Title: An Interpretable Implicit-Based Approach for Modeling Local Spatial Effects: A Case Study of Global Gross Primary Productivity</h3>
<ul>
<li><strong>Authors: </strong>Siqi Du, Hongsheng Huang, Kaixin Shen, Ziqi Liu, Shengjun Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06170">https://arxiv.org/abs/2502.06170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06170">https://arxiv.org/pdf/2502.06170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06170]] An Interpretable Implicit-Based Approach for Modeling Local Spatial Effects: A Case Study of Global Gross Primary Productivity(https://arxiv.org/abs/2502.06170)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In Earth sciences, unobserved factors exhibit non-stationary spatial distributions, causing the relationships between features and targets to display spatial heterogeneity. In geographic machine learning tasks, conventional statistical learning methods often struggle to capture spatial heterogeneity, leading to unsatisfactory prediction accuracy and unreliable interpretability. While approaches like Geographically Weighted Regression (GWR) capture local variations, they fall short of uncovering global patterns and tracking the continuous evolution of spatial heterogeneity. Motivated by this limitation, we propose a novel perspective - that is, simultaneously modeling common features across different locations alongside spatial differences using deep neural networks. The proposed method is a dual-branch neural network with an encoder-decoder structure. In the encoding stage, the method aggregates node information in a spatiotemporal conditional graph using GCN and LSTM, encoding location-specific spatiotemporal heterogeneity as an implicit conditional vector. Additionally, a self-attention-based encoder is used to extract location-invariant common features from the data. In the decoding stage, the approach employs a conditional generation strategy that predicts response variables and interpretative weights based on data features under spatiotemporal conditions. The approach is validated by predicting vegetation gross primary productivity (GPP) using global climate and land cover data from 2001 to 2020. Trained on 50 million samples and tested on 2.8 million, the proposed model achieves an RMSE of 0.836, outperforming LightGBM (1.063) and TabNet (0.944). Visualization analyses indicate that our method can reveal the distribution differences of the dominant factors of GPP across various times and locations.</li>
</ul>

<h3>Title: PLATTER: A Page-Level Handwritten Text Recognition System for Indic Scripts</h3>
<ul>
<li><strong>Authors: </strong>Badri Vishal Kasuba, Dhruv Kudale, Venkatapathy Subramanian, Parag Chaudhuri, Ganesh Ramakrishnan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06172">https://arxiv.org/abs/2502.06172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06172">https://arxiv.org/pdf/2502.06172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06172]] PLATTER: A Page-Level Handwritten Text Recognition System for Indic Scripts(https://arxiv.org/abs/2502.06172)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>In recent years, the field of Handwritten Text Recognition (HTR) has seen the emergence of various new models, each claiming to perform competitively better than the other in specific scenarios. However, making a fair comparison of these models is challenging due to inconsistent choices and diversity in test sets. Furthermore, recent advancements in HTR often fail to account for the diverse languages, especially Indic languages, likely due to the scarcity of relevant labeled datasets. Moreover, much of the previous work has focused primarily on character-level or word-level recognition, overlooking the crucial stage of Handwritten Text Detection (HTD) necessary for building a page-level end-to-end handwritten OCR pipeline. Through our paper, we address these gaps by making three pivotal contributions. Firstly, we present an end-to-end framework for Page-Level hAndwriTTen TExt Recognition (PLATTER) by treating it as a two-stage problem involving word-level HTD followed by HTR. This approach enables us to identify, assess, and address challenges in each stage independently. Secondly, we demonstrate the usage of PLATTER to measure the performance of our language-agnostic HTD model and present a consistent comparison of six trained HTR models on ten diverse Indic languages thereby encouraging consistent comparisons. Finally, we also release a Corpus of Handwritten Indic Scripts (CHIPS), a meticulously curated, page-level Indic handwritten OCR dataset labeled for both detection and recognition purposes. Additionally, we release our code and trained models, to encourage further contributions in this direction.</li>
</ul>

<h3>Title: Uncertainty-Aware Adaptation of Large Language Models for Protein-Protein Interaction Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sanket Jantre, Tianle Wang, Gilchan Park, Kriti Chopra, Nicholas Jeon, Xiaoning Qian, Nathan M. Urban, Byung-Jun Yoon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06173">https://arxiv.org/abs/2502.06173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06173">https://arxiv.org/pdf/2502.06173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06173]] Uncertainty-Aware Adaptation of Large Language Models for Protein-Protein Interaction Analysis(https://arxiv.org/abs/2502.06173)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Identification of protein-protein interactions (PPIs) helps derive cellular mechanistic understanding, particularly in the context of complex conditions such as neurodegenerative disorders, metabolic syndromes, and cancer. Large Language Models (LLMs) have demonstrated remarkable potential in predicting protein structures and interactions via automated mining of vast biomedical literature; yet their inherent uncertainty remains a key challenge for deriving reproducible findings, critical for biomedical applications. In this study, we present an uncertainty-aware adaptation of LLMs for PPI analysis, leveraging fine-tuned LLaMA-3 and BioMedGPT models. To enhance prediction reliability, we integrate LoRA ensembles and Bayesian LoRA models for uncertainty quantification (UQ), ensuring confidence-calibrated insights into protein behavior. Our approach achieves competitive performance in PPI identification across diverse disease contexts while addressing model uncertainty, thereby enhancing trustworthiness and reproducibility in computational biology. These findings underscore the potential of uncertainty-aware LLM adaptation for advancing precision medicine and biomedical research.</li>
</ul>

<h3>Title: RideKE: Leveraging Low-Resource, User-Generated Twitter Content for Sentiment and Emotion Detection in Kenyan Code-Switched Dataset</h3>
<ul>
<li><strong>Authors: </strong>Naome A. Etori, Maria L. Gini</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06180">https://arxiv.org/abs/2502.06180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06180">https://arxiv.org/pdf/2502.06180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06180]] RideKE: Leveraging Low-Resource, User-Generated Twitter Content for Sentiment and Emotion Detection in Kenyan Code-Switched Dataset(https://arxiv.org/abs/2502.06180)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Social media has become a crucial open-access platform for individuals to express opinions and share experiences. However, leveraging low-resource language data from Twitter is challenging due to scarce, poor-quality content and the major variations in language use, such as slang and code-switching. Identifying tweets in these languages can be difficult as Twitter primarily supports high-resource languages. We analyze Kenyan code-switched data and evaluate four state-of-the-art (SOTA) transformer-based pretrained models for sentiment and emotion classification, using supervised and semi-supervised methods. We detail the methodology behind data collection and annotation, and the challenges encountered during the data curation phase. Our results show that XLM-R outperforms other models; for sentiment analysis, XLM-R supervised model achieves the highest accuracy (69.2\%) and F1 score (66.1\%), XLM-R semi-supervised (67.2\% accuracy, 64.1\% F1 score). In emotion analysis, DistilBERT supervised leads in accuracy (59.8\%) and F1 score (31\%), mBERT semi-supervised (accuracy (59\% and F1 score 26.5\%). AfriBERTa models show the lowest accuracy and F1 scores. All models tend to predict neutral sentiment, with Afri-BERT showing the highest bias and unique sensitivity to empathy emotion. this https URL</li>
</ul>

<h3>Title: Multi-Level Decoupled Relational Distillation for Heterogeneous Architectures</h3>
<ul>
<li><strong>Authors: </strong>Yaoxin Yang, Peng Ye, Weihao Lin, Kangcong Li, Yan Wen, Jia Hao, Tao Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06189">https://arxiv.org/abs/2502.06189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06189">https://arxiv.org/pdf/2502.06189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06189]] Multi-Level Decoupled Relational Distillation for Heterogeneous Architectures(https://arxiv.org/abs/2502.06189)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Heterogeneous distillation is an effective way to transfer knowledge from cross-architecture teacher models to student models. However, existing heterogeneous distillation methods do not take full advantage of the dark knowledge hidden in the teacher's output, limiting their this http URL this end, we propose a novel framework named Multi-Level Decoupled Relational Knowledge Distillation (MLDR-KD) to unleash the potential of relational distillation in heterogeneous distillation. Concretely, we first introduce Decoupled Finegrained Relation Alignment (DFRA) in both logit and feature levels to balance the trade-off between distilled dark knowledge and the confidence in the correct category of the heterogeneous teacher model. Then, Multi-Scale Dynamic Fusion (MSDF) module is applied to dynamically fuse the projected logits of multiscale features at different stages in student model, further improving performance of our method in feature level. We verify our method on four architectures (CNNs, Transformers, MLPs and Mambas), two datasets (CIFAR-100 and Tiny-ImageNet). Compared with the best available method, our MLDR-KD improves student model performance with gains of up to 4.86% on CIFAR-100 and 2.78% on Tiny-ImageNet datasets respectively, showing robustness and generality in heterogeneous distillation. Code will be released soon.</li>
</ul>

<h3>Title: Multimodal Task Representation Memory Bank vs. Catastrophic Forgetting in Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>You Zhou, Jiangshan Zhao, Deyu Zeng, Zuo Zuo, Weixiang Liu, Zongze Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06194">https://arxiv.org/abs/2502.06194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06194">https://arxiv.org/pdf/2502.06194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06194]] Multimodal Task Representation Memory Bank vs. Catastrophic Forgetting in Anomaly Detection(https://arxiv.org/abs/2502.06194)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Unsupervised Continuous Anomaly Detection (UCAD) faces significant challenges in multi-task representation learning, with existing methods suffering from incomplete representation and catastrophic forgetting. Unlike supervised models, unsupervised scenarios lack prior information, making it difficult to effectively distinguish redundant and complementary multimodal features. To address this, we propose the Multimodal Task Representation Memory Bank (MTRMB) method through two key technical innovations: A Key-Prompt-Multimodal Knowledge (KPMK) mechanism that uses concise key prompts to guide cross-modal feature interaction between BERT and ViT. Refined Structure-based Contrastive Learning (RSCL) leveraging Grounding DINO and SAM to generate precise segmentation masks, pulling features of the same structural region closer while pushing different structural regions apart. Experiments on MVtec AD and VisA datasets demonstrate MTRMB's superiority, achieving an average detection accuracy of 0.921 at the lowest forgetting rate, significantly outperforming state-of-the-art methods. We plan to open source on GitHub.</li>
</ul>

<h3>Title: Comparing Image Segmentation Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Milind Cherukuri</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06201">https://arxiv.org/abs/2502.06201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06201">https://arxiv.org/pdf/2502.06201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06201]] Comparing Image Segmentation Algorithms(https://arxiv.org/abs/2502.06201)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents a novel approach for denoising binary images using simulated annealing (SA), a global optimization technique that addresses the inherent challenges of non convex energy functions. Binary images are often corrupted by noise, necessitating effective restoration methods. We propose an energy function E(x, y) that captures the relationship between the noisy image y and the desired clean image x. Our algorithm combines simulated annealing with a localized optimization strategy to efficiently navigate the solution space, minimizing the energy function while maintaining computational efficiency. We evaluate the performance of the proposed method against traditional iterative conditional modes (ICM), employing a binary image with 10% pixel corruption as a test case. Experimental results demonstrate that the simulated annealing method achieves a significant restoration improvement, yielding a 99.19% agreement with the original image compared to 96.21% for ICM. Visual assessments reveal that simulated annealing effectively removes noise while preserving structural details, making it a promising approach for binary image denoising. This work contributes to the field of image processing by highlighting the advantages of incorporating global optimization techniques in restoration tasks.</li>
</ul>

<h3>Title: Non-literal Understanding of Number Words by Language Models</h3>
<ul>
<li><strong>Authors: </strong>Polina Tsvilodub, Kanishk Gandhi, Haoran Zhao, Jan-Philipp Fr√§nken, Michael Franke, Noah D. Goodman</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06204">https://arxiv.org/abs/2502.06204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06204">https://arxiv.org/pdf/2502.06204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06204]] Non-literal Understanding of Number Words by Language Models(https://arxiv.org/abs/2502.06204)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Humans naturally interpret numbers non-literally, effortlessly combining context, world knowledge, and speaker intent. We investigate whether large language models (LLMs) interpret numbers similarly, focusing on hyperbole and pragmatic halo effects. Through systematic comparison with human data and computational models of pragmatic reasoning, we find that LLMs diverge from human interpretation in striking ways. By decomposing pragmatic reasoning into testable components, grounded in the Rational Speech Act framework, we pinpoint where LLM processing diverges from human cognition -- not in prior knowledge, but in reasoning with it. This insight leads us to develop a targeted solution -- chain-of-thought prompting inspired by an RSA model makes LLMs' interpretations more human-like. Our work demonstrates how computational cognitive models can both diagnose AI-human differences and guide development of more human-like language understanding capabilities.</li>
</ul>

<h3>Title: C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Guoxin Chen, Minpeng Liao, Peiying Yu, Dingmin Wang, Zile Qiao, Chao Yang, Xin Zhao, Kai Fan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06205">https://arxiv.org/abs/2502.06205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06205">https://arxiv.org/pdf/2502.06205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06205]] C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation(https://arxiv.org/abs/2502.06205)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) systems face a fundamental challenge in aligning independently developed retrievers and large language models (LLMs). Existing approaches typically involve modifying either component or introducing simple intermediate modules, resulting in practical limitations and sub-optimal performance. Inspired by human search behavior -- typically involving a back-and-forth process of proposing search queries and reviewing documents, we propose C-3PO, a proxy-centric framework that facilitates communication between retrievers and LLMs through a lightweight multi-agent system. Our framework implements three specialized agents that collaboratively optimize the entire RAG pipeline without altering the retriever and LLMs. These agents work together to assess the need for retrieval, generate effective queries, and select information suitable for the LLMs. To enable effective multi-agent coordination, we develop a tree-structured rollout approach for reward credit assignment in reinforcement learning. Extensive experiments in both in-domain and out-of-distribution scenarios demonstrate that C-3PO significantly enhances RAG performance while maintaining plug-and-play flexibility and superior generalization capabilities.</li>
</ul>

<h3>Title: Unveiling the Capabilities of Large Language Models in Detecting Offensive Language with Annotation Disagreement</h3>
<ul>
<li><strong>Authors: </strong>Junyu Lu, Kai Ma, Kaichun Wang, Kelaiti Xiao, Roy Ka-Wei Lee, Bo Xu, Liang Yang, Hongfei Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06207">https://arxiv.org/abs/2502.06207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06207">https://arxiv.org/pdf/2502.06207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06207]] Unveiling the Capabilities of Large Language Models in Detecting Offensive Language with Annotation Disagreement(https://arxiv.org/abs/2502.06207)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LLMs are widely used for offensive language detection due to their advanced capability. However, the challenges posed by human annotation disagreement in real-world datasets remain underexplored. These disagreement samples are difficult to detect due to their ambiguous nature. Additionally, the confidence of LLMs in processing disagreement samples can provide valuable insights into their alignment with human annotators. To address this gap, we systematically evaluate the ability of LLMs to detect offensive language with annotation disagreement. We compare the binary accuracy of multiple LLMs across varying annotation agreement levels and analyze the relationship between LLM confidence and annotation agreement. Furthermore, we investigate the impact of disagreement samples on LLM decision-making during few-shot learning and instruction fine-tuning. Our findings highlight the challenges posed by disagreement samples and offer guidance for improving LLM-based offensive language detection.</li>
</ul>

<h3>Title: Position: Continual Learning Benefits from An Evolving Population over An Unified Model</h3>
<ul>
<li><strong>Authors: </strong>Aojun Lu, Junchao Ke, Chunhui Ding, Jiahao Fan, Yanan Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06210">https://arxiv.org/abs/2502.06210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06210">https://arxiv.org/pdf/2502.06210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06210]] Position: Continual Learning Benefits from An Evolving Population over An Unified Model(https://arxiv.org/abs/2502.06210)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks have demonstrated remarkable success in machine learning; however, they remain fundamentally ill-suited for Continual Learning (CL). Recent research has increasingly focused on achieving CL without the need for rehearsal. Among these, parameter isolation-based methods have proven particularly effective in enhancing CL by optimizing model weights for each incremental task. Despite their success, they fall short in optimizing architectures tailored to distinct incremental tasks. To address this limitation, updating a group of models with different architectures offers a promising alternative to the traditional CL paradigm that relies on a single unified model. Building on this insight, this study introduces a novel Population-based Continual Learning (PCL) framework. PCL extends CL to the architectural level by maintaining and evolving a population of neural network architectures, which are continually refined for the current task through NAS. Importantly, the well-evolved population for the current incremental task is naturally inherited by the subsequent one, thereby facilitating forward transfer, a crucial objective in CL. Throughout the CL process, the population evolves, yielding task-specific architectures that collectively form a robust CL system. Experimental results demonstrate that PCL outperforms state-of-the-art rehearsal-free CL methods that employs a unified model, highlighting its potential as a new paradigm for CL.</li>
</ul>

<h3>Title: Fully Exploiting Vision Foundation Model's Profound Prior Knowledge for Generalizable RGB-Depth Driving Scene Parsing</h3>
<ul>
<li><strong>Authors: </strong>Sicen Guo, Tianyou Wen, Chuang-Wei Liu, Qijun Chen, Rui Fan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06219">https://arxiv.org/abs/2502.06219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06219">https://arxiv.org/pdf/2502.06219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06219]] Fully Exploiting Vision Foundation Model's Profound Prior Knowledge for Generalizable RGB-Depth Driving Scene Parsing(https://arxiv.org/abs/2502.06219)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Recent vision foundation models (VFMs), typically based on Vision Transformer (ViT), have significantly advanced numerous computer vision tasks. Despite their success in tasks focused solely on RGB images, the potential of VFMs in RGB-depth driving scene parsing remains largely under-explored. In this article, we take one step toward this emerging research area by investigating a feasible technique to fully exploit VFMs for generalizable RGB-depth driving scene parsing. Specifically, we explore the inherent characteristics of RGB and depth data, thereby presenting a Heterogeneous Feature Integration Transformer (HFIT). This network enables the efficient extraction and integration of comprehensive heterogeneous features without re-training ViTs. Relative depth prediction results from VFMs, used as inputs to the HFIT side adapter, overcome the limitations of the dependence on depth maps. Our proposed HFIT demonstrates superior performance compared to all other traditional single-modal and data-fusion scene parsing networks, pre-trained VFMs, and ViT adapters on the Cityscapes and KITTI Semantics datasets. We believe this novel strategy paves the way for future innovations in VFM-based data-fusion techniques for driving scene parsing. Our source code is publicly available at this https URL.</li>
</ul>

<h3>Title: FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and Cup Segmentation in Fundus Images</h3>
<ul>
<li><strong>Authors: </strong>Jinchen Yu, Yongwei Nie, Fei Qi, Wenxiong Liao, Hongmin Cai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06220">https://arxiv.org/abs/2502.06220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06220">https://arxiv.org/pdf/2502.06220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06220]] FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and Cup Segmentation in Fundus Images(https://arxiv.org/abs/2502.06220)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model (SAM) has gained popularity as a versatile image segmentation method, thanks to its strong generalization capabilities across various domains. However, when applied to optic disc (OD) and optic cup (OC) segmentation tasks, SAM encounters challenges due to the complex structures, low contrast, and blurred boundaries typical of fundus images, leading to suboptimal performance. To overcome these challenges, we introduce a novel model, FunduSAM, which incorporates several Adapters into SAM to create a deep network specifically designed for OD and OC segmentation. The FunduSAM utilizes Adapter into each transformer block after encoder for parameter fine-tuning (PEFT). It enhances SAM's feature extraction capabilities by designing a Convolutional Block Attention Module (CBAM), addressing issues related to blurred boundaries and low contrast. Given the unique requirements of OD and OC segmentation, polar transformation is used to convert the original fundus OD images into a format better suited for training and evaluating FunduSAM. A joint loss is used to achieve structure preservation between the OD and OC, while accurate segmentation. Extensive experiments on the REFUGE dataset, comprising 1,200 fundus images, demonstrate the superior performance of FunduSAM compared to five mainstream approaches.</li>
</ul>

<h3>Title: Unsupervised deep learning for semantic segmentation of multispectral LiDAR forest point clouds</h3>
<ul>
<li><strong>Authors: </strong>Lassi Ruoppa, Oona Oinonen, Josef Taher, Matti Lehtom√§ki, Narges Takhtkeshha, Antero Kukko, Harri Kaartinen, Juha Hyypp√§</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06227">https://arxiv.org/abs/2502.06227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06227">https://arxiv.org/pdf/2502.06227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06227]] Unsupervised deep learning for semantic segmentation of multispectral LiDAR forest point clouds(https://arxiv.org/abs/2502.06227)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Point clouds captured with laser scanning systems from forest environments can be utilized in a wide variety of applications within forestry and plant ecology, such as the estimation of tree stem attributes, leaf angle distribution, and above-ground biomass. However, effectively utilizing the data in such tasks requires the semantic segmentation of the data into wood and foliage points, also known as leaf-wood separation. The traditional approach to leaf-wood separation has been geometry- and radiometry-based unsupervised algorithms, which tend to perform poorly on data captured with airborne laser scanning (ALS) systems, even with a high point density. While recent machine and deep learning approaches achieve great results even on sparse point clouds, they require manually labeled training data, which is often extremely laborious to produce. Multispectral (MS) information has been demonstrated to have potential for improving the accuracy of leaf-wood separation, but quantitative assessment of its effects has been lacking. This study proposes a fully unsupervised deep learning method, GrowSP-ForMS, which is specifically designed for leaf-wood separation of high-density MS ALS point clouds and based on the GrowSP architecture. GrowSP-ForMS achieved a mean accuracy of 84.3% and a mean intersection over union (mIoU) of 69.6% on our MS test set, outperforming the unsupervised reference methods by a significant margin. When compared to supervised deep learning methods, our model performed similarly to the slightly older PointNet architecture but was outclassed by more recent approaches. Finally, two ablation studies were conducted, which demonstrated that our proposed changes increased the test set mIoU of GrowSP-ForMS by 29.4 percentage points (pp) in comparison to the original GrowSP model and that utilizing MS data improved the mIoU by 5.6 pp from the monospectral case.</li>
</ul>

<h3>Title: Multi-Scale Transformer Architecture for Accurate Medical Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Hu, Yanlin Xiang, Yang Lin, Junliang Du, Hanchao Zhang, Houze Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06243">https://arxiv.org/abs/2502.06243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06243">https://arxiv.org/pdf/2502.06243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06243]] Multi-Scale Transformer Architecture for Accurate Medical Image Classification(https://arxiv.org/abs/2502.06243)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>This study introduces an AI-driven skin lesion classification algorithm built on an enhanced Transformer architecture, addressing the challenges of accuracy and robustness in medical image analysis. By integrating a multi-scale feature fusion mechanism and refining the self-attention process, the model effectively extracts both global and local features, enhancing its ability to detect lesions with ambiguous boundaries and intricate structures. Performance evaluation on the ISIC 2017 dataset demonstrates that the improved Transformer surpasses established AI models, including ResNet50, VGG19, ResNext, and Vision Transformer, across key metrics such as accuracy, AUC, F1-Score, and Precision. Grad-CAM visualizations further highlight the interpretability of the model, showcasing strong alignment between the algorithm's focus areas and actual lesion sites. This research underscores the transformative potential of advanced AI models in medical imaging, paving the way for more accurate and reliable diagnostic tools. Future work will explore the scalability of this approach to broader medical imaging tasks and investigate the integration of multimodal data to enhance AI-driven diagnostic frameworks for intelligent healthcare.</li>
</ul>

<h3>Title: PiKE: Adaptive Data Mixing for Multi-Task Learning Under Low Gradient Conflicts</h3>
<ul>
<li><strong>Authors: </strong>Zeman Li, Yuan Deng, Peilin Zhong, Meisam Razaviyayn, Vahab Mirrokni</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06244">https://arxiv.org/abs/2502.06244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06244">https://arxiv.org/pdf/2502.06244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06244]] PiKE: Adaptive Data Mixing for Multi-Task Learning Under Low Gradient Conflicts(https://arxiv.org/abs/2502.06244)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Modern machine learning models are trained on diverse datasets and tasks to improve generalization. A key challenge in multitask learning is determining the optimal data mixing and sampling strategy across different data sources. Prior research in this multi-task learning setting has primarily focused on mitigating gradient conflicts between tasks. However, we observe that many real-world multitask learning scenarios-such as multilingual training and multi-domain learning in large foundation models-exhibit predominantly positive task interactions with minimal or no gradient conflict. Building on this insight, we introduce PiKE (Positive gradient interaction-based K-task weights Estimator), an adaptive data mixing algorithm that dynamically adjusts task contributions throughout training. PiKE optimizes task sampling to minimize overall loss, effectively leveraging positive gradient interactions with almost no additional computational overhead. We establish theoretical convergence guarantees for PiKE and demonstrate its superiority over static and non-adaptive mixing strategies. Additionally, we extend PiKE to promote fair learning across tasks, ensuring balanced progress and preventing task underrepresentation. Empirical evaluations on large-scale language model pretraining show that PiKE consistently outperforms existing heuristic and static mixing strategies, leading to faster convergence and improved downstream task performance.</li>
</ul>

<h3>Title: DGNO: A Novel Physics-aware Neural Operator for Solving Forward and Inverse PDE Problems based on Deep, Generative Probabilistic Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yaohua Zang, Phaedon-Stelios Koutsourelakis</a></li>
<li><strong>Subjects: </strong>cs.LG, math-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06250">https://arxiv.org/abs/2502.06250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06250">https://arxiv.org/pdf/2502.06250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06250]] DGNO: A Novel Physics-aware Neural Operator for Solving Forward and Inverse PDE Problems based on Deep, Generative Probabilistic Modeling(https://arxiv.org/abs/2502.06250)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Solving parametric partial differential equations (PDEs) and associated PDE-based, inverse problems is a central task in engineering and physics, yet existing neural operator methods struggle with high-dimensional, discontinuous inputs and require large amounts of {\em labeled} training data. We propose the Deep Generative Neural Operator (DGNO), a physics-aware framework that addresses these challenges by leveraging a deep, generative, probabilistic model in combination with a set of lower-dimensional, latent variables that simultaneously encode PDE-inputs and PDE-outputs. This formulation can make use of unlabeled data and significantly improves inverse problem-solving, particularly for discontinuous or discrete-valued input functions. DGNO enforces physics constraints without labeled data by incorporating as virtual observables, weak-form residuals based on compactly supported radial basis functions (CSRBFs). These relax regularity constraints and eliminate higher-order derivatives from the objective function. We also introduce MultiONet, a novel neural operator architecture, which is a more expressive generalization of the popular DeepONet that significantly enhances the approximating power of the proposed model. These innovations make DGNO particularly effective for challenging forward and inverse, PDE-based problems, such as those involving multi-phase media. Numerical experiments demonstrate that DGNO achieves higher accuracy across multiple benchmarks while exhibiting robustness to noise and strong generalization to out-of-distribution cases. Its adaptability, and the ability to handle sparse, noisy data while providing probabilistic estimates, make DGNO a powerful tool for scientific and engineering applications.</li>
</ul>

<h3>Title: K-ON: Stacking Knowledge On the Head Layer of Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Lingbing Guo, Yichi Zhang, Zhongpu Bo, Zhuo Chen, Mengshu Sun, Zhiqiang Zhang, Wen Zhang, Huajun Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06257">https://arxiv.org/abs/2502.06257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06257">https://arxiv.org/pdf/2502.06257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06257]] K-ON: Stacking Knowledge On the Head Layer of Large Language Model(https://arxiv.org/abs/2502.06257)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have significantly improved various natural language processing (NLP) tasks. Typically, LLMs are trained to predict the next token, aligning well with many NLP tasks. However, in knowledge graph (KG) scenarios, entities are the fundamental units and identifying an entity requires at least several tokens. This leads to a granularity mismatch between KGs and natural languages. To address this issue, we propose K-ON, which integrates KG knowledge into the LLM by employing multiple head layers for next k-step prediction. K-ON can not only generate entity-level results in one step, but also enables contrastive loss against entities, which is the most powerful tool in KG representation learning. Experimental results show that K-ON outperforms state-of-the-art methods that incorporate text and even the other modalities.</li>
</ul>

<h3>Title: Emergent Response Planning in LLM</h3>
<ul>
<li><strong>Authors: </strong>Zhichen Dong, Zhanhui Zhou, Zhixuan Liu, Chao Yang, Chaochao Lu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06258">https://arxiv.org/abs/2502.06258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06258">https://arxiv.org/pdf/2502.06258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06258]] Emergent Response Planning in LLM(https://arxiv.org/abs/2502.06258)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we argue that large language models (LLMs), though trained to predict only the next token, exhibit emergent planning behaviors: $\textbf{their hidden representations encode future outputs beyond the next token}$. Through simple probing, we demonstrate that LLM prompt representations encode global attributes of their entire responses, including $\textit{structural attributes}$ (response length, reasoning steps), $\textit{content attributes}$ (character choices in storywriting, multiple-choice answers at the end of response), and $\textit{behavioral attributes}$ (answer confidence, factual consistency). In addition to identifying response planning, we explore how it scales with model size across tasks and how it evolves during generation. The findings that LLMs plan ahead for the future in their hidden representations suggests potential applications for improving transparency and generation control.</li>
</ul>

<h3>Title: HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational Pharmacovigilance</h3>
<ul>
<li><strong>Authors: </strong>Zhaoying Wang, Yingdan Shi, Xiang Liu, Can Chen, Jun Wen, Ren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.MN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06274">https://arxiv.org/abs/2502.06274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06274">https://arxiv.org/pdf/2502.06274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06274]] HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational Pharmacovigilance(https://arxiv.org/abs/2502.06274)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Drug-side effect research is vital for understanding adverse reactions arising in complex multi-drug therapies. However, the scarcity of higher-order datasets that capture the combinatorial effects of multiple drugs severely limits progress in this field. Existing resources such as TWOSIDES primarily focus on pairwise interactions. To fill this critical gap, we introduce HODDI, the first Higher-Order Drug-Drug Interaction Dataset, constructed from U.S. Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS) records spanning the past decade, to advance computational pharmacovigilance. HODDI contains 109,744 records involving 2,506 unique drugs and 4,569 unique side effects, specifically curated to capture multi-drug interactions and their collective impact on adverse effects. Comprehensive statistical analyses demonstrate HODDI's extensive coverage and robust analytical metrics, making it a valuable resource for studying higher-order drug relationships. Evaluating HODDI with multiple models, we found that simple Multi-Layer Perceptron (MLP) can outperform graph models, while hypergraph models demonstrate superior performance in capturing complex multi-drug interactions, further validating HODDI's effectiveness. Our findings highlight the inherent value of higher-order information in drug-side effect prediction and position HODDI as a benchmark dataset for advancing research in pharmacovigilance, drug safety, and personalized medicine. The dataset and codes are available at this https URL.</li>
</ul>

<h3>Title: DebateBench: A Challenging Long Context Reasoning Benchmark For Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Utkarsh Tiwari, Aryan Seth, Adi Mukherjee, Kaavya Mer, Kavish, Dhruv Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06279">https://arxiv.org/abs/2502.06279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06279">https://arxiv.org/pdf/2502.06279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06279]] DebateBench: A Challenging Long Context Reasoning Benchmark For Large Language Models(https://arxiv.org/abs/2502.06279)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce DebateBench, a novel dataset consisting of an extensive collection of transcripts and metadata from some of the world's most prestigious competitive debates. The dataset consists of British Parliamentary debates from prestigious debating tournaments on diverse topics, annotated with detailed speech-level scores and house rankings sourced from official adjudication data. We curate 256 speeches across 32 debates with each debate being over 1 hour long with each input being an average of 32,000 tokens. Designed to capture long-context, large-scale reasoning tasks, DebateBench provides a benchmark for evaluating modern large language models (LLMs) on their ability to engage in argumentation, deliberation, and alignment with human experts. To do well on DebateBench, the LLMs must perform in-context learning to understand the rules and evaluation criteria of the debates, then analyze 8 seven minute long speeches and reason about the arguments presented by all speakers to give the final results. Our preliminary evaluation using GPT o1, GPT-4o, and Claude Haiku, shows that LLMs struggle to perform well on DebateBench, highlighting the need to develop more sophisticated techniques for improving their performance.</li>
</ul>

<h3>Title: Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE</h3>
<ul>
<li><strong>Authors: </strong>Haiduo Huang, Fuwei Yang, Zhenhua Liu, Yixing Xu, Jinze Li, Yang Liu, Xuanwu Yin, Dong Li, Pengju Ren, Emad Barsoum</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06282">https://arxiv.org/abs/2502.06282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06282">https://arxiv.org/pdf/2502.06282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06282]] Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE(https://arxiv.org/abs/2502.06282)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding (SD) accelerates large language model inference by using a smaller draft model to predict multiple tokens, which are then verified in parallel by the larger target model. However, the limited capacity of the draft model often necessitates tree-based sampling to improve prediction accuracy, where multiple candidates are generated at each step. We identify a key limitation in this approach: the candidates at the same step are derived from the same representation, limiting diversity and reducing overall effectiveness. To address this, we propose Jakiro, leveraging Mixture of Experts (MoE), where independent experts generate diverse predictions, effectively decoupling correlations among candidates. Furthermore, we introduce a hybrid inference strategy, combining autoregressive decoding for initial tokens with parallel decoding for subsequent stages, and enhance the latter with contrastive mechanism in features to improve accuracy. Our method significantly boosts prediction accuracy and achieves higher inference speedups. Extensive experiments across diverse models validate the effectiveness and robustness of our approach, establishing a new SOTA in speculative decoding. Our codes are available at this https URL.</li>
</ul>

<h3>Title: Enhancing Ground-to-Aerial Image Matching for Visual Misinformation Detection Using Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Matteo Mule, Matteo Pannacci, Ali Ghasemi Goudarzi, Francesco Pro, Lorenzo Papa, Luca Maiano, Irene Amerini</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06288">https://arxiv.org/abs/2502.06288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06288">https://arxiv.org/pdf/2502.06288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06288]] Enhancing Ground-to-Aerial Image Matching for Visual Misinformation Detection Using Semantic Segmentation(https://arxiv.org/abs/2502.06288)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>The recent advancements in generative AI techniques, which have significantly increased the online dissemination of altered images and videos, have raised serious concerns about the credibility of digital media available on the Internet and distributed through information channels and social networks. This issue particularly affects domains that rely heavily on trustworthy data, such as journalism, forensic analysis, and Earth observation. To address these concerns, the ability to geolocate a non-geo-tagged ground-view image without external information, such as GPS coordinates, has become increasingly critical. This study tackles the challenge of linking a ground-view image, potentially exhibiting varying fields of view (FoV), to its corresponding satellite image without the aid of GPS data. To achieve this, we propose a novel four-stream Siamese-like architecture, the Quadruple Semantic Align Net (SAN-QUAD), which extends previous state-of-the-art (SOTA) approaches by leveraging semantic segmentation applied to both ground and satellite imagery. Experimental results on a subset of the CVUSA dataset demonstrate significant improvements of up to 9.8\% over prior methods across various FoV settings.</li>
</ul>

<h3>Title: SeaExam and SeaBench: Benchmarking LLMs with Local Multilingual Questions in Southeast Asia</h3>
<ul>
<li><strong>Authors: </strong>Chaoqun Liu, Wenxuan Zhang, Jiahao Ying, Mahani Aljunied, Anh Tuan Luu, Lidong Bing</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06298">https://arxiv.org/abs/2502.06298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06298">https://arxiv.org/pdf/2502.06298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06298]] SeaExam and SeaBench: Benchmarking LLMs with Local Multilingual Questions in Southeast Asia(https://arxiv.org/abs/2502.06298)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study introduces two novel benchmarks, SeaExam and SeaBench, designed to evaluate the capabilities of Large Language Models (LLMs) in Southeast Asian (SEA) application scenarios. Unlike existing multilingual datasets primarily derived from English translations, these benchmarks are constructed based on real-world scenarios from SEA regions. SeaExam draws from regional educational exams to form a comprehensive dataset that encompasses subjects such as local history and literature. In contrast, SeaBench is crafted around multi-turn, open-ended tasks that reflect daily interactions within SEA communities. Our evaluations demonstrate that SeaExam and SeaBench more effectively discern LLM performance on SEA language tasks compared to their translated benchmarks. This highlights the importance of using real-world queries to assess the multilingual capabilities of LLMs.</li>
</ul>

<h3>Title: Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Maty√°≈° Lorenc</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06301">https://arxiv.org/abs/2502.06301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06301">https://arxiv.org/pdf/2502.06301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06301]] Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning(https://arxiv.org/abs/2502.06301)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we experiment with novelty-based variants of OpenAI-ES, the NS-ES and NSR-ES algorithms, and evaluate their effectiveness in training complex, transformer-based architectures designed for the problem of reinforcement learning such as Decision Transformers. We also test if we can accelerate the novelty-based training of these larger models by seeding the training by a pretrained models. By this, we build on our previous work, where we tested the ability of evolution strategies - specifically the aforementioned OpenAI-ES - to train the Decision Transformer architecture. The results were mixed. NS-ES showed progress, but it would clearly need many more iterations for it to yield interesting results. NSR-ES, on the other hand, proved quite capable of being straightforwardly used on larger models, since its performance appears as similar between the feed-forward model and Decision Transformer, as it was for the OpenAI-ES in our previous work.</li>
</ul>

<h3>Title: Latent Convergence Modulation in Large Language Models: A Novel Approach to Iterative Contextual Realignment</h3>
<ul>
<li><strong>Authors: </strong>Patricia Porretta, Sylvester Pakenham, Huxley Ainsworth, Gregory Chatten, Godfrey Allerton, Simon Hollingsworth, Vance Periwinkle</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06302">https://arxiv.org/abs/2502.06302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06302">https://arxiv.org/pdf/2502.06302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06302]] Latent Convergence Modulation in Large Language Models: A Novel Approach to Iterative Contextual Realignment(https://arxiv.org/abs/2502.06302)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Token prediction stability remains a challenge in autoregressive generative models, where minor variations in early inference steps often lead to significant semantic drift over extended sequences. A structured modulation mechanism was introduced to regulate hidden state transitions, ensuring that latent representation trajectories remain aligned with prior contextual dependencies while preserving generative flexibility. The modulation framework was designed to function within transformer-based architectures, dynamically constraining representation evolution without imposing external memory dependencies or extensive architectural modifications. Empirical evaluations demonstrated that structured latent adjustments contributed to reductions in perplexity fluctuations, entropy variance, and lexical instability, improving coherence in long-form text generation. Gradient propagation stability was further analyzed, revealing that the modulation process led to smoother optimization pathways, mitigating erratic fluctuations in weight updates across successive inference steps. The computational efficiency of the modulation process was assessed, showing that its integration within transformer-based architectures introduced only marginal overhead while maintaining compatibility with existing optimization frameworks. The structured modulation constraints also influenced syntactic variation, preventing excessive repetition while maintaining balanced sentence length distributions. Comparative evaluations against baseline models reinforced the role of controlled latent state evolution in improving pronoun resolution, logical consistency, and contextual alignment across autoregressive text generation tasks.</li>
</ul>

<h3>Title: Cell Nuclei Detection and Classification in Whole Slide Images with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Oscar Pina, Eduard Dorca, Ver√≥nica Vilaplana</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06307">https://arxiv.org/abs/2502.06307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06307">https://arxiv.org/pdf/2502.06307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06307]] Cell Nuclei Detection and Classification in Whole Slide Images with Transformers(https://arxiv.org/abs/2502.06307)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate and efficient cell nuclei detection and classification in histopathological Whole Slide Images (WSIs) are pivotal for digital pathology applications. Traditional cell segmentation approaches, while commonly used, are computationally expensive and require extensive post-processing, limiting their practicality for high-throughput clinical settings. In this paper, we propose a paradigm shift from segmentation to detection for extracting cell information from WSIs, introducing CellNuc-DETR as a more effective solution. We evaluate the accuracy performance of CellNuc-DETR on the PanNuke dataset and conduct cross-dataset evaluations on CoNSeP and MoNuSeg to assess robustness and generalization capabilities. Our results demonstrate state-of-the-art performance in both cell nuclei detection and classification tasks. Additionally, we assess the efficiency of CellNuc-DETR on large WSIs, showing that it not only outperforms current methods in accuracy but also significantly reduces inference times. Specifically, CellNuc-DETR is twice as fast as the fastest segmentation-based method, HoVer-NeXt, while achieving substantially higher accuracy. Moreover, it surpasses CellViT in accuracy and is approximately ten times more efficient in inference speed on WSIs. These results establish CellNuc-DETR as a superior approach for cell analysis in digital pathology, combining high accuracy with computational efficiency.</li>
</ul>

<h3>Title: From Pixels to Components: Eigenvector Masking for Visual Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Alice Bizeul, Thomas Sutter, Alain Ryser, Bernhard Sch√∂lkopf, Julius von K√ºgelgen, Julia E. Vogt</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06314">https://arxiv.org/abs/2502.06314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06314">https://arxiv.org/pdf/2502.06314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06314]] From Pixels to Components: Eigenvector Masking for Visual Representation Learning(https://arxiv.org/abs/2502.06314)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Predicting masked from visible parts of an image is a powerful self-supervised approach for visual representation learning. However, the common practice of masking random patches of pixels exhibits certain failure modes, which can prevent learning meaningful high-level features, as required for downstream tasks. We propose an alternative masking strategy that operates on a suitable transformation of the data rather than on the raw pixels. Specifically, we perform principal component analysis and then randomly mask a subset of components, which accounts for a fixed ratio of the data variance. The learning task then amounts to reconstructing the masked components from the visible ones. Compared to local patches of pixels, the principal components of images carry more global information. We thus posit that predicting masked from visible components involves more high-level features, allowing our masking strategy to extract more useful representations. This is corroborated by our empirical findings which demonstrate improved image classification performance for component over pixel masking. Our method thus constitutes a simple and robust data-driven alternative to traditional masked image modeling approaches.</li>
</ul>

<h3>Title: Can AI Examine Novelty of Patents?: Novelty Evaluation Based on the Correspondence between Patent Claim and Prior Art</h3>
<ul>
<li><strong>Authors: </strong>Hayato Ikoma, Teruko Mitamura</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06316">https://arxiv.org/abs/2502.06316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06316">https://arxiv.org/pdf/2502.06316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06316]] Can AI Examine Novelty of Patents?: Novelty Evaluation Based on the Correspondence between Patent Claim and Prior Art(https://arxiv.org/abs/2502.06316)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Assessing the novelty of patent claims is a critical yet challenging task traditionally performed by patent examiners. While advancements in NLP have enabled progress in various patent-related tasks, novelty assessment remains unexplored. This paper introduces a novel challenge by evaluating the ability of large language models (LLMs) to assess patent novelty by comparing claims with cited prior art documents, following the process similar to that of patent examiners done. We present the first dataset specifically designed for novelty evaluation, derived from real patent examination cases, and analyze the capabilities of LLMs to address this task. Our study reveals that while classification models struggle to effectively assess novelty, generative models make predictions with a reasonable level of accuracy, and their explanations are accurate enough to understand the relationship between the target patent and prior art. These findings demonstrate the potential of LLMs to assist in patent evaluation, reducing the workload for both examiners and applicants. Our contributions highlight the limitations of current models and provide a foundation for improving AI-driven patent analysis through advanced models and refined datasets.</li>
</ul>

<h3>Title: UniDemoir\'e: Towards Universal Image Demoir\'eing with Data Generation and Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Zemin Yang, Yujing Sun, Xidong Peng, Siu Ming Yiu, Yuexin Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06324">https://arxiv.org/abs/2502.06324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06324">https://arxiv.org/pdf/2502.06324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06324]] UniDemoir\'e: Towards Universal Image Demoir\'eing with Data Generation and Synthesis(https://arxiv.org/abs/2502.06324)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Image demoir√©ing poses one of the most formidable challenges in image restoration, primarily due to the unpredictable and anisotropic nature of moir√© patterns. Limited by the quantity and diversity of training data, current methods tend to overfit to a single moir√© domain, resulting in performance degradation for new domains and restricting their robustness in real-world applications. In this paper, we propose a universal image demoir√©ing solution, UniDemoir√©, which has superior generalization capability. Notably, we propose innovative and effective data generation and synthesis methods that can automatically provide vast high-quality moir√© images to train a universal demoir√©ing model. Our extensive experiments demonstrate the cutting-edge performance and broad potential of our approach for generalized image demoir√©ing.</li>
</ul>

<h3>Title: Prompt-Driven Continual Graph Learning</h3>
<ul>
<li><strong>Authors: </strong>Qi Wang, Tianfei Zhou, Ye Yuan, Rui Mao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06327">https://arxiv.org/abs/2502.06327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06327">https://arxiv.org/pdf/2502.06327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06327]] Prompt-Driven Continual Graph Learning(https://arxiv.org/abs/2502.06327)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Continual Graph Learning (CGL), which aims to accommodate new tasks over evolving graph data without forgetting prior knowledge, is garnering significant research interest. Mainstream solutions adopt the memory replay-based idea, ie, caching representative data from earlier tasks for retraining the graph model. However, this strategy struggles with scalability issues for constantly evolving graphs and raises concerns regarding data privacy. Inspired by recent advancements in the prompt-based learning paradigm, this paper introduces a novel prompt-driven continual graph learning (PROMPTCGL) framework, which learns a separate prompt for each incoming task and maintains the underlying graph neural network model fixed. In this way, PROMPTCGL naturally avoids catastrophic forgetting of knowledge from previous tasks. More specifically, we propose hierarchical prompting to instruct the model from both feature- and topology-level to fully address the variability of task graphs in dynamic continual learning. Additionally, we develop a personalized prompt generator to generate tailored prompts for each graph node while minimizing the number of prompts needed, leading to constant memory consumption regardless of the graph scale. Extensive experiments on four benchmarks show that PROMPTCGL achieves superior performance against existing CGL approaches while significantly reducing memory consumption. Our code is available at this https URL.</li>
</ul>

<h3>Title: Expect the Unexpected: FailSafe Long Context QA for Finance</h3>
<ul>
<li><strong>Authors: </strong>Kiran Kamble, Melisa Russak, Dmytro Mozolevskyi, Muayad Ali, Mateusz Russak, Waseem AlShikh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06329">https://arxiv.org/abs/2502.06329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06329">https://arxiv.org/pdf/2502.06329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06329]] Expect the Unexpected: FailSafe Long Context QA for Finance(https://arxiv.org/abs/2502.06329)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose a new long-context financial benchmark, FailSafeQA, designed to test the robustness and context-awareness of LLMs against six variations in human-interface interactions in LLM-based query-answer systems within finance. We concentrate on two case studies: Query Failure and Context Failure. In the Query Failure scenario, we perturb the original query to vary in domain expertise, completeness, and linguistic accuracy. In the Context Failure case, we simulate the uploads of degraded, irrelevant, and empty documents. We employ the LLM-as-a-Judge methodology with Qwen2.5-72B-Instruct and use fine-grained rating criteria to define and calculate Robustness, Context Grounding, and Compliance scores for 24 off-the-shelf models. The results suggest that although some models excel at mitigating input perturbations, they must balance robust answering with the ability to refrain from hallucinating. Notably, Palmyra-Fin-128k-Instruct, recognized as the most compliant model, maintained strong baseline performance but encountered challenges in sustaining robust predictions in 17% of test cases. On the other hand, the most robust model, OpenAI o3-mini, fabricated information in 41% of tested cases. The results demonstrate that even high-performing models have significant room for improvement and highlight the role of FailSafeQA as a tool for developing LLMs optimized for dependability in financial applications. The dataset is available at: this https URL</li>
</ul>

<h3>Title: Microcanonical Langevin Ensembles: Advancing the Sampling of Bayesian Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Emanuel Sommer, Jakob Robnik, Giorgi Nozadze, Uros Seljak, David R√ºgamer</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06335">https://arxiv.org/abs/2502.06335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06335">https://arxiv.org/pdf/2502.06335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06335]] Microcanonical Langevin Ensembles: Advancing the Sampling of Bayesian Neural Networks(https://arxiv.org/abs/2502.06335)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite recent advances, sampling-based inference for Bayesian Neural Networks (BNNs) remains a significant challenge in probabilistic deep learning. While sampling-based approaches do not require a variational distribution assumption, current state-of-the-art samplers still struggle to navigate the complex and highly multimodal posteriors of BNNs. As a consequence, sampling still requires considerably longer inference times than non-Bayesian methods even for small neural networks, despite recent advances in making software implementations more efficient. Besides the difficulty of finding high-probability regions, the time until samplers provide sufficient exploration of these areas remains unpredictable. To tackle these challenges, we introduce an ensembling approach that leverages strategies from optimization and a recently proposed sampler called Microcanonical Langevin Monte Carlo (MCLMC) for efficient, robust and predictable sampling performance. Compared to approaches based on the state-of-the-art No-U-Turn Sampler, our approach delivers substantial speedups up to an order of magnitude, while maintaining or improving predictive performance and uncertainty quantification across diverse tasks and data modalities. The suggested Microcanonical Langevin Ensembles and modifications to MCLMC additionally enhance the method's predictability in resource requirements, facilitating easier parallelization. All in all, the proposed method offers a promising direction for practical, scalable inference for BNNs.</li>
</ul>

<h3>Title: DefTransNet: A Transformer-based Method for Non-Rigid Point Cloud Registration in the Simulation of Soft Tissue Deformation</h3>
<ul>
<li><strong>Authors: </strong>Sara Monji-Azad, Marvin Kinz, Siddharth Kothari, Robin Khanna, Amrei Carla Mihan, David Maennel, Claudia Scherl, Juergen Hesser</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06336">https://arxiv.org/abs/2502.06336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06336">https://arxiv.org/pdf/2502.06336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06336]] DefTransNet: A Transformer-based Method for Non-Rigid Point Cloud Registration in the Simulation of Soft Tissue Deformation(https://arxiv.org/abs/2502.06336)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Soft-tissue surgeries, such as tumor resections, are complicated by tissue deformations that can obscure the accurate location and shape of tissues. By representing tissue surfaces as point clouds and applying non-rigid point cloud registration (PCR) methods, surgeons can better understand tissue deformations before, during, and after surgery. Existing non-rigid PCR methods, such as feature-based approaches, struggle with robustness against challenges like noise, outliers, partial data, and large deformations, making accurate point correspondence difficult. Although learning-based PCR methods, particularly Transformer-based approaches, have recently shown promise due to their attention mechanisms for capturing interactions, their robustness remains limited in challenging scenarios. In this paper, we present DefTransNet, a novel end-to-end Transformer-based architecture for non-rigid PCR. DefTransNet is designed to address the key challenges of deformable registration, including large deformations, outliers, noise, and partial data, by inputting source and target point clouds and outputting displacement vector fields. The proposed method incorporates a learnable transformation matrix to enhance robustness to affine transformations, integrates global and local geometric information, and captures long-range dependencies among points using Transformers. We validate our approach on four datasets: ModelNet, SynBench, 4DMatch, and DeformedTissue, using both synthetic and real-world data to demonstrate the generalization of our proposed method. Experimental results demonstrate that DefTransNet outperforms current state-of-the-art registration networks across various challenging conditions. Our code and data are publicly available.</li>
</ul>

<h3>Title: Accelerating Outlier-robust Rotation Estimation by Stereographic Projection</h3>
<ul>
<li><strong>Authors: </strong>Taosi Xu, Yinlong Liu, Xianbo Wang, Zhi-Xin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06337">https://arxiv.org/abs/2502.06337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06337">https://arxiv.org/pdf/2502.06337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06337]] Accelerating Outlier-robust Rotation Estimation by Stereographic Projection(https://arxiv.org/abs/2502.06337)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Rotation estimation plays a fundamental role in many computer vision and robot tasks. However, efficiently estimating rotation in large inputs containing numerous outliers (i.e., mismatches) and noise is a recognized challenge. Many robust rotation estimation methods have been designed to address this challenge. Unfortunately, existing methods are often inapplicable due to their long computation time and the risk of local optima. In this paper, we propose an efficient and robust rotation estimation method. Specifically, our method first investigates geometric constraints involving only the rotation axis. Then, it uses stereographic projection and spatial voting techniques to identify the rotation axis and angle. Furthermore, our method efficiently obtains the optimal rotation estimation and can estimate multiple rotations simultaneously. To verify the feasibility of our method, we conduct comparative experiments using both synthetic and real-world data. The results show that, with GPU assistance, our method can solve large-scale ($10^6$ points) and severely corrupted (90\% outlier rate) rotation estimation problems within 0.07 seconds, with an angular error of only 0.01 degrees, which is superior to existing methods in terms of accuracy and efficiency.</li>
</ul>

<h3>Title: Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior</h3>
<ul>
<li><strong>Authors: </strong>Lee Hyoseok, Kyeong Seon Kim, Kwon Byung-Ki, Tae-Hyun Oh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06338">https://arxiv.org/abs/2502.06338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06338">https://arxiv.org/pdf/2502.06338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06338]] Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior(https://arxiv.org/abs/2502.06338)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Depth completion, predicting dense depth maps from sparse depth measurements, is an ill-posed problem requiring prior knowledge. Recent methods adopt learning-based approaches to implicitly capture priors, but the priors primarily fit in-domain data and do not generalize well to out-of-domain scenarios. To address this, we propose a zero-shot depth completion method composed of an affine-invariant depth diffusion model and test-time alignment. We use pre-trained depth diffusion models as depth prior knowledge, which implicitly understand how to fill in depth for scenes. Our approach aligns the affine-invariant depth prior with metric-scale sparse measurements, enforcing them as hard constraints via an optimization loop at test-time. Our zero-shot depth completion method demonstrates generalization across various domain datasets, achieving up to a 21\% average performance improvement over the previous state-of-the-art methods while enhancing spatial understanding by sharpening scene details. We demonstrate that aligning a monocular affine-invariant depth prior with sparse metric measurements is a proven strategy to achieve domain-generalizable depth completion without relying on extensive training data. Project page: this https URL.</li>
</ul>

<h3>Title: AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation</h3>
<ul>
<li><strong>Authors: </strong>Bo Gao, Yuan Wang, Qingsong Wei, Yong Liu, Rick Siow Mong Goh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06348">https://arxiv.org/abs/2502.06348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06348">https://arxiv.org/pdf/2502.06348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06348]] AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation(https://arxiv.org/abs/2502.06348)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, extraction, fair</a></li>
<li><strong>Abstract: </strong>Decentralized finance applications depend on accurate price oracles to ensure secure transactions, yet these oracles are highly vulnerable to manipulation, enabling attackers to exploit smart contract vulnerabilities for unfair asset valuation and financial gain. Detecting such manipulations traditionally relies on the manual effort of experienced experts, presenting significant challenges. In this paper, we propose a novel LLM-driven framework that automates the detection of price oracle manipulations by leveraging the complementary strengths of different LLM models. Our approach begins with domain-specific knowledge extraction, where an LLM model synthesizes precise insights about price oracle vulnerabilities from top-tier academic papers, eliminating the need for profound expertise from developers or auditors. This knowledge forms the foundation for a second LLM model to generate structured, context-aware chain of thought prompts, which guide a third LLM model in accurately identifying manipulation patterns in smart contracts. We validate the framework effectiveness through experiments on 60 known vulnerabilities from 46 real-world DeFi attacks or projects spanning 2021 to 2023. The best performing combination of LLMs (Haiku-Haiku-4o-mini) identified by AiRacleX demonstrate a 2.58-times improvement in recall (0.667 vs 0.259) compared to the state-of-the-art tool GPTScan, while maintaining comparable precision. Furthermore, our framework demonstrates the feasibility of replacing commercial models with open-source alternatives, enhancing privacy and security for developers.</li>
</ul>

<h3>Title: Provably Near-Optimal Federated Ensemble Distillation with Negligible Overhead</h3>
<ul>
<li><strong>Authors: </strong>Won-Jun Jang, Hyeon-Seo Park, Si-Hyeon Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06349">https://arxiv.org/abs/2502.06349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06349">https://arxiv.org/pdf/2502.06349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06349]] Provably Near-Optimal Federated Ensemble Distillation with Negligible Overhead(https://arxiv.org/abs/2502.06349)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, data-free</a></li>
<li><strong>Abstract: </strong>Federated ensemble distillation addresses client heterogeneity by generating pseudo-labels for an unlabeled server dataset based on client predictions and training the server model using the pseudo-labeled dataset. The unlabeled server dataset can either be pre-existing or generated through a data-free approach. The effectiveness of this approach critically depends on the method of assigning weights to client predictions when creating pseudo-labels, especially in highly heterogeneous settings. Inspired by theoretical results from GANs, we propose a provably near-optimal weighting method that leverages client discriminators trained with a server-distributed generator and local datasets. Our experiments on various image classification tasks demonstrate that the proposed method significantly outperforms baselines. Furthermore, we show that the additional communication cost, client-side privacy leakage, and client-side computational overhead introduced by our method are negligible, both in scenarios with and without a pre-existing server dataset.</li>
</ul>

<h3>Title: Calibrating LLMs with Information-Theoretic Evidential Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Yawei Li, David R√ºgamer, Bernd Bischl, Mina Rezaei</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06351">https://arxiv.org/abs/2502.06351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06351">https://arxiv.org/pdf/2502.06351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06351]] Calibrating LLMs with Information-Theoretic Evidential Deep Learning(https://arxiv.org/abs/2502.06351)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuned large language models (LLMs) often exhibit overconfidence, particularly when trained on small datasets, resulting in poor calibration and inaccurate uncertainty estimates. Evidential Deep Learning (EDL), an uncertainty-aware approach, enables uncertainty estimation in a single forward pass, making it a promising method for calibrating fine-tuned LLMs. However, despite its computational efficiency, EDL is prone to overfitting, as its training objective can result in overly concentrated probability distributions. To mitigate this, we propose regularizing EDL by incorporating an information bottleneck (IB). Our approach IB-EDL suppresses spurious information in the evidence generated by the model and encourages truly predictive information to influence both the predictions and uncertainty estimates. Extensive experiments across various fine-tuned LLMs and tasks demonstrate that IB-EDL outperforms both existing EDL and non-EDL approaches. By improving the trustworthiness of LLMs, IB-EDL facilitates their broader adoption in domains requiring high levels of confidence calibration. Code is available at this https URL.</li>
</ul>

<h3>Title: Guidance-base Diffusion Models for Improving Photoacoustic Image Quality</h3>
<ul>
<li><strong>Authors: </strong>Tatsuhiro Eguchi, Shumpei Takezaki, Mihoko Shimano, Takayuki Yagi, Ryoma Bise</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06354">https://arxiv.org/abs/2502.06354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06354">https://arxiv.org/pdf/2502.06354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06354]] Guidance-base Diffusion Models for Improving Photoacoustic Image Quality(https://arxiv.org/abs/2502.06354)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Photoacoustic(PA) imaging is a non-destructive and non-invasive technology for visualizing minute blood vessel structures in the body using ultrasonic sensors. In PA imaging, the image quality of a single-shot image is poor, and it is necessary to improve the image quality by averaging many single-shot images. Therefore, imaging the entire subject requires high imaging costs. In our study, we propose a method to improve the quality of PA images using diffusion models. In our method, we improve the reverse diffusion process using sensor information of PA imaging and introduce a guidance method using imaging condition information to generate high-quality images.</li>
</ul>

<h3>Title: Towards bandit-based prompt-tuning for in-the-wild foundation agents</h3>
<ul>
<li><strong>Authors: </strong>Finn Rietz, Oleg Smirnov, Sara Karimi, Lele Cao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06358">https://arxiv.org/abs/2502.06358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06358">https://arxiv.org/pdf/2502.06358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06358]] Towards bandit-based prompt-tuning for in-the-wild foundation agents(https://arxiv.org/abs/2502.06358)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Prompting has emerged as the dominant paradigm for adapting large, pre-trained transformer-based models to downstream tasks. The Prompting Decision Transformer (PDT) enables large-scale, multi-task offline reinforcement learning pre-training by leveraging stochastic trajectory prompts to identify the target task. However, these prompts are sampled uniformly from expert demonstrations, overlooking a critical limitation: Not all prompts are equally informative for differentiating between tasks. To address this, we propose an inference time bandit-based prompt-tuning framework that explores and optimizes trajectory prompt selection to enhance task performance. Our experiments indicate not only clear performance gains due to bandit-based prompt-tuning, but also better sample complexity, scalability, and prompt space exploration compared to prompt-tuning baselines.</li>
</ul>

<h3>Title: Hyperparameters in Score-Based Membership Inference Attacks</h3>
<ul>
<li><strong>Authors: </strong>Gauri Pradhan, Joonas J√§lk√∂, Marlon Tobaben, Antti Honkela</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06374">https://arxiv.org/abs/2502.06374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06374">https://arxiv.org/pdf/2502.06374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06374]] Hyperparameters in Score-Based Membership Inference Attacks(https://arxiv.org/abs/2502.06374)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Membership Inference Attacks (MIAs) have emerged as a valuable framework for evaluating privacy leakage by machine learning models. Score-based MIAs are distinguished, in particular, by their ability to exploit the confidence scores that the model generates for particular inputs. Existing score-based MIAs implicitly assume that the adversary has access to the target model's hyperparameters, which can be used to train the shadow models for the attack. In this work, we demonstrate that the knowledge of target hyperparameters is not a prerequisite for MIA in the transfer learning setting. Based on this, we propose a novel approach to select the hyperparameters for training the shadow models for MIA when the attacker has no prior knowledge about them by matching the output distributions of target and shadow models. We demonstrate that using the new approach yields hyperparameters that lead to an attack near indistinguishable in performance from an attack that uses target hyperparameters to train the shadow models. Furthermore, we study the empirical privacy risk of unaccounted use of training data for hyperparameter optimization (HPO) in differentially private (DP) transfer learning. We find no statistically significant evidence that performing HPO using training data would increase vulnerability to MIA.</li>
</ul>

<h3>Title: Many-Task Federated Fine-Tuning via Unified Task Vectors</h3>
<ul>
<li><strong>Authors: </strong>Vasileios Tsouvalas, Tanir Ozcelebi, Nirvana Meratnia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06376">https://arxiv.org/abs/2502.06376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06376">https://arxiv.org/pdf/2502.06376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06376]] Many-Task Federated Fine-Tuning via Unified Task Vectors(https://arxiv.org/abs/2502.06376)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) traditionally assumes homogeneous client tasks; however, in real-world scenarios, clients often specialize in diverse tasks, introducing task heterogeneity. To address this challenge, Many-Task FL (MaT-FL) has emerged, enabling clients to collaborate effectively despite task diversity. Existing MaT-FL approaches rely on client grouping or personalized layers, requiring the server to manage individual models and failing to account for clients handling multiple tasks. We propose MaTU, a MaT-FL approach that enables joint learning of task vectors across clients, eliminating the need for clustering or client-specific weight storage at the server. Our method introduces a novel aggregation mechanism that determines task similarity based on the direction of clients task vectors and constructs a unified task vector encapsulating all tasks. To address task-specific requirements, we augment the unified task vector with lightweight modulators that facilitate knowledge transfer among related tasks while disentangling dissimilar ones. Evaluated across 30 datasets, MaTU achieves superior performance over state-of-the-art MaT-FL approaches, with results comparable to per-task fine-tuning, while delivering significant communication savings.</li>
</ul>

<h3>Title: Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo</h3>
<ul>
<li><strong>Authors: </strong>Filip Ekstr√∂m Kelvinius, Zheng Zhao, Fredrik Lindsten</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06379">https://arxiv.org/abs/2502.06379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06379">https://arxiv.org/pdf/2502.06379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06379]] Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo(https://arxiv.org/abs/2502.06379)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>A recent line of research has exploited pre-trained generative diffusion models as priors for solving Bayesian inverse problems. We contribute to this research direction by designing a sequential Monte Carlo method for linear-Gaussian inverse problems which builds on ``decoupled diffusion", where the generative process is designed such that larger updates to the sample are possible. The method is asymptotically exact and we demonstrate the effectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC) algorithm on both synthetic data and image reconstruction tasks. Further, we demonstrate how the approach can be extended to discrete data.</li>
</ul>

<h3>Title: How Humans Help LLMs: Assessing and Incentivizing Human Preference Annotators</h3>
<ul>
<li><strong>Authors: </strong>Shang Liu, Hanzhao Wang, Zhongyao Ma, Xiaocheng Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT, econ.TH</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06387">https://arxiv.org/abs/2502.06387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06387">https://arxiv.org/pdf/2502.06387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06387]] How Humans Help LLMs: Assessing and Incentivizing Human Preference Annotators(https://arxiv.org/abs/2502.06387)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human-annotated preference data play an important role in aligning large language models (LLMs). In this paper, we investigate the questions of assessing the performance of human annotators and incentivizing them to provide high-quality annotations. The quality assessment of language/text annotation faces two challenges: (i) the intrinsic heterogeneity among annotators, which prevents the classic methods that assume the underlying existence of a true label; and (ii) the unclear relationship between the annotation quality and the performance of downstream tasks, which excludes the possibility of inferring the annotators' behavior based on the model performance trained from the annotation data. Then we formulate a principal-agent model to characterize the behaviors of and the interactions between the company and the human annotators. The model rationalizes a practical mechanism of a bonus scheme to incentivize annotators which benefits both parties and it underscores the importance of the joint presence of an assessment system and a proper contract scheme. From a technical perspective, our analysis extends the existing literature on the principal-agent model by considering a continuous action space for the agent. We show the gap between the first-best and the second-best solutions (under the continuous action space) is of $\Theta(1/\sqrt{n \log n})$ for the binary contracts and $\Theta(1/n)$ for the linear contracts, where $n$ is the number of samples used for performance assessment; this contrasts with the known result of $\exp(-\Theta(n))$ for the binary contracts when the action space is discrete. Throughout the paper, we use real preference annotation data to accompany our discussions.</li>
</ul>

<h3>Title: When Data Manipulation Meets Attack Goals: An In-depth Survey of Attacks for VLMs</h3>
<ul>
<li><strong>Authors: </strong>Aobotao Dai, Xinyu Ma, Lei Chen, Songze Li, Lin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06390">https://arxiv.org/abs/2502.06390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06390">https://arxiv.org/pdf/2502.06390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06390]] When Data Manipulation Meets Attack Goals: An In-depth Survey of Attacks for VLMs(https://arxiv.org/abs/2502.06390)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) have gained considerable prominence in recent years due to their remarkable capability to effectively integrate and process both textual and visual information. This integration has significantly enhanced performance across a diverse spectrum of applications, such as scene perception and robotics. However, the deployment of VLMs has also given rise to critical safety and security concerns, necessitating extensive research to assess the potential vulnerabilities these VLM systems may harbor. In this work, we present an in-depth survey of the attack strategies tailored for VLMs. We categorize these attacks based on their underlying objectives - namely jailbreak, camouflage, and exploitation - while also detailing the various methodologies employed for data manipulation of VLMs. Meanwhile, we outline corresponding defense mechanisms that have been proposed to mitigate these vulnerabilities. By discerning key connections and distinctions among the diverse types of attacks, we propose a compelling taxonomy for VLM attacks. Moreover, we summarize the evaluation metrics that comprehensively describe the characteristics and impact of different attacks on VLMs. Finally, we conclude with a discussion of promising future research directions that could further enhance the robustness and safety of VLMs, emphasizing the importance of ongoing exploration in this critical area of study. To facilitate community engagement, we maintain an up-to-date project page, accessible at: this https URL.</li>
</ul>

<h3>Title: TANGLED: Generating 3D Hair Strands from Images with Arbitrary Styles and Viewpoints</h3>
<ul>
<li><strong>Authors: </strong>Pengyu Long, Zijun Zhao, Min Ouyang, Qingcheng Zhao, Qixuan Zhang, Wei Yang, Lan Xu, Jingyi Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06392">https://arxiv.org/abs/2502.06392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06392">https://arxiv.org/pdf/2502.06392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06392]] TANGLED: Generating 3D Hair Strands from Images with Arbitrary Styles and Viewpoints(https://arxiv.org/abs/2502.06392)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Hairstyles are intricate and culturally significant with various geometries, textures, and structures. Existing text or image-guided generation methods fail to handle the richness and complexity of diverse styles. We present TANGLED, a novel approach for 3D hair strand generation that accommodates diverse image inputs across styles, viewpoints, and quantities of input views. TANGLED employs a three-step pipeline. First, our MultiHair Dataset provides 457 diverse hairstyles annotated with 74 attributes, emphasizing complex and culturally significant styles to improve model generalization. Second, we propose a diffusion framework conditioned on multi-view linearts that can capture topological cues (e.g., strand density and parting lines) while filtering out noise. By leveraging a latent diffusion model with cross-attention on lineart features, our method achieves flexible and robust 3D hair generation across diverse input conditions. Third, a parametric post-processing module enforces braid-specific constraints to maintain coherence in complex structures. This framework not only advances hairstyle realism and diversity but also enables culturally inclusive digital avatars and novel applications like sketch-based 3D strand editing for animation and augmented reality.</li>
</ul>

<h3>Title: Habitizing Diffusion Planning for Efficient and Effective Decision Making</h3>
<ul>
<li><strong>Authors: </strong>Haofei Lu, Yifei Shen, Dongsheng Li, Junliang Xing, Dongqi Han</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06401">https://arxiv.org/abs/2502.06401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06401">https://arxiv.org/pdf/2502.06401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06401]] Habitizing Diffusion Planning for Efficient and Effective Decision Making(https://arxiv.org/abs/2502.06401)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have shown great promise in decision-making, also known as diffusion planning. However, the slow inference speeds limit their potential for broader real-world applications. Here, we introduce Habi, a general framework that transforms powerful but slow diffusion planning models into fast decision-making models, which mimics the cognitive process in the brain that costly goal-directed behavior gradually transitions to efficient habitual behavior with repetitive practice. Even using a laptop CPU, the habitized model can achieve an average 800+ Hz decision-making frequency (faster than previous diffusion planners by orders of magnitude) on standard offline reinforcement learning benchmarks D4RL, while maintaining comparable or even higher performance compared to its corresponding diffusion planner. Our work proposes a fresh perspective of leveraging powerful diffusion models for real-world decision-making tasks. We also provide robust evaluations and analysis, offering insights from both biological and engineering perspectives for efficient and effective decision-making.</li>
</ul>

<h3>Title: An Automated Machine Learning Framework for Surgical Suturing Action Detection under Class Imbalance</h3>
<ul>
<li><strong>Authors: </strong>Baobing Zhang, Paul Sullivan, Benjie Tang, Ghulam Nabi, Mustafa Suphi Erden</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06407">https://arxiv.org/abs/2502.06407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06407">https://arxiv.org/pdf/2502.06407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06407]] An Automated Machine Learning Framework for Surgical Suturing Action Detection under Class Imbalance(https://arxiv.org/abs/2502.06407)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>In laparoscopy surgical training and evaluation, real-time detection of surgical actions with interpretable outputs is crucial for automated and real-time instructional feedback and skill development. Such capability would enable development of machine guided training systems. This paper presents a rapid deployment approach utilizing automated machine learning methods, based on surgical action data collected from both experienced and trainee surgeons. The proposed approach effectively tackles the challenge of highly imbalanced class distributions, ensuring robust predictions across varying skill levels of surgeons. Additionally, our method partially incorporates model transparency, addressing the reliability requirements in medical applications. Compared to deep learning approaches, traditional machine learning models not only facilitate efficient rapid deployment but also offer significant advantages in interpretability. Through experiments, this study demonstrates the potential of this approach to provide quick, reliable and effective real-time detection in surgical training environments</li>
</ul>

<h3>Title: Systematic Outliers in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yongqi An, Xu Zhao, Tao Yu, Ming Tang, Jinqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06415">https://arxiv.org/abs/2502.06415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06415">https://arxiv.org/pdf/2502.06415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06415]] Systematic Outliers in Large Language Models(https://arxiv.org/abs/2502.06415)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Outliers have been widely observed in Large Language Models (LLMs), significantly impacting model performance and posing challenges for model compression. Understanding the functionality and formation mechanisms of these outliers is critically important. Existing works, however, largely focus on reducing the impact of outliers from an algorithmic perspective, lacking an in-depth investigation into their causes and roles. In this work, we provide a detailed analysis of the formation process, underlying causes, and functions of outliers in LLMs. We define and categorize three types of outliers-activation outliers, weight outliers, and attention outliers-and analyze their distributions across different dimensions, uncovering inherent connections between their occurrences and their ultimate influence on the attention mechanism. Based on these observations, we hypothesize and explore the mechanisms by which these outliers arise and function, demonstrating through theoretical derivations and experiments that they emerge due to the self-attention mechanism's softmax operation. These outliers act as implicit context-aware scaling factors within the attention mechanism. As these outliers stem from systematic influences, we term them systematic outliers. Our study not only enhances the understanding of Transformer-based LLMs but also shows that structurally eliminating outliers can accelerate convergence and improve model compression. The code is avilable at this https URL.</li>
</ul>

<h3>Title: Robust Watermarks Leak: Channel-Aware Feature Extraction Enables Adversarial Watermark Manipulation</h3>
<ul>
<li><strong>Authors: </strong>Zhongjie Ba, Yitao Zhang, Peng Cheng, Bin Gong, Xinyu Zhang, Qinglong Wang, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06418">https://arxiv.org/abs/2502.06418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06418">https://arxiv.org/pdf/2502.06418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06418]] Robust Watermarks Leak: Channel-Aware Feature Extraction Enables Adversarial Watermark Manipulation(https://arxiv.org/abs/2502.06418)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal, extraction, watermark</a></li>
<li><strong>Abstract: </strong>Watermarking plays a key role in the provenance and detection of AI-generated content. While existing methods prioritize robustness against real-world distortions (e.g., JPEG compression and noise addition), we reveal a fundamental tradeoff: such robust watermarks inherently improve the redundancy of detectable patterns encoded into images, creating exploitable information leakage. To leverage this, we propose an attack framework that extracts leakage of watermark patterns through multi-channel feature learning using a pre-trained vision model. Unlike prior works requiring massive data or detector access, our method achieves both forgery and detection evasion with a single watermarked image. Extensive experiments demonstrate that our method achieves a 60\% success rate gain in detection evasion and 51\% improvement in forgery accuracy compared to state-of-the-art methods while maintaining visual fidelity. Our work exposes the robustness-stealthiness paradox: current "robust" watermarks sacrifice security for distortion resistance, providing insights for future watermark design.</li>
</ul>

<h3>Title: CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better Interpretability of Intelligent Fault Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Qian Chen, Xingjian Dong, Kui Hu, Kangkang Chen, Zhike Peng, Guang Meng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06424">https://arxiv.org/abs/2502.06424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06424">https://arxiv.org/pdf/2502.06424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06424]] CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better Interpretability of Intelligent Fault Diagnosis(https://arxiv.org/abs/2502.06424)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Neural networks (NNs), with their powerful nonlinear mapping and end-to-end capabilities, are widely applied in mechanical intelligent fault diagnosis (IFD). However, as typical black-box models, they pose challenges in understanding their decision basis and logic, limiting their deployment in high-reliability scenarios. Hence, various methods have been proposed to enhance the interpretability of IFD. Among these, post-hoc approaches can provide explanations without changing model architecture, preserving its flexibility and scalability. However, existing post-hoc methods often suffer from limitations in explanation forms. They either require preprocessing that disrupts the end-to-end nature or overlook fault mechanisms, leading to suboptimal explanations. To address these issues, we derived the cyclic-spectral (CS) transform and proposed the CS-SHAP by extending Shapley additive explanations (SHAP) to the CS domain. CS-SHAP can evaluate contributions from both carrier and modulation frequencies, aligning more closely with fault mechanisms and delivering clearer and more accurate explanations. Three datasets are utilized to validate the superior interpretability of CS-SHAP, ensuring its correctness, reproducibility, and practical performance. With open-source code and outstanding interpretability, CS-SHAP has the potential to be widely adopted and become the post-hoc interpretability benchmark in IFD, even in other classification tasks. The code is available on this https URL.</li>
</ul>

<h3>Title: Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs</h3>
<ul>
<li><strong>Authors: </strong>Hiroki Watanabe, Motonobu Uchikoshi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06425">https://arxiv.org/abs/2502.06425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06425">https://arxiv.org/pdf/2502.06425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06425]] Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs(https://arxiv.org/abs/2502.06425)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly utilized in domains such as finance, healthcare, and interpersonal relationships to provide advice tailored to user traits and contexts. However, this personalization often relies on sensitive data, raising critical privacy concerns and necessitating data minimization. To address these challenges, we propose a framework that integrates zero-knowledge proof (ZKP) technology, specifically zkVM, with LLM-based chatbots. This integration enables privacy-preserving data sharing by verifying user traits without disclosing sensitive information. Our research introduces both an architecture and a prompting strategy for this approach. Through empirical evaluation, we clarify the current constraints and performance limitations of both zkVM and the proposed prompting strategy, thereby demonstrating their practical feasibility in real-world scenarios.</li>
</ul>

<h3>Title: Hybrid State-Space and GRU-based Graph Tokenization Mamba for Hyperspectral Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ahmad, Muhammad Hassaan Farooq Butt, Muhammad Usama, Manuel Mazzara, Salvatore Distefano, Adil Mehmood Khan, Danfeng Hong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06427">https://arxiv.org/abs/2502.06427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06427">https://arxiv.org/pdf/2502.06427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06427]] Hybrid State-Space and GRU-based Graph Tokenization Mamba for Hyperspectral Image Classification(https://arxiv.org/abs/2502.06427)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Hyperspectral image (HSI) classification plays a pivotal role in domains such as environmental monitoring, agriculture, and urban planning. However, it faces significant challenges due to the high-dimensional nature of the data and the complex spectral-spatial relationships inherent in HSI. Traditional methods, including conventional machine learning and convolutional neural networks (CNNs), often struggle to effectively capture these intricate spectral-spatial features and global contextual information. Transformer-based models, while powerful in capturing long-range dependencies, often demand substantial computational resources, posing challenges in scenarios where labeled datasets are limited, as is commonly seen in HSI applications. To overcome these challenges, this work proposes GraphMamba, a hybrid model that combines spectral-spatial token generation, graph-based token prioritization, and cross-attention mechanisms. The model introduces a novel hybridization of state-space modeling and Gated Recurrent Units (GRU), capturing both linear and nonlinear spatial-spectral dynamics. GraphMamba enhances the ability to model complex spatial-spectral relationships while maintaining scalability and computational efficiency across diverse HSI datasets. Through comprehensive experiments, we demonstrate that GraphMamba outperforms existing state-of-the-art models, offering a scalable and robust solution for complex HSI classification tasks.</li>
</ul>

<h3>Title: CoS: Chain-of-Shot Prompting for Long Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jian Hu, Zixu Cheng, Chenyang Si, Wei Li, Shaogang Gong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06428">https://arxiv.org/abs/2502.06428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06428">https://arxiv.org/pdf/2502.06428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06428]] CoS: Chain-of-Shot Prompting for Long Video Understanding(https://arxiv.org/abs/2502.06428)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal Large Language Models (MLLMs) struggle with long videos due to the need for excessive visual tokens. These tokens exceed massively the context length of MLLMs, resulting in filled by redundant task-irrelevant shots. How to select shots is an unsolved critical problem: sparse sampling risks missing key details, while exhaustive sampling overwhelms the model with irrelevant content, leading to video misunderstanding. To solve this problem, we propose Chain-of-Shot prompting (CoS). The key idea is to frame shot selection as test-time visual prompt optimisation, choosing shots adaptive to video understanding semantic task by optimising shots-task alignment. CoS has two key parts: (1) a binary video summary mechanism that performs pseudo temporal grounding, discovering a binary coding to identify task-relevant shots, and (2) a video co-reasoning module that deploys the binary coding to pair (learning to align) task-relevant positive shots with irrelevant negative shots. It embeds the optimised shot selections into the original video, facilitating a focus on relevant context to optimize long video understanding. Experiments across three baselines and five datasets demonstrate the effectiveness and adaptability of CoS. Code given in this https URL.</li>
</ul>

<h3>Title: Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising</h3>
<ul>
<li><strong>Authors: </strong>Huaqiu Li, Wang Zhang, Xiaowan Hu, Tao Jiang, Zikang Chen, Haoqian Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06432">https://arxiv.org/abs/2502.06432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06432">https://arxiv.org/pdf/2502.06432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06432]] Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising(https://arxiv.org/abs/2502.06432)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Many studies have concentrated on constructing supervised models utilizing paired datasets for image denoising, which proves to be expensive and time-consuming. Current self-supervised and unsupervised approaches typically rely on blind-spot networks or sub-image pairs sampling, resulting in pixel information loss and destruction of detailed structural information, thereby significantly constraining the efficacy of such methods. In this paper, we introduce Prompt-SID, a prompt-learning-based single image denoising framework that emphasizes preserving of structural details. This approach is trained in a self-supervised manner using downsampled image pairs. It captures original-scale image information through structural encoding and integrates this prompt into the denoiser. To achieve this, we propose a structural representation generation model based on the latent diffusion process and design a structural attention module within the transformer-based denoiser architecture to decode the prompt. Additionally, we introduce a scale replay training mechanism, which effectively mitigates the scale gap from images of different resolutions. We conduct comprehensive experiments on synthetic, real-world, and fluorescence imaging datasets, showcasing the remarkable effectiveness of Prompt-SID.</li>
</ul>

<h3>Title: Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images</h3>
<ul>
<li><strong>Authors: </strong>Lingao Xiao, Songhua Liu, Yang He, Xinchao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06434">https://arxiv.org/abs/2502.06434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06434">https://arxiv.org/pdf/2502.06434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06434]] Rethinking Large-scale Dataset Compression: Shifting Focus From Labels to Images(https://arxiv.org/abs/2502.06434)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Dataset distillation and dataset pruning are two prominent techniques for compressing datasets to improve computational and storage efficiency. Despite their overlapping objectives, these approaches are rarely compared directly. Even within each field, the evaluation protocols are inconsistent across various methods, which complicates fair comparisons and hinders reproducibility. Considering these limitations, we introduce in this paper a benchmark that equitably evaluates methodologies across both distillation and pruning literatures. Notably, our benchmark reveals that in the mainstream dataset distillation setting for large-scale datasets, which heavily rely on soft labels from pre-trained models, even randomly selected subsets can achieve surprisingly competitive performance. This finding suggests that an overemphasis on soft labels may be diverting attention from the intrinsic value of the image data, while also imposing additional burdens in terms of generation, storage, and application. To address these issues, we propose a new framework for dataset compression, termed Prune, Combine, and Augment (PCA), which focuses on leveraging image data exclusively, relies solely on hard labels for evaluation, and achieves state-of-the-art performance in this setup. By shifting the emphasis back to the images, our benchmark and PCA framework pave the way for more balanced and accessible techniques in dataset compression research. Our code is available at: this https URL</li>
</ul>

<h3>Title: FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Anna Tegon, Thorir Mar Ingolfsson, Xiaying Wang, Luca Benini, Yawei Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06438">https://arxiv.org/abs/2502.06438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06438">https://arxiv.org/pdf/2502.06438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06438]] FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model(https://arxiv.org/abs/2502.06438)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Accurate and efficient electroencephalography (EEG) analysis is essential for detecting seizures and artifacts in long-term monitoring, with applications spanning hospital diagnostics to wearable health devices. Robust EEG analytics have the potential to greatly improve patient care. However, traditional deep learning models, especially Transformer-based architectures, are hindered by their quadratic time and memory complexity, making them less suitable for resource-constrained environments. To address these challenges, we present FEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novel self-supervised framework that establishes new efficiency benchmarks for EEG analysis through bidirectional state-space modeling. Unlike Transformer-based models, which incur quadratic time and memory complexity, FEMBA scales linearly with sequence length, enabling more scalable and efficient processing of extended EEG recordings. Trained on over 21,000 hours of unlabeled EEG and fine-tuned on three downstream tasks, FEMBA achieves competitive performance in comparison with transformer models, with significantly lower computational cost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUAB and 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstrates viability for resource-constrained devices. These results pave the way for scalable, general-purpose EEG analytics in both clinical and highlight FEMBA as a promising candidate for wearable applications.</li>
</ul>

<h3>Title: Low-dimensional Functions are Efficiently Learnable under Randomly Biased Distributions</h3>
<ul>
<li><strong>Authors: </strong>Elisabetta Cornacchia, Dan Mikulincer, Elchanan Mossel</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06443">https://arxiv.org/abs/2502.06443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06443">https://arxiv.org/pdf/2502.06443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06443]] Low-dimensional Functions are Efficiently Learnable under Randomly Biased Distributions(https://arxiv.org/abs/2502.06443)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The problem of learning single index and multi index models has gained significant interest as a fundamental task in high-dimensional statistics. Many recent works have analysed gradient-based methods, particularly in the setting of isotropic data distributions, often in the context of neural network training. Such studies have uncovered precise characterisations of algorithmic sample complexity in terms of certain analytic properties of the target function, such as the leap, information, and generative exponents. These properties establish a quantitative separation between low and high complexity learning tasks. In this work, we show that high complexity cases are rare. Specifically, we prove that introducing a small random perturbation to the data distribution--via a random shift in the first moment--renders any Gaussian single index model as easy to learn as a linear function. We further extend this result to a class of multi index models, namely sparse Boolean functions, also known as Juntas.</li>
</ul>

<h3>Title: Benchmarking Vision-Language Models on Optical Character Recognition in Dynamic Video Environments</h3>
<ul>
<li><strong>Authors: </strong>Sankalp Nagaonkar, Augustya Sharma, Ashish Choithani, Ashutosh Trivedi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06445">https://arxiv.org/abs/2502.06445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06445">https://arxiv.org/pdf/2502.06445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06445]] Benchmarking Vision-Language Models on Optical Character Recognition in Dynamic Video Environments(https://arxiv.org/abs/2502.06445)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>This paper introduces an open-source benchmark for evaluating Vision-Language Models (VLMs) on Optical Character Recognition (OCR) tasks in dynamic video environments. We present a curated dataset containing 1,477 manually annotated frames spanning diverse domains, including code editors, news broadcasts, YouTube videos, and advertisements. Three state of the art VLMs - Claude-3, Gemini-1.5, and GPT-4o are benchmarked against traditional OCR systems such as EasyOCR and RapidOCR. Evaluation metrics include Word Error Rate (WER), Character Error Rate (CER), and Accuracy. Our results highlight the strengths and limitations of VLMs in video-based OCR tasks, demonstrating their potential to outperform conventional OCR models in many scenarios. However, challenges such as hallucinations, content security policies, and sensitivity to occluded or stylized text remain. The dataset and benchmarking framework are publicly available to foster further research.</li>
</ul>

<h3>Title: MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations</h3>
<ul>
<li><strong>Authors: </strong>Kaixuan Huang, Jiacheng Guo, Zihao Li, Xiang Ji, Jiawei Ge, Wenzhe Li, Yingqing Guo, Tianle Cai, Hui Yuan, Runzhe Wang, Yue Wu, Ming Yin, Shange Tang, Yangsibo Huang, Chi Jin, Xinyun Chen, Chiyuan Zhang, Mengdi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06453">https://arxiv.org/abs/2502.06453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06453">https://arxiv.org/pdf/2502.06453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06453]] MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations(https://arxiv.org/abs/2502.06453)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have demonstrated impressive performance on challenging mathematical reasoning tasks, which has triggered the discussion of whether the performance is achieved by true reasoning capability or memorization. To investigate this question, prior work has constructed mathematical benchmarks when questions undergo simple perturbations -- modifications that still preserve the underlying reasoning patterns of the solutions. However, no work has explored hard perturbations, which fundamentally change the nature of the problem so that the original solution steps do not apply. To bridge the gap, we construct MATH-P-Simple and MATH-P-Hard via simple perturbation and hard perturbation, respectively. Each consists of 279 perturbed math problems derived from level-5 (hardest) problems in the MATH dataset (Hendrycksmath et. al., 2021). We observe significant performance drops on MATH-P-Hard across various models, including o1-mini (-16.49%) and gemini-2.0-flash-thinking (-12.9%). We also raise concerns about a novel form of memorization where models blindly apply learned problem-solving skills without assessing their applicability to modified contexts. This issue is amplified when using original problems for in-context learning. We call for research efforts to address this challenge, which is critical for developing more robust and reliable reasoning models.</li>
</ul>

<h3>Title: A Survey of Theory of Mind in Large Language Models: Evaluations, Representations, and Safety Risks</h3>
<ul>
<li><strong>Authors: </strong>Hieu Minh "Jord" Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06470">https://arxiv.org/abs/2502.06470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06470">https://arxiv.org/pdf/2502.06470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06470]] A Survey of Theory of Mind in Large Language Models: Evaluations, Representations, and Safety Risks(https://arxiv.org/abs/2502.06470)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Theory of Mind (ToM), the ability to attribute mental states to others and predict their behaviour, is fundamental to social intelligence. In this paper, we survey studies evaluating behavioural and representational ToM in Large Language Models (LLMs), identify important safety risks from advanced LLM ToM capabilities, and suggest several research directions for effective evaluation and mitigation of these risks.</li>
</ul>

<h3>Title: KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment</h3>
<ul>
<li><strong>Authors: </strong>Yuxing Lu, Jinzhuo Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CE, cs.DL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06472">https://arxiv.org/abs/2502.06472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06472">https://arxiv.org/pdf/2502.06472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06472]] KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment(https://arxiv.org/abs/2502.06472)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical for modern AI systems, but manual curation struggles to scale with the rapid growth of scientific literature. This paper presents KARMA, a novel framework employing multi-agent large language models (LLMs) to automate KG enrichment through structured analysis of unstructured text. Our approach employs nine collaborative agents, spanning entity discovery, relation extraction, schema alignment, and conflict resolution that iteratively parse documents, verify extracted knowledge, and integrate it into existing graph structures while adhering to domain-specific schema. Experiments on 1,200 PubMed articles from three different domains demonstrate the effectiveness of KARMA in knowledge graph enrichment, with the identification of up to 38,230 new entities while achieving 83.1\% LLM-verified correctness and reducing conflict edges by 18.6\% through multi-layer assessments.</li>
</ul>

<h3>Title: UniMoD: Efficient Unified Multimodal Transformers with Mixture-of-Depths</h3>
<ul>
<li><strong>Authors: </strong>Weijia Mao, Zhenheng Yang, Mike Zheng Shou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06474">https://arxiv.org/abs/2502.06474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06474">https://arxiv.org/pdf/2502.06474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06474]] UniMoD: Efficient Unified Multimodal Transformers with Mixture-of-Depths(https://arxiv.org/abs/2502.06474)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Unified multimodal transformers, which handle both generation and understanding tasks within a shared parameter space, have received increasing attention in recent research. Although various unified transformers have been proposed, training these models is costly due to redundant tokens and heavy attention computation. In the past, studies on large language models have demonstrated that token pruning methods, such as Mixture of Depths (MoD), can significantly improve computational efficiency. MoD employs a router to select the most important ones for processing within a transformer layer. However, directly applying MoD-based token pruning to unified transformers will result in suboptimal performance because different tasks exhibit varying levels of token redundancy. In our work, we analyze the unified transformers by (1) examining attention weight patterns, (2) evaluating the layer importance and token redundancy, and (3) analyzing task interactions. Our findings reveal that token redundancy is primarily influenced by different tasks and layers. Building on these findings, we introduce UniMoD, a task-aware token pruning method that employs a separate router for each task to determine which tokens should be pruned. We apply our method to Show-o and Emu3, reducing training FLOPs by approximately 15% in Show-o and 40% in Emu3, while maintaining or improving performance on several benchmarks. Code will be released at this https URL.</li>
</ul>

<h3>Title: Adaptive Prompting: Ad-hoc Prompt Composition for Social Bias Detection</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Splieth√∂ver, Tim Knebler, Fabian Fumagalli, Maximilian Muschalik, Barbara Hammer, Eyke H√ºllermeier, Henning Wachsmuth</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06487">https://arxiv.org/abs/2502.06487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06487">https://arxiv.org/pdf/2502.06487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06487]] Adaptive Prompting: Ad-hoc Prompt Composition for Social Bias Detection(https://arxiv.org/abs/2502.06487)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances on instruction fine-tuning have led to the development of various prompting techniques for large language models, such as explicit reasoning steps. However, the success of techniques depends on various parameters, such as the task, language model, and context provided. Finding an effective prompt is, therefore, often a trial-and-error process. Most existing approaches to automatic prompting aim to optimize individual techniques instead of compositions of techniques and their dependence on the input. To fill this gap, we propose an adaptive prompting approach that predicts the optimal prompt composition ad-hoc for a given input. We apply our approach to social bias detection, a highly context-dependent task that requires semantic understanding. We evaluate it with three large language models on three datasets, comparing compositions to individual techniques and other baselines. The results underline the importance of finding an effective prompt composition. Our approach robustly ensures high detection performance, and is best in several settings. Moreover, first experiments on other tasks support its generalizability.</li>
</ul>

<h3>Title: GuideLLM: Exploring LLM-Guided Conversation with Applications in Autobiography Interviewing</h3>
<ul>
<li><strong>Authors: </strong>Jinhao Duan, Xinyu Zhao, Zhuoxuan Zhang, Eunhye Ko, Lily Boddy, Chenan Wang, Tianhao Li, Alexander Rasgon, Junyuan Hong, Min Kyung Lee, Chenxi Yuan, Qi Long, Ying Ding, Tianlong Chen, Kaidi Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06494">https://arxiv.org/abs/2502.06494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06494">https://arxiv.org/pdf/2502.06494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06494]] GuideLLM: Exploring LLM-Guided Conversation with Applications in Autobiography Interviewing(https://arxiv.org/abs/2502.06494)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although Large Language Models (LLMs) succeed in human-guided conversations such as instruction following and question answering, the potential of LLM-guided conversations-where LLMs direct the discourse and steer the conversation's objectives-remains under-explored. In this study, we first characterize LLM-guided conversation into three fundamental components: (i) Goal Navigation; (ii) Context Management; (iii) Empathetic Engagement, and propose GuideLLM as an installation. We then implement an interviewing environment for the evaluation of LLM-guided conversation. Specifically, various topics are involved in this environment for comprehensive interviewing evaluation, resulting in around 1.4k turns of utterances, 184k tokens, and over 200 events mentioned during the interviewing for each chatbot evaluation. We compare GuideLLM with 6 state-of-the-art LLMs such as GPT-4o and Llama-3-70b-Instruct, from the perspective of interviewing quality, and autobiography generation quality. For automatic evaluation, we derive user proxies from multiple autobiographies and employ LLM-as-a-judge to score LLM behaviors. We further conduct a human-involved experiment by employing 45 human participants to chat with GuideLLM and baselines. We then collect human feedback, preferences, and ratings regarding the qualities of conversation and autobiography. Experimental results indicate that GuideLLM significantly outperforms baseline LLMs in automatic evaluation and achieves consistent leading performances in human ratings.</li>
</ul>

<h3>Title: Learning Clustering-based Prototypes for Compositional Zero-shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Hongyu Qu, Jianan Wei, Xiangbo Shu, Wenguan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06501">https://arxiv.org/abs/2502.06501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06501">https://arxiv.org/pdf/2502.06501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06501]] Learning Clustering-based Prototypes for Compositional Zero-shot Learning(https://arxiv.org/abs/2502.06501)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning primitive (i.e., attribute and object) concepts from seen compositions is the primary challenge of Compositional Zero-Shot Learning (CZSL). Existing CZSL solutions typically rely on oversimplified data assumptions, e.g., modeling each primitive with a single centroid primitive representation, ignoring the natural diversities of the attribute (resp. object) when coupled with different objects (resp. attribute). In this work, we develop ClusPro, a robust clustering-based prototype mining framework for CZSL that defines the conceptual boundaries of primitives through a set of diversified prototypes. Specifically, ClusPro conducts within-primitive clustering on the embedding space for automatically discovering and dynamically updating prototypes. These representative prototypes are subsequently used to repaint a well-structured and independent primitive embedding space, ensuring intra-primitive separation and inter-primitive decorrelation through prototype-based contrastive learning and decorrelation learning. Moreover, ClusPro efficiently performs prototype clustering in a non-parametric fashion without the introduction of additional learnable parameters or computational budget during testing. Experiments on three benchmarks demonstrate ClusPro outperforms various top-leading CZSL solutions under both closed-world and open-world settings.</li>
</ul>

<h3>Title: An Efficient Security Model for Industrial Internet of Things (IIoT) System Based on Machine Learning Principles</h3>
<ul>
<li><strong>Authors: </strong>Sahar L. Qaddoori, Qutaiba I. Ali</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06502">https://arxiv.org/abs/2502.06502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06502">https://arxiv.org/pdf/2502.06502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06502]] An Efficient Security Model for Industrial Internet of Things (IIoT) System Based on Machine Learning Principles(https://arxiv.org/abs/2502.06502)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack</a></li>
<li><strong>Abstract: </strong>This paper presents a security paradigm for edge devices to defend against various internal and external threats. The first section of the manuscript proposes employing machine learning models to identify MQTT-based (Message Queue Telemetry Transport) attacks using the Intrusion Detection and Prevention System (IDPS) for edge nodes. Because the Machine Learning (ML) model cannot be trained directly on low-performance platforms (such as edge devices),a new methodology for updating ML models is proposed to provide a tradeoff between the model performance and the computational complexity. The proposed methodology involves training the model on a high-performance computing platform and then installing the trained model as a detection engine on low-performance platforms (such as the edge node of the edge layer) to identify new attacks. Multiple security techniques have been employed in the second half of the manuscript to verify that the exchanged trained model and the exchanged data files are valid and undiscoverable (information authenticity and privacy) and that the source (such as a fog node or edge device) is indeed what it it claimed to be (source authentication and message integrity). Finally, the proposed security paradigm is found to be effective against various internal and external threats and can be applied to a low-cost single-board computer (SBC).</li>
</ul>

<h3>Title: Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation</h3>
<ul>
<li><strong>Authors: </strong>Soobin Um, Beomsu Kim, Jong Chul Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06516">https://arxiv.org/abs/2502.06516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06516">https://arxiv.org/pdf/2502.06516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06516]] Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation(https://arxiv.org/abs/2502.06516)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Minority samples are underrepresented instances located in low-density regions of a data manifold, and are valuable in many generative AI applications, such as data augmentation, creative content generation, etc. Unfortunately, existing diffusion-based minority generators often rely on computationally expensive guidance dedicated for minority generation. To address this, here we present a simple yet powerful guidance-free approach called Boost-and-Skip for generating minority samples using diffusion models. The key advantage of our framework requires only two minimal changes to standard generative processes: (i) variance-boosted initialization and (ii) timestep skipping. We highlight that these seemingly-trivial modifications are supported by solid theoretical and empirical evidence, thereby effectively promoting emergence of underrepresented minority features. Our comprehensive experiments demonstrate that Boost-and-Skip greatly enhances the capability of generating minority samples, even rivaling guidance-based state-of-the-art approaches while requiring significantly fewer computations.</li>
</ul>

<h3>Title: Sentient: Multi-Scenario Behavioral Intent Analysis for Advanced Persistent Threat Detection</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Yan, Ning An, Wei Qiao, Weiheng Wu, Bo Jiang, Yuling Liu, Zhigang Lu, Junrong Liu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06521">https://arxiv.org/abs/2502.06521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06521">https://arxiv.org/pdf/2502.06521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06521]] Sentient: Multi-Scenario Behavioral Intent Analysis for Advanced Persistent Threat Detection(https://arxiv.org/abs/2502.06521)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) are challenging to detect due to their complexity and stealth. To mitigate such attacks, many approaches utilize provenance graphs to model entities and their dependencies, detecting the covert and persistent nature of APTs. However, existing methods face several challenges: 1) Environmental noise hinders precise detection; 2) Reliance on hard-to-obtain labeled data and prior knowledge of APTs limits their ability to detect unknown threats; 3) The difficulty in capturing long-range interaction dependencies, leading to the loss of critical context. We propose Sentient, a threat detection system based on behavioral intent analysis that detects node-level threats from audit logs. Sentient constructs a provenance graph from the audit logs and uses this graph to build multiple scenarios. By combining graph comprehension with multiple scenario comprehension, Sentient learns normal interaction behaviors. Sentient detects anomalies by identifying interactions that deviate from the established behavior patterns. We evaluated Sentient on three widely used datasets covering both real-world and simulated attacks. The results confirm that Sentient consistently delivers strong detection performance. Notably, Sentient achieves entity-level APT detection with a precision of 96% and a recall of 99%.</li>
</ul>

<h3>Title: CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>D. She, Mushui Liu, Jingxuan Pang, Jin Wang, Zhen Yang, Wanggui He, Guanghao Zhang, Yi Wang, Qihan Huang, Haobin Tang, Yunlong Yu, Siming Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06527">https://arxiv.org/abs/2502.06527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06527">https://arxiv.org/pdf/2502.06527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06527]] CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers(https://arxiv.org/abs/2502.06527)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Customized generation has achieved significant progress in image synthesis, yet personalized video generation remains challenging due to temporal inconsistencies and quality degradation. In this paper, we introduce CustomVideoX, an innovative framework leveraging the video diffusion transformer for personalized video generation from a reference image. CustomVideoX capitalizes on pre-trained video networks by exclusively training the LoRA parameters to extract reference features, ensuring both efficiency and adaptability. To facilitate seamless interaction between the reference image and video content, we propose 3D Reference Attention, which enables direct and simultaneous engagement of reference image features with all video frames across spatial and temporal dimensions. To mitigate the excessive influence of reference image features and textual guidance on generated video content during inference, we implement the Time-Aware Reference Attention Bias (TAB) strategy, dynamically modulating reference bias over different time steps. Additionally, we introduce the Entity Region-Aware Enhancement (ERAE) module, aligning highly activated regions of key entity tokens with reference feature injection by adjusting attention bias. To thoroughly evaluate personalized video generation, we establish a new benchmark, VideoBench, comprising over 50 objects and 100 prompts for extensive assessment. Experimental results show that CustomVideoX significantly outperforms existing methods in terms of video consistency and quality.</li>
</ul>

<h3>Title: Ignore the KL Penalty! Boosting Exploration on Critical Tokens to Enhance RL Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Jean Vassoyan, Nathana√´l Beau, Roman Plaud</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06533">https://arxiv.org/abs/2502.06533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06533">https://arxiv.org/pdf/2502.06533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06533]] Ignore the KL Penalty! Boosting Exploration on Critical Tokens to Enhance RL Fine-Tuning(https://arxiv.org/abs/2502.06533)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The ability to achieve long-term goals is a key challenge in the current development of large language models (LLMs). To address this, pre-trained LLMs can be fine-tuned with reinforcement learning (RL) to explore solutions that optimize a given goal. However, exploration with LLMs is difficult, as a balance has to be struck between discovering new solutions and staying close enough to the pre-trained model, so as not to degrade basic capabilities. This is typically controlled with a Kullback-Leibler (KL) penalty. In this paper, we investigate the exploration dynamics of a small language model on a simple arithmetic task. We show how varying degrees of pre-training influence exploration and demonstrate the importance of "critical tokens" which have a dramatic impact on the final outcome. Consequently, we introduce a simple modification to the KL penalty that favors exploration on critical tokens, increasing the efficiency of the RL fine-tuning stage.</li>
</ul>

<h3>Title: Unsupervised Learning for Feature Extraction and Temporal Alignment of 3D+t Point Clouds of Zebrafish Embryos</h3>
<ul>
<li><strong>Authors: </strong>Zhu Chen, Ina Laube, Johannes Stegmaier</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06543">https://arxiv.org/abs/2502.06543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06543">https://arxiv.org/pdf/2502.06543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06543]] Unsupervised Learning for Feature Extraction and Temporal Alignment of 3D+t Point Clouds of Zebrafish Embryos(https://arxiv.org/abs/2502.06543)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Zebrafish are widely used in biomedical research and developmental stages of their embryos often need to be synchronized for further analysis. We present an unsupervised approach to extract descriptive features from 3D+t point clouds of zebrafish embryos and subsequently use those features to temporally align corresponding developmental stages. An autoencoder architecture is proposed to learn a descriptive representation of the point clouds and we designed a deep regression network for their temporal alignment. We achieve a high alignment accuracy with an average mismatch of only 3.83 minutes over an experimental duration of 5.3 hours. As a fully-unsupervised approach, there is no manual labeling effort required and unlike manual analyses the method easily scales. Besides, the alignment without human annotation of the data also avoids any influence caused by subjective bias.</li>
</ul>

<h3>Title: Dimension-free Regret for Learning Asymmetric Linear Dynamical Systems</h3>
<ul>
<li><strong>Authors: </strong>Annie Marsden, Elad Hazan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06545">https://arxiv.org/abs/2502.06545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06545">https://arxiv.org/pdf/2502.06545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06545]] Dimension-free Regret for Learning Asymmetric Linear Dynamical Systems(https://arxiv.org/abs/2502.06545)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Previously, methods for learning marginally stable linear dynamical systems either required the transition matrix to be symmetric or incurred regret bounds that scale polynomially with the system's hidden dimension. In this work, we introduce a novel method that overcomes this trade-off, achieving dimension-free regret despite the presence of asymmetric matrices and marginal stability. Our method combines spectral filtering with linear predictors and employs Chebyshev polynomials in the complex plane to construct a novel spectral filtering basis. This construction guarantees sublinear regret in an online learning framework, without relying on any statistical or generative assumptions. Specifically, we prove that as long as the transition matrix has eigenvalues with complex component bounded by $1/\mathrm{poly} \log T$, then our method achieves regret $\tilde{O}(T^{9/10})$ when compared to the best linear dynamical predictor in hindsight.</li>
</ul>

<h3>Title: Efficient Scientific Full Text Classification: The Case of EICAT Impact Assessments</h3>
<ul>
<li><strong>Authors: </strong>Marc Felix Brinner, Sina Zarrie√ü</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06551">https://arxiv.org/abs/2502.06551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06551">https://arxiv.org/pdf/2502.06551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06551]] Efficient Scientific Full Text Classification: The Case of EICAT Impact Assessments(https://arxiv.org/abs/2502.06551)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>This study explores strategies for efficiently classifying scientific full texts using both small, BERT-based models and local large language models like Llama-3.1 8B. We focus on developing methods for selecting subsets of input sentences to reduce input size while simultaneously enhancing classification performance. To this end, we compile a novel dataset consisting of full-text scientific papers from the field of invasion biology, specifically addressing the impacts of invasive species. These papers are aligned with publicly available impact assessments created by researchers for the International Union for Conservation of Nature (IUCN). Through extensive experimentation, we demonstrate that various sources like human evidence annotations, LLM-generated annotations or explainability scores can be used to train sentence selection models that improve the performance of both encoder- and decoder-based language models while optimizing efficiency through the reduction in input length, leading to improved results even if compared to models like ModernBERT that are able to handle the complete text as input. Additionally, we find that repeated sampling of shorter inputs proves to be a very effective strategy that, at a slightly increased cost, can further improve classification performance.</li>
</ul>

<h3>Title: Diffusion Models for Computational Neuroimaging: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Haokai Zhao, Haowei Lou, Lina Yao, Wei Peng, Ehsan Adeli, Kilian M Pohl, Yu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06552">https://arxiv.org/abs/2502.06552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06552">https://arxiv.org/pdf/2502.06552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06552]] Diffusion Models for Computational Neuroimaging: A Survey(https://arxiv.org/abs/2502.06552)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Computational neuroimaging involves analyzing brain images or signals to provide mechanistic insights and predictive tools for human cognition and behavior. While diffusion models have shown stability and high-quality generation in natural images, there is increasing interest in adapting them to analyze brain data for various neurological tasks such as data enhancement, disease diagnosis and brain decoding. This survey provides an overview of recent efforts to integrate diffusion models into computational neuroimaging. We begin by introducing the common neuroimaging data modalities, follow with the diffusion formulations and conditioning mechanisms. Then we discuss how the variations of the denoising starting point, condition input and generation target of diffusion models are developed and enhance specific neuroimaging tasks. For a comprehensive overview of the ongoing research, we provide a publicly available repository at this https URL.</li>
</ul>

<h3>Title: Is API Access to LLMs Useful for Generating Private Synthetic Tabular Data?</h3>
<ul>
<li><strong>Authors: </strong>Marika Swanberg, Ryan McKenna, Edo Roth, Albert Cheu, Peter Kairouz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06555">https://arxiv.org/abs/2502.06555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06555">https://arxiv.org/pdf/2502.06555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06555]] Is API Access to LLMs Useful for Generating Private Synthetic Tabular Data?(https://arxiv.org/abs/2502.06555)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Differentially private (DP) synthetic data is a versatile tool for enabling the analysis of private data. Recent advancements in large language models (LLMs) have inspired a number of algorithm techniques for improving DP synthetic data generation. One family of approaches uses DP finetuning on the foundation model weights; however, the model weights for state-of-the-art models may not be public. In this work we propose two DP synthetic tabular data algorithms that only require API access to the foundation model. We adapt the Private Evolution algorithm (Lin et al., 2023; Xie et al., 2024) -- which was designed for image and text data -- to the tabular data domain. In our extension of Private Evolution, we define a query workload-based distance measure, which may be of independent interest. We propose a family of algorithms that use one-shot API access to LLMs, rather than adaptive queries to the LLM. Our findings reveal that API-access to powerful LLMs does not always improve the quality of DP synthetic data compared to established baselines that operate without such access. We provide insights into the underlying reasons and propose improvements to LLMs that could make them more effective for this application.</li>
</ul>

<h3>Title: Position: It's Time to Act on the Risk of Efficient Personalized Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Eugenia Iofinova, Andrej Jovanovic, Dan Alistarh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06560">https://arxiv.org/abs/2502.06560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06560">https://arxiv.org/pdf/2502.06560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06560]] Position: It's Time to Act on the Risk of Efficient Personalized Text Generation(https://arxiv.org/abs/2502.06560)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, generative</a></li>
<li><strong>Abstract: </strong>The recent surge in high-quality open-sourced Generative AI text models (colloquially: LLMs), as well as efficient finetuning techniques, has opened the possibility of creating high-quality personalized models, i.e., models generating text attuned to a specific individual's needs and capable of credibly imitating their writing style by leveraging that person's own data to refine an open-source model. The technology to create such models is accessible to private individuals, and training and running such models can be done cheaply on consumer-grade hardware. These advancements are a huge gain for usability and privacy. This position paper argues, however, that these advancements also introduce new safety risks by making it practically feasible for malicious actors to impersonate specific individuals at scale, for instance for the purpose of phishing emails, based on small amounts of publicly available text. We further argue that these risks are complementary to - and distinct from - the much-discussed risks of other impersonation attacks such as image, voice, or video deepfakes, and are not adequately addressed by the larger research community, or the current generation of open - and closed-source models.</li>
</ul>

<h3>Title: Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Chengwen Qi, Ren Ma, Bowen Li, He Du, Binyuan Hui, Jinwang Wu, Yuanjun Laili, Conghui He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06563">https://arxiv.org/abs/2502.06563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06563">https://arxiv.org/pdf/2502.06563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06563]] Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation(https://arxiv.org/abs/2502.06563)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>First-order logic (FOL) reasoning, which involves sequential deduction, is pivotal for intelligent systems and serves as a valuable task for evaluating reasoning capabilities, particularly in chain-of-thought (CoT) contexts. Existing benchmarks often rely on extensive human annotation or handcrafted templates, making it difficult to achieve the necessary complexity, scalability, and diversity for robust evaluation. To address these limitations, we propose a novel framework called ProverGen that synergizes the generative strengths of Large Language Models (LLMs) with the rigor and precision of symbolic provers, enabling the creation of a scalable, diverse, and high-quality FOL reasoning dataset, ProverQA. ProverQA is also distinguished by its inclusion of accessible and logically coherent intermediate reasoning steps for each problem. Our evaluation shows that state-of-the-art LLMs struggle to solve ProverQA problems, even with CoT prompting, highlighting the dataset's challenging nature. We also finetune Llama3.1-8B-Instruct on a separate training set generated by our framework. The finetuned model demonstrates consistent improvements on both in-distribution and out-of-distribution test sets, suggesting the value of our proposed data generation framework. Code available at: this https URL</li>
</ul>

<h3>Title: LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM</h3>
<ul>
<li><strong>Authors: </strong>Zhi Zhou, Kun-Yang Yu, Shi-Yu Tian, Jiang-Xin Shi, Xiao-Wen Yang, Pengxiao Song, Yi-Xuan Jin, Lan-Zhe Guo, Yu-Feng Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06572">https://arxiv.org/abs/2502.06572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06572">https://arxiv.org/pdf/2502.06572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06572]] LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM(https://arxiv.org/abs/2502.06572)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), both proprietary and open-source, have demonstrated remarkable capabilities across various natural language processing tasks. However, they face significant limitations in legal reasoning tasks. Proprietary models introduce data privacy risks and high inference costs, while open-source models underperform due to insufficient legal domain training data. To address these limitations, we study data generation for legal reasoning to improve the legal reasoning performance of open-source LLMs with the help of proprietary LLMs. This is challenging due to the lack of legal knowledge in proprietary LLMs and the difficulty in verifying the generated data. We propose KgDG, a knowledge-guided data generation framework for legal reasoning. Our framework enables leveraging legal knowledge to enhance generation diversity and introduces a refinement and verification process to ensure the quality of generated data. Moreover, we expand the generated dataset to further enhance the LLM reasoning capabilities. Using KgDG, we create a synthetic legal reasoning dataset containing 50K high-quality examples. Our trained model LawGPT outperforms existing legal-specific LLMs and achieves performance comparable to proprietary LLMs, demonstrating the effectiveness of KgDG and LawGPT. Our code and resources is publicly available at this https URL .</li>
</ul>

<h3>Title: Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Zhuang, Jingfeng Yang, Haoming Jiang, Xin Liu, Kewei Cheng, Sanket Lokegaonkar, Yifan Gao, Qing Ping, Tianyi Liu, Binxuan Huang, Zheng Li, Zhengyang Wang, Pei Chen, Ruijie Wang, Rongzhi Zhang, Nasser Zalmout, Priyanka Nigam, Bing Yin, Chao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06589">https://arxiv.org/abs/2502.06589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06589">https://arxiv.org/pdf/2502.06589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06589]] Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training(https://arxiv.org/abs/2502.06589)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous agents typically rely on complex prompting or extensive fine-tuning, which often fails to introduce new capabilities while preserving strong generalizability. We introduce Hephaestus-Forge, the first large-scale pre-training corpus designed to enhance the fundamental capabilities of LLM agents in API function calling, intrinsic reasoning and planning, and adapting to environmental feedback. Hephaestus-Forge comprises 103B agent-specific data encompassing 76,537 APIs, including both tool documentation to introduce knowledge of API functions and function calling trajectories to strengthen intrinsic reasoning. To explore effective training protocols, we investigate scaling laws to identify the optimal recipe in data mixing ratios. By continual pre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale open-source LLMs and rivals commercial LLMs on three agent benchmarks, demonstrating the effectiveness of our pre-training corpus in enhancing fundamental agentic capabilities and generalization of LLMs to new tasks or environments.</li>
</ul>

<h3>Title: A Large-scale AI-generated Image Inpainting Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Paschalis Giakoumoglou, Dimitrios Karageorgiou, Symeon Papadopoulos, Panagiotis C. Petrantonakis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06593">https://arxiv.org/abs/2502.06593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06593">https://arxiv.org/pdf/2502.06593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06593]] A Large-scale AI-generated Image Inpainting Benchmark(https://arxiv.org/abs/2502.06593)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in generative models enable highly realistic image manipulations, creating an urgent need for robust forgery detection methods. Current datasets for training and evaluating these methods are limited in scale and diversity. To address this, we propose a methodology for creating high-quality inpainting datasets and apply it to create DiQuID, comprising over 95,000 inpainted images generated from 78,000 original images sourced from MS-COCO, RAISE, and OpenImages. Our methodology consists of three components: (1) Semantically Aligned Object Replacement (SAOR) that identifies suitable objects through instance segmentation and generates contextually appropriate prompts, (2) Multiple Model Image Inpainting (MMII) that employs various state-of-the-art inpainting pipelines primarily based on diffusion models to create diverse manipulations, and (3) Uncertainty-Guided Deceptiveness Assessment (UGDA) that evaluates image realism through comparative analysis with originals. The resulting dataset surpasses existing ones in diversity, aesthetic quality, and technical quality. We provide comprehensive benchmarking results using state-of-the-art forgery detection methods, demonstrating the dataset's effectiveness in evaluating and improving detection algorithms. Through a human study with 42 participants on 1,000 images, we show that while humans struggle with images classified as deceiving by our methodology, models trained on our dataset maintain high performance on these challenging cases. Code and dataset are available at this https URL.</li>
</ul>

<h3>Title: Continual Release Moment Estimation with Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Nikita P. Kalinin, Jalaj Upadhyay, Christoph H. Lampert</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06597">https://arxiv.org/abs/2502.06597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06597">https://arxiv.org/pdf/2502.06597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06597]] Continual Release Moment Estimation with Differential Privacy(https://arxiv.org/abs/2502.06597)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We propose Joint Moment Estimation (JME), a method for continually and privately estimating both the first and second moments of data with reduced noise compared to naive approaches. JME uses the matrix mechanism and a joint sensitivity analysis to allow the second moment estimation with no additional privacy cost, thereby improving accuracy while maintaining privacy. We demonstrate JME's effectiveness in two applications: estimating the running mean and covariance matrix for Gaussian density estimation, and model training with DP-Adam on CIFAR-10.</li>
</ul>

<h3>Title: Amortized In-Context Bayesian Posterior Estimation</h3>
<ul>
<li><strong>Authors: </strong>Sarthak Mittal, Niels Leif Bracher, Guillaume Lajoie, Priyank Jaini, Marcus Brubaker</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06601">https://arxiv.org/abs/2502.06601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06601">https://arxiv.org/pdf/2502.06601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06601]] Amortized In-Context Bayesian Posterior Estimation(https://arxiv.org/abs/2502.06601)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Bayesian inference provides a natural way of incorporating prior beliefs and assigning a probability measure to the space of hypotheses. Current solutions rely on iterative routines like Markov Chain Monte Carlo (MCMC) sampling and Variational Inference (VI), which need to be re-run whenever new observations are available. Amortization, through conditional estimation, is a viable strategy to alleviate such difficulties and has been the guiding principle behind simulation-based inference, neural processes and in-context methods using pre-trained models. In this work, we conduct a thorough comparative analysis of amortized in-context Bayesian posterior estimation methods from the lens of different optimization objectives and architectural choices. Such methods train an amortized estimator to perform posterior parameter inference by conditioning on a set of data examples passed as context to a sequence model such as a transformer. In contrast to language models, we leverage permutation invariant architectures as the true posterior is invariant to the ordering of context examples. Our empirical study includes generalization to out-of-distribution tasks, cases where the assumed underlying model is misspecified, and transfer from simulated to real problems. Subsequently, it highlights the superiority of the reverse KL estimator for predictive problems, especially when combined with the transformer architecture and normalizing flows.</li>
</ul>

<h3>Title: MaterialFusion: High-Quality, Zero-Shot, and Controllable Material Transfer with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Kamil Garifullin, Maxim Nikolaev, Andrey Kuznetsov, Aibek Alanov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06606">https://arxiv.org/abs/2502.06606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06606">https://arxiv.org/pdf/2502.06606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06606]] MaterialFusion: High-Quality, Zero-Shot, and Controllable Material Transfer with Diffusion Models(https://arxiv.org/abs/2502.06606)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Manipulating the material appearance of objects in images is critical for applications like augmented reality, virtual prototyping, and digital content creation. We present MaterialFusion, a novel framework for high-quality material transfer that allows users to adjust the degree of material application, achieving an optimal balance between new material properties and the object's original features. MaterialFusion seamlessly integrates the modified object into the scene by maintaining background consistency and mitigating boundary artifacts. To thoroughly evaluate our approach, we have compiled a dataset of real-world material transfer examples and conducted complex comparative analyses. Through comprehensive quantitative evaluations and user studies, we demonstrate that MaterialFusion significantly outperforms existing methods in terms of quality, user control, and background preservation. Code is available at this https URL.</li>
</ul>

<h3>Title: TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models</h3>
<ul>
<li><strong>Authors: </strong>Yangguang Li, Zi-Xin Zou, Zexiang Liu, Dehu Wang, Yuan Liang, Zhipeng Yu, Xingchao Liu, Yuan-Chen Guo, Ding Liang, Wanli Ouyang, Yan-Pei Cao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06608">https://arxiv.org/abs/2502.06608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06608">https://arxiv.org/pdf/2502.06608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06608]] TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models(https://arxiv.org/abs/2502.06608)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in diffusion techniques have propelled image and video generation to unprece- dented levels of quality, significantly accelerating the deployment and application of generative AI. However, 3D shape generation technology has so far lagged behind, constrained by limitations in 3D data scale, complexity of 3D data process- ing, and insufficient exploration of advanced tech- niques in the 3D domain. Current approaches to 3D shape generation face substantial challenges in terms of output quality, generalization capa- bility, and alignment with input conditions. We present TripoSG, a new streamlined shape diffu- sion paradigm capable of generating high-fidelity 3D meshes with precise correspondence to input images. Specifically, we propose: 1) A large-scale rectified flow transformer for 3D shape generation, achieving state-of-the-art fidelity through training on extensive, high-quality data. 2) A hybrid supervised training strategy combining SDF, normal, and eikonal losses for 3D VAE, achieving high- quality 3D reconstruction performance. 3) A data processing pipeline to generate 2 million high- quality 3D samples, highlighting the crucial rules for data quality and quantity in training 3D gen- erative models. Through comprehensive experi- ments, we have validated the effectiveness of each component in our new framework. The seamless integration of these parts has enabled TripoSG to achieve state-of-the-art performance in 3D shape generation. The resulting 3D shapes exhibit en- hanced detail due to high-resolution capabilities and demonstrate exceptional fidelity to input im- ages. Moreover, TripoSG demonstrates improved versatility in generating 3D models from diverse image styles and contents, showcasing strong gen- eralization capabilities. To foster progress and innovation in the field of 3D generation, we will make our model publicly available.</li>
</ul>

<h3>Title: Multi-Scale Feature Fusion with Image-Driven Spatial Integration for Left Atrium Segmentation from Cardiac MRI Images</h3>
<ul>
<li><strong>Authors: </strong>Bipasha Kundu, Zixin Yang, Richard Simon, Cristian Linte</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06615">https://arxiv.org/abs/2502.06615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06615">https://arxiv.org/pdf/2502.06615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06615]] Multi-Scale Feature Fusion with Image-Driven Spatial Integration for Left Atrium Segmentation from Cardiac MRI Images(https://arxiv.org/abs/2502.06615)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation of the left atrium (LA) from late gadolinium-enhanced magnetic resonance imaging plays a vital role in visualizing diseased atrial structures, enabling the diagnosis and management of cardiovascular diseases. It is particularly essential for planning treatment with ablation therapy, a key intervention for atrial fibrillation (AF). However, manual segmentation is time-intensive and prone to inter-observer variability, underscoring the need for automated solutions. Class-agnostic foundation models like DINOv2 have demonstrated remarkable feature extraction capabilities in vision tasks. However, their lack of domain specificity and task-specific adaptation can reduce spatial resolution during feature extraction, impacting the capture of fine anatomical detail in medical imaging. To address this limitation, we propose a segmentation framework that integrates DINOv2 as an encoder with a UNet-style decoder, incorporating multi-scale feature fusion and input image integration to enhance segmentation accuracy. The learnable weighting mechanism dynamically prioritizes hierarchical features from different encoder blocks of the foundation model, optimizing feature selection for task relevance. Additionally, the input image is reintroduced during the decoding stage to preserve high-resolution spatial details, addressing limitations of downsampling in the encoder. We validate our approach on the LAScarQS 2022 dataset and demonstrate improved performance with a 92.3% Dice and 84.1% IoU score for giant architecture compared to the nnUNet baseline model. These findings emphasize the efficacy of our approach in advancing the field of automated left atrium segmentation from cardiac MRI.</li>
</ul>

<h3>Title: Scaling Multi-Document Event Summarization: Evaluating Compression vs. Full-Text Approaches</h3>
<ul>
<li><strong>Authors: </strong>Adithya Pratapa, Teruko Mitamura</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06617">https://arxiv.org/abs/2502.06617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06617">https://arxiv.org/pdf/2502.06617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06617]] Scaling Multi-Document Event Summarization: Evaluating Compression vs. Full-Text Approaches(https://arxiv.org/abs/2502.06617)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Automatically summarizing large text collections is a valuable tool for document research, with applications in journalism, academic research, legal work, and many other fields. In this work, we contrast two classes of systems for large-scale multi-document summarization (MDS): compression and full-text. Compression-based methods use a multi-stage pipeline and often lead to lossy summaries. Full-text methods promise a lossless summary by relying on recent advances in long-context reasoning. To understand their utility on large-scale MDS, we evaluated them on three datasets, each containing approximately one hundred documents per summary. Our experiments cover a diverse set of long-context transformers (Llama-3.1, Command-R, Jamba-1.5-Mini) and compression methods (retrieval-augmented, hierarchical, incremental). Overall, we find that full-text and retrieval methods perform the best in most settings. With further analysis into the salient information retention patterns, we show that compression-based methods show strong promise at intermediate stages, even outperforming full-context. However, they suffer information loss due to their multi-stage pipeline and lack of global context. Our results highlight the need to develop hybrid approaches that combine compression and full-text approaches for optimal performance on large-scale multi-document summarization.</li>
</ul>

<h3>Title: Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Jiachen Li, Xiaojin Gong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06619">https://arxiv.org/abs/2502.06619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06619">https://arxiv.org/pdf/2502.06619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06619]] Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification(https://arxiv.org/abs/2502.06619)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Domain-generalizable re-identification (DG Re-ID) aims to train a model on one or more source domains and evaluate its performance on unseen target domains, a task that has attracted growing attention due to its practical relevance. While numerous methods have been proposed, most rely on discriminative or contrastive learning frameworks to learn generalizable feature representations. However, these approaches often fail to mitigate shortcut learning, leading to suboptimal performance. In this work, we propose a novel method called diffusion model-assisted representation learning with a correlation-aware conditioning scheme (DCAC) to enhance DG Re-ID. Our method integrates a discriminative and contrastive Re-ID model with a pre-trained diffusion model through a correlation-aware conditioning scheme. By incorporating ID classification probabilities generated from the Re-ID model with a set of learnable ID-wise prompts, the conditioning scheme injects dark knowledge that captures ID correlations to guide the diffusion process. Simultaneously, feedback from the diffusion model is back-propagated through the conditioning scheme to the Re-ID model, effectively improving the generalization capability of Re-ID features. Extensive experiments on both single-source and multi-source DG Re-ID tasks demonstrate that our method achieves state-of-the-art performance. Comprehensive ablation studies further validate the effectiveness of the proposed approach, providing insights into its robustness. Codes will be available at this https URL.</li>
</ul>

<h3>Title: Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language</h3>
<ul>
<li><strong>Authors: </strong>Zhiqiang Zhong, Simon Sataa-Yu Larsen, Haoyu Guo, Tao Tang, Kuangyu Zhou, Davide Mottin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06634">https://arxiv.org/abs/2502.06634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06634">https://arxiv.org/pdf/2502.06634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06634]] Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language(https://arxiv.org/abs/2502.06634)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in AI for biological research focus on integrating molecular data with natural language to accelerate drug discovery. However, the scarcity of high-quality annotations limits progress in this area. This paper introduces LA$^3$, a Language-based Automatic Annotation Augmentation framework that leverages large language models to augment existing datasets, thereby improving AI training. We demonstrate the effectiveness of LA$^3$ by creating an enhanced dataset, LaChEBI-20, where we systematically rewrite the annotations of molecules from an established dataset. These rewritten annotations preserve essential molecular information while providing more varied sentence structures and vocabulary. Using LaChEBI-20, we train LaMolT5 based on a benchmark architecture to learn the mapping between molecular representations and augmented annotations. Experimental results on text-based *de novo* molecule generation and molecule captioning demonstrate that LaMolT5 outperforms state-of-the-art models. Notably, incorporating LA$^3$ leads to improvements of up to 301% over the benchmark architecture. Furthermore, we validate the effectiveness of LA$^3$ notable applications in *image*, *text* and *graph* tasks, affirming its versatility and utility.</li>
</ul>

<h3>Title: MoETuner: Optimized Mixture of Expert Serving with Balanced Expert Placement and Token Routing</h3>
<ul>
<li><strong>Authors: </strong>Seokjin Go, Divya Mahajan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06643">https://arxiv.org/abs/2502.06643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06643">https://arxiv.org/pdf/2502.06643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06643]] MoETuner: Optimized Mixture of Expert Serving with Balanced Expert Placement and Token Routing(https://arxiv.org/abs/2502.06643)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) model architecture has emerged as a promising solution for scaling transformer models efficiently, offering sparse activation that reduces computational costs while increasing model capacity. However, as MoE models scale, they need to be distributed across GPU devices, thus face critical performance bottlenecks due to their large memory footprint. Expert parallelism distributes experts across GPUs, however, faces key challenges including an unbalanced token routing and expert activation, resulting in communication tail latency and processing inefficiencies. While existing solutions address some of these issues, they fail to resolve the dual challenges of load imbalance and communication skew. The imbalance in token processing load across experts causes uneven processing times on different GPUs, while communication skew between GPUs leads to unbalanced inter-GPU data transfers. These factors degrade the performance of MoE models by increasing tail latency and reducing overall throughput. To address these limitations, we propose an Integer Linear Programming (ILP) formulation to optimize expert placement by jointly considering token load, communication, and computation costs. We exploit the property that there is a token routing dependency across layers, where tokens routed to a specific expert in one layer are likely to be routed to a limited set of experts in the subsequent layer. Our solution, MoETuner, offers an optimal expert-to-GPU assignment that minimizes inter-GPU token routing costs and balances token processing across devices, thereby reducing tail latency and end-to-end execution time. Experimental results demonstrate 9.3% and 17.5% of end-to-end speedups for single-node and multi-node inference respectively, showcasing the potential of our ILP-based optimization for offering expert parallel solutions for next-generation MoEs.</li>
</ul>

<h3>Title: Prototype Contrastive Consistency Learning for Semi-Supervised Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shihuan He, Zhihui Lai, Ruxin Wang, Heng Kong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06650">https://arxiv.org/abs/2502.06650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06650">https://arxiv.org/pdf/2502.06650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06650]] Prototype Contrastive Consistency Learning for Semi-Supervised Medical Image Segmentation(https://arxiv.org/abs/2502.06650)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation is a crucial task in medical image analysis, but it can be very challenging especially when there are less labeled data but with large unlabeled data. Contrastive learning has proven to be effective for medical image segmentation in semi-supervised learning by constructing contrastive samples from partial pixels. However, although previous contrastive learning methods can mine semantic information from partial pixels within images, they ignore the whole context information of unlabeled images, which is very important to precise segmentation. In order to solve this problem, we propose a novel prototype contrastive learning method called Prototype Contrastive Consistency Segmentation (PCCS) for semi-supervised medical image segmentation. The core idea is to enforce the prototypes of the same semantic class to be closer and push the prototypes in different semantic classes far away from each other. Specifically, we construct a signed distance map and an uncertainty map from unlabeled images. The signed distance map is used to construct prototypes for contrastive learning, and then we estimate the prototype uncertainty from the uncertainty map as trade-off among prototypes. In order to obtain better prototypes, based on the student-teacher architecture, a new mechanism named prototype updating prototype is designed to assist in updating the prototypes for contrastive learning. In addition, we propose an uncertainty-consistency loss to mine more reliable information from unlabeled data. Extensive experiments on medical image segmentation demonstrate that PCCS achieves better segmentation performance than the state-of-the-art methods. The code is available at this https URL.</li>
</ul>

<h3>Title: Differentially Private Empirical Cumulative Distribution Functions</h3>
<ul>
<li><strong>Authors: </strong>Antoine Barczewski, Amal Mawass, Jan Ramon</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06651">https://arxiv.org/abs/2502.06651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06651">https://arxiv.org/pdf/2502.06651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06651]] Differentially Private Empirical Cumulative Distribution Functions(https://arxiv.org/abs/2502.06651)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>In order to both learn and protect sensitive training data, there has been a growing interest in privacy preserving machine learning methods. Differential privacy has emerged as an important measure of privacy. We are interested in the federated setting where a group of parties each have one or more training instances and want to learn collaboratively without revealing their data. In this paper, we propose strategies to compute differentially private empirical distribution functions. While revealing complete functions is more expensive from the point of view of privacy budget, it may also provide richer and more valuable information to the learner. We prove privacy guarantees and discuss the computational cost, both for a generic strategy fitting any security model and a special-purpose strategy based on secret sharing. We survey a number of applications and present experiments.</li>
</ul>

<h3>Title: Transparent NLP: Using RAG and LLM Alignment for Privacy Q&A</h3>
<ul>
<li><strong>Authors: </strong>Anna Leschanowsky, Zahra Kolagar, Erion √áano, Ivan Habernal, Dara Hallinan, Emanu√´l A. P. Habets, Birgit Popp</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06652">https://arxiv.org/abs/2502.06652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06652">https://arxiv.org/pdf/2502.06652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06652]] Transparent NLP: Using RAG and LLM Alignment for Privacy Q&A(https://arxiv.org/abs/2502.06652)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>The transparency principle of the General Data Protection Regulation (GDPR) requires data processing information to be clear, precise, and accessible. While language models show promise in this context, their probabilistic nature complicates truthfulness and comprehensibility. This paper examines state-of-the-art Retrieval Augmented Generation (RAG) systems enhanced with alignment techniques to fulfill GDPR obligations. We evaluate RAG systems incorporating an alignment module like Rewindable Auto-regressive Inference (RAIN) and our proposed multidimensional extension, MultiRAIN, using a Privacy Q&A dataset. Responses are optimized for preciseness and comprehensibility and are assessed through 21 metrics, including deterministic and large language model-based evaluations. Our results show that RAG systems with an alignment module outperform baseline RAG systems on most metrics, though none fully match human answers. Principal component analysis of the results reveals complex interactions between metrics, highlighting the need to refine metrics. This study provides a foundation for integrating advanced natural language processing systems into legal compliance frameworks.</li>
</ul>

<h3>Title: In-Context Learning (and Unlearning) of Length Biases</h3>
<ul>
<li><strong>Authors: </strong>Stephanie Schoch, Yangfeng Ji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06653">https://arxiv.org/abs/2502.06653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06653">https://arxiv.org/pdf/2502.06653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06653]] In-Context Learning (and Unlearning) of Length Biases(https://arxiv.org/abs/2502.06653)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have demonstrated strong capabilities to learn in-context, where exemplar input-output pairings are appended to the prompt for demonstration. However, existing work has demonstrated the ability of models to learn lexical and label biases in-context, which negatively impacts both performance and robustness of models. The impact of other statistical data biases remains under-explored, which this work aims to address. We specifically investigate the impact of length biases on in-context learning. We demonstrate that models do learn length biases in the context window for their predictions, and further empirically analyze the factors that modulate the level of bias exhibited by the model. In addition, we show that learning length information in-context can be used to counter the length bias that has been encoded in models (e.g., via fine-tuning). This reveals the power of in-context learning in debiasing model prediction behaviors without the need for costly parameter updates.</li>
</ul>

<h3>Title: Onion Routing Key Distribution for QKDN</h3>
<ul>
<li><strong>Authors: </strong>Pedro Otero-Garc√≠a, Javier Blanco-Romero, Ana Fern√°ndez-Vilas, Daniel Sobral-Blanco, Manuel Fern√°ndez-Veiga, Florina Almenares-Mendoza</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06657">https://arxiv.org/abs/2502.06657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06657">https://arxiv.org/pdf/2502.06657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06657]] Onion Routing Key Distribution for QKDN(https://arxiv.org/abs/2502.06657)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>The advance of quantum computing poses a significant threat to classical cryptography, compromising the security of current encryption schemes such as RSA and ECC. In response to this challenge, two main approaches have emerged: quantum cryptography and post-quantum cryptography (PQC). However, both have implementation and security limitations. In this paper, we propose a secure key distribution protocol for Quantum Key Distribution Networks (QKDN), which incorporates encapsulation techniques in the key-relay model for QKDN inspired by onion routing and combined with PQC to guarantee confidentiality, integrity, authenticity and anonymity in communication. The proposed protocol optimizes security by using post-quantum public key encryption to protect the shared secrets from intermediate nodes in the QKDN, thereby reducing the risk of attacks by malicious intermediaries. Finally, relevant use cases are presented, such as critical infrastructure networks, interconnection of data centers and digital money, demonstrating the applicability of the proposal in critical high-security environments.</li>
</ul>

<h3>Title: EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xingrun Xing, Zheng Liu, Shitao Xiao, Boyan Gao, Yiming Liang, Wanpeng Zhang, Haokun Lin, Guoqi Li, Jiajun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06663">https://arxiv.org/abs/2502.06663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06663">https://arxiv.org/pdf/2502.06663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06663]] EfficientLLM: Scalable Pruning-Aware Pretraining for Architecture-Agnostic Edge Language Models(https://arxiv.org/abs/2502.06663)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Modern large language models (LLMs) driven by scaling laws, achieve intelligence emergency in large model sizes. Recently, the increasing concerns about cloud costs, latency, and privacy make it an urgent requirement to develop compact edge language models. Distinguished from direct pretraining that bounded by the scaling law, this work proposes the pruning-aware pretraining, focusing on retaining performance of much larger optimized models. It features following characteristics: 1) Data-scalable: we introduce minimal parameter groups in LLM and continuously optimize structural pruning, extending post-training pruning methods like LLM-Pruner and SparseGPT into the pretraining phase. 2) Architecture-agnostic: the LLM architecture is auto-designed using saliency-driven pruning, which is the first time to exceed SoTA human-designed LLMs in modern pretraining. We reveal that it achieves top-quality edge language models, termed EfficientLLM, by scaling up LLM compression and extending its boundary. EfficientLLM significantly outperforms SoTA baselines with $100M \sim 1B$ parameters, such as MobileLLM, SmolLM, Qwen2.5-0.5B, OLMo-1B, Llama3.2-1B in common sense benchmarks. As the first attempt, EfficientLLM bridges the performance gap between traditional LLM compression and direct pretraining methods, and we will fully open source at this https URL.</li>
</ul>

<h3>Title: Automatic Evaluation of Healthcare LLMs Beyond Question-Answering</h3>
<ul>
<li><strong>Authors: </strong>Anna Arias-Duart, Pablo Agustin Martin-Torres, Daniel Hinjos, Pablo Bernabeu-Perez, Lucia Urcelay Ganzabal, Marta Gonzalez Mallo, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Sergio Alvarez-Napagao, Dario Garcia-Gasulla</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06666">https://arxiv.org/abs/2502.06666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06666">https://arxiv.org/pdf/2502.06666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06666]] Automatic Evaluation of Healthcare LLMs Beyond Question-Answering(https://arxiv.org/abs/2502.06666)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current Large Language Models (LLMs) benchmarks are often based on open-ended or close-ended QA evaluations, avoiding the requirement of human labor. Close-ended measurements evaluate the factuality of responses but lack expressiveness. Open-ended capture the model's capacity to produce discourse responses but are harder to assess for correctness. These two approaches are commonly used, either independently or together, though their relationship remains poorly understood. This work is focused on the healthcare domain, where both factuality and discourse matter greatly. It introduces a comprehensive, multi-axis suite for healthcare LLM evaluation, exploring correlations between open and close benchmarks and metrics. Findings include blind spots and overlaps in current methodologies. As an updated sanity check, we release a new medical benchmark--CareQA--, with both open and closed variants. Finally, we propose a novel metric for open-ended evaluations --Relaxed Perplexity-- to mitigate the identified limitations.</li>
</ul>

<h3>Title: Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations</h3>
<ul>
<li><strong>Authors: </strong>Rui Chen, Tailai Peng, Xinran Xie, Dekun Lin, Zhe Cui, Zheng Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06669">https://arxiv.org/abs/2502.06669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06669">https://arxiv.org/pdf/2502.06669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06669]] Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations(https://arxiv.org/abs/2502.06669)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Significant improvements have been observed in the zero-shot capabilities of the Large Language Models (LLMs). Due to their high sensitivity to input, research has increasingly focused on enhancing LLMs' performance via direct and simple prompt engineering rather than intricate domain adaptation. Studies suggest that LLMs exhibit emotional intelligence, and both positive and negative emotions can potentially enhance task performances. However, prior interaction prompts have predominantly concentrated on a single stimulus type, neglecting to compare different stimulus effects, examine the influence of varying task difficulties, or explore underlying mechanisms. This paper, inspired by the positive correlation between self-efficacy and task performance within the social cognitive theory, introduces Verbal Efficacy Stimulations (VES). Our VES comprises three types of verbal prompts: encouraging, provocative, and critical, addressing six aspects such as helpfulness and competence. And we further categorize task difficulty, aiming to extensively investigate how distinct VES influence the self-efficacy and task achievements of language models at varied levels of difficulty. The experimental results show that the three types of VES improve the performance of LLMs on most tasks, and the most effective VES varies for different models. In extensive experiments, we have obtained some findings consistent with psychological theories, providing novel insights for future research.</li>
</ul>

<h3>Title: CHIRLA: Comprehensive High-resolution Identification and Re-identification for Large-scale Analysis</h3>
<ul>
<li><strong>Authors: </strong>Bessie Dominguez-Dager, Felix Escalona, Francisco Gomez-Donoso, Miguel Cazorla</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06681">https://arxiv.org/abs/2502.06681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06681">https://arxiv.org/pdf/2502.06681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06681]] CHIRLA: Comprehensive High-resolution Identification and Re-identification for Large-scale Analysis(https://arxiv.org/abs/2502.06681)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Person re-identification (Re-ID) is a key challenge in computer vision, requiring the matching of individuals across different cameras, locations, and time periods. While most research focuses on short-term scenarios with minimal appearance changes, real-world applications demand robust Re-ID systems capable of handling long-term scenarios, where persons' appearances can change significantly due to variations in clothing and physical characteristics. In this paper, we present CHIRLA, Comprehensive High-resolution Identification and Re-identification for Large-scale Analysis, a novel dataset specifically designed for long-term person Re-ID. CHIRLA consists of recordings from strategically placed cameras over a seven-month period, capturing significant variations in both temporal and appearance attributes, including controlled changes in participants' clothing and physical features. The dataset includes 22 individuals, four connected indoor environments, and seven cameras. We collected more than five hours of video that we semi-automatically labeled to generate around one million bounding boxes with identity annotations. By introducing this comprehensive benchmark, we aim to facilitate the development and evaluation of Re-ID algorithms that can reliably perform in challenging, long-term real-world scenarios.</li>
</ul>

<h3>Title: Transfer Your Perspective: Controllable 3D Generation from Any Viewpoint in a Driving Scene</h3>
<ul>
<li><strong>Authors: </strong>Tai-Yu Pan, Sooyoung Jeon, Mengdi Fan, Jinsu Yoo, Zhenyang Feng, Mark Campbell, Kilian Q. Weinberger, Bharath Hariharan, Wei-Lun Chao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06682">https://arxiv.org/abs/2502.06682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06682">https://arxiv.org/pdf/2502.06682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06682]] Transfer Your Perspective: Controllable 3D Generation from Any Viewpoint in a Driving Scene(https://arxiv.org/abs/2502.06682)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Self-driving cars relying solely on ego-centric perception face limitations in sensing, often failing to detect occluded, faraway objects. Collaborative autonomous driving (CAV) seems like a promising direction, but collecting data for development is non-trivial. It requires placing multiple sensor-equipped agents in a real-world driving scene, simultaneously! As such, existing datasets are limited in locations and agents. We introduce a novel surrogate to the rescue, which is to generate realistic perception from different viewpoints in a driving scene, conditioned on a real-world sample - the ego-car's sensory data. This surrogate has huge potential: it could potentially turn any ego-car dataset into a collaborative driving one to scale up the development of CAV. We present the very first solution, using a combination of simulated collaborative data and real ego-car data. Our method, Transfer Your Perspective (TYP), learns a conditioned diffusion model whose output samples are not only realistic but also consistent in both semantics and layouts with the given ego-car data. Empirical results demonstrate TYP's effectiveness in aiding in a CAV setting. In particular, TYP enables us to (pre-)train collaborative perception algorithms like early and late fusion with little or no real-world collaborative data, greatly facilitating downstream CAV applications.</li>
</ul>

<h3>Title: No Trick, No Treat: Pursuits and Challenges Towards Simulation-free Training of Neural Samplers</h3>
<ul>
<li><strong>Authors: </strong>Jiajun He, Yuanqi Du, Francisco Vargas, Dinghuai Zhang, Shreyas Padhy, RuiKang OuYang, Carla Gomes, Jos√© Miguel Hern√°ndez-Lobato</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06685">https://arxiv.org/abs/2502.06685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06685">https://arxiv.org/pdf/2502.06685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06685]] No Trick, No Treat: Pursuits and Challenges Towards Simulation-free Training of Neural Samplers(https://arxiv.org/abs/2502.06685)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We consider the sampling problem, where the aim is to draw samples from a distribution whose density is known only up to a normalization constant. Recent breakthroughs in generative modeling to approximate a high-dimensional data distribution have sparked significant interest in developing neural network-based methods for this challenging problem. However, neural samplers typically incur heavy computational overhead due to simulating trajectories during training. This motivates the pursuit of simulation-free training procedures of neural samplers. In this work, we propose an elegant modification to previous methods, which allows simulation-free training with the help of a time-dependent normalizing flow. However, it ultimately suffers from severe mode collapse. On closer inspection, we find that nearly all successful neural samplers rely on Langevin preconditioning to avoid mode collapsing. We systematically analyze several popular methods with various objective functions and demonstrate that, in the absence of Langevin preconditioning, most of them fail to adequately cover even a simple target. Finally, we draw attention to a strong baseline by combining the state-of-the-art MCMC method, Parallel Tempering (PT), with an additional generative model to shed light on future explorations of neural samplers.</li>
</ul>

<h3>Title: Network Intrusion Datasets: A Survey, Limitations, and Recommendations</h3>
<ul>
<li><strong>Authors: </strong>Patrik Goldschmidt, Daniela Chud√°</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06688">https://arxiv.org/abs/2502.06688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06688">https://arxiv.org/pdf/2502.06688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06688]] Network Intrusion Datasets: A Survey, Limitations, and Recommendations(https://arxiv.org/abs/2502.06688)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, robust</a></li>
<li><strong>Abstract: </strong>Data-driven cyberthreat detection has become a crucial defense technique in modern cybersecurity. Network defense, supported by Network Intrusion Detection Systems (NIDSs), has also increasingly adopted data-driven approaches, leading to greater reliance on data. Despite its importance, data scarcity has long been recognized as a major obstacle in NIDS research. In response, the community has published many new datasets recently. However, many of them remain largely unknown and unanalyzed, leaving researchers uncertain about their suitability for specific use cases. In this paper, we aim to address this knowledge gap by performing a systematic literature review (SLR) of 89 public datasets for NIDS research. Each dataset is comparatively analyzed across 13 key properties, and its potential applications are outlined. Beyond the review, we also discuss domain-specific challenges and common data limitations to facilitate a critical view on data quality. To aid in data selection, we conduct a dataset popularity analysis in contemporary state-of-the-art NIDS research. Furthermore, the paper presents best practices for dataset selection, generation, and usage. By providing a comprehensive overview of the domain and its data, this work aims to guide future research toward improving data quality and the robustness of NIDS solutions.</li>
</ul>

<h3>Title: FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups</h3>
<ul>
<li><strong>Authors: </strong>Geraldin Nanfack, Eugene Belilovsky</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06695">https://arxiv.org/abs/2502.06695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06695">https://arxiv.org/pdf/2502.06695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06695]] FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups(https://arxiv.org/abs/2502.06695)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Deep learning models frequently exploit spurious features in training data to achieve low training error, often resulting in poor generalization when faced with shifted testing distributions. To address this issue, various methods from imbalanced learning, representation learning, and classifier recalibration have been proposed to enhance the robustness of deep neural networks against spurious correlations. In this paper, we observe that models trained with empirical risk minimization tend to generalize well for examples from the majority groups while memorizing instances from minority groups. Building on recent findings that show memorization can be localized to a limited number of neurons, we apply example-tied dropout as a method we term FairDropout, aimed at redirecting this memorization to specific neurons that we subsequently drop out during inference. We empirically evaluate FairDropout using the subpopulation benchmark suite encompassing vision, language, and healthcare tasks, demonstrating that it significantly reduces reliance on spurious correlations, and outperforms state-of-the-art methods.</li>
</ul>

<h3>Title: Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Runze Liu, Junqi Gao, Jian Zhao, Kaiyan Zhang, Xiu Li, Biqing Qi, Wanli Ouyang, Bowen Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06703">https://arxiv.org/abs/2502.06703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06703">https://arxiv.org/pdf/2502.06703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06703]] Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling(https://arxiv.org/abs/2502.06703)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Test-Time Scaling (TTS) is an important method for improving the performance of Large Language Models (LLMs) by using additional computation during the inference phase. However, current studies do not systematically analyze how policy models, Process Reward Models (PRMs), and problem difficulty influence TTS. This lack of analysis limits the understanding and practical use of TTS methods. In this paper, we focus on two core questions: (1) What is the optimal approach to scale test-time computation across different policy models, PRMs, and problem difficulty levels? (2) To what extent can extended computation improve the performance of LLMs on complex tasks, and can smaller language models outperform larger ones through this approach? Through comprehensive experiments on MATH-500 and challenging AIME24 tasks, we have the following observations: (1) The compute-optimal TTS strategy is highly dependent on the choice of policy model, PRM, and problem difficulty. (2) With our compute-optimal TTS strategy, extremely small policy models can outperform larger models. For example, a 1B LLM can exceed a 405B LLM on MATH-500. Moreover, on both MATH-500 and AIME24, a 0.5B LLM outperforms GPT-4o, a 3B LLM surpasses a 405B LLM, and a 7B LLM beats o1 and DeepSeek-R1, while with higher inference efficiency. These findings show the significance of adapting TTS strategies to the specific characteristics of each task and model and indicate that TTS is a promising approach for enhancing the reasoning abilities of LLMs.</li>
</ul>

<h3>Title: A Case Study in Gamification for a Cybersecurity Education Program: A Game for Cryptography</h3>
<ul>
<li><strong>Authors: </strong>Dylan Huitema, Albert Wong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06706">https://arxiv.org/abs/2502.06706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06706">https://arxiv.org/pdf/2502.06706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06706]] A Case Study in Gamification for a Cybersecurity Education Program: A Game for Cryptography(https://arxiv.org/abs/2502.06706)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Advances in technology, a growing pool of sensitive data, and heightened global tensions has increased the demand for skilled cybersecurity professionals. Despite the recent increase in attention given to cybersecurity education, traditional approaches have continue in failing to keep pace with the rapidly evolving cyber threat landscape. Challenges such as a shortage of qualified educators and resource-intensive practical training exacerbate these issues. Gamification offers an innovative approach to provide practical hands-on experiences, and equip educators with up-to-date and accessible teaching tools that are targeted to industry-specific concepts. The paper begins with a review of the literature on existing challenges in cybersecurity education and gamification methods already employed in the field, before presenting a real-world case study of a gamified cryptography teaching tool. The paper discusses the design, development process, and intended use cases for this tool. This research highlights and provides an example of how integrating gamification into curricula can address key educational gaps, ensuring a more robust and effective pipeline of cybersecurity talent for the future.</li>
</ul>

<h3>Title: TEMSET-24K: Densely Annotated Dataset for Indexing Multipart Endoscopic Videos using Surgical Timeline Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Bilal, Mahmood Alam, Deepa Bapu, Stephan Korsgen, Neeraj Lal, Simon Bach, Amir M Hajivanand, Muhammed Ali, Kamran Soomro, Iqbal Qasim, Pawe≈Ç Capik, Aslam Khan, Zaheer Khan, Hunaid Vohra, Massimo Caputo, Andrew Beggs, Adnan Qayyum, Junaid Qadir, Shazad Ashraf</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06708">https://arxiv.org/abs/2502.06708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06708">https://arxiv.org/pdf/2502.06708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06708]] TEMSET-24K: Densely Annotated Dataset for Indexing Multipart Endoscopic Videos using Surgical Timeline Segmentation(https://arxiv.org/abs/2502.06708)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Indexing endoscopic surgical videos is vital in surgical data science, forming the basis for systematic retrospective analysis and clinical performance evaluation. Despite its significance, current video analytics rely on manual indexing, a time-consuming process. Advances in computer vision, particularly deep learning, offer automation potential, yet progress is limited by the lack of publicly available, densely annotated surgical datasets. To address this, we present TEMSET-24K, an open-source dataset comprising 24,306 trans-anal endoscopic microsurgery (TEMS) video micro-clips. Each clip is meticulously annotated by clinical experts using a novel hierarchical labeling taxonomy encompassing phase, task, and action triplets, capturing intricate surgical workflows. To validate this dataset, we benchmarked deep learning models, including transformer-based architectures. Our in silico evaluation demonstrates high accuracy (up to 0.99) and F1 scores (up to 0.99) for key phases like Setup and Suturing. The STALNet model, tested with ConvNeXt, ViT, and SWIN V2 encoders, consistently segmented well-represented phases. TEMSET-24K provides a critical benchmark, propelling state-of-the-art solutions in surgical data science.</li>
</ul>

<h3>Title: Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Daouda Sow, Herbert Woisetschl√§ger, Saikiran Bulusu, Shiqiang Wang, Hans-Arno Jacobsen, Yingbin Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06733">https://arxiv.org/abs/2502.06733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06733">https://arxiv.org/pdf/2502.06733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06733]] Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining(https://arxiv.org/abs/2502.06733)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pretraining large language models (LLMs) on vast and heterogeneous datasets is crucial for achieving state-of-the-art performance across diverse downstream tasks. However, current training paradigms treat all samples equally, overlooking the importance or relevance of individual samples throughout the training process. Existing reweighting strategies, which primarily focus on group-level data importance, fail to leverage fine-grained instance-level information and do not adapt dynamically to individual sample importance as training progresses. In this paper, we introduce novel algorithms for dynamic, instance-level data reweighting aimed at improving both the efficiency and effectiveness of LLM pretraining. Our methods adjust the weight of each training sample based on its loss value in an online fashion, allowing the model to dynamically focus on more informative or important samples at the current training stage. In particular, our framework allows us to systematically devise reweighting strategies deprioritizing redundant or uninformative data, which we find tend to work best. Furthermore, we develop a new theoretical framework for analyzing the impact of loss-based reweighting on the convergence of gradient-based optimization, providing the first formal characterization of how these strategies affect convergence bounds. We empirically validate our approach across a spectrum of tasks, from pretraining 7B and 1.4B parameter LLMs to smaller-scale language models and linear regression problems, demonstrating that our loss-based reweighting approach can lead to faster convergence and significantly improved performance.</li>
</ul>

<h3>Title: Se\~norita-2M: A High-Quality Instruction-based Dataset for General Video Editing by Video Specialists</h3>
<ul>
<li><strong>Authors: </strong>Bojia Zi, Penghui Ruan, Marco Chen, Xianbiao Qi, Shaozhe Hao, Shihao Zhao, Youze Huang, Bin Liang, Rong Xiao, Kam-Fai Wong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06734">https://arxiv.org/abs/2502.06734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06734">https://arxiv.org/pdf/2502.06734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06734]] Se\~norita-2M: A High-Quality Instruction-based Dataset for General Video Editing by Video Specialists(https://arxiv.org/abs/2502.06734)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in video generation have spurred the development of video editing techniques, which can be divided into inversion-based and end-to-end methods. However, current video editing methods still suffer from several challenges. Inversion-based methods, though training-free and flexible, are time-consuming during inference, struggle with fine-grained editing instructions, and produce artifacts and jitter. On the other hand, end-to-end methods, which rely on edited video pairs for training, offer faster inference speeds but often produce poor editing results due to a lack of high-quality training video pairs. In this paper, to close the gap in end-to-end methods, we introduce Se√±orita-2M, a high-quality video editing dataset. Se√±orita-2M consists of approximately 2 millions of video editing pairs. It is built by crafting four high-quality, specialized video editing models, each crafted and trained by our team to achieve state-of-the-art editing results. We also propose a filtering pipeline to eliminate poorly edited video pairs. Furthermore, we explore common video editing architectures to identify the most effective structure based on current pre-trained generative model. Extensive experiments show that our dataset can help to yield remarkably high-quality video editing results. More details are available at this https URL.</li>
</ul>

<h3>Title: Enhancing Pneumonia Diagnosis and Severity Assessment through Deep Learning: A Comprehensive Approach Integrating CNN Classification and Infection Segmentation</h3>
<ul>
<li><strong>Authors: </strong>S Kumar Reddy Mallidi (1) ((1) Sri Vasavi Engineering College)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06735">https://arxiv.org/abs/2502.06735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06735">https://arxiv.org/pdf/2502.06735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06735]] Enhancing Pneumonia Diagnosis and Severity Assessment through Deep Learning: A Comprehensive Approach Integrating CNN Classification and Infection Segmentation(https://arxiv.org/abs/2502.06735)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Lung disease poses a substantial global health challenge, with pneumonia being a prevalent concern. This research focuses on leveraging deep learning techniques to detect and assess pneumonia, addressing two interconnected objectives. Initially, Convolutional Neural Network (CNN) models are introduced for pneumonia classification, emphasizing the necessity of comprehensive diagnostic assessments considering COVID-19. Subsequently, the study advocates for the utilization of deep learning-based segmentation to determine the severity of infection. This dual-pronged approach offers valuable insights for medical professionals, facilitating a more nuanced understanding and effective treatment of pneumonia. Integrating deep learning aims to elevate the accuracy and efficiency of pneumonia detection, thereby contributing to enhanced healthcare outcomes on a global scale.</li>
</ul>

<h3>Title: VersaPRM: Multi-Domain Process Reward Model via Synthetic Reasoning Data</h3>
<ul>
<li><strong>Authors: </strong>Thomas Zeng, Shuibai Zhang, Shutong Wu, Christian Classen, Daewon Chae, Ethan Ewer, Minjae Lee, Heeju Kim, Wonjun Kang, Jackson Kunde, Ying Fan, Jungtaek Kim, Hyung Il Koo, Kannan Ramchandran, Dimitris Papailiopoulos, Kangwook Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06737">https://arxiv.org/abs/2502.06737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06737">https://arxiv.org/pdf/2502.06737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06737]] VersaPRM: Multi-Domain Process Reward Model via Synthetic Reasoning Data(https://arxiv.org/abs/2502.06737)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Process Reward Models (PRMs) have proven effective at enhancing mathematical reasoning for Large Language Models (LLMs) by leveraging increased inference-time computation. However, they are predominantly trained on mathematical data and their generalizability to non-mathematical domains has not been rigorously studied. In response, this work first shows that current PRMs have poor performance in other domains. To address this limitation, we introduce VersaPRM, a multi-domain PRM trained on synthetic reasoning data generated using our novel data generation and annotation method. VersaPRM achieves consistent performance gains across diverse domains. For instance, in the MMLU-Pro category of Law, VersaPRM via weighted majority voting, achieves a 7.9% performance gain over the majority voting baseline -- surpassing Qwen2.5-Math-PRM's gain of 1.3%. We further contribute to the community by open-sourcing all data, code and models for VersaPRM.</li>
</ul>

<h3>Title: A note on the physical interpretation of neural PDE's</h3>
<ul>
<li><strong>Authors: </strong>Sauro Succi</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.dis-nn, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06739">https://arxiv.org/abs/2502.06739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06739">https://arxiv.org/pdf/2502.06739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06739]] A note on the physical interpretation of neural PDE's(https://arxiv.org/abs/2502.06739)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>We highlight a formal and substantial analogy between Machine Learning (ML) algorithms and discrete dynamical systems (DDS) in relaxation form. The analogy offers a transparent interpretation of the weights in terms of physical information-propagation processes and identifies the model function of the forward ML step with the local attractor of the corresponding discrete dynamics. Besides improving the explainability of current ML applications, this analogy may also facilitate the development of a new class ML algorithms with a reduced number of weights.</li>
</ul>

<h3>Title: ViSIR: Vision Transformer Single Image Reconstruction Method for Earth System Models</h3>
<ul>
<li><strong>Authors: </strong>Ehsan Zeraatkar, Salah Faroughi, Jelena Tesic</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06741">https://arxiv.org/abs/2502.06741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06741">https://arxiv.org/pdf/2502.06741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06741]] ViSIR: Vision Transformer Single Image Reconstruction Method for Earth System Models(https://arxiv.org/abs/2502.06741)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Purpose: Earth system models (ESMs) integrate the interactions of the atmosphere, ocean, land, ice, and biosphere to estimate the state of regional and global climate under a wide variety of conditions. The ESMs are highly complex, and thus, deep neural network architectures are used to model the complexity and store the down-sampled data. In this paper, we propose the Vision Transformer Sinusoidal Representation Networks (ViSIR) to improve the single image SR (SR) reconstruction task for the ESM data. Methods: ViSIR combines the SR capability of Vision Transformers (ViT) with the high-frequency detail preservation of the Sinusoidal Representation Network (SIREN) to address the spectral bias observed in SR tasks. Results: The ViSIR outperforms ViT by 4.1 dB, SIREN by 7.5 dB, and SR-Generative Adversarial (SR-GANs) by 7.1dB PSNR on average for three different measurements. Conclusion: The proposed ViSIR is evaluated and compared with state-of-the-art methods. The results show that the proposed algorithm is outperforming other methods in terms of Mean Square Error(MSE), Peak-Signal-to-Noise-Ratio(PSNR), and Structural Similarity Index Measure(SSIM).</li>
</ul>

<h3>Title: Gradient Multi-Normalization for Stateless and Scalable LLM Training</h3>
<ul>
<li><strong>Authors: </strong>Meyer Scetbon, Chao Ma, Wenbo Gong, Edward Meeds</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06742">https://arxiv.org/abs/2502.06742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06742">https://arxiv.org/pdf/2502.06742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06742]] Gradient Multi-Normalization for Stateless and Scalable LLM Training(https://arxiv.org/abs/2502.06742)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training large language models (LLMs) typically relies on adaptive optimizers like Adam (Kingma & Ba, 2015) which store additional state information to accelerate convergence but incur significant memory overhead. Recent efforts, such as SWAN (Ma et al., 2024) address this by eliminating the need for optimizer states while achieving performance comparable to Adam via a multi-step preprocessing procedure applied to instantaneous gradients. Motivated by the success of SWAN, we introduce a novel framework for designing stateless optimizers that normalizes stochastic gradients according to multiple norms. To achieve this, we propose a simple alternating scheme to enforce the normalization of gradients w.r.t these norms. We show that our procedure can produce, up to an arbitrary precision, a fixed-point of the problem, and that SWAN is a particular instance of our approach with carefully chosen norms, providing a deeper understanding of its design. However, SWAN's computationally expensive whitening/orthogonalization step limit its practicality for large LMs. Using our principled perspective, we develop of a more efficient, scalable, and practical stateless optimizer. Our algorithm relaxes the properties of SWAN, significantly reducing its computational cost while retaining its memory efficiency, making it applicable to training large-scale models. Experiments on pre-training LLaMA models with up to 1 billion parameters demonstrate a 3X speedup over Adam with significantly reduced memory requirements, outperforming other memory-efficient baselines.</li>
</ul>

<h3>Title: Wandering around: A bioinspired approach to visual attention through object motion sensitivity</h3>
<ul>
<li><strong>Authors: </strong>Giulia D Angelo, Victoria Clerico, Chiara Bartolozzi, Matej Hoffmann, P. Michael Furlong, Alexander Hadjiivanov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06747">https://arxiv.org/abs/2502.06747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06747">https://arxiv.org/pdf/2502.06747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06747]] Wandering around: A bioinspired approach to visual attention through object motion sensitivity(https://arxiv.org/abs/2502.06747)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Active vision enables dynamic visual perception, offering an alternative to static feedforward architectures in computer vision, which rely on large datasets and high computational resources. Biological selective attention mechanisms allow agents to focus on salient Regions of Interest (ROIs), reducing computational demand while maintaining real-time responsiveness. Event-based cameras, inspired by the mammalian retina, enhance this capability by capturing asynchronous scene changes enabling efficient low-latency processing. To distinguish moving objects while the event-based camera is in motion the agent requires an object motion segmentation mechanism to accurately detect targets and center them in the visual field (fovea). Integrating event-based sensors with neuromorphic algorithms represents a paradigm shift, using Spiking Neural Networks to parallelize computation and adapt to dynamic environments. This work presents a Spiking Convolutional Neural Network bioinspired attention system for selective attention through object motion sensitivity. The system generates events via fixational eye movements using a Dynamic Vision Sensor integrated into the Speck neuromorphic hardware, mounted on a Pan-Tilt unit, to identify the ROI and saccade toward it. The system, characterized using ideal gratings and benchmarked against the Event Camera Motion Segmentation Dataset, reaches a mean IoU of 82.2% and a mean SSIM of 96% in multi-object motion segmentation. The detection of salient objects reaches 88.8% accuracy in office scenarios and 89.8% in low-light conditions on the Event-Assisted Low-Light Video Object Segmentation Dataset. A real-time demonstrator shows the system's 0.12 s response to dynamic scenes. Its learning-free design ensures robustness across perceptual scenes, making it a reliable foundation for real-time robotic applications serving as a basis for more complex architectures.</li>
</ul>

<h3>Title: Blockchain-Powered Asset Tokenization Platform</h3>
<ul>
<li><strong>Authors: </strong>Aaryan Sinha, Raja Muthalagu, Pranav Pawar, Alavikunhu Panthakkan, Shadi Atalla</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06752">https://arxiv.org/abs/2502.06752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06752">https://arxiv.org/pdf/2502.06752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06752]] Blockchain-Powered Asset Tokenization Platform(https://arxiv.org/abs/2502.06752)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Blockchain Technology has revolutionized Finance and Technology with its secure, decentralized, and trust-less methodologies of data management. In a world where asset value fluctuations are unprecedented, it has become increasingly important to secure one's stake on their valuable assets and streamline the process of acquiring and transferring that stake over a trust-less environment. Tokenization proves to be unbeaten when it comes to giving the ownership of one's asset, an immutable, liquid, and irrefutable identity, as of the likes of cryptocurrency. It enables users to store and maintain records of their assets and even transfer fractions of these assets to other investors and stakeholders in the form of these tokens. However, like cryptocurrency, it too has witnessed attacks by malicious users that have compromised on their very foundation of this http URL attacks have inflicted more damage since they represent real-world assets that have physical importance. This project aims to assist users to secure their valuable assets by providing a highly secure user-friendly platform to manage, create and deploy asset-tokens, and facilitate open and transparent communication between stakeholders, thereby upholding the decentralized nature of blockchain and offering the financial freedom of asset ownership, with an added market value of a cryptocurrency-backed tokens.</li>
</ul>

<h3>Title: SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement</h3>
<ul>
<li><strong>Authors: </strong>Yuqi Lin, Hengjia Li, Wenqi Shao, Zheng Yang, Jun Zhao, Xiaofei He, Ping Luo, Kaipeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06756">https://arxiv.org/abs/2502.06756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06756">https://arxiv.org/pdf/2502.06756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06756]] SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement(https://arxiv.org/abs/2502.06756)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we explore a principal way to enhance the quality of widely pre-existing coarse masks, enabling them to serve as reliable training data for segmentation models to reduce the annotation cost. In contrast to prior refinement techniques that are tailored to specific models or tasks in a close-world manner, we propose SAMRefiner, a universal and efficient approach by adapting SAM to the mask refinement task. The core technique of our model is the noise-tolerant prompting scheme. Specifically, we introduce a multi-prompt excavation strategy to mine diverse input prompts for SAM (i.e., distance-guided points, context-aware elastic bounding boxes, and Gaussian-style masks) from initial coarse masks. These prompts can collaborate with each other to mitigate the effect of defects in coarse masks. In particular, considering the difficulty of SAM to handle the multi-object case in semantic segmentation, we introduce a split-then-merge (STM) pipeline. Additionally, we extend our method to SAMRefiner++ by introducing an additional IoU adaption step to further boost the performance of the generic SAMRefiner on the target dataset. This step is self-boosted and requires no additional annotation. The proposed framework is versatile and can flexibly cooperate with existing segmentation methods. We evaluate our mask framework on a wide range of benchmarks under different settings, demonstrating better accuracy and efficiency. SAMRefiner holds significant potential to expedite the evolution of refinement tools. Our code is available at this https URL.</li>
</ul>

<h3>Title: Rationalization Models for Text-to-SQL</h3>
<ul>
<li><strong>Authors: </strong>Gaetano Rossiello, Nhan Pham, Michael Glass, Junkyu Lee, Shankar Subramanian</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06759">https://arxiv.org/abs/2502.06759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06759">https://arxiv.org/pdf/2502.06759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06759]] Rationalization Models for Text-to-SQL(https://arxiv.org/abs/2502.06759)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>We introduce a framework for generating Chain-of-Thought (CoT) rationales to enhance text-to-SQL model fine-tuning. These rationales consist of intermediate SQL statements and explanations, serving as incremental steps toward constructing the final SQL query. The process begins with manually annotating a small set of examples, which are then used to prompt a large language model in an iterative, dynamic few-shot knowledge distillation procedure from a teacher model. A rationalization model is subsequently trained on the validated decomposed queries, enabling extensive synthetic CoT annotations for text-to-SQL datasets. To evaluate the approach, we fine-tune small language models with and without these rationales on the BIRD dataset. Results indicate that step-by-step query generation improves execution accuracy, especially for moderately and highly complex queries, while also enhancing explainability.</li>
</ul>

<h3>Title: When, Where and Why to Average Weights?</h3>
<ul>
<li><strong>Authors: </strong>Niccol√≤ Ajroldi, Antonio Orvieto, Jonas Geiping</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06761">https://arxiv.org/abs/2502.06761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06761">https://arxiv.org/pdf/2502.06761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06761]] When, Where and Why to Average Weights?(https://arxiv.org/abs/2502.06761)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Averaging checkpoints along the training trajectory is a simple yet powerful approach to improve the generalization performance of Machine Learning models and reduce training time. Motivated by these potential gains, and in an effort to fairly and thoroughly benchmark this technique, we present an extensive evaluation of averaging techniques in modern Deep Learning, which we perform using AlgoPerf \citep{dahl_benchmarking_2023}, a large-scale benchmark for optimization algorithms. We investigate whether weight averaging can reduce training time, improve generalization, and replace learning rate decay, as suggested by recent literature. Our evaluation across seven architectures and datasets reveals that averaging significantly accelerates training and yields considerable efficiency gains, at the price of a minimal implementation and memory cost, while mildly improving generalization across all considered workloads. Finally, we explore the relationship between averaging and learning rate annealing and show how to optimally combine the two to achieve the best performances.</li>
</ul>

<h3>Title: History-Guided Video Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Kiwhan Song, Boyuan Chen, Max Simchowitz, Yilun Du, Russ Tedrake, Vincent Sitzmann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06764">https://arxiv.org/abs/2502.06764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06764">https://arxiv.org/pdf/2502.06764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06764]] History-Guided Video Diffusion(https://arxiv.org/abs/2502.06764)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Classifier-free guidance (CFG) is a key technique for improving conditional generation in diffusion models, enabling more accurate control while enhancing sample quality. It is natural to extend this technique to video diffusion, which generates video conditioned on a variable number of context frames, collectively referred to as history. However, we find two key challenges to guiding with variable-length history: architectures that only support fixed-size conditioning, and the empirical observation that CFG-style history dropout performs poorly. To address this, we propose the Diffusion Forcing Transformer (DFoT), a video diffusion architecture and theoretically grounded training objective that jointly enable conditioning on a flexible number of history frames. We then introduce History Guidance, a family of guidance methods uniquely enabled by DFoT. We show that its simplest form, vanilla history guidance, already significantly improves video generation quality and temporal consistency. A more advanced method, history guidance across time and frequency further enhances motion dynamics, enables compositional generalization to out-of-distribution history, and can stably roll out extremely long videos. Website: this https URL</li>
</ul>

<h3>Title: Exploiting Sparsity for Long Context Inference: Million Token Contexts on Commodity GPUs</h3>
<ul>
<li><strong>Authors: </strong>Ryan Synk, Monte Hoover, John Kirchenbauer, Neel Jain, Alex Stein, Manli Shu, Josue Melendez Sanchez, Ramani Duraiswami, Tom Goldstein</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06766">https://arxiv.org/abs/2502.06766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06766">https://arxiv.org/pdf/2502.06766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06766]] Exploiting Sparsity for Long Context Inference: Million Token Contexts on Commodity GPUs(https://arxiv.org/abs/2502.06766)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>There is growing demand for performing inference with hundreds of thousands of input tokens on trained transformer models. Inference at this extreme scale demands significant computational resources, hindering the application of transformers at long contexts on commodity (i.e not data center scale) hardware. To address the inference time costs associated with running self-attention based transformer language models on long contexts and enable their adoption on widely available hardware, we propose a tunable mechanism that reduces the cost of the forward pass by attending to only the most relevant tokens at every generation step using a top-k selection mechanism. We showcase the efficiency gains afforded by our method by performing inference on context windows up to 1M tokens using approximately 16GB of GPU RAM. Our experiments reveal that models are capable of handling the sparsity induced by the reduced number of keys and values. By attending to less than 2% of input tokens, we achieve over 95% of model performance on common long context benchmarks (LM-Eval, AlpacaEval, and RULER).</li>
</ul>

<h3>Title: Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions</h3>
<ul>
<li><strong>Authors: </strong>Jaeyeon Kim, Kulin Shah, Vasilis Kontonis, Sham Kakade, Sitan Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06768">https://arxiv.org/abs/2502.06768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06768">https://arxiv.org/pdf/2502.06768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06768]] Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions(https://arxiv.org/abs/2502.06768)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In recent years, masked diffusion models (MDMs) have emerged as a promising alternative approach for generative modeling over discrete domains. Compared to autoregressive models (ARMs), MDMs trade off complexity at training time with flexibility at inference time. At training time, they must learn to solve an exponentially large number of infilling problems, but at inference time, they can decode tokens in essentially arbitrary order. In this work, we closely examine these two competing effects. On the training front, we theoretically and empirically demonstrate that MDMs indeed train on computationally intractable subproblems compared to their autoregressive counterparts. On the inference front, we show that a suitable strategy for adaptively choosing the token decoding order significantly enhances the capabilities of MDMs, allowing them to sidestep hard subproblems. On logic puzzles like Sudoku, we show that adaptive inference can boost solving accuracy in pretrained MDMs from $<7$% to $\approx 90$%, even outperforming ARMs with $7\times$ as many parameters and that were explicitly trained via teacher forcing to learn the right order of decoding.</li>
</ul>

<h3>Title: Enhancing Performance of Explainable AI Models with Constrained Concept Refinement</h3>
<ul>
<li><strong>Authors: </strong>Geyu Liang, Senne Michielssen, Salar Fattahi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06775">https://arxiv.org/abs/2502.06775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06775">https://arxiv.org/pdf/2502.06775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06775]] Enhancing Performance of Explainable AI Models with Constrained Concept Refinement(https://arxiv.org/abs/2502.06775)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>The trade-off between accuracy and interpretability has long been a challenge in machine learning (ML). This tension is particularly significant for emerging interpretable-by-design methods, which aim to redesign ML algorithms for trustworthy interpretability but often sacrifice accuracy in the process. In this paper, we address this gap by investigating the impact of deviations in concept representations-an essential component of interpretable models-on prediction performance and propose a novel framework to mitigate these effects. The framework builds on the principle of optimizing concept embeddings under constraints that preserve interpretability. Using a generative model as a test-bed, we rigorously prove that our algorithm achieves zero loss while progressively enhancing the interpretability of the resulting model. Additionally, we evaluate the practical performance of our proposed framework in generating explainable predictions for image classification tasks across various benchmarks. Compared to existing explainable methods, our approach not only improves prediction accuracy while preserving model interpretability across various large-scale benchmarks but also achieves this with significantly lower computational cost.</li>
</ul>

<h3>Title: Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT</h3>
<ul>
<li><strong>Authors: </strong>Dongyang Liu, Shicheng Li, Yutong Liu, Zhen Li, Kai Wang, Xinyue Li, Qi Qin, Yufei Liu, Yi Xin, Zhongyu Li, Bin Fu, Chenyang Si, Yuewen Cao, Conghui He, Ziwei Liu, Yu Qiao, Qibin Hou, Hongsheng Li, Peng Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06782">https://arxiv.org/abs/2502.06782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06782">https://arxiv.org/pdf/2502.06782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06782]] Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT(https://arxiv.org/abs/2502.06782)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent advancements have established Diffusion Transformers (DiTs) as a dominant framework in generative modeling. Building on this success, Lumina-Next achieves exceptional performance in the generation of photorealistic images with Next-DiT. However, its potential for video generation remains largely untapped, with significant challenges in modeling the spatiotemporal complexity inherent to video data. To address this, we introduce Lumina-Video, a framework that leverages the strengths of Next-DiT while introducing tailored solutions for video synthesis. Lumina-Video incorporates a Multi-scale Next-DiT architecture, which jointly learns multiple patchifications to enhance both efficiency and flexibility. By incorporating the motion score as an explicit condition, Lumina-Video also enables direct control of generated videos' dynamic degree. Combined with a progressive training scheme with increasingly higher resolution and FPS, and a multi-source training scheme with mixed natural and synthetic data, Lumina-Video achieves remarkable aesthetic quality and motion smoothness at high training and inference efficiency. We additionally propose Lumina-V2A, a video-to-audio model based on Next-DiT, to create synchronized sounds for generated videos. Codes are released at this https URL.</li>
</ul>

<h3>Title: DeepCrossAttention: Supercharging Transformer Residual Connections</h3>
<ul>
<li><strong>Authors: </strong>Mike Heddes, Adel Javanmard, Kyriakos Axiotis, Gang Fu, MohammadHossein Bateni, Vahab Mirrokni</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.06785">https://arxiv.org/abs/2502.06785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.06785">https://arxiv.org/pdf/2502.06785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.06785]] DeepCrossAttention: Supercharging Transformer Residual Connections(https://arxiv.org/abs/2502.06785)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer networks have achieved remarkable success across diverse domains, leveraging a variety of architectural innovations, including residual connections. However, traditional residual connections, which simply sum the outputs of previous layers, can dilute crucial information. This work introduces DeepCrossAttention (DCA), an approach that enhances residual learning in transformers. DCA employs learnable, input-dependent weights to dynamically combine layer outputs, enabling the model to selectively focus on the most relevant information in any of the previous layers. Furthermore, DCA incorporates depth-wise cross-attention, allowing for richer interactions between layers at different depths. Our language modeling experiments show that DCA achieves improved perplexity for a given training time. Moreover, DCA obtains the same model quality up to 3x faster while adding a negligible number of parameters. Theoretical analysis confirms that DCA provides an improved trade-off between accuracy and model size when the ratio of collective layer ranks to the ambient dimension falls below a critical threshold.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
