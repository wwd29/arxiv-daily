<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-01-17</h1>
<h3>Title: Two Directions for Clinical Data Generation with Large Language Models:  Data-to-Label and Label-to-Data</h3>
<ul>
<li><strong>Authors: </strong>Rumeng Li, Xun Wang, Hong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06774">https://arxiv.org/abs/2401.06774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06774">https://arxiv.org/pdf/2401.06774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06774]] Two Directions for Clinical Data Generation with Large Language Models:  Data-to-Label and Label-to-Data(https://arxiv.org/abs/2401.06774)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can generate natural language texts for various domains and tasks, but their potential for clinical text mining, a domain with scarce, sensitive, and imbalanced medical data, is underexplored. We investigate whether LLMs can augment clinical data for detecting Alzheimer's Disease (AD)-related signs and symptoms from electronic health records (EHRs), a challenging task that requires high expertise. We create a novel pragmatic taxonomy for AD sign and symptom progression based on expert knowledge, which guides LLMs to generate synthetic data following two different directions: "data-to-label", which labels sentences from a public EHR collection with AD-related signs and symptoms; and "label-to-data", which generates sentences with AD-related signs and symptoms based on the label definition. We train a system to detect AD-related signs and symptoms from EHRs, using three datasets: (1) a gold dataset annotated by human experts on longitudinal EHRs of AD patients; (2) a silver dataset created by the data-to-label method; and (3) a bronze dataset created by the label-to-data method. We find that using the silver and bronze datasets improves the system performance, outperforming the system using only the gold dataset. This shows that LLMs can generate synthetic clinical data for a complex task by incorporating expert knowledge, and our label-to-data method can produce datasets that are free of sensitive information, while maintaining acceptable quality.</li>
</ul>

<h3>Title: Large language models in healthcare and medical domain: A review</h3>
<ul>
<li><strong>Authors: </strong>Zabir Al Nazi, Wei Peng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06775">https://arxiv.org/abs/2401.06775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06775">https://arxiv.org/pdf/2401.06775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06775]] Large language models in healthcare and medical domain: A review(https://arxiv.org/abs/2401.06775)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>The deployment of large language models (LLMs) within the healthcare sector has sparked both enthusiasm and apprehension. These models exhibit the remarkable capability to provide proficient responses to free-text queries, demonstrating a nuanced understanding of professional medical knowledge. This comprehensive survey delves into the functionalities of existing LLMs designed for healthcare applications, elucidating the trajectory of their development, starting from traditional Pretrained Language Models (PLMs) to the present state of LLMs in healthcare sector. First, we explore the potential of LLMs to amplify the efficiency and effectiveness of diverse healthcare applications, particularly focusing on clinical language understanding tasks. These tasks encompass a wide spectrum, ranging from named entity recognition and relation extraction to natural language inference, multi-modal medical applications, document classification, and question-answering. Additionally, we conduct an extensive comparison of the most recent state-of-the-art LLMs in the healthcare domain, while also assessing the utilization of various open-source LLMs and highlighting their significance in healthcare applications. Furthermore, we present the essential performance metrics employed to evaluate LLMs in the biomedical domain, shedding light on their effectiveness and limitations. Finally, we summarize the prominent challenges and constraints faced by large language models in the healthcare sector, offering a holistic perspective on their potential benefits and shortcomings. This review provides a comprehensive exploration of the current landscape of LLMs in healthcare, addressing their role in transforming medical applications and the areas that warrant further research and development.</li>
</ul>

<h3>Title: Human-Instruction-Free LLM Self-Alignment with Limited Samples</h3>
<ul>
<li><strong>Authors: </strong>Hongyi Guo, Yuanshun Yao, Wei Shen, Jiaheng Wei, Xiaoying Zhang, Zhaoran Wang, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06785">https://arxiv.org/abs/2401.06785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06785">https://arxiv.org/pdf/2401.06785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06785]] Human-Instruction-Free LLM Self-Alignment with Limited Samples(https://arxiv.org/abs/2401.06785)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models (LLMs) with human values is a vital task for LLM practitioners. Current alignment techniques have several limitations: (1) requiring a large amount of annotated data; (2) demanding heavy human involvement; (3) lacking a systematic mechanism to continuously improve. In this work, we study aligning LLMs to a new domain with limited samples (e.g. < 100). We propose an algorithm that can self-align LLMs iteratively without active human involvement. Unlike existing works, our algorithm relies on neither human-crafted instructions nor labeled rewards, significantly reducing human involvement. In addition, our algorithm can self-improve the alignment continuously. The key idea is to first retrieve high-quality samples related to the target domain and use them as In-context Learning examples to generate more samples. Then we use the self-generated samples to finetune the LLM iteratively. We show that our method can unlock the LLMs' self-generalization ability to perform alignment with near-zero human supervision. We test our algorithm on three benchmarks in safety, truthfulness, and instruction-following, and show good performance in alignment, domain adaptability, and scalability.</li>
</ul>

<h3>Title: Using Zero-shot Prompting in the Automatic Creation and Expansion of  Topic Taxonomies for Tagging Retail Banking Transactions</h3>
<ul>
<li><strong>Authors: </strong>Daniel de S. Moraes, Pedro T. C. Santos, Polyana B. da Costa, Matheus A. S. Pinto, Ivan de J. P. Pinto, Álvaro M. G. da Veiga, Sergio Colcher, Antonio J. G. Busson, Rafael H. Rocha, Rennan Gaio, Rafael Miceli, Gabriela Tourinho, Marcos Rabaioli, Leandro Santos, Fellipe Marques, David Favaro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06790">https://arxiv.org/abs/2401.06790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06790">https://arxiv.org/pdf/2401.06790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06790]] Using Zero-shot Prompting in the Automatic Creation and Expansion of  Topic Taxonomies for Tagging Retail Banking Transactions(https://arxiv.org/abs/2401.06790)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This work presents an unsupervised method for automatically constructing and expanding topic taxonomies by using instruction-based fine-tuned LLMs (Large Language Models). We apply topic modeling and keyword extraction techniques to create initial topic taxonomies and LLMs to post-process the resulting terms and create a hierarchy. To expand an existing taxonomy with new terms, we use zero-shot prompting to find out where to add new nodes, which, to our knowledge, is the first work to present such an approach to taxonomy tasks. We use the resulting taxonomies to assign tags that characterize merchants from a retail bank dataset. To evaluate our work, we asked 12 volunteers to answer a two-part form in which we first assessed the quality of the taxonomies created and then the tags assigned to merchants based on that taxonomy. The evaluation revealed a coherence rate exceeding 90% for the chosen taxonomies, while the average coherence for merchant tagging surpassed 80%.</li>
</ul>

<h3>Title: LightHouse: A Survey of AGI Hallucination</h3>
<ul>
<li><strong>Authors: </strong>Feng Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06792">https://arxiv.org/abs/2401.06792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06792">https://arxiv.org/pdf/2401.06792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06792]] LightHouse: A Survey of AGI Hallucination(https://arxiv.org/abs/2401.06792)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the development of artificial intelligence, large-scale models have become increasingly intelligent. However, numerous studies indicate that hallucinations within these large models are a bottleneck hindering the development of AI research. In the pursuit of achieving strong artificial intelligence, a significant volume of research effort is being invested in the AGI (Artificial General Intelligence) hallucination research. Previous explorations have been conducted in researching hallucinations within LLMs (Large Language Models). As for multimodal AGI, research on hallucinations is still in an early stage. To further the progress of research in the domain of hallucinatory phenomena, we present a bird's eye view of hallucinations in AGI, summarizing the current work on AGI hallucinations and proposing some directions for future research.</li>
</ul>

<h3>Title: AI and Generative AI for Research Discovery and Summarization</h3>
<ul>
<li><strong>Authors: </strong>Mark Glickman, Yi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06795">https://arxiv.org/abs/2401.06795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06795">https://arxiv.org/pdf/2401.06795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06795]] AI and Generative AI for Research Discovery and Summarization(https://arxiv.org/abs/2401.06795)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>AI and generative AI tools, including chatbots like ChatGPT that rely on large language models (LLMs), have burst onto the scene this year, creating incredible opportunities to increase work productivity and improve our lives. Statisticians and data scientists have begun experiencing the benefits from the availability of these tools in numerous ways, such as the generation of programming code from text prompts to analyze data or fit statistical models. One area that these tools can make a substantial impact is in research discovery and summarization. Standalone tools and plugins to chatbots are being developed that allow researchers to more quickly find relevant literature than pre-2023 search tools. Furthermore, generative AI tools have improved to the point where they can summarize and extract the key points from research articles in succinct language. Finally, chatbots based on highly parameterized LLMs can be used to simulate abductive reasoning, which provides researchers the ability to make connections among related technical topics, which can also be used for research discovery. We review the developments in AI and generative AI for research discovery and summarization, and propose directions where these types of tools are likely to head in the future that may be of interest to statistician and data scientists.</li>
</ul>

<h3>Title: AI Hallucinations: A Misnomer Worth Clarifying</h3>
<ul>
<li><strong>Authors: </strong>Negar Maleki, Balaji Padmanabhan, Kaushik Dutta</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06796">https://arxiv.org/abs/2401.06796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06796">https://arxiv.org/pdf/2401.06796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06796]] AI Hallucinations: A Misnomer Worth Clarifying(https://arxiv.org/abs/2401.06796)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models continue to advance in Artificial Intelligence (AI), text generation systems have been shown to suffer from a problematic phenomenon termed often as "hallucination." However, with AI's increasing presence across various domains including medicine, concerns have arisen regarding the use of the term itself. In this study, we conducted a systematic review to identify papers defining "AI hallucination" across fourteen databases. We present and analyze definitions obtained across all databases, categorize them based on their applications, and extract key points within each category. Our results highlight a lack of consistency in how the term is used, but also help identify several alternative terms in the literature. We discuss implications of these and call for a more unified effort to bring consistency to an important contemporary AI issue that can affect multiple domains significantly.</li>
</ul>

<h3>Title: Reinforcement Learning for Optimizing RAG for Domain Chatbots</h3>
<ul>
<li><strong>Authors: </strong>Mandar Kulkarni, Praveen Tangarajan, Kyung Kim, Anusua Trivedi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06800">https://arxiv.org/abs/2401.06800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06800">https://arxiv.org/pdf/2401.06800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06800]] Reinforcement Learning for Optimizing RAG for Domain Chatbots(https://arxiv.org/abs/2401.06800)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the advent of Large Language Models (LLM), conversational assistants have become prevalent for domain use cases. LLMs acquire the ability to contextual question answering through training, and Retrieval Augmented Generation (RAG) further enables the bot to answer domain-specific questions. This paper describes a RAG-based approach for building a chatbot that answers user's queries using Frequently Asked Questions (FAQ) data. We train an in-house retrieval embedding model using infoNCE loss, and experimental results demonstrate that the in-house model works significantly better than the well-known general-purpose public embedding model, both in terms of retrieval accuracy and Out-of-Domain (OOD) query detection. As an LLM, we use an open API-based paid ChatGPT model. We noticed that a previously retrieved-context could be used to generate an answer for specific patterns/sequences of queries (e.g., follow-up queries). Hence, there is a scope to optimize the number of LLM tokens and cost. Assuming a fixed retrieval model and an LLM, we optimize the number of LLM tokens using Reinforcement Learning (RL). Specifically, we propose a policy-based model external to the RAG, which interacts with the RAG pipeline through policy actions and updates the policy to optimize the cost. The policy model can perform two actions: to fetch FAQ context or skip retrieval. We use the open API-based GPT-4 as the reward model. We then train a policy model using policy gradient on multiple training chat sessions. As a policy model, we experimented with a public gpt-2 model and an in-house BERT model. With the proposed RL-based optimization combined with similarity threshold, we are able to achieve significant cost savings while getting a slightly improved accuracy. Though we demonstrate results for the FAQ chatbot, the proposed RL approach is generic and can be experimented with any existing RAG pipeline.</li>
</ul>

<h3>Title: Generative AI Meets Semantic Communication: Evolution and Revolution of  Communication Tasks</h3>
<ul>
<li><strong>Authors: </strong>Eleonora Grassucci, Jihong Park, Sergio Barbarossa, Seong-Lyun Kim, Jinho Choi, Danilo Comminiello</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06803">https://arxiv.org/abs/2401.06803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06803">https://arxiv.org/pdf/2401.06803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06803]] Generative AI Meets Semantic Communication: Evolution and Revolution of  Communication Tasks(https://arxiv.org/abs/2401.06803)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>While deep generative models are showing exciting abilities in computer vision and natural language processing, their adoption in communication frameworks is still far underestimated. These methods are demonstrated to evolve solutions to classic communication problems such as denoising, restoration, or compression. Nevertheless, generative models can unveil their real potential in semantic communication frameworks, in which the receiver is not asked to recover the sequence of bits used to encode the transmitted (semantic) message, but only to regenerate content that is semantically consistent with the transmitted message. Disclosing generative models capabilities in semantic communication paves the way for a paradigm shift with respect to conventional communication systems, which has great potential to reduce the amount of data traffic and offers a revolutionary versatility to novel tasks and applications that were not even conceivable a few years ago. In this paper, we present a unified perspective of deep generative models in semantic communication and we unveil their revolutionary role in future communication frameworks, enabling emerging applications and tasks. Finally, we analyze the challenges and opportunities to face to develop generative models specifically tailored for communication systems.</li>
</ul>

<h3>Title: ChatGPT, Let us Chat Sign Language: Experiments, Architectural Elements,  Challenges and Research Directions</h3>
<ul>
<li><strong>Authors: </strong>Nada Shahin, Leila Ismail</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06804">https://arxiv.org/abs/2401.06804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06804">https://arxiv.org/pdf/2401.06804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06804]] ChatGPT, Let us Chat Sign Language: Experiments, Architectural Elements,  Challenges and Research Directions(https://arxiv.org/abs/2401.06804)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>ChatGPT is a language model based on Generative AI. Existing research work on ChatGPT focused on its use in various domains. However, its potential for Sign Language Translation (SLT) is yet to be explored. This paper addresses this void. Therefore, we present GPT's evolution aiming a retrospective analysis of the improvements to its architecture for SLT. We explore ChatGPT's capabilities in translating different sign languages in paving the way to better accessibility for deaf and hard-of-hearing community. Our experimental results indicate that ChatGPT can accurately translate from English to American (ASL), Australian (AUSLAN), and British (BSL) sign languages and from Arabic Sign Language (ArSL) to English with only one prompt iteration. However, the model failed to translate from Arabic to ArSL and ASL, AUSLAN, and BSL to Arabic. Consequently, we present challenges and derive insights for future research directions.</li>
</ul>

<h3>Title: Exploring the Reasoning Abilities of Multimodal Large Language Models  (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yiqi Wang, Wentao Chen, Xiaotian Han, Xudong Lin, Haiteng Zhao, Yongfei Liu, Bohan Zhai, Jianbo Yuan, Quanzeng You, Hongxia Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06805">https://arxiv.org/abs/2401.06805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06805">https://arxiv.org/pdf/2401.06805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06805]] Exploring the Reasoning Abilities of Multimodal Large Language Models  (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning(https://arxiv.org/abs/2401.06805)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Strong Artificial Intelligence (Strong AI) or Artificial General Intelligence (AGI) with abstract reasoning ability is the goal of next-generation AI. Recent advancements in Large Language Models (LLMs), along with the emerging field of Multimodal Large Language Models (MLLMs), have demonstrated impressive capabilities across a wide range of multimodal tasks and applications. Particularly, various MLLMs, each with distinct model architectures, training data, and training stages, have been evaluated across a broad range of MLLM benchmarks. These studies have, to varying degrees, revealed different aspects of the current capabilities of MLLMs. However, the reasoning abilities of MLLMs have not been systematically investigated. In this survey, we comprehensively review the existing evaluation protocols of multimodal reasoning, categorize and illustrate the frontiers of MLLMs, introduce recent trends in applications of MLLMs on reasoning-intensive tasks, and finally discuss current practices and future directions. We believe our survey establishes a solid base and sheds light on this important topic, multimodal reasoning.</li>
</ul>

<h3>Title: AugSumm: towards generalizable speech summarization using synthetic  labels from large language model</h3>
<ul>
<li><strong>Authors: </strong>Jee-weon Jung, Roshan Sharma, William Chen, Bhiksha Raj, Shinji Watanabe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06806">https://arxiv.org/abs/2401.06806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06806">https://arxiv.org/pdf/2401.06806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06806]] AugSumm: towards generalizable speech summarization using synthetic  labels from large language model(https://arxiv.org/abs/2401.06806)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Abstractive speech summarization (SSUM) aims to generate human-like summaries from speech. Given variations in information captured and phrasing, recordings can be summarized in multiple ways. Therefore, it is more reasonable to consider a probabilistic distribution of all potential summaries rather than a single summary. However, conventional SSUM models are mostly trained and evaluated with a single ground-truth (GT) human-annotated deterministic summary for every recording. Generating multiple human references would be ideal to better represent the distribution statistically, but is impractical because annotation is expensive. We tackle this challenge by proposing AugSumm, a method to leverage large language models (LLMs) as a proxy for human annotators to generate augmented summaries for training and evaluation. First, we explore prompting strategies to generate synthetic summaries from ChatGPT. We validate the quality of synthetic summaries using multiple metrics including human evaluation, where we find that summaries generated using AugSumm are perceived as more valid to humans. Second, we develop methods to utilize synthetic summaries in training and evaluation. Experiments on How2 demonstrate that pre-training on synthetic summaries and fine-tuning on GT summaries improves ROUGE-L by 1 point on both GT and AugSumm-based test sets. AugSumm summaries are available at https://github.com/Jungjee/AugSumm.</li>
</ul>

<h3>Title: An EcoSage Assistant: Towards Building A Multimodal Plant Care Dialogue  Assistant</h3>
<ul>
<li><strong>Authors: </strong>Mohit Tomar, Abhisek Tiwari, Tulika Saha, Prince Jha, Sriparna Saha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06807">https://arxiv.org/abs/2401.06807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06807">https://arxiv.org/pdf/2401.06807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06807]] An EcoSage Assistant: Towards Building A Multimodal Plant Care Dialogue  Assistant(https://arxiv.org/abs/2401.06807)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent times, there has been an increasing awareness about imminent environmental challenges, resulting in people showing a stronger dedication to taking care of the environment and nurturing green life. The current $19.6 billion indoor gardening industry, reflective of this growing sentiment, not only signifies a monetary value but also speaks of a profound human desire to reconnect with the natural world. However, several recent surveys cast a revealing light on the fate of plants within our care, with more than half succumbing primarily due to the silent menace of improper care. Thus, the need for accessible expertise capable of assisting and guiding individuals through the intricacies of plant care has become paramount more than ever. In this work, we make the very first attempt at building a plant care assistant, which aims to assist people with plant(-ing) concerns through conversations. We propose a plant care conversational dataset named Plantational, which contains around 1K dialogues between users and plant care experts. Our end-to-end proposed approach is two-fold : (i) We first benchmark the dataset with the help of various large language models (LLMs) and visual language model (VLM) by studying the impact of instruction tuning (zero-shot and few-shot prompting) and fine-tuning techniques on this task; (ii) finally, we build EcoSage, a multi-modal plant care assisting dialogue generation framework, incorporating an adapter-based modality infusion using a gated mechanism. We performed an extensive examination (both automated and manual evaluation) of the performance exhibited by various LLMs and VLM in the generation of the domain-specific dialogue responses to underscore the respective strengths and weaknesses of these diverse models.</li>
</ul>

<h3>Title: When ChatGPT is gone: Creativity reverts and homogeneity persists</h3>
<ul>
<li><strong>Authors: </strong>Qinghan Liu, Yiyong Zhou, Jihao Huang, Guiquan Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06816">https://arxiv.org/abs/2401.06816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06816">https://arxiv.org/pdf/2401.06816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06816]] When ChatGPT is gone: Creativity reverts and homogeneity persists(https://arxiv.org/abs/2401.06816)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>ChatGPT has been evidenced to enhance human performance in creative tasks. Yet, it is still unclear if this boosting effect sustains with and without ChatGPT. In a pre-registered seven-day lab experiment and a follow-up survey after 30 days of experiment completion, we examined the impacts of ChatGPT presence and absence on sustained creativity using a text dataset of 3302 creative ideas and 427 creative solutions from 61 college students. Participants in the treatment group used ChatGPT in creative tasks, while those in the control group completed the tasks by themselves. The findings show that although the boosting effect of ChatGPT was consistently observed over a five-day creative journey, human creative performance reverted to baseline when ChatGPT was down on the 7th and the 30th day. More critically, the use of ChatGPT in creative tasks resulted in increasingly homogenized contents, and this homogenization effect persisted even when ChatGPT was absence. These findings pose a challenge to the prevailing argument that ChatGPT can enhance human creativity. In fact, generative AI like ChatGPT lends to human with a temporary rise in creative performance but boxes human creative capability in the long run, highlighting the imperative for cautious generative AI integration in creative endeavors.</li>
</ul>

<h3>Title: Analyzing Regional Impacts of Climate Change using Natural Language  Processing Techniques</h3>
<ul>
<li><strong>Authors: </strong>Tanwi Mallick, John Murphy, Joshua David Bergerson, Duane R. Verner, John K Hutchison, Leslie-Anne Levy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06817">https://arxiv.org/abs/2401.06817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06817">https://arxiv.org/pdf/2401.06817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06817]] Analyzing Regional Impacts of Climate Change using Natural Language  Processing Techniques(https://arxiv.org/abs/2401.06817)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding the multifaceted effects of climate change across diverse geographic locations is crucial for timely adaptation and the development of effective mitigation strategies. As the volume of scientific literature on this topic continues to grow exponentially, manually reviewing these documents has become an immensely challenging task. Utilizing Natural Language Processing (NLP) techniques to analyze this wealth of information presents an efficient and scalable solution. By gathering extensive amounts of peer-reviewed articles and studies, we can extract and process critical information about the effects of climate change in specific regions. We employ BERT (Bidirectional Encoder Representations from Transformers) for Named Entity Recognition (NER), which enables us to efficiently identify specific geographies within the climate literature. This, in turn, facilitates location-specific analyses. We conduct region-specific climate trend analyses to pinpoint the predominant themes or concerns related to climate change within a particular area, trace the temporal progression of these identified issues, and evaluate their frequency, severity, and potential development over time. These in-depth examinations of location-specific climate data enable the creation of more customized policy-making, adaptation, and mitigation strategies, addressing each region's unique challenges and providing more effective solutions rooted in data-driven insights. This approach, founded on a thorough exploration of scientific texts, offers actionable insights to a wide range of stakeholders, from policymakers to engineers to environmentalists. By proactively understanding these impacts, societies are better positioned to prepare, allocate resources wisely, and design tailored strategies to cope with future climate conditions, ensuring a more resilient future for all.</li>
</ul>

<h3>Title: Surrogate Neural Networks Local Stability for Aircraft Predictive  Maintenance</h3>
<ul>
<li><strong>Authors: </strong>Mélanie Ducoffe, Guillaume Povéda, Audrey Galametz, Ryma Boumazouza, Marion-Cécile Martin, Julien Baris, Derk Daverschot, Eugene O'Higgins</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06821">https://arxiv.org/abs/2401.06821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06821">https://arxiv.org/pdf/2401.06821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06821]] Surrogate Neural Networks Local Stability for Aircraft Predictive  Maintenance(https://arxiv.org/abs/2401.06821)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Surrogate Neural Networks (NN) now routinely serve as substitutes for computationally demanding simulations (e.g., finite element). They enable faster analyses in industrial applications e.g., manufacturing processes, performance assessment. The verification of surrogate models is a critical step to assess their robustness under different scenarios. We explore the combination of empirical and formal methods in one NN verification pipeline. We showcase its efficiency on an industrial use case of aircraft predictive maintenance. We assess the local stability of surrogate NN designed to predict the stress sustained by an aircraft part from external loads. Our contribution lies in the complete verification of the surrogate models that possess a high-dimensional input and output space, thus accommodating multi-objective constraints. We also demonstrate the pipeline effectiveness in substantially decreasing the runtime needed to assess the targeted property.</li>
</ul>

<h3>Title: Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation  Engineering</h3>
<ul>
<li><strong>Authors: </strong>Tianlong Li, Xiaoqing Zheng, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06824">https://arxiv.org/abs/2401.06824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06824">https://arxiv.org/pdf/2401.06824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06824]] Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation  Engineering(https://arxiv.org/abs/2401.06824)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Getting large language models (LLMs) to refuse to answer hostile toxicity questions is a core issue under the theme of LLMs security. Previous approaches have used prompts engineering to jailbreak LLMs and answer some toxicity questions. These approaches can easily fail after the model manufacturer makes additional fine-tuning to the model. To promote the further understanding of model jailbreaking by researchers, we are inspired by Representation Engineering to propose a jailbreaking method that does not require elaborate construction prompts, is not affected by model fine-tuning, and can be widely applied to any open-source LLMs in a pluggable manner. We have evaluated this method on multiple mainstream LLMs on carefully supplemented toxicity datasets, and the experimental results demonstrate the significant effectiveness of our approach. After being surprised by some interesting jailbreaking cases, we did extensive in-depth research to explore the techniques behind this method.</li>
</ul>

<h3>Title: APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning</h3>
<ul>
<li><strong>Authors: </strong>Guiming Cao, Kaize Shi, Hong Fu, Huaiwen Zhang, Guandong Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06827">https://arxiv.org/abs/2401.06827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06827">https://arxiv.org/pdf/2401.06827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06827]] APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning(https://arxiv.org/abs/2401.06827)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Pre-trained Vision-Language (V-L) models set the benchmark for generalization to downstream tasks among the noteworthy contenders. Many characteristics of the V-L model have been explored in existing research including the challenge of the sensitivity to text input and the tuning process across multi-modal prompts. With the advanced utilization of the V-L model like CLIP, recent approaches deploy learnable prompts instead of hand-craft prompts to boost the generalization performance and address the aforementioned challenges. Inspired by layer-wise training, which is wildly used in image fusion, we note that using a sequential training process to adapt different modalities branches of CLIP efficiently facilitates the improvement of generalization. In the context of addressing the multi-modal prompting challenge, we propose Token-wise Adaptive for Multi-modal Prompt Learning (APLe) for tuning both modalities prompts, vision and language, as tokens in a sequential manner. APLe addresses the challenges in V-L models to promote prompt learning across both modalities, which indicates a competitive generalization performance in line with the state-of-the-art. Preeminently, APLe shows robustness and favourable performance in prompt-length experiments with an absolute advantage in adopting the V-L models.</li>
</ul>

<h3>Title: Cross-Attention Watermarking of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Folco Bertini Baldassini, Huy H. Nguyen, Ching-Chung Chang, Isao Echizen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06829">https://arxiv.org/abs/2401.06829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06829">https://arxiv.org/pdf/2401.06829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06829]] Cross-Attention Watermarking of Large Language Models(https://arxiv.org/abs/2401.06829)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark, large language model</a></li>
<li><strong>Abstract: </strong>A new approach to linguistic watermarking of language models is presented in which information is imperceptibly inserted into the output text while preserving its readability and original meaning. A cross-attention mechanism is used to embed watermarks in the text during inference. Two methods using cross-attention are presented that minimize the effect of watermarking on the performance of a pretrained model. Exploration of different training strategies for optimizing the watermarking and of the challenges and implications of applying this approach in real-world scenarios clarified the tradeoff between watermark robustness and text quality. Watermark selection substantially affects the generated output for high entropy sentences. This proactive watermarking approach has potential application in future model development.</li>
</ul>

<h3>Title: A Survey on the Applications of Frontier AI, Foundation Models, and  Large Language Models to Intelligent Transportation Systems</h3>
<ul>
<li><strong>Authors: </strong>Mohamed R. Shoaib, Heba M. Emara, Jun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06831">https://arxiv.org/abs/2401.06831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06831">https://arxiv.org/pdf/2401.06831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06831]] A Survey on the Applications of Frontier AI, Foundation Models, and  Large Language Models to Intelligent Transportation Systems(https://arxiv.org/abs/2401.06831)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This survey paper explores the transformative influence of frontier AI, foundation models, and Large Language Models (LLMs) in the realm of Intelligent Transportation Systems (ITS), emphasizing their integral role in advancing transportation intelligence, optimizing traffic management, and contributing to the realization of smart cities. Frontier AI refers to the forefront of AI technology, encompassing the latest advancements, innovations, and experimental techniques in the field, especially AI foundation models and LLMs. Foundation models, like GPT-4, are large, general-purpose AI models that provide a base for a wide range of applications. They are characterized by their versatility and scalability. LLMs are obtained from finetuning foundation models with a specific focus on processing and generating natural language. They excel in tasks like language understanding, text generation, translation, and summarization. By leveraging vast textual data, including traffic reports and social media interactions, LLMs extract critical insights, fostering the evolution of ITS. The survey navigates the dynamic synergy between LLMs and ITS, delving into applications in traffic management, integration into autonomous vehicles, and their role in shaping smart cities. It provides insights into ongoing research, innovations, and emerging trends, aiming to inspire collaboration at the intersection of language, intelligence, and mobility for safer, more efficient, and sustainable transportation systems. The paper further surveys interactions between LLMs and various aspects of ITS, exploring roles in traffic management, facilitating autonomous vehicles, and contributing to smart city development, while addressing challenges brought by frontier AI and foundation models. This paper offers valuable inspiration for future research and innovation in the transformative domain of intelligent transportation.</li>
</ul>

<h3>Title: Enhancing the Emotional Generation Capability of Large Language Models  via Emotional Chain-of-Thought</h3>
<ul>
<li><strong>Authors: </strong>Zaijing Li, Gongwei Chen, Rui Shao, Dongmei Jiang, Liqiang Nie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06836">https://arxiv.org/abs/2401.06836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06836">https://arxiv.org/pdf/2401.06836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06836]] Enhancing the Emotional Generation Capability of Large Language Models  via Emotional Chain-of-Thought(https://arxiv.org/abs/2401.06836)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The Emotional Generation is a subset of emotional intelligence, which aims to output an emotional response based on emotional conditions as input. Emotion generation has a wide range of applications, including emotion chat, emotional visual caption, and emotional rewriting. However, it faces challenges such as a lack of interpretability and poor evaluability. In this paper, we propose the Emotional Chain-of-Thought (ECoT), a plug-and-play prompting method that enhances the performance of Large Language Models (LLMs) on various emotional generation tasks by aligning with human emotional intelligence guidelines. To assess the reliability of ECoT, we propose an automated model-based evaluation method called EGS. Extensive experimental results demonstrate the effectiveness of ECoT and EGS. Further,we discuss the promise of LLMs in the field of sentiment analysis and present key insights into the LLMs with the ECoT in emotional generation tasks.</li>
</ul>

<h3>Title: Structsum Generation for Faster Text Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Parag Jain, Andreea Marzoca, Francesco Piccinno</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06837">https://arxiv.org/abs/2401.06837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06837">https://arxiv.org/pdf/2401.06837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06837]] Structsum Generation for Faster Text Comprehension(https://arxiv.org/abs/2401.06837)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We consider the task of generating structured representations of text using large language models (LLMs). We focus on tables and mind maps as representative modalities. Tables are more organized way of representing data, while mind maps provide a visually dynamic and flexible approach, particularly suitable for sparse content. Despite the effectiveness of LLMs on different tasks, we show that current models struggle with generating structured outputs. In response, we present effective prompting strategies for both of these tasks. We introduce a taxonomy of problems around factuality, global and local structure, common to both modalities and propose a set of critiques to tackle these issues resulting in an absolute improvement in accuracy of +37pp (79%) for mind maps and +15pp (78%) for tables. To evaluate semantic coverage of generated structured representations we propose Auto-QA, and we verify the adequacy of Auto-QA using SQuAD dataset. We further evaluate the usefulness of structured representations via a text comprehension user study. The results show a significant reduction in comprehension time compared to text when using table (42.9%) and mind map (31.9%), without loss in accuracy.</li>
</ul>

<h3>Title: Large Language Models Can Learn Temporal Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Siheng Xiong, Ali Payani, Ramana Kompella, Faramarz Fekri</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06853">https://arxiv.org/abs/2401.06853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06853">https://arxiv.org/pdf/2401.06853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06853]] Large Language Models Can Learn Temporal Reasoning(https://arxiv.org/abs/2401.06853)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) learn temporal concepts from the co-occurrence of related tokens in a sequence. Compared with conventional text generation, temporal reasoning, which reaches a conclusion based on mathematical, logical and commonsense knowledge, is more challenging. In this paper, we propose TempGraph-LLM, a new paradigm towards text-based temporal reasoning. To be specific, we first teach LLMs to translate the context into a temporal graph. A synthetic dataset, which is fully controllable and requires minimal supervision, is constructed for pre-training on this task. We prove in experiments that LLMs benefit from the pre-training on other tasks. On top of that, we guide LLMs to perform symbolic reasoning with the strategies of Chain of Thoughts (CoTs) bootstrapping and special data augmentation. We observe that CoTs with symbolic reasoning bring more consistent and reliable results than those using free text.</li>
</ul>

<h3>Title: Fine-grained Hallucination Detection and Editing for Language Models</h3>
<ul>
<li><strong>Authors: </strong>Abhika Mishra, Akari Asai, Vidhisha Balachandran, Yizhong Wang, Graham Neubig, Yulia Tsvetkov, Hannaneh Hajishirzi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06855">https://arxiv.org/abs/2401.06855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06855">https://arxiv.org/pdf/2401.06855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06855]] Fine-grained Hallucination Detection and Editing for Language Models(https://arxiv.org/abs/2401.06855)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LMs) are prone to generate diverse factually incorrect statements, which are widely called hallucinations. Current approaches predominantly focus on coarse-grained automatic hallucination detection or editing, overlooking nuanced error levels. In this paper, we propose a novel task -- automatic fine-grained hallucination detection -- and present a comprehensive taxonomy encompassing six hierarchically defined types of hallucination. To facilitate evaluation, we introduce a new benchmark that includes fine-grained human judgments on two LM outputs across various domains. Our analysis reveals that ChatGPT and Llama 2-Chat exhibit hallucinations in 60% and 75% of their outputs, respectively, and a majority of these hallucinations fall into categories that have been underexplored. As an initial step to address this, we train FAVA, a retrieval-augmented LM by carefully designing synthetic data generations to detect and correct fine-grained hallucinations. On our benchmark, our automatic and human evaluations show that FAVA significantly outperforms ChatGPT on fine-grained hallucination detection by a large margin though a large room for future improvement still exists. FAVA's suggested edits also improve the factuality of LM-generated text, resulting in 5-10% FActScore improvements.</li>
</ul>

<h3>Title: Health-LLM: Large Language Models for Health Prediction via Wearable  Sensor Data</h3>
<ul>
<li><strong>Authors: </strong>Yubin Kim, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, Hae Won Park</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06866">https://arxiv.org/abs/2401.06866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06866">https://arxiv.org/pdf/2401.06866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06866]] Health-LLM: Large Language Models for Health Prediction via Wearable  Sensor Data(https://arxiv.org/abs/2401.06866)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are capable of many natural language tasks, yet they are far from perfect. In health applications, grounding and interpreting domain-specific and non-linguistic data is important. This paper investigates the capacity of LLMs to deliver multi-modal health predictions based on contextual information (e.g. user demographics, health knowledge) and physiological data (e.g. resting heart rate, sleep minutes). We present a comprehensive evaluation of eight state-of-the-art LLMs with diverse prompting and fine-tuning techniques on six public health datasets (PM-Data, LifeSnaps, GLOBEM, AW_FB, MIT-BIH & MIMIC-III). Our experiments cover thirteen consumer health prediction tasks in mental health, activity, metabolic, sleep, and cardiac assessment. Our fine-tuned model, Health-Alpaca exhibits comparable performance to larger models (GPT-3.5 and GPT-4), achieving the best performance in 5 out of 13 tasks. Ablation studies highlight the effectiveness of context enhancement strategies, and generalization capability of the fine-tuned models across training datasets and the size of training samples. Notably, we observe that our context enhancement can yield up to 23.8% improvement in performance. While constructing contextually rich prompts (combining user context, health knowledge and temporal information) exhibits synergistic improvement, the inclusion of health knowledge context in prompts significantly enhances overall performance.</li>
</ul>

<h3>Title: Promptly Predicting Structures: The Return of Inference</h3>
<ul>
<li><strong>Authors: </strong>Maitrey Mehta, Valentina Pyatkin, Vivek Srikumar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06877">https://arxiv.org/abs/2401.06877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06877">https://arxiv.org/pdf/2401.06877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06877]] Promptly Predicting Structures: The Return of Inference(https://arxiv.org/abs/2401.06877)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prompt-based methods have been used extensively across NLP to build zero- and few-shot label predictors. Many NLP tasks are naturally structured: that is, their outputs consist of multiple labels which constrain each other. Annotating data for such tasks can be cumbersome. Can the promise of the prompt-based paradigm be extended to such structured outputs? In this paper, we present a framework for constructing zero- and few-shot linguistic structure predictors. Our key insight is that we can use structural constraints -- and combinatorial inference derived from them -- to filter out inconsistent structures predicted by large language models. We instantiated this framework on two structured prediction tasks, and five datasets. Across all cases, our results show that enforcing consistency not only constructs structurally valid outputs, but also improves performance over the unconstrained variants.</li>
</ul>

<h3>Title: Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular Data  Generation and Evaluation in Learning Analytics</h3>
<ul>
<li><strong>Authors: </strong>Qinyi Liu, Mohammad Khalil, Ronas Shakya, Jelena Jovanovic</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06883">https://arxiv.org/abs/2401.06883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06883">https://arxiv.org/pdf/2401.06883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06883]] Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular Data  Generation and Evaluation in Learning Analytics(https://arxiv.org/abs/2401.06883)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Privacy poses a significant obstacle to the progress of learning analytics (LA), presenting challenges like inadequate anonymization and data misuse that current solutions struggle to address. Synthetic data emerges as a potential remedy, offering robust privacy protection. However, prior LA research on synthetic data lacks thorough evaluation, essential for assessing the delicate balance between privacy and data utility. Synthetic data must not only enhance privacy but also remain practical for data analytics. Moreover, diverse LA scenarios come with varying privacy and utility needs, making the selection of an appropriate synthetic data approach a pressing challenge. To address these gaps, we propose a comprehensive evaluation of synthetic data, which encompasses three dimensions of synthetic data quality, namely resemblance, utility, and privacy. We apply this evaluation to three distinct LA datasets, using three different synthetic data generation methods. Our results show that synthetic data can maintain similar utility (i.e., predictive performance) as real data, while preserving privacy. Furthermore, considering different privacy and data utility requirements in different LA scenarios, we make customized recommendations for synthetic data generation. This paper not only presents a comprehensive evaluation of synthetic data but also illustrates its potential in mitigating privacy concerns within the field of LA, thus contributing to a wider application of synthetic data in LA and promoting a better practice for open science.</li>
</ul>

<h3>Title: Analyses and Concerns in Precision Medicine: A Statistical Perspective</h3>
<ul>
<li><strong>Authors: </strong>Xiaofei Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06899">https://arxiv.org/abs/2401.06899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06899">https://arxiv.org/pdf/2401.06899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06899]] Analyses and Concerns in Precision Medicine: A Statistical Perspective(https://arxiv.org/abs/2401.06899)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>This article explores the critical role of statistical analysis in precision medicine. It discusses how personalized healthcare is enhanced by statistical methods that interpret complex, multidimensional datasets, focusing on predictive modeling, machine learning algorithms, and data visualization techniques. The paper addresses challenges in data integration and interpretation, particularly with diverse data sources like electronic health records (EHRs) and genomic data. It also delves into ethical considerations such as patient privacy and data security. In addition, the paper highlights the evolution of statistical analysis in medicine, core statistical methodologies in precision medicine, and future directions in the field, emphasizing the integration of artificial intelligence (AI) and machine learning (ML).</li>
</ul>

<h3>Title: Comparing GPT-4 and Open-Source Language Models in Misinformation  Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Tyler Vergho, Jean-Francois Godbout, Reihaneh Rabbany, Kellin Pelrine</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06920">https://arxiv.org/abs/2401.06920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06920">https://arxiv.org/pdf/2401.06920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06920]] Comparing GPT-4 and Open-Source Language Models in Misinformation  Mitigation(https://arxiv.org/abs/2401.06920)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent large language models (LLMs) have been shown to be effective for misinformation detection. However, the choice of LLMs for experiments varies widely, leading to uncertain conclusions. In particular, GPT-4 is known to be strong in this domain, but it is closed source, potentially expensive, and can show instability between different versions. Meanwhile, alternative LLMs have given mixed results. In this work, we show that Zephyr-7b presents a consistently viable alternative, overcoming key limitations of commonly used approaches like Llama-2 and GPT-3.5. This provides the research community with a solid open-source option and shows open-source models are gradually catching up on this task. We then highlight how GPT-3.5 exhibits unstable performance, such that this very widely used model could provide misleading results in misinformation detection. Finally, we validate new tools including approaches to structured output and the latest version of GPT-4 (Turbo), showing they do not compromise performance, thus unlocking them for future research and potentially enabling more complex pipelines for misinformation mitigation.</li>
</ul>

<h3>Title: Accelerated Sampling of Rare Events using a Neural Network Bias  Potential</h3>
<ul>
<li><strong>Authors: </strong>Xinru Hua, Rasool Ahmad, Jose Blanchet, Wei Cai</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06936">https://arxiv.org/abs/2401.06936</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06936">https://arxiv.org/pdf/2401.06936</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06936]] Accelerated Sampling of Rare Events using a Neural Network Bias  Potential(https://arxiv.org/abs/2401.06936)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>In the field of computational physics and material science, the efficient sampling of rare events occurring at atomic scale is crucial. It aids in understanding mechanisms behind a wide range of important phenomena, including protein folding, conformal changes, chemical reactions and materials diffusion and deformation. Traditional simulation methods, such as Molecular Dynamics and Monte Carlo, often prove inefficient in capturing the timescale of these rare events by brute force. In this paper, we introduce a practical approach by combining the idea of importance sampling with deep neural networks (DNNs) that enhance the sampling of these rare events. In particular, we approximate the variance-free bias potential function with DNNs which is trained to maximize the probability of rare event transition under the importance potential function. This method is easily scalable to high-dimensional problems and provides robust statistical guarantees on the accuracy of the estimated probability of rare event transition. Furthermore, our algorithm can actively generate and learn from any successful samples, which is a novel improvement over existing methods. Using a 2D system as a test bed, we provide comparisons between results obtained from different training strategies, traditional Monte Carlo sampling and numerically solved optimal bias potential function under different temperatures. Our numerical results demonstrate the efficacy of the DNN-based importance sampling of rare events.</li>
</ul>

<h3>Title: 3D Object Detection and High-Resolution Traffic Parameters Extraction  Using Low-Resolution LiDAR Data</h3>
<ul>
<li><strong>Authors: </strong>Linlin Zhang, Xiang Yu, Armstrong Aboah, Yaw Adu-Gyamfi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06946">https://arxiv.org/abs/2401.06946</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06946">https://arxiv.org/pdf/2401.06946</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06946]] 3D Object Detection and High-Resolution Traffic Parameters Extraction  Using Low-Resolution LiDAR Data(https://arxiv.org/abs/2401.06946)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Traffic volume data collection is a crucial aspect of transportation engineering and urban planning, as it provides vital insights into traffic patterns, congestion, and infrastructure efficiency. Traditional manual methods of traffic data collection are both time-consuming and costly. However, the emergence of modern technologies, particularly Light Detection and Ranging (LiDAR), has revolutionized the process by enabling efficient and accurate data collection. Despite the benefits of using LiDAR for traffic data collection, previous studies have identified two major limitations that have impeded its widespread adoption. These are the need for multiple LiDAR systems to obtain complete point cloud information of objects of interest, as well as the labor-intensive process of annotating 3D bounding boxes for object detection tasks. In response to these challenges, the current study proposes an innovative framework that alleviates the need for multiple LiDAR systems and simplifies the laborious 3D annotation process. To achieve this goal, the study employed a single LiDAR system, that aims at reducing the data acquisition cost and addressed its accompanying limitation of missing point cloud information by developing a Point Cloud Completion (PCC) framework to fill in missing point cloud information using point density. Furthermore, we also used zero-shot learning techniques to detect vehicles and pedestrians, as well as proposed a unique framework for extracting low to high features from the object of interest, such as height, acceleration, and speed. Using the 2D bounding box detection and extracted height information, this study is able to generate 3D bounding boxes automatically without human intervention.</li>
</ul>

<h3>Title: E^2-LLM: Efficient and Extreme Length Extension of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaheng Liu, Zhiqi Bai, Yuanxing Zhang, Chenchen Zhang, Yu Zhang, Ge Zhang, Jiakai Wang, Haoran Que, Yukang Chen, Wenbo Su, Tiezheng Ge, Jie Fu, Wenhu Chen, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06951">https://arxiv.org/abs/2401.06951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06951">https://arxiv.org/pdf/2401.06951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06951]] E^2-LLM: Efficient and Extreme Length Extension of Large Language Models(https://arxiv.org/abs/2401.06951)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. Existing long-context extension methods usually need additional training procedures to support corresponding long-context windows, where the long-context training data (e.g., 32k) is needed, and high GPU training costs are assumed. To address the aforementioned issues, we propose an Efficient and Extreme length extension method for Large Language Models, called E 2 -LLM, with only one training procedure and dramatically reduced computation cost, which also removes the need to collect long-context data. Concretely, first, the training data of our E 2 -LLM only requires a short length (e.g., 4k), which reduces the tuning cost greatly. Second, the training procedure on the short training context window is performed only once time, and we can support different evaluation context windows at inference. Third, in E 2 - LLM, based on RoPE position embeddings, we introduce two different augmentation methods on the scale and position index parameters for different samples in training. It aims to make the model more robust to the different relative differences when directly interpolating the arbitrary context length at inference. Comprehensive experimental results on multiple benchmark datasets demonstrate the effectiveness of our E 2 -LLM on challenging long-context tasks.</li>
</ul>

<h3>Title: Reinforcement Learning for Scalable Train Timetable Rescheduling with  Graph Representation</h3>
<ul>
<li><strong>Authors: </strong>Peng Yue, Yaochu Jin, Xuewu Dai, Zhenhua Feng, Dongliang Cui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06952">https://arxiv.org/abs/2401.06952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06952">https://arxiv.org/pdf/2401.06952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06952]] Reinforcement Learning for Scalable Train Timetable Rescheduling with  Graph Representation(https://arxiv.org/abs/2401.06952)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Train timetable rescheduling (TTR) aims to promptly restore the original operation of trains after unexpected disturbances or disruptions. Currently, this work is still done manually by train dispatchers, which is challenging to maintain performance under various problem instances. To mitigate this issue, this study proposes a reinforcement learning-based approach to TTR, which makes the following contributions compared to existing work. First, we design a simple directed graph to represent the TTR problem, enabling the automatic extraction of informative states through graph neural networks. Second, we reformulate the construction process of TTR's solution, not only decoupling the decision model from the problem size but also ensuring the generated scheme's feasibility. Third, we design a learning curriculum for our model to handle the scenarios with different levels of delay. Finally, a simple local search method is proposed to assist the learned decision model, which can significantly improve solution quality with little additional computation cost, further enhancing the practical value of our method. Extensive experimental results demonstrate the effectiveness of our method. The learned decision model can achieve better performance for various problems with varying degrees of train delay and different scales when compared to handcrafted rules and state-of-the-art solvers.</li>
</ul>

<h3>Title: FedDriveScore: Federated Scoring Driving Behavior with a Mixture of  Metric Distributions</h3>
<ul>
<li><strong>Authors: </strong>Lin Lu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06953">https://arxiv.org/abs/2401.06953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06953">https://arxiv.org/pdf/2401.06953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06953]] FedDriveScore: Federated Scoring Driving Behavior with a Mixture of  Metric Distributions(https://arxiv.org/abs/2401.06953)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, fair</a></li>
<li><strong>Abstract: </strong>Scoring the driving performance of various drivers on a unified scale, based on how safe or economical they drive on their daily trips, is essential for the driver profile task. Connected vehicles provide the opportunity to collect real-world driving data, which is advantageous for constructing scoring models. However, the lack of pre-labeled scores impede the use of supervised regression models and the data privacy issues hinder the way of traditionally data-centralized learning on the cloud side for model training. To address them, an unsupervised scoring method is presented without the need for labels while still preserving fairness and objectiveness compared to subjective scoring strategies. Subsequently, a federated learning framework based on vehicle-cloud collaboration is proposed as a privacy-friendly alternative to centralized learning. This framework includes a consistently federated version of the scoring method to reduce the performance degradation of the global scoring model caused by the statistical heterogeneous challenge of local data. Theoretical and experimental analysis demonstrate that our federated scoring model is consistent with the utility of the centrally learned counterpart and is effective in evaluating driving performance.</li>
</ul>

<h3>Title: Bridging the Preference Gap between Retrievers and LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zixuan Ke, Weize Kong, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06954">https://arxiv.org/abs/2401.06954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06954">https://arxiv.org/pdf/2401.06954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06954]] Bridging the Preference Gap between Retrievers and LLMs(https://arxiv.org/abs/2401.06954)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated superior results across a wide range of tasks, while retrieval has long been established as an effective means of obtaining task-relevant information for humans. Retrieval-augmented Generation (RAG) are known for their effectiveness in knowledge-intensive tasks by locating relevant information and placing it within the context window of the LLM. However, the relationship between retrievers and LLMs is still under-investigated. Most existing work treats the retriever and the LLM as independent components and leaves a gap between retrieving human-friendly information and assembling a LLM-friendly context. In this work, we examine a novel bridge model, validate the ranking and selection assumptions in retrievers in the context of RAG, and propose a training framework that chains together supervised and reinforcement learning to learn a bridge model. Empirical results demonstrate the effectiveness of our method in both question-answering and personalized generation tasks.</li>
</ul>

<h3>Title: Transformer for Object Re-Identification: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Mang Ye, Shuoyi Chen, Chenyue Li, Wei-Shi Zheng, David Crandall, Bo Du</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06960">https://arxiv.org/abs/2401.06960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06960">https://arxiv.org/pdf/2401.06960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06960]] Transformer for Object Re-Identification: A Survey(https://arxiv.org/abs/2401.06960)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Object Re-Identification (Re-ID) aims to identify and retrieve specific objects from varying viewpoints. For a prolonged period, this field has been predominantly driven by deep convolutional neural networks. In recent years, the Transformer has witnessed remarkable advancements in computer vision, prompting an increasing body of research to delve into the application of Transformer in Re-ID. This paper provides a comprehensive review and in-depth analysis of the Transformer-based Re-ID. In categorizing existing works into Image/Video-Based Re-ID, Re-ID with limited data/annotations, Cross-Modal Re-ID, and Special Re-ID Scenarios, we thoroughly elucidate the advantages demonstrated by the Transformer in addressing a multitude of challenges across these domains. Considering the trending unsupervised Re-ID, we propose a new Transformer baseline, UntransReID, achieving state-of-the-art performance on both single-/cross modal tasks. Besides, this survey also covers a wide range of Re-ID research objects, including progress in animal Re-ID. Given the diversity of species in animal Re-ID, we devise a standardized experimental benchmark and conduct extensive experiments to explore the applicability of Transformer for this task to facilitate future research. Finally, we discuss some important yet under-investigated open issues in the big foundation model era, we believe it will serve as a new handbook for researchers in this field.</li>
</ul>

<h3>Title: CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs'  Mathematical Reasoning Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Yujun Mao, Yoon Kim, Yilun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06961">https://arxiv.org/abs/2401.06961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06961">https://arxiv.org/pdf/2401.06961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06961]] CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs'  Mathematical Reasoning Capabilities(https://arxiv.org/abs/2401.06961)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent large language models (LLMs) have shown indications of mathematical reasoning ability. However it has not been clear how they would fare on more challenging competition-level problems. And while self-generated verbalizations of intermediate reasoning steps (i.e., chain-of-thought prompting) have been shown to be helpful, whether LLMs can make use of helpful side information such as problem-specific hints has not been investigated before. In this paper, we propose a challenging benchmark dataset for enabling such analyses. The Concept and Hint-Annotated Math Problems (CHAMP) consists of high school math competition problems, annotated with concepts, or general math facts, and hints, or problem-specific tricks. These annotations allow us to explore the effects of additional information, such as relevant hints, misleading concepts, or related problems. This benchmark is difficult, with the best model only scoring 58.1% in standard settings. With concepts and hints, performance sometimes improves, indicating that some models can make use of such side information. We further annotate model-generated solutions for their correctness. Using this corpus, we find that models often arrive at the correct final answer through wrong reasoning steps. In addition, we test whether models are able to verify these solutions, and find that most models struggle. The dataset and code are available on the project website.</li>
</ul>

<h3>Title: Domain Adaptation for Large-Vocabulary Object Detectors</h3>
<ul>
<li><strong>Authors: </strong>Kai Jiang, Jiaxing Huang, Weiying Xie, Yunsong Li, Ling Shao, Shijian Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06969">https://arxiv.org/abs/2401.06969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06969">https://arxiv.org/pdf/2401.06969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06969]] Domain Adaptation for Large-Vocabulary Object Detectors(https://arxiv.org/abs/2401.06969)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Large-vocabulary object detectors (LVDs) aim to detect objects of many categories, which learn super objectness features and can locate objects accurately while applied to various downstream data. However, LVDs often struggle in recognizing the located objects due to domain discrepancy in data distribution and object vocabulary. At the other end, recent vision-language foundation models such as CLIP demonstrate superior open-vocabulary recognition capability. This paper presents KGD, a Knowledge Graph Distillation technique that exploits the implicit knowledge graphs (KG) in CLIP for effectively adapting LVDs to various downstream domains. KGD consists of two consecutive stages: 1) KG extraction that employs CLIP to encode downstream domain data as nodes and their feature distances as edges, constructing KG that inherits the rich semantic relations in CLIP explicitly; and 2) KG encapsulation that transfers the extracted KG into LVDs to enable accurate cross-domain object classification. In addition, KGD can extract both visual and textual KG independently, providing complementary vision and language knowledge for object localization and object classification in detection tasks over various downstream domains. Experiments over multiple widely adopted detection benchmarks show that KGD outperforms the state-of-the-art consistently by large margins.</li>
</ul>

<h3>Title: TemporalAugmenter: An Ensemble Recurrent Based Deep Learning Approach  for Signal Classification</h3>
<ul>
<li><strong>Authors: </strong>Nelly Elsayed, Constantinos L. Zekios, Navid Asadizanjani, Zag ElSayed</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06970">https://arxiv.org/abs/2401.06970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06970">https://arxiv.org/pdf/2401.06970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06970]] TemporalAugmenter: An Ensemble Recurrent Based Deep Learning Approach  for Signal Classification(https://arxiv.org/abs/2401.06970)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Ensemble modeling has been widely used to solve complex problems as it helps to improve overall performance and generalization. In this paper, we propose a novel TemporalAugmenter approach based on ensemble modeling for augmenting the temporal information capturing for long-term and short-term dependencies in data integration of two variations of recurrent neural networks in two learning streams to obtain the maximum possible temporal extraction. Thus, the proposed model augments the extraction of temporal dependencies. In addition, the proposed approach reduces the preprocessing and prior stages of feature extraction, which reduces the required energy to process the models built upon the proposed TemporalAugmenter approach, contributing towards green AI. Moreover, the proposed model can be simply integrated into various domains including industrial, medical, and human-computer interaction applications. Our proposed approach empirically evaluated the speech emotion recognition, electrocardiogram signal, and signal quality examination tasks as three different signals with varying complexity and different temporal dependency features.</li>
</ul>

<h3>Title: Class-Imbalanced Semi-Supervised Learning for Large-Scale Point Cloud  Semantic Segmentation via Decoupling Optimization</h3>
<ul>
<li><strong>Authors: </strong>Mengtian Li, Shaohui Lin, Zihan Wang, Yunhang Shen, Baochang Zhang, Lizhuang Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06975">https://arxiv.org/abs/2401.06975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06975">https://arxiv.org/pdf/2401.06975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06975]] Class-Imbalanced Semi-Supervised Learning for Large-Scale Point Cloud  Semantic Segmentation via Decoupling Optimization(https://arxiv.org/abs/2401.06975)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised learning (SSL), thanks to the significant reduction of data annotation costs, has been an active research topic for large-scale 3D scene understanding. However, the existing SSL-based methods suffer from severe training bias, mainly due to class imbalance and long-tail distributions of the point cloud data. As a result, they lead to a biased prediction for the tail class segmentation. In this paper, we introduce a new decoupling optimization framework, which disentangles feature representation learning and classifier in an alternative optimization manner to shift the bias decision boundary effectively. In particular, we first employ two-round pseudo-label generation to select unlabeled points across head-to-tail classes. We further introduce multi-class imbalanced focus loss to adaptively pay more attention to feature learning across head-to-tail classes. We fix the backbone parameters after feature learning and retrain the classifier using ground-truth points to update its parameters. Extensive experiments demonstrate the effectiveness of our method outperforming previous state-of-the-art methods on both indoor and outdoor 3D point cloud datasets (i.e., S3DIS, ScanNet-V2, Semantic3D, and SemanticKITTI) using 1% and 1pt evaluation.</li>
</ul>

<h3>Title: ENTED: Enhanced Neural Texture Extraction and Distribution for  Reference-based Blind Face Restoration</h3>
<ul>
<li><strong>Authors: </strong>Yuen-Fui Lau, Tianjia Zhang, Zhefan Rao, Qifeng Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06978">https://arxiv.org/abs/2401.06978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06978">https://arxiv.org/pdf/2401.06978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06978]] ENTED: Enhanced Neural Texture Extraction and Distribution for  Reference-based Blind Face Restoration(https://arxiv.org/abs/2401.06978)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We present ENTED, a new framework for blind face restoration that aims to restore high-quality and realistic portrait images. Our method involves repairing a single degraded input image using a high-quality reference image. We utilize a texture extraction and distribution framework to transfer high-quality texture features between the degraded input and reference image. However, the StyleGAN-like architecture in our framework requires high-quality latent codes to generate realistic images. The latent code extracted from the degraded input image often contains corrupted features, making it difficult to align the semantic information from the input with the high-quality textures from the reference. To overcome this challenge, we employ two special techniques. The first technique, inspired by vector quantization, replaces corrupted semantic features with high-quality code words. The second technique generates style codes that carry photorealistic texture information from a more informative latent space developed using the high-quality features in the reference image's manifold. Extensive experiments conducted on synthetic and real-world datasets demonstrate that our method produces results with more realistic contextual details and outperforms state-of-the-art methods. A thorough ablation study confirms the effectiveness of each proposed module.</li>
</ul>

<h3>Title: Gradient Coreset for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Durga Sivasubramanian, Lokesh Nagalapatti, Rishabh Iyer, Ganesh Ramakrishnan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06989">https://arxiv.org/abs/2401.06989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06989">https://arxiv.org/pdf/2401.06989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06989]] Gradient Coreset for Federated Learning(https://arxiv.org/abs/2401.06989)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is used to learn machine learning models with data that is partitioned across multiple clients, including resource-constrained edge devices. It is therefore important to devise solutions that are efficient in terms of compute, communication, and energy consumption, while ensuring compliance with the FL framework's privacy requirements. Conventional approaches to these problems select a weighted subset of the training dataset, known as coreset, and learn by fitting models on it. Such coreset selection approaches are also known to be robust to data noise. However, these approaches rely on the overall statistics of the training data and are not easily extendable to the FL setup. In this paper, we propose an algorithm called Gradient based Coreset for Robust and Efficient Federated Learning (GCFL) that selects a coreset at each client, only every $K$ communication rounds and derives updates only from it, assuming the availability of a small validation dataset at the server. We demonstrate that our coreset selection technique is highly effective in accounting for noise in clients' data. We conduct experiments using four real-world datasets and show that GCFL is (1) more compute and energy efficient than FL, (2) robust to various kinds of noise in both the feature space and labels, (3) preserves the privacy of the validation dataset, and (4) introduces a small communication overhead but achieves significant gains in performance, particularly in cases when the clients' data is noisy.</li>
</ul>

<h3>Title: UniVision: A Unified Framework for Vision-Centric 3D Perception</h3>
<ul>
<li><strong>Authors: </strong>Yu Hong, Qian Liu, Huayuan Cheng, Danjiao Ma, Hang Dai, Yu Wang, Guangzhi Cao, Yong Ding</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.06994">https://arxiv.org/abs/2401.06994</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.06994">https://arxiv.org/pdf/2401.06994</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.06994]] UniVision: A Unified Framework for Vision-Centric 3D Perception(https://arxiv.org/abs/2401.06994)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>The past few years have witnessed the rapid development of vision-centric 3D perception in autonomous driving. Although the 3D perception models share many structural and conceptual similarities, there still exist gaps in their feature representations, data formats, and objectives, posing challenges for unified and efficient 3D perception framework design. In this paper, we present UniVision, a simple and efficient framework that unifies two major tasks in vision-centric 3D perception, \ie, occupancy prediction and object detection. Specifically, we propose an explicit-implicit view transform module for complementary 2D-3D feature transformation. We propose a local-global feature extraction and fusion module for efficient and adaptive voxel and BEV feature extraction, enhancement, and interaction. Further, we propose a joint occupancy-detection data augmentation strategy and a progressive loss weight adjustment strategy which enables the efficiency and stability of the multi-task framework training. We conduct extensive experiments for different perception tasks on four public benchmarks, including nuScenes LiDAR segmentation, nuScenes detection, OpenOccupancy, and Occ3D. UniVision achieves state-of-the-art results with +1.5 mIoU, +1.8 NDS, +1.5 mIoU, and +1.8 mIoU gains on each benchmark, respectively. We believe that the UniVision framework can serve as a high-performance baseline for the unified vision-centric 3D perception task. The code will be available at \url{https://github.com/Cc-Hy/UniVision}.</li>
</ul>

<h3>Title: Extending LLMs' Context Window with 100 Samples</h3>
<ul>
<li><strong>Authors: </strong>Yikai Zhang, Junlong Li, Pengfei Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07004">https://arxiv.org/abs/2401.07004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07004">https://arxiv.org/pdf/2401.07004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07004]] Extending LLMs' Context Window with 100 Samples(https://arxiv.org/abs/2401.07004)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are known to have limited extrapolation ability beyond their pre-trained context window, constraining their application in downstream tasks with lengthy inputs. Recent studies have sought to extend LLMs' context window by modifying rotary position embedding (RoPE), a popular position encoding method adopted by well-known LLMs such as LLaMA, PaLM, and GPT-NeoX. However, prior works like Position Interpolation (PI) and YaRN are resource-intensive and lack comparative experiments to assess their applicability. In this work, we identify the inherent need for LLMs' attention entropy (i.e. the information entropy of attention scores) to maintain stability and introduce a novel extension to RoPE which combines adjusting RoPE's base frequency and scaling the attention logits to help LLMs efficiently adapt to a larger context window. We validate the superiority of our method in both fine-tuning performance and robustness across different context window sizes on various context-demanding tasks. Notably, our method extends the context window of LLaMA-2-7B-Chat to 16,384 with only 100 samples and 6 training steps, showcasing extraordinary efficiency. Finally, we also explore how data compositions and training curricula affect context window extension for specific downstream tasks, suggesting fine-tuning LLMs with lengthy conversations as a good starting point. We release our code and SFT data at https://github.com/GAIR-NLP/Entropy-ABF.</li>
</ul>

<h3>Title: Joint Extraction of Uyghur Medicine Knowledge with Edge Computing</h3>
<ul>
<li><strong>Authors: </strong>Fan Lu, Quan Qi, Huaibin Qin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07009">https://arxiv.org/abs/2401.07009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07009">https://arxiv.org/pdf/2401.07009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07009]] Joint Extraction of Uyghur Medicine Knowledge with Edge Computing(https://arxiv.org/abs/2401.07009)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction</a></li>
<li><strong>Abstract: </strong>Medical knowledge extraction methods based on edge computing deploy deep learning models on edge devices to achieve localized entity and relation extraction. This approach avoids transferring substantial sensitive data to cloud data centers, effectively safeguarding the privacy of healthcare services. However, existing relation extraction methods mainly employ a sequential pipeline approach, which classifies relations between determined entities after entity recognition. This mode faces challenges such as error propagation between tasks, insufficient consideration of dependencies between the two subtasks, and the neglect of interrelations between different relations within a sentence. To address these challenges, a joint extraction model with parameter sharing in edge computing is proposed, named CoEx-Bert. This model leverages shared parameterization between two models to jointly extract entities and relations. Specifically, CoEx-Bert employs two models, each separately sharing hidden layer parameters, and combines these two loss functions for joint backpropagation to optimize the model parameters. Additionally, it effectively resolves the issue of entity overlapping when extracting knowledge from unstructured Uyghur medical texts by considering contextual relations. Finally, this model is deployed on edge devices for real-time extraction and inference of Uyghur medical knowledge. Experimental results demonstrate that CoEx-Bert outperforms existing state-of-the-art methods, achieving accuracy, recall, and F1 scores of 90.65\%, 92.45\%, and 91.54\%, respectively, in the Uyghur traditional medical literature dataset. These improvements represent a 6.45\% increase in accuracy, a 9.45\% increase in recall, and a 7.95\% increase in F1 score compared to the baseline.</li>
</ul>

<h3>Title: Weak Labeling for Cropland Mapping in Africa</h3>
<ul>
<li><strong>Authors: </strong>Gilles Quentin Hacheme, Akram Zaytar, Girmaw Abebe Tadesse, Caleb Robinson, Rahul Dodhia, Juan M. Lavista Ferres, Stephen Wood</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07014">https://arxiv.org/abs/2401.07014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07014">https://arxiv.org/pdf/2401.07014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07014]] Weak Labeling for Cropland Mapping in Africa(https://arxiv.org/abs/2401.07014)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, segmentation</a></li>
<li><strong>Abstract: </strong>Cropland mapping can play a vital role in addressing environmental, agricultural, and food security challenges. However, in the context of Africa, practical applications are often hindered by the limited availability of high-resolution cropland maps. Such maps typically require extensive human labeling, thereby creating a scalability bottleneck. To address this, we propose an approach that utilizes unsupervised object clustering to refine existing weak labels, such as those obtained from global cropland maps. The refined labels, in conjunction with sparse human annotations, serve as training data for a semantic segmentation network designed to identify cropland areas. We conduct experiments to demonstrate the benefits of the improved weak labels generated by our method. In a scenario where we train our model with only 33 human-annotated labels, the F_1 score for the cropland category increases from 0.53 to 0.84 when we add the mined negative labels.</li>
</ul>

<h3>Title: Edge-Enabled Anomaly Detection and Information Completion for Social  Network Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Fan Lu, Quan Qi, Huaibin Qin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07022">https://arxiv.org/abs/2401.07022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07022">https://arxiv.org/pdf/2401.07022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07022]] Edge-Enabled Anomaly Detection and Information Completion for Social  Network Knowledge Graphs(https://arxiv.org/abs/2401.07022)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>In the rapidly advancing information era, various human behaviors are being precisely recorded in the form of data, including identity information, criminal records, and communication data. Law enforcement agencies can effectively maintain social security and precisely combat criminal activities by analyzing the aforementioned data. In comparison to traditional data analysis methods, deep learning models, relying on the robust computational power in cloud centers, exhibit higher accuracy in extracting data features and inferring data. However, within the architecture of cloud centers, the transmission of data from end devices introduces significant latency, hindering real-time inference of data. Furthermore, low-latency edge computing architectures face limitations in direct deployment due to relatively weak computing and storage capacities of nodes. To address these challenges, a lightweight distributed knowledge graph completion architecture is proposed. Firstly, we introduce a lightweight distributed knowledge graph completion architecture that utilizes knowledge graph embedding for data analysis. Subsequently, to filter out substandard data, a personnel data quality assessment method named PDQA is proposed. Lastly, we present a model pruning algorithm that significantly reduces the model size while maximizing performance, enabling lightweight deployment. In experiments, we compare the effects of 11 advanced models on completing the knowledge graph of public security personnel information. The results indicate that the RotatE model outperforms other models significantly in knowledge graph completion, with the pruned model size reduced by 70\%, and hits@10 reaching 86.97\%.}</li>
</ul>

<h3>Title: Code Security Vulnerability Repair Using Reinforcement Learning with  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nafis Tanveer Islam, Peyman Najafirad</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07031">https://arxiv.org/abs/2401.07031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07031">https://arxiv.org/pdf/2401.07031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07031]] Code Security Vulnerability Repair Using Reinforcement Learning with  Large Language Models(https://arxiv.org/abs/2401.07031)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>With the recent advancement of Large Language Models (LLMs), generating functionally correct code has become less complicated for a wide array of developers. While using LLMs has sped up the functional development process, it poses a heavy risk to code security. Code generation with proper security measures using LLM is a significantly more challenging task than functional code generation. Security measures may include adding a pair of lines of code with the original code, consisting of null pointer checking or prepared statements for SQL injection prevention. Currently, available code repair LLMs generate code repair by supervised fine-tuning, where the model looks at cross-entropy loss. However, the original and repaired codes are mostly similar in functionality and syntactically, except for a few (1-2) lines, which act as security measures. This imbalance between the lines needed for security measures and the functional code enforces the supervised fine-tuned model to prioritize generating functional code without adding proper security measures, which also benefits the model by resulting in minimal loss. Therefore, in this work, for security hardening and strengthening of generated code from LLMs, we propose a reinforcement learning-based method for program-specific repair with the combination of semantic and syntactic reward mechanisms that focus heavily on adding security and functional measures in the code, respectively.</li>
</ul>

<h3>Title: xCoT: Cross-lingual Instruction Tuning for Cross-lingual  Chain-of-Thought Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Linzheng Chai, Jian Yang, Tao Sun, Hongcheng Guo, Jiaheng Liu, Bing Wang, Xiannian Liang, Jiaqi Bai, Tongliang Li, Qiyao Peng, Zhoujun Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07037">https://arxiv.org/abs/2401.07037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07037">https://arxiv.org/pdf/2401.07037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07037]] xCoT: Cross-lingual Instruction Tuning for Cross-lingual  Chain-of-Thought Reasoning(https://arxiv.org/abs/2401.07037)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-thought (CoT) has emerged as a powerful technique to elicit reasoning in large language models and improve a variety of downstream tasks. CoT mainly demonstrates excellent performance in English, but its usage in low-resource languages is constrained due to poor language generalization. To bridge the gap among different languages, we propose a cross-lingual instruction fine-tuning framework (xCOT) to transfer knowledge from high-resource languages to low-resource languages. Specifically, the multilingual instruction training data (xCOT-INSTRUCT) is created to encourage the semantic alignment of multiple languages. We introduce cross-lingual in-context few-shot learning (xICL)) to accelerate multilingual agreement in instruction tuning, where some fragments of source languages in examples are randomly substituted by their counterpart translations of target languages. During multilingual instruction tuning, we adopt the randomly online CoT strategy to enhance the multilingual reasoning ability of the large language model by first translating the query to another language and then answering in English. To further facilitate the language transfer, we leverage the high-resource CoT to supervise the training of low-resource languages with cross-lingual distillation. Experimental results on previous benchmarks demonstrate the superior performance of xCoT in reducing the gap among different languages, highlighting its potential to reduce the cross-lingual gap.</li>
</ul>

<h3>Title: COIN: Chance-Constrained Imitation Learning for Uncertainty-aware  Adaptive Resource Oversubscription Policy</h3>
<ul>
<li><strong>Authors: </strong>Lu Wang, Mayukh Das, Fangkai Yang, Chao Duo, Bo Qiao, Hang Dong, Si Qin, Chetan Bansal, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07051">https://arxiv.org/abs/2401.07051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07051">https://arxiv.org/pdf/2401.07051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07051]] COIN: Chance-Constrained Imitation Learning for Uncertainty-aware  Adaptive Resource Oversubscription Policy(https://arxiv.org/abs/2401.07051)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We address the challenge of learning safe and robust decision policies in presence of uncertainty in context of the real scientific problem of adaptive resource oversubscription to enhance resource efficiency while ensuring safety against resource congestion risk. Traditional supervised prediction or forecasting models are ineffective in learning adaptive policies whereas standard online optimization or reinforcement learning is difficult to deploy on real systems. Offline methods such as imitation learning (IL) are ideal since we can directly leverage historical resource usage telemetry. But, the underlying aleatoric uncertainty in such telemetry is a critical bottleneck. We solve this with our proposed novel chance-constrained imitation learning framework, which ensures implicit safety against uncertainty in a principled manner via a combination of stochastic (chance) constraints on resource congestion risk and ensemble value functions. This leads to substantial ($\approx 3-4\times$) improvement in resource efficiency and safety in many oversubscription scenarios, including resource management in cloud services.</li>
</ul>

<h3>Title: GoMatching: A Simple Baseline for Video Text Spotting via Long and Short  Term Matching</h3>
<ul>
<li><strong>Authors: </strong>Haibin He, Maoyuan Ye, Jing Zhang, Juhua Liu, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07080">https://arxiv.org/abs/2401.07080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07080">https://arxiv.org/pdf/2401.07080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07080]] GoMatching: A Simple Baseline for Video Text Spotting via Long and Short  Term Matching(https://arxiv.org/abs/2401.07080)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Beyond the text detection and recognition tasks in image text spotting, video text spotting presents an augmented challenge with the inclusion of tracking. While advanced end-to-end trainable methods have shown commendable performance, the pursuit of multi-task optimization may pose the risk of producing sub-optimal outcomes for individual tasks. In this paper, we highlight a main bottleneck in the state-of-the-art video text spotter: the limited recognition capability. In response to this issue, we propose to efficiently turn an off-the-shelf query-based image text spotter into a specialist on video and present a simple baseline termed GoMatching, which focuses the training efforts on tracking while maintaining strong recognition performance. To adapt the image text spotter to video datasets, we add a rescoring head to rescore each detected instance's confidence via efficient tuning, leading to a better tracking candidate pool. Additionally, we design a long-short term matching module, termed LST-Matcher, to enhance the spotter's tracking capability by integrating both long- and short-term matching results via Transformer. Based on the above simple designs, GoMatching achieves impressive performance on two public benchmarks, e.g., setting a new record on the ICDAR15-video dataset, and one novel test set with arbitrary-shaped text, while saving considerable training budgets. The code will be released at https://github.com/Hxyz-123/GoMatching.</li>
</ul>

<h3>Title: Exploring Adversarial Attacks against Latent Diffusion Model from the  Perspective of Adversarial Transferability</h3>
<ul>
<li><strong>Authors: </strong>Junxi Chen, Junhao Dong, Xiaohua Xie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07087">https://arxiv.org/abs/2401.07087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07087">https://arxiv.org/pdf/2401.07087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07087]] Exploring Adversarial Attacks against Latent Diffusion Model from the  Perspective of Adversarial Transferability(https://arxiv.org/abs/2401.07087)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, diffusion</a></li>
<li><strong>Abstract: </strong>Recently, many studies utilized adversarial examples (AEs) to raise the cost of malicious image editing and copyright violation powered by latent diffusion models (LDMs). Despite their successes, a few have studied the surrogate model they used to generate AEs. In this paper, from the perspective of adversarial transferability, we investigate how the surrogate model's property influences the performance of AEs for LDMs. Specifically, we view the time-step sampling in the Monte-Carlo-based (MC-based) adversarial attack as selecting surrogate models. We find that the smoothness of surrogate models at different time steps differs, and we substantially improve the performance of the MC-based AEs by selecting smoother surrogate models. In the light of the theoretical framework on adversarial transferability in image classification, we also conduct a theoretical analysis to explain why smooth surrogate models can also boost AEs for LDMs.</li>
</ul>

<h3>Title: Leveraging Large Language Models for NLG Evaluation: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Zhen Li, Xiaohan Xu, Tao Shen, Can Xu, Jia-Chen Gu, Chongyang Tao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07103">https://arxiv.org/abs/2401.07103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07103">https://arxiv.org/pdf/2401.07103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07103]] Leveraging Large Language Models for NLG Evaluation: A Survey(https://arxiv.org/abs/2401.07103)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>In the rapidly evolving domain of Natural Language Generation (NLG) evaluation, introducing Large Language Models (LLMs) has opened new avenues for assessing generated content quality, e.g., coherence, creativity, and context relevance. This survey aims to provide a thorough overview of leveraging LLMs for NLG evaluation, a burgeoning area that lacks a systematic analysis. We propose a coherent taxonomy for organizing existing LLM-based evaluation metrics, offering a structured framework to understand and compare these methods. Our detailed exploration includes critically assessing various LLM-based methodologies, as well as comparing their strengths and limitations in evaluating NLG outputs. By discussing unresolved challenges, including bias, robustness, domain-specificity, and unified evaluation, this survey seeks to offer insights to researchers and advocate for fairer and more advanced NLG evaluation techniques.</li>
</ul>

<h3>Title: EHRAgent: Code Empowers Large Language Models for Complex Tabular  Reasoning on Electronic Health Records</h3>
<ul>
<li><strong>Authors: </strong>Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda Zhu, Joyce Ho, Carl Yang, May D. Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07128">https://arxiv.org/abs/2401.07128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07128">https://arxiv.org/pdf/2401.07128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07128]] EHRAgent: Code Empowers Large Language Models for Complex Tabular  Reasoning on Electronic Health Records(https://arxiv.org/abs/2401.07128)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving. We propose EHRAgent1, an LLM agent empowered with a code interface, to autonomously generate and execute code for complex clinical tasks within electronic health records (EHRs). First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on two real-world EHR datasets show that EHRAgent outperforms the strongest LLM agent baseline by 36.48% and 12.41%, respectively. EHRAgent leverages the emerging few-shot learning capabilities of LLMs, enabling autonomous code generation and execution to tackle complex clinical tasks with minimal demonstrations.</li>
</ul>

<h3>Title: CAC 2.0: A Corrupt and Correct Logic Locking Technique Resilient to  Structural Analysis Attacks</h3>
<ul>
<li><strong>Authors: </strong>Levent Aksoy, Muhammad Yasin, Samuel Pagliarini</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07142">https://arxiv.org/abs/2401.07142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07142">https://arxiv.org/pdf/2401.07142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07142]] CAC 2.0: A Corrupt and Correct Logic Locking Technique Resilient to  Structural Analysis Attacks(https://arxiv.org/abs/2401.07142)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>Logic locking proposed to protect integrated circuits from serious hardware threats has been studied extensively over a decade. In these years, many efficient logic locking techniques have been proven to be broken. The state-of-the-art logic locking techniques, including the prominent corrupt and correct (CAC) technique, are resilient to satisfiability (SAT)-based and removal attacks, but vulnerable to structural analysis attacks. To overcome this drawback, this paper introduces an improved version of CAC, called CAC 2.0, which increases the search space of structural analysis attacks using obfuscation. To do so, CAC 2.0 locks the original circuit twice, one after another, on different nodes with different number of protected primary inputs using CAC, while hiding original protected primary inputs among decoy primary inputs. This paper also introduces an open source logic locking tool, called HIID, equipped with well-known techniques including CAC 2.0. Our experiments show that CAC 2.0 is resilient to existing SAT-based, removal, and structural analysis attacks. To achieve this, it increases the number of key inputs at most 4x and the gate-level area between 30.2% and 0.8% on circuits with low and high complexity with respect to CAC.</li>
</ul>

<h3>Title: Scalable and Efficient Methods for Uncertainty Estimation and Reduction  in Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Soyed Tuhin Ahmed</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07145">https://arxiv.org/abs/2401.07145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07145">https://arxiv.org/pdf/2401.07145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07145]] Scalable and Efficient Methods for Uncertainty Estimation and Reduction  in Deep Learning(https://arxiv.org/abs/2401.07145)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural networks (NNs) can achieved high performance in various fields such as computer vision, and natural language processing. However, deploying NNs in resource-constrained safety-critical systems has challenges due to uncertainty in the prediction caused by out-of-distribution data, and hardware non-idealities. To address the challenges of deploying NNs in resource-constrained safety-critical systems, this paper summarizes the (4th year) PhD thesis work that explores scalable and efficient methods for uncertainty estimation and reduction in deep learning, with a focus on Computation-in-Memory (CIM) using emerging resistive non-volatile memories. We tackle the inherent uncertainties arising from out-of-distribution inputs and hardware non-idealities, crucial in maintaining functional safety in automated decision-making systems. Our approach encompasses problem-aware training algorithms, novel NN topologies, and hardware co-design solutions, including dropout-based \emph{binary} Bayesian Neural Networks leveraging spintronic devices and variational inference techniques. These innovations significantly enhance OOD data detection, inference accuracy, and energy efficiency, thereby contributing to the reliability and robustness of NN implementations.</li>
</ul>

<h3>Title: Assessing the Effectiveness of Binary-Level CFI Techniques</h3>
<ul>
<li><strong>Authors: </strong>Ruturaj K. Vaidya, Prasad A. Kulkarni</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07148">https://arxiv.org/abs/2401.07148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07148">https://arxiv.org/pdf/2401.07148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07148]] Assessing the Effectiveness of Binary-Level CFI Techniques(https://arxiv.org/abs/2401.07148)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>Memory corruption is an important class of vulnerability that can be leveraged to craft control flow hijacking attacks. Control Flow Integrity (CFI) provides protection against such attacks. Application of type-based CFI policies requires information regarding the number and type of function arguments. Binary-level type recovery is inherently speculative, which motivates the need for an evaluation framework to assess the effectiveness of binary-level CFI techniques compared with their source-level counterparts, where such type information is fully and accurately accessible. In this work, we develop a novel, generalized and extensible framework to assess how the program analysis information we get from state-of-the-art binary analysis tools affects the efficacy of type-based CFI techniques. We introduce new and insightful metrics to quantitatively compare source independent CFI policies with their ground truth source aware counterparts. We leverage our framework to evaluate binary-level CFI policies implemented using program analysis information extracted from the IDA Pro binary analyzer and compared with the ground truth information obtained from the LLVM compiler, and present our observations.</li>
</ul>

<h3>Title: Discovering Command and Control Channels Using Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Cheng Wang, Akshay Kakkar, Christopher Redino, Abdul Rahman, Ajinsyam S, Ryan Clark, Daniel Radke, Tyler Cody, Lanxiao Huang, Edward Bowen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07154">https://arxiv.org/abs/2401.07154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07154">https://arxiv.org/pdf/2401.07154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07154]] Discovering Command and Control Channels Using Reinforcement Learning(https://arxiv.org/abs/2401.07154)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Command and control (C2) paths for issuing commands to malware are sometimes the only indicators of its existence within networks. Identifying potential C2 channels is often a manually driven process that involves a deep understanding of cyber tradecraft. Efforts to improve discovery of these channels through using a reinforcement learning (RL) based approach that learns to automatically carry out C2 attack campaigns on large networks, where multiple defense layers are in place serves to drive efficiency for network operators. In this paper, we model C2 traffic flow as a three-stage process and formulate it as a Markov decision process (MDP) with the objective to maximize the number of valuable hosts whose data is exfiltrated. The approach also specifically models payload and defense mechanisms such as firewalls which is a novel contribution. The attack paths learned by the RL agent can in turn help the blue team identify high-priority vulnerabilities and develop improved defense strategies. The method is evaluated on a large network with more than a thousand hosts and the results demonstrate that the agent can effectively learn attack paths while avoiding firewalls.</li>
</ul>

<h3>Title: Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhengxin Zhang, Dan Zhao, Xupeng Miao, Gabriele Oliaro, Qing Li, Yong Jiang, Zhihao Jia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07159">https://arxiv.org/abs/2401.07159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07159">https://arxiv.org/pdf/2401.07159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07159]] Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized  Large Language Models(https://arxiv.org/abs/2401.07159)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Finetuning large language models (LLMs) has been empirically effective on a variety of downstream tasks. Existing approaches to finetuning an LLM either focus on parameter-efficient finetuning, which only updates a small number of trainable parameters, or attempt to reduce the memory footprint during the training phase of the finetuning. Typically, the memory footprint during finetuning stems from three contributors: model weights, optimizer states, and intermediate activations. However, existing works still require considerable memory and none can simultaneously mitigate memory footprint for all three sources. In this paper, we present Quantized Side Tuing (QST), which enables memory-efficient and fast finetuning of LLMs by operating through a dual-stage process. First, QST quantizes an LLM's model weights into 4-bit to reduce the memory footprint of the LLM's original weights; QST also introduces a side network separated from the LLM, which utilizes the hidden states of the LLM to make task-specific predictions. Using a separate side network avoids performing backpropagation through the LLM, thus reducing the memory requirement of the intermediate activations. Furthermore, QST leverages several low-rank adaptors and gradient-free downsample modules to significantly reduce the trainable parameters, so as to save the memory footprint of the optimizer states. Experiments show that QST can reduce the total memory footprint by up to 2.3 $\times$ and speed up the finetuning process by up to 3 $\times$ while achieving competent performance compared with the state-of-the-art. When it comes to full finetuning, QST can reduce the total memory footprint up to 7 $\times$.</li>
</ul>

<h3>Title: Domain Adaptation for Sustainable Soil Management using Causal and  Contrastive Constraint Minimization</h3>
<ul>
<li><strong>Authors: </strong>Somya Sharma, Swati Sharma, Rafael Padilha, Emre Kiciman, Ranveer Chandra</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07175">https://arxiv.org/abs/2401.07175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07175">https://arxiv.org/pdf/2401.07175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07175]] Domain Adaptation for Sustainable Soil Management using Causal and  Contrastive Constraint Minimization(https://arxiv.org/abs/2401.07175)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Monitoring organic matter is pivotal for maintaining soil health and can help inform sustainable soil management practices. While sensor-based soil information offers higher-fidelity and reliable insights into organic matter changes, sampling and measuring sensor data is cost-prohibitive. We propose a multi-modal, scalable framework that can estimate organic matter from remote sensing data, a more readily available data source while leveraging sparse soil information for improving generalization. Using the sensor data, we preserve underlying causal relations among sensor attributes and organic matter. Simultaneously we leverage inherent structure in the data and train the model to discriminate among domains using contrastive learning. This causal and contrastive constraint minimization ensures improved generalization and adaptation to other domains. We also shed light on the interpretability of the framework by identifying attributes that are important for improving generalization. Identifying these key soil attributes that affect organic matter will aid in efforts to standardize data collection efforts.</li>
</ul>

<h3>Title: Reinforcement Learning from LLM Feedback to Counteract Goal  Misgeneralization</h3>
<ul>
<li><strong>Authors: </strong>Houda Nait El Barj, Theophile Sautory</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07181">https://arxiv.org/abs/2401.07181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07181">https://arxiv.org/pdf/2401.07181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07181]] Reinforcement Learning from LLM Feedback to Counteract Goal  Misgeneralization(https://arxiv.org/abs/2401.07181)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We introduce a method to address goal misgeneralization in reinforcement learning (RL), leveraging Large Language Model (LLM) feedback during training. Goal misgeneralization, a type of robustness failure in RL occurs when an agent retains its capabilities out-of-distribution yet pursues a proxy rather than the intended one. Our approach utilizes LLMs to analyze an RL agent's policies during training and identify potential failure scenarios. The RL agent is then deployed in these scenarios, and a reward model is learnt through the LLM preferences and feedback. This LLM-informed reward model is used to further train the RL agent on the original dataset. We apply our method to a maze navigation task, and show marked improvements in goal generalization, especially in cases where true and proxy goals are somewhat distinguishable and behavioral biases are pronounced. This study demonstrates how the LLM, despite its lack of task proficiency, can efficiently supervise RL agents, providing scalable oversight and valuable insights for enhancing goal-directed learning in RL through the use of LLMs.</li>
</ul>

<h3>Title: Left-right Discrepancy for Adversarial Attack on Stereo Networks</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Wang, Xiaofei Hui, Beijia Lu, Nimrod Lilith, Jun Liu, Sameer Alam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07188">https://arxiv.org/abs/2401.07188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07188">https://arxiv.org/pdf/2401.07188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07188]] Left-right Discrepancy for Adversarial Attack on Stereo Networks(https://arxiv.org/abs/2401.07188)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Stereo matching neural networks often involve a Siamese structure to extract intermediate features from left and right images. The similarity between these intermediate left-right features significantly impacts the accuracy of disparity estimation. In this paper, we introduce a novel adversarial attack approach that generates perturbation noise specifically designed to maximize the discrepancy between left and right image features. Extensive experiments demonstrate the superior capability of our method to induce larger prediction errors in stereo neural networks, e.g. outperforming existing state-of-the-art attack methods by 219% MAE on the KITTI dataset and 85% MAE on the Scene Flow dataset. Additionally, we extend our approach to include a proxy network black-box attack method, eliminating the need for access to stereo neural network. This method leverages an arbitrary network from a different vision task as a proxy to generate adversarial noise, effectively causing the stereo network to produce erroneous predictions. Our findings highlight a notable sensitivity of stereo networks to discrepancies in shallow layer features, offering valuable insights that could guide future research in enhancing the robustness of stereo vision systems.</li>
</ul>

<h3>Title: Inroads to a Structured Data Natural Language Bijection and the role of  LLM annotation</h3>
<ul>
<li><strong>Authors: </strong>Blake Vente</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07190">https://arxiv.org/abs/2401.07190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07190">https://arxiv.org/pdf/2401.07190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07190]] Inroads to a Structured Data Natural Language Bijection and the role of  LLM annotation(https://arxiv.org/abs/2401.07190)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This work finds limited evidence supporting the theory that using multiple tasks with sequence-to-sequence transformer language models can improve performance on some metrics. In particular, the multi-task generalist t5-small outperforms the specialist t5-small with a $F_1$ of $0.771$ up from $0.692$, which may point to underlying cross-task knowledge generalization. This further suggests that even with the same network, "re-using" the same data in a different way may lead to higher performance in some metrics. However, the inverse task alone is likely only an optimization strategy, since it does not yield a significant general improvement at the model sizes explored in this work. Also, adding $\approx 4500$ LLM annotated records (interlaced with the $12800$ WebNLG training records) does not substantially change automatic metric performance compared to the same t5-small model without the synthetic data. This may be due to a learning capacity bottleneck on account of model size, and decreases observed may be due to distributional differences in the corpora. Future research using larger models or human evaluation is required to more fully explain the mechanisms contributing to performance on these tasks.</li>
</ul>

<h3>Title: Crafter: Facial Feature Crafting against Inversion-based Identity Theft  on Deep Models</h3>
<ul>
<li><strong>Authors: </strong>Shiming Wang, Zhe Ji, Liyao Xiang, Hao Zhang, Xinbing Wang, Chenghu Zhou, Bo Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07205">https://arxiv.org/abs/2401.07205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07205">https://arxiv.org/pdf/2401.07205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07205]] Crafter: Facial Feature Crafting against Inversion-based Identity Theft  on Deep Models(https://arxiv.org/abs/2401.07205)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>With the increased capabilities at the edge (e.g., mobile device) and more stringent privacy requirement, it becomes a recent trend for deep learning-enabled applications to pre-process sensitive raw data at the edge and transmit the features to the backend cloud for further processing. A typical application is to run machine learning (ML) services on facial images collected from different individuals. To prevent identity theft, conventional methods commonly rely on an adversarial game-based approach to shed the identity information from the feature. However, such methods can not defend against adaptive attacks, in which an attacker takes a countermove against a known defence strategy. We propose Crafter, a feature crafting mechanism deployed at the edge, to protect the identity information from adaptive model inversion attacks while ensuring the ML tasks are properly carried out in the cloud. The key defence strategy is to mislead the attacker to a non-private prior from which the attacker gains little about the private identity. In this case, the crafted features act like poison training samples for attackers with adaptive model updates. Experimental results indicate that Crafter successfully defends both basic and possible adaptive attacks, which can not be achieved by state-of-the-art adversarial game-based methods.</li>
</ul>

<h3>Title: Application of 2D Homography for High Resolution Traffic Data Collection  using CCTV Cameras</h3>
<ul>
<li><strong>Authors: </strong>Linlin Zhang, Xiang Yu, Abdulateef Daud, Abdul Rashid Mussah, Yaw Adu-Gyamfi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07220">https://arxiv.org/abs/2401.07220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07220">https://arxiv.org/pdf/2401.07220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07220]] Application of 2D Homography for High Resolution Traffic Data Collection  using CCTV Cameras(https://arxiv.org/abs/2401.07220)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Traffic cameras remain the primary source data for surveillance activities such as congestion and incident monitoring. To date, State agencies continue to rely on manual effort to extract data from networked cameras due to limitations of the current automatic vision systems including requirements for complex camera calibration and inability to generate high resolution data. This study implements a three-stage video analytics framework for extracting high-resolution traffic data such vehicle counts, speed, and acceleration from infrastructure-mounted CCTV cameras. The key components of the framework include object recognition, perspective transformation, and vehicle trajectory reconstruction for traffic data collection. First, a state-of-the-art vehicle recognition model is implemented to detect and classify vehicles. Next, to correct for camera distortion and reduce partial occlusion, an algorithm inspired by two-point linear perspective is utilized to extracts the region of interest (ROI) automatically, while a 2D homography technique transforms the CCTV view to bird's-eye view (BEV). Cameras are calibrated with a two-layer matrix system to enable the extraction of speed and acceleration by converting image coordinates to real-world measurements. Individual vehicle trajectories are constructed and compared in BEV using two time-space-feature-based object trackers, namely Motpy and BYTETrack. The results of the current study showed about +/- 4.5% error rate for directional traffic counts, less than 10% MSE for speed bias between camera estimates in comparison to estimates from probe data sources. Extracting high-resolution data from traffic cameras has several implications, ranging from improvements in traffic management and identify dangerous driving behavior, high-risk areas for accidents, and other safety concerns, enabling proactive measures to reduce accidents and fatalities.</li>
</ul>

<h3>Title: The Effects of Data Imbalance Under a Federated Learning Approach for  Credit Risk Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Shuyao Zhang, Jordan Tay, Pedro Baiz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07234">https://arxiv.org/abs/2401.07234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07234">https://arxiv.org/pdf/2401.07234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07234]] The Effects of Data Imbalance Under a Federated Learning Approach for  Credit Risk Forecasting(https://arxiv.org/abs/2401.07234)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Credit risk forecasting plays a crucial role for commercial banks and other financial institutions in granting loans to customers and minimise the potential loss. However, traditional machine learning methods require the sharing of sensitive client information with an external server to build a global model, potentially posing a risk of security threats and privacy leakage. A newly developed privacy-preserving distributed machine learning technique known as Federated Learning (FL) allows the training of a global model without the necessity of accessing private local data directly. This investigation examined the feasibility of federated learning in credit risk assessment and showed the effects of data imbalance on model performance. Two neural network architectures, Multilayer Perceptron (MLP) and Long Short-Term Memory (LSTM), and one tree ensemble architecture, Extreme Gradient Boosting (XGBoost), were explored across three different datasets under various scenarios involving different numbers of clients and data distribution configurations. We demonstrate that federated models consistently outperform local models on non-dominant clients with smaller datasets. This trend is especially pronounced in highly imbalanced data scenarios, yielding a remarkable average improvement of 17.92% in model performance. However, for dominant clients (clients with more data), federated models may not exhibit superior performance, suggesting the need for special incentives for this type of clients to encourage their participation.</li>
</ul>

<h3>Title: Distilling Event Sequence Knowledge From Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Somin Wadhwa, Oktie Hassanzadeh, Debarun Bhattacharjya, Ken Barker, Jian Ni</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07237">https://arxiv.org/abs/2401.07237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07237">https://arxiv.org/pdf/2401.07237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07237]] Distilling Event Sequence Knowledge From Large Language Models(https://arxiv.org/abs/2401.07237)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>Event sequence models have been found to be highly effective in the analysis and prediction of events. Building such models requires availability of abundant high-quality event sequence data. In certain applications, however, clean structured event sequences are not available, and automated sequence extraction results in data that is too noisy and incomplete. In this work, we explore the use of Large Language Models (LLMs) to generate event sequences that can effectively be used for probabilistic event model construction. This can be viewed as a mechanism of distilling event sequence knowledge from LLMs. Our approach relies on a Knowledge Graph (KG) of event concepts with partial causal relations to guide the generative language model for causal event sequence generation. We show that our approach can generate high-quality event sequences, filling a knowledge gap in the input KG. Furthermore, we explore how the generated sequences can be leveraged to discover useful and more complex structured knowledge from pattern mining and probabilistic event models. We release our sequence generation code and evaluation framework, as well as corpus of event sequence data.</li>
</ul>

<h3>Title: MIMIC: Mask Image Pre-training with Mix Contrastive Fine-tuning for  Facial Expression Recognition</h3>
<ul>
<li><strong>Authors: </strong>Fan Zhang, Xiaobao Guo, Xiaojiang Peng, Alex Kot</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07245">https://arxiv.org/abs/2401.07245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07245">https://arxiv.org/pdf/2401.07245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07245]] MIMIC: Mask Image Pre-training with Mix Contrastive Fine-tuning for  Facial Expression Recognition(https://arxiv.org/abs/2401.07245)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Cutting-edge research in facial expression recognition (FER) currently favors the utilization of convolutional neural networks (CNNs) backbone which is supervisedly pre-trained on face recognition datasets for feature extraction. However, due to the vast scale of face recognition datasets and the high cost associated with collecting facial labels, this pre-training paradigm incurs significant expenses. Towards this end, we propose to pre-train vision Transformers (ViTs) through a self-supervised approach on a mid-scale general image dataset. In addition, when compared with the domain disparity existing between face datasets and FER datasets, the divergence between general datasets and FER datasets is more pronounced. Therefore, we propose a contrastive fine-tuning approach to effectively mitigate this domain disparity. Specifically, we introduce a novel FER training paradigm named Mask Image pre-training with MIx Contrastive fine-tuning (MIMIC). In the initial phase, we pre-train the ViT via masked image reconstruction on general images. Subsequently, in the fine-tuning stage, we introduce a mix-supervised contrastive learning process, which enhances the model with a more extensive range of positive samples by the mixing strategy. Through extensive experiments conducted on three benchmark datasets, we demonstrate that our MIMIC outperforms the previous training paradigm, showing its capability to learn better representations. Remarkably, the results indicate that the vanilla ViT can achieve impressive performance without the need for intricate, auxiliary-designed modules. Moreover, when scaling up the model size, MIMIC exhibits no performance saturation and is superior to the current state-of-the-art methods.</li>
</ul>

<h3>Title: 3D Landmark Detection on Human Point Clouds: A Benchmark and A Dual  Cascade Point Transformer Framework</h3>
<ul>
<li><strong>Authors: </strong>Fan Zhang, Shuyi Mao, Qing Li, Xiaojiang Peng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07251">https://arxiv.org/abs/2401.07251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07251">https://arxiv.org/pdf/2401.07251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07251]] 3D Landmark Detection on Human Point Clouds: A Benchmark and A Dual  Cascade Point Transformer Framework(https://arxiv.org/abs/2401.07251)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>3D landmark detection plays a pivotal role in various applications such as 3D registration, pose estimation, and virtual try-on. While considerable success has been achieved in 2D human landmark detection or pose estimation, there is a notable scarcity of reported works on landmark detection in unordered 3D point clouds. This paper introduces a novel challenge, namely 3D landmark detection on human point clouds, presenting two primary contributions. Firstly, we establish a comprehensive human point cloud dataset, named HPoint103, designed to support the 3D landmark detection community. This dataset comprises 103 human point clouds created with commercial software and actors, each manually annotated with 11 stable landmarks. Secondly, we propose a Dual Cascade Point Transformer (D-CPT) model for precise point-based landmark detection. D-CPT gradually refines the landmarks through cascade Transformer decoder layers across the entire point cloud stream, simultaneously enhancing landmark coordinates with a RefineNet over local regions. Comparative evaluations with popular point-based methods on HPoint103 and the public dataset DHP19 demonstrate the dramatic outperformance of our D-CPT. Additionally, the integration of our RefineNet into existing methods consistently improves performance.</li>
</ul>

<h3>Title: LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts</h3>
<ul>
<li><strong>Authors: </strong>Shoupeng Ren, Tianyu Tu, Jian Liu, Di Wu, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07261">https://arxiv.org/abs/2401.07261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07261">https://arxiv.org/pdf/2401.07261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07261]] LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts(https://arxiv.org/abs/2401.07261)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>DeFi incidents stemming from various smart contract vulnerabilities have culminated in financial damages exceeding 3 billion USD. The attacks causing such incidents commonly commence with the deployment of adversarial contracts, subsequently leveraging these contracts to execute adversarial transactions that exploit vulnerabilities in victim contracts. Existing defense mechanisms leverage heuristic or machine learning algorithms to detect adversarial transactions, but they face significant challenges in detecting private adversarial transactions. Namely, attackers can send adversarial transactions directly to miners, evading visibility within the blockchain network and effectively bypassing the detection. In this paper, we propose a new direction for detecting DeFi attacks, i.e., detecting adversarial contracts instead of adversarial transactions, allowing us to proactively identify potential attack intentions, even if they employ private adversarial transactions. Specifically, we observe that most adversarial contracts follow a similar pattern, e.g., anonymous fund source, closed-source, frequent token-related function calls. Based on this observation, we build a machine learning classifier that can effectively distinguish adversarial contracts from benign ones. We build a dataset consists of features extracted from 304 adversarial contracts and 13,000 benign contracts. Based on this dataset, we evaluate different classifiers, the results of which show that our method for identifying DeFi adversarial contracts performs exceptionally well. For example, the F1-Score for LightGBM-based classifier is 0.9434, with a remarkably low false positive rate of only 0.12%.</li>
</ul>

<h3>Title: SpineCLUE: Automatic Vertebrae Identification Using Contrastive Learning  and Uncertainty Estimation</h3>
<ul>
<li><strong>Authors: </strong>Sheng Zhang, Minheng Chen, Junxian Wu, Ziyue Zhang, Tonglong Li, Cheng Xue, Youyong Kong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07271">https://arxiv.org/abs/2401.07271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07271">https://arxiv.org/pdf/2401.07271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07271]] SpineCLUE: Automatic Vertebrae Identification Using Contrastive Learning  and Uncertainty Estimation(https://arxiv.org/abs/2401.07271)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Vertebrae identification in arbitrary fields-of-view plays a crucial role in diagnosing spine disease. Most spine CT contain only local regions, such as the neck, chest, and abdomen. Therefore, identification should not depend on specific vertebrae or a particular number of vertebrae being visible. Existing methods at the spine-level are unable to meet this challenge. In this paper, we propose a three-stage method to address the challenges in 3D CT vertebrae identification at vertebrae-level. By sequentially performing the tasks of vertebrae localization, segmentation, and identification, the anatomical prior information of the vertebrae is effectively utilized throughout the process. Specifically, we introduce a dual-factor density clustering algorithm to acquire localization information for individual vertebra, thereby facilitating subsequent segmentation and identification processes. In addition, to tackle the issue of interclass similarity and intra-class variability, we pre-train our identification network by using a supervised contrastive learning method. To further optimize the identification results, we estimated the uncertainty of the classification network and utilized the message fusion module to combine the uncertainty scores, while aggregating global information about the spine. Our method achieves state-of-the-art results on the VerSe19 and VerSe20 challenge benchmarks. Additionally, our approach demonstrates outstanding generalization performance on an collected dataset containing a wide range of abnormal cases.</li>
</ul>

<h3>Title: Semi-supervised Semantic Segmentation using Redesigned Self-Training for  White Blood Cel</h3>
<ul>
<li><strong>Authors: </strong>Vinh Quoc Luu, Duy Khanh Le, Huy Thanh Nguyen, Minh Thanh Nguyen, Thinh Tien Nguyen, Vinh Quang Dinh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07278">https://arxiv.org/abs/2401.07278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07278">https://arxiv.org/pdf/2401.07278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07278]] Semi-supervised Semantic Segmentation using Redesigned Self-Training for  White Blood Cel(https://arxiv.org/abs/2401.07278)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI) in healthcare, especially in white blood cell cancer diagnosis, is hindered by two primary challenges: the lack of large-scale labeled datasets for white blood cell (WBC) segmentation and outdated segmentation methods. To address the first challenge, a semi-supervised learning framework should be brought to efficiently annotate the large dataset. In this work, we address this issue by proposing a novel self-training pipeline with the incorporation of FixMatch. We discover that by incorporating FixMatch in the self-training pipeline, the performance improves in the majority of cases. Our performance achieved the best performance with the self-training scheme with consistency on DeepLab-V3 architecture and ResNet-50, reaching 90.69%, 87.37%, and 76.49% on Zheng 1, Zheng 2, and LISC datasets, respectively.</li>
</ul>

<h3>Title: Improving Domain Adaptation through Extended-Text Reading Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Ting Jiang, Shaohan Huang, Shengyue Luo, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, Fuzhen Zhuang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07284">https://arxiv.org/abs/2401.07284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07284">https://arxiv.org/pdf/2401.07284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07284]] Improving Domain Adaptation through Extended-Text Reading Comprehension(https://arxiv.org/abs/2401.07284)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To enhance the domain-specific capabilities of large language models, continued pre-training on a domain-specific corpus is a prevalent method. Recent work demonstrates that adapting models using reading comprehension data formatted by regex-based patterns can significantly improve performance on domain-specific tasks. However, regex-based patterns are incapable of parsing raw corpora using domain-specific knowledge. Furthermore, the question and answer pairs are extracted directly from the corpus in predefined formats offers limited context. To address this limitation, we improve reading comprehension via LLM and clustering. LLM focuses on leveraging domain knowledge within the corpus to refine comprehension stage, while clustering supplies relevant knowledge by extending the context to enrich reading stage. Additionally, our method incorporates parameter-efficient fine-tuning to improve the efficiency of domain adaptation. In comparison to AdaptLLM, our method achieves an improvement exceeding 5% in domain-specific tasks. Our code will available at https://github.com/microsoft/LMOps.</li>
</ul>

<h3>Title: CANDLE: Iterative Conceptualization and Instantiation Distillation from  Large Language Models for Commonsense Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Weiqi Wang, Tianqing Fang, Chunyang Li, Haochen Shi, Wenxuan Ding, Baixuan Xu, Zhaowei Wang, Jiaxin Bai, Xin Liu, Jiayang Cheng, Chunkit Chan, Yangqiu Song</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07286">https://arxiv.org/abs/2401.07286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07286">https://arxiv.org/pdf/2401.07286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07286]] CANDLE: Iterative Conceptualization and Instantiation Distillation from  Large Language Models for Commonsense Reasoning(https://arxiv.org/abs/2401.07286)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The sequential process of conceptualization and instantiation is essential to generalizable commonsense reasoning as it allows the application of existing knowledge to unfamiliar scenarios. However, existing works tend to undervalue the step of instantiation and heavily rely on pre-built concept taxonomies and human annotations to collect both types of knowledge, resulting in a lack of instantiated knowledge to complete reasoning, high cost, and limited scalability. To tackle these challenges, we introduce CANDLE, a distillation framework that iteratively performs contextualized conceptualization and instantiation over commonsense knowledge bases by instructing large language models to generate both types of knowledge with critic filtering. By applying CANDLE to ATOMIC, we construct a comprehensive knowledge base comprising six million conceptualizations and instantiated commonsense knowledge triples. Both types of knowledge are firmly rooted in the original ATOMIC dataset, and intrinsic evaluations demonstrate their exceptional quality and diversity. Empirical results indicate that distilling CANDLE on student models provides benefits across four downstream tasks. Our code, data, and models are publicly available at https://github.com/HKUST-KnowComp/CANDLE.</li>
</ul>

<h3>Title: Small Language Model Can Self-correct</h3>
<ul>
<li><strong>Authors: </strong>Haixia Han, Jiaqing Liang, Jie Shi, Qianyu He, Yanghua Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07301">https://arxiv.org/abs/2401.07301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07301">https://arxiv.org/pdf/2401.07301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07301]] Small Language Model Can Self-correct(https://arxiv.org/abs/2401.07301)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Language Models (LMs) such as ChatGPT have exhibited remarkable performance across various downstream tasks. Nevertheless, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. Previous studies have devised sophisticated pipelines and prompts to induce large LMs to exhibit the capability for self-correction. However, large LMs are explicitly prompted to verify and modify its answers separately rather than completing all steps spontaneously like humans. Moreover, these complex prompts are extremely challenging for small LMs to follow. In this paper, we introduce the \underline{I}ntrinsic \underline{S}elf-\underline{C}orrection (ISC) in generative language models, aiming to correct the initial output of LMs in a self-triggered manner, even for those small LMs with 6 billion parameters. Specifically, we devise a pipeline for constructing self-correction data and propose Partial Answer Masking (PAM), aiming to endow the model with the capability for intrinsic self-correction through fine-tuning. We conduct experiments using LMs with parameters sizes ranging from 6 billion to 13 billion in two tasks, including commonsense reasoning and factual knowledge reasoning. Our experiments demonstrate that the outputs generated using ISC outperform those generated without self-correction. We believe that the output quality of even small LMs can be further improved by empowering them with the ability to intrinsic self-correct.</li>
</ul>

<h3>Title: Harnessing Large Language Models Over Transformer Models for Detecting  Bengali Depressive Social Media Text: A Comprehensive Study</h3>
<ul>
<li><strong>Authors: </strong>Ahmadul Karim Chowdhury, Md. Saidur Rahman Sujon, Md. Shirajus Salekin Shafi, Tasin Ahmmad, Sifat Ahmed, Khan Md Hasib, Faisal Muhammad Shah</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07310">https://arxiv.org/abs/2401.07310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07310">https://arxiv.org/pdf/2401.07310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07310]] Harnessing Large Language Models Over Transformer Models for Detecting  Bengali Depressive Social Media Text: A Comprehensive Study(https://arxiv.org/abs/2401.07310)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>In an era where the silent struggle of underdiagnosed depression pervades globally, our research delves into the crucial link between mental health and social media. This work focuses on early detection of depression, particularly in extroverted social media users, using LLMs such as GPT 3.5, GPT 4 and our proposed GPT 3.5 fine-tuned model DepGPT, as well as advanced Deep learning models(LSTM, Bi-LSTM, GRU, BiGRU) and Transformer models(BERT, BanglaBERT, SahajBERT, BanglaBERT-Base). The study categorized Reddit and X datasets into "Depressive" and "Non-Depressive" segments, translated into Bengali by native speakers with expertise in mental health, resulting in the creation of the Bengali Social Media Depressive Dataset (BSMDD). Our work provides full architecture details for each model and a methodical way to assess their performance in Bengali depressive text categorization using zero-shot and few-shot learning techniques. Our work demonstrates the superiority of SahajBERT and Bi-LSTM with FastText embeddings in their respective domains also tackles explainability issues with transformer models and emphasizes the effectiveness of LLMs, especially DepGPT, demonstrating flexibility and competence in a range of learning contexts. According to the experiment results, the proposed model, DepGPT, outperformed not only Alpaca Lora 7B in zero-shot and few-shot scenarios but also every other model, achieving a near-perfect accuracy of 0.9796 and an F1-score of 0.9804, high recall, and exceptional precision. Although competitive, GPT-3.5 Turbo and Alpaca Lora 7B show relatively poorer effectiveness in zero-shot and few-shot situations. The work emphasizes the effectiveness and flexibility of LLMs in a variety of linguistic circumstances, providing insightful information about the complex field of depression detection models.</li>
</ul>

<h3>Title: MapNeXt: Revisiting Training and Scaling Practices for Online Vectorized  HD Map Construction</h3>
<ul>
<li><strong>Authors: </strong>Toyota Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07323">https://arxiv.org/abs/2401.07323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07323">https://arxiv.org/pdf/2401.07323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07323]] MapNeXt: Revisiting Training and Scaling Practices for Online Vectorized  HD Map Construction(https://arxiv.org/abs/2401.07323)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>High-Definition (HD) maps are pivotal to autopilot navigation. Integrating the capability of lightweight HD map construction at runtime into a self-driving system recently emerges as a promising direction. In this surge, vision-only perception stands out, as a camera rig can still perceive the stereo information, let alone its appealing signature of portability and economy. The latest MapTR architecture solves the online HD map construction task in an end-to-end fashion but its potential is yet to be explored. In this work, we present a full-scale upgrade of MapTR and propose MapNeXt, the next generation of HD map learning architecture, delivering major contributions from the model training and scaling perspectives. After shedding light on the training dynamics of MapTR and exploiting the supervision from map elements thoroughly, MapNeXt-Tiny raises the mAP of MapTR-Tiny from 49.0% to 54.8%, without any architectural modifications. Enjoying the fruit of map segmentation pre-training, MapNeXt-Base further lifts the mAP up to 63.9% that has already outperformed the prior art, a multi-modality MapTR, by 1.4% while being $\sim1.8\times$ faster. Towards pushing the performance frontier to the next level, we draw two conclusions on practical model scaling: increased query favors a larger decoder network for adequate digestion; a large backbone steadily promotes the final accuracy without bells and whistles. Building upon these two rules of thumb, MapNeXt-Huge achieves state-of-the-art performance on the challenging nuScenes benchmark. Specifically, we push the mapless vision-only single-model performance to be over 78% for the first time, exceeding the best model from existing methods by 16%.</li>
</ul>

<h3>Title: Privacy-Preserving Intrusion Detection in Software-defined VANET using  Federated Learning with BERT</h3>
<ul>
<li><strong>Authors: </strong>Shakil Ibne Ahsan, Phil Legg, S M Iftekharul Alam</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07343">https://arxiv.org/abs/2401.07343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07343">https://arxiv.org/pdf/2401.07343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07343]] Privacy-Preserving Intrusion Detection in Software-defined VANET using  Federated Learning with BERT(https://arxiv.org/abs/2401.07343)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>The absence of robust security protocols renders the VANET (Vehicle ad-hoc Networks) network open to cyber threats by compromising passengers and road safety. Intrusion Detection Systems (IDS) are widely employed to detect network security threats. With vehicles' high mobility on the road and diverse environments, VANETs devise ever-changing network topologies, lack privacy and security, and have limited bandwidth efficiency. The absence of privacy precautions, End-to-End Encryption methods, and Local Data Processing systems in VANET also present many privacy and security difficulties. So, assessing whether a novel real-time processing IDS approach can be utilized for this emerging technology is crucial. The present study introduces a novel approach for intrusion detection using Federated Learning (FL) capabilities in conjunction with the BERT model for sequence classification (FL-BERT). The significance of data privacy is duly recognized. According to FL methodology, each client has its own local model and dataset. They train their models locally and then send the model's weights to the server. After aggregation, the server aggregates the weights from all clients to update a global model. After aggregation, the global model's weights are shared with the clients. This practice guarantees the secure storage of sensitive raw data on individual clients' devices, effectively protecting privacy. After conducting the federated learning procedure, we assessed our models' performance using a separate test dataset. The FL-BERT technique has yielded promising results, opening avenues for further investigation in this particular area of research. We reached the result of our approaches by comparing existing research works and found that FL-BERT is more effective for privacy and security concerns. Our results suggest that FL-BERT is a promising technique for enhancing attack detection.</li>
</ul>

<h3>Title: PersonalityChat: Conversation Distillation for Personalized Dialog  Modeling with Facts and Traits</h3>
<ul>
<li><strong>Authors: </strong>Ehsan Lotfi, Maxime De Bruyn, Jeska Buhmann, Walter Daelemans</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07363">https://arxiv.org/abs/2401.07363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07363">https://arxiv.org/pdf/2401.07363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07363]] PersonalityChat: Conversation Distillation for Personalized Dialog  Modeling with Facts and Traits(https://arxiv.org/abs/2401.07363)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The new wave of Large Language Models (LLM) has offered an efficient tool to curate sizeable conversational datasets. So far studies have mainly focused on task-oriented or generic open-domain dialogs, and have not fully explored the ability of LLMs in following complicated prompts. In this work, we focus on personalization, and employ LLMs to curate a dataset which is difficult and costly to crowd-source: PersonalityChat is a synthetic conversational dataset based upon the popular PersonaChat dataset, but conditioned on both personas and (Big-5) personality traits. Evaluating models fine-tuned on this dataset, we show that the personality trait labels can be used for trait-based personalization of generative dialogue models. We also perform a head-to-head comparison between PersonalityChat and PersonaChat, and show that training on the distilled dataset results in more fluent and coherent dialog agents in the small-model regime.</li>
</ul>

<h3>Title: Active Learning for NLP with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xuesong Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07367">https://arxiv.org/abs/2401.07367</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07367">https://arxiv.org/pdf/2401.07367</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07367]] Active Learning for NLP with Large Language Models(https://arxiv.org/abs/2401.07367)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human annotation of training samples is expensive, laborious, and sometimes challenging, especially for Natural Language Processing (NLP) tasks. To reduce the labeling cost and enhance the sample efficiency, Active Learning (AL) technique can be used to label as few samples as possible to reach a reasonable or similar results. To reduce even more costs and with the significant advances of Large Language Models (LLMs), LLMs can be a good candidate to annotate samples. This work investigates the accuracy and cost of using LLMs (GPT-3.5 and GPT-4) to label samples on 3 different datasets. A consistency-based strategy is proposed to select samples that are potentially incorrectly labeled so that human annotations can be used for those samples in AL settings, and we call it mixed annotation strategy. Then we test performance of AL under two different settings: (1) using human annotations only; (2) using the proposed mixed annotation strategy. The accuracy of AL models under 3 AL query strategies are reported on 3 text classification datasets, i.e., AG's News, TREC-6, and Rotten Tomatoes. On AG's News and Rotten Tomatoes, the models trained with the mixed annotation strategy achieves similar or better results compared to that with human annotations. The method reveals great potentials of LLMs as annotators in terms of accuracy and cost efficiency in active learning settings.</li>
</ul>

<h3>Title: A Novel Zero-Trust Machine Learning Green Architecture for Healthcare  IoT Cybersecurity: Review, Analysis, and Implementation</h3>
<ul>
<li><strong>Authors: </strong>Zag ElSayed, Nelly Elsayed, Sajjad Bay</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07368">https://arxiv.org/abs/2401.07368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07368">https://arxiv.org/pdf/2401.07368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07368]] A Novel Zero-Trust Machine Learning Green Architecture for Healthcare  IoT Cybersecurity: Review, Analysis, and Implementation(https://arxiv.org/abs/2401.07368)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, robust</a></li>
<li><strong>Abstract: </strong>The integration of Internet of Things (IoT) devices in healthcare applications has revolutionized patient care, monitoring, and data management. The Global IoT in Healthcare Market value is $252.2 Billion in 2023. However, the rapid involvement of these devices brings information security concerns that pose critical threats to patient privacy and the integrity of healthcare data. This paper introduces a novel machine learning (ML) based architecture explicitly designed to address and mitigate security vulnerabilities in IoT devices within healthcare applications. By leveraging advanced convolution ML architecture, the proposed architecture aims to proactively monitor and detect potential threats, ensuring the confidentiality and integrity of sensitive healthcare information while minimizing the cost and increasing the portability specialized for healthcare and emergency environments. The experimental results underscore the accuracy of up to 93.6% for predicting various attacks based on the results demonstrate a zero-day detection accuracy simulated using the CICIoT2023 dataset and reduces the cost by a factor of x10. The significance of our approach is in fortifying the security posture of IoT devices and maintaining a robust implementation of trustful healthcare systems.</li>
</ul>

<h3>Title: Generation of Synthetic Images for Pedestrian Detection Using a Sequence  of GANs</h3>
<ul>
<li><strong>Authors: </strong>Viktor Seib, Malte Roosen, Ida Germann, Stefan Wirtz, Dietrich Paulus</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07370">https://arxiv.org/abs/2401.07370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07370">https://arxiv.org/pdf/2401.07370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07370]] Generation of Synthetic Images for Pedestrian Detection Using a Sequence  of GANs(https://arxiv.org/abs/2401.07370)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Creating annotated datasets demands a substantial amount of manual effort. In this proof-of-concept work, we address this issue by proposing a novel image generation pipeline. The pipeline consists of three distinct generative adversarial networks (previously published), combined in a novel way to augment a dataset for pedestrian detection. Despite the fact that the generated images are not always visually pleasant to the human eye, our detection benchmark reveals that the results substantially surpass the baseline. The presented proof-of-concept work was done in 2020 and is now published as a technical report after a three years retention period.</li>
</ul>

<h3>Title: Knee or ROC</h3>
<ul>
<li><strong>Authors: </strong>Veronica Wendt, Byunggu Yu, Caleb Kelly, Junwhan Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07390">https://arxiv.org/abs/2401.07390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07390">https://arxiv.org/pdf/2401.07390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07390]] Knee or ROC(https://arxiv.org/abs/2401.07390)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Self-attention transformers have demonstrated accuracy for image classification with smaller data sets. However, a limitation is that tests to-date are based upon single class image detection with known representation of image populations. For instances where the input image classes may be greater than one and test sets that lack full information on representation of image populations, accuracy calculations must adapt. The Receiver Operating Characteristic (ROC) accuracy thresh-old can address the instances of multi-class input images. However, this approach is unsuitable in instances where image population representation is unknown. We consider calculating accuracy using the knee method to determine threshold values on an ad-hoc basis. Results of ROC curve and knee thresholds for a multi-class data set, created from CIFAR-10 images, are discussed for multi-class image detection.</li>
</ul>

<h3>Title: Cross Domain Early Crop Mapping using CropGAN and CNN Classifier</h3>
<ul>
<li><strong>Authors: </strong>Yiqun Wang, Hui Huang, Radu State</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07398">https://arxiv.org/abs/2401.07398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07398">https://arxiv.org/pdf/2401.07398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07398]] Cross Domain Early Crop Mapping using CropGAN and CNN Classifier(https://arxiv.org/abs/2401.07398)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Driven by abundant satellite imagery, machine learning-based approaches have recently been promoted to generate high-resolution crop cultivation maps to support many agricultural applications. One of the major challenges faced by these approaches is the limited availability of ground truth labels. In the absence of ground truth, existing work usually adopts the "direct transfer strategy" that trains a classifier using historical labels collected from other regions and then applies the trained model to the target region. Unfortunately, the spectral features of crops exhibit inter-region and inter-annual variability due to changes in soil composition, climate conditions, and crop progress, the resultant models perform poorly on new and unseen regions or years. This paper presents the Crop Generative Adversarial Network (CropGAN) to address the above cross-domain issue. Our approach does not need labels from the target domain. Instead, it learns a mapping function to transform the spectral features of the target domain to the source domain (with labels) while preserving their local structure. The classifier trained by the source domain data can be directly applied to the transformed data to produce high-accuracy early crop maps of the target domain. Comprehensive experiments across various regions and years demonstrate the benefits and effectiveness of the proposed approach. Compared with the widely adopted direct transfer strategy, the F1 score after applying the proposed CropGAN is improved by 13.13% - 50.98%</li>
</ul>

<h3>Title: Leveraging the power of transformers for guilt detection in text</h3>
<ul>
<li><strong>Authors: </strong>Abdul Gafar Manuel Meque, Jason Angel, Grigori Sidorov, Alexander Gelbukh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07414">https://arxiv.org/abs/2401.07414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07414">https://arxiv.org/pdf/2401.07414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07414]] Leveraging the power of transformers for guilt detection in text(https://arxiv.org/abs/2401.07414)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years, language models and deep learning techniques have revolutionized natural language processing tasks, including emotion detection. However, the specific emotion of guilt has received limited attention in this field. In this research, we explore the applicability of three transformer-based language models for detecting guilt in text and compare their performance for general emotion detection and guilt detection. Our proposed model outformed BERT and RoBERTa models by two and one points respectively. Additionally, we analyze the challenges in developing accurate guilt-detection models and evaluate our model's effectiveness in detecting related emotions like "shame" through qualitative analysis of results.</li>
</ul>

<h3>Title: BoNuS: Boundary Mining for Nuclei Segmentation with Partial Point Labels</h3>
<ul>
<li><strong>Authors: </strong>Yi Lin, Zeyu Wang, Dong Zhang, Kwang-Ting Cheng, Hao Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07437">https://arxiv.org/abs/2401.07437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07437">https://arxiv.org/pdf/2401.07437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07437]] BoNuS: Boundary Mining for Nuclei Segmentation with Partial Point Labels(https://arxiv.org/abs/2401.07437)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Nuclei segmentation is a fundamental prerequisite in the digital pathology workflow. The development of automated methods for nuclei segmentation enables quantitative analysis of the wide existence and large variances in nuclei morphometry in histopathology images. However, manual annotation of tens of thousands of nuclei is tedious and time-consuming, which requires significant amount of human effort and domain-specific expertise. To alleviate this problem, in this paper, we propose a weakly-supervised nuclei segmentation method that only requires partial point labels of nuclei. Specifically, we propose a novel boundary mining framework for nuclei segmentation, named BoNuS, which simultaneously learns nuclei interior and boundary information from the point labels. To achieve this goal, we propose a novel boundary mining loss, which guides the model to learn the boundary information by exploring the pairwise pixel affinity in a multiple-instance learning manner. Then, we consider a more challenging problem, i.e., partial point label, where we propose a nuclei detection module with curriculum learning to detect the missing nuclei with prior morphological knowledge. The proposed method is validated on three public datasets, MoNuSeg, CPM, and CoNIC datasets. Experimental results demonstrate the superior performance of our method to the state-of-the-art weakly-supervised nuclei segmentation methods. Code: https://github.com/hust-linyi/bonus.</li>
</ul>

<h3>Title: Stability Analysis of ChatGPT-based Sentiment Analysis in AI Quality  Assurance</h3>
<ul>
<li><strong>Authors: </strong>Tinghui Ouyang, AprilPyone MaungMaung, Koichi Konishi, Yoshiki Seo, Isao Echizen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07441">https://arxiv.org/abs/2401.07441</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07441">https://arxiv.org/pdf/2401.07441</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07441]] Stability Analysis of ChatGPT-based Sentiment Analysis in AI Quality  Assurance(https://arxiv.org/abs/2401.07441)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>In the era of large AI models, the complex architecture and vast parameters present substantial challenges for effective AI quality management (AIQM), e.g. large language model (LLM). This paper focuses on investigating the quality assurance of a specific LLM-based AI product--a ChatGPT-based sentiment analysis system. The study delves into stability issues related to both the operation and robustness of the expansive AI model on which ChatGPT is based. Experimental analysis is conducted using benchmark datasets for sentiment analysis. The results reveal that the constructed ChatGPT-based sentiment analysis system exhibits uncertainty, which is attributed to various operational factors. It demonstrated that the system also exhibits stability issues in handling conventional small text attacks involving robustness.</li>
</ul>

<h3>Title: Taec: a Manually annotated text dataset for trait and phenotype  extraction and entity linking in wheat breeding literature</h3>
<ul>
<li><strong>Authors: </strong>Claire Nédellec, Clara Sauvion, Robert Bossy, Mariya Borovikova, Louise Deléger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07447">https://arxiv.org/abs/2401.07447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07447">https://arxiv.org/pdf/2401.07447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07447]] Taec: a Manually annotated text dataset for trait and phenotype  extraction and entity linking in wheat breeding literature(https://arxiv.org/abs/2401.07447)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Wheat varieties show a large diversity of traits and phenotypes. Linking them to genetic variability is essential for shorter and more efficient wheat breeding programs. Newly desirable wheat variety traits include disease resistance to reduce pesticide use, adaptation to climate change, resistance to heat and drought stresses, or low gluten content of grains. Wheat breeding experiments are documented by a large body of scientific literature and observational data obtained in-field and under controlled conditions. The cross-referencing of complementary information from the literature and observational data is essential to the study of the genotype-phenotype relationship and to the improvement of wheat selection. The scientific literature on genetic marker-assisted selection describes much information about the genotype-phenotype relationship. However, the variety of expressions used to refer to traits and phenotype values in scientific articles is a hinder to finding information and cross-referencing it. When trained adequately by annotated examples, recent text mining methods perform highly in named entity recognition and linking in the scientific domain. While several corpora contain annotations of human and animal phenotypes, currently, no corpus is available for training and evaluating named entity recognition and entity-linking methods in plant phenotype literature. The Triticum aestivum trait Corpus is a new gold standard for traits and phenotypes of wheat. It consists of 540 PubMed references fully annotated for trait, phenotype, and species named entities using the Wheat Trait and Phenotype Ontology and the species taxonomy of the National Center for Biotechnology Information. A study of the performance of tools trained on the Triticum aestivum trait Corpus shows that the corpus is suitable for the training and evaluation of named entity recognition and linking.</li>
</ul>

<h3>Title: Hierarchical Fashion Design with Multi-stage Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zhifeng Xie, Hao li, Huiming Ding, Mengtian Li, Ying Cao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07450">https://arxiv.org/abs/2401.07450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07450">https://arxiv.org/pdf/2401.07450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07450]] Hierarchical Fashion Design with Multi-stage Diffusion Models(https://arxiv.org/abs/2401.07450)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Cross-modal fashion synthesis and editing offer intelligent support to fashion designers by enabling the automatic generation and local modification of design drafts.While current diffusion models demonstrate commendable stability and controllability in image synthesis,they still face significant challenges in generating fashion design from abstract design elements and fine-grained editing.Abstract sensory expressions, \eg office, business, and party, form the high-level design concepts, while measurable aspects like sleeve length, collar type, and pant length are considered the low-level attributes of clothing.Controlling and editing fashion images using lengthy text descriptions poses a difficulty.In this paper, we propose HieraFashDiff,a novel fashion design method using the shared multi-stage diffusion model encompassing high-level design concepts and low-level clothing attributes in a hierarchical structure.Specifically, we categorized the input text into different levels and fed them in different time step to the diffusion model according to the criteria of professional clothing designers.HieraFashDiff allows designers to add low-level attributes after high-level prompts for interactive editing incrementally.In addition, we design a differentiable loss function in the sampling process with a mask to keep non-edit areas.Comprehensive experiments performed on our newly conducted Hierarchical fashion dataset,demonstrate that our proposed method outperforms other state-of-the-art competitors.</li>
</ul>

<h3>Title: Model Editing at Scale leads to Gradual and Catastrophic Forgetting</h3>
<ul>
<li><strong>Authors: </strong>Akshat Gupta, Anurag Rao, Gopala Anumanchipalli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07453">https://arxiv.org/abs/2401.07453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07453">https://arxiv.org/pdf/2401.07453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07453]] Model Editing at Scale leads to Gradual and Catastrophic Forgetting(https://arxiv.org/abs/2401.07453)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Editing knowledge in large language models is an attractive capability to have which allows us to correct incorrectly learnt facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated using metrics for reliability, specificity and generalization over one or few edits. We argue that for model editing to have practical utility, we must be able to make multiple edits to the same model. With this in mind, we evaluate the current model editing methods at scale, focusing on two state of the art methods: ROME and MEMIT. We find that as the model is edited sequentially with multiple facts, it continually forgets previously edited facts and the ability to perform downstream tasks. This forgetting happens in two phases -- an initial gradual but progressive forgetting phase followed by abrupt or catastrophic forgetting phase. Both gradual and catastrophic forgetting limit the usefulness of model editing methods at scale -- the former making model editing less effective as multiple edits are made to the model while the latter caps the scalability of such model editing methods. Our analysis also highlights other key limitations of ROME and MEMIT at scale. With our work, we push for the development and evaluation of model editing methods keeping scalability in mind.</li>
</ul>

<h3>Title: Only Send What You Need: Learning to Communicate Efficiently in  Federated Multilingual Machine Translation</h3>
<ul>
<li><strong>Authors: </strong>Yun-Wei Chu, Dong-Jun Han, Christopher G. Brinton</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07456">https://arxiv.org/abs/2401.07456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07456">https://arxiv.org/pdf/2401.07456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07456]] Only Send What You Need: Learning to Communicate Efficiently in  Federated Multilingual Machine Translation(https://arxiv.org/abs/2401.07456)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a promising approach for solving multilingual tasks, potentially enabling clients with their own language-specific data to collaboratively construct a high-quality neural machine translation (NMT) model. However, communication constraints in practical network systems present challenges for exchanging large-scale NMT engines between FL parties. In this paper, we propose a meta-learning-based adaptive parameter selection methodology, MetaSend, that improves the communication efficiency of model transmissions from clients during FL-based multilingual NMT training. Our approach learns a dynamic threshold for filtering parameters prior to transmission without compromising the NMT model quality, based on the tensor deviations of clients between different FL rounds. Through experiments on two NMT datasets with different language distributions, we demonstrate that MetaSend obtains substantial improvements over baselines in translation quality in the presence of a limited communication budget.</li>
</ul>

<h3>Title: Semantic Segmentation in Multiple Adverse Weather Conditions with Domain  Knowledge Retention</h3>
<ul>
<li><strong>Authors: </strong>Xin Yang, Wending Yan, Yuan Yuan, Michael Bi Mi, Robby T. Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07459">https://arxiv.org/abs/2401.07459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07459">https://arxiv.org/pdf/2401.07459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07459]] Semantic Segmentation in Multiple Adverse Weather Conditions with Domain  Knowledge Retention(https://arxiv.org/abs/2401.07459)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation's performance is often compromised when applied to unlabeled adverse weather conditions. Unsupervised domain adaptation is a potential approach to enhancing the model's adaptability and robustness to adverse weather. However, existing methods encounter difficulties when sequentially adapting the model to multiple unlabeled adverse weather conditions. They struggle to acquire new knowledge while also retaining previously learned knowledge.To address these problems, we propose a semantic segmentation method for multiple adverse weather conditions that incorporates adaptive knowledge acquisition, pseudolabel blending, and weather composition replay. Our adaptive knowledge acquisition enables the model to avoid learning from extreme images that could potentially cause the model to forget. In our approach of blending pseudo-labels, we not only utilize the current model but also integrate the previously learned model into the ongoing learning process. This collaboration between the current teacher and the previous model enhances the robustness of the pseudo-labels for the current target. Our weather composition replay mechanism allows the model to continuously refine its previously learned weather information while simultaneously learning from the new target domain. Our method consistently outperforms the stateof-the-art methods, and obtains the best performance with averaged mIoU (%) of 65.7 and the lowest forgetting (%) of 3.6 against 60.1 and 11.3, on the ACDC datasets for a four-target continual multi-target domain adaptation.</li>
</ul>

<h3>Title: A Deep Hierarchical Feature Sparse Framework for Occluded Person  Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Yihu Song, Shuaishi Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07469">https://arxiv.org/abs/2401.07469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07469">https://arxiv.org/pdf/2401.07469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07469]] A Deep Hierarchical Feature Sparse Framework for Occluded Person  Re-Identification(https://arxiv.org/abs/2401.07469)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Most existing methods tackle the problem of occluded person re-identification (ReID) by utilizing auxiliary models, resulting in a complicated and inefficient ReID framework that is unacceptable for real-time applications. In this work, a speed-up person ReID framework named SUReID is proposed to mitigate occlusion interference while speeding up inference. The SUReID consists of three key components: hierarchical token sparsification (HTS) strategy, non-parametric feature alignment knowledge distillation (NPKD), and noise occlusion data augmentation (NODA). The HTS strategy works by pruning the redundant tokens in the vision transformer to achieve highly effective self-attention computation and eliminate interference from occlusions or background noise. However, the pruned tokens may contain human part features that contaminate the feature representation and degrade the performance. To solve this problem, the NPKD is employed to supervise the HTS strategy, retaining more discriminative tokens and discarding meaningless ones. Furthermore, the NODA is designed to introduce more noisy samples, which further trains the ability of the HTS to disentangle different tokens. Experimental results show that the SUReID achieves superior performance with surprisingly fast inference.</li>
</ul>

<h3>Title: A Contrast Based Feature Selection Algorithm for High-dimensional Data  set in Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Chunxu Cao, Qiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07482">https://arxiv.org/abs/2401.07482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07482">https://arxiv.org/pdf/2401.07482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07482]] A Contrast Based Feature Selection Algorithm for High-dimensional Data  set in Machine Learning(https://arxiv.org/abs/2401.07482)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Feature selection is an important process in machine learning and knowledge discovery. By selecting the most informative features and eliminating irrelevant ones, the performance of learning algorithms can be improved and the extraction of meaningful patterns and insights from data can be facilitated. However, most existing feature selection methods, when applied to large datasets, encountered the bottleneck of high computation costs. To address this problem, we propose a novel filter feature selection method, ContrastFS, which selects discriminative features based on the discrepancies features shown between different classes. We introduce a dimensionless quantity as a surrogate representation to summarize the distributional individuality of certain classes, based on this quantity we evaluate features and study the correlation among them. We validate effectiveness and efficiency of our approach on several widely studied benchmark datasets, results show that the new method performs favorably with negligible computation in comparison with other state-of-the-art feature selection methods.</li>
</ul>

<h3>Title: Feature Selection via Maximizing Distances between Class Conditional  Distributions</h3>
<ul>
<li><strong>Authors: </strong>Chunxu Cao, Qiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07488">https://arxiv.org/abs/2401.07488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07488">https://arxiv.org/pdf/2401.07488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07488]] Feature Selection via Maximizing Distances between Class Conditional  Distributions(https://arxiv.org/abs/2401.07488)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>For many data-intensive tasks, feature selection is an important preprocessing step. However, most existing methods do not directly and intuitively explore the intrinsic discriminative information of features. We propose a novel feature selection framework based on the distance between class conditional distributions, measured by integral probability metrics (IPMs). Our framework directly explores the discriminative information of features in the sense of distributions for supervised classification. We analyze the theoretical and practical aspects of IPMs for feature selection, construct criteria based on IPMs. We propose several variant feature selection methods of our framework based on the 1-Wasserstein distance and implement them on real datasets from different domains. Experimental results show that our framework can outperform state-of-the-art methods in terms of classification accuracy and robustness to perturbations.</li>
</ul>

<h3>Title: Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering  Tasks</h3>
<ul>
<li><strong>Authors: </strong>Zihao Wang, P S Pravin, Zhe Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07494">https://arxiv.org/abs/2401.07494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07494">https://arxiv.org/pdf/2401.07494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07494]] Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering  Tasks(https://arxiv.org/abs/2401.07494)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Computational efficiency and adversarial robustness are critical factors in real-world engineering applications. Yet, conventional neural networks often fall short in addressing both simultaneously, or even separately. Drawing insights from natural physical systems and existing literature, it is known that an input convex architecture enhances computational efficiency, while a Lipschitz-constrained architecture bolsters adversarial robustness. By leveraging the strengths of convexity and Lipschitz continuity, we develop a novel network architecture, termed Input Convex Lipschitz Recurrent Neural Network. This model outperforms existing recurrent units across a spectrum of engineering tasks in terms of computational efficiency and adversarial robustness. These tasks encompass a benchmark MNIST image classification, real-world solar irradiance prediction for Solar PV system planning at LHT Holdings in Singapore, and real-time Model Predictive Control optimization for a chemical reactor.</li>
</ul>

<h3>Title: Compositional Oil Spill Detection Based on Object Detector and Adapted  Segment Anything Model from SAR Images</h3>
<ul>
<li><strong>Authors: </strong>Wenhui Wu, Man Sing Wong, Xinyu Yu, Guoqiang Shi, Coco Yin Tung Kwok, Kang Zou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07502">https://arxiv.org/abs/2401.07502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07502">https://arxiv.org/pdf/2401.07502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07502]] Compositional Oil Spill Detection Based on Object Detector and Adapted  Segment Anything Model from SAR Images(https://arxiv.org/abs/2401.07502)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation-based methods have attracted extensive attention in oil spill detection from SAR images. However, the existing approaches require a large number of finely annotated segmentation samples in the training stage. To alleviate this issue, we propose a composite oil spill detection framework, SAM-OIL, comprising an object detector (e.g., YOLOv8), an adapted Segment Anything Model (SAM), and an Ordered Mask Fusion (OMF) module. SAM-OIL is the first application of the powerful SAM in oil spill detection. Specifically, the SAM-OIL strategy uses YOLOv8 to obtain the categories and bounding boxes of oil spill-related objects, then inputs bounding boxes into the adapted SAM to retrieve category-agnostic masks, and finally adopts the Ordered Mask Fusion (OMF) module to fuse the masks and categories. The adapted SAM, combining a frozen SAM with a learnable Adapter module, can enhance SAM's ability to segment ambiguous objects. The OMF module, a parameter-free method, can effectively resolve pixel category conflicts within SAM. Experimental results demonstrate that SAM-OIL surpasses existing semantic segmentation-based oil spill detection methods, achieving mIoU of 69.52%. The results also indicated that both OMF and Adapter modules can effectively improve the accuracy in SAM-OIL.</li>
</ul>

<h3>Title: Developing ChatGPT for Biology and Medicine: A Complete Review of  Biomedical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Qing Li, Lei Li, Yu Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07510">https://arxiv.org/abs/2401.07510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07510">https://arxiv.org/pdf/2401.07510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07510]] Developing ChatGPT for Biology and Medicine: A Complete Review of  Biomedical Question Answering(https://arxiv.org/abs/2401.07510)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>ChatGPT explores a strategic blueprint of question answering (QA) in delivering medical diagnosis, treatment recommendations, and other healthcare support. This is achieved through the increasing incorporation of medical domain data via natural language processing (NLP) and multimodal paradigms. By transitioning the distribution of text, images, videos, and other modalities from the general domain to the medical domain, these techniques have expedited the progress of medical domain question answering (MDQA). They bridge the gap between human natural language and sophisticated medical domain knowledge or expert manual annotations, handling large-scale, diverse, unbalanced, or even unlabeled data analysis scenarios in medical contexts. Central to our focus is the utilizing of language models and multimodal paradigms for medical question answering, aiming to guide the research community in selecting appropriate mechanisms for their specific medical research requirements. Specialized tasks such as unimodal-related question answering, reading comprehension, reasoning, diagnosis, relation extraction, probability modeling, and others, as well as multimodal-related tasks like vision question answering, image caption, cross-modal retrieval, report summarization, and generation, are discussed in detail. Each section delves into the intricate specifics of the respective method under consideration. This paper highlights the structures and advancements of medical domain explorations against general domain methods, emphasizing their applications across different tasks and datasets. It also outlines current challenges and opportunities for future medical domain research, paving the way for continued innovation and application in this rapidly evolving field.</li>
</ul>

<h3>Title: Temporal Link Prediction Using Graph Embedding Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Sanaz Hasanzadeh Fard, Mohammad Ghassemi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07516">https://arxiv.org/abs/2401.07516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07516">https://arxiv.org/pdf/2401.07516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07516]] Temporal Link Prediction Using Graph Embedding Dynamics(https://arxiv.org/abs/2401.07516)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Graphs are a powerful representation tool in machine learning applications, with link prediction being a key task in graph learning. Temporal link prediction in dynamic networks is of particular interest due to its potential for solving complex scientific and real-world problems. Traditional approaches to temporal link prediction have focused on finding the aggregation of dynamics of the network as a unified output. In this study, we propose a novel perspective on temporal link prediction by defining nodes as Newtonian objects and incorporating the concept of velocity to predict network dynamics. By computing more specific dynamics of each node, rather than overall dynamics, we improve both accuracy and explainability in predicting future connections. We demonstrate the effectiveness of our approach using two datasets, including 17 years of co-authorship data from PubMed. Experimental results show that our temporal graph embedding dynamics approach improves downstream classification models' ability to predict future collaboration efficacy in co-authorship networks by 17.34% (AUROC improvement relative to the baseline model). Furthermore, our approach offers an interpretable layer over traditional approaches to address the temporal link prediction problem.</li>
</ul>

<h3>Title: InstantID: Zero-shot Identity-Preserving Generation in Seconds</h3>
<ul>
<li><strong>Authors: </strong>Qixun Wang, Xu Bai, Haofan Wang, Zekui Qin, Anthony Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07519">https://arxiv.org/abs/2401.07519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07519">https://arxiv.org/pdf/2401.07519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07519]] InstantID: Zero-shot Identity-Preserving Generation in Seconds(https://arxiv.org/abs/2401.07519)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>There has been significant progress in personalized image synthesis with methods such as Textual Inversion, DreamBooth, and LoRA. Yet, their real-world applicability is hindered by high storage demands, lengthy fine-tuning processes, and the need for multiple reference images. Conversely, existing ID embedding-based methods, while requiring only a single forward inference, face challenges: they either necessitate extensive fine-tuning across numerous model parameters, lack compatibility with community pre-trained models, or fail to maintain high face fidelity. Addressing these limitations, we introduce InstantID, a powerful diffusion model-based solution. Our plug-and-play module adeptly handles image personalization in various styles using just a single facial image, while ensuring high fidelity. To achieve this, we design a novel IdentityNet by imposing strong semantic and weak spatial conditions, integrating facial and landmark images with textual prompts to steer the image generation. InstantID demonstrates exceptional performance and efficiency, proving highly beneficial in real-world applications where identity preservation is paramount. Moreover, our work seamlessly integrates with popular pre-trained text-to-image diffusion models like SD1.5 and SDXL, serving as an adaptable plugin. Our codes and pre-trained checkpoints will be available at https://github.com/InstantID/InstantID.</li>
</ul>

<h3>Title: TAROT: A Hierarchical Framework with Multitask Co-Pretraining on  Semi-Structured Data towards Effective Person-Job Fit</h3>
<ul>
<li><strong>Authors: </strong>Yihan Cao, Xu Chen, Lun Du, Hao Chen, Qiang Fu, Shi Han, Yushu Du, Yanbin Kang, Guangming Lu, Zi Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07525">https://arxiv.org/abs/2401.07525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07525">https://arxiv.org/pdf/2401.07525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07525]] TAROT: A Hierarchical Framework with Multitask Co-Pretraining on  Semi-Structured Data towards Effective Person-Job Fit(https://arxiv.org/abs/2401.07525)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Person-job fit is an essential part of online recruitment platforms in serving various downstream applications like Job Search and Candidate Recommendation. Recently, pretrained large language models have further enhanced the effectiveness by leveraging richer textual information in user profiles and job descriptions apart from user behavior features and job metadata. However, the general domain-oriented design struggles to capture the unique structural information within user profiles and job descriptions, leading to a loss of latent semantic correlations. We propose TAROT, a hierarchical multitask co-pretraining framework, to better utilize structural and semantic information for informative text embeddings. TAROT targets semi-structured text in profiles and jobs, and it is co-pretained with multi-grained pretraining tasks to constrain the acquired semantic information at each level. Experiments on a real-world LinkedIn dataset show significant performance improvements, proving its effectiveness in person-job fit tasks.</li>
</ul>

<h3>Title: Editing Arbitrary Propositions in LLMs without Subject Labels</h3>
<ul>
<li><strong>Authors: </strong>Itai Feigenbaum, Devansh Arpit, Huan Wang, Shelby Heinecke, Juan Carlos Niebles, Weiran Yao, Caiming Xiong, Silvio Savarese</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07526">https://arxiv.org/abs/2401.07526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07526">https://arxiv.org/pdf/2401.07526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07526]] Editing Arbitrary Propositions in LLMs without Subject Labels(https://arxiv.org/abs/2401.07526)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) editing modifies factual information in LLMs. Locate-and-Edit (L\&E) methods accomplish this by finding where relevant information is stored within the neural network, and editing the weights at that location. The goal of editing is to modify the response of an LLM to a proposition independently of its phrasing, while not modifying its response to other related propositions. Existing methods are limited to binary propositions, which represent straightforward binary relations between a subject and an object. Furthermore, existing methods rely on semantic subject labels, which may not be available or even be well-defined in practice. In this paper, we show that both of these issues can be effectively skirted with a simple and fast localization method called Gradient Tracing (GT). This localization method allows editing arbitrary propositions instead of just binary ones, and does so without the need for subject labels. As propositions always have a truth value, our experiments prompt an LLM as a boolean classifier, and edit its T/F response to propositions. Our method applies GT for location tracing, and then edit the model at that location using a mild variant of Rank-One Model Editing (ROME). On datasets of binary propositions derived from the CounterFact dataset, we show that our method -- without access to subject labels -- performs close to state-of-the-art L\&E methods which has access subject labels. We then introduce a new dataset, Factual Accuracy Classification Test (FACT), which includes non-binary propositions and for which subject labels are not generally applicable, and therefore is beyond the scope of existing L\&E methods. Nevertheless, we show that with our method editing is possible on FACT.</li>
</ul>

<h3>Title: One for All: Toward Unified Foundation Models for Earth Vision</h3>
<ul>
<li><strong>Authors: </strong>Zhitong Xiong, Yi Wang, Fahong Zhang, Xiao Xiang Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07527">https://arxiv.org/abs/2401.07527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07527">https://arxiv.org/pdf/2401.07527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07527]] One for All: Toward Unified Foundation Models for Earth Vision(https://arxiv.org/abs/2401.07527)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Foundation models characterized by extensive parameters and trained on large-scale datasets have demonstrated remarkable efficacy across various downstream tasks for remote sensing data. Current remote sensing foundation models typically specialize in a single modality or a specific spatial resolution range, limiting their versatility for downstream datasets. While there have been attempts to develop multi-modal remote sensing foundation models, they typically employ separate vision encoders for each modality or spatial resolution, necessitating a switch in backbones contingent upon the input data. To address this issue, we introduce a simple yet effective method, termed OFA-Net (One-For-All Network): employing a single, shared Transformer backbone for multiple data modalities with different spatial resolutions. Using the masked image modeling mechanism, we pre-train a single Transformer backbone on a curated multi-modal dataset with this simple design. Then the backbone model can be used in different downstream tasks, thus forging a path towards a unified foundation backbone model in Earth vision. The proposed method is evaluated on 12 distinct downstream tasks and demonstrates promising performance.</li>
</ul>

<h3>Title: MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of  Multimodal Large Language Models in Perception</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Wang, Yusheng Liao, Heyang Liu, Hongcheng Liu, Yu Wang, Yanfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07529">https://arxiv.org/abs/2401.07529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07529">https://arxiv.org/pdf/2401.07529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07529]] MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of  Multimodal Large Language Models in Perception(https://arxiv.org/abs/2401.07529)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have shown their remarkable abilities in visual perception and understanding recently. However, how to comprehensively evaluate the capabilities of MLLMs remains a challenge. Most of the existing benchmarks predominantly focus on assessing perception, cognition, and reasoning, neglecting the abilities of self-awareness, referring to the model's recognition of its own capability boundary. In our study, we focus on self-awareness in image perception and introduce the knowledge quadrant for MLLMs, which clearly defines the knowns and unknowns in perception. Based on this, we propose a novel benchmark specifically designed to evaluate the Self-Aware capabilities in Perception for MLLMs(MM-SAP). MM-SAP encompasses three distinct sub-datasets, each focusing on different aspects of self-awareness. We evaluated eight well-known MLLMs using MM-SAP, analyzing their self-awareness and providing detailed insights. Code and data are available at https://github.com/YHWmz/MM-SAP</li>
</ul>

<h3>Title: Study Features via Exploring Distribution Structure</h3>
<ul>
<li><strong>Authors: </strong>Chunxu Cao, Qiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07540">https://arxiv.org/abs/2401.07540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07540">https://arxiv.org/pdf/2401.07540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07540]] Study Features via Exploring Distribution Structure(https://arxiv.org/abs/2401.07540)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present a novel framework for data redundancy measurement based on probabilistic modeling of datasets, and a new criterion for redundancy detection that is resilient to noise. We also develop new methods for data redundancy reduction using both deterministic and stochastic optimization techniques. Our framework is flexible and can handle different types of features, and our experiments on benchmark datasets demonstrate the effectiveness of our methods. We provide a new perspective on feature selection, and propose effective and robust approaches for both supervised and unsupervised learning problems.</li>
</ul>

<h3>Title: Combining Image- and Geometric-based Deep Learning for Shape Regression:  A Comparison to Pixel-level Methods for Segmentation in Chest X-Ray</h3>
<ul>
<li><strong>Authors: </strong>Ron Keuth, Mattias Heinrich</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07542">https://arxiv.org/abs/2401.07542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07542">https://arxiv.org/pdf/2401.07542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07542]] Combining Image- and Geometric-based Deep Learning for Shape Regression:  A Comparison to Pixel-level Methods for Segmentation in Chest X-Ray(https://arxiv.org/abs/2401.07542)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>When solving a segmentation task, shaped-base methods can be beneficial compared to pixelwise classification due to geometric understanding of the target object as shape, preventing the generation of anatomical implausible predictions in particular for corrupted data. In this work, we propose a novel hybrid method that combines a lightweight CNN backbone with a geometric neural network (Point Transformer) for shape regression. Using the same CNN encoder, the Point Transformer reaches segmentation quality on per with current state-of-the-art convolutional decoders ($4\pm1.9$ vs $3.9\pm2.9$ error in mm and $85\pm13$ vs $88\pm10$ Dice), but crucially, is more stable w.r.t image distortion, starting to outperform them at a corruption level of 30%. Furthermore, we include the nnU-Net as an upper baseline, which has $3.7\times$ more trainable parameters than our proposed method.</li>
</ul>

<h3>Title: See the Unseen: Better Context-Consistent Knowledge-Editing by Noises</h3>
<ul>
<li><strong>Authors: </strong>Youcheng Huang, Wenqiang Lei, Zheng Zhang, Jiancheng Lv, Shuicheng Yan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07544">https://arxiv.org/abs/2401.07544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07544">https://arxiv.org/pdf/2401.07544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07544]] See the Unseen: Better Context-Consistent Knowledge-Editing by Noises(https://arxiv.org/abs/2401.07544)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Knowledge-editing updates knowledge of large language models (LLMs) and contributes to the interpretability and application of LLMs. However, knowledge applying is context-consistent: LLMs can recall the same knowledge in different contexts. Existing works ignore this property and the editing lacks generalization. In this paper, we empirically find that the effects of different contexts upon LLMs in recalling the same knowledge follow a Gaussian-like distribution. We then sample Gaussian noises to simulate the effects of different contexts when updating LLMs. By such, we can make LLMs see the unseen contexts where the edited knowledge will be applied, therefore improving the editing generalization. Experimental results on three LLMs demonstrate the effectiveness of our methods and also distinguish our methods from the others of fine-tuning LLMs by noises.</li>
</ul>

<h3>Title: Robust Semi-Supervised Learning for Self-learning Open-World Classes</h3>
<ul>
<li><strong>Authors: </strong>Wenjuan Xi, Xin Song, Weili Guo, Yang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07551">https://arxiv.org/abs/2401.07551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07551">https://arxiv.org/pdf/2401.07551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07551]] Robust Semi-Supervised Learning for Self-learning Open-World Classes(https://arxiv.org/abs/2401.07551)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Existing semi-supervised learning (SSL) methods assume that labeled and unlabeled data share the same class space. However, in real-world applications, unlabeled data always contain classes not present in the labeled set, which may cause classification performance degradation of known classes. Therefore, open-world SSL approaches are researched to handle the presence of multiple unknown classes in the unlabeled data, which aims to accurately classify known classes while fine-grained distinguishing different unknown classes. To address this challenge, in this paper, we propose an open-world SSL method for Self-learning Open-world Classes (SSOC), which can explicitly self-learn multiple unknown classes. Specifically, SSOC first defines class center tokens for both known and unknown classes and autonomously learns token representations according to all samples with the cross-attention mechanism. To effectively discover novel classes, SSOC further designs a pairwise similarity loss in addition to the entropy loss, which can wisely exploit the information available in unlabeled data from instances' predictions and relationships. Extensive experiments demonstrate that SSOC outperforms the state-of-the-art baselines on multiple popular classification benchmarks. Specifically, on the ImageNet-100 dataset with a novel ratio of 90%, SSOC achieves a remarkable 22% improvement.</li>
</ul>

<h3>Title: Call graph discovery in binary programs from unknown instruction set  architectures</h3>
<ul>
<li><strong>Authors: </strong>Håvard Pettersen, Donn Morrison</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07565">https://arxiv.org/abs/2401.07565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07565">https://arxiv.org/pdf/2401.07565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07565]] Call graph discovery in binary programs from unknown instruction set  architectures(https://arxiv.org/abs/2401.07565)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction</a></li>
<li><strong>Abstract: </strong>This study addresses the challenge of reverse engineering binaries from unknown instruction set architectures, a complex task with potential implications for software maintenance and cyber-security. We focus on the tasks of detecting candidate call and return opcodes for automatic extraction of call graphs in order to simplify the reverse engineering process. Empirical testing on a small dataset of binary files from different architectures demonstrates that the approach can accurately detect specific opcodes under conditions of noisy data. The method lays the groundwork for a valuable tool for reverse engineering where the reverse engineer has minimal a priori knowledge of the underlying instruction set architecture.</li>
</ul>

<h3>Title: A Bi-Pyramid Multimodal Fusion Method for the Diagnosis of Bipolar  Disorders</h3>
<ul>
<li><strong>Authors: </strong>Guoxin Wang, Sheng Shi, Shan An, Fengmei Fan, Wenshu Ge, Qi Wang, Feng Yu, Zhiren Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07571">https://arxiv.org/abs/2401.07571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07571">https://arxiv.org/pdf/2401.07571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07571]] A Bi-Pyramid Multimodal Fusion Method for the Diagnosis of Bipolar  Disorders(https://arxiv.org/abs/2401.07571)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Previous research on the diagnosis of Bipolar disorder has mainly focused on resting-state functional magnetic resonance imaging. However, their accuracy can not meet the requirements of clinical diagnosis. Efficient multimodal fusion strategies have great potential for applications in multimodal data and can further improve the performance of medical diagnosis models. In this work, we utilize both sMRI and fMRI data and propose a novel multimodal diagnosis model for bipolar disorder. The proposed Patch Pyramid Feature Extraction Module extracts sMRI features, and the spatio-temporal pyramid structure extracts the fMRI features. Finally, they are fused by a fusion module to output diagnosis results with a classifier. Extensive experiments show that our proposed method outperforms others in balanced accuracy from 0.657 to 0.732 on the OpenfMRI dataset, and achieves the state of the art.</li>
</ul>

<h3>Title: Exploiting GPT-4 Vision for Zero-shot Point Cloud Understanding</h3>
<ul>
<li><strong>Authors: </strong>Qi Sun, Xiao Cui, Wengang Zhou, Houqiang Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07572">https://arxiv.org/abs/2401.07572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07572">https://arxiv.org/pdf/2401.07572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07572]] Exploiting GPT-4 Vision for Zero-shot Point Cloud Understanding(https://arxiv.org/abs/2401.07572)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>In this study, we tackle the challenge of classifying the object category in point clouds, which previous works like PointCLIP struggle to address due to the inherent limitations of the CLIP architecture. Our approach leverages GPT-4 Vision (GPT-4V) to overcome these challenges by employing its advanced generative abilities, enabling a more adaptive and robust classification process. We adapt the application of GPT-4V to process complex 3D data, enabling it to achieve zero-shot recognition capabilities without altering the underlying model architecture. Our methodology also includes a systematic strategy for point cloud image visualization, mitigating domain gap and enhancing GPT-4V's efficiency. Experimental validation demonstrates our approach's superiority in diverse scenarios, setting a new benchmark in zero-shot point cloud classification.</li>
</ul>

<h3>Title: Cascaded Cross-Modal Transformer for Audio-Textual Classification</h3>
<ul>
<li><strong>Authors: </strong>Nicolae-Catalin Ristea, Andrei Anghel, Radu Tudor Ionescu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07575">https://arxiv.org/abs/2401.07575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07575">https://arxiv.org/pdf/2401.07575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07575]] Cascaded Cross-Modal Transformer for Audio-Textual Classification(https://arxiv.org/abs/2401.07575)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Speech classification tasks often require powerful language understanding models to grasp useful features, which becomes problematic when limited training data is available. To attain superior classification performance, we propose to harness the inherent value of multimodal representations by transcribing speech using automatic speech recognition (ASR) models and translating the transcripts into different languages via pretrained translation models. We thus obtain an audio-textual (multimodal) representation for each data sample. Subsequently, we combine language-specific Bidirectional Encoder Representations from Transformers (BERT) with Wav2Vec2.0 audio features via a novel cascaded cross-modal transformer (CCMT). Our model is based on two cascaded transformer blocks. The first one combines text-specific features from distinct languages, while the second one combines acoustic features with multilingual features previously learned by the first transformer block. We employed our system in the Requests Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge. CCMT was declared the winning solution, obtaining an unweighted average recall (UAR) of 65.41% and 85.87% for complaint and request detection, respectively. Moreover, we applied our framework on the Speech Commands v2 and HarperValleyBank dialog data sets, surpassing previous studies reporting results on these benchmarks. Our code is freely available for download at: https://github.com/ristea/ccmt.</li>
</ul>

<h3>Title: PMFSNet: Polarized Multi-scale Feature Self-attention Network For  Lightweight Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jiahui Zhong, Wenhong Tian, Yuanlun Xie, Zhijia Liu, Jie Ou, Taoran Tian, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07579">https://arxiv.org/abs/2401.07579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07579">https://arxiv.org/pdf/2401.07579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07579]] PMFSNet: Polarized Multi-scale Feature Self-attention Network For  Lightweight Medical Image Segmentation(https://arxiv.org/abs/2401.07579)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Current state-of-the-art medical image segmentation methods prioritize accuracy but often at the expense of increased computational demands and larger model sizes. Applying these large-scale models to the relatively limited scale of medical image datasets tends to induce redundant computation, complicating the process without the necessary benefits. This approach not only adds complexity but also presents challenges for the integration and deployment of lightweight models on edge devices. For instance, recent transformer-based models have excelled in 2D and 3D medical image segmentation due to their extensive receptive fields and high parameter count. However, their effectiveness comes with a risk of overfitting when applied to small datasets and often neglects the vital inductive biases of Convolutional Neural Networks (CNNs), essential for local feature representation. In this work, we propose PMFSNet, a novel medical imaging segmentation model that effectively balances global and local feature processing while avoiding the computational redundancy typical in larger models. PMFSNet streamlines the UNet-based hierarchical structure and simplifies the self-attention mechanism's computational complexity, making it suitable for lightweight applications. It incorporates a plug-and-play PMFS block, a multi-scale feature enhancement module based on attention mechanisms, to capture long-term dependencies. Extensive comprehensive results demonstrate that even with a model (less than 1 million parameters), our method achieves superior performance in various segmentation tasks across different data scales. It achieves (IoU) metrics of 84.68%, 82.02%, and 78.82% on public datasets of teeth CT (CBCT), ovarian tumors ultrasound(MMOTU), and skin lesions dermoscopy images (ISIC 2018), respectively. The source code is available at https://github.com/yykzjh/PMFSNet.</li>
</ul>

<h3>Title: Collaboratively Self-supervised Video Representation Learning for Action  Recognition</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhang, Zhifan Wan, Lanqing Hu, Stephen Lin, Shuzhe Wu, Shiguang Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07584">https://arxiv.org/abs/2401.07584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07584">https://arxiv.org/pdf/2401.07584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07584]] Collaboratively Self-supervised Video Representation Learning for Action  Recognition(https://arxiv.org/abs/2401.07584)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Considering the close connection between action recognition and human pose estimation, we design a Collaboratively Self-supervised Video Representation (CSVR) learning framework specific to action recognition by jointly considering generative pose prediction and discriminative context matching as pretext tasks. Specifically, our CSVR consists of three branches: a generative pose prediction branch, a discriminative context matching branch, and a video generating branch. Among them, the first one encodes dynamic motion feature by utilizing Conditional-GAN to predict the human poses of future frames, and the second branch extracts static context features by pulling the representations of clips and compressed key frames from the same video together while pushing apart the pairs from different videos. The third branch is designed to recover the current video frames and predict the future ones, for the purpose of collaboratively improving dynamic motion features and static context features. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the UCF101 and HMDB51 datasets.</li>
</ul>

<h3>Title: Multimodal Crowd Counting with Pix2Pix GANs</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Asif Khan, Hamid Menouar, Ridha Hamila</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07591">https://arxiv.org/abs/2401.07591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07591">https://arxiv.org/pdf/2401.07591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07591]] Multimodal Crowd Counting with Pix2Pix GANs(https://arxiv.org/abs/2401.07591)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Most state-of-the-art crowd counting methods use color (RGB) images to learn the density map of the crowd. However, these methods often struggle to achieve higher accuracy in densely crowded scenes with poor illumination. Recently, some studies have reported improvement in the accuracy of crowd counting models using a combination of RGB and thermal images. Although multimodal data can lead to better predictions, multimodal data might not be always available beforehand. In this paper, we propose the use of generative adversarial networks (GANs) to automatically generate thermal infrared (TIR) images from color (RGB) images and use both to train crowd counting models to achieve higher accuracy. We use a Pix2Pix GAN network first to translate RGB images to TIR images. Our experiments on several state-of-the-art crowd counting models and benchmark crowd datasets report significant improvement in accuracy.</li>
</ul>

<h3>Title: MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Divyanshu Aggarwal, Ashutosh Sathe, Sunayana Sitaram</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07598">https://arxiv.org/abs/2401.07598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07598">https://arxiv.org/pdf/2401.07598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07598]] MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of  Large Language Models(https://arxiv.org/abs/2401.07598)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter efficient finetuning has emerged as a viable solution for improving the performance of Large Language Models without requiring massive resources and compute. Prior work on multilingual evaluation has shown that there is a large gap between the performance of LLMs on English and other languages. Further, there is also a large gap between the performance of smaller open-source models and larger LLMs. Finetuning can be an effective way to bridge this gap and make language models more equitable. In this work, we finetune the LLaMA-7B and Mistral-7B models on synthetic multilingual instruction tuning data to determine its effect on model performance on five downstream tasks covering twenty three languages in all. Additionally, we experiment with various parameters, such as rank for low-rank adaptation and values of quantisation to determine their effects on downstream performance and find that higher rank and higher quantisation values benefit low-resource languages. We find that parameter efficient finetuning of smaller open source models sometimes bridges the gap between the performance of these models and the larger ones, however, English performance can take a hit. We also find that finetuning sometimes improves performance on low-resource languages, while degrading performance on high-resource languages.</li>
</ul>

<h3>Title: Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks  Against LLM-Integrated Applications</h3>
<ul>
<li><strong>Authors: </strong>Xuchen Suo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07612">https://arxiv.org/abs/2401.07612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07612">https://arxiv.org/pdf/2401.07612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07612]] Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks  Against LLM-Integrated Applications(https://arxiv.org/abs/2401.07612)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The critical challenge of prompt injection attacks in Large Language Models (LLMs) integrated applications, a growing concern in the Artificial Intelligence (AI) field. Such attacks, which manipulate LLMs through natural language inputs, pose a significant threat to the security of these applications. Traditional defense strategies, including output and input filtering, as well as delimiter use, have proven inadequate. This paper introduces the 'Signed-Prompt' method as a novel solution. The study involves signing sensitive instructions within command segments by authorized users, enabling the LLM to discern trusted instruction sources. The paper presents a comprehensive analysis of prompt injection attack patterns, followed by a detailed explanation of the Signed-Prompt concept, including its basic architecture and implementation through both prompt engineering and fine-tuning of LLMs. Experiments demonstrate the effectiveness of the Signed-Prompt method, showing substantial resistance to various types of prompt injection attacks, thus validating its potential as a robust defense strategy in AI security.</li>
</ul>

<h3>Title: Fine-Grained Prototypes Distillation for Few-Shot Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Zichen Wang, Bo Yang, Haonan Yue, Zhenghao Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07629">https://arxiv.org/abs/2401.07629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07629">https://arxiv.org/pdf/2401.07629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07629]] Fine-Grained Prototypes Distillation for Few-Shot Object Detection(https://arxiv.org/abs/2401.07629)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Few-shot object detection (FSOD) aims at extending a generic detector for novel object detection with only a few training examples. It attracts great concerns recently due to the practical meanings. Meta-learning has been demonstrated to be an effective paradigm for this task. In general, methods based on meta-learning employ an additional support branch to encode novel examples (a.k.a. support images) into class prototypes, which are then fused with query branch to facilitate the model prediction. However, the class-level prototypes are difficult to precisely generate, and they also lack detailed information, leading to instability in performance.New methods are required to capture the distinctive local context for more robust novel object detection. To this end, we propose to distill the most representative support features into fine-grained prototypes. These prototypes are then assigned into query feature maps based on the matching results, modeling the detailed feature relations between two branches. This process is realized by our Fine-Grained Feature Aggregation (FFA) module. Moreover, in terms of high-level feature fusion, we propose Balanced Class-Agnostic Sampling (B-CAS) strategy and Non-Linear Fusion (NLF) module from differenct perspectives. They are complementary to each other and depict the high-level feature relations more effectively. Extensive experiments on PASCAL VOC and MS COCO benchmarks show that our method sets a new state-of-the-art performance in most settings. Our code is available at https://github.com/wangchen1801/FPD.</li>
</ul>

<h3>Title: Foundation Models for Biomedical Image Segmentation: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Ho Hin Lee, Yu Gu, Theodore Zhao, Yanbo Xu, Jianwei Yang, Naoto Usuyama, Cliff Wong, Mu Wei, Bennett A. Landman, Yuankai Huo, Alberto Santamaria-Pang, Hoifung Poon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07654">https://arxiv.org/abs/2401.07654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07654">https://arxiv.org/pdf/2401.07654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07654]] Foundation Models for Biomedical Image Segmentation: A Survey(https://arxiv.org/abs/2401.07654)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in biomedical image analysis have been significantly driven by the Segment Anything Model (SAM). This transformative technology, originally developed for general-purpose computer vision, has found rapid application in medical image processing. Within the last year, marked by over 100 publications, SAM has demonstrated its prowess in zero-shot learning adaptations for medical imaging. The fundamental premise of SAM lies in its capability to segment or identify objects in images without prior knowledge of the object type or imaging modality. This approach aligns well with tasks achievable by the human visual system, though its application in non-biological vision contexts remains more theoretically challenging. A notable feature of SAM is its ability to adjust segmentation according to a specified resolution scale or area of interest, akin to semantic priming. This adaptability has spurred a wave of creativity and innovation in applying SAM to medical imaging. Our review focuses on the period from April 1, 2023, to September 30, 2023, a critical first six months post-initial publication. We examine the adaptations and integrations of SAM necessary to address longstanding clinical challenges, particularly in the context of 33 open datasets covered in our analysis. While SAM approaches or achieves state-of-the-art performance in numerous applications, it falls short in certain areas, such as segmentation of the carotid artery, adrenal glands, optic nerve, and mandible bone. Our survey delves into the innovative techniques where SAM's foundational approach excels and explores the core concepts in translating and applying these models effectively in diverse medical imaging scenarios.</li>
</ul>

<h3>Title: Empirical Evidence for the Fragment level Understanding on Drug  Molecular Structure of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xiuyuan Hu, Guoqing Liu, Yang Zhao, Hao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07657">https://arxiv.org/abs/2401.07657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07657">https://arxiv.org/pdf/2401.07657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07657]] Empirical Evidence for the Fragment level Understanding on Drug  Molecular Structure of LLMs(https://arxiv.org/abs/2401.07657)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.</li>
</ul>

<h3>Title: Privacy-Aware Single-Nucleotide Polymorphisms (SNPs) using Bilinear  Group Accumulators in Batch Mode</h3>
<ul>
<li><strong>Authors: </strong>William J Buchanan, Sam Grierson, Daniel Uribe</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07691">https://arxiv.org/abs/2401.07691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07691">https://arxiv.org/pdf/2401.07691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07691]] Privacy-Aware Single-Nucleotide Polymorphisms (SNPs) using Bilinear  Group Accumulators in Batch Mode(https://arxiv.org/abs/2401.07691)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, biometric</a></li>
<li><strong>Abstract: </strong>Biometric data is often highly sensitive, and a leak of this data can lead to serious privacy breaches. Some of the most sensitive of this type of data relates to the usage of DNA data on individuals. A leak of this type of data without consent could lead to privacy breaches of data protection laws. Along with this, there have been several recent data breaches related to the leak of DNA information, including from 23andMe and Ancestry. It is thus fundamental that a citizen should have the right to know if their DNA data is contained within a DNA database and ask for it to be removed if they are concerned about its usage. This paper outlines a method of hashing the core information contained within the data stores - known as Single-Nucleotide Polymorphisms (SNPs) - into a bilinear group accumulator in batch mode, which can then be searched by a trusted entity for matches. The time to create the witness proof and to verify were measured at 0.86 ms and 10.90 ms, respectively.</li>
</ul>

<h3>Title: Data vs. Model Machine Learning Fairness Testing: An Empirical Study</h3>
<ul>
<li><strong>Authors: </strong>Arumoy Shome, Luis Cruz, Arie van Deursen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07697">https://arxiv.org/abs/2401.07697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07697">https://arxiv.org/pdf/2401.07697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07697]] Data vs. Model Machine Learning Fairness Testing: An Empirical Study(https://arxiv.org/abs/2401.07697)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Although several fairness definitions and bias mitigation techniques exist in the literature, all existing solutions evaluate fairness of Machine Learning (ML) systems after the training stage. In this paper, we take the first steps towards evaluating a more holistic approach by testing for fairness both before and after model training. We evaluate the effectiveness of the proposed approach and position it within the ML development lifecycle, using an empirical analysis of the relationship between model dependent and independent fairness metrics. The study uses 2 fairness metrics, 4 ML algorithms, 5 real-world datasets and 1600 fairness evaluation cycles. We find a linear relationship between data and model fairness metrics when the distribution and the size of the training data changes. Our results indicate that testing for fairness prior to training can be a ``cheap'' and effective means of catching a biased data collection process early; detecting data drifts in production systems and minimising execution of full training cycles thus reducing development time and costs.</li>
</ul>

<h3>Title: Prompting open-source and commercial language models for grammatical  error correction of English learner text</h3>
<ul>
<li><strong>Authors: </strong>Christopher Davis, Andrew Caines, Øistein Andersen, Shiva Taslimipoor, Helen Yannakoudakis, Zheng Yuan, Christopher Bryant, Marek Rei, Paula Buttery</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07702">https://arxiv.org/abs/2401.07702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07702">https://arxiv.org/pdf/2401.07702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07702]] Prompting open-source and commercial language models for grammatical  error correction of English learner text(https://arxiv.org/abs/2401.07702)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Thanks to recent advances in generative AI, we are able to prompt large language models (LLMs) to produce texts which are fluent and grammatical. In addition, it has been shown that we can elicit attempts at grammatical error correction (GEC) from LLMs when prompted with ungrammatical input sentences. We evaluate how well LLMs can perform at GEC by measuring their performance on established benchmark datasets. We go beyond previous studies, which only examined GPT* models on a selection of English GEC datasets, by evaluating seven open-source and three commercial LLMs on four established GEC benchmarks. We investigate model performance and report results against individual error types. Our results indicate that LLMs do not always outperform supervised English GEC models except in specific contexts -- namely commercial LLMs on benchmarks annotated with fluency corrections as opposed to minimal edits. We find that several open-source models outperform commercial ones on minimal edit benchmarks, and that in some settings zero-shot prompting is just as competitive as few-shot prompting.</li>
</ul>

<h3>Title: Towards Efficient Diffusion-Based Image Editing with Instant Attention  Masks</h3>
<ul>
<li><strong>Authors: </strong>Siyu Zou, Jiji Tang, Yiyi Zhou, Jing He, Chaoyi Zhao, Rongsheng Zhang, Zhipeng Hu, Xiaoshuai Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07709">https://arxiv.org/abs/2401.07709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07709">https://arxiv.org/pdf/2401.07709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07709]] Towards Efficient Diffusion-Based Image Editing with Instant Attention  Masks(https://arxiv.org/abs/2401.07709)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion-based Image Editing (DIE) is an emerging research hot-spot, which often applies a semantic mask to control the target area for diffusion-based editing. However, most existing solutions obtain these masks via manual operations or off-line processing, greatly reducing their efficiency. In this paper, we propose a novel and efficient image editing method for Text-to-Image (T2I) diffusion models, termed Instant Diffusion Editing(InstDiffEdit). In particular, InstDiffEdit aims to employ the cross-modal attention ability of existing diffusion models to achieve instant mask guidance during the diffusion steps. To reduce the noise of attention maps and realize the full automatics, we equip InstDiffEdit with a training-free refinement scheme to adaptively aggregate the attention distributions for the automatic yet accurate mask generation. Meanwhile, to supplement the existing evaluations of DIE, we propose a new benchmark called Editing-Mask to examine the mask accuracy and local editing ability of existing methods. To validate InstDiffEdit, we also conduct extensive experiments on ImageNet and Imagen, and compare it with a bunch of the SOTA methods. The experimental results show that InstDiffEdit not only outperforms the SOTA methods in both image quality and editing results, but also has a much faster inference speed, i.e., +5 to +6 times. Our code available at https://anonymous.4open.science/r/InstDiffEdit-C306/</li>
</ul>

<h3>Title: Graph Transformer GANs with Graph Masked Modeling for Architectural  Layout Generation</h3>
<ul>
<li><strong>Authors: </strong>Hao Tang, Ling Shao, Nicu Sebe, Luc Van Gool</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07721">https://arxiv.org/abs/2401.07721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07721">https://arxiv.org/pdf/2401.07721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07721]] Graph Transformer GANs with Graph Masked Modeling for Architectural  Layout Generation(https://arxiv.org/abs/2401.07721)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>We present a novel graph Transformer generative adversarial network (GTGAN) to learn effective graph node relations in an end-to-end fashion for challenging graph-constrained architectural layout generation tasks. The proposed graph-Transformer-based generator includes a novel graph Transformer encoder that combines graph convolutions and self-attentions in a Transformer to model both local and global interactions across connected and non-connected graph nodes. Specifically, the proposed connected node attention (CNA) and non-connected node attention (NNA) aim to capture the global relations across connected nodes and non-connected nodes in the input graph, respectively. The proposed graph modeling block (GMB) aims to exploit local vertex interactions based on a house layout topology. Moreover, we propose a new node classification-based discriminator to preserve the high-level semantic and discriminative node features for different house components. To maintain the relative spatial relationships between ground truth and predicted graphs, we also propose a novel graph-based cycle-consistency loss. Finally, we propose a novel self-guided pre-training method for graph representation learning. This approach involves simultaneous masking of nodes and edges at an elevated mask ratio (i.e., 40%) and their subsequent reconstruction using an asymmetric graph-centric autoencoder architecture. This method markedly improves the model's learning proficiency and expediency. Experiments on three challenging graph-constrained architectural layout generation tasks (i.e., house layout generation, house roof generation, and building layout generation) with three public datasets demonstrate the effectiveness of the proposed method in terms of objective quantitative scores and subjective visual realism. New state-of-the-art results are established by large margins on these three tasks.</li>
</ul>

<h3>Title: HexaGen3D: StableDiffusion is just one step away from Fast and Diverse  Text-to-3D Generation</h3>
<ul>
<li><strong>Authors: </strong>Antoine Mercier, Ramin Nakhli, Mahesh Reddy, Rajeev Yasarla, Hong Cai, Fatih Porikli, Guillaume Berger</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07727">https://arxiv.org/abs/2401.07727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07727">https://arxiv.org/pdf/2401.07727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07727]] HexaGen3D: StableDiffusion is just one step away from Fast and Diverse  Text-to-3D Generation(https://arxiv.org/abs/2401.07727)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Despite the latest remarkable advances in generative modeling, efficient generation of high-quality 3D assets from textual prompts remains a difficult task. A key challenge lies in data scarcity: the most extensive 3D datasets encompass merely millions of assets, while their 2D counterparts contain billions of text-image pairs. To address this, we propose a novel approach which harnesses the power of large, pretrained 2D diffusion models. More specifically, our approach, HexaGen3D, fine-tunes a pretrained text-to-image model to jointly predict 6 orthographic projections and the corresponding latent triplane. We then decode these latents to generate a textured mesh. HexaGen3D does not require per-sample optimization, and can infer high-quality and diverse objects from textual prompts in 7 seconds, offering significantly better quality-to-latency trade-offs when comparing to existing approaches. Furthermore, HexaGen3D demonstrates strong generalization to new objects or compositions.</li>
</ul>

<h3>Title: MaskClustering: View Consensus based Mask Graph Clustering for  Open-Vocabulary 3D Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mi Yan, Jiazhao Zhang, Yan Zhu, He Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07745">https://arxiv.org/abs/2401.07745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07745">https://arxiv.org/pdf/2401.07745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07745]] MaskClustering: View Consensus based Mask Graph Clustering for  Open-Vocabulary 3D Instance Segmentation(https://arxiv.org/abs/2401.07745)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Open-vocabulary 3D instance segmentation has emerged as a frontier topic due to its capability to segment 3D instances beyond a predefined set of categories. However, compared to significant progress in the 2D domain, methods for 3D open-vocabulary instance segmentation are hindered by the limited scale of high-quality annotated 3D data. To harness the capabilities of 2D models, recent efforts have focused on merging 2D masks based on metrics such as geometric and semantic similarity to form 3D instances. In contrast to these local metrics, we propose a novel metric called view consensus to better exploit multi-view observation. The key insight is that two 2D masks should be considered as belonging to the same instance if a considerable number of other 2D masks from other views contain both these two masks. Based on this metric, we build a global mask graph and iteratively cluster masks, prioritizing mask pairs with solid view consensus. The corresponding 3D points cluster of these 2D mask clusters can be regarded as 3D instances, along with the fused open-vocabulary features from clustered 2D masks. Through this multi-view verification and fusion mechanism, our method effectively leverages the prior instance knowledge from massive 2D masks predicted by visual foundation models, eliminating the need for training on 3D data. Experiments on publicly available datasets, including ScanNet200 and MatterPort3D, demonstrate that our method achieves state-of-the-art performance in both open-vocabulary instance segmentation and class-agnostic mask generation. Our project page is at https://pku-epic.github.io/MaskClustering.</li>
</ul>

<h3>Title: Joint Probability Selection and Power Allocation for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Ouiame Marnissi, Hajar EL Hammouti, El Houcine Bergou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07756">https://arxiv.org/abs/2401.07756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07756">https://arxiv.org/pdf/2401.07756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07756]] Joint Probability Selection and Power Allocation for Federated Learning(https://arxiv.org/abs/2401.07756)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In this paper, we study the performance of federated learning over wireless networks, where devices with a limited energy budget train a machine learning model. The federated learning performance depends on the selection of the clients participating in the learning at each round. Most existing studies suggest deterministic approaches for the client selection, resulting in challenging optimization problems that are usually solved using heuristics, and therefore without guarantees on the quality of the final solution. We formulate a new probabilistic approach to jointly select clients and allocate power optimally so that the expected number of participating clients is maximized. To solve the problem, a new alternating algorithm is proposed, where at each step, the closed-form solutions for user selection probabilities and power allocations are obtained. Our numerical results show that the proposed approach achieves a significant performance in terms of energy consumption, completion time and accuracy as compared to the studied benchmarks.</li>
</ul>

<h3>Title: Seeing the Unseen: Visual Common Sense for Semantic Placement</h3>
<ul>
<li><strong>Authors: </strong>Ram Ramrakhya, Aniruddha Kembhavi, Dhruv Batra, Zsolt Kira, Kuo-Hao Zeng, Luca Weihs</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07770">https://arxiv.org/abs/2401.07770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07770">https://arxiv.org/pdf/2401.07770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07770]] Seeing the Unseen: Visual Common Sense for Semantic Placement(https://arxiv.org/abs/2401.07770)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Computer vision tasks typically involve describing what is present in an image (e.g. classification, detection, segmentation, and captioning). We study a visual common sense task that requires understanding what is not present. Specifically, given an image (e.g. of a living room) and name of an object ("cushion"), a vision system is asked to predict semantically-meaningful regions (masks or bounding boxes) in the image where that object could be placed or is likely be placed by humans (e.g. on the sofa). We call this task: Semantic Placement (SP) and believe that such common-sense visual understanding is critical for assitive robots (tidying a house), and AR devices (automatically rendering an object in the user's space). Studying the invisible is hard. Datasets for image description are typically constructed by curating relevant images and asking humans to annotate the contents of the image; neither of those two steps are straightforward for objects not present in the image. We overcome this challenge by operating in the opposite direction: we start with an image of an object in context from web, and then remove that object from the image via inpainting. This automated pipeline converts unstructured web data into a dataset comprising pairs of images with/without the object. Using this, we collect a novel dataset, with ${\sim}1.3$M images across $9$ object categories, and train a SP prediction model called CLIP-UNet. CLIP-UNet outperforms existing VLMs and baselines that combine semantic priors with object detectors on real-world and simulated images. In our user studies, we find that the SP masks predicted by CLIP-UNet are favored $43.7\%$ and $31.3\%$ times when comparing against the $4$ SP baselines on real and simulated images. In addition, we demonstrate leveraging SP mask predictions from CLIP-UNet enables downstream applications like building tidying robots in indoor environments.</li>
</ul>

<h3>Title: Quantum Transfer Learning for Acceptability Judgements</h3>
<ul>
<li><strong>Authors: </strong>Giuseppe Buonaiuto, Raffaele Guarasci, Aniello Minutolo, Giuseppe De Pietro, Massimo Esposito</a></li>
<li><strong>Subjects: </strong>cs.CL, physics.comp-ph, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07777">https://arxiv.org/abs/2401.07777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07777">https://arxiv.org/pdf/2401.07777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07777]] Quantum Transfer Learning for Acceptability Judgements(https://arxiv.org/abs/2401.07777)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hybrid quantum-classical classifiers promise to positively impact critical aspects of natural language processing tasks, particularly classification-related ones. Among the possibilities currently investigated, quantum transfer learning, i.e., using a quantum circuit for fine-tuning pre-trained classical models for a specific task, is attracting significant attention as a potential platform for proving quantum advantage. This work shows potential advantages, both in terms of performance and expressiveness, of quantum transfer learning algorithms trained on embedding vectors extracted from a large language model to perform classification on a classical Linguistics task: acceptability judgments. Acceptability judgment is the ability to determine whether a sentence is considered natural and well-formed by a native speaker. The approach has been tested on sentences extracted from ItaCoLa, a corpus that collects Italian sentences labeled with their acceptability judgment. The evaluation phase shows results for the quantum transfer learning pipeline comparable to state-of-the-art classical transfer learning algorithms, proving current quantum computers' capabilities to tackle NLP tasks for ready-to-use applications. Furthermore, a qualitative linguistic analysis, aided by explainable AI methods, reveals the capabilities of quantum transfer learning algorithms to correctly classify complex and more structured sentences, compared to their classical counterpart. This finding sets the ground for a quantifiable quantum advantage in NLP in the near future.</li>
</ul>

<h3>Title: Towards A Better Metric for Text-to-Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Jay Zhangjie Wu, Guian Fang, Haoning Wu, Xintao Wang, Yixiao Ge, Xiaodong Cun, David Junhao Zhang, Jia-Wei Liu, Yuchao Gu, Rui Zhao, Weisi Lin, Wynne Hsu, Ying Shan, Mike Zheng Shou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07781">https://arxiv.org/abs/2401.07781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07781">https://arxiv.org/pdf/2401.07781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07781]] Towards A Better Metric for Text-to-Video Generation(https://arxiv.org/abs/2401.07781)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative models have demonstrated remarkable capability in synthesizing high-quality text, images, and videos. For video generation, contemporary text-to-video models exhibit impressive capabilities, crafting visually stunning videos. Nonetheless, evaluating such videos poses significant challenges. Current research predominantly employs automated metrics such as FVD, IS, and CLIP Score. However, these metrics provide an incomplete analysis, particularly in the temporal assessment of video content, thus rendering them unreliable indicators of true video quality. Furthermore, while user studies have the potential to reflect human perception accurately, they are hampered by their time-intensive and laborious nature, with outcomes that are often tainted by subjective bias. In this paper, we investigate the limitations inherent in existing metrics and introduce a novel evaluation pipeline, the Text-to-Video Score (T2VScore). This metric integrates two pivotal criteria: (1) Text-Video Alignment, which scrutinizes the fidelity of the video in representing the given text description, and (2) Video Quality, which evaluates the video's overall production caliber with a mixture of experts. Moreover, to evaluate the proposed metrics and facilitate future improvements on them, we present the TVGE dataset, collecting human judgements of 2,543 text-to-video generated videos on the two criteria. Experiments on the TVGE dataset demonstrate the superiority of the proposed T2VScore on offering a better metric for text-to-video generation.</li>
</ul>

<h3>Title: Cybersecurity and Embodiment Integrity for Modern Robots: A Conceptual  Framework</h3>
<ul>
<li><strong>Authors: </strong>Alberto Giaretta, Amy Loutfi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07783">https://arxiv.org/abs/2401.07783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07783">https://arxiv.org/pdf/2401.07783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07783]] Cybersecurity and Embodiment Integrity for Modern Robots: A Conceptual  Framework(https://arxiv.org/abs/2401.07783)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Modern robots are stepping away from monolithic entities built using ad-hoc sensors and actuators, due to new technologies and communication paradigms, such as the Internet of Things (IoT) and the Robotic Operating System (ROS). Using such paradigms, robots can be built by acquiring heterogeneous standard devices and putting them in communication with each other. This approach brings high degrees of modularity, but it also yields uncertainty of providing cybersecurity assurances, and guarantees on the integrity of the embodiment. In this paper, we first illustrate how cyberattacks on different devices can have radically different consequences on the robot's ability to complete its tasks and preserve its embodiment. We also claim that modern robots should have self-awareness for what it concerns such aspects, and formulate the different characteristics that robots should integrate for doing so. Then, we show that achieving these propositions requires that robots possess at least three properties that conceptually link devices and tasks. Last, we reflect on how these three properties could be achieved in a larger conceptual framework.</li>
</ul>

<h3>Title: Improving OCR Quality in 19th Century Historical Documents Using a  Combined Machine Learning Based Approach</h3>
<ul>
<li><strong>Authors: </strong>David Fleischhacker, Wolfgang Goederle, Roman Kern</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07787">https://arxiv.org/abs/2401.07787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07787">https://arxiv.org/pdf/2401.07787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07787]] Improving OCR Quality in 19th Century Historical Documents Using a  Combined Machine Learning Based Approach(https://arxiv.org/abs/2401.07787)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper addresses a major challenge to historical research on the 19th century. Large quantities of sources have become digitally available for the first time, while extraction techniques are lagging behind. Therefore, we researched machine learning (ML) models to recognise and extract complex data structures in a high-value historical primary source, the Schematismus. It records every single person in the Habsburg civil service above a certain hierarchical level between 1702 and 1918 and documents the genesis of the central administration over two centuries. Its complex and intricate structure as well as its enormous size have so far made any more comprehensive analysis of the administrative and social structure of the later Habsburg Empire on the basis of this source impossible. We pursued two central objectives: Primarily, the improvement of the OCR quality, for which we considered an improved structure recognition to be essential; in the further course, it turned out that this also made the extraction of the data structure possible. We chose Faster R-CNN as base for the ML architecture for structure recognition. In order to obtain the required amount of training data quickly and economically, we synthesised Hof- und Staatsschematismus-style data, which we used to train our model. The model was then fine-tuned with a smaller set of manually annotated historical source data. We then used Tesseract-OCR, which was further optimised for the style of our documents, to complete the combined structure extraction and OCR process. Results show a significant decrease in the two standard parameters of OCR-performance, WER and CER (where lower values are better). Combined structure detection and fine-tuned OCR improved CER and WER values by remarkable 71.98 percent (CER) respectively 52.49 percent (WER).</li>
</ul>

<h3>Title: Flexibly Scaling Large Language Models Contexts Through Extensible  Tokenization</h3>
<ul>
<li><strong>Authors: </strong>Ninglu Shao, Shitao Xiao, Zheng Liu, Peitian Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07793">https://arxiv.org/abs/2401.07793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07793">https://arxiv.org/pdf/2401.07793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07793]] Flexibly Scaling Large Language Models Contexts Through Extensible  Tokenization(https://arxiv.org/abs/2401.07793)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are in need of sufficient contexts to handle many critical applications, such as retrieval augmented generation and few-shot learning. However, due to the constrained window size, the LLMs can only access to the information within a limited context. Although the size of context window can be extended by fine-tuning, it will result in a substantial cost in both training and inference stage. In this paper, we present Extensible Tokenization as an alternative method which realizes the flexible scaling of LLMs' context. Extensible Tokenization stands as a midware in between of the tokenized context and the LLM, which transforms the raw token embeddings into the extensible embeddings. Such embeddings provide a more compact representation for the long context, on top of which the LLM is able to perceive more information with the same context window. Extensible Tokenization is also featured by its flexibility: the scaling factor can be flexibly determined within a feasible scope, leading to the extension of an arbitrary context length at the inference time. Besides, Extensible Tokenization is introduced as a drop-in component, which can be seamlessly plugged into not only the LLM itself and but also its fine-tuned derivatives, bringing in the extended contextual information while fully preserving the LLM's existing capabilities. We perform comprehensive experiments on long-context language modeling and understanding tasks, which verify Extensible Tokenization as an effective, efficient, flexible, and compatible method to extend LLM's context. Our model and source code will be made publicly available.</li>
</ul>

<h3>Title: Fusing Echocardiography Images and Medical Records for Continuous  Patient Stratification</h3>
<ul>
<li><strong>Authors: </strong>Nathan Painchaud, Pierre-Yves Courand, Pierre-Marc Jodoin, Nicolas Duchateau, Olivier Bernard</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07796">https://arxiv.org/abs/2401.07796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07796">https://arxiv.org/pdf/2401.07796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07796]] Fusing Echocardiography Images and Medical Records for Continuous  Patient Stratification(https://arxiv.org/abs/2401.07796)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning now enables automatic and robust extraction of cardiac function descriptors from echocardiographic sequences, such as ejection fraction or strain. These descriptors provide fine-grained information that physicians consider, in conjunction with more global variables from the clinical record, to assess patients' condition. Drawing on novel transformer models applied to tabular data (e.g., variables from electronic health records), we propose a method that considers all descriptors extracted from medical records and echocardiograms to learn the representation of a difficult-to-characterize cardiovascular pathology, namely hypertension. Our method first projects each variable into its own representation space using modality-specific approaches. These standardized representations of multimodal data are then fed to a transformer encoder, which learns to merge them into a comprehensive representation of the patient through a pretext task of predicting a clinical rating. This pretext task is formulated as an ordinal classification to enforce a pathological continuum in the representation space. We observe the major trends along this continuum for a cohort of 239 hypertensive patients to describe, with unprecedented gradation, the effect of hypertension on a number of cardiac function descriptors. Our analysis shows that i) pretrained weights from a foundation model allow to reach good performance (83% accuracy) even with limited data (less than 200 training samples), ii) trends across the population are reproducible between trainings, and iii) for descriptors whose interactions with hypertension are well documented, patterns are consistent with prior physiological knowledge.</li>
</ul>

<h3>Title: Consolidating Strategies for Countering Hate Speech Using Persuasive  Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Sougata Saha, Rohini Srihari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07810">https://arxiv.org/abs/2401.07810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07810">https://arxiv.org/pdf/2401.07810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07810]] Consolidating Strategies for Countering Hate Speech Using Persuasive  Dialogues(https://arxiv.org/abs/2401.07810)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hateful comments are prevalent on social media platforms. Although tools for automatically detecting, flagging, and blocking such false, offensive, and harmful content online have lately matured, such reactive and brute force methods alone provide short-term and superficial remedies while the perpetrators persist. With the public availability of large language models which can generate articulate synthetic and engaging content at scale, there are concerns about the rapid growth of dissemination of such malicious content on the web. There is now a need to focus on deeper, long-term solutions that involve engaging with the human perpetrator behind the source of the content to change their viewpoint or at least bring down the rhetoric using persuasive means. To do that, we propose defining and experimenting with controllable strategies for generating counter-arguments to hateful comments in online conversations. We experiment with controlling response generation using features based on (i) argument structure and reasoning-based Walton argument schemes, (ii) counter-argument speech acts, and (iii) human characteristics-based qualities such as Big-5 personality traits and human values. Using automatic and human evaluations, we determine the best combination of features that generate fluent, argumentative, and logically sound arguments for countering hate. We further share the developed computational models for automatically annotating text with such features, and a silver-standard annotated version of an existing hate speech dialog corpora.</li>
</ul>

<h3>Title: Wikidata as a seed for Web Extraction</h3>
<ul>
<li><strong>Authors: </strong>Kunpeng Guo, Dennis Diefenbach, Antoine Gourru, Christophe Gravier</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07812">https://arxiv.org/abs/2401.07812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07812">https://arxiv.org/pdf/2401.07812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07812]] Wikidata as a seed for Web Extraction(https://arxiv.org/abs/2401.07812)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Wikidata has grown to a knowledge graph with an impressive size. To date, it contains more than 17 billion triples collecting information about people, places, films, stars, publications, proteins, and many more. On the other side, most of the information on the Web is not published in highly structured data repositories like Wikidata, but rather as unstructured and semi-structured content, more concretely in HTML pages containing text and tables. Finding, monitoring, and organizing this data in a knowledge graph is requiring considerable work from human editors. The volume and complexity of the data make this task difficult and time-consuming. In this work, we present a framework that is able to identify and extract new facts that are published under multiple Web domains so that they can be proposed for validation by Wikidata editors. The framework is relying on question-answering technologies. We take inspiration from ideas that are used to extract facts from textual collections and adapt them to extract facts from Web pages. For achieving this, we demonstrate that language models can be adapted to extract facts not only from textual collections but also from Web pages. By exploiting the information already contained in Wikidata the proposed framework can be trained without the need for any additional learning signals and can extract new facts for a wide range of properties and domains. Following this path, Wikidata can be used as a seed to extract facts on the Web. Our experiments show that we can achieve a mean performance of 84.07 at F1-score. Moreover, our estimations show that we can potentially extract millions of facts that can be proposed for human validation. The goal is to help editors in their daily tasks and contribute to the completion of the Wikidata knowledge graph.</li>
</ul>

<h3>Title: Question Translation Training for Better Multilingual Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Zhu, Shujian Huang, Fei Yuan, Shuaijie She, Jiajun Chen, Alexandra Birch</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07817">https://arxiv.org/abs/2401.07817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07817">https://arxiv.org/pdf/2401.07817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07817]] Question Translation Training for Better Multilingual Reasoning(https://arxiv.org/abs/2401.07817)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models show compelling performance on reasoning tasks but they tend to perform much worse in languages other than English. This is unsurprising given that their training data largely consists of English text and instructions. A typical solution is to translate instruction data into all languages of interest, and then train on the resulting multilingual data, which is called translate-training. This approach not only incurs high cost, but also results in poorly translated data due to the non-standard formatting of chain-of-thought and mathematical reasoning instructions. In this paper, we explore the benefits of question alignment, where we train the model to translate reasoning questions into English by finetuning on X-English question data. In this way we perform targetted, in-domain language alignment which makes best use of English instruction data to unlock the LLMs' multilingual reasoning abilities. Experimental results on LLaMA2-13B show that question alignment leads to consistent improvements over the translate-training approach: an average improvement of 11.3\% and 16.1\% accuracy across ten languages on the MGSM and MSVAMP maths reasoning benchmarks (The project will be available at: https://github.com/NJUNLP/QAlign).</li>
</ul>

<h3>Title: Phenotyping calcification in vascular tissues using artificial  intelligence</h3>
<ul>
<li><strong>Authors: </strong>Mehdi Ramezanpour, Anne M. Robertson, Yasutaka Tobe, Xiaowei Jia, Juan R. Cebral</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.data-an, q-bio.QM, q-bio.TO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07825">https://arxiv.org/abs/2401.07825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07825">https://arxiv.org/pdf/2401.07825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07825]] Phenotyping calcification in vascular tissues using artificial  intelligence(https://arxiv.org/abs/2401.07825)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Vascular calcification is implicated as an important factor in major adverse cardiovascular events (MACE), including heart attack and stroke. A controversy remains over how to integrate the diverse forms of vascular calcification into clinical risk assessment tools. Even the commonly used calcium score for coronary arteries, which assumes risk scales positively with total calcification, has important inconsistencies. Fundamental studies are needed to determine how risk is influenced by the diverse calcification phenotypes. However, studies of these kinds are hindered by the lack of high-throughput, objective, and non-destructive tools for classifying calcification in imaging data sets. Here, we introduce a new classification system for phenotyping calcification along with a semi-automated, non-destructive pipeline that can distinguish these phenotypes in even atherosclerotic tissues. The pipeline includes a deep-learning-based framework for segmenting lipid pools in noisy micro-CT images and an unsupervised clustering framework for categorizing calcification based on size, clustering, and topology. This approach is illustrated for five vascular specimens, providing phenotyping for thousands of calcification particles across as many as 3200 images in less than seven hours. Average Dice Similarity Coefficients of 0.96 and 0.87 could be achieved for tissue and lipid pool, respectively, with training and validation needed on only 13 images despite the high heterogeneity in these tissues. By introducing an efficient and comprehensive approach to phenotyping calcification, this work enables large-scale studies to identify a more reliable indicator of the risk of cardiovascular events, a leading cause of global mortality and morbidity.</li>
</ul>

<h3>Title: Milestones in Bengali Sentiment Analysis leveraging Transformer-models:  Fundamentals, Challenges and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Saptarshi Sengupta, Shreya Ghosh, Prasenjit Mitra, Tarikul Islam Tamiti</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07847">https://arxiv.org/abs/2401.07847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07847">https://arxiv.org/pdf/2401.07847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07847]] Milestones in Bengali Sentiment Analysis leveraging Transformer-models:  Fundamentals, Challenges and Future Directions(https://arxiv.org/abs/2401.07847)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sentiment Analysis (SA) refers to the task of associating a view polarity (usually, positive, negative, or neutral; or even fine-grained such as slightly angry, sad, etc.) to a given text, essentially breaking it down to a supervised (since we have the view labels apriori) classification task. Although heavily studied in resource-rich languages such as English thus pushing the SOTA by leaps and bounds, owing to the arrival of the Transformer architecture, the same cannot be said for resource-poor languages such as Bengali (BN). For a language spoken by roughly 300 million people, the technology enabling them to run trials on their favored tongue is severely lacking. In this paper, we analyze the SOTA for SA in Bengali, particularly, Transformer-based models. We discuss available datasets, their drawbacks, the nuances associated with Bengali i.e. what makes this a challenging language to apply SA on, and finally provide insights for future direction to mitigate the limitations in the field.</li>
</ul>

<h3>Title: Unlocking Efficiency in Large Language Model Inference: A Comprehensive  Survey of Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Heming Xia, Zhe Yang, Qingxiu Dong, Peiyi Wang, Yongqi Li, Tao Ge, Tianyu Liu, Wenjie Li, Zhifang Sui</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07851">https://arxiv.org/abs/2401.07851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07851">https://arxiv.org/pdf/2401.07851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07851]] Unlocking Efficiency in Large Language Model Inference: A Comprehensive  Survey of Speculative Decoding(https://arxiv.org/abs/2401.07851)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To mitigate the high inference latency stemming from autoregressive decoding in Large Language Models (LLMs), Speculative Decoding has emerged as a novel decoding paradigm for LLM inference. In each decoding step, this method first efficiently drafts several future tokens and then verifies them in parallel. Unlike autoregressive decoding, Speculative Decoding facilitates the simultaneous decoding of multiple tokens per step, thereby accelerating inference. This paper presents a comprehensive overview and analysis of this promising decoding paradigm. We begin by providing a formal definition and formulation of Speculative Decoding. Then, we organize in-depth discussions on its key facets, including current leading techniques, the challenges faced, and potential future directions in this field. We aim for this work to serve as a catalyst for further research on Speculative Decoding, ultimately contributing to more efficient LLM inference.</li>
</ul>

<h3>Title: VeCAF: VLM-empowered Collaborative Active Finetuning with Training  Objective Awareness</h3>
<ul>
<li><strong>Authors: </strong>Rongyu Zhang, Zefan Cai, Huanrui Yang, Zidong Liu, Denis Gudovskiy, Tomoyuki Okuno, Yohei Nakata, Kurt Keutzer, Baobao Chang, Yuan Du, Li Du, Shanghang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07853">https://arxiv.org/abs/2401.07853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07853">https://arxiv.org/pdf/2401.07853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07853]] VeCAF: VLM-empowered Collaborative Active Finetuning with Training  Objective Awareness(https://arxiv.org/abs/2401.07853)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Finetuning a pretrained vision model (PVM) is a common technique for learning downstream vision tasks. The conventional finetuning process with the randomly sampled data points results in diminished training efficiency. To address this drawback, we propose a novel approach, VLM-empowered Collaborative Active Finetuning (VeCAF). VeCAF optimizes a parametric data selection model by incorporating the training objective of the model being tuned. Effectively, this guides the PVM towards the performance goal with improved data and computational efficiency. As vision-language models (VLMs) have achieved significant advancements by establishing a robust connection between image and language domains, we exploit the inherent semantic richness of the text embedding space and utilize text embedding of pretrained VLM models to augment PVM image features for better data selection and finetuning. Furthermore, the flexibility of text-domain augmentation gives VeCAF a unique ability to handle out-of-distribution scenarios without external augmented data. Extensive experiments show the leading performance and high efficiency of VeCAF that is superior to baselines in both in-distribution and out-of-distribution image classification tasks. On ImageNet, VeCAF needs up to 3.3x less training batches to reach the target performance compared to full finetuning and achieves 2.8% accuracy improvement over SOTA methods with the same number of batches.</li>
</ul>

<h3>Title: $M^{2}$Fusion: Bayesian-based Multimodal Multi-level Fusion on  Colorectal Cancer Microsatellite Instability Prediction</h3>
<ul>
<li><strong>Authors: </strong>Quan Liu, Jiawen Yao, Lisha Yao, Xin Chen, Jingren Zhou, Le Lu, Ling Zhang, Zaiyi Liu, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07854">https://arxiv.org/abs/2401.07854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07854">https://arxiv.org/pdf/2401.07854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07854]] $M^{2}$Fusion: Bayesian-based Multimodal Multi-level Fusion on  Colorectal Cancer Microsatellite Instability Prediction(https://arxiv.org/abs/2401.07854)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Colorectal cancer (CRC) micro-satellite instability (MSI) prediction on histopathology images is a challenging weakly supervised learning task that involves multi-instance learning on gigapixel images. To date, radiology images have proven to have CRC MSI information and efficient patient imaging techniques. Different data modalities integration offers the opportunity to increase the accuracy and robustness of MSI prediction. Despite the progress in representation learning from the whole slide images (WSI) and exploring the potential of making use of radiology data, CRC MSI prediction remains a challenge to fuse the information from multiple data modalities (e.g., pathology WSI and radiology CT image). In this paper, we propose $M^{2}$Fusion: a Bayesian-based multimodal multi-level fusion pipeline for CRC MSI. The proposed fusion model $M^{2}$Fusion is capable of discovering more novel patterns within and across modalities that are beneficial for predicting MSI than using a single modality alone, as well as other fusion methods. The contribution of the paper is three-fold: (1) $M^{2}$Fusion is the first pipeline of multi-level fusion on pathology WSI and 3D radiology CT image for MSI prediction; (2) CT images are the first time integrated into multimodal fusion for CRC MSI prediction; (3) feature-level fusion strategy is evaluated on both Transformer-based and CNN-based method. Our approach is validated on cross-validation of 352 cases and outperforms either feature-level (0.8177 vs. 0.7908) or decision-level fusion strategy (0.8177 vs. 0.7289) on AUC score.</li>
</ul>

<h3>Title: Authorship Obfuscation in Multilingual Machine-Generated Text Detection</h3>
<ul>
<li><strong>Authors: </strong>Dominik Macko, Robert Moro, Adaku Uchendu, Ivan Srba, Jason Samuel Lucas, Michiharu Yamashita, Nafis Irtiza Tripto, Dongwon Lee, Jakub Simko, Maria Bielikova</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07867">https://arxiv.org/abs/2401.07867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07867">https://arxiv.org/pdf/2401.07867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07867]] Authorship Obfuscation in Multilingual Machine-Generated Text Detection(https://arxiv.org/abs/2401.07867)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>High-quality text generation capability of latest Large Language Models (LLMs) causes concerns about their misuse (e.g., in massive generation/spread of disinformation). Machine-generated text (MGT) detection is important to cope with such threats. However, it is susceptible to authorship obfuscation (AO) methods, such as paraphrasing, which can cause MGTs to evade detection. So far, this was evaluated only in monolingual settings. Thus, the susceptibility of recently proposed multilingual detectors is still unknown. We fill this gap by comprehensively benchmarking the performance of 10 well-known AO methods, attacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10 $\times$ 37 $\times$ 11 = 4,070 combinations). We also evaluate the effect of data augmentation on adversarial robustness using obfuscated texts. The results indicate that all tested AO methods can cause detection evasion in all tested languages, where homoglyph attacks are especially successful.</li>
</ul>

<h3>Title: JumpCoder: Go Beyond Autoregressive Coder via Online Modification</h3>
<ul>
<li><strong>Authors: </strong>Mouxiang Chen, Hao Tian, Zhongxin Liu, Xiaoxue Ren, Jianling Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07870">https://arxiv.org/abs/2401.07870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07870">https://arxiv.org/pdf/2401.07870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07870]] JumpCoder: Go Beyond Autoregressive Coder via Online Modification(https://arxiv.org/abs/2401.07870)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While existing code large language models (code LLMs) exhibit impressive capabilities in code generation, their autoregressive sequential generation inherently lacks reversibility. This limitation hinders them from timely correcting previous missing statements during coding as humans do, often leading to error propagation and suboptimal performance. We introduce JumpCoder, a novel modelagnostic framework that enables online modification and non-sequential generation to augment the code LLMs. The key idea behind JumpCoder is to insert new code into the currently generated code when necessary during generation, which is achieved through an auxiliary infilling model that works in tandem with the code LLM. Since identifying the best infill position beforehand is intractable, we adopt an infill-first, judge-later strategy, which experiments with filling at the $k$ most critical positions following the generation of each line, and uses an Abstract Syntax Tree (AST) parser alongside the Generation Model Scoring to effectively judge the validity of each potential infill. Extensive experiments using six state-of-the-art code LLMs across multiple benchmarks consistently indicate significant improvements over all baselines. Notably, JumpCoder assists code LLMs in achieving up to a 3.6% increase in Pass@1 for Python, 6.3% for Java, and 3.7% for C++ in the multilingual HumanEval benchmarks. Our code is public at https://github.com/Keytoyze/JumpCoder.</li>
</ul>

<h3>Title: The What, Why, and How of Context Length Extension Techniques in Large  Language Models -- A Detailed Survey</h3>
<ul>
<li><strong>Authors: </strong>Saurav Pawar, S.M Towhidul Islam Tonmoy, S M Mehedi Zaman, Vinija Jain, Aman Chadha, Amitava Das</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07872">https://arxiv.org/abs/2401.07872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07872">https://arxiv.org/pdf/2401.07872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07872]] The What, Why, and How of Context Length Extension Techniques in Large  Language Models -- A Detailed Survey(https://arxiv.org/abs/2401.07872)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) represents a notable breakthrough in Natural Language Processing (NLP), contributing to substantial progress in both text comprehension and generation. However, amidst these advancements, it is noteworthy that LLMs often face a limitation in terms of context length extrapolation. Understanding and extending the context length for LLMs is crucial in enhancing their performance across various NLP applications. In this survey paper, we delve into the multifaceted aspects of exploring why it is essential, and the potential transformations that superior techniques could bring to NLP applications. We study the inherent challenges associated with extending context length and present an organized overview of the existing strategies employed by researchers. Additionally, we discuss the intricacies of evaluating context extension techniques and highlight the open challenges that researchers face in this domain. Furthermore, we explore whether there is a consensus within the research community regarding evaluation standards and identify areas where further agreement is needed. This comprehensive survey aims to serve as a valuable resource for researchers, guiding them through the nuances of context length extension techniques and fostering discussions on future advancements in this evolving field.</li>
</ul>

<h3>Title: EMBRE: Entity-aware Masking for Biomedical Relation Extraction</h3>
<ul>
<li><strong>Authors: </strong>Mingjie Li, Karin Verspoor</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07877">https://arxiv.org/abs/2401.07877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07877">https://arxiv.org/pdf/2401.07877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07877]] EMBRE: Entity-aware Masking for Biomedical Relation Extraction(https://arxiv.org/abs/2401.07877)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Information extraction techniques, including named entity recognition (NER) and relation extraction (RE), are crucial in many domains to support making sense of vast amounts of unstructured text data by identifying and connecting relevant information. Such techniques can assist researchers in extracting valuable insights. In this paper, we introduce the Entity-aware Masking for Biomedical Relation Extraction (EMBRE) method for biomedical relation extraction, as applied in the context of the BioRED challenge Task 1, in which human-annotated entities are provided as input. Specifically, we integrate entity knowledge into a deep neural network by pretraining the backbone model with an entity masking objective. We randomly mask named entities for each instance and let the model identify the masked entity along with its type. In this way, the model is capable of learning more specific knowledge and more robust representations. Then, we utilize the pre-trained model as our backbone to encode language representations and feed these representations into two multilayer perceptron (MLPs) to predict the logits for relation and novelty, respectively. The experimental results demonstrate that our proposed method can improve the performances of entity pair, relation and novelty extraction over our baseline.</li>
</ul>

<h3>Title: Learned Best-Effort LLM Serving</h3>
<ul>
<li><strong>Authors: </strong>Siddharth Jha, Coleman Hooper, Xiaoxuan Liu, Sehoon Kim, Kurt Keutzer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07886">https://arxiv.org/abs/2401.07886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07886">https://arxiv.org/pdf/2401.07886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07886]] Learned Best-Effort LLM Serving(https://arxiv.org/abs/2401.07886)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Many applications must provide low-latency LLM service to users or risk unacceptable user experience. However, over-provisioning resources to serve fluctuating request patterns is often prohibitively expensive. In this work, we present a best-effort serving system that employs deep reinforcement learning to adjust service quality based on the task distribution and system load. Our best-effort system can maintain availability with over 10x higher client request rates, serves above 96% of peak performance 4.1x more often, and serves above 98% of peak performance 2.3x more often than static serving on unpredictable workloads. Our learned router is robust to shifts in both the arrival and task distribution. Compared to static serving, learned best-effort serving allows for cost-efficient serving through increased hardware utility. Additionally, we argue that learned best-effort LLM serving is applicable in wide variety of settings and provides application developers great flexibility to meet their specific needs.</li>
</ul>

<h3>Title: Machine Learning Techniques to Identify Hand Gestures amidst Forearm  Muscle Signals</h3>
<ul>
<li><strong>Authors: </strong>Ryan Cho, Sunil Patel, Kyu Taek Cho, Jaejin Hwang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07889">https://arxiv.org/abs/2401.07889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07889">https://arxiv.org/pdf/2401.07889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07889]] Machine Learning Techniques to Identify Hand Gestures amidst Forearm  Muscle Signals(https://arxiv.org/abs/2401.07889)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This study investigated the use of forearm EMG data for distinguishing eight hand gestures, employing the Neural Network and Random Forest algorithms on data from ten participants. The Neural Network achieved 97 percent accuracy with 1000-millisecond windows, while the Random Forest achieved 85 percent accuracy with 200-millisecond windows. Larger window sizes improved gesture classification due to increased temporal resolution. The Random Forest exhibited faster processing at 92 milliseconds, compared to the Neural Network's 124 milliseconds. In conclusion, the study identified a Neural Network with a 1000-millisecond stream as the most accurate (97 percent), and a Random Forest with a 200-millisecond stream as the most efficient (85 percent). Future research should focus on increasing sample size, incorporating more hand gestures, and exploring different feature extraction methods and modeling algorithms to enhance system accuracy and efficiency.</li>
</ul>

<h3>Title: The Pitfalls of Defining Hallucination</h3>
<ul>
<li><strong>Authors: </strong>Kees van Deemter</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07897">https://arxiv.org/abs/2401.07897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07897">https://arxiv.org/pdf/2401.07897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07897]] The Pitfalls of Defining Hallucination(https://arxiv.org/abs/2401.07897)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite impressive advances in Natural Language Generation (NLG) and Large Language Models (LLMs), researchers are still unclear about important aspects of NLG evaluation. To substantiate this claim, I examine current classifications of hallucination and omission in Data-text NLG, and I propose a logic-based synthesis of these classfications. I conclude by highlighting some remaining limitations of all current thinking about hallucination and by discussing implications for LLMs.</li>
</ul>

<h3>Title: Word Boundary Information Isn't Useful for Encoder Language Models</h3>
<ul>
<li><strong>Authors: </strong>Edward Gow-Smith, Dylan Phelps, Harish Tayyar Madabushi, Carolina Scarton, Aline Villavicencio</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07923">https://arxiv.org/abs/2401.07923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07923">https://arxiv.org/pdf/2401.07923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07923]] Word Boundary Information Isn't Useful for Encoder Language Models(https://arxiv.org/abs/2401.07923)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>All existing transformer-based approaches to NLP using subword tokenisation algorithms encode whitespace (word boundary information) through the use of special space symbols (such as \#\# or \_) forming part of tokens. These symbols have been shown to a) lead to reduced morphological validity of tokenisations, and b) give substantial vocabulary redundancy. As such, removing these symbols has been shown to have a beneficial effect on the processing of morphologically complex words for transformer encoders in the pretrain-finetune paradigm. In this work, we explore whether word boundary information is at all useful to such models. In particular, we train transformer encoders across four different training scales, and investigate several alternative approaches to including word boundary information, evaluating on a range of tasks across different domains and problem set-ups: GLUE (for sentence-level classification), NER (for token-level classification), and two classification datasets involving complex words (Superbizarre and FLOTA). Overall, through an extensive experimental setup that includes the pre-training of 29 models, we find no substantial improvements from our alternative approaches, suggesting that modifying tokenisers to remove word boundary information isn't leading to a loss of useful information.</li>
</ul>

<h3>Title: Can Large Language Models Explain Themselves?</h3>
<ul>
<li><strong>Authors: </strong>Andreas Madsen, Sarath Chandar, Siva Reddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07927">https://arxiv.org/abs/2401.07927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07927">https://arxiv.org/pdf/2401.07927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07927]] Can Large Language Models Explain Themselves?(https://arxiv.org/abs/2401.07927)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Instruction-tuned large language models (LLMs) excel at many tasks, and will even provide explanations for their behavior. Since these models are directly accessible to the public, there is a risk that convincing and wrong explanations can lead to unsupported confidence in LLMs. Therefore, interpretability-faithfulness of self-explanations is an important consideration for AI Safety. Assessing the interpretability-faithfulness of these explanations, termed self-explanations, is challenging as the models are too complex for humans to annotate what is a correct explanation. To address this, we propose employing self-consistency checks as a measure of faithfulness. For example, if an LLM says a set of words is important for making a prediction, then it should not be able to make the same prediction without these words. While self-consistency checks are a common approach to faithfulness, they have not previously been applied to LLM's self-explanations. We apply self-consistency checks to three types of self-explanations: counterfactuals, importance measures, and redactions. Our work demonstrate that faithfulness is both task and model dependent, e.g., for sentiment classification, counterfactual explanations are more faithful for Llama2, importance measures for Mistral, and redaction for Falcon 40B. Finally, our findings are robust to prompt-variations.</li>
</ul>

<h3>Title: Vertical Federated Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Paul K. Mandal, Cole Leo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07931">https://arxiv.org/abs/2401.07931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07931">https://arxiv.org/pdf/2401.07931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07931]] Vertical Federated Image Segmentation(https://arxiv.org/abs/2401.07931)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, segmentation</a></li>
<li><strong>Abstract: </strong>With the popularization of AI solutions for image based problems, there has been a growing concern for both data privacy and acquisition. In a large number of cases, information is located on separate data silos and it can be difficult for a developer to consolidate all of it in a fashion that is appropriate for machine learning model development. Alongside this, a portion of these localized data regions may not have access to a labelled ground truth. This indicates that they have the capacity to reach conclusions numerically, but are not able to assign classifications amid a lack of pertinent information. Such a determination is often negligible, especially when attempting to develop image based solutions that often necessitate this capability. With this being the case, we propose an innovative vertical federated learning (VFL) model architecture that can operate under this common set of conditions. This is the first (and currently the only) implementation of a system that can work under the constraints of a VFL environment and perform image segmentation while maintaining nominal accuracies. We achieved this by utilizing an FCN that boasts the ability to operate on federates that lack labelled data and privately share the respective weights with a central server, that of which hosts the necessary features for classification. Tests were conducted on the CamVid dataset in order to determine the impact of heavy feature compression required for the transfer of information between federates, as well as to reach nominal conclusions about the overall performance metrics when working under such constraints.</li>
</ul>

<h3>Title: Transformer-based Video Saliency Prediction with High Temporal Dimension  Decoding</h3>
<ul>
<li><strong>Authors: </strong>Morteza Moradi, Simone Palazzo, Concetto Spampinato</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07942">https://arxiv.org/abs/2401.07942</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07942">https://arxiv.org/pdf/2401.07942</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07942]] Transformer-based Video Saliency Prediction with High Temporal Dimension  Decoding(https://arxiv.org/abs/2401.07942)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years, finding an effective and efficient strategy for exploiting spatial and temporal information has been a hot research topic in video saliency prediction (VSP). With the emergence of spatio-temporal transformers, the weakness of the prior strategies, e.g., 3D convolutional networks and LSTM-based networks, for capturing long-range dependencies has been effectively compensated. While VSP has drawn benefits from spatio-temporal transformers, finding the most effective way for aggregating temporal features is still challenging. To address this concern, we propose a transformer-based video saliency prediction approach with high temporal dimension decoding network (THTD-Net). This strategy accounts for the lack of complex hierarchical interactions between features that are extracted from the transformer-based spatio-temporal encoder: in particular, it does not require multiple decoders and aims at gradually reducing temporal features' dimensions in the decoder. This decoder-based architecture yields comparable performance to multi-branch and over-complicated models on common benchmarks such as DHF1K, UCF-sports and Hollywood-2.</li>
</ul>

<h3>Title: SemEval-2017 Task 4: Sentiment Analysis in Twitter using BERT</h3>
<ul>
<li><strong>Authors: </strong>Rupak Kumar Das, Dr. Ted Pedersen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07944">https://arxiv.org/abs/2401.07944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07944">https://arxiv.org/pdf/2401.07944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07944]] SemEval-2017 Task 4: Sentiment Analysis in Twitter using BERT(https://arxiv.org/abs/2401.07944)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This paper uses the BERT model, which is a transformer-based architecture, to solve task 4A, English Language, Sentiment Analysis in Twitter of SemEval2017. BERT is a very powerful large language model for classification tasks when the amount of training data is small. For this experiment, we have used the BERT{\textsubscript{\tiny BASE}} model, which has 12 hidden layers. This model provides better accuracy, precision, recall, and f1 score than the Naive Bayes baseline model. It performs better in binary classification subtasks than the multi-class classification subtasks. We also considered all kinds of ethical issues during this experiment, as Twitter data contains personal and sensible information. The dataset and code used in our experiment can be found in this GitHub repository.</li>
</ul>

<h3>Title: SciGLM: Training Scientific Language Models with Self-Reflective  Instruction Annotation and Tuning</h3>
<ul>
<li><strong>Authors: </strong>Dan Zhang, Ziniu Hu, Sining Zhoubian, Zhengxiao Du, Kaiyu Yang, Zihan Wang, Yisong Yue, Yuxiao Dong, Jie Tang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07950">https://arxiv.org/abs/2401.07950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07950">https://arxiv.org/pdf/2401.07950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07950]] SciGLM: Training Scientific Language Models with Self-Reflective  Instruction Annotation and Tuning(https://arxiv.org/abs/2401.07950)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>\label{sec:abstract} Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving advanced numerical calculations. To bridge these gaps, we introduce SciGLM, a suite of scientific language models able to conduct college-level scientific reasoning. Central to our approach is a novel self-reflective instruction annotation framework to address the data scarcity challenge in the science domain. This framework leverages existing LLMs to generate step-by-step reasoning for unlabelled scientific questions, followed by a process of self-reflective critic-and-revise. Applying this framework, we curated SciInstruct, a diverse and high-quality dataset encompassing mathematics, physics, chemistry, and formal proofs. We fine-tuned the ChatGLM family of language models with SciInstruct, enhancing their capabilities in scientific and mathematical reasoning. Remarkably, SciGLM consistently improves both the base model (ChatGLM3-6B-Base) and larger-scale models (12B and 32B), without sacrificing the language understanding capabilities of the base model. This makes SciGLM a suitable foundational model to facilitate diverse scientific discovery tasks. For the benefit of the wider research community, we release SciInstruct, SciGLM, alongside a self-reflective framework and fine-tuning code at \url{https://github.com/THUDM/SciGLM}.</li>
</ul>

<h3>Title: A Study on Large Language Models' Limitations in Multiple-Choice  Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Aisha Khatun, Daniel G. Brown</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07955">https://arxiv.org/abs/2401.07955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07955">https://arxiv.org/pdf/2401.07955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07955]] A Study on Large Language Models' Limitations in Multiple-Choice  Question Answering(https://arxiv.org/abs/2401.07955)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The widespread adoption of Large Language Models (LLMs) has become commonplace, particularly with the emergence of open-source models. More importantly, smaller models are well-suited for integration into consumer devices and are frequently employed either as standalone solutions or as subroutines in various AI tasks. Despite their ubiquitous use, there is no systematic analysis of their specific capabilities and limitations. In this study, we tackle one of the most widely used tasks - answering Multiple Choice Question (MCQ). We analyze 26 small open-source models and find that 65% of the models do not understand the task, only 4 models properly select an answer from the given choices, and only 5 of these models are choice order independent. These results are rather alarming given the extensive use of MCQ tests with these models. We recommend exercising caution and testing task understanding before using MCQ to evaluate LLMs in any field whatsoever.</li>
</ul>

<h3>Title: ADMIn: Attacks on Dataset, Model and Input. A Threat Model for AI Based  Software</h3>
<ul>
<li><strong>Authors: </strong>Vimal Kumar, Juliette Mayo, Khadija Bahiss</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07960">https://arxiv.org/abs/2401.07960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07960">https://arxiv.org/pdf/2401.07960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07960]] ADMIn: Attacks on Dataset, Model and Input. A Threat Model for AI Based  Software(https://arxiv.org/abs/2401.07960)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) and artificial intelligence (AI) techniques have now become commonplace in software products and services. When threat modelling a system, it is therefore important that we consider threats unique to ML and AI techniques, in addition to threats to our software. In this paper, we present a threat model that can be used to systematically uncover threats to AI based software. The threat model consists of two main parts, a model of the software development process for AI based software and an attack taxonomy that has been developed using attacks found in adversarial AI research. We apply the threat model to two real life AI based software and discuss the process and the threats found.</li>
</ul>

<h3>Title: Leveraging External Knowledge Resources to Enable Domain-Specific  Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Saptarshi Sengupta, Connor Heaton, Prasenjit Mitra, Soumalya Sarkar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07977">https://arxiv.org/abs/2401.07977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07977">https://arxiv.org/pdf/2401.07977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07977]] Leveraging External Knowledge Resources to Enable Domain-Specific  Comprehension(https://arxiv.org/abs/2401.07977)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Machine Reading Comprehension (MRC) has been a long-standing problem in NLP and, with the recent introduction of the BERT family of transformer based language models, it has come a long way to getting solved. Unfortunately, however, when BERT variants trained on general text corpora are applied to domain-specific text, their performance inevitably degrades on account of the domain shift i.e. genre/subject matter discrepancy between the training and downstream application data. Knowledge graphs act as reservoirs for either open or closed domain information and prior studies have shown that they can be used to improve the performance of general-purpose transformers in domain-specific applications. Building on existing work, we introduce a method using Multi-Layer Perceptrons (MLPs) for aligning and integrating embeddings extracted from knowledge graphs with the embeddings spaces of pre-trained language models (LMs). We fuse the aligned embeddings with open-domain LMs BERT and RoBERTa, and fine-tune them for two MRC tasks namely span detection (COVID-QA) and multiple-choice questions (PubMedQA). On the COVID-QA dataset, we see that our approach allows these models to perform similar to their domain-specific counterparts, Bio/Sci-BERT, as evidenced by the Exact Match (EM) metric. With regards to PubMedQA, we observe an overall improvement in accuracy while the F1 stays relatively the same over the domain-specific models.</li>
</ul>

<h3>Title: Robustness Against Adversarial Attacks via Learning Confined Adversarial  Polytopes</h3>
<ul>
<li><strong>Authors: </strong>Shayan Mohajer Hamidi, Linfeng Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07991">https://arxiv.org/abs/2401.07991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07991">https://arxiv.org/pdf/2401.07991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07991]] Robustness Against Adversarial Attacks via Learning Confined Adversarial  Polytopes(https://arxiv.org/abs/2401.07991)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) could be deceived by generating human-imperceptible perturbations of clean samples. Therefore, enhancing the robustness of DNNs against adversarial attacks is a crucial task. In this paper, we aim to train robust DNNs by limiting the set of outputs reachable via a norm-bounded perturbation added to a clean sample. We refer to this set as adversarial polytope, and each clean sample has a respective adversarial polytope. Indeed, if the respective polytopes for all the samples are compact such that they do not intersect the decision boundaries of the DNN, then the DNN is robust against adversarial samples. Hence, the inner-working of our algorithm is based on learning \textbf{c}onfined \textbf{a}dversarial \textbf{p}olytopes (CAP). By conducting a thorough set of experiments, we demonstrate the effectiveness of CAP over existing adversarial robustness methods in improving the robustness of models against state-of-the-art attacks including AutoAttack.</li>
</ul>

<h3>Title: Playing the MEV Game on a First-Come-First-Served Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Burak Öz, Jonas Gebele, Parshant Singh, Filip Rezabek, Florian Matthes</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07992">https://arxiv.org/abs/2401.07992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07992">https://arxiv.org/pdf/2401.07992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07992]] Playing the MEV Game on a First-Come-First-Served Blockchain(https://arxiv.org/abs/2401.07992)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, extraction</a></li>
<li><strong>Abstract: </strong>Maximal Extractable Value (MEV) searching has gained prominence on the Ethereum blockchain since the surge in Decentralized Finance activities. In Ethereum, MEV extraction primarily hinges on fee payments to block proposers. However, in First-Come-First-Served (FCFS) blockchain networks, the focus shifts to latency optimizations, akin to High-Frequency Trading in Traditional Finance. This paper illustrates the dynamics of the MEV extraction game in an FCFS network, specifically Algorand. We introduce an arbitrage detection algorithm tailored to the unique time constraints of FCFS networks and assess its effectiveness. Additionally, our experiments investigate potential optimizations in Algorand's network layer to secure optimal execution positions. Our analysis reveals that while the states of relevant trading pools are updated approximately every six blocks on median, pursuing MEV at the block state level is not viable on Algorand, as arbitrage opportunities are typically executed within the blocks they appear. Our algorithm's performance under varying time constraints underscores the importance of timing in arbitrage discovery. Furthermore, our network-level experiments identify critical transaction prioritization strategies for Algorand's FCFS network. Key among these is reducing latency in connections with relays that are well-connected to high-staked proposers.</li>
</ul>

<h3>Title: Carrying over algorithm in transformers</h3>
<ul>
<li><strong>Authors: </strong>Jorrit Kruthoff</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07993">https://arxiv.org/abs/2401.07993</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07993">https://arxiv.org/pdf/2401.07993</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07993]] Carrying over algorithm in transformers(https://arxiv.org/abs/2401.07993)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Addition is perhaps one of the simplest arithmetic tasks one can think of and is usually performed using the carrying over algorithm. This algorithm consists of two tasks: adding digits in the same position and carrying over a one whenever necessary. We study how transformer models implement this algorithm and how the two aforementioned tasks are allocated to different parts of the network. We first focus on two-layer encoder-only models and show that the carrying over algorithm is implemented in a modular fashion. The first layer is mostly responsible for adding digits in the same position. The second layer first decides, in the attention, which positions need a carried one or not, and then performs the carrying of the one in the final MLP. We provide a simple way of precisely identifying which neurons are responsible for that task. This implementation of the carrying over algorithm occurs across a range of hyperparameters for two as well as three-layer models. For small decoder-only models, we observe the same implementation and provide suggestive evidence for its existence in three 7B large language models.</li>
</ul>

<h3>Title: The Pulse of Fileless Cryptojacking Attacks: Malicious PowerShell  Scripts</h3>
<ul>
<li><strong>Authors: </strong>Said Varlioglu, Nelly Elsayed, Eva Ruhsar Varlioglu, Murat Ozer, Zag ElSayed</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.07995">https://arxiv.org/abs/2401.07995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.07995">https://arxiv.org/pdf/2401.07995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.07995]] The Pulse of Fileless Cryptojacking Attacks: Malicious PowerShell  Scripts(https://arxiv.org/abs/2401.07995)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Fileless malware predominantly relies on PowerShell scripts, leveraging the native capabilities of Windows systems to execute stealthy attacks that leave no traces on the victim's system. The effectiveness of the fileless method lies in its ability to remain operational on victim endpoints through memory execution, even if the attacks are detected, and the original malicious scripts are removed. Threat actors have increasingly utilized this technique, particularly since 2017, to conduct cryptojacking attacks. With the emergence of new Remote Code Execution (RCE) vulnerabilities in ubiquitous libraries, widespread cryptocurrency mining attacks have become prevalent, often employing fileless techniques. This paper provides a comprehensive analysis of PowerShell scripts of fileless cryptojacking, dissecting the common malicious patterns based on the MITRE ATT&CK framework.</li>
</ul>

<h3>Title: Convolutional Neural Network Compression via Dynamic Parameter Rank  Pruning</h3>
<ul>
<li><strong>Authors: </strong>Manish Sharma, Jamison Heard, Eli Saber, Panos P. Markopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08014">https://arxiv.org/abs/2401.08014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08014">https://arxiv.org/pdf/2401.08014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08014]] Convolutional Neural Network Compression via Dynamic Parameter Rank  Pruning(https://arxiv.org/abs/2401.08014)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While Convolutional Neural Networks (CNNs) excel at learning complex latent-space representations, their over-parameterization can lead to overfitting and reduced performance, particularly with limited data. This, alongside their high computational and memory demands, limits the applicability of CNNs for edge deployment. Low-rank matrix approximation has emerged as a promising approach to reduce CNN parameters, but its application presents challenges including rank selection and performance loss. To address these issues, we propose an efficient training method for CNN compression via dynamic parameter rank pruning. Our approach integrates efficient matrix factorization and novel regularization techniques, forming a robust framework for dynamic rank reduction and model compression. We use Singular Value Decomposition (SVD) to model low-rank convolutional filters and dense weight matrices and we achieve model compression by training the SVD factors with back-propagation in an end-to-end way. We evaluate our method on an array of modern CNNs, including ResNet-18, ResNet-20, and ResNet-32, and datasets like CIFAR-10, CIFAR-100, and ImageNet (2012), showcasing its applicability in computer vision. Our experiments show that the proposed method can yield substantial storage savings while maintaining or even enhancing classification performance.</li>
</ul>

<h3>Title: Small Object Detection by DETR via Information Augmentation and Adaptive  Feature Fusion</h3>
<ul>
<li><strong>Authors: </strong>Ji Huang, Hui Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08017">https://arxiv.org/abs/2401.08017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08017">https://arxiv.org/pdf/2401.08017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08017]] Small Object Detection by DETR via Information Augmentation and Adaptive  Feature Fusion(https://arxiv.org/abs/2401.08017)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The main challenge for small object detection algorithms is to ensure accuracy while pursuing real-time performance. The RT-DETR model performs well in real-time object detection, but performs poorly in small object detection accuracy. In order to compensate for the shortcomings of the RT-DETR model in small object detection, two key improvements are proposed in this study. Firstly, The RT-DETR utilises a Transformer that receives input solely from the final layer of Backbone features. This means that the Transformer's input only receives semantic information from the highest level of abstraction in the Deep Network, and ignores detailed information such as edges, texture or color gradients that are critical to the location of small objects at lower levels of abstraction. Including only deep features can introduce additional background noise. This can have a negative impact on the accuracy of small object detection. To address this issue, we propose the fine-grained path augmentation method. This method helps to locate small objects more accurately by providing detailed information to the deep network. So, the input to the transformer contains both semantic and detailed information. Secondly, In RT-DETR, the decoder takes feature maps of different levels as input after concatenating them with equal weight. However, this operation is not effective in dealing with the complex relationship of multi-scale information captured by feature maps of different sizes. Therefore, we propose an adaptive feature fusion algorithm that assigns learnable parameters to each feature map from different levels. This allows the model to adaptively fuse feature maps from different levels and effectively integrate feature information from different scales. This enhances the model's ability to capture object features at different scales, thereby improving the accuracy of detecting small objects.</li>
</ul>

<h3>Title: Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with  Crowdsourcing and Active Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenjun Qiu, David Lie, Lisa Austin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08038">https://arxiv.org/abs/2401.08038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08038">https://arxiv.org/pdf/2401.08038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08038]] Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with  Crowdsourcing and Active Learning(https://arxiv.org/abs/2401.08038)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, segmentation</a></li>
<li><strong>Abstract: </strong>A significant challenge to training accurate deep learning models on privacy policies is the cost and difficulty of obtaining a large and comprehensive set of training data. To address these challenges, we present Calpric , which combines automatic text selection and segmentation, active learning and the use of crowdsourced annotators to generate a large, balanced training set for privacy policies at low cost. Automated text selection and segmentation simplifies the labeling task, enabling untrained annotators from crowdsourcing platforms, like Amazon's Mechanical Turk, to be competitive with trained annotators, such as law students, and also reduces inter-annotator agreement, which decreases labeling cost. Having reliable labels for training enables the use of active learning, which uses fewer training samples to efficiently cover the input space, further reducing cost and improving class and data category balance in the data set. The combination of these techniques allows Calpric to produce models that are accurate over a wider range of data categories, and provide more detailed, fine-grain labels than previous work. Our crowdsourcing process enables Calpric to attain reliable labeled data at a cost of roughly $0.92-$1.71 per labeled text segment. Calpric 's training process also generates a labeled data set of 16K privacy policy text segments across 9 Data categories with balanced positive and negative samples.</li>
</ul>

<h3>Title: Forging Vision Foundation Models for Autonomous Driving: Challenges,  Methodologies, and Opportunities</h3>
<ul>
<li><strong>Authors: </strong>Xu Yan, Haiming Zhang, Yingjie Cai, Jingming Guo, Weichao Qiu, Bin Gao, Kaiqiang Zhou, Yue Zhao, Huan Jin, Jiantao Gao, Zhen Li, Lihui Jiang, Wei Zhang, Hongbo Zhang, Dengxin Dai, Bingbing Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08045">https://arxiv.org/abs/2401.08045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08045">https://arxiv.org/pdf/2401.08045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08045]] Forging Vision Foundation Models for Autonomous Driving: Challenges,  Methodologies, and Opportunities(https://arxiv.org/abs/2401.08045)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rise of large foundation models, trained on extensive datasets, is revolutionizing the field of AI. Models such as SAM, DALL-E2, and GPT-4 showcase their adaptability by extracting intricate patterns and performing effectively across diverse tasks, thereby serving as potent building blocks for a wide range of AI applications. Autonomous driving, a vibrant front in AI applications, remains challenged by the lack of dedicated vision foundation models (VFMs). The scarcity of comprehensive training data, the need for multi-sensor integration, and the diverse task-specific architectures pose significant obstacles to the development of VFMs in this field. This paper delves into the critical challenge of forging VFMs tailored specifically for autonomous driving, while also outlining future directions. Through a systematic analysis of over 250 papers, we dissect essential techniques for VFM development, including data preparation, pre-training strategies, and downstream task adaptation. Moreover, we explore key advancements such as NeRF, diffusion models, 3D Gaussian Splatting, and world models, presenting a comprehensive roadmap for future research. To empower researchers, we have built and maintained https://github.com/zhanghm1995/Forge_VFM4AD, an open-access repository constantly updated with the latest advancements in forging VFMs for autonomous driving.</li>
</ul>

<h3>Title: Enhancing Robustness of LLM-Synthetic Text Detectors for Academic  Writing: A Comprehensive Analysis</h3>
<ul>
<li><strong>Authors: </strong>Zhicheng Dou, Yuchen Guo, Ching-Chun Chang, Huy H. Nguyen, Isao Echizen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08046">https://arxiv.org/abs/2401.08046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08046">https://arxiv.org/pdf/2401.08046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08046]] Enhancing Robustness of LLM-Synthetic Text Detectors for Academic  Writing: A Comprehensive Analysis(https://arxiv.org/abs/2401.08046)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>The emergence of large language models (LLMs), such as Generative Pre-trained Transformer 4 (GPT-4) used by ChatGPT, has profoundly impacted the academic and broader community. While these models offer numerous advantages in terms of revolutionizing work and study methods, they have also garnered significant attention due to their potential negative consequences. One example is generating academic reports or papers with little to no human contribution. Consequently, researchers have focused on developing detectors to address the misuse of LLMs. However, most existing methods prioritize achieving higher accuracy on restricted datasets, neglecting the crucial aspect of generalizability. This limitation hinders their practical application in real-life scenarios where reliability is paramount. In this paper, we present a comprehensive analysis of the impact of prompts on the text generated by LLMs and highlight the potential lack of robustness in one of the current state-of-the-art GPT detectors. To mitigate these issues concerning the misuse of LLMs in academic writing, we propose a reference-based Siamese detector named Synthetic-Siamese which takes a pair of texts, one as the inquiry and the other as the reference. Our method effectively addresses the lack of robustness of previous detectors (OpenAI detector and DetectGPT) and significantly improves the baseline performances in realistic academic writing scenarios by approximately 67% to 95%.</li>
</ul>

<h3>Title: EmoTalker: Emotionally Editable Talking Face Generation via Diffusion  Model</h3>
<ul>
<li><strong>Authors: </strong>Bingyuan Zhang, Xulong Zhang, Ning Cheng, Jun Yu, Jing Xiao, Jianzong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08049">https://arxiv.org/abs/2401.08049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08049">https://arxiv.org/pdf/2401.08049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08049]] EmoTalker: Emotionally Editable Talking Face Generation via Diffusion  Model(https://arxiv.org/abs/2401.08049)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In recent years, the field of talking faces generation has attracted considerable attention, with certain methods adept at generating virtual faces that convincingly imitate human expressions. However, existing methods face challenges related to limited generalization, particularly when dealing with challenging identities. Furthermore, methods for editing expressions are often confined to a singular emotion, failing to adapt to intricate emotions. To overcome these challenges, this paper proposes EmoTalker, an emotionally editable portraits animation approach based on the diffusion model. EmoTalker modifies the denoising process to ensure preservation of the original portrait's identity during inference. To enhance emotion comprehension from text input, Emotion Intensity Block is introduced to analyze fine-grained emotions and strengths derived from prompts. Additionally, a crafted dataset is harnessed to enhance emotion comprehension within prompts. Experiments show the effectiveness of EmoTalker in generating high-quality, emotionally customizable facial expressions.</li>
</ul>

<h3>Title: SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhixuan Liu, Peter Schaldenbrand, Beverley-Claire Okogwu, Wenxuan Peng, Youngsik Yun, Andrew Hundt, Jihie Kim, Jean Oh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08053">https://arxiv.org/abs/2401.08053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08053">https://arxiv.org/pdf/2401.08053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08053]] SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation(https://arxiv.org/abs/2401.08053)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Accurate representation in media is known to improve the well-being of the people who consume it. Generative image models trained on large web-crawled datasets such as LAION are known to produce images with harmful stereotypes and misrepresentations of cultures. We improve inclusive representation in generated images by (1) engaging with communities to collect a culturally representative dataset that we call the Cross-Cultural Understanding Benchmark (CCUB) and (2) proposing a novel Self-Contrastive Fine-Tuning (SCoFT) method that leverages the model's known biases to self-improve. SCoFT is designed to prevent overfitting on small datasets, encode only high-level information from the data, and shift the generated distribution away from misrepresentations encoded in a pretrained model. Our user study conducted on 51 participants from 5 different countries based on their self-selected national cultural affiliation shows that fine-tuning on CCUB consistently generates images with higher cultural relevance and fewer stereotypes when compared to the Stable Diffusion baseline, which is further improved with our SCoFT technique.</li>
</ul>

<h3>Title: Robust Tiny Object Detection in Aerial Images amidst Label Noise</h3>
<ul>
<li><strong>Authors: </strong>Haoran Zhu, Chang Xu, Wen Yang, Ruixiang Zhang, Yan Zhang, Gui-Song Xia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08056">https://arxiv.org/abs/2401.08056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08056">https://arxiv.org/pdf/2401.08056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08056]] Robust Tiny Object Detection in Aerial Images amidst Label Noise(https://arxiv.org/abs/2401.08056)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Precise detection of tiny objects in remote sensing imagery remains a significant challenge due to their limited visual information and frequent occurrence within scenes. This challenge is further exacerbated by the practical burden and inherent errors associated with manual annotation: annotating tiny objects is laborious and prone to errors (i.e., label noise). Training detectors for such objects using noisy labels often leads to suboptimal performance, with networks tending to overfit on noisy labels. In this study, we address the intricate issue of tiny object detection under noisy label supervision. We systematically investigate the impact of various types of noise on network training, revealing the vulnerability of object detectors to class shifts and inaccurate bounding boxes for tiny objects. To mitigate these challenges, we propose a DeNoising Tiny Object Detector (DN-TOD), which incorporates a Class-aware Label Correction (CLC) scheme to address class shifts and a Trend-guided Learning Strategy (TLS) to handle bounding box noise. CLC mitigates inaccurate class supervision by identifying and filtering out class-shifted positive samples, while TLS reduces noisy box-induced erroneous supervision through sample reweighting and bounding box regeneration. Additionally, Our method can be seamlessly integrated into both one-stage and two-stage object detection pipelines. Comprehensive experiments conducted on synthetic (i.e., noisy AI-TOD-v2.0 and DOTA-v2.0) and real-world (i.e., AI-TOD) noisy datasets demonstrate the robustness of DN-TOD under various types of label noise. Notably, when applied to the strong baseline RFLA, DN-TOD exhibits a noteworthy performance improvement of 4.9 points under 40% mixed noise. Datasets, codes, and models will be made publicly available.</li>
</ul>

<h3>Title: Achieve Fairness without Demographics for Dermatological Disease  Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Ching-Hao Chiu, Yu-Jen Chen, Yawen Wu, Yiyu Shi, Tsung-Yi Ho</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08066">https://arxiv.org/abs/2401.08066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08066">https://arxiv.org/pdf/2401.08066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08066]] Achieve Fairness without Demographics for Dermatological Disease  Diagnosis(https://arxiv.org/abs/2401.08066)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>In medical image diagnosis, fairness has become increasingly crucial. Without bias mitigation, deploying unfair AI would harm the interests of the underprivileged population and potentially tear society apart. Recent research addresses prediction biases in deep learning models concerning demographic groups (e.g., gender, age, and race) by utilizing demographic (sensitive attribute) information during training. However, many sensitive attributes naturally exist in dermatological disease images. If the trained model only targets fairness for a specific attribute, it remains unfair for other attributes. Moreover, training a model that can accommodate multiple sensitive attributes is impractical due to privacy concerns. To overcome this, we propose a method enabling fair predictions for sensitive attributes during the testing phase without using such information during training. Inspired by prior work highlighting the impact of feature entanglement on fairness, we enhance the model features by capturing the features related to the sensitive and target attributes and regularizing the feature entanglement between corresponding classes. This ensures that the model can only classify based on the features related to the target attribute without relying on features associated with sensitive attributes, thereby improving fairness and accuracy. Additionally, we use disease masks from the Segment Anything Model (SAM) to enhance the quality of the learned feature. Experimental results demonstrate that the proposed method can improve fairness in classification compared to state-of-the-art methods in two dermatological disease datasets.</li>
</ul>

<h3>Title: Transformer-based approach for Ethereum Price Prediction Using  Crosscurrency correlation and Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Shubham Singh, Mayur Bhat</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-fin.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08077">https://arxiv.org/abs/2401.08077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08077">https://arxiv.org/pdf/2401.08077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08077]] Transformer-based approach for Ethereum Price Prediction Using  Crosscurrency correlation and Sentiment Analysis(https://arxiv.org/abs/2401.08077)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The research delves into the capabilities of a transformer-based neural network for Ethereum cryptocurrency price forecasting. The experiment runs around the hypothesis that cryptocurrency prices are strongly correlated with other cryptocurrencies and the sentiments around the cryptocurrency. The model employs a transformer architecture for several setups from single-feature scenarios to complex configurations incorporating volume, sentiment, and correlated cryptocurrency prices. Despite a smaller dataset and less complex architecture, the transformer model surpasses ANN and MLP counterparts on some parameters. The conclusion presents a hypothesis on the illusion of causality in cryptocurrency price movements driven by sentiments.</li>
</ul>

<h3>Title: Adversarial Masking Contrastive Learning for vein recognition</h3>
<ul>
<li><strong>Authors: </strong>Huafeng Qin, Yiquan Wu, Mounim A. El-Yacoubi, Jun Wang, Guangxiang Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08079">https://arxiv.org/abs/2401.08079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08079">https://arxiv.org/pdf/2401.08079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08079]] Adversarial Masking Contrastive Learning for vein recognition(https://arxiv.org/abs/2401.08079)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, extraction, transformer, generative</a></li>
<li><strong>Abstract: </strong>Vein recognition has received increasing attention due to its high security and privacy. Recently, deep neural networks such as Convolutional neural networks (CNN) and Transformers have been introduced for vein recognition and achieved state-of-the-art performance. Despite the recent advances, however, existing solutions for finger-vein feature extraction are still not optimal due to scarce training image samples. To overcome this problem, in this paper, we propose an adversarial masking contrastive learning (AMCL) approach, that generates challenging samples to train a more robust contrastive learning model for the downstream palm-vein recognition task, by alternatively optimizing the encoder in the contrastive learning model and a set of latent variables. First, a huge number of masks are generated to train a robust generative adversarial network (GAN). The trained generator transforms a latent variable from the latent variable space into a mask space. Then, we combine the trained generator with a contrastive learning model to obtain our AMCL, where the generator produces challenging masking images to increase the contrastive loss and the contrastive learning model is trained based on the harder images to learn a more robust feature representation. After training, the trained encoder in the contrastive learning model is combined with a classification layer to build a classifier, which is further fine-tuned on labeled training data for vein recognition. The experimental results on three databases demonstrate that our approach outperforms existing contrastive learning approaches in terms of improving identification accuracy of vein classifiers and achieves state-of-the-art recognition results.</li>
</ul>

<h3>Title: UV-SAM: Adapting Segment Anything Model for Urban Village Identification</h3>
<ul>
<li><strong>Authors: </strong>Xin Zhang, Yu Liu, Yuming Lin, Qingming Liao, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08083">https://arxiv.org/abs/2401.08083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08083">https://arxiv.org/pdf/2401.08083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08083]] UV-SAM: Adapting Segment Anything Model for Urban Village Identification(https://arxiv.org/abs/2401.08083)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Urban villages, defined as informal residential areas in or around urban centers, are characterized by inadequate infrastructures and poor living conditions, closely related to the Sustainable Development Goals (SDGs) on poverty, adequate housing, and sustainable cities. Traditionally, governments heavily depend on field survey methods to monitor the urban villages, which however are time-consuming, labor-intensive, and possibly delayed. Thanks to widely available and timely updated satellite images, recent studies develop computer vision techniques to detect urban villages efficiently. However, existing studies either focus on simple urban village image classification or fail to provide accurate boundary information. To accurately identify urban village boundaries from satellite images, we harness the power of the vision foundation model and adapt the Segment Anything Model (SAM) to urban village segmentation, named UV-SAM. Specifically, UV-SAM first leverages a small-sized semantic segmentation model to produce mixed prompts for urban villages, including mask, bounding box, and image representations, which are then fed into SAM for fine-grained boundary identification. Extensive experimental results on two datasets in China demonstrate that UV-SAM outperforms existing baselines, and identification results over multiple years show that both the number and area of urban villages are decreasing over time, providing deeper insights into the development trends of urban villages and sheds light on the vision foundation models for sustainable cities. The dataset and codes of this study are available at https://github.com/tsinghua-fib-lab/UV-SAM.</li>
</ul>

<h3>Title: Enhancing Document-level Translation of Large Language Model via  Translation Mixed-instructions</h3>
<ul>
<li><strong>Authors: </strong>Yachao Li, Junhui Li, Jing Jiang, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08088">https://arxiv.org/abs/2401.08088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08088">https://arxiv.org/pdf/2401.08088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08088]] Enhancing Document-level Translation of Large Language Model via  Translation Mixed-instructions(https://arxiv.org/abs/2401.08088)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing large language models (LLMs) for machine translation are typically fine-tuned on sentence-level translation instructions and achieve satisfactory performance at the sentence level. However, when applied to document-level translation, these models face a significant challenge, particularly when dealing with documents containing over 512 tokens. This challenge arises from the issue of sentence-level coverage, where subsequent sentences in the document remain untranslated. As a result, the document-level translation capability of LLMs fine-tuned on sentence-level translation instructions is significantly limited. We conjecture that the primary cause of LLMs' weak document-level translation performance is the absence of document-to-document mapping ability. To address the issue, we propose an approach that combines sentence-level and document-level translation instructions of varying lengths to fine-tune LLMs. Our proposed translation mixed-instructions enable LLMs (Llama-2~7B and 13B) to maintain consistent translation performance from the sentence level to documents containing as many as 2048 tokens. Extensive experimental results show that the proposed approach significantly enhances the document-level translation capabilities of LLMs on 10 language pairs, effectively mitigating the sentence-level coverage issue in document-level translation. Experimentation on discourse phenomena has demonstrated that our document-level translation approach significantly improves translation quality, both in terms of BLEU score and discourse coherence.</li>
</ul>

<h3>Title: A Study on Training and Developing Large Language Models for Behavior  Tree Generation</h3>
<ul>
<li><strong>Authors: </strong>Fu Li, Xueying Wang, Bin Li, Yunlong Wu, Yanzhen Wang, Xiaodong Yi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08089">https://arxiv.org/abs/2401.08089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08089">https://arxiv.org/pdf/2401.08089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08089]] A Study on Training and Developing Large Language Models for Behavior  Tree Generation(https://arxiv.org/abs/2401.08089)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper presents an innovative exploration of the application potential of large language models (LLM) in addressing the challenging task of automatically generating behavior trees (BTs) for complex tasks. The conventional manual BT generation method is inefficient and heavily reliant on domain expertise. On the other hand, existing automatic BT generation technologies encounter bottlenecks related to task complexity, model adaptability, and reliability. In order to overcome these challenges, we propose a novel methodology that leverages the robust representation and reasoning abilities of LLMs. The core contribution of this paper lies in the design of a BT generation framework based on LLM, which encompasses the entire process, from data synthesis and model training to application developing and data verification. Synthetic data is introduced to train the BT generation model (BTGen model), enhancing its understanding and adaptability to various complex tasks, thereby significantly improving its overall performance. In order to ensure the effectiveness and executability of the generated BTs, we emphasize the importance of data verification and introduce a multilevel verification strategy. Additionally, we explore a range of agent design and development schemes with LLM as the central element. We hope that the work in this paper may provide a reference for the researchers who are interested in BT generation based on LLMs.</li>
</ul>

<h3>Title: A Survey of Resource-efficient LLM and Multimodal Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Mengwei Xu, Wangsong Yin, Dongqi Cai, Rongjie Yi, Daliang Xu, Qipeng Wang, Bingyang Wu, Yihao Zhao, Chen Yang, Shihe Wang, Qiyang Zhang, Zhenyan Lu, Li Zhang, Shangguang Wang, Yuanchun Li, Yunxin Liu, Xin Jin, Xuanzhe Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08092">https://arxiv.org/abs/2401.08092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08092">https://arxiv.org/pdf/2401.08092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08092]] A Survey of Resource-efficient LLM and Multimodal Foundation Models(https://arxiv.org/abs/2401.08092)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large foundation models, including large language models (LLMs), vision transformers (ViTs), diffusion, and LLM-based multimodal models, are revolutionizing the entire machine learning lifecycle, from training to deployment. However, the substantial advancements in versatility and performance these models offer come at a significant cost in terms of hardware resources. To support the growth of these large models in a scalable and environmentally sustainable way, there has been a considerable focus on developing resource-efficient strategies. This survey delves into the critical importance of such research, examining both algorithmic and systemic aspects. It offers a comprehensive analysis and valuable insights gleaned from existing literature, encompassing a broad array of topics from cutting-edge model architectures and training/serving algorithms to practical system designs and implementations. The goal of this survey is to provide an overarching understanding of how current approaches are tackling the resource challenges posed by large foundation models and to potentially inspire future breakthroughs in this field.</li>
</ul>

<h3>Title: Inpainting Normal Maps for Lightstage data</h3>
<ul>
<li><strong>Authors: </strong>Hancheng Zuo, Bernard Tiddeman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08099">https://arxiv.org/abs/2401.08099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08099">https://arxiv.org/pdf/2401.08099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08099]] Inpainting Normal Maps for Lightstage data(https://arxiv.org/abs/2401.08099)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This study introduces a novel method for inpainting normal maps using a generative adversarial network (GAN). Normal maps, often derived from a lightstage, are crucial in performance capture but can have obscured areas due to movement (e.g., by arms, hair, or props). Inpainting fills these missing areas with plausible data. Our approach extends previous general image inpainting techniques, employing a bow tie-like generator network and a discriminator network, with alternating training phases. The generator aims to synthesize images aligning with the ground truth and deceive the discriminator, which differentiates between real and processed images. Periodically, the discriminator undergoes retraining to enhance its ability to identify processed images. Importantly, our method adapts to the unique characteristics of normal map data, necessitating modifications to the loss function. We utilize a cosine loss instead of mean squared error loss for generator training. Limited training data availability, even with synthetic datasets, demands significant augmentation, considering the specific nature of the input data. This includes appropriate image flipping and in-plane rotations to accurately alter normal vectors. Throughout training, we monitored key metrics such as average loss, Structural Similarity Index Measure (SSIM), and Peak Signal-to-Noise Ratio (PSNR) for the generator, along with average loss and accuracy for the discriminator. Our findings suggest that the proposed model effectively generates high-quality, realistic inpainted normal maps, suitable for performance capture applications. These results establish a foundation for future research, potentially involving more advanced networks and comparisons with inpainting of source images used to create the normal maps.</li>
</ul>

<h3>Title: Hardware Acceleration for Real-Time Wildfire Detection Onboard Drone  Networks</h3>
<ul>
<li><strong>Authors: </strong>Austin Briley, Fatemeh Afghah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08105">https://arxiv.org/abs/2401.08105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08105">https://arxiv.org/pdf/2401.08105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08105]] Hardware Acceleration for Real-Time Wildfire Detection Onboard Drone  Networks(https://arxiv.org/abs/2401.08105)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Early wildfire detection in remote and forest areas is crucial for minimizing devastation and preserving ecosystems. Autonomous drones offer agile access to remote, challenging terrains, equipped with advanced imaging technology that delivers both high-temporal and detailed spatial resolution, making them valuable assets in the early detection and monitoring of wildfires. However, the limited computation and battery resources of Unmanned Aerial Vehicles (UAVs) pose significant challenges in implementing robust and efficient image classification models. Current works in this domain often operate offline, emphasizing the need for solutions that can perform inference in real time, given the constraints of UAVs. To address these challenges, this paper aims to develop a real-time image classification and fire segmentation model. It presents a comprehensive investigation into hardware acceleration using the Jetson Nano P3450 and the implications of TensorRT, NVIDIA's high-performance deep-learning inference library, on fire classification accuracy and speed. The study includes implementations of Quantization Aware Training (QAT), Automatic Mixed Precision (AMP), and post-training mechanisms, comparing them against the latest baselines for fire segmentation and classification. All experiments utilize the FLAME dataset - an image dataset collected by low-altitude drones during a prescribed forest fire. This work contributes to the ongoing efforts to enable real-time, on-board wildfire detection capabilities for UAVs, addressing speed and the computational and energy constraints of these crucial monitoring systems. The results show a 13% increase in classification speed compared to similar models without hardware optimization. Comparatively, loss and accuracy are within 1.225% of the original values.</li>
</ul>

<h3>Title: Mobile Contactless Palmprint Recognition: Use of Multiscale, Multimodel  Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Steven A. Grosz, Akash Godbole, Anil K. Jain</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08111">https://arxiv.org/abs/2401.08111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08111">https://arxiv.org/pdf/2401.08111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08111]] Mobile Contactless Palmprint Recognition: Use of Multiscale, Multimodel  Embeddings(https://arxiv.org/abs/2401.08111)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, transformer</a></li>
<li><strong>Abstract: </strong>Contactless palmprints are comprised of both global and local discriminative features. Most prior work focuses on extracting global features or local features alone for palmprint matching, whereas this research introduces a novel framework that combines global and local features for enhanced palmprint matching accuracy. Leveraging recent advancements in deep learning, this study integrates a vision transformer (ViT) and a convolutional neural network (CNN) to extract complementary local and global features. Next, a mobile-based, end-to-end palmprint recognition system is developed, referred to as Palm-ID. On top of the ViT and CNN features, Palm-ID incorporates a palmprint enhancement module and efficient dimensionality reduction (for faster matching). Palm-ID balances the trade-off between accuracy and latency, requiring just 18ms to extract a template of size 516 bytes, which can be efficiently searched against a 10,000 palmprint gallery in 0.33ms on an AMD EPYC 7543 32-Core CPU utilizing 128-threads. Cross-database matching protocols and evaluations on large-scale operational datasets demonstrate the robustness of the proposed method, achieving a TAR of 98.06% at FAR=0.01% on a newly collected, time-separated dataset. To show a practical deployment of the end-to-end system, the entire recognition pipeline is embedded within a mobile device for enhanced user privacy and security.</li>
</ul>

<h3>Title: SpecSTG: A Fast Spectral Diffusion Framework for Probabilistic  Spatio-Temporal Traffic Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Lequan Lin, Dai Shi, Andi Han, Junbin Gao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08119">https://arxiv.org/abs/2401.08119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08119">https://arxiv.org/pdf/2401.08119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08119]] SpecSTG: A Fast Spectral Diffusion Framework for Probabilistic  Spatio-Temporal Traffic Forecasting(https://arxiv.org/abs/2401.08119)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Traffic forecasting, a crucial application of spatio-temporal graph (STG) learning, has traditionally relied on deterministic models for accurate point estimations. Yet, these models fall short of identifying latent risks of unexpected volatility in future observations. To address this gap, probabilistic methods, especially variants of diffusion models, have emerged as uncertainty-aware solutions. However, existing diffusion methods typically focus on generating separate future time series for individual sensors in the traffic network, resulting in insufficient involvement of spatial network characteristics in the probabilistic learning process. To better leverage spatial dependencies and systematic patterns inherent in traffic data, we propose SpecSTG, a novel spectral diffusion framework. Our method generates the Fourier representation of future time series, transforming the learning process into the spectral domain enriched with spatial information. Additionally, our approach incorporates a fast spectral graph convolution designed for Fourier input, alleviating the computational burden associated with existing models. Numerical experiments show that SpecSTG achieves outstanding performance with traffic flow and traffic speed datasets compared to state-of-the-art baselines. The source code for SpecSTG is available at https://anonymous.4open.science/r/SpecSTG.</li>
</ul>

<h3>Title: CycLight: learning traffic signal cooperation with a cycle-level  strategy</h3>
<ul>
<li><strong>Authors: </strong>Gengyue Han, Xiaohan Liu, Xianyue Peng, Hao Wang, Yu Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08121">https://arxiv.org/abs/2401.08121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08121">https://arxiv.org/pdf/2401.08121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08121]] CycLight: learning traffic signal cooperation with a cycle-level  strategy(https://arxiv.org/abs/2401.08121)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study introduces CycLight, a novel cycle-level deep reinforcement learning (RL) approach for network-level adaptive traffic signal control (NATSC) systems. Unlike most traditional RL-based traffic controllers that focus on step-by-step decision making, CycLight adopts a cycle-level strategy, optimizing cycle length and splits simultaneously using Parameterized Deep Q-Networks (PDQN) algorithm. This cycle-level approach effectively reduces the computational burden associated with frequent data communication, meanwhile enhancing the practicality and safety of real-world applications. A decentralized framework is formulated for multi-agent cooperation, while attention mechanism is integrated to accurately assess the impact of the surroundings on the current intersection. CycLight is tested in a large synthetic traffic grid using the microscopic traffic simulation tool, SUMO. Experimental results not only demonstrate the superiority of CycLight over other state-of-the-art approaches but also showcase its robustness against information transmission delays.</li>
</ul>

<h3>Title: Framework and Classification of Indicator of Compromise for  physics-based attacks</h3>
<ul>
<li><strong>Authors: </strong>Vincent Tan</a></li>
<li><strong>Subjects: </strong>cs.CR, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08127">https://arxiv.org/abs/2401.08127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08127">https://arxiv.org/pdf/2401.08127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08127]] Framework and Classification of Indicator of Compromise for  physics-based attacks(https://arxiv.org/abs/2401.08127)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, extraction</a></li>
<li><strong>Abstract: </strong>Quantum communications are based on the law of physics for information security and the implications for this form of future information security enabled by quantum science has to be studied. Physics-based vulnerabilities may exist due to the inherent physics properties and behavior of quantum technologies such as Quantum Key Distribution (QKD), thus resulting in new threats that may emerge with attackers exploiting the physics-based vulnerabilities. There were many studies and experiments done to demonstrate the threat of physics-based attacks on quantum links. However, there is a lack of a framework that provides a common language to communicate about the threats and type of adversaries being dealt with for physics-based attacks. This paper is a review of physics-based attacks that were being investigated and attempt to initialize a framework based on the attack objectives and methodologies, referencing the concept from the well-established MITRE ATT&CK, therefore pioneering the classification of Indicator of Compromises (IoCs) for physics-based attacks. This paper will then pave the way for future work in the development of a forensic tool for the different classification of IoCs, with the methods of evidence collections and possible points of extractions for analysis being further investigated.</li>
</ul>

<h3>Title: Machine Learning-Based Malicious Vehicle Detection for Security Threats  and Attacks in Vehicle Ad-hoc Network (VANET) Communications</h3>
<ul>
<li><strong>Authors: </strong>Thanh Nguyen Canh, Xiem HoangVan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08135">https://arxiv.org/abs/2401.08135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08135">https://arxiv.org/pdf/2401.08135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08135]] Machine Learning-Based Malicious Vehicle Detection for Security Threats  and Attacks in Vehicle Ad-hoc Network (VANET) Communications(https://arxiv.org/abs/2401.08135)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>With the rapid growth of Vehicle Ad-hoc Network (VANET) as a promising technology for efficient and reliable communication among vehicles and infrastructure, the security and integrity of VANET communications has become a critical concern. One of the significant threats to VANET is the presence of blackhole attacks, where malicious nodes disrupt the network's functionality and compromise data confidentiality, integrity, and availability. In this paper, we propose a machine learning-based approach for blackhole detection in VANET. To achieve this task, we first create a comprehensive dataset comprising normal and malicious traffic flows. Afterward, we study and define a promising set of features to discriminate the blackhole attacks. Finally, we evaluate various machine learning algorithms, including Gradient Boosting, Random Forest, Support Vector Machines, k-Nearest Neighbors, Gaussian Naive Bayes, and Logistic Regression. Experimental results demonstrate the effectiveness of these algorithms in distinguishing between normal and malicious nodes. Our findings also highlight the potential of machine learning based approach in enhancing the security of VANET by detecting and mitigating blackhole attacks.</li>
</ul>

<h3>Title: IoTWarden: A Deep Reinforcement Learning Based Real-time Defense System  to Mitigate Trigger-action IoT Attacks</h3>
<ul>
<li><strong>Authors: </strong>Md Morshed Alam (1), Israt Jahan (2), Weichao Wang (1) ((1) Department of Software and Information Systems, University of North Carolina at Charlotte, Charlotte, USA, (2) Department of Computer Science, University of Memphis, Memphis, USA)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08141">https://arxiv.org/abs/2401.08141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08141">https://arxiv.org/pdf/2401.08141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08141]] IoTWarden: A Deep Reinforcement Learning Based Real-time Defense System  to Mitigate Trigger-action IoT Attacks(https://arxiv.org/abs/2401.08141)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>In trigger-action IoT platforms, IoT devices report event conditions to IoT hubs notifying their cyber states and let the hubs invoke actions in other IoT devices based on functional dependencies defined as rules in a rule engine. These functional dependencies create a chain of interactions that help automate network tasks. Adversaries exploit this chain to report fake event conditions to IoT hubs and perform remote injection attacks upon a smart environment to indirectly control targeted IoT devices. Existing defense efforts usually depend on static analysis over IoT apps to develop rule-based anomaly detection mechanisms. We also see ML-based defense mechanisms in the literature that harness physical event fingerprints to determine anomalies in an IoT network. However, these methods often demonstrate long response time and lack of adaptability when facing complicated attacks. In this paper, we propose to build a deep reinforcement learning based real-time defense system for injection attacks. We define the reward functions for defenders and implement a deep Q-network based approach to identify the optimal defense policy. Our experiments show that the proposed mechanism can effectively and accurately identify and defend against injection attacks with reasonable computation overhead.</li>
</ul>

<h3>Title: Completely Occluded and Dense Object Instance Segmentation Using Box  Prompt-Based Segmentation Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Zhen Zhou, Junfeng Fan, Yunkai Ma, Sihan Zhao, Fengshui Jing, Min Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08174">https://arxiv.org/abs/2401.08174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08174">https://arxiv.org/pdf/2401.08174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08174]] Completely Occluded and Dense Object Instance Segmentation Using Box  Prompt-Based Segmentation Foundation Models(https://arxiv.org/abs/2401.08174)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Completely occluded and dense object instance segmentation (IS) is an important and challenging task. Although current amodal IS methods can predict invisible regions of occluded objects, they are difficult to directly predict completely occluded objects. For dense object IS, existing box-based methods are overly dependent on the performance of bounding box detection. In this paper, we propose CFNet, a coarse-to-fine IS framework for completely occluded and dense objects, which is based on box prompt-based segmentation foundation models (BSMs). Specifically, CFNet first detects oriented bounding boxes (OBBs) to distinguish instances and provide coarse localization information. Then, it predicts OBB prompt-related masks for fine segmentation. To predict completely occluded object instances, CFNet performs IS on occluders and utilizes prior geometric properties, which overcomes the difficulty of directly predicting completely occluded object instances. Furthermore, based on BSMs, CFNet reduces the dependence on bounding box detection performance, improving dense object IS performance. Moreover, we propose a novel OBB prompt encoder for BSMs. To make CFNet more lightweight, we perform knowledge distillation on it and introduce a Gaussian smoothing method for teacher targets. Experimental results demonstrate that CFNet achieves the best performance on both industrial and publicly available datasets.</li>
</ul>

<h3>Title: Key-point Guided Deformable Image Manipulation Using Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Seok-Hwan Oh, Guil Jung, Myeong-Gee Kim, Sang-Yun Kim, Young-Min Kim, Hyeon-Jik Lee, Hyuk-Sool Kwon, Hyeon-Min Bae</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08178">https://arxiv.org/abs/2401.08178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08178">https://arxiv.org/pdf/2401.08178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08178]] Key-point Guided Deformable Image Manipulation Using Diffusion Model(https://arxiv.org/abs/2401.08178)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce a Key-point-guided Diffusion probabilistic Model (KDM) that gains precise control over images by manipulating the object's key-point. We propose a two-stage generative model incorporating an optical flow map as an intermediate output. By doing so, a dense pixel-wise understanding of the semantic relation between the image and sparse key point is configured, leading to more realistic image generation. Additionally, the integration of optical flow helps regulate the inter-frame variance of sequential images, demonstrating an authentic sequential image generation. The KDM is evaluated with diverse key-point conditioned image synthesis tasks, including facial image generation, human pose synthesis, and echocardiography video prediction, demonstrating the KDM is proving consistency enhanced and photo-realistic images compared with state-of-the-art models.</li>
</ul>

<h3>Title: DPAFNet:Dual Path Attention Fusion Network for Single Image Deraining</h3>
<ul>
<li><strong>Authors: </strong>Bingcai Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08185">https://arxiv.org/abs/2401.08185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08185">https://arxiv.org/pdf/2401.08185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08185]] DPAFNet:Dual Path Attention Fusion Network for Single Image Deraining(https://arxiv.org/abs/2401.08185)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Rainy weather will have a significant impact on the regular operation of the imaging system. Based on this premise, image rain removal has always been a popular branch of low-level visual tasks, especially methods using deep neural networks. However, most neural networks are but-branched, such as only using convolutional neural networks or Transformers, which is unfavourable for the multidimensional fusion of image features. In order to solve this problem, this paper proposes a dual-branch attention fusion network. Firstly, a two-branch network structure is proposed. Secondly, an attention fusion module is proposed to selectively fuse the features extracted by the two branches rather than simply adding them. Finally, complete ablation experiments and sufficient comparison experiments prove the rationality and effectiveness of the proposed method.</li>
</ul>

<h3>Title: MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible  Pipeline</h3>
<ul>
<li><strong>Authors: </strong>Minpeng Liao, Wei Luo, Chengxi Li, Jing Wu, Kai Fan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08190">https://arxiv.org/abs/2401.08190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08190">https://arxiv.org/pdf/2401.08190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08190]] MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible  Pipeline(https://arxiv.org/abs/2401.08190)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have seen considerable advancements in natural language understanding tasks, yet there remains a gap to bridge before attaining true artificial general intelligence, especially concerning shortcomings in mathematical reasoning capabilities. We postulate that the inherent nature of LLM training, which focuses on predicting probabilities of next token, presents challenges in effectively modeling mathematical reasoning that demands exact calculations, both from data-driven and theoretical standpoints. In this paper, we address this challenge by enriching the data landscape and introducing a novel math dataset, enhanced with a capability to utilize a Python code interpreter. This dataset is derived from GSM8K and MATH and has been further refined through a combination of GPT-4 annotations, human review, and self-training processes, where the errors in the original GSM8K training set have been fixed. Additionally, we propose a tentative, easily replicable protocol for the fine-tuning of math-specific LLMs, which has led to a significant improvement in the performance of a 7B-parameter LLM on the GSM8K and MATH datasets. We are committed to advancing the field of mathematical reasoning in LLMs and, to that end, we have made the model checkpoints and will make the dataset publicly available. We hope this will facilitate further research and development within the community.</li>
</ul>

<h3>Title: End-to-End Optimized Image Compression with the Frequency-Oriented  Transform</h3>
<ul>
<li><strong>Authors: </strong>Yuefeng Zhang, Kai Lin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08194">https://arxiv.org/abs/2401.08194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08194">https://arxiv.org/pdf/2401.08194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08194]] End-to-End Optimized Image Compression with the Frequency-Oriented  Transform(https://arxiv.org/abs/2401.08194)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Image compression constitutes a significant challenge amidst the era of information explosion. Recent studies employing deep learning methods have demonstrated the superior performance of learning-based image compression methods over traditional codecs. However, an inherent challenge associated with these methods lies in their lack of interpretability. Following an analysis of the varying degrees of compression degradation across different frequency bands, we propose the end-to-end optimized image compression model facilitated by the frequency-oriented transform. The proposed end-to-end image compression model consists of four components: spatial sampling, frequency-oriented transform, entropy estimation, and frequency-aware fusion. The frequency-oriented transform separates the original image signal into distinct frequency bands, aligning with the human-interpretable concept. Leveraging the non-overlapping hypothesis, the model enables scalable coding through the selective transmission of arbitrary frequency components. Extensive experiments are conducted to demonstrate that our model outperforms all traditional codecs including next-generation standard H.266/VVC on MS-SSIM metric. Moreover, visual analysis tasks (i.e., object detection and semantic segmentation) are conducted to verify the proposed compression method could preserve semantic fidelity besides signal-level precision.</li>
</ul>

<h3>Title: On Cryptographic Mechanisms for the Selective Disclosure of Verifiable  Credentials</h3>
<ul>
<li><strong>Authors: </strong>Andrea Flamini, Giada Sciarretta, Mario Scuro, Amir Sharif, Alessandro Tomasi, Silvio Ranise</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08196">https://arxiv.org/abs/2401.08196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08196">https://arxiv.org/pdf/2401.08196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08196]] On Cryptographic Mechanisms for the Selective Disclosure of Verifiable  Credentials(https://arxiv.org/abs/2401.08196)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Verifiable credentials are a digital analogue of physical credentials. Their authenticity and integrity are protected by means of cryptographic techniques, and they can be presented to verifiers to reveal attributes or even predicates about the attributes included in the credential. One way to preserve privacy during presentation consists in selectively disclosing the attributes in a credential. In this paper we present the most widespread cryptographic mechanisms used to enable selective disclosure of attributes identifying two categories: the ones based on hiding commitments - e.g., mdl ISO/IEC 18013-5 - and the ones based on non-interactive zero-knowledge proofs - e.g., BBS signatures. We also include a description of the cryptographic primitives used to design such cryptographic mechanisms. We describe the design of the cryptographic mechanisms and compare them by performing an analysis on their standard maturity in terms of standardization, cryptographic agility and quantum safety, then we compare the features that they support with main focus on the unlinkability of presentations, the ability to create predicate proofs and support for threshold credential issuance. Finally we perform an experimental evaluation based on the Rust open source implementations that we have considered most relevant. In particular we evaluate the size of credentials and presentations built using different cryptographic mechanisms and the time needed to generate and verify them. We also highlight some trade-offs that must be considered in the instantiation of the cryptographic mechanisms.</li>
</ul>

<h3>Title: Transcending the Limit of Local Window: Advanced Super-Resolution  Transformer with Adaptive Token Dictionary</h3>
<ul>
<li><strong>Authors: </strong>Leheng Zhang, Yawei Li, Xingyu Zhou, Xiaorui Zhao, Shuhang Gu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08209">https://arxiv.org/abs/2401.08209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08209">https://arxiv.org/pdf/2401.08209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08209]] Transcending the Limit of Local Window: Advanced Super-Resolution  Transformer with Adaptive Token Dictionary(https://arxiv.org/abs/2401.08209)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Single Image Super-Resolution is a classic computer vision problem that involves estimating high-resolution (HR) images from low-resolution (LR) ones. Although deep neural networks (DNNs), especially Transformers for super-resolution, have seen significant advancements in recent years, challenges still remain, particularly in limited receptive field caused by window-based self-attention. To address these issues, we introduce a group of auxiliary Adapeive Token Dictionary to SR Transformer and establish an ATD-SR method. The introduced token dictionary could learn prior information from training data and adapt the learned prior to specific testing image through an adaptive refinement step. The refinement strategy could not only provide global information to all input tokens but also group image tokens into categories. Based on category partitions, we further propose a category-based self-attention mechanism designed to leverage distant but similar tokens for enhancing input features. The experimental results show that our method achieves the best performance on various single image super-resolution benchmarks.</li>
</ul>

<h3>Title: ModelNet-O: A Large-Scale Synthetic Dataset for Occlusion-Aware Point  Cloud Classification</h3>
<ul>
<li><strong>Authors: </strong>Zhongbin Fang, Xia Li, Xiangtai Li, Shen Zhao, Mengyuan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08210">https://arxiv.org/abs/2401.08210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08210">https://arxiv.org/pdf/2401.08210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08210]] ModelNet-O: A Large-Scale Synthetic Dataset for Occlusion-Aware Point  Cloud Classification(https://arxiv.org/abs/2401.08210)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, 3D point cloud classification has made significant progress with the help of many datasets. However, these datasets do not reflect the incomplete nature of real-world point clouds caused by occlusion, which limits the practical application of current methods. To bridge this gap, we propose ModelNet-O, a large-scale synthetic dataset of 123,041 samples that emulate real-world point clouds with self-occlusion caused by scanning from monocular cameras. ModelNet-O is 10 times larger than existing datasets and offers more challenging cases to evaluate the robustness of existing methods. Our observation on ModelNet-O reveals that well-designed sparse structures can preserve structural information of point clouds under occlusion, motivating us to propose a robust point cloud processing method that leverages a critical point sampling (CPS) strategy in a multi-level manner. We term our method PointMLS. Through extensive experiments, we demonstrate that our PointMLS achieves state-of-the-art results on ModelNet-O and competitive results on regular datasets, and it is robust and effective. More experiments also demonstrate the robustness and effectiveness of PointMLS.</li>
</ul>

<h3>Title: Towards Efficient and Certified Recovery from Poisoning Attacks in  Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yu Jiang, Jiyuan Shen, Ziyao Liu, Chee Wei Tan, Kwok-Yan Lam</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08216">https://arxiv.org/abs/2401.08216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08216">https://arxiv.org/pdf/2401.08216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08216]] Towards Efficient and Certified Recovery from Poisoning Attacks in  Federated Learning(https://arxiv.org/abs/2401.08216)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is vulnerable to poisoning attacks, where malicious clients manipulate their updates to affect the global model. Although various methods exist for detecting those clients in FL, identifying malicious clients requires sufficient model updates, and hence by the time malicious clients are detected, FL models have been already poisoned. Thus, a method is needed to recover an accurate global model after malicious clients are identified. Current recovery methods rely on (i) all historical information from participating FL clients and (ii) the initial model unaffected by the malicious clients, leading to a high demand for storage and computational resources. In this paper, we show that highly effective recovery can still be achieved based on (i) selective historical information rather than all historical information and (ii) a historical model that has not been significantly affected by malicious clients rather than the initial model. In this scenario, while maintaining comparable recovery performance, we can accelerate the recovery speed and decrease memory consumption. Following this concept, we introduce Crab, an efficient and certified recovery method, which relies on selective information storage and adaptive model rollback. Theoretically, we demonstrate that the difference between the global model recovered by Crab and the one recovered by train-from-scratch can be bounded under certain assumptions. Our empirical evaluation, conducted across three datasets over multiple machine learning models, and a variety of untargeted and targeted poisoning attacks reveals that Crab is both accurate and efficient, and consistently outperforms previous approaches in terms of both recovery speed and memory consumption.</li>
</ul>

<h3>Title: Efficient and Mathematically Robust Operations for Certified Neural  Networks Inference</h3>
<ul>
<li><strong>Authors: </strong>Fabien Geyer, Johannes Freitag, Tobias Schulz, Sascha Uhrig</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08225">https://arxiv.org/abs/2401.08225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08225">https://arxiv.org/pdf/2401.08225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08225]] Efficient and Mathematically Robust Operations for Certified Neural  Networks Inference(https://arxiv.org/abs/2401.08225)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, machine learning (ML) and neural networks (NNs) have gained widespread use and attention across various domains, particularly in transportation for achieving autonomy, including the emergence of flying taxis for urban air mobility (UAM). However, concerns about certification have come up, compelling the development of standardized processes encompassing the entire ML and NN pipeline. This paper delves into the inference stage and the requisite hardware, highlighting the challenges associated with IEEE 754 floating-point arithmetic and proposing alternative number representations. By evaluating diverse summation and dot product algorithms, we aim to mitigate issues related to non-associativity. Additionally, our exploration of fixed-point arithmetic reveals its advantages over floating-point methods, demonstrating significant hardware efficiencies. Employing an empirical approach, we ascertain the optimal bit-width necessary to attain an acceptable level of accuracy, considering the inherent complexity of bit-width optimization.</li>
</ul>

<h3>Title: Multi-scale 2D Temporal Map Diffusion Models for Natural Language Video  Localization</h3>
<ul>
<li><strong>Authors: </strong>Chongzhi Zhang, Mingyuan Zhang, Zhiyang Teng, Jiayi Li, Xizhou Zhu, Lewei Lu, Ziwei Liu, Aixin Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08232">https://arxiv.org/abs/2401.08232</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08232">https://arxiv.org/pdf/2401.08232</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08232]] Multi-scale 2D Temporal Map Diffusion Models for Natural Language Video  Localization(https://arxiv.org/abs/2401.08232)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Natural Language Video Localization (NLVL), grounding phrases from natural language descriptions to corresponding video segments, is a complex yet critical task in video understanding. Despite ongoing advancements, many existing solutions lack the capability to globally capture temporal dynamics of the video data. In this study, we present a novel approach to NLVL that aims to address this issue. Our method involves the direct generation of a global 2D temporal map via a conditional denoising diffusion process, based on the input video and language query. The main challenges are the inherent sparsity and discontinuity of a 2D temporal map in devising the diffusion decoder. To address these challenges, we introduce a multi-scale technique and develop an innovative diffusion decoder. Our approach effectively encapsulates the interaction between the query and video data across various time scales. Experiments on the Charades and DiDeMo datasets underscore the potency of our design.</li>
</ul>

<h3>Title: Enhancing Wind Speed and Wind Power Forecasting Using Shape-Wise Feature  Engineering: A Novel Approach for Improved Accuracy and Robustness</h3>
<ul>
<li><strong>Authors: </strong>Mulomba Mukendi Christian, Yun Seon Kim, Hyebong Choi, Jaeyoung Lee, SongHee You</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08233">https://arxiv.org/abs/2401.08233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08233">https://arxiv.org/pdf/2401.08233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08233]] Enhancing Wind Speed and Wind Power Forecasting Using Shape-Wise Feature  Engineering: A Novel Approach for Improved Accuracy and Robustness(https://arxiv.org/abs/2401.08233)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate prediction of wind speed and power is vital for enhancing the efficiency of wind energy systems. Numerous solutions have been implemented to date, demonstrating their potential to improve forecasting. Among these, deep learning is perceived as a revolutionary approach in the field. However, despite their effectiveness, the noise present in the collected data remains a significant challenge. This noise has the potential to diminish the performance of these algorithms, leading to inaccurate predictions. In response to this, this study explores a novel feature engineering approach. This approach involves altering the data input shape in both Convolutional Neural Network-Long Short-Term Memory (CNN-LSTM) and Autoregressive models for various forecasting horizons. The results reveal substantial enhancements in model resilience against noise resulting from step increases in data. The approach could achieve an impressive 83% accuracy in predicting unseen data up to the 24th steps. Furthermore, this method consistently provides high accuracy for short, mid, and long-term forecasts, outperforming the performance of individual models. These findings pave the way for further research on noise reduction strategies at different forecasting horizons through shape-wise feature engineering.</li>
</ul>

<h3>Title: A Generative Adversarial Attack for Multilingual Text Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Tom Roth, Inigo Jauregi Unanue, Alsharif Abuadbba, Massimo Piccardi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08255">https://arxiv.org/abs/2401.08255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08255">https://arxiv.org/pdf/2401.08255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08255]] A Generative Adversarial Attack for Multilingual Text Classifiers(https://arxiv.org/abs/2401.08255)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, generative</a></li>
<li><strong>Abstract: </strong>Current adversarial attack algorithms, where an adversary changes a text to fool a victim model, have been repeatedly shown to be effective against text classifiers. These attacks, however, generally assume that the victim model is monolingual and cannot be used to target multilingual victim models, a significant limitation given the increased use of these models. For this reason, in this work we propose an approach to fine-tune a multilingual paraphrase model with an adversarial objective so that it becomes able to generate effective adversarial examples against multilingual classifiers. The training objective incorporates a set of pre-trained models to ensure text quality and language consistency of the generated text. In addition, all the models are suitably connected to the generator by vocabulary-mapping matrices, allowing for full end-to-end differentiability of the overall training pipeline. The experimental validation over two multilingual datasets and five languages has shown the effectiveness of the proposed approach compared to existing baselines, particularly in terms of query efficiency. We also provide a detailed analysis of the generated attacks and discuss limitations and opportunities for future research.</li>
</ul>

<h3>Title: Probabilistically Robust Watermarking of Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Mikhail Pautov, Nikita Bogdanov, Stanislav Pyatkin, Oleg Rogov, Ivan Oseledets</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08261">https://arxiv.org/abs/2401.08261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08261">https://arxiv.org/pdf/2401.08261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08261]] Probabilistically Robust Watermarking of Neural Networks(https://arxiv.org/abs/2401.08261)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal, extraction, watermark</a></li>
<li><strong>Abstract: </strong>As deep learning (DL) models are widely and effectively used in Machine Learning as a Service (MLaaS) platforms, there is a rapidly growing interest in DL watermarking techniques that can be used to confirm the ownership of a particular model. Unfortunately, these methods usually produce watermarks susceptible to model stealing attacks. In our research, we introduce a novel trigger set-based watermarking approach that demonstrates resilience against functionality stealing attacks, particularly those involving extraction and distillation. Our approach does not require additional model training and can be applied to any model architecture. The key idea of our method is to compute the trigger set, which is transferable between the source model and the set of proxy models with a high probability. In our experimental study, we show that if the probability of the set being transferable is reasonably high, it can be effectively used for ownership verification of the stolen model. We evaluate our method on multiple benchmarks and show that our approach outperforms current state-of-the-art watermarking techniques in all considered experimental setups.</li>
</ul>

<h3>Title: Siamese Content-based Search Engine for a More Transparent Skin and  Breast Cancer Diagnosis through Histological Imaging</h3>
<ul>
<li><strong>Authors: </strong>Zahra Tabatabaei, Adrián Colomer, JAvier Oliver Moll, Valery Naranjo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08272">https://arxiv.org/abs/2401.08272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08272">https://arxiv.org/pdf/2401.08272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08272]] Siamese Content-based Search Engine for a More Transparent Skin and  Breast Cancer Diagnosis through Histological Imaging(https://arxiv.org/abs/2401.08272)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Computer Aid Diagnosis (CAD) has developed digital pathology with Deep Learning (DL)-based tools to assist pathologists in decision-making. Content-Based Histopathological Image Retrieval (CBHIR) is a novel tool to seek highly correlated patches in terms of similarity in histopathological features. In this work, we proposed two CBHIR approaches on breast (Breast-twins) and skin cancer (Skin-twins) data sets for robust and accurate patch-level retrieval, integrating a custom-built Siamese network as a feature extractor. The proposed Siamese network is able to generalize for unseen images by focusing on the similar histopathological features of the input pairs. The proposed CBHIR approaches are evaluated on the Breast (public) and Skin (private) data sets with top K accuracy. Finding the optimum amount of K is challenging, but also, as much as K increases, the dissimilarity between the query and the returned images increases which might mislead the pathologists. To the best of the author's belief, this paper is tackling this issue for the first time on histopathological images by evaluating the top first retrieved images. The Breast-twins model achieves 70% of the F1score at the top first, which exceeds the other state-of-the-art methods at a higher amount of K such as 5 and 400. Skin-twins overpasses the recently proposed Convolutional Auto Encoder (CAE) by 67%, increasing the precision. Besides, the Skin-twins model tackles the challenges of Spitzoid Tumors of Uncertain Malignant Potential (STUMP) to assist pathologists with retrieving top K images and their corresponding labels. So, this approach can offer a more explainable CAD tool to pathologists in terms of transparency, trustworthiness, or reliability among other characteristics.</li>
</ul>

<h3>Title: Large Language Models are Null-Shot Learners</h3>
<ul>
<li><strong>Authors: </strong>Pittawat Taveekitworachai, Febri Abdullah, Ruck Thawonmas</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08273">https://arxiv.org/abs/2401.08273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08273">https://arxiv.org/pdf/2401.08273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08273]] Large Language Models are Null-Shot Learners(https://arxiv.org/abs/2401.08273)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents null-shot prompting. Null-shot prompting exploits hallucination in large language models (LLMs) by instructing LLMs to utilize information from the "Examples" section that never exists within the provided context to perform a task. While reducing hallucination is crucial and non-negligible for daily and critical uses of LLMs, we propose that in the current landscape in which these LLMs still hallucinate, it is possible, in fact, to exploit hallucination to increase performance in performing tasks compared to standard zero-shot prompting. Experiments with six LLMs show improvements in performance across the majority of eight datasets, including reading comprehension, arithmetic reasoning, and closed-book question answering. The observed inconsistency in increased relative performance across LLMs also potentially indicates a different degree of inherent hallucination in each model. These differences show that it is possible to utilize null-shot prompting as a way to detect degrees of hallucination in LLMs using existing benchmarking datasets. We also perform ablation studies, including experimenting with a modified version of null-shot prompting that incorporates ideas from zero-shot chain-of-thought prompting, which shows different trends of results.</li>
</ul>

<h3>Title: Modeling Spoof Noise by De-spoofing Diffusion and its Application in  Face Anti-spoofing</h3>
<ul>
<li><strong>Authors: </strong>Bin Zhang, Xiangyu Zhu, Xiaoyu Zhang, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08275">https://arxiv.org/abs/2401.08275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08275">https://arxiv.org/pdf/2401.08275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08275]] Modeling Spoof Noise by De-spoofing Diffusion and its Application in  Face Anti-spoofing(https://arxiv.org/abs/2401.08275)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, diffusion</a></li>
<li><strong>Abstract: </strong>Face anti-spoofing is crucial for ensuring the security and reliability of face recognition systems. Several existing face anti-spoofing methods utilize GAN-like networks to detect presentation attacks by estimating the noise pattern of a spoof image and recovering the corresponding genuine image. But GAN's limited face appearance space results in the denoised faces cannot cover the full data distribution of genuine faces, thereby undermining the generalization performance of such methods. In this work, we present a pioneering attempt to employ diffusion models to denoise a spoof image and restore the genuine image. The difference between these two images is considered as the spoof noise, which can serve as a discriminative cue for face anti-spoofing. We evaluate our proposed method on several intra-testing and inter-testing protocols, where the experimental results showcase the effectiveness of our method in achieving competitive performance in terms of both accuracy and generalization.</li>
</ul>

<h3>Title: AesBench: An Expert Benchmark for Multimodal Large Language Models on  Image Aesthetics Perception</h3>
<ul>
<li><strong>Authors: </strong>Yipo Huang, Quan Yuan, Xiangfei Sheng, Zhichao Yang, Haoning Wu, Pengfei Chen, Yuzhe Yang, Leida Li, Weisi Lin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08276">https://arxiv.org/abs/2401.08276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08276">https://arxiv.org/pdf/2401.08276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08276]] AesBench: An Expert Benchmark for Multimodal Large Language Models on  Image Aesthetics Perception(https://arxiv.org/abs/2401.08276)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With collective endeavors, multimodal large language models (MLLMs) are undergoing a flourishing development. However, their performances on image aesthetics perception remain indeterminate, which is highly desired in real-world applications. An obvious obstacle lies in the absence of a specific benchmark to evaluate the effectiveness of MLLMs on aesthetic perception. This blind groping may impede the further development of more advanced MLLMs with aesthetic perception capacity. To address this dilemma, we propose AesBench, an expert benchmark aiming to comprehensively evaluate the aesthetic perception capacities of MLLMs through elaborate design across dual facets. (1) We construct an Expert-labeled Aesthetics Perception Database (EAPD), which features diversified image contents and high-quality annotations provided by professional aesthetic experts. (2) We propose a set of integrative criteria to measure the aesthetic perception abilities of MLLMs from four perspectives, including Perception (AesP), Empathy (AesE), Assessment (AesA) and Interpretation (AesI). Extensive experimental results underscore that the current MLLMs only possess rudimentary aesthetic perception ability, and there is still a significant gap between MLLMs and humans. We hope this work can inspire the community to engage in deeper explorations on the aesthetic potentials of MLLMs. Source data will be available at https://github.com/yipoh/AesBench.</li>
</ul>

<h3>Title: Inferflow: an Efficient and Highly Configurable Inference Engine for  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shuming Shi, Enbo Zhao, Deng Cai, Leyang Cui, Xinting Huang, Huayang Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08294">https://arxiv.org/abs/2401.08294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08294">https://arxiv.org/pdf/2401.08294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08294]] Inferflow: an Efficient and Highly Configurable Inference Engine for  Large Language Models(https://arxiv.org/abs/2401.08294)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>We present Inferflow, an efficient and highly configurable inference engine for large language models (LLMs). With Inferflow, users can serve most of the common transformer models by simply modifying some lines in corresponding configuration files, without writing a single line of source code. Compared with most existing inference engines, Inferflow has some key features. First, by implementing a modular framework of atomic build-blocks and technologies, Inferflow is compositionally generalizable to new models. Second, 3.5-bit quantization is introduced in Inferflow as a tradeoff between 3-bit and 4-bit quantization. Third, hybrid model partitioning for multi-GPU inference is introduced in Inferflow to better balance inference speed and throughput than the existing partition-by-layer and partition-by-tensor strategies.</li>
</ul>

<h3>Title: DAPT: A Dual Attention Framework for Parameter-Efficient Continual  Learning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Weixiang Zhao, Shilong Wang, Yulin Hu, Yanyan Zhao, Bing Qin, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08295">https://arxiv.org/abs/2401.08295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08295">https://arxiv.org/pdf/2401.08295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08295]] DAPT: A Dual Attention Framework for Parameter-Efficient Continual  Learning of Large Language Models(https://arxiv.org/abs/2401.08295)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The continual learning (CL) ability is vital for deploying large language models (LLMs) in the dynamic world. Based on parameter-efficient tuning (PET), existing methods devise the learning module and the selection module to handle the challenges of catastrophic forgetting (CF) and knowledge transfer (KT) in CL. The learning module allocates separate PET blocks for each continually emerged task and the selection module function to choose the correct one for the input at testing time. However, there are limitations in their deigns of both modules and they ignore the potential of aligning the two module to address CF and KT simultaneously. To this end, we propose a novel Dual Attention Framework , to align the PET learning and selection via the Dual Attentive Learning\&Selection module. Extensive Experiments on two CL benchmarks demonstrate the superiority of DAPT to resist CF and facilitate KT at the same time. Moreover, DAPT exhibits the superiority when we scale it to different model sizes (from 770M to 11B) and unseen tasks.</li>
</ul>

<h3>Title: Anchor function: a type of benchmark functions for studying language  models</h3>
<ul>
<li><strong>Authors: </strong>Zhongwang Zhang, Zhiwei Wang, Junjie Yao, Zhangchen Zhou, Xiaolong Li, Weinan E, Zhi-Qin John Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08309">https://arxiv.org/abs/2401.08309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08309">https://arxiv.org/pdf/2401.08309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08309]] Anchor function: a type of benchmark functions for studying language  models(https://arxiv.org/abs/2401.08309)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Understanding transformer-based language models is becoming increasingly crucial, particularly as they play pivotal roles in advancing towards artificial general intelligence. However, language model research faces significant challenges, especially for academic research groups with constrained resources. These challenges include complex data structures, unknown target functions, high computational costs and memory requirements, and a lack of interpretability in the inference process, etc. Drawing a parallel to the use of simple models in scientific research, we propose the concept of an anchor function. This is a type of benchmark function designed for studying language models in learning tasks that follow an "anchor-key" pattern. By utilizing the concept of an anchor function, we can construct a series of functions to simulate various language tasks. The anchor function plays a role analogous to that of mice in diabetes research, particularly suitable for academic research. We demonstrate the utility of the anchor function with an example, revealing two basic operations by attention structures in language models: shifting tokens and broadcasting one token from one position to many positions. These operations are also commonly observed in large language models. The anchor function framework, therefore, opens up a series of valuable and accessible research questions for further exploration, especially for theoretical study.</li>
</ul>

<h3>Title: Application of LLM Agents in Recruitment: A Novel Framework for Resume  Screening</h3>
<ul>
<li><strong>Authors: </strong>Chengguang Gan, Qinghao Zhang, Tatsunori Mori</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08315">https://arxiv.org/abs/2401.08315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08315">https://arxiv.org/pdf/2401.08315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08315]] Application of LLM Agents in Recruitment: A Novel Framework for Resume  Screening(https://arxiv.org/abs/2401.08315)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The automation of resume screening is a crucial aspect of the recruitment process in organizations. Automated resume screening systems often encompass a range of natural language processing (NLP) tasks. The advent of Large Language Models (LLMs) has notably enhanced the efficacy of these systems, showcasing their robust generalization abilities across diverse language-related tasks. Accompanying these developments are various agents based on LLMs, which facilitate their application in practical scenarios. This paper introduces a novel LLM-based agent framework for resume screening, aimed at enhancing efficiency and time management in recruitment processes. Our framework is distinct in its ability to efficiently summarize and grade each resume from a large dataset. Moreover, it utilizes LLM agents for decision-making, determining which candidates receive job offers, or which ones to bring in for interviews. To evaluate our framework, we constructed a dataset from actual resumes and conducted simulate a resume screening process. Subsequently, the outcomes of the simulation experiment were compared and subjected to detailed analysis. The results demonstrate that our automated resume screening framework is 11 times faster than traditional manual methods. Furthermore, by fine-tuning the LLMs, we observed a significant improvement in the F1 score, reaching 87.73\%, during the resume sentence classification phase. In the resume summarization and grading phase, our fine-tuned model surpassed the baseline performance of the GPT-3.5 model. Analysis of the decision-making efficacy of the LLM agents in the final offer stage further underscores the potential of LLM agents in transforming resume screening processes.</li>
</ul>

<h3>Title: RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large  Language Models in Tool Learning</h3>
<ul>
<li><strong>Authors: </strong>Junjie Ye, Yilong Wu, Songyang Gao, Sixian Li, Guanyu Li, Xiaoran Fan, Qi Zhang, Tao Gui, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08326">https://arxiv.org/abs/2401.08326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08326">https://arxiv.org/pdf/2401.08326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08326]] RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large  Language Models in Tool Learning(https://arxiv.org/abs/2401.08326)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Tool learning has generated widespread interest as a vital means of interaction between Large Language Models (LLMs) and the physical world. Current research predominantly emphasizes LLMs' capacity to utilize tools in well-structured environments while overlooking their stability when confronted with the inevitable noise of the real world. To bridge this gap, we introduce RoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool learning. Specifically, we establish five external environments, each featuring varying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union), providing an in-depth analysis of the model's resilience across three critical phases: tool selection, parameter identification, and content filling. Experiments involving six widely-used models underscore the urgent necessity for enhancing the robustness of LLMs in tool learning. For instance, the performance of GPT-4 even drops significantly from 80.00 to 58.10 when there is no substantial change in manual accuracy. More surprisingly, the noise correction capability inherent in the GPT family paradoxically impedes its adaptability in the face of mild noise. In light of these findings, we propose RoTTuning, a strategy that enriches the diversity of training environments to bolster the robustness of LLMs in tool learning. The code and data are available at https://github.com/Junjie-Ye/RoTBench.</li>
</ul>

<h3>Title: Learn What You Need in Personalized Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Kexin Lv, Rui Ye, Xiaolin Huang, Jie Yang, Siheng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08327">https://arxiv.org/abs/2401.08327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08327">https://arxiv.org/pdf/2401.08327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08327]] Learn What You Need in Personalized Federated Learning(https://arxiv.org/abs/2401.08327)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Personalized federated learning aims to address data heterogeneity across local clients in federated learning. However, current methods blindly incorporate either full model parameters or predefined partial parameters in personalized federated learning. They fail to customize the collaboration manner according to each local client's data characteristics, causing unpleasant aggregation results. To address this essential issue, we propose $\textit{Learn2pFed}$, a novel algorithm-unrolling-based personalized federated learning framework, enabling each client to adaptively select which part of its local model parameters should participate in collaborative training. The key novelty of the proposed $\textit{Learn2pFed}$ is to optimize each local model parameter's degree of participant in collaboration as learnable parameters via algorithm unrolling methods. This approach brings two benefits: 1) mathmatically determining the participation degree of local model parameters in the federated collaboration, and 2) obtaining more stable and improved solutions. Extensive experiments on various tasks, including regression, forecasting, and image classification, demonstrate that $\textit{Learn2pFed}$ significantly outperforms previous personalized federated learning methods.</li>
</ul>

<h3>Title: Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal  Correlation</h3>
<ul>
<li><strong>Authors: </strong>Devavrat Tomar, Guillaume Vray, Jean-Philippe Thiran, Behzad Bozorgtabar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08328">https://arxiv.org/abs/2401.08328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08328">https://arxiv.org/pdf/2401.08328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08328]] Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal  Correlation(https://arxiv.org/abs/2401.08328)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In an era where test-time adaptation methods increasingly rely on the nuanced manipulation of batch normalization (BN) parameters, one critical assumption often goes overlooked: that of independently and identically distributed (i.i.d.) test batches with respect to unknown labels. This assumption culminates in biased estimates of BN statistics and jeopardizes system stability under non-i.i.d. conditions. This paper pioneers a departure from the i.i.d. paradigm by introducing a groundbreaking strategy termed "Un-Mixing Test-Time Normalization Statistics" (UnMix-TNS). UnMix-TNS re-calibrates the instance-wise statistics used to normalize each instance in a batch by mixing it with multiple unmixed statistics components, thus inherently simulating the i.i.d. environment. The key lies in our innovative online unmixing procedure, which persistently refines these statistics components by drawing upon the closest instances from an incoming test batch. Remarkably generic in its design, UnMix-TNS seamlessly integrates with an array of state-of-the-art test-time adaptation methods and pre-trained architectures equipped with BN layers. Empirical evaluations corroborate the robustness of UnMix-TNS under varied scenarios ranging from single to continual and mixed domain shifts. UnMix-TNS stands out when handling test data streams with temporal correlation, including those with corrupted real-world non-i.i.d. streams, sustaining its efficacy even with minimal batch sizes and individual samples. Our results set a new standard for test-time adaptation, demonstrating significant improvements in both stability and performance across multiple benchmarks.</li>
</ul>

<h3>Title: Generative Denoise Distillation: Simple Stochastic Noises Induce  Efficient Knowledge Transfer for Dense Prediction</h3>
<ul>
<li><strong>Authors: </strong>Zhaoge Liu, Xiaohao Xu, Yunkang Cao, Weiming Shen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08332">https://arxiv.org/abs/2401.08332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08332">https://arxiv.org/pdf/2401.08332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08332]] Generative Denoise Distillation: Simple Stochastic Noises Induce  Efficient Knowledge Transfer for Dense Prediction(https://arxiv.org/abs/2401.08332)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Knowledge distillation is the process of transferring knowledge from a more powerful large model (teacher) to a simpler counterpart (student). Numerous current approaches involve the student imitating the knowledge of the teacher directly. However, redundancy still exists in the learned representations through these prevalent methods, which tend to learn each spatial location's features indiscriminately. To derive a more compact representation (concept feature) from the teacher, inspired by human cognition, we suggest an innovative method, termed Generative Denoise Distillation (GDD), where stochastic noises are added to the concept feature of the student to embed them into the generated instance feature from a shallow network. Then, the generated instance feature is aligned with the knowledge of the instance from the teacher. We extensively experiment with object detection, instance segmentation, and semantic segmentation to demonstrate the versatility and effectiveness of our method. Notably, GDD achieves new state-of-the-art performance in the tasks mentioned above. We have achieved substantial improvements in semantic segmentation by enhancing PspNet and DeepLabV3, both of which are based on ResNet-18, resulting in mIoU scores of 74.67 and 77.69, respectively, surpassing their previous scores of 69.85 and 73.20 on the Cityscapes dataset of 20 categories. The source code of GDD is available at https://github.com/ZhgLiu/GDD.</li>
</ul>

<h3>Title: dabih -- encrypted data storage and sharing platform</h3>
<ul>
<li><strong>Authors: </strong>Michael Huttner, Jakob Simeth, Renato Liguori, Fulvia Ferrazzi, Rainer Spang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE, q-bio.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08333">https://arxiv.org/abs/2401.08333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08333">https://arxiv.org/pdf/2401.08333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08333]] dabih -- encrypted data storage and sharing platform(https://arxiv.org/abs/2401.08333)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Background: The secure management of sensitive clinical data, particularly human genomics data, has become a critical requirement in modern biomedical research. Although the necessary software and algorithms are readily available, their use by non-IT experts poses significant challenges. Methods: We developed dabih, an open-source web application specifically designed to facilitate user-friendly encrypted data management. dabih enables web-based uploading, storing, sharing, and downloading of sensitive data in any format. Its approach to data security involves a two-stage envelope encryption process. We combine symmetric-key encryption for data and public-key encryption as key encapsulation mechanism. The private key necessary for decrypting the data remains exclusively on the owner's device. Thus, accessing data is impossible without explicit permission from the keyholder. Results: dabih is available open-source on GitHub https://github.com/spang-lab/dabih, as ready to use containers on docker hub and includes a command line interface and a graphical bulk upload tool as pre-built binaries. Documentation is available as part of the web application. Conclusions: dabih enables everyone to use strong cryptography for their data, while being just as simple to use as other, non-encrypted, data storage solutions. All the cryptography occurs seamlessly in the background as users interact with a secure web portal, simply by dragging and dropping files.</li>
</ul>

<h3>Title: Multi-view Distillation based on Multi-modal Fusion for Few-shot Action  Recognition(CLIP-$\mathrm{M^2}$DF)</h3>
<ul>
<li><strong>Authors: </strong>Fei Guo, YiKang Wang, Han Qi, WenPing Jin, Li Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08345">https://arxiv.org/abs/2401.08345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08345">https://arxiv.org/pdf/2401.08345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08345]] Multi-view Distillation based on Multi-modal Fusion for Few-shot Action  Recognition(CLIP-$\mathrm{M^2}$DF)(https://arxiv.org/abs/2401.08345)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, few-shot action recognition has attracted increasing attention. It generally adopts the paradigm of meta-learning. In this field, overcoming the overlapping distribution of classes and outliers is still a challenging problem based on limited samples. We believe the combination of Multi-modal and Multi-view can improve this issue depending on information complementarity. Therefore, we propose a method of Multi-view Distillation based on Multi-modal Fusion. Firstly, a Probability Prompt Selector for the query is constructed to generate probability prompt embedding based on the comparison score between the prompt embeddings of the support and the visual embedding of the query. Secondly, we establish a Multi-view. In each view, we fuse the prompt embedding as consistent information with visual and the global or local temporal context to overcome the overlapping distribution of classes and outliers. Thirdly, we perform the distance fusion for the Multi-view and the mutual distillation of matching ability from one to another, enabling the model to be more robust to the distribution bias. Our code is available at the URL: \url{https://github.com/cofly2014/MDMF}.</li>
</ul>

<h3>Title: We don't need no labels: Estimating post-deployment model performance  under covariate shift without ground truth</h3>
<ul>
<li><strong>Authors: </strong>Jakub Białek, Wojtek Kuberski, Nikolaos Perrakis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08348">https://arxiv.org/abs/2401.08348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08348">https://arxiv.org/pdf/2401.08348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08348]] We don't need no labels: Estimating post-deployment model performance  under covariate shift without ground truth(https://arxiv.org/abs/2401.08348)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The performance of machine learning models often degrades after deployment due to data distribution shifts. In many use cases, it is impossible to calculate the post-deployment performance because labels are unavailable or significantly delayed. Proxy methods for evaluating model performance stability, like drift detection techniques, do not properly quantify data distribution shift impact. As a solution, we propose a robust and accurate performance estimation method for evaluating ML classification models on unlabeled data that accurately quantifies the impact of covariate shift on model performance. We call it multi-calibrated confidence-based performance estimation (M-CBPE). It is model and data-type agnostic and works for any performance metric. It does not require access to the monitored model - it uses the model predictions and probability estimates. M-CBPE does not need user input on the nature of the covariate shift as it fully learns from the data. We evaluate it with over 600 dataset-model pairs from US census data and compare it with multiple benchmarks using several evaluation metrics. Results show that M-CBPE is the best method to estimate the performance of classification models in any evaluation context.</li>
</ul>

<h3>Title: Salute the Classic: Revisiting Challenges of Machine Translation in the  Age of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jianhui Pang, Fanghua Ye, Longyue Wang, Dian Yu, Derek F. Wong, Shuming Shi, Zhaopeng Tu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08350">https://arxiv.org/abs/2401.08350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08350">https://arxiv.org/pdf/2401.08350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08350]] Salute the Classic: Revisiting Challenges of Machine Translation in the  Age of Large Language Models(https://arxiv.org/abs/2401.08350)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The evolution of Neural Machine Translation (NMT) has been significantly influenced by six core challenges (Koehn and Knowles, 2017), which have acted as benchmarks for progress in this field. This study revisits these challenges, offering insights into their ongoing relevance in the context of advanced Large Language Models (LLMs): domain mismatch, amount of parallel data, rare word prediction, translation of long sentences, attention model as word alignment, and sub-optimal beam search. Our empirical findings indicate that LLMs effectively lessen the reliance on parallel data for major languages in the pretraining phase. Additionally, the LLM-based translation system significantly enhances the translation of long sentences that contain approximately 80 words and shows the capability to translate documents of up to 512 words. However, despite these significant improvements, the challenges of domain mismatch and prediction of rare words persist. While the challenges of word alignment and beam search, specifically associated with NMT, may not apply to LLMs, we identify three new challenges for LLMs in translation tasks: inference efficiency, translation of low-resource languages in the pretraining phase, and human-aligned evaluation. The datasets and models are released at https://github.com/pangjh3/LLM4MT.</li>
</ul>

<h3>Title: Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian  Approach</h3>
<ul>
<li><strong>Authors: </strong>Mahrokh Ghoddousi Boroujeni, Andreas Krause, Giancarlo Ferrari Trecate</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08351">https://arxiv.org/abs/2401.08351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08351">https://arxiv.org/pdf/2401.08351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08351]] Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian  Approach(https://arxiv.org/abs/2401.08351)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning aims to infer a shared model from private and decentralized data stored locally by multiple clients. Personalized federated learning (PFL) goes one step further by adapting the global model to each client, enhancing the model's fit for different clients. A significant level of personalization is required for highly heterogeneous clients, but can be challenging to achieve especially when they have small datasets. To address this problem, we propose a PFL algorithm named PAC-PFL for learning probabilistic models within a PAC-Bayesian framework that utilizes differential privacy to handle data-dependent priors. Our algorithm collaboratively learns a shared hyper-posterior and regards each client's posterior inference as the personalization step. By establishing and minimizing a generalization bound on the average true risk of clients, PAC-PFL effectively combats over-fitting. PACPFL achieves accurate and well-calibrated predictions, supported by experiments on a dataset of photovoltaic panel power generation, FEMNIST dataset (Caldas et al., 2019), and Dirichlet-partitioned EMNIST dataset (Cohen et al., 2017).</li>
</ul>

<h3>Title: SAMF: Small-Area-Aware Multi-focus Image Fusion for Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Xilai Li, Xiaosong Li, Haishu Tan, Jinyang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08357">https://arxiv.org/abs/2401.08357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08357">https://arxiv.org/pdf/2401.08357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08357]] SAMF: Small-Area-Aware Multi-focus Image Fusion for Object Detection(https://arxiv.org/abs/2401.08357)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Existing multi-focus image fusion (MFIF) methods often fail to preserve the uncertain transition region and detect small focus areas within large defocused regions accurately. To address this issue, this study proposes a new small-area-aware MFIF algorithm for enhancing object detection capability. First, we enhance the pixel attributes within the small focus and boundary regions, which are subsequently combined with visual saliency detection to obtain the pre-fusion results used to discriminate the distribution of focused pixels. To accurately ensure pixel focus, we consider the source image as a combination of focused, defocused, and uncertain regions and propose a three-region segmentation strategy. Finally, we design an effective pixel selection rule to generate segmentation decision maps and obtain the final fusion results. Experiments demonstrated that the proposed method can accurately detect small and smooth focus areas while improving object detection performance, outperforming existing methods in both subjective and objective evaluations. The source code is available at https://github.com/ixilai/SAMF.</li>
</ul>

<h3>Title: Hallucination Detection and Hallucination Mitigation: An Investigation</h3>
<ul>
<li><strong>Authors: </strong>Junliang Luo, Tianyu Li, Di Wu, Michael Jenkin, Steve Liu, Gregory Dudek</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08358">https://arxiv.org/abs/2401.08358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08358">https://arxiv.org/pdf/2401.08358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08358]] Hallucination Detection and Hallucination Mitigation: An Investigation(https://arxiv.org/abs/2401.08358)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), including ChatGPT, Bard, and Llama, have achieved remarkable successes over the last two years in a range of different applications. In spite of these successes, there exist concerns that limit the wide application of LLMs. A key problem is the problem of hallucination. Hallucination refers to the fact that in addition to correct responses, LLMs can also generate seemingly correct but factually incorrect responses. This report aims to present a comprehensive review of the current literature on both hallucination detection and hallucination mitigation. We hope that this report can serve as a good reference for both engineers and researchers who are interested in LLMs and applying them to real world tasks.</li>
</ul>

<h3>Title: Mitigating Bias in Machine Learning Models for Phishing Webpage  Detection</h3>
<ul>
<li><strong>Authors: </strong>Aditya Kulkarni, Vivek Balachandran, Dinil Mon Divakaran, Tamal Das</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08363">https://arxiv.org/abs/2401.08363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08363">https://arxiv.org/pdf/2401.08363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08363]] Mitigating Bias in Machine Learning Models for Phishing Webpage  Detection(https://arxiv.org/abs/2401.08363)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The widespread accessibility of the Internet has led to a surge in online fraudulent activities, underscoring the necessity of shielding users' sensitive information from cybercriminals. Phishing, a well-known cyberattack, revolves around the creation of phishing webpages and the dissemination of corresponding URLs, aiming to deceive users into sharing their sensitive information, often for identity theft or financial gain. Various techniques are available for preemptively categorizing zero-day phishing URLs by distilling unique attributes and constructing predictive models. However, these existing techniques encounter unresolved issues. This proposal delves into persistent challenges within phishing detection solutions, particularly concentrated on the preliminary phase of assembling comprehensive datasets, and proposes a potential solution in the form of a tool engineered to alleviate bias in ML models. Such a tool can generate phishing webpages for any given set of legitimate URLs, infusing randomly selected content and visual-based phishing features. Furthermore, we contend that the tool holds the potential to assess the efficacy of existing phishing detection solutions, especially those trained on confined datasets.</li>
</ul>

<h3>Title: Exploiting Inter-Layer Expert Affinity for Accelerating  Mixture-of-Experts Model Inference</h3>
<ul>
<li><strong>Authors: </strong>Jinghan Yao, Quentin Anthony, Aamir Shafi, Hari Subramoni, Dhabaleswar K. (DK)Panda</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08383">https://arxiv.org/abs/2401.08383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08383">https://arxiv.org/pdf/2401.08383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08383]] Exploiting Inter-Layer Expert Affinity for Accelerating  Mixture-of-Experts Model Inference(https://arxiv.org/abs/2401.08383)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>In large language models like the Generative Pre-trained Transformer, the Mixture of Experts paradigm has emerged as a powerful technique for enhancing model expressiveness and accuracy. However, deploying GPT MoE models for parallel inference on distributed systems presents significant challenges, primarily due to the extensive Alltoall communication required for expert routing and aggregation. This communication bottleneck exacerbates the already complex computational landscape, hindering the efficient utilization of high-performance computing resources. In this paper, we propose a lightweight optimization technique called ExFlow, to largely accelerate the inference of these MoE models. We take a new perspective on alleviating the communication overhead by exploiting the inter-layer expert affinity. Unlike previous methods, our solution can be directly applied to pre-trained MoE models without any fine-tuning or accuracy degradation. By proposing a context-coherent expert parallelism on distributed systems, our design only uses one Alltoall communication to deliver the same functionality while previous methods all require two Alltoalls. By carefully examining the conditional probability in tokens' routing across multiple layers, we proved that pre-trained GPT MoE models implicitly exhibit a strong inter-layer expert affinity. We then design an efficient integer programming model to capture such features and show that by properly placing the experts on corresponding GPUs, we can reduce up to 67% cross-GPU routing latency. Our solution beats the cutting-edge MoE implementations with experts from 8 to 64, with up to 2.2x improvement in inference throughput. We further provide a detailed study of how the model implicitly acquires this expert affinity at the very early training stage and how this affinity evolves and stabilizes during training.</li>
</ul>

<h3>Title: DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Zongxin Yang, Guikun Chen, Xiaodi Li, Wenguan Wang, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08392">https://arxiv.org/abs/2401.08392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08392">https://arxiv.org/pdf/2401.08392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08392]] DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language  Models(https://arxiv.org/abs/2401.08392)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The field of AI agents is advancing at an unprecedented rate due to the capabilities of large language models (LLMs). However, LLM-driven visual agents mainly focus on solving tasks for the image modality, which limits their ability to understand the dynamic nature of the real world, making it still far from real-life applications, e.g., guiding students in laboratory experiments and identifying their mistakes. Considering the video modality better reflects the ever-changing and perceptually intensive nature of real-world scenarios, we devise DoraemonGPT, a comprehensive and conceptually elegant system driven by LLMs to handle dynamic video tasks. Given a video with a question/task, DoraemonGPT begins by converting the input video with massive content into a symbolic memory that stores \textit{task-related} attributes. This structured representation allows for spatial-temporal querying and reasoning by sub-task tools, resulting in concise and relevant intermediate results. Recognizing that LLMs have limited internal knowledge when it comes to specialized domains (e.g., analyzing the scientific principles underlying experiments), we incorporate plug-and-play tools to assess external knowledge and address tasks across different domains. Moreover, we introduce a novel LLM-driven planner based on Monte Carlo Tree Search to efficiently explore the large planning space for scheduling various tools. The planner iteratively finds feasible solutions by backpropagating the result's reward, and multiple solutions can be summarized into an improved final answer. We extensively evaluate DoraemonGPT in dynamic scenes and provide in-the-wild showcases demonstrating its ability to handle more complex questions than previous studies.</li>
</ul>

<h3>Title: Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine</h3>
<ul>
<li><strong>Authors: </strong>Qiao Jin, Fangyuan Chen, Yiliang Zhou, Ziyang Xu, Justin M. Cheung, Robert Chen, Ronald M. Summers, Justin F. Rousseau, Peiyun Ni, Marc J Landsman, Sally L. Baxter, Subhi J. Al'Aref, Yijia Li, Michael F. Chiang, Yifan Peng, Zhiyong Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08396">https://arxiv.org/abs/2401.08396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08396">https://arxiv.org/pdf/2401.08396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08396]] Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine(https://arxiv.org/abs/2401.08396)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent studies indicate that Generative Pre-trained Transformer 4 with Vision (GPT-4V) outperforms human physicians in medical challenge tasks. However, these evaluations primarily focused on the accuracy of multi-choice questions alone. Our study extends the current scope by conducting a comprehensive analysis of GPT-4V's rationales of image comprehension, recall of medical knowledge, and step-by-step multimodal reasoning when solving New England Journal of Medicine (NEJM) Image Challenges - an imaging quiz designed to test the knowledge and diagnostic capabilities of medical professionals. Evaluation results confirmed that GPT-4V outperforms human physicians regarding multi-choice accuracy (88.0% vs. 77.0%, p=0.034). GPT-4V also performs well in cases where physicians incorrectly answer, with over 80% accuracy. However, we discovered that GPT-4V frequently presents flawed rationales in cases where it makes the correct final choices (27.3%), most prominent in image comprehension (21.6%). Regardless of GPT-4V's high accuracy in multi-choice questions, our findings emphasize the necessity for further in-depth evaluations of its rationales before integrating such models into clinical workflows.</li>
</ul>

<h3>Title: RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on  Agriculture</h3>
<ul>
<li><strong>Authors: </strong>Aman Gupta, Anup Shirgaonkar, Angels de Luis Balaguer, Bruno Silva, Daniel Holstein, Dawei Li, Jennifer Marsman, Leonardo O. Nunes, Mahsa Rouzbahman, Morris Sharp, Nick Mecklenburg, Rafael Padilha, Ranveer Chandra, Renato Luiz de Freitas Cunha, Roberto de M. Estevão Filho, Ryan Tsang, Sara Malvar, Swati Sharma, Todd Hendry, Vijay Aski, Vijetha Vijayendran, Vinamra Benara</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08406">https://arxiv.org/abs/2401.08406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08406">https://arxiv.org/pdf/2401.08406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08406]] RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on  Agriculture(https://arxiv.org/abs/2401.08406)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>There are two common ways in which developers are incorporating proprietary and domain-specific data when building applications of Large Language Models (LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the prompt with the external data, while fine-Tuning incorporates the additional knowledge into the model itself. However, the pros and cons of both approaches are not well understood. In this paper, we propose a pipeline for fine-tuning and RAG, and present the tradeoffs of both for multiple popular LLMs, including Llama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages, including extracting information from PDFs, generating questions and answers, using them for fine-tuning, and leveraging GPT-4 for evaluating the results. We propose metrics to assess the performance of different stages of the RAG and fine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset. Agriculture as an industry has not seen much penetration of AI, and we study a potentially disruptive application - what if we could provide location-specific insights to a farmer? Our results show the effectiveness of our dataset generation pipeline in capturing geographic-specific knowledge, and the quantitative and qualitative benefits of RAG and fine-tuning. We see an accuracy increase of over 6 p.p. when fine-tuning the model and this is cumulative with RAG, which increases accuracy by 5 p.p. further. In one particular experiment, we also demonstrate that the fine-tuned model leverages information from across geographies to answer specific questions, increasing answer similarity from 47% to 72%. Overall, the results point to how systems built using LLMs can be adapted to respond and incorporate knowledge across a dimension that is critical for a specific industry, paving the way for further applications of LLMs in other industrial domains.</li>
</ul>

<h3>Title: Cross-Domain Few-Shot Segmentation via Iterative Support-Query  Correspondence Mining</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Nie, Yun Xing, Gongjie Zhang, Pei Yan, Aoran Xiao, Yap-Peng Tan, Alex C. Kot, Shijian Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08407">https://arxiv.org/abs/2401.08407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08407">https://arxiv.org/pdf/2401.08407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08407]] Cross-Domain Few-Shot Segmentation via Iterative Support-Query  Correspondence Mining(https://arxiv.org/abs/2401.08407)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Cross-Domain Few-Shot Segmentation (CD-FSS) poses the challenge of segmenting novel categories from a distinct domain using only limited exemplars. In this paper, we undertake a comprehensive study of CD-FSS and uncover two crucial insights: (i) the necessity of a fine-tuning stage to effectively transfer the learned meta-knowledge across domains, and (ii) the overfitting risk during the na\"ive fine-tuning due to the scarcity of novel category examples. With these insights, we propose a novel cross-domain fine-tuning strategy that addresses the challenging CD-FSS tasks. We first design Bi-directional Few-shot Prediction (BFP), which establishes support-query correspondence in a bi-directional manner, crafting augmented supervision to reduce the overfitting risk. Then we further extend BFP into Iterative Few-shot Adaptor (IFA), which is a recursive framework to capture the support-query correspondence iteratively, targeting maximal exploitation of supervisory signals from the sparse novel category samples. Extensive empirical evaluations show that our method significantly outperforms the state-of-the-arts (+7.8\%), which verifies that IFA tackles the cross-domain challenges and mitigates the overfitting simultaneously. Code will be made available.</li>
</ul>

<h3>Title: Contrastive Preference Optimization: Pushing the Boundaries of LLM  Performance in Machine Translation</h3>
<ul>
<li><strong>Authors: </strong>Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen, Benjamin Van Durme, Kenton Murray, Young Jin Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08417">https://arxiv.org/abs/2401.08417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08417">https://arxiv.org/pdf/2401.08417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08417]] Contrastive Preference Optimization: Pushing the Boundaries of LLM  Performance in Machine Translation(https://arxiv.org/abs/2401.08417)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Moderate-sized large language models (LLMs) -- those with 7B or 13B parameters -- exhibit promising machine translation (MT) performance. However, even the top-performing 13B LLM-based translation models, like ALMA, does not match the performance of state-of-the-art conventional encoder-decoder translation models or larger-scale LLMs such as GPT-4. In this study, we bridge this performance gap. We first assess the shortcomings of supervised fine-tuning for LLMs in the MT task, emphasizing the quality issues present in the reference data, despite being human-generated. Then, in contrast to SFT which mimics reference translations, we introduce Contrastive Preference Optimization (CPO), a novel approach that trains models to avoid generating adequate but not perfect translations. Applying CPO to ALMA models with only 22K parallel sentences and 12M parameters yields significant improvements. The resulting model, called ALMA-R, can match or exceed the performance of the WMT competition winners and GPT-4 on WMT'21, WMT'22 and WMT'23 test datasets.</li>
</ul>

<h3>Title: Ask the experts: sourcing high-quality datasets for nutritional  counselling through Human-AI collaboration</h3>
<ul>
<li><strong>Authors: </strong>Simone Balloccu, Ehud Reiter, Vivek Kumar, Diego Reforgiato Recupero, Daniele Riboni</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08420">https://arxiv.org/abs/2401.08420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08420">https://arxiv.org/pdf/2401.08420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08420]] Ask the experts: sourcing high-quality datasets for nutritional  counselling through Human-AI collaboration(https://arxiv.org/abs/2401.08420)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), with their flexible generation abilities, can be powerful data sources in domains with few or no available corpora. However, problems like hallucinations and biases limit such applications. In this case study, we pick nutrition counselling, a domain lacking any public resource, and show that high-quality datasets can be gathered by combining LLMs, crowd-workers and nutrition experts. We first crowd-source and cluster a novel dataset of diet-related issues, then work with experts to prompt ChatGPT into producing related supportive text. Finally, we let the experts evaluate the safety of the generated text. We release HAI-coaching, the first expert-annotated nutrition counselling dataset containing ~2.4K dietary struggles from crowd workers, and ~97K related supportive texts generated by ChatGPT. Extensive analysis shows that ChatGPT while producing highly fluent and human-like text, also manifests harmful behaviours, especially in sensitive topics like mental health, making it unsuitable for unsupervised use.</li>
</ul>

<h3>Title: Improving Limited Supervised Foot Ulcer Segmentation Using Cross-Domain  Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Shang-Jui Kuo, Po-Han Huang, Chia-Ching Lin, Jeng-Lin Li, Ming-Ching Chang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08422">https://arxiv.org/abs/2401.08422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08422">https://arxiv.org/pdf/2401.08422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08422]] Improving Limited Supervised Foot Ulcer Segmentation Using Cross-Domain  Augmentation(https://arxiv.org/abs/2401.08422)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Diabetic foot ulcers pose health risks, including higher morbidity, mortality, and amputation rates. Monitoring wound areas is crucial for proper care, but manual segmentation is subjective due to complex wound features and background variation. Expert annotations are costly and time-intensive, thus hampering large dataset creation. Existing segmentation models relying on extensive annotations are impractical in real-world scenarios with limited annotated data. In this paper, we propose a cross-domain augmentation method named TransMix that combines Augmented Global Pre-training AGP and Localized CutMix Fine-tuning LCF to enrich wound segmentation data for model learning. TransMix can effectively improve the foot ulcer segmentation model training by leveraging other dermatology datasets not on ulcer skins or wounds. AGP effectively increases the overall image variability, while LCF increases the diversity of wound regions. Experimental results show that TransMix increases the variability of wound regions and substantially improves the Dice score for models trained with only 40 annotated images under various proportions.</li>
</ul>

<h3>Title: U-DIADS-Bib: a full and few-shot pixel-precise dataset for document  layout analysis of ancient manuscripts</h3>
<ul>
<li><strong>Authors: </strong>Silvia Zottin, Axel De Nardin, Emanuela Colombi, Claudio Piciarelli, Filippo Pavan, Gian Luca Foresti</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08425">https://arxiv.org/abs/2401.08425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08425">https://arxiv.org/pdf/2401.08425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08425]] U-DIADS-Bib: a full and few-shot pixel-precise dataset for document  layout analysis of ancient manuscripts(https://arxiv.org/abs/2401.08425)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Document Layout Analysis, which is the task of identifying different semantic regions inside of a document page, is a subject of great interest for both computer scientists and humanities scholars as it represents a fundamental step towards further analysis tasks for the former and a powerful tool to improve and facilitate the study of the documents for the latter. However, many of the works currently present in the literature, especially when it comes to the available datasets, fail to meet the needs of both worlds and, in particular, tend to lean towards the needs and common practices of the computer science side, leading to resources that are not representative of the humanities real needs. For this reason, the present paper introduces U-DIADS-Bib, a novel, pixel-precise, non-overlapping and noiseless document layout analysis dataset developed in close collaboration between specialists in the fields of computer vision and humanities. Furthermore, we propose a novel, computer-aided, segmentation pipeline in order to alleviate the burden represented by the time-consuming process of manual annotation, necessary for the generation of the ground truth segmentation maps. Finally, we present a standardized few-shot version of the dataset (U-DIADS-BibFS), with the aim of encouraging the development of models and solutions able to address this task with as few samples as possible, which would allow for more effective use in a real-world scenario, where collecting a large number of segmentations is not always feasible.</li>
</ul>

<h3>Title: Machine Translation with Large Language Models: Prompt Engineering for  Persian, English, and Russian Directions</h3>
<ul>
<li><strong>Authors: </strong>Nooshin Pourkamali, Shler Ebrahim Sharifi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08429">https://arxiv.org/abs/2401.08429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08429">https://arxiv.org/pdf/2401.08429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08429]] Machine Translation with Large Language Models: Prompt Engineering for  Persian, English, and Russian Directions(https://arxiv.org/abs/2401.08429)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative large language models (LLMs) have demonstrated exceptional proficiency in various natural language processing (NLP) tasks, including machine translation, question answering, text summarization, and natural language understanding. To further enhance the performance of LLMs in machine translation, we conducted an investigation into two popular prompting methods and their combination, focusing on cross-language combinations of Persian, English, and Russian. We employed n-shot feeding and tailored prompting frameworks. Our findings indicate that multilingual LLMs like PaLM exhibit human-like machine translation outputs, enabling superior fine-tuning of desired translation nuances in accordance with style guidelines and linguistic considerations. These models also excel in processing and applying prompts. However, the choice of language model, machine translation task, and the specific source and target languages necessitate certain considerations when adopting prompting frameworks and utilizing n-shot in-context learning. Furthermore, we identified errors and limitations inherent in popular LLMs as machine translation tools and categorized them based on various linguistic metrics. This typology of errors provides valuable insights for utilizing LLMs effectively and offers methods for designing prompts for in-context learning. Our report aims to contribute to the advancement of machine translation with LLMs by improving both the accuracy and reliability of evaluation metrics.</li>
</ul>

<h3>Title: CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Yaojia Lv, Haojie Pan, Ruiji Fu, Ming Liu, Zhongyuan Wang, Bing Qin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08438">https://arxiv.org/abs/2401.08438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08438">https://arxiv.org/pdf/2401.08438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08438]] CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language  Models(https://arxiv.org/abs/2401.08438)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Cognitive dynamics are pivotal to advance human understanding of the world. Recent advancements in large language models (LLMs) reveal their potential for cognitive simulation. However, these LLM-based cognitive studies primarily focus on static modeling, overlooking the dynamic nature of cognition. To bridge this gap, we propose the concept of the cognitive dynamics of LLMs and present a corresponding task with the inspiration of longitudinal studies. Towards the task, we develop CogBench, a novel benchmark to assess the cognitive dynamics of LLMs and validate it through participant surveys. We also design two evaluation metrics for CogBench, including Authenticity and Rationality. Recognizing the inherent static nature of LLMs, we introduce CogGPT for the task, which features an innovative iterative cognitive mechanism aimed at enhancing lifelong cognitive dynamics. Empirical results demonstrate the superiority of CogGPT over existing methods, particularly in its ability to facilitate role-specific cognitive dynamics under continuous information flows.</li>
</ul>

<h3>Title: Security and Privacy Issues and Solutions in Federated Learning for  Digital Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Hyejun Jeong, Tai-Myoung Chung</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08458">https://arxiv.org/abs/2401.08458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08458">https://arxiv.org/pdf/2401.08458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08458]] Security and Privacy Issues and Solutions in Federated Learning for  Digital Healthcare(https://arxiv.org/abs/2401.08458)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>The advent of Federated Learning has enabled the creation of a high-performing model as if it had been trained on a considerable amount of data. A multitude of participants and a server cooperatively train a model without the need for data disclosure or collection. The healthcare industry, where security and privacy are paramount, can substantially benefit from this new learning paradigm, as data collection is no longer feasible due to stringent data policies. Nonetheless, unaddressed challenges and insufficient attack mitigation are hampering its adoption. Attack surfaces differ from traditional centralized learning in that the server and clients communicate between each round of training. In this paper, we thus present vulnerabilities, attacks, and defenses based on the widened attack surfaces, as well as suggest promising new research directions toward a more robust FL.</li>
</ul>

<h3>Title: Incentivizing Secure Software Development: The Role of Liability  (Waiver) and Audit</h3>
<ul>
<li><strong>Authors: </strong>Ziyuan Huang, Gergely Biczók, Mingyan Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08476">https://arxiv.org/abs/2401.08476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08476">https://arxiv.org/pdf/2401.08476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08476]] Incentivizing Secure Software Development: The Role of Liability  (Waiver) and Audit(https://arxiv.org/abs/2401.08476)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>Misaligned incentives in secure software development have long been the focus of research in the economics of security. Product liability, a powerful legal framework in other industries, has been largely ineffective for software products until recent times. However, the rapid regulatory responses to recent global cyberattacks by both the United States and the European Union, together with the (relative) success of the General Data Protection Regulation in defining both duty and standard of care for software vendors, may just enable regulators to use liability to re-align incentives for the benefit of the digital society. Specifically, the recently proposed United States National Cybersecurity Strategy shifts responsibility for cyber incidents back to software vendors. In doing so, the strategy also puts forward the concept of the liability waiver: if a software company voluntarily undergoes and passes an IT security audit, its liability is waived. In this paper, we analyze this audit scenario from the aspect of the software vendor. We propose a mechanism where a software vendor should first undergo a repeated auditing process in each stage of which the vendor decides whether to quit early or stay with additional security investment. We show that the optimal strategy for an opt-in vendor is to never quit; and exert cumulative investments in either "one-and-done" or "incremental" manner. We relate the audit mechanism to a liability waiver insurance policy and revealed its effect on reshaping the vendor's risk perception. We also discuss influence of audit quality on the vendor's incentives and pinpoint that a desirable audit rule should be highly accurate and less strict.</li>
</ul>

<h3>Title: Solving Continual Offline Reinforcement Learning with Decision  Transformer</h3>
<ul>
<li><strong>Authors: </strong>Kaixin Huang, Li Shen, Chen Zhao, Chun Yuan, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08478">https://arxiv.org/abs/2401.08478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08478">https://arxiv.org/pdf/2401.08478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08478]] Solving Continual Offline Reinforcement Learning with Decision  Transformer(https://arxiv.org/abs/2401.08478)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Continuous offline reinforcement learning (CORL) combines continuous and offline reinforcement learning, enabling agents to learn multiple tasks from static datasets without forgetting prior tasks. However, CORL faces challenges in balancing stability and plasticity. Existing methods, employing Actor-Critic structures and experience replay (ER), suffer from distribution shifts, low efficiency, and weak knowledge-sharing. We aim to investigate whether Decision Transformer (DT), another offline RL paradigm, can serve as a more suitable offline continuous learner to address these issues. We first compare AC-based offline algorithms with DT in the CORL framework. DT offers advantages in learning efficiency, distribution shift mitigation, and zero-shot generalization but exacerbates the forgetting problem during supervised parameter updates. We introduce multi-head DT (MH-DT) and low-rank adaptation DT (LoRA-DT) to mitigate DT's forgetting problem. MH-DT stores task-specific knowledge using multiple heads, facilitating knowledge sharing with common components. It employs distillation and selective rehearsal to enhance current task learning when a replay buffer is available. In buffer-unavailable scenarios, LoRA-DT merges less influential weights and fine-tunes DT's decisive MLP layer to adapt to the current task. Extensive experiments on MoJuCo and Meta-World benchmarks demonstrate that our methods outperform SOTA CORL baselines and showcase enhanced learning capabilities and superior memory efficiency.</li>
</ul>

<h3>Title: Contrastive Perplexity for Controlled Generation: An Application in  Detoxifying Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tassilo Klein, Moin Nabi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08491">https://arxiv.org/abs/2401.08491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08491">https://arxiv.org/pdf/2401.08491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08491]] Contrastive Perplexity for Controlled Generation: An Application in  Detoxifying Large Language Models(https://arxiv.org/abs/2401.08491)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The generation of undesirable and factually incorrect content of large language models poses a significant challenge and remains largely an unsolved issue. This paper studies the integration of a contrastive learning objective for fine-tuning LLMs for implicit knowledge editing and controlled text generation. Optimizing the training objective entails aligning text perplexities in a contrastive fashion. To facilitate training the model in a self-supervised fashion, we leverage an off-the-shelf LLM for training data generation. We showcase applicability in the domain of detoxification. Herein, the proposed approach leads to a significant decrease in the generation of toxic content while preserving general utility for downstream tasks such as commonsense reasoning and reading comprehension. The proposed approach is conceptually simple but empirically powerful.</li>
</ul>

<h3>Title: The Effect of Group Status on the Variability of Group Representations  in LLM-generated Text</h3>
<ul>
<li><strong>Authors: </strong>Messi H.J. Lee, Jacob M. Montgomery, Calvin K. Lai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08495">https://arxiv.org/abs/2401.08495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08495">https://arxiv.org/pdf/2401.08495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08495]] The Effect of Group Status on the Variability of Group Representations  in LLM-generated Text(https://arxiv.org/abs/2401.08495)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have become pervasive in everyday life, yet their inner workings remain opaque. While scholarly efforts have demonstrated LLMs' propensity to reproduce biases in their training data, they have primarily focused on the association of social groups with stereotypic attributes. In this paper, we extend this line of inquiry to investigate a bias akin to the social-psychological phenomenon where socially dominant groups are perceived to be less homogeneous than socially subordinate groups as it is reproduced by LLMs. We had ChatGPT, a state-of-the-art LLM, generate a diversity of texts about intersectional group identities and compared text homogeneity. We consistently find that LLMs portray African, Asian, and Hispanic Americans as more homogeneous than White Americans. They also portray women as more homogeneous than men, but these differences are small. Finally, we find that the effect of gender differs across racial/ethnic groups such that the effect of gender is consistent within African and Hispanic Americans but not within Asian and White Americans. We speculate possible sources of this bias in LLMs and posit that the bias has the potential to amplify biases in future LLM training and to reinforce stereotypes.</li>
</ul>

<h3>Title: ValUES: A Framework for Systematic Validation of Uncertainty Estimation  in Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Kim-Celine Kahl, Carsten T. Lüth, Maximilian Zenk, Klaus Maier-Hein, Paul F. Jaeger</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08501">https://arxiv.org/abs/2401.08501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08501">https://arxiv.org/pdf/2401.08501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08501]] ValUES: A Framework for Systematic Validation of Uncertainty Estimation  in Semantic Segmentation(https://arxiv.org/abs/2401.08501)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Uncertainty estimation is an essential and heavily-studied component for the reliable application of semantic segmentation methods. While various studies exist claiming methodological advances on the one hand, and successful application on the other hand, the field is currently hampered by a gap between theory and practice leaving fundamental questions unanswered: Can data-related and model-related uncertainty really be separated in practice? Which components of an uncertainty method are essential for real-world performance? Which uncertainty method works well for which application? In this work, we link this research gap to a lack of systematic and comprehensive evaluation of uncertainty methods. Specifically, we identify three key pitfalls in current literature and present an evaluation framework that bridges the research gap by providing 1) a controlled environment for studying data ambiguities as well as distribution shifts, 2) systematic ablations of relevant method components, and 3) test-beds for the five predominant uncertainty applications: OoD-detection, active learning, failure detection, calibration, and ambiguity modeling. Empirical results on simulated as well as real-world data demonstrate how the proposed framework is able to answer the predominant questions in the field revealing for instance that 1) separation of uncertainty types works on simulated data but does not necessarily translate to real-world data, 2) aggregation of scores is a crucial but currently neglected component of uncertainty methods, 3) While ensembles are performing most robustly across the different downstream tasks and settings, test-time augmentation often constitutes a light-weight alternative. Code is at: https://github.com/IML-DKFZ/values</li>
</ul>

<h3>Title: Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Zhenhui Ye, Tianyun Zhong, Yi Ren, Jiaqi Yang, Weichuang Li, Jiawei Huang, Ziyue Jiang, Jinzheng He, Rongjie Huang, Jinglin Liu, Chen Zhang, Xiang Yin, Zejun Ma, Zhou Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08503">https://arxiv.org/abs/2401.08503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08503">https://arxiv.org/pdf/2401.08503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08503]] Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis(https://arxiv.org/abs/2401.08503)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>One-shot 3D talking portrait generation aims to reconstruct a 3D avatar from an unseen image, and then animate it with a reference video or audio to generate a talking portrait video. The existing methods fail to simultaneously achieve the goals of accurate 3D avatar reconstruction and stable talking face animation. Besides, while the existing works mainly focus on synthesizing the head part, it is also vital to generate natural torso and background segments to obtain a realistic talking portrait video. To address these limitations, we present Real3D-Potrait, a framework that (1) improves the one-shot 3D reconstruction power with a large image-to-plane model that distills 3D prior knowledge from a 3D face generative model; (2) facilitates accurate motion-conditioned animation with an efficient motion adapter; (3) synthesizes realistic video with natural torso movement and switchable background using a head-torso-background super-resolution model; and (4) supports one-shot audio-driven talking face generation with a generalizable audio-to-motion model. Extensive experiments show that Real3D-Portrait generalizes well to unseen identities and generates more realistic talking portrait videos compared to previous methods.</li>
</ul>

<h3>Title: EmoLLMs: A Series of Emotional Large Language Models and Annotation  Tools for Comprehensive Affective Analysis</h3>
<ul>
<li><strong>Authors: </strong>Zhiwei Liu, Kailai Yang, Tianlin Zhang, Qianqian Xie, Zeping Yu, Sophia Ananiadou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08508">https://arxiv.org/abs/2401.08508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08508">https://arxiv.org/pdf/2401.08508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08508]] EmoLLMs: A Series of Emotional Large Language Models and Annotation  Tools for Comprehensive Affective Analysis(https://arxiv.org/abs/2401.08508)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sentiment analysis and emotion detection are important research topics in natural language processing (NLP) and benefit many downstream tasks. With the widespread application of LLMs, researchers have started exploring the application of LLMs based on instruction-tuning in the field of sentiment analysis. However, these models only focus on single aspects of affective classification tasks (e.g. sentimental polarity or categorical emotions), and overlook the regression tasks (e.g. sentiment strength or emotion intensity), which leads to poor performance in downstream tasks. The main reason is the lack of comprehensive affective instruction tuning datasets and evaluation benchmarks, which cover various affective classification and regression tasks. Moreover, although emotional information is useful for downstream tasks, existing downstream datasets lack high-quality and comprehensive affective annotations. In this paper, we propose EmoLLMs, the first series of open-sourced instruction-following LLMs for comprehensive affective analysis based on fine-tuning various LLMs with instruction data, the first multi-task affective analysis instruction dataset (AAID) with 234K data samples based on various classification and regression tasks to support LLM instruction tuning, and a comprehensive affective evaluation benchmark (AEB) with 14 tasks from various sources and domains to test the generalization ability of LLMs. We propose a series of EmoLLMs by fine-tuning LLMs with AAID to solve various affective instruction tasks. We compare our model with a variety of LLMs on AEB, where our models outperform all other open-sourced LLMs, and surpass ChatGPT and GPT-4 in most tasks, which shows that the series of EmoLLMs achieve the ChatGPT-level and GPT-4-level generalization capabilities on affective analysis tasks, and demonstrates our models can be used as affective annotation tools.</li>
</ul>

<h3>Title: PPSURF: Combining Patches and Point Convolutions for Detailed Surface  Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Philipp Erler, Lizeth Fuentes, Pedro Hermosilla, Paul Guerrero, Renato Pajarola Michael Wimmer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08518">https://arxiv.org/abs/2401.08518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08518">https://arxiv.org/pdf/2401.08518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08518]] PPSURF: Combining Patches and Point Convolutions for Detailed Surface  Reconstruction(https://arxiv.org/abs/2401.08518)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D surface reconstruction from point clouds is a key step in areas such as content creation, archaeology, digital cultural heritage, and engineering. Current approaches either try to optimize a non-data-driven surface representation to fit the points, or learn a data-driven prior over the distribution of commonly occurring surfaces and how they correlate with potentially noisy point clouds. Data-driven methods enable robust handling of noise and typically either focus on a global or a local prior, which trade-off between robustness to noise on the global end and surface detail preservation on the local end. We propose PPSurf as a method that combines a global prior based on point convolutions and a local prior based on processing local point cloud patches. We show that this approach is robust to noise while recovering surface details more accurately than the current state-of-the-art. Our source code, pre-trained model and dataset are available at: https://github.com/cg-tuwien/ppsurf</li>
</ul>

<h3>Title: SecPLF: Secure Protocols for Loanable Funds against Oracle Manipulation  Attacks</h3>
<ul>
<li><strong>Authors: </strong>Sanidhay Arora, Yingjiu Li, Yebo Feng, Jiahua Xu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08520">https://arxiv.org/abs/2401.08520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08520">https://arxiv.org/pdf/2401.08520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08520]] SecPLF: Secure Protocols for Loanable Funds against Oracle Manipulation  Attacks(https://arxiv.org/abs/2401.08520)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>The evolving landscape of Decentralized Finance (DeFi) has raised critical security concerns, especially pertaining to Protocols for Loanable Funds (PLFs) and their dependency on price oracles, which are susceptible to manipulation. The emergence of flash loans has further amplified these risks, enabling increasingly complex oracle manipulation attacks that can lead to significant financial losses. Responding to this threat, we first dissect the attack mechanism by formalizing the standard operational and adversary models for PLFs. Based on our analysis, we propose SecPLF, a robust and practical solution designed to counteract oracle manipulation attacks efficiently. SecPLF operates by tracking a price state for each crypto-asset, including the recent price and the timestamp of its last update. By imposing price constraints on the price oracle usage, SecPLF ensures a PLF only engages a price oracle if the last recorded price falls within a defined threshold, thereby negating the profitability of potential attacks. Our evaluation based on historical market data confirms SecPLF's efficacy in providing high-confidence prevention against arbitrage attacks that arise due to minor price differences. SecPLF delivers proactive protection against oracle manipulation attacks, offering ease of implementation, oracle-agnostic property, and resource and cost efficiency.</li>
</ul>

<h3>Title: Video Quality Assessment Based on Swin TransformerV2 and Coarse to Fine  Strategy</h3>
<ul>
<li><strong>Authors: </strong>Zihao Yu, Fengbin Guan, Yiting Lu, Xin Li, Zhibo Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08522">https://arxiv.org/abs/2401.08522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08522">https://arxiv.org/pdf/2401.08522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08522]] Video Quality Assessment Based on Swin TransformerV2 and Coarse to Fine  Strategy(https://arxiv.org/abs/2401.08522)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The objective of non-reference video quality assessment is to evaluate the quality of distorted video without access to reference high-definition references. In this study, we introduce an enhanced spatial perception module, pre-trained on multiple image quality assessment datasets, and a lightweight temporal fusion module to address the no-reference visual quality assessment (NR-VQA) task. This model implements Swin Transformer V2 as a local-level spatial feature extractor and fuses these multi-stage representations through a series of transformer layers. Furthermore, a temporal transformer is utilized for spatiotemporal feature fusion across the video. To accommodate compressed videos of varying bitrates, we incorporate a coarse-to-fine contrastive strategy to enrich the model's capability to discriminate features from videos of different bitrates. This is an expanded version of the one-page abstract.</li>
</ul>

<h3>Title: MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level  Image-Concept Alignment</h3>
<ul>
<li><strong>Authors: </strong>Yequan Bie, Luyang Luo, Hao Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08527">https://arxiv.org/abs/2401.08527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08527">https://arxiv.org/pdf/2401.08527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08527]] MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level  Image-Concept Alignment(https://arxiv.org/abs/2401.08527)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Black-box deep learning approaches have showcased significant potential in the realm of medical image analysis. However, the stringent trustworthiness requirements intrinsic to the medical field have catalyzed research into the utilization of Explainable Artificial Intelligence (XAI), with a particular focus on concept-based methods. Existing concept-based methods predominantly apply concept annotations from a single perspective (e.g., global level), neglecting the nuanced semantic relationships between sub-regions and concepts embedded within medical images. This leads to underutilization of the valuable medical information and may cause models to fall short in harmoniously balancing interpretability and performance when employing inherently interpretable architectures such as Concept Bottlenecks. To mitigate these shortcomings, we propose a multi-modal explainable disease diagnosis framework that meticulously aligns medical images and clinical-related concepts semantically at multiple strata, encompassing the image level, token level, and concept level. Moreover, our method allows for model intervention and offers both textual and visual explanations in terms of human-interpretable concepts. Experimental results on three skin image datasets demonstrate that our method, while preserving model interpretability, attains high performance and label efficiency for concept detection and disease diagnosis.</li>
</ul>

<h3>Title: DiConStruct: Causal Concept-based Explanations through Black-Box  Distillation</h3>
<ul>
<li><strong>Authors: </strong>Ricardo Moreira, Jacopo Bono, Mário Cardoso, Pedro Saleiro, Mário A. T. Figueiredo, Pedro Bizarro</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08534">https://arxiv.org/abs/2401.08534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08534">https://arxiv.org/pdf/2401.08534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08534]] DiConStruct: Causal Concept-based Explanations through Black-Box  Distillation(https://arxiv.org/abs/2401.08534)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Model interpretability plays a central role in human-AI decision-making systems. Ideally, explanations should be expressed using human-interpretable semantic concepts. Moreover, the causal relations between these concepts should be captured by the explainer to allow for reasoning about the explanations. Lastly, explanation methods should be efficient and not compromise the performance of the predictive task. Despite the rapid advances in AI explainability in recent years, as far as we know to date, no method fulfills these three properties. Indeed, mainstream methods for local concept explainability do not produce causal explanations and incur a trade-off between explainability and prediction performance. We present DiConStruct, an explanation method that is both concept-based and causal, with the goal of creating more interpretable local explanations in the form of structural causal models and concept attributions. Our explainer works as a distillation model to any black-box machine learning model by approximating its predictions while producing the respective explanations. Because of this, DiConStruct generates explanations efficiently while not impacting the black-box prediction task. We validate our method on an image dataset and a tabular dataset, showing that DiConStruct approximates the black-box models with higher fidelity than other concept explainability baselines, while providing explanations that include the causal relations between the concepts.</li>
</ul>

<h3>Title: Scalable Pre-training of Large Autoregressive Image Models</h3>
<ul>
<li><strong>Authors: </strong>Alaaeldin El-Nouby, Michal Klein, Shuangfei Zhai, Miguel Angel Bautista, Alexander Toshev, Vaishaal Shankar, Joshua M Susskind, Armand Joulin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08541">https://arxiv.org/abs/2401.08541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08541">https://arxiv.org/pdf/2401.08541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08541]] Scalable Pre-training of Large Autoregressive Image Models(https://arxiv.org/abs/2401.08541)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces AIM, a collection of vision models pre-trained with an autoregressive objective. These models are inspired by their textual counterparts, i.e., Large Language Models (LLMs), and exhibit similar scaling properties. Specifically, we highlight two key findings: (1) the performance of the visual features scale with both the model capacity and the quantity of data, (2) the value of the objective function correlates with the performance of the model on downstream tasks. We illustrate the practical implication of these findings by pre-training a 7 billion parameter AIM on 2 billion images, that achieves 84.0% on ImageNet-1k with a frozen trunk. Interestingly, even at this scale, we observe no sign of saturation in performance, suggesting that AIM potentially represents a new frontier for training large-scale vision models. The pre-training of AIM is similar to the pre-training of LLMs, and does not require any image-specific strategy to stabilize the training at scale.</li>
</ul>

<h3>Title: Multi-Track Timeline Control for Text-Driven 3D Human Motion Generation</h3>
<ul>
<li><strong>Authors: </strong>Mathis Petrovich, Or Litany, Umar Iqbal, Michael J. Black, Gül Varol, Xue Bin Peng, Davis Rempe</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08559">https://arxiv.org/abs/2401.08559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08559">https://arxiv.org/pdf/2401.08559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08559]] Multi-Track Timeline Control for Text-Driven 3D Human Motion Generation(https://arxiv.org/abs/2401.08559)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative modeling have led to promising progress on synthesizing 3D human motion from text, with methods that can generate character animations from short prompts and specified durations. However, using a single text prompt as input lacks the fine-grained control needed by animators, such as composing multiple actions and defining precise durations for parts of the motion. To address this, we introduce the new problem of timeline control for text-driven motion synthesis, which provides an intuitive, yet fine-grained, input interface for users. Instead of a single prompt, users can specify a multi-track timeline of multiple prompts organized in temporal intervals that may overlap. This enables specifying the exact timings of each action and composing multiple actions in sequence or at overlapping intervals. To generate composite animations from a multi-track timeline, we propose a new test-time denoising method. This method can be integrated with any pre-trained motion diffusion model to synthesize realistic motions that accurately reflect the timeline. At every step of denoising, our method processes each timeline interval (text prompt) individually, subsequently aggregating the predictions with consideration for the specific body parts engaged in each action. Experimental comparisons and ablations validate that our method produces realistic motions that respect the semantics and timing of given text prompts. Our code and models are publicly available at https://mathis.petrovich.fr/stmc.</li>
</ul>

<h3>Title: ADVENT: Attack/Anomaly Detection in VANETs</h3>
<ul>
<li><strong>Authors: </strong>Hamideh Baharlouei, Adetokunbo Makanju, Nur Zincir-Heywood</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08564">https://arxiv.org/abs/2401.08564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08564">https://arxiv.org/pdf/2401.08564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08564]] ADVENT: Attack/Anomaly Detection in VANETs(https://arxiv.org/abs/2401.08564)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>In the domain of Vehicular Ad hoc Networks (VANETs), where the imperative of having a real-world malicious detector capable of detecting attacks in real-time and unveiling their perpetrators is crucial, our study introduces a system with this goal. This system is designed for real-time detection of malicious behavior, addressing the critical need to first identify the onset of attacks and subsequently the responsible actors. Prior work in this area have never addressed both requirements, which we believe are necessary for real world deployment, simultaneously. By seamlessly integrating statistical and machine learning techniques, the proposed system prioritizes simplicity and efficiency. It excels in swiftly detecting attack onsets with a remarkable F1-score of 99.66%, subsequently identifying malicious vehicles with an average F1-score of approximately 97.85%. Incorporating federated learning in both stages enhances privacy and improves the efficiency of malicious node detection, effectively reducing the false negative rate.</li>
</ul>

<h3>Title: RoHM: Robust Human Motion Reconstruction via Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Siwei Zhang, Bharat Lal Bhatnagar, Yuanlu Xu, Alexander Winkler, Petr Kadlecek, Siyu Tang, Federica Bogo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08570">https://arxiv.org/abs/2401.08570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08570">https://arxiv.org/pdf/2401.08570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08570]] RoHM: Robust Human Motion Reconstruction via Diffusion(https://arxiv.org/abs/2401.08570)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We propose RoHM, an approach for robust 3D human motion reconstruction from monocular RGB(-D) videos in the presence of noise and occlusions. Most previous approaches either train neural networks to directly regress motion in 3D or learn data-driven motion priors and combine them with optimization at test time. The former do not recover globally coherent motion and fail under occlusions; the latter are time-consuming, prone to local minima, and require manual tuning. To overcome these shortcomings, we exploit the iterative, denoising nature of diffusion models. RoHM is a novel diffusion-based motion model that, conditioned on noisy and occluded input data, reconstructs complete, plausible motions in consistent global coordinates. Given the complexity of the problem -- requiring one to address different tasks (denoising and infilling) in different solution spaces (local and global motion) -- we decompose it into two sub-tasks and learn two models, one for global trajectory and one for local motion. To capture the correlations between the two, we then introduce a novel conditioning module, combining it with an iterative inference scheme. We apply RoHM to a variety of tasks -- from motion reconstruction and denoising to spatial and temporal infilling. Extensive experiments on three popular datasets show that our method outperforms state-of-the-art approaches qualitatively and quantitatively, while being faster at test time. The code will be available at https://sanweiliti.github.io/ROHM/ROHM.html.</li>
</ul>

<h3>Title: Benchmarking the Robustness of Image Watermarks</h3>
<ul>
<li><strong>Authors: </strong>Bang An, Mucong Ding, Tahseen Rabbani, Aakriti Agrawal, Yuancheng Xu, Chenghao Deng, Sicheng Zhu, Abdirisak Mohamed, Yuxin Wen, Tom Goldstein, Furong Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08573">https://arxiv.org/abs/2401.08573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08573">https://arxiv.org/pdf/2401.08573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08573]] Benchmarking the Robustness of Image Watermarks(https://arxiv.org/abs/2401.08573)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>This paper investigates the weaknesses of image watermarking techniques. We present WAVES (Watermark Analysis Via Enhanced Stress-testing), a novel benchmark for assessing watermark robustness, overcoming the limitations of current evaluation methods.WAVES integrates detection and identification tasks, and establishes a standardized evaluation protocol comprised of a diverse range of stress tests. The attacks in WAVES range from traditional image distortions to advanced and novel variations of adversarial, diffusive, and embedding-based attacks. We introduce a normalized score of attack potency which incorporates several widely used image quality metrics and allows us to produce of an ordered ranking of attacks. Our comprehensive evaluation over reveals previously undetected vulnerabilities of several modern watermarking algorithms. WAVES is envisioned as a toolkit for the future development of robust watermarking systems.</li>
</ul>

<h3>Title: MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in  3D World</h3>
<ul>
<li><strong>Authors: </strong>Yining Hong, Zishuo Zheng, Peihao Chen, Yian Wang, Junyan Li, Chuang Gan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.08577">https://arxiv.org/abs/2401.08577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.08577">https://arxiv.org/pdf/2401.08577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.08577]] MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in  3D World(https://arxiv.org/abs/2401.08577)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human beings possess the capability to multiply a melange of multisensory cues while actively exploring and interacting with the 3D world. Current multi-modal large language models, however, passively absorb sensory data as inputs, lacking the capacity to actively interact with the objects in the 3D environment and dynamically collect their multisensory information. To usher in the study of this area, we propose MultiPLY, a multisensory embodied large language model that could incorporate multisensory interactive data, including visual, audio, tactile, and thermal information into large language models, thereby establishing the correlation among words, actions, and percepts. To this end, we first collect Multisensory Universe, a large-scale multisensory interaction dataset comprising 500k data by deploying an LLM-powered embodied agent to engage with the 3D environment. To perform instruction tuning with pre-trained LLM on such generated data, we first encode the 3D scene as abstracted object-centric representations and then introduce action tokens denoting that the embodied agent takes certain actions within the environment, as well as state tokens that represent the multisensory state observations of the agent at each time step. In the inference time, MultiPLY could generate action tokens, instructing the agent to take the action in the environment and obtain the next multisensory state observation. The observation is then appended back to the LLM via state tokens to generate subsequent text or action tokens. We demonstrate that MultiPLY outperforms baselines by a large margin through a diverse set of embodied tasks involving object retrieval, tool use, multisensory captioning, and task decomposition.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
