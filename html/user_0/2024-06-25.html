<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-06-25</h1>
<h3>Title: Title:
          Constructing Multilingual Visual-Text Datasets Revealing Visual Multilingual Ability of Vision Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jesse Atuhurra, Iqra Ali, Tatsuya Hiraoka, Hidetaka Kamigaito, Tomoya Iwakura, Taro Watanabe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Constructing Multilingual Visual-Text Datasets Revealing Visual Multilingual Ability of Vision Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have increased interest in vision language models (VLMs), which process image-text pairs as input. Studies investigating the visual understanding ability of VLMs have been proposed, but such studies are still preliminary because existing datasets do not permit a comprehensive evaluation of the fine-grained visual linguistic abilities of VLMs across multiple languages. To further explore the strengths of VLMs, such as GPT-4V \cite{openai2023GPT4}, we developed new datasets for the systematic and qualitative analysis of VLMs. Our contribution is four-fold: 1) we introduced nine vision-and-language (VL) tasks (including object recognition, image-text matching, and more) and constructed multilingual visual-text datasets in four languages: English, Japanese, Swahili, and Urdu through utilizing templates containing \textit{questions} and prompting GPT4-V to generate the \textit{answers} and the \textit{rationales}, 2) introduced a new VL task named \textit{unrelatedness}, 3) introduced rationales to enable human understanding of the VLM reasoning process, and 4) employed human evaluation to measure the suitability of proposed datasets for VL tasks. We show that VLMs can be fine-tuned on our datasets. Our work is the first to conduct such analyses in Swahili and Urdu. Also, it introduces \textit{rationales} in VL analysis, which played a vital role in the evaluation.</li>
</ul>

<h3>Title: Title:
          Exploring LLM Multi-Agents for ICD Coding</h3>
<ul>
<li><strong>Authors: </strong>Rumeng Li, Xun Wang, Hong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Exploring LLM Multi-Agents for ICD Coding(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive and diverse abilities that can benefit various domains, such as zero and few-shot information extraction from clinical text without domain-specific training. However, for the ICD coding task, they often hallucinate key details and produce high recall but low precision results due to the high-dimensional and skewed distribution of the ICD codes. Existing LLM-based methods fail to account for the complex and dynamic interactions among the human agents involved in coding, such as patients, physicians, and coders, and they lack interpretability and reliability. In this paper, we present a novel multi-agent method for ICD coding, which mimics the real-world coding process with five agents: a patient agent, a physician agent, a coder agent, a reviewer agent, and an adjuster agent. Each agent has a specific function and uses a LLM-based model to perform it. We evaluate our method on the MIMIC-III dataset and show that our proposed multi-agent coding framework substantially improves performance on both common and rare codes compared to Zero-shot Chain of Thought (CoT) prompting and self-consistency with CoT. The ablation study confirms the proposed agent roles' efficacy. Our method also matches the state-of-the-art ICD coding methods that require pre-training or fine-tuning, in terms of coding accuracy, rare code accuracy, and explainability.</li>
</ul>

<h3>Title: Title:
          An Exploratory Study on Human-Centric Video Anomaly Detection through Variational Autoencoders and Trajectory Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ghazal Alinezhad Noghre, Armin Danesh Pazho, Hamed Tabkhi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          An Exploratory Study on Human-Centric Video Anomaly Detection through Variational Autoencoders and Trajectory Prediction(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Video Anomaly Detection (VAD) represents a challenging and prominent research task within computer vision. In recent years, Pose-based Video Anomaly Detection (PAD) has drawn considerable attention from the research community due to several inherent advantages over pixel-based approaches despite the occasional suboptimal performance. Specifically, PAD is characterized by reduced computational complexity, intrinsic privacy preservation, and the mitigation of concerns related to discrimination and bias against specific demographic groups. This paper introduces TSGAD, a novel human-centric Two-Stream Graph-Improved Anomaly Detection leveraging Variational Autoencoders (VAEs) and trajectory prediction. TSGAD aims to explore the possibility of utilizing VAEs as a new approach for pose-based human-centric VAD alongside the benefits of trajectory prediction. We demonstrate TSGAD's effectiveness through comprehensive experimentation on benchmark datasets. TSGAD demonstrates comparable results with state-of-the-art methods showcasing the potential of adopting variational autoencoders. This suggests a promising direction for future research endeavors. The code base for this work is available at this https URL.</li>
</ul>

<h3>Title: Title:
          Feature Purified Transformer With Cross-level Feature Guiding Decoder For Multi-class OOD and Anomaly Deteciton</h3>
<ul>
<li><strong>Authors: </strong>Jerry Chun-Wei Lin, Pi-Wei Chen, Chao-Chun Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Feature Purified Transformer With Cross-level Feature Guiding Decoder For Multi-class OOD and Anomaly Deteciton(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Reconstruction networks are prevalently used in unsupervised anomaly and Out-of-Distribution (OOD) detection due to their independence from labeled anomaly data. However, in multi-class datasets, the effectiveness of anomaly detection is often compromised by the models' generalized reconstruction capabilities, which allow anomalies to blend within the expanded boundaries of normality resulting from the added categories, thereby reducing detection accuracy. We introduce the FUTUREG framework, which incorporates two innovative modules: the Feature Purification Module (FPM) and the CFG Decoder. The FPM constrains the normality boundary within the latent space to effectively filter out anomalous features, while the CFG Decoder uses layer-wise encoder representations to guide the reconstruction of filtered features, preserving fine-grained details. Together, these modules enhance the reconstruction error for anomalies, ensuring high-quality reconstructions for normal samples. Our results demonstrate that FUTUREG achieves state-of-the-art performance in multi-class OOD settings and remains competitive in industrial anomaly detection scenarios.</li>
</ul>

<h3>Title: Title:
          Investigating the Robustness of LLMs on Math Word Problems</h3>
<ul>
<li><strong>Authors: </strong>Ujjwala Anantheswaran, Himanshu Gupta, Kevin Scaria, Shreyas Verma, Chitta Baral, Swaroop Mishra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Investigating the Robustness of LLMs on Math Word Problems(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel at various tasks, including solving math word problems (MWPs), but struggle with real-world problems containing irrelevant information. To address this, we propose a prompting framework that generates adversarial variants of MWPs by adding irrelevant variables. We introduce a dataset, ProbleMATHIC, containing both adversarial and non-adversarial MWPs. Our experiments reveal that LLMs are susceptible to distraction by numerical noise, resulting in an average relative performance drop of ~26% on adversarial MWPs. To mitigate this, we fine-tune LLMs (Llama-2, Mistral) on the adversarial samples from our dataset. Fine-tuning on adversarial training instances improves performance on adversarial MWPs by ~8%, indicating increased robustness to noise and better ability to identify relevant data for reasoning. Finally, to assess the generalizability of our prompting framework, we introduce GSM-8K-Adv, an adversarial variant of the GSM-8K benchmark. LLMs continue to struggle when faced with adversarial information, reducing performance by up to ~6%.</li>
</ul>

<h3>Title: Title:
          Deep Vision-Based Framework for Coastal Flood Prediction Under Climate Change Impacts and Shoreline Adaptations</h3>
<ul>
<li><strong>Authors: </strong>Areg Karapetyan, Aaron Chung Hin Chow, Samer Madanat</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Deep Vision-Based Framework for Coastal Flood Prediction Under Climate Change Impacts and Shoreline Adaptations(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In light of growing threats posed by climate change in general and sea level rise (SLR) in particular, the necessity for computationally efficient means to estimate and analyze potential coastal flood hazards has become increasingly pressing. Data-driven supervised learning methods serve as promising candidates that can dramatically expedite the process, thereby eliminating the computational bottleneck associated with traditional physics-based hydrodynamic simulators. Yet, the development of accurate and reliable coastal flood prediction models, especially those based on Deep Learning (DL) techniques, has been plagued with two major issues: (1) the scarcity of training data and (2) the high-dimensional output required for detailed inundation mapping. To remove this barrier, we present a systematic framework for training high-fidelity Deep Vision-based coastal flood prediction models in low-data settings. We test the proposed workflow on different existing vision models, including a fully transformer-based architecture and a Convolutional Neural Network (CNN) with additive attention gates. Additionally, we introduce a deep CNN architecture tailored specifically to the coastal flood prediction problem at hand. The model was designed with a particular focus on its compactness so as to cater to resource-constrained scenarios and accessibility aspects. The performance of the developed DL models is validated against commonly adopted geostatistical regression methods and traditional Machine Learning (ML) approaches, demonstrating substantial improvement in prediction quality. Lastly, we round up the contributions by providing a meticulously curated dataset of synthetic flood inundation maps of Abu Dhabi's coast produced with a physics-based hydrodynamic simulator, which can serve as a benchmark for evaluating future coastal flood prediction models.</li>
</ul>

<h3>Title: Title:
          RadEx: A Framework for Structured Information Extraction from Radiology Reports based on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Daniel Reichenpfader, Jonas Knupp, André Sander, Kerstin Denecke</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          RadEx: A Framework for Structured Information Extraction from Radiology Reports based on Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>Annually and globally, over three billion radiography examinations and computer tomography scans result in mostly unstructured radiology reports containing free text. Despite the potential benefits of structured reporting, its adoption is limited by factors such as established processes, resource constraints and potential loss of information. However, structured information would be necessary for various use cases, including automatic analysis, clinical trial matching, and prediction of health outcomes. This study introduces RadEx, an end-to-end framework comprising 15 software components and ten artifacts to develop systems that perform automated information extraction from radiology reports. It covers the complete process from annotating training data to extracting information by offering a consistent generic information model and setting boundaries for model development. Specifically, RadEx allows clinicians to define relevant information for clinical domains (e.g., mammography) and to create report templates. The framework supports both generative and encoder-only models and the decoupling of information extraction from template filling enables independent model improvements. Developing information extraction systems according to the RadEx framework facilitates implementation and maintenance as components are easily exchangeable, while standardized artifacts ensure interoperability between components.</li>
</ul>

<h3>Title: Title:
          Reasoning or Simply Next Token Prediction? A Benchmark for Stress-Testing Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wentian Wang, Paul Kantor, Jacob Feldman, Lazaros Gallos, Hao Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Reasoning or Simply Next Token Prediction? A Benchmark for Stress-Testing Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose MMLU-SR, a novel dataset designed to measure the true comprehension abilities of Large Language Models (LLMs) by challenging their performance in question-answering tasks with modified terms. We reasoned that an agent that ``truly'' understands a concept can still evaluate it when key terms are replaced by suitably defined alternate terms, and sought to differentiate such comprehension from mere text replacement. In our study, we modified standardized test questions by replacing a key term with a dummy word along with its definition. The key term could be in the context of questions, answers, or both questions and answers. Notwithstanding the high scores achieved by recent popular LLMs on the MMLU leaderboard, we found a substantial reduction in model performance after such replacement, suggesting poor comprehension. This new benchmark provides a rigorous benchmark for testing true model comprehension, and poses a challenge to the broader scientific community.</li>
</ul>

<h3>Title: Title:
          Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Bonlarron, Jean-Charles Régin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Constrained text generation remains a challenging task, particularly when dealing with hard constraints. Traditional Natural Language Processing (NLP) approaches prioritize generating meaningful and coherent output. Also, the current state-of-the-art methods often lack the expressiveness and constraint satisfaction capabilities to handle such tasks effectively. This paper presents the Constraints First Framework to remedy this issue. This framework considers a constrained text generation problem as a discrete combinatorial optimization problem. It is solved by a constraint programming method that combines linguistic properties (e.g., n-grams or language level) with other more classical constraints (e.g., the number of characters, syllables, or words). Eventually, a curation phase allows for selecting the best-generated sentences according to perplexity using a large language model. The effectiveness of this approach is demonstrated by tackling a new more tediously constrained text generation problem: the iconic RADNER sentences problem. This problem aims to generate sentences respecting a set of quite strict rules defined by their use in vision and clinical research. Thanks to our CP-based approach, many new strongly constrained sentences have been successfully generated in an automatic manner. This highlights the potential of our approach to handle unreasonably constrained text generation scenarios.</li>
</ul>

<h3>Title: Title:
          Self-Regulated Data-Free Knowledge Amalgamation for Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Prashanth Vijayaraghavan, Hongzhi Wang, Luyao Shi, Tyler Baldwin, David Beymer, Ehsan Degan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Self-Regulated Data-Free Knowledge Amalgamation for Text Classification(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, data-free</a></li>
<li><strong>Abstract: </strong>Recently, there has been a growing availability of pre-trained text models on various model repositories. These models greatly reduce the cost of training new models from scratch as they can be fine-tuned for specific tasks or trained on large datasets. However, these datasets may not be publicly accessible due to the privacy, security, or intellectual property issues. In this paper, we aim to develop a lightweight student network that can learn from multiple teacher models without accessing their original training data. Hence, we investigate Data-Free Knowledge Amalgamation (DFKA), a knowledge-transfer task that combines insights from multiple pre-trained teacher models and transfers them effectively to a compact student network. To accomplish this, we propose STRATANET, a modeling framework comprising: (a) a steerable data generator that produces text data tailored to each teacher and (b) an amalgamation module that implements a self-regulative strategy using confidence estimates from the teachers' different layers to selectively integrate their knowledge and train a versatile student. We evaluate our method on three benchmark text classification datasets with varying labels or domains. Empirically, we demonstrate that the student model learned using our STRATANET outperforms several baselines significantly under data-driven and data-free constraints.</li>
</ul>

<h3>Title: Title:
          CrisisSense-LLM: Instruction Fine-Tuned Large Language Model for Multi-label Social Media Text Classification in Disaster Informatics</h3>
<ul>
<li><strong>Authors: </strong>Kai Yin, Chengkai Liu, Ali Mostafavi, Xia Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          CrisisSense-LLM: Instruction Fine-Tuned Large Language Model for Multi-label Social Media Text Classification in Disaster Informatics(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In the field of crisis/disaster informatics, social media is increasingly being used for improving situational awareness to inform response and relief efforts. Efficient and accurate text classification tools have been a focal area of investigation in crisis informatics. However, current methods mostly rely on single-label text classification models, which fails to capture different insights embedded in dynamic and multifaceted disaster-related social media data. This study introduces a novel approach to disaster text classification by enhancing a pre-trained Large Language Model (LLM) through instruction fine-tuning targeted for multi-label classification of disaster-related tweets. Our methodology involves creating a comprehensive instruction dataset from disaster-related tweets, which is then used to fine-tune an open-source LLM, thereby embedding it with disaster-specific knowledge. This fine-tuned model can classify multiple aspects of disaster-related information simultaneously, such as the type of event, informativeness, and involvement of human aid, significantly improving the utility of social media data for situational awareness in disasters. The results demonstrate that this approach enhances the categorization of critical information from social media posts, thereby facilitating a more effective deployment for situational awareness during emergencies. This research paves the way for more advanced, adaptable, and robust disaster management tools, leveraging the capabilities of LLMs to improve real-time situational awareness and response strategies in disaster scenarios.</li>
</ul>

<h3>Title: Title:
          Twin-Merging: Dynamic Integration of Modular Expertise in Model Merging</h3>
<ul>
<li><strong>Authors: </strong>Zhenyi Lu, Chenghao Fan, Wei Wei, Xiaoye Qu, Dangyang Chen, Yu Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Twin-Merging: Dynamic Integration of Modular Expertise in Model Merging(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In the era of large language models, model merging is a promising way to combine multiple task-specific models into a single multitask model without extra training. However, two challenges remain: (a) interference between different models and (b) heterogeneous data during testing. Traditional model merging methods often show significant performance gaps compared to fine-tuned models due to these issues. Additionally, a one-size-fits-all model lacks flexibility for diverse test data, leading to performance degradation. We show that both shared and exclusive task-specific knowledge are crucial for merging performance, but directly merging exclusive knowledge hinders overall performance. In view of this, we propose Twin-Merging, a method that encompasses two principal stages: (1) modularizing knowledge into shared and exclusive components, with compression to reduce redundancy and enhance efficiency; (2) dynamically merging shared and task-specific knowledge based on the input. This approach narrows the performance gap between merged and fine-tuned models and improves adaptability to heterogeneous data. Extensive experiments on $12$ datasets for both discriminative and generative tasks demonstrate the effectiveness of our method, showing an average improvement of $28.34\%$ in absolute normalized score for discriminative tasks and even surpassing the fine-tuned upper bound on the generative tasks. (Our implementation is available in this https URL.)</li>
</ul>

<h3>Title: Title:
          On Giant's Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion</h3>
<ul>
<li><strong>Authors: </strong>Chenghao Fan, Zhenyi Lu, Wei Wei, Jie Tian, Xiaoye Qu, Dangyang Chen, Yu Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          On Giant's Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Efficient fine-tuning of large language models for task-specific applications is imperative, yet the vast number of parameters in these models makes their training increasingly challenging. Despite numerous proposals for effective methods, a substantial memory overhead remains for gradient computations during updates. \thm{Can we fine-tune a series of task-specific small models and transfer their knowledge directly to a much larger model without additional training?} In this paper, we explore weak-to-strong specialization using logit arithmetic, facilitating a direct answer to this question. Existing weak-to-strong methods often employ a static knowledge transfer ratio and a single small model for transferring complex knowledge, which leads to suboptimal performance. % To address this, To surmount these limitations, we propose a dynamic logit fusion approach that works with a series of task-specific small models, each specialized in a different task. This method adaptively allocates weights among these models at each decoding step, learning the weights through Kullback-Leibler divergence constrained optimization problems. We conduct extensive experiments across various benchmarks in both single-task and multi-task settings, achieving leading results. By transferring expertise from the 7B model to the 13B model, our method closes the performance gap by 96.4\% in single-task scenarios and by 86.3\% in multi-task scenarios compared to full fine-tuning of the 13B model. Notably, we achieve surpassing performance on unseen tasks. Moreover, we further demonstrate that our method can effortlessly integrate in-context learning for single tasks and task arithmetic for multi-task scenarios. (Our implementation is available in this https URL.)</li>
</ul>

<h3>Title: Title:
          Blockchain for Academic Integrity: Developing the Blockchain Academic Credential Interoperability Protocol (BACIP)</h3>
<ul>
<li><strong>Authors: </strong>Juan A. Berrios Moya</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Blockchain for Academic Integrity: Developing the Blockchain Academic Credential Interoperability Protocol (BACIP)(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust</a></li>
<li><strong>Abstract: </strong>This research introduces the Blockchain Academic Credential Interoperability Protocol (BACIP), designed to significantly enhance the security, privacy, and interoperability of verifying academic credentials globally, addressing the widespread issue of academic fraud. BACIP integrates dual blockchain architecture, smart contracts, and zero-knowledge proofs to offer a scalable and transparent framework aimed at reducing fraud and improving the mobility and opportunities for students and professionals worldwide. The research methodology adopts a mixed-methods approach, involving a rigorous review of pertinent literature and systematic integration of advanced technological components. This includes both qualitative and quantitative analyses that underpin the development of a universally compatible system. Preliminary evaluations suggest that BACIP could enhance verification efficiency and bolster security against tampering and unauthorized access. While the theoretical framework and practical implementations have laid a solid foundation, the protocol's real-world efficacy awaits empirical validation in a production environment. Future research will focus on deploying a prototype, establishing robust validation policies, and defining precise testing parameters. This critical phase is indispensable for a thorough assessment of BACIP's operational robustness and its compliance with international educational standards. This work contributes significantly to the academic field by proposing a robust model for managing and safeguarding academic credentials, thus laying a strong foundation for further innovation in credential verification using blockchain technology.</li>
</ul>

<h3>Title: Title:
          Duplicate Detection with GenAI</h3>
<ul>
<li><strong>Authors: </strong>Ian Ormesher</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DB, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Duplicate Detection with GenAI(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Customer data is often stored as records in Customer Relations Management systems (CRMs). Data which is manually entered into such systems by one of more users over time leads to data replication, partial duplication or fuzzy duplication. This in turn means that there no longer a single source of truth for customers, contacts, accounts, etc. Downstream business processes become increasing complex and contrived without a unique mapping between a record in a CRM and the target customer. Current methods to detect and de-duplicate records use traditional Natural Language Processing techniques known as Entity Matching. In this paper we show how using the latest advancements in Large Language Models and Generative AI can vastly improve the identification and repair of duplicated records. On common benchmark datasets we find an improvement in the accuracy of data de-duplication rates from 30 percent using NLP techniques to almost 60 percent using our proposed method.</li>
</ul>

<h3>Title: Title:
          JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ze Wang, Zekun Wu, Xin Guan, Michael Thaler, Adriano Koshiyama, Skylar Lu, Sachin Beepath, Ediz Ertekin Jr., Maria Perez-Ortiz</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a novel framework for benchmarking hierarchical gender hiring bias in Large Language Models (LLMs) for resume scoring, revealing significant issues of reverse bias and overdebiasing. Our contributions are fourfold: First, we introduce a framework using a real, anonymized resume dataset from the Healthcare, Finance, and Construction industries, meticulously used to avoid confounding factors. It evaluates gender hiring biases across hierarchical levels, including Level bias, Spread bias, Taste-based bias, and Statistical bias. This framework can be generalized to other social traits and tasks easily. Second, we propose novel statistical and computational hiring bias metrics based on a counterfactual approach, including Rank After Scoring (RAS), Rank-based Impact Ratio, Permutation Test-Based Metrics, and Fixed Effects Model-based Metrics. These metrics, rooted in labor economics, NLP, and law, enable holistic evaluation of hiring biases. Third, we analyze hiring biases in ten state-of-the-art LLMs. Six out of ten LLMs show significant biases against males in healthcare and finance. An industry-effect regression reveals that the healthcare industry is the most biased against males. GPT-4o and GPT-3.5 are the most biased models, showing significant bias in all three industries. Conversely, Gemini-1.5-Pro, Llama3-8b-Instruct, and Llama3-70b-Instruct are the least biased. The hiring bias of all LLMs, except for Llama3-8b-Instruct and Claude-3-Sonnet, remains consistent regardless of random expansion or reduction of resume content. Finally, we offer a user-friendly demo to facilitate adoption and practical application of the framework.</li>
</ul>

<h3>Title: Title:
          SegHist: A General Segmentation-based Framework for Chinese Historical Document Text Line Detection</h3>
<ul>
<li><strong>Authors: </strong>Xingjian Hu, Baole Wei, Liangcai Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          SegHist: A General Segmentation-based Framework for Chinese Historical Document Text Line Detection(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Text line detection is a key task in historical document analysis facing many challenges of arbitrary-shaped text lines, dense texts, and text lines with high aspect ratios, etc. In this paper, we propose a general framework for historical document text detection (SegHist), enabling existing segmentation-based text detection methods to effectively address the challenges, especially text lines with high aspect ratios. Integrating the SegHist framework with the commonly used method DB++, we develop DB-SegHist. This approach achieves \ac{SOTA} on the \ac{CHDAC}, MTHv2, and competitive results on \ac{HDRC} datasets, with a significant improvement of 1.19\% on the most challenging \ac{CHDAC} dataset which features more text lines with high aspect ratios. Moreover, our method attains \ac{SOTA} on rotated MTHv2 and rotated \ac{HDRC}, demonstrating its rotational robustness. The code is available at this https URL.</li>
</ul>

<h3>Title: Title:
          Near-Lossless Acceleration of Long Context LLM Inference with Adaptive Structured Sparse Attention</h3>
<ul>
<li><strong>Authors: </strong>Qianchao Zhu, Jiangfei Duan, Chang Chen, Siran Liu, Xiuhong Li, Guanyu Feng, Xin Lv, Huanqi Cao, Xiao Chuanfu, Xingcheng Zhang, Dahua Lin, Chao Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Near-Lossless Acceleration of Long Context LLM Inference with Adaptive Structured Sparse Attention(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) now support extremely long context windows, but the quadratic complexity of vanilla attention results in significantly long Time-to-First-Token (TTFT) latency. Existing approaches to address this complexity require additional pretraining or finetuning, and often sacrifice model accuracy. In this paper, we first provide both theoretical and empirical foundations for near-lossless sparse attention. We find dynamically capturing head-specific sparse patterns at runtime with low overhead is crucial. To address this, we propose SampleAttention, an adaptive structured and near-lossless sparse attention. Leveraging observed significant sparse patterns, SampleAttention attends to a fixed percentage of adjacent tokens to capture local window patterns, and employs a two-stage query-guided key-value filtering approach, which adaptively select a minimum set of key-values with low overhead, to capture column stripe patterns. Comprehensive evaluations show that SampleAttention can seamlessly replace vanilla attention in off-the-shelf LLMs with nearly no accuracy loss, and reduces TTFT by up to $2.42\times$ compared with FlashAttention.</li>
</ul>

<h3>Title: Title:
          A Flexible Cryptographic Infrastructure for High-security SDR-based Systems</h3>
<ul>
<li><strong>Authors: </strong>Peter Hillmann, Björn Stelte</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.NI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          A Flexible Cryptographic Infrastructure for High-security SDR-based Systems(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Military software defined radio (SDR) systems are a major factor in future network-centric operations due to their flexibility and support for more capable radio communications systems. The inherent nature of software-based systems requires a more complex auxiliary infrastructure and multiple independent levels of security compared with typical systems: Secure booting of the SDR device, cryptographically signed software, real time operating platform software as well as radio applications. This technology raises new challenges with respect to the management. The largest impact on SDR deployments is due to the auxiliary cryptographic infrastructure for the security of the software life cycle and the cyclic update of the keys. Compared to conventional radio devices, the SDR system with the cryptographic infrastructure described in this paper reaches a higher security level and is more flexible. The advantage is the possibility to deploy trunked radio system and further waveforms, such as coalition wideband, which will be standardized in the future. Also it is possible to update cryptographic mechanisms. In this work, we analyze the requirements for a high secure SDR deployment and model the life cycle of the components of a deployed SDR node based on the Joint Program Executive Office (JPEO) Software Communication Architecture (SCA).</li>
</ul>

<h3>Title: Title:
          Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction</h3>
<ul>
<li><strong>Authors: </strong>Yuncheng Hua, Yujin Huang, Shuo Huang, Tao Feng, Lizhen Qu, Chris Bain, Richard Bassed, Gholamreza Haffari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper tackles the task of emotion-cause pair extraction in the unsupervised domain adaptation setting. The problem is challenging as the distributions of the events causing emotions in target domains are dramatically different than those in source domains, despite the distributions of emotional expressions between domains are overlapped. Inspired by causal discovery, we propose a novel deep latent model in the variational autoencoder (VAE) framework, which not only captures the underlying latent structures of data but also utilizes the easily transferable knowledge of emotions as the bridge to link the distributions of events in different domains. To facilitate knowledge transfer across domains, we also propose a novel variational posterior regularization technique to disentangle the latent representations of emotions from those of events in order to mitigate the damage caused by the spurious correlations related to the events in source domains. Through extensive experiments, we demonstrate that our model outperforms the strongest baseline by approximately 11.05% on a Chinese benchmark and 2.45% on a English benchmark in terms of weighted-average F1 score. The source code will be publicly available upon acceptance.</li>
</ul>

<h3>Title: Title:
          Simple Cracking of (Noise-Based) Dynamic Watermarking in Smart Grids</h3>
<ul>
<li><strong>Authors: </strong>Mehmet Yildirim, Nasir Kenarangui, Robert Balog, Laszlo B. Kish, Chanan Singh</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Simple Cracking of (Noise-Based) Dynamic Watermarking in Smart Grids(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, watermark</a></li>
<li><strong>Abstract: </strong>Previous research employing a conceptual approach with a digital twin has demonstrated that (noise-based) dynamic watermarking is incapable of providing unconditional security in smart electrical grid systems. However, the implementation of digital twins can be prohibitively costly or infeasible due to limited available data on critical infrastructure. In this study, we first analyze the spectral properties of dynamic watermarking and its associated protocol. Subsequently, we present a straightforward attack inspired by the digital twin method, which extracts and utilizes the grid noises and completely breaches the security of dynamic watermarking without requiring knowledge of the private watermarking signal. The attacker can fully expose the grid while evading detection by the controller. Our findings indicate that in the absence of secure and authenticated communications, dynamic watermarking offers neither conditional nor unconditional security. Conversely, when communication lines, sensors, and communicators are equipped with tamper-resistant and secure/authenticated links, dynamic watermarking becomes redundant for grid security.</li>
</ul>

<h3>Title: Title:
          Secure Combination of Untrusted Time information Based on Optimized Dempster-Shafer Theory</h3>
<ul>
<li><strong>Authors: </strong>Yang Li, Yujie Luo, Yichen Zhang, Ao Sun, Wei Huang, Shuai Zhang, Tao Zhang, Chuang Zhou, Li Ma, Jie Yang, Mei Wu, Heng Wang, Yan Pan, Yun Shao, Xing Chen, Ziyang Chen, Song Yu, Hong Guo, Bingjie Xu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Secure Combination of Untrusted Time information Based on Optimized Dempster-Shafer Theory(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Secure precision time synchronization is important for applications of Cyber-Physical Systems. However, several attacks, especially the Time Delay Attack (TDA), deteriorates the performance of time synchronization system seriously. Multiple paths scheme is thought as an effective security countermeasure to decrease the influence of TDA. However, the effective secure combination algorithm is still missed for precision time synchronization. In this paper, a secure combination algorithm based on Dempster-Shafer theory is proposed for multiple paths method. Special optimizations are done for the combination algorithm to solve the potential problems due to untrusted evidence. Theoretical simulation shows that the proposed algorithm works much better than Fault Tolerant Algorithm (FTA) and the attack detection method based on single path. And experimental demonstration proves the feasibility and superiority of the proposed algorithm, where the time stability with 27.97 ps, 1.57 ps, and 1.12 ps at average time 1s, 10s, 100s is achieved under TDA and local clock jump. The proposed algorithm can be used to improve the security and resilience of many importance synchronization protocol, such as NTP, PTP, and TWFTT.</li>
</ul>

<h3>Title: Title:
          Dr.E Bridges Graphs with Large Language Models through Words</h3>
<ul>
<li><strong>Authors: </strong>Zipeng Liu, Likang Wu, Ming He, Zhong Guan, Hongke Zhao, Nan Feng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Dr.E Bridges Graphs with Large Language Models through Words(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Significant efforts have been directed toward integrating powerful Large Language Models (LLMs) with diverse modalities, particularly focusing on the fusion of vision, language, and audio data. However, the graph-structured data, inherently rich in structural and domain-specific knowledge, have not yet been gracefully adapted to LLMs. Existing methods either describe the graph with raw text, suffering the loss of graph structural information, or feed Graph Neural Network (GNN) embeddings directly into LLM at the cost of losing semantic representation. To bridge this gap, we introduce an innovative, end-to-end modality-aligning framework, equipped with a pretrained Dual-Residual Vector Quantized-Variational AutoEncoder (Dr.E). This framework is specifically designed to facilitate token-level alignment with LLMs, enabling an effective translation of the intrinsic `language' of graphs into comprehensible natural language. Our experimental evaluations on standard GNN node classification tasks demonstrate competitive performance against other state-of-the-art approaches. Additionally, our framework ensures interpretability, efficiency, and robustness, with its effectiveness further validated under both fine-tuning and few-shot settings. This study marks the first successful endeavor to achieve token-level alignment between GNNs and LLMs.</li>
</ul>

<h3>Title: Title:
          Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Haochen Liu, Song Wang, Chen Chen, Jundong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Few-shot Knowledge Graph (KG) Relational Reasoning aims to predict unseen triplets (i.e., query triplets) for rare relations in KGs, given only several triplets of these relations as references (i.e., support triplets). This task has gained significant traction due to the widespread use of knowledge graphs in various natural language processing applications. Previous approaches have utilized meta-training methods and manually constructed meta-relation sets to tackle this task. Recent efforts have focused on edge-mask-based methods, which exploit the structure of the contextualized graphs of target triplets (i.e., a subgraph containing relevant triplets in the KG). However, existing edge-mask-based methods have limitations in extracting insufficient information from KG and are highly influenced by spurious information in KG. To overcome these challenges, we propose SAFER (Subgraph Adaptation for Few-shot Relational Reasoning), a novel approach that effectively adapts the information in contextualized graphs to various subgraphs generated from support and query triplets to perform the prediction. Specifically, SAFER enables the extraction of more comprehensive information from support triplets while minimizing the impact of spurious information when predicting query triplets. Experimental results on three prevalent datasets demonstrate the superiority of our proposed framework SAFER.</li>
</ul>

<h3>Title: Title:
          System Description for the Displace Speaker Diarization Challenge 2023</h3>
<ul>
<li><strong>Authors: </strong>Ali Aliyev</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          System Description for the Displace Speaker Diarization Challenge 2023(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper describes our solution for the Diarization of Speaker and Language in Conversational Environments Challenge (Displace 2023). We used a combination of VAD for finding segfments with speech, Resnet architecture based CNN for feature extraction from these segments, and spectral clustering for features clustering. Even though it was not trained with using Hindi, the described algorithm achieves the following metrics: DER 27. 1% and DER 27. 4%, on the development and phase-1 evaluation parts of the dataset, respectively.</li>
</ul>

<h3>Title: Title:
          Steering Without Side Effects: Improving Post-Deployment Control of Language Models</h3>
<ul>
<li><strong>Authors: </strong>Asa Cooper Stickland, Alexander Lyzhov, Jacob Pfau, Salsabila Mahdi, Samuel R. Bowman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Steering Without Side Effects: Improving Post-Deployment Control of Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Language models (LMs) have been shown to behave unexpectedly post-deployment. For example, new jailbreaks continually arise, allowing model misuse, despite extensive red-teaming and adversarial training from developers. Given most model queries are unproblematic and frequent retraining results in unstable user experience, methods for mitigation of worst-case behavior should be targeted. One such method is classifying inputs as potentially problematic, then selectively applying steering vectors on these problematic inputs, i.e. adding particular vectors to model hidden states. However, steering vectors can also negatively affect model performance, which will be an issue on cases where the classifier was incorrect. We present KL-then-steer (KTS), a technique that decreases the side effects of steering while retaining its benefits, by first training a model to minimize Kullback-Leibler (KL) divergence between a steered and unsteered model on benign inputs, then steering the model that has undergone this training. Our best method prevents 44% of jailbreak attacks compared to the original Llama-2-chat-7B model while maintaining helpfulness (as measured by MT-Bench) on benign requests almost on par with the original LM. To demonstrate the generality and transferability of our method beyond jailbreaks, we show that our KTS model can be steered to reduce bias towards user-suggested answers on TruthfulQA. Code is available: this https URL.</li>
</ul>

<h3>Title: Title:
          Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Yili Wang, Yixin Liu, Xu Shen, Chenyu Li, Kaize Ding, Rui Miao, Ying Wang, Shirui Pan, Xin Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>To build safe and reliable graph machine learning systems, unsupervised graph-level anomaly detection (GLAD) and unsupervised graph-level out-of-distribution (OOD) detection (GLOD) have received significant attention in recent years. Though those two lines of research indeed share the same objective, they have been studied independently in the community due to distinct evaluation setups, creating a gap that hinders the application and evaluation of methods from one to the other. To bridge the gap, in this work, we present a Unified Benchmark for unsupervised Graph-level OOD and anomaly Detection (our method), a comprehensive evaluation framework that unifies GLAD and GLOD under the concept of generalized graph-level OOD detection. Our benchmark encompasses 35 datasets spanning four practical anomaly and OOD detection scenarios, facilitating the comparison of 16 representative GLAD/GLOD methods. We conduct multi-dimensional analyses to explore the effectiveness, generalizability, robustness, and efficiency of existing methods, shedding light on their strengths and limitations. Furthermore, we provide an open-source codebase (this https URL) of our method to foster reproducible research and outline potential directions for future investigations based on our insights.</li>
</ul>

<h3>Title: Title:
          Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization</h3>
<ul>
<li><strong>Authors: </strong>Sungbin Shin, Wonpyo Park, Jaeho Lee, Namhoon Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work suggests fundamentally rethinking the current practice of pruning large language models (LLMs). The way it is done is by divide and conquer: split the model into submodels, sequentially prune them, and reconstruct predictions of the dense counterparts on small calibration data one at a time; the final model is obtained simply by putting the resulting sparse submodels together. While this approach enables pruning under memory constraints, it generates high reconstruction errors. In this work, we first present an array of reconstruction techniques that can significantly reduce this error by more than $90\%$. Unwittingly, however, we discover that minimizing reconstruction error is not always ideal and can overfit the given calibration data, resulting in rather increased language perplexity and poor performance at downstream tasks. We find out that a strategy of self-generating calibration data can mitigate this trade-off between reconstruction and generalization, suggesting new directions in the presence of both benefits and pitfalls of reconstruction for pruning LLMs.</li>
</ul>

<h3>Title: Title:
          Data Efficient Evaluation of Large Language Models and Text-to-Image Models via Adaptive Sampling</h3>
<ul>
<li><strong>Authors: </strong>Cong Xu, Gayathri Saranathan, Mahammad Parwez Alam, Arpit Shah, James Lim, Soon Yee Wong, Foltin Martin, Suparna Bhattacharya</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Data Efficient Evaluation of Large Language Models and Text-to-Image Models via Adaptive Sampling(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Evaluating LLMs and text-to-image models is a computationally intensive task often overlooked. Efficient evaluation is crucial for understanding the diverse capabilities of these models and enabling comparisons across a growing number of new models and benchmarks. To address this, we introduce SubLIME, a data-efficient evaluation framework that employs adaptive sampling techniques, such as clustering and quality-based methods, to create representative subsets of benchmarks. Our approach ensures statistically aligned model rankings compared to full datasets, evidenced by high Pearson correlation coefficients. Empirical analysis across six NLP benchmarks reveals that: (1) quality-based sampling consistently achieves strong correlations (0.85 to 0.95) with full datasets at a 10\% sampling rate such as Quality SE and Quality CPD (2) clustering methods excel in specific benchmarks such as MMLU (3) no single method universally outperforms others across all metrics. Extending this framework, we leverage the HEIM leaderboard to cover 25 text-to-image models on 17 different benchmarks. SubLIME dynamically selects the optimal technique for each benchmark, significantly reducing evaluation costs while preserving ranking integrity and score distribution. Notably, a minimal sampling rate of 1% proves effective for benchmarks like MMLU. Additionally, we demonstrate that employing difficulty-based sampling to target more challenging benchmark segments enhances model differentiation with broader score distributions. We also combine semantic search, tool use, and GPT-4 review to identify redundancy across benchmarks within specific LLM categories, such as coding benchmarks. This allows us to further reduce the number of samples needed to maintain targeted rank preservation. Overall, SubLIME offers a versatile and cost-effective solution for the robust evaluation of LLMs and text-to-image models.</li>
</ul>

<h3>Title: Title:
          Supersonic OT: Fast Unconditionally Secure Oblivious Transfer</h3>
<ul>
<li><strong>Authors: </strong>Aydin Abadi, Yvo Desmedt</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Supersonic OT: Fast Unconditionally Secure Oblivious Transfer(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, federate</a></li>
<li><strong>Abstract: </strong>Oblivious Transfer (OT) is a fundamental cryptographic protocol with applications in secure Multi-Party Computation, Federated Learning, and Private Set Intersection. With the advent of quantum computing, it is crucial to develop unconditionally secure core primitives like OT to ensure their continued security in the post-quantum era. Despite over four decades since OT's introduction, the literature has predominantly relied on computational assumptions, except in cases using unconventional methods like noisy channels or a fully trusted party. Introducing "Supersonic OT", a highly efficient and unconditionally secure OT scheme that avoids public-key-based primitives, we offer an alternative to traditional approaches. Supersonic OT enables a receiver to obtain a response of size O(1). Its simple (yet non-trivial) design facilitates easy security analysis and implementation. The protocol employs a basic secret-sharing scheme, controlled swaps, the one-time pad, and a third-party helper who may be corrupted by a semi-honest adversary. Our implementation and runtime analysis indicate that a single instance of Supersonic OT completes in 0.35 milliseconds, making it up to 2000 times faster than the state-of-the-art base OT.</li>
</ul>

<h3>Title: Title:
          Geneverse: A collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Liu, Yijia Xiao, Xiao Luo, Hua Xu, W. Jim Zheng, Hongyu Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Geneverse: A collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The applications of large language models (LLMs) are promising for biomedical and healthcare research. Despite the availability of open-source LLMs trained using a wide range of biomedical data, current research on the applications of LLMs to genomics and proteomics is still limited. To fill this gap, we propose a collection of finetuned LLMs and multimodal LLMs (MLLMs), known as Geneverse, for three novel tasks in genomic and proteomic research. The models in Geneverse are trained and evaluated based on domain-specific datasets, and we use advanced parameter-efficient finetuning techniques to achieve the model adaptation for tasks including the generation of descriptions for gene functions, protein function inference from its structure, and marker gene selection from spatial transcriptomic data. We demonstrate that adapted LLMs and MLLMs perform well for these tasks and may outperform closed-source large-scale models based on our evaluations focusing on both truthfulness and structural correctness. All of the training strategies and base models we used are freely accessible.</li>
</ul>

<h3>Title: Title:
          Open-Vocabulary Temporal Action Localization using Multimodal Guidance</h3>
<ul>
<li><strong>Authors: </strong>Akshita Gupta, Aditya Arora, Sanath Narayan, Salman Khan, Fahad Shahbaz Khan, Graham W. Taylor</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Open-Vocabulary Temporal Action Localization using Multimodal Guidance(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Open-Vocabulary Temporal Action Localization (OVTAL) enables a model to recognize any desired action category in videos without the need to explicitly curate training data for all categories. However, this flexibility poses significant challenges, as the model must recognize not only the action categories seen during training but also novel categories specified at inference. Unlike standard temporal action localization, where training and test categories are predetermined, OVTAL requires understanding contextual cues that reveal the semantics of novel categories. To address these challenges, we introduce OVFormer, a novel open-vocabulary framework extending ActionFormer with three key contributions. First, we employ task-specific prompts as input to a large language model to obtain rich class-specific descriptions for action categories. Second, we introduce a cross-attention mechanism to learn the alignment between class representations and frame-level video features, facilitating the multimodal guided features. Third, we propose a two-stage training strategy which includes training with a larger vocabulary dataset and finetuning to downstream data to generalize to novel categories. OVFormer extends existing TAL methods to open-vocabulary settings. Comprehensive evaluations on the THUMOS14 and ActivityNet-1.3 benchmarks demonstrate the effectiveness of our method. Code and pretrained models will be publicly released.</li>
</ul>

<h3>Title: Title:
          SAIL: Self-Improving Efficient Online Alignment of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mucong Ding, Souradip Chakraborty, Vibhu Agrawal, Zora Che, Alec Koppel, Mengdi Wang, Amrit Bedi, Furong Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          SAIL: Self-Improving Efficient Online Alignment of Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) is a key method for aligning large language models (LLMs) with human preferences. However, current offline alignment approaches like DPO, IPO, and SLiC rely heavily on fixed preference datasets, which can lead to sub-optimal performance. On the other hand, recent literature has focused on designing online RLHF methods but still lacks a unified conceptual formulation and suffers from distribution shift issues. To address this, we establish that online LLM alignment is underpinned by bilevel optimization. By reducing this formulation to an efficient single-level first-order method (using the reward-policy equivalence), our approach generates new samples and iteratively refines model alignment by exploring responses and regulating preference labels. In doing so, we permit alignment methods to operate in an online and self-improving manner, as well as generalize prior online RLHF methods as special cases. Compared to state-of-the-art iterative RLHF methods, our approach significantly improves alignment performance on open-sourced datasets with minimal computational overhead.</li>
</ul>

<h3>Title: Title:
          Robust Reinforcement Learning from Corrupted Human Feedback</h3>
<ul>
<li><strong>Authors: </strong>Alexander Bukharin, Ilgee Hong, Haoming Jiang, Qingru Zhang, Zixuan Zhang, Tuo Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Robust Reinforcement Learning from Corrupted Human Feedback(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning from human feedback (RLHF) provides a principled framework for aligning AI systems with human preference data. For various reasons, e.g., personal bias, context ambiguity, lack of training, etc, human annotators may give incorrect or inconsistent preference labels. To tackle this challenge, we propose a robust RLHF approach -- $R^3M$, which models the potentially corrupted preference label as sparse outliers. Accordingly, we formulate the robust reward learning as an $\ell_1$-regularized maximum likelihood estimation problem. Computationally, we develop an efficient alternating optimization algorithm, which only incurs negligible computational overhead compared with the standard RLHF approach. Theoretically, we prove that under proper regularity conditions, $R^3M$ can consistently learn the underlying reward and identify outliers, provided that the number of outlier labels scales sublinearly with the preference sample size. Furthermore, we remark that $R^3M$ is versatile and can be extended to various preference optimization methods, including direct preference optimization (DPO). Our experiments on robotic control and natural language generation with large language models (LLMs) show that $R^3M$ improves robustness of the reward against several types of perturbations to the preference data.</li>
</ul>

<h3>Title: Title:
          Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods</h3>
<ul>
<li><strong>Authors: </strong>Kathleen C. Fraser, Hillary Dawkins, Svetlana Kiritchenko</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have advanced to a point that even humans have difficulty discerning whether a text was generated by another human, or by a computer. However, knowing whether a text was produced by human or artificial intelligence (AI) is important to determining its trustworthiness, and has applications in many domains including detecting fraud and academic dishonesty, as well as combating the spread of misinformation and political propaganda. The task of AI-generated text (AIGT) detection is therefore both very challenging, and highly critical. In this survey, we summarize state-of-the art approaches to AIGT detection, including watermarking, statistical and stylistic analysis, and machine learning classification. We also provide information about existing datasets for this task. Synthesizing the research findings, we aim to provide insight into the salient factors that combine to determine how "detectable" AIGT text is under different scenarios, and to make practical recommendations for future work towards this significant technical and societal challenge.</li>
</ul>

<h3>Title: Title:
          Ten Years of ZMap</h3>
<ul>
<li><strong>Authors: </strong>Zakir Durumeric, David Adrian, Phillip Stephens, Eric Wustrow, J. Alex Halderman</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Ten Years of ZMap(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Since ZMap's debut in 2013, networking and security researchers have used the open-source scanner to write hundreds of research papers that study Internet behavior. In addition, ZMap powers much of the attack-surface management and security ratings industries, and more than a dozen security companies have built products on top of ZMap. Behind the scenes, much of ZMap's behavior - ranging from its pseudorandom IP generation to its packet construction - has quietly evolved as we have learned more about how to scan the Internet. In this work, we quantify ZMap's adoption over the ten years since its release, describe its modern behavior (and the measurements that motivated those changes), and offer lessons from releasing and maintaining ZMap.</li>
</ul>

<h3>Title: Title:
          TinyStyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Zachary Horvitz, Ajay Patel, Kanishk Singh, Chris Callison-Burch, Kathleen McKeown, Zhou Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          TinyStyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The goal of text style transfer is to transform the style of texts while preserving their original meaning, often with only a few examples of the target style. Existing style transfer methods generally rely on the few-shot capabilities of large language models or on complex controllable text generation approaches that are inefficient and underperform on fluency metrics. We introduce TinyStyler, a lightweight but effective approach, which leverages a small language model (800M params) and pre-trained authorship embeddings to perform efficient, few-shot text style transfer. We evaluate on the challenging task of authorship style transfer and find TinyStyler outperforms strong approaches such as GPT-4. We also evaluate TinyStyler's ability to perform text attribute style transfer (formal $\leftrightarrow$ informal) with automatic and human evaluations and find that the approach outperforms recent controllable text generation methods. Our model has been made publicly available at this https URL .</li>
</ul>

<h3>Title: Title:
          News Deja Vu: Connecting Past and Present with Semantic Search</h3>
<ul>
<li><strong>Authors: </strong>Brevin Franklin, Emily Silcock, Abhishek Arora, Tom Bryan, Melissa Dell</a></li>
<li><strong>Subjects: </strong>cs.CL, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          News Deja Vu: Connecting Past and Present with Semantic Search(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Social scientists and the general public often analyze contemporary events by drawing parallels with the past, a process complicated by the vast, noisy, and unstructured nature of historical texts. For example, hundreds of millions of page scans from historical newspapers have been noisily transcribed. Traditional sparse methods for searching for relevant material in these vast corpora, e.g., with keywords, can be brittle given complex vocabularies and OCR noise. This study introduces News Deja Vu, a novel semantic search tool that leverages transformer large language models and a bi-encoder approach to identify historical news articles that are most similar to modern news queries. News Deja Vu first recognizes and masks entities, in order to focus on broader parallels rather than the specific named entities being discussed. Then, a contrastively trained, lightweight bi-encoder retrieves historical articles that are most similar semantically to a modern query, illustrating how phenomena that might seem unique to the present have varied historical precedents. Aimed at social scientists, the user-friendly News Deja Vu package is designed to be accessible for those who lack extensive familiarity with deep learning. It works with large text datasets, and we show how it can be deployed to a massive scale corpus of historical, open-source news articles. While human expertise remains important for drawing deeper insights, News Deja Vu provides a powerful tool for exploring parallels in how people have perceived past and present.</li>
</ul>

<h3>Title: Title:
          DiVerify: Diversifying Identity Verification in Next-Generation Software Signing</h3>
<ul>
<li><strong>Authors: </strong>Chinenye L. Okafor, James C. Davis, Santiago Torres-Arias</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          DiVerify: Diversifying Identity Verification in Next-Generation Software Signing(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Code signing enables software developers to digitally sign their code using cryptographic keys, thereby associating the code to their identity. This allows users to verify the authenticity and integrity of the software, ensuring it has not been tampered with. Next-generation software signing such as Sigstore and OpenPubKey simplify code signing by providing streamlined mechanisms to verify and link signer identities to the public key. However, their designs have vulnerabilities: reliance on an identity provider introduces a single point of failure, and the failure to follow the principle of least privilege on the client side increases security risks. We introduce Diverse Identity Verification (DiVerify) scheme, which strengthens the security guarantees of next-generation software signing by leveraging threshold identity validations and scope mechanisms. We formalize a general definition of diverse verification scope and how it applies to next-generation software signing solutions, enabling clients to protect themselves from the impact of a compromised identity provider and help identity providers minimize the impact of compromised clients. As proof of concept, we implement DiVerify in the Sigstore ecosystem and evaluate the security improvements. By using fine-grained access control mechanisms and implementing threshold validations over account signing capabilities, we demonstrate that signing tools can protect themselves against threats from compromised identity providers and malicious signing clients.</li>
</ul>

<h3>Title: Title:
          Pareto-Optimal Learning from Preferences with Hidden Context</h3>
<ul>
<li><strong>Authors: </strong>Ryan Boldi, Li Ding, Lee Spector, Scott Niekum</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Pareto-Optimal Learning from Preferences with Hidden Context(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Ensuring AI models align with human values is essential for their safety and functionality. Reinforcement learning from human feedback (RLHF) uses human preferences to achieve this alignment. However, preferences sourced from diverse populations can result in point estimates of human values that may be sub-optimal or unfair to specific groups. We propose Pareto Optimal Preference Learning (POPL), which frames discrepant group preferences as objectives with potential trade-offs, aiming for policies that are Pareto-optimal on the preference dataset. POPL utilizes Lexicase selection, an iterative process to select diverse and Pareto-optimal solutions. Our empirical evaluations demonstrate that POPL surpasses baseline methods in learning sets of reward functions, effectively catering to distinct groups without access to group numbers or membership labels. Furthermore, we illustrate that POPL can serve as a foundation for techniques optimizing specific notions of group fairness, ensuring inclusive and equitable AI model alignment.</li>
</ul>

<h3>Title: Title:
          QuADTool: Attack-Defense-Tree Synthesis, Analysis and Bridge to Verification</h3>
<ul>
<li><strong>Authors: </strong>Florian Dorfhuber, Julia Eisentraut, Jan Kretinsky</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          QuADTool: Attack-Defense-Tree Synthesis, Analysis and Bridge to Verification(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Ranking risks and countermeasures is one of the foremost goals of quantitative security analysis. One of the popular frameworks, used also in industrial practice, for this task are attack-defense trees. Standard quantitative analyses available for attack-defense trees can distinguish likely from unlikely vulnerabilities. We provide a tool that allows for easy synthesis and analysis of those models, also featuring probabilities, costs and time. Furthermore, it provides a variety of interfaces to existing model checkers and analysis tools. Unfortunately, currently available tools rely on precise quantitative inputs (probabilities, timing, or costs of attacks), which are rarely available. Instead, only statistical, imprecise information is typically available, leaving us with probably approximately correct (PAC) estimates of the real quantities. As a part of our tool, we extend the standard analysis techniques so they can handle the PAC input and yield rigorous bounds on the imprecision and uncertainty of the final result of the analysis.</li>
</ul>

<h3>Title: Title:
          MOUNTAINEER: Topology-Driven Visual Analytics for Comparing Local Explanations</h3>
<ul>
<li><strong>Authors: </strong>Parikshit Solunke, Vitoria Guardieiro, Joao Rulff, Peter Xenopoulos, Gromit Yeuk-Yin Chan, Brian Barr, Luis Gustavo Nonato, Claudio Silva</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GR, math.AT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          MOUNTAINEER: Topology-Driven Visual Analytics for Comparing Local Explanations(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>With the increasing use of black-box Machine Learning (ML) techniques in critical applications, there is a growing demand for methods that can provide transparency and accountability for model predictions. As a result, a large number of local explainability methods for black-box models have been developed and popularized. However, machine learning explanations are still hard to evaluate and compare due to the high dimensionality, heterogeneous representations, varying scales, and stochastic nature of some of these methods. Topological Data Analysis (TDA) can be an effective method in this domain since it can be used to transform attributions into uniform graph representations, providing a common ground for comparison across different explanation methods. We present a novel topology-driven visual analytics tool, Mountaineer, that allows ML practitioners to interactively analyze and compare these representations by linking the topological graphs back to the original data distribution, model predictions, and feature attributions. Mountaineer facilitates rapid and iterative exploration of ML explanations, enabling experts to gain deeper insights into the explanation techniques, understand the underlying data distributions, and thus reach well-founded conclusions about model behavior. Furthermore, we demonstrate the utility of Mountaineer through two case studies using real-world data. In the first, we show how Mountaineer enabled us to compare black-box ML explanations and discern regions of and causes of disagreements between different explanations. In the second, we demonstrate how the tool can be used to compare and understand ML models themselves. Finally, we conducted interviews with three industry experts to help us evaluate our work.</li>
</ul>

<h3>Title: Title:
          Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding are Both the Problem</h3>
<ul>
<li><strong>Authors: </strong>Sara Court, Micha Elsner</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding are Both the Problem(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work investigates the in-context learning abilities of pretrained large language models (LLMs) when instructed to translate text from a low-resource language into a high-resource language as part of an automated machine translation pipeline. We conduct a set of experiments translating Southern Quechua to Spanish and examine the informativity of various types of information retrieved from a constrained database of digitized pedagogical materials (dictionaries and grammar lessons) and parallel corpora. Using both automatic and human evaluation of model output, we conduct ablation studies that manipulate (1) context type (morpheme translations, grammar descriptions, and corpus examples), (2) retrieval methods (automated vs. manual), and (3) model type. Our results suggest that even relatively small LLMs are capable of utilizing prompt context for zero-shot low-resource translation when provided a minimally sufficient amount of relevant linguistic information. However, the variable effects of prompt type, retrieval method, model type, and language-specific factors highlight the limitations of using even the best LLMs as translation systems for the majority of the world's 7,000+ languages and their speakers.</li>
</ul>

<h3>Title: Title:
          Benchmarking Uncertainty Quantification Methods for Large Language Models with LM-Polygraph</h3>
<ul>
<li><strong>Authors: </strong>Roman Vashurin, Ekaterina Fadeeva, Artem Vazhentsev, Akim Tsvigun, Daniil Vasilev, Rui Xing, Abdelrahman Boda Sadallah, Lyudmila Rvanova, Sergey Petrakov, Alexander Panchenko, Timothy Baldwin, Preslav Nakov, Maxim Panov, Artem Shelmanov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Benchmarking Uncertainty Quantification Methods for Large Language Models with LM-Polygraph(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Uncertainty quantification (UQ) is becoming increasingly recognized as a critical component of applications that rely on machine learning (ML). The rapid proliferation of large language models (LLMs) has stimulated researchers to seek efficient and effective approaches to UQ in text generation tasks, as in addition to their emerging capabilities, these models have introduced new challenges for building safe applications. As with other ML models, LLMs are prone to make incorrect predictions, ``hallucinate'' by fabricating claims, or simply generate low-quality output for a given input. UQ is a key element in dealing with these challenges. However research to date on UQ methods for LLMs has been fragmented, with disparate evaluation methods. In this work, we tackle this issue by introducing a novel benchmark that implements a collection of state-of-the-art UQ baselines, and provides an environment for controllable and consistent evaluation of novel techniques by researchers in various text generation tasks. Our benchmark also supports the assessment of confidence normalization methods in terms of their ability to provide interpretable scores. Using our benchmark, we conduct a large-scale empirical investigation of UQ and normalization techniques across nine tasks and shed light on the most promising approaches.</li>
</ul>

<h3>Title: Title:
          DataFreeShield: Defending Adversarial Attacks without Training Data</h3>
<ul>
<li><strong>Authors: </strong>Hyeyoon Lee, Kanghyun Choi, Dain Kwon, Sunjong Park, Mayoore Selvarasa Jaiswal, Noseong Park, Jonghyun Choi, Jinho Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          DataFreeShield: Defending Adversarial Attacks without Training Data(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, robust, data-free</a></li>
<li><strong>Abstract: </strong>Recent advances in adversarial robustness rely on an abundant set of training data, where using external or additional datasets has become a common setting. However, in real life, the training data is often kept private for security and privacy issues, while only the pretrained weight is available to the public. In such scenarios, existing methods that assume accessibility to the original data become inapplicable. Thus we investigate the pivotal problem of data-free adversarial robustness, where we try to achieve adversarial robustness without accessing any real data. Through a preliminary study, we highlight the severity of the problem by showing that robustness without the original dataset is difficult to achieve, even with similar domain datasets. To address this issue, we propose DataFreeShield, which tackles the problem from two perspectives: surrogate dataset generation and adversarial training using the generated data. Through extensive validation, we show that DataFreeShield outperforms baselines, demonstrating that the proposed method sets the first entirely data-free solution for the adversarial robustness problem.</li>
</ul>

<h3>Title: Title:
          Taming 3DGS: High-Quality Radiance Fields with Limited Resources</h3>
<ul>
<li><strong>Authors: </strong>Saswat Subhajyoti Mallick, Rahul Goel, Bernhard Kerbl, Francisco Vicente Carrasco, Markus Steinberger, Fernando De La Torre</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Taming 3DGS: High-Quality Radiance Fields with Limited Resources(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) has transformed novel-view synthesis with its fast, interpretable, and high-fidelity rendering. However, its resource requirements limit its usability. Especially on constrained devices, training performance degrades quickly and often cannot complete due to excessive memory consumption of the model. The method converges with an indefinite number of Gaussians -- many of them redundant -- making rendering unnecessarily slow and preventing its usage in downstream tasks that expect fixed-size inputs. To address these issues, we tackle the challenges of training and rendering 3DGS models on a budget. We use a guided, purely constructive densification process that steers densification toward Gaussians that raise the reconstruction quality. Model size continuously increases in a controlled manner towards an exact budget, using score-based densification of Gaussians with training-time priors that measure their contribution. We further address training speed obstacles: following a careful analysis of 3DGS' original pipeline, we derive faster, numerically equivalent solutions for gradient computation and attribute updates, including an alternative parallelization for efficient backpropagation. We also propose quality-preserving approximations where suitable to reduce training time even further. Taken together, these enhancements yield a robust, scalable solution with reduced training times, lower compute and memory requirements, and high quality. Our evaluation shows that in a budgeted setting, we obtain competitive quality metrics with 3DGS while achieving a 4--5x reduction in both model size and training time. With more generous budgets, our measured quality surpasses theirs. These advances open the door for novel-view synthesis in constrained environments, e.g., mobile devices.</li>
</ul>

<h3>Title: Title:
          TorchSpatial: A Location Encoding Framework and Benchmark for Spatial Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Nemin Wu, Qian Cao, Zhangyu Wang, Zeping Liu, Yanlin Qi, Jielu Zhang, Joshua Ni, Xiaobai Yao, Hongxu Ma, Lan Mu, Stefano Ermon, Tanuja Ganu, Akshay Nambi, Ni Lao, Gengchen Mai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          TorchSpatial: A Location Encoding Framework and Benchmark for Spatial Representation Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Spatial representation learning (SRL) aims at learning general-purpose neural network representations from various types of spatial data (e.g., points, polylines, polygons, networks, images, etc.) in their native formats. Learning good spatial representations is a fundamental problem for various downstream applications such as species distribution modeling, weather forecasting, trajectory generation, geographic question answering, etc. Even though SRL has become the foundation of almost all geospatial artificial intelligence (GeoAI) research, we have not yet seen significant efforts to develop an extensive deep learning framework and benchmark to support SRL model development and evaluation. To fill this gap, we propose TorchSpatial, a learning framework and benchmark for location (point) encoding, which is one of the most fundamental data types of spatial representation learning. TorchSpatial contains three key components: 1) a unified location encoding framework that consolidates 15 commonly recognized location encoders, ensuring scalability and reproducibility of the implementations; 2) the LocBench benchmark tasks encompassing 7 geo-aware image classification and 4 geo-aware image regression datasets; 3) a comprehensive suite of evaluation metrics to quantify geo-aware models' overall performance as well as their geographic bias, with a novel Geo-Bias Score metric. Finally, we provide a detailed analysis and insights into the model performance and geographic bias of different location encoders. We believe TorchSpatial will foster future advancement of spatial representation learning and spatial fairness in GeoAI research. The TorchSpatial model framework, LocBench, and Geo-Bias Score evaluation framework are available at this https URL.</li>
</ul>

<h3>Title: Title:
          Contextual Sprint Classification in Soccer Based on Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Hyunsung Kim, Gun-Hee Joe, Jinsung Yoon, Sang-Ki Ko</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Contextual Sprint Classification in Soccer Based on Deep Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The analysis of high-intensity runs (or sprints) in soccer has long been a topic of interest for sports science researchers and practitioners. In particular, recent studies suggested contextualizing sprints based on their tactical purposes to better understand the physical-tactical requirements of modern match-play. However, they have a limitation in scalability, as human experts have to manually classify hundreds of sprints for every match. To address this challenge, this paper proposes a deep learning framework for automatically classifying sprints in soccer into contextual categories. The proposed model covers the permutation-invariant and sequential nature of multi-agent trajectories in soccer by deploying Set Transformers and a bidirectional GRU. We train the model with category labels made through the collaboration of human annotators and a rule-based classifier. Experimental results show that our model classifies sprints in the test dataset into 15 categories with the accuracy of 77.65%, implying the potential of the proposed framework for facilitating the integrated analysis of soccer sprints at scale.</li>
</ul>

<h3>Title: Title:
          PI-Whisper: An Adaptive and Incremental ASR Framework for Diverse and Evolving Speaker Characteristics</h3>
<ul>
<li><strong>Authors: </strong>Amir Nassereldine, Dancheng Liu, Chenhui Xu, Jinjun Xiong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          PI-Whisper: An Adaptive and Incremental ASR Framework for Diverse and Evolving Speaker Characteristics(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>As edge-based automatic speech recognition (ASR) technologies become increasingly prevalent for the development of intelligent and personalized assistants, three important challenges must be addressed for these resource-constrained ASR models, i.e., adaptivity, incrementality, and inclusivity. We propose a novel ASR framework, PI-Whisper, in this work and show how it can improve an ASR's recognition capabilities adaptively by identifying different speakers' characteristics in real-time, how such an adaption can be performed incrementally without repetitive retraining, and how it can improve the equity and fairness for diverse speaker groups. More impressively, our proposed PI-Whisper framework attains all of these nice properties while still achieving state-of-the-art accuracy with up to 13.7% reduction of the word error rate (WER) with linear scalability with respect to computing resources.</li>
</ul>

<h3>Title: Title:
          Large Language Models have Intrinsic Self-Correction Ability</h3>
<ul>
<li><strong>Authors: </strong>Dancheng Liu, Amir Nassereldine, Ziming Yang, Chenhui Xu, Yuting Hu, Jiajie Li, Utkarsh Kumar, Changjae Lee, Jinjun Xiong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Large Language Models have Intrinsic Self-Correction Ability(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have attracted significant attention for their remarkable abilities in various natural language processing tasks, but they suffer from hallucinations that will cause performance degradation. One promising solution to improve the LLMs' performance is to ask LLMs to revise their answer after generation, a technique known as self-correction. Among the two types of self-correction, intrinsic self-correction is considered a promising direction because it does not utilize external knowledge. However, recent works doubt the validity of LLM's ability to conduct intrinsic self-correction. In this paper, we present a novel perspective on the intrinsic self-correction capabilities of LLMs through theoretical analyses and empirical experiments. In addition, we identify two critical factors for successful self-correction: zero temperature and fair prompts. Leveraging these factors, we demonstrate that intrinsic self-correction ability is exhibited across multiple existing LLMs. Our findings offer insights into the fundamental theories underlying the self-correction behavior of LLMs and remark on the importance of unbiased prompts and zero temperature settings in harnessing their full potential.</li>
</ul>

<h3>Title: Title:
          The Case for Transport-Level Encryption in Datacenter Networks</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Gao, Xinshu Ma, Suhas Narreddy, Eugenio Luo, Steven W. D. Chien, Michio Honda</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          The Case for Transport-Level Encryption in Datacenter Networks(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Cloud applications need network data encryption to isolate from other tenants and protect their data from potential eavesdroppers in the network infrastructure. This paper presents SDP, a protocol design for emerging datacenter transport protocols, such as pHost, NDP, and Homa, to integrate data encryption with the use of existing NIC offloading of cryptographic operations designed for TLS over TCP. Therefore, SDP could enable a deployment path of new transport protocols in datacenters without giving up hardware offloading support, which would otherwise make encryption on those protocols even slower than TLS over TCP. SDP is based on Homa, and outperforms TLS over TCP by up to 29 % in throughput. SDP currently supports two real-world applications, Redis, improving throughput by up to 24 %, and in-kernel NVMe-oF, cutting P99 latency by up to 21 %.</li>
</ul>

<h3>Title: Title:
          Segmenting Dead Sea Scroll Fragments for a Scientific Image Set</h3>
<ul>
<li><strong>Authors: </strong>Bronson Brown-deVost, Berat Kurar-Barakat, Nachum Dershowitz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Segmenting Dead Sea Scroll Fragments for a Scientific Image Set(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents a customized pipeline for segmenting manuscript fragments from images curated by the Israel Antiquities Authority (IAA). The images present challenges for standard segmentation methods due to the presence of the ruler, color, and plate number bars, as well as a black background that resembles the ink and varying backing substrates. The proposed pipeline, consisting of four steps, addresses these challenges by isolating and solving each difficulty using custom tailored methods. Further, the usage of a multi-step pipeline will surely be helpful from a conceptual standpoint for other image segmentation projects that encounter problems that have proven intractable when applying any of the more commonly used segmentation techniques. In addition, we create a dataset with bar detection and fragment segmentation ground truth and evaluate the pipeline steps qualitatively and quantitatively on it. This dataset is publicly available to support the development of the field. It aims to address the lack of standard sets of fragment images and evaluation metrics and enable researchers to evaluate their methods in a reliable and reproducible manner.</li>
</ul>

<h3>Title: Title:
          SS-Bench: A Benchmark for Social Story Generation and Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Yi Feng, Mingyang Song, Jiaqi Wang, Mao Zheng, Liping Jing, Jian Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          SS-Bench: A Benchmark for Social Story Generation and Evaluation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Children with Autism Spectrum Disorder (ASD) often misunderstand social situations and struggle to participate in daily routines. Psychology experts write Social Stories under strict constraints of structural clarity, descriptive orientation, and situational safety to enhance their abilities in these regimes. However, Social Stories are costly in creation and often limited in diversity and timeliness. As Large Language Models (LLMs) become increasingly powerful, there is a growing need for more automated, affordable, and accessible methods to generate Social Stories in real-time with broad coverage. Adapting LLMs to meet the unique and strict constraints of Social Stories is a challenging issue. To this end, we propose \textbf{SS-Bench}, a \textbf{S}ocial \textbf{S}tory \textbf{Bench}mark for generating and evaluating Social Stories. Specifically, we develop a constraint-driven strategy named \textbf{\textsc{StarSow}} to hierarchically prompt LLMs to generate Social Stories and build a benchmark, which has been validated through experiments to fine-tune smaller models for generating qualified Social Stories. Additionally, we introduce \textbf{Quality Assessment Criteria}, employed in human and GPT evaluations, to verify the effectiveness of the generated stories. We hope this work benefits the autism community and catalyzes future research focusing on particular groups.</li>
</ul>

<h3>Title: Title:
          Self-Supervised Alignment Learning for Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Haofeng Li, Yiming Ouyang, Xiang Wan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Self-Supervised Alignment Learning for Medical Image Segmentation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recently, self-supervised learning (SSL) methods have been used in pre-training the segmentation models for 2D and 3D medical images. Most of these methods are based on reconstruction, contrastive learning and consistency regularization. However, the spatial correspondence of 2D slices from a 3D medical image has not been fully exploited. In this paper, we propose a novel self-supervised alignment learning framework to pre-train the neural network for medical image segmentation. The proposed framework consists of a new local alignment loss and a global positional loss. We observe that in the same 3D scan, two close 2D slices usually contain similar anatomic structures. Thus, the local alignment loss is proposed to make the pixel-level features of matched structures close to each other. Experimental results show that the proposed alignment learning is competitive with existing self-supervised pre-training approaches on CT and MRI datasets, under the setting of limited annotations.</li>
</ul>

<h3>Title: Title:
          video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guangzhi Sun, Wenyi Yu, Changli Tang, Xianzhao Chen, Tian Tan, Wei Li, Lu Lu, Zejun Ma, Yuxuan Wang, Chao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Speech understanding as an element of the more generic video understanding using audio-visual large language models (av-LLMs) is a crucial yet understudied aspect. This paper proposes video-SALMONN, a single end-to-end av-LLM for video processing, which can understand not only visual frame sequences, audio events and music, but speech as well. To obtain fine-grained temporal information required by speech understanding, while keeping efficient for other video elements, this paper proposes a novel multi-resolution causal Q-Former (MRC Q-Former) structure to connect pre-trained audio-visual encoders and the backbone large language model. Moreover, dedicated training approaches including the diversity loss and the unpaired audio-visual mixed training scheme are proposed to avoid frames or modality dominance. On the introduced speech-audio-visual evaluation benchmark, video-SALMONN achieves more than 25\% absolute accuracy improvements on the video-QA task and over 30\% absolute accuracy improvements on audio-visual QA tasks with human speech. In addition, video-SALMONN demonstrates remarkable video comprehension and reasoning abilities on tasks that are unprecedented by other av-LLMs. Our training code and model checkpoints are available at \texttt{\url{this https URL}}.</li>
</ul>

<h3>Title: Title:
          Teach Better or Show Smarter? On Instructions and Exemplars in Automatic Prompt Optimization</h3>
<ul>
<li><strong>Authors: </strong>Xingchen Wan, Ruoxi Sun, Hootan Nakhost, Sercan O. Arik</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Teach Better or Show Smarter? On Instructions and Exemplars in Automatic Prompt Optimization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have demonstrated remarkable capabilities, but their performance is heavily reliant on effective prompt engineering. Automatic prompt optimization (APO) methods are designed to automate this and can be broadly categorized into those targeting instructions (instruction optimization, IO) vs. those targeting exemplars (exemplar selection, ES). Despite their shared objective, these have evolved rather independently, with IO recently receiving more research attention. This paper seeks to bridge this gap by comprehensively comparing the performance of representative IO and ES techniques, both isolation and combination, on a diverse set of challenging tasks. Our findings reveal that intelligently reusing model-generated input-output pairs obtained from evaluating prompts on the validation set as exemplars consistently improves performance over IO methods but is currently under-investigated. We also find that despite the recent focus on IO, how we select exemplars can outweigh how we optimize instructions, with ES strategies as simple as random search outperforming state-of-the-art IO methods with seed instructions without any optimization. Moreover, we observe synergy between ES and IO, with optimal combinations surpassing individual contributions. We conclude that studying exemplar selection as a standalone method and its optimal combination with instruction optimization remains a crucial aspect of APO and deserves greater consideration in future research, even in the era of highly capable instruction-following models.</li>
</ul>

<h3>Title: Title:
          I Experienced More than 10 DeFi Scams: On DeFi Users' Perception of Security Breaches and Countermeasures</h3>
<ul>
<li><strong>Authors: </strong>Mingyi Liu, Jun Ho Huh, HyungSeok Han, Jaehyuk Lee, Jihae Ahn, Frank Li, Hyoungshick Kim, Taesoo Kim</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          I Experienced More than 10 DeFi Scams: On DeFi Users' Perception of Security Breaches and Countermeasures(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Decentralized Finance (DeFi) offers a whole new investment experience and has quickly emerged as an enticing alternative to Centralized Finance (CeFi). Rapidly growing market size and active users, however, have also made DeFi a lucrative target for scams and hacks, with 1.95 billion USD lost in 2023. Unfortunately, no prior research thoroughly investigates DeFi users' security risk awareness levels and the adequacy of their risk mitigation strategies. Based on a semi-structured interview study (N = 14) and a follow-up survey (N = 493), this paper investigates DeFi users' security perceptions and commonly adopted practices, and how those affected by previous scams or hacks (DeFi victims) respond and try to recover their losses. Our analysis shows that users often prefer DeFi over CeFi due to their decentralized nature and strong profitability. Despite being aware that DeFi, compared to CeFi, is prone to more severe attacks, users are willing to take those risks to explore new investment opportunities. Worryingly, most victims do not learn from previous experiences; unlike victims studied through traditional systems, DeFi victims tend to find new services, without revising their security practices, to recover their losses quickly. The abundance of various DeFi services and opportunities allows victims to continuously explore new financial opportunities, and this reality seems to cloud their security priorities. Indeed, our results indicate that DeFi users' strong financial motivations outweigh their security concerns - much like those who are addicted to gambling. Our observations about victims' post-incident behaviors suggest that stronger control in the form of industry regulations would be necessary to protect DeFi users from future breaches.</li>
</ul>

<h3>Title: Title:
          Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models</h3>
<ul>
<li><strong>Authors: </strong>Xinrong Zhang, Yingfa Chen, Shengding Hu, Xu Han, Zihang Xu, Yuanwei Xu, Weilin Zhao, Maosong Sun, Zhiyuan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) increasingly permeate daily lives, there is a growing demand for real-time interactions that mirror human conversations. Traditional turn-based chat systems driven by LLMs prevent users from verbally interacting with the system while it is generating responses. To overcome these limitations, we adapt existing LLMs to \textit{duplex models} so that these LLMs can listen for users while generating output and dynamically adjust themselves to provide users with instant feedback. % such as in response to interruptions. Specifically, we divide the queries and responses of conversations into several time slices and then adopt a time-division-multiplexing (TDM) encoding-decoding strategy to pseudo-simultaneously process these slices. Furthermore, to make LLMs proficient enough to handle real-time conversations, we build a fine-tuning dataset consisting of alternating time slices of queries and responses as well as covering typical feedback types in instantaneous interactions. Our experiments show that although the queries and responses of conversations are segmented into incomplete slices for processing, LLMs can preserve their original performance on standard benchmarks with a few fine-tuning steps on our dataset. Automatic and human evaluation indicate that duplex models make user-AI interactions more natural and human-like, and greatly improve user satisfaction compared to vanilla LLMs. Our duplex model and dataset will be released.</li>
</ul>

<h3>Title: Title:
          How to Learn More? Exploring Kolmogorov-Arnold Networks for Hyperspectral Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Ali Jamali, Swalpa Kumar Roy, Danfeng Hong, Bing Lu, Pedram Ghamisi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          How to Learn More? Exploring Kolmogorov-Arnold Networks for Hyperspectral Image Classification(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Convolutional Neural Networks (CNNs) and vision transformers (ViTs) have shown excellent capability in complex hyperspectral image (HSI) classification. However, these models require a significant number of training data and are computational resources. On the other hand, modern Multi-Layer Perceptrons (MLPs) have demonstrated great classification capability. These modern MLP-based models require significantly less training data compared to CNNs and ViTs, achieving the state-of-the-art classification accuracy. Recently, Kolmogorov-Arnold Networks (KANs) were proposed as viable alternatives for MLPs. Because of their internal similarity to splines and their external similarity to MLPs, KANs are able to optimize learned features with remarkable accuracy in addition to being able to learn new features. Thus, in this study, we assess the effectiveness of KANs for complex HSI data classification. Moreover, to enhance the HSI classification accuracy obtained by the KANs, we develop and propose a Hybrid architecture utilizing 1D, 2D, and 3D KANs. To demonstrate the effectiveness of the proposed KAN architecture, we conducted extensive experiments on three newly created HSI benchmark datasets: QUH-Pingan, QUH-Tangdaowan, and QUH-Qingyun. The results underscored the competitive or better capability of the developed hybrid KAN-based model across these benchmark datasets over several other CNN- and ViT-based algorithms, including 1D-CNN, 2DCNN, 3D CNN, VGG-16, ResNet-50, EfficientNet, RNN, and ViT. The code are publicly available at (this https URL)</li>
</ul>

<h3>Title: Title:
          Scaling Laws for Fact Memorization of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xingyu Lu, Xiaonan Li, Qinyuan Cheng, Kai Ding, Xuanjing Huang, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Scaling Laws for Fact Memorization of Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fact knowledge memorization is crucial for Large Language Models (LLM) to generate factual and reliable responses. However, the behaviors of LLM fact memorization remain under-explored. In this paper, we analyze the scaling laws for LLM's fact knowledge and LLMs' behaviors of memorizing different types of facts. We find that LLMs' fact knowledge capacity has a linear and negative exponential law relationship with model size and training epochs, respectively. Estimated by the built scaling law, memorizing the whole Wikidata's facts requires training an LLM with 1000B non-embed parameters for 100 epochs, suggesting that using LLMs to memorize all public facts is almost implausible for a general pre-training setting. Meanwhile, we find that LLMs can generalize on unseen fact knowledge and its scaling law is similar to general pre-training. Additionally, we analyze the compatibility and preference of LLMs' fact memorization. For compatibility, we find LLMs struggle with memorizing redundant facts in a unified way. Only when correlated facts have the same direction and structure, the LLM can compatibly memorize them. This shows the inefficiency of LLM memorization for redundant facts. For preference, the LLM pays more attention to memorizing more frequent and difficult facts, and the subsequent facts can overwrite prior facts' memorization, which significantly hinders low-frequency facts memorization. Our findings reveal the capacity and characteristics of LLMs' fact knowledge learning, which provide directions for LLMs' fact knowledge augmentation.</li>
</ul>

<h3>Title: Title:
          Breaking Secure Aggregation: Label Leakage from Aggregated Gradients in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhibo Wang, Zhiwei Chang, Jiahui Hu, Xiaoyi Pang, Jiacheng Du, Yongle Chen, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Breaking Secure Aggregation: Label Leakage from Aggregated Gradients in Federated Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, steal, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) exhibits privacy vulnerabilities under gradient inversion attacks (GIAs), which can extract private information from individual gradients. To enhance privacy, FL incorporates Secure Aggregation (SA) to prevent the server from obtaining individual gradients, thus effectively resisting GIAs. In this paper, we propose a stealthy label inference attack to bypass SA and recover individual clients' private labels. Specifically, we conduct a theoretical analysis of label inference from the aggregated gradients that are exclusively obtained after implementing SA. The analysis results reveal that the inputs (embeddings) and outputs (logits) of the final fully connected layer (FCL) contribute to gradient disaggregation and label restoration. To preset the embeddings and logits of FCL, we craft a fishing model by solely modifying the parameters of a single batch normalization (BN) layer in the original model. Distributing client-specific fishing models, the server can derive the individual gradients regarding the bias of FCL by resolving a linear system with expected embeddings and the aggregated gradients as coefficients. Then the labels of each client can be precisely computed based on preset logits and gradients of FCL's bias. Extensive experiments show that our attack achieves large-scale label recovery with 100\% accuracy on various datasets and model architectures.</li>
</ul>

<h3>Title: Title:
          RankAdaptor: Hierarchical Dynamic Low-Rank Adaptation for Structural Pruned LLMs</h3>
<ul>
<li><strong>Authors: </strong>Changhai Zhou, Shijie Han, Shiyang Zhang, Shichao Weng, Zekai Liu, Cheng Jin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          RankAdaptor: Hierarchical Dynamic Low-Rank Adaptation for Structural Pruned LLMs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The efficient compression of large language models (LLMs) is becoming increasingly popular. However, recovering the accuracy of compressed LLMs is still a major challenge. Structural pruning with standard Low-Rank Adaptation (LoRA) is a common technique in current LLM compression. In structural pruning, the model architecture is modified unevenly, resulting in suboptimal performance in various downstream tasks via standard LoRA with fixed rank. To address this problem, we introduce RankAdaptor, an efficient fine-tuning method with hierarchical dynamic rank scheduling for pruned LLMs. An end-to-end automatic optimization flow is developed that utilizes a lightweight performance model to determine the different ranks during fine-tuning. Comprehensive experiments on popular benchmarks show that RankAdaptor consistently outperforms standard LoRA with structural pruning over different pruning settings. Without increasing the trainable parameters, RankAdaptor further reduces the accuracy performance gap between the recovery of the pruned model and the original model compared to standard LoRA.</li>
</ul>

<h3>Title: Title:
          Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Min Zhao, Hongzhou Zhu, Chendong Xiang, Kaiwen Zheng, Chongxuan Li, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have obtained substantial progress in image-to-video (I2V) generation. However, such models are not fully understood. In this paper, we report a significant but previously overlooked issue in I2V diffusion models (I2V-DMs), namely, conditional image leakage. I2V-DMs tend to over-rely on the conditional image at large time steps, neglecting the crucial task of predicting the clean video from noisy inputs, which results in videos lacking dynamic and vivid motion. We further address this challenge from both inference and training aspects by presenting plug-and-play strategies accordingly. First, we introduce a training-free inference strategy that starts the generation process from an earlier time step to avoid the unreliable late-time steps of I2V-DMs, as well as an initial noise distribution with optimal analytic expressions (Analytic-Init) by minimizing the KL divergence between it and the actual marginal distribution to effectively bridge the training-inference gap. Second, to mitigate conditional image leakage during training, we design a time-dependent noise distribution for the conditional image, which favors high noise levels at large time steps to sufficiently interfere with the conditional image. We validate these strategies on various I2V-DMs using our collected open-domain image benchmark and the UCF101 dataset. Extensive results demonstrate that our methods outperform baselines by producing videos with more dynamic and natural motion without compromising image alignment and temporal consistency. The project page: \url{this https URL}.</li>
</ul>

<h3>Title: Title:
          Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level</h3>
<ul>
<li><strong>Authors: </strong>Zhaopeng Feng, Ruizhe Chen, Yan Zhang, Zijie Meng, Zuozhu Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>General-purpose Large Language Models (LLMs) like GPT-4 have achieved remarkable advancements in machine translation (MT) by leveraging extensive web content. On the other hand, translation-specific LLMs are built by pre-training on domain-specific monolingual corpora and fine-tuning with human-annotated translation data. Despite the superior performance, these methods either demand an unprecedented scale of computing and data or substantial human editing and annotation efforts. In this paper, we develop Ladder, a novel model-agnostic and cost-effective tool to refine the performance of general LLMs for MT. Ladder is trained on pseudo-refinement triplets which can be easily obtained from existing LLMs without additional human cost. During training, we propose a hierarchical fine-tuning strategy with an easy-to-hard schema, improving Ladder's refining performance progressively. The trained Ladder can be seamlessly integrated with any general-purpose LLMs to boost their translation performance. By utilizing Gemma-2B/7B as the backbone, Ladder-2B can elevate raw translations to the level of top-tier open-source models (e.g., refining BigTranslate-13B with +6.91 BLEU and +3.52 COMET for XX-En), and Ladder-7B can further enhance model performance to be on par with the state-of-the-art GPT-4. Extensive ablation and analysis corroborate the effectiveness of Ladder in diverse settings. Our code is available at this https URL</li>
</ul>

<h3>Title: Title:
          Modeling Unknown Stochastic Dynamical System Subject to External Excitation</h3>
<ul>
<li><strong>Authors: </strong>Yuan Chen, Dongbin Xiu</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY, math.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Modeling Unknown Stochastic Dynamical System Subject to External Excitation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We present a numerical method for learning unknown nonautonomous stochastic dynamical system, i.e., stochastic system subject to time dependent excitation or control signals. Our basic assumption is that the governing equations for the stochastic system are unavailable. However, short bursts of input/output (I/O) data consisting of certain known excitation signals and their corresponding system responses are available. When a sufficient amount of such I/O data are available, our method is capable of learning the unknown dynamics and producing an accurate predictive model for the stochastic responses of the system subject to arbitrary excitation signals not in the training data. Our method has two key components: (1) a local approximation of the training I/O data to transfer the learning into a parameterized form; and (2) a generative model to approximate the underlying unknown stochastic flow map in distribution. After presenting the method in detail, we present a comprehensive set of numerical examples to demonstrate the performance of the proposed method, especially for long-term system predictions.</li>
</ul>

<h3>Title: Title:
          Multimodal Segmentation for Vocal Tract Modeling</h3>
<ul>
<li><strong>Authors: </strong>Rishi Jain, Bohan Yu, Peter Wu, Tejas Prabhune, Gopala Anumanchipalli</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Multimodal Segmentation for Vocal Tract Modeling(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate modeling of the vocal tract is necessary to construct articulatory representations for interpretable speech processing and linguistics. However, vocal tract modeling is challenging because many internal articulators are occluded from external motion capture technologies. Real-time magnetic resonance imaging (RT-MRI) allows measuring precise movements of internal articulators during speech, but annotated datasets of MRI are limited in size due to time-consuming and computationally expensive labeling methods. We first present a deep labeling strategy for the RT-MRI video using a vision-only segmentation approach. We then introduce a multimodal algorithm using audio to improve segmentation of vocal articulators. Together, we set a new benchmark for vocal tract modeling in MRI video segmentation and use this to release labels for a 75-speaker RT-MRI dataset, increasing the amount of labeled public RT-MRI data of the vocal tract by over a factor of 9. The code and dataset labels can be found at \url{this http URL}.</li>
</ul>

<h3>Title: Title:
          Fine-grained Background Representation for Weakly Supervised Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Xu Yin, Woobin Im, Dongbo Min, Yuchi Huo, Fei Pan, Sung-Eui Yoon</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Fine-grained Background Representation for Weakly Supervised Semantic Segmentation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Generating reliable pseudo masks from image-level labels is challenging in the weakly supervised semantic segmentation (WSSS) task due to the lack of spatial information. Prevalent class activation map (CAM)-based solutions are challenged to discriminate the foreground (FG) objects from the suspicious background (BG) pixels (a.k.a. co-occurring) and learn the integral object regions. This paper proposes a simple fine-grained background representation (FBR) method to discover and represent diverse BG semantics and address the co-occurring problems. We abandon using the class prototype or pixel-level features for BG representation. Instead, we develop a novel primitive, negative region of interest (NROI), to capture the fine-grained BG semantic information and conduct the pixel-to-NROI contrast to distinguish the confusing BG pixels. We also present an active sampling strategy to mine the FG negatives on-the-fly, enabling efficient pixel-to-pixel intra-foreground contrastive learning to activate the entire object region. Thanks to the simplicity of design and convenience in use, our proposed method can be seamlessly plugged into various models, yielding new state-of-the-art results under various WSSS settings across benchmarks. Leveraging solely image-level (I) labels as supervision, our method achieves 73.2 mIoU and 45.6 mIoU segmentation results on Pascal Voc and MS COCO test sets, respectively. Furthermore, by incorporating saliency maps as an additional supervision signal (I+S), we attain 74.9 mIoU on Pascal Voc test set. Concurrently, our FBR approach demonstrates meaningful performance gains in weakly-supervised instance segmentation (WSIS) tasks, showcasing its robustness and strong generalization capabilities across diverse domains.</li>
</ul>

<h3>Title: Title:
          EDGE-LLM: Enabling Efficient Large Language Model Adaptation on Edge Devices via Layerwise Unified Compression and Adaptive Layer Tuning and Voting</h3>
<ul>
<li><strong>Authors: </strong>Zhongzhi Yu, Zheng Wang, Yuhan Li, Haoran You, Ruijie Gao, Xiaoya Zhou, Sreenidhi Reedy Bommu, Yang Katie Zhao, Yingyan Celine Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          EDGE-LLM: Enabling Efficient Large Language Model Adaptation on Edge Devices via Layerwise Unified Compression and Adaptive Layer Tuning and Voting(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Efficient adaption of large language models (LLMs) on edge devices is essential for applications requiring continuous and privacy-preserving adaptation and inference. However, existing tuning techniques fall short because of the high computation and memory overheads. To this end, we introduce a computation- and memory-efficient LLM tuning framework, called Edge-LLM, to facilitate affordable and effective LLM adaptation on edge devices. Specifically, Edge-LLM features three core components: (1) a layer-wise unified compression (LUC) technique to reduce the computation overhead by generating layer-wise pruning sparsity and quantization bit-width policies, (2) an adaptive layer tuning and voting scheme to reduce the memory overhead by reducing the backpropagation depth, and (3) a complementary hardware scheduling strategy to handle the irregular computation patterns introduced by LUC and adaptive layer tuning, thereby achieving efficient computation and data movements. Extensive experiments demonstrate that Edge-LLM achieves a 2.92x speed up and a 4x memory overhead reduction as compared to vanilla tuning methods with comparable task accuracy. Our code is available at this https URL</li>
</ul>

<h3>Title: Title:
          Rethinking the Diffusion Models for Numerical Tabular Data Imputation from the Perspective of Wasserstein Gradient Flow</h3>
<ul>
<li><strong>Authors: </strong>Zhichao Chen, Haoxuan Li, Fangyikang Wang, Odin Zhang, Hu Xu, Xiaoyu Jiang, Zhihuan Song, Eric H. Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Rethinking the Diffusion Models for Numerical Tabular Data Imputation from the Perspective of Wasserstein Gradient Flow(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) have gained attention in Missing Data Imputation (MDI), but there remain two long-neglected issues to be addressed: (1). Inaccurate Imputation, which arises from inherently sample-diversification-pursuing generative process of DMs. (2). Difficult Training, which stems from intricate design required for the mask matrix in model training stage. To address these concerns within the realm of numerical tabular datasets, we introduce a novel principled approach termed Kernelized Negative Entropy-regularized Wasserstein gradient flow Imputation (KnewImp). Specifically, based on Wasserstein gradient flow (WGF) framework, we first prove that issue (1) stems from the cost functionals implicitly maximized in DM-based MDI are equivalent to the MDI's objective plus diversification-promoting non-negative terms. Based on this, we then design a novel cost functional with diversification-discouraging negative entropy and derive our KnewImp approach within WGF framework and reproducing kernel Hilbert space. After that, we prove that the imputation procedure of KnewImp can be derived from another cost functional related to the joint distribution, eliminating the need for the mask matrix and hence naturally addressing issue (2). Extensive experiments demonstrate that our proposed KnewImp approach significantly outperforms existing state-of-the-art methods.</li>
</ul>

<h3>Title: Title:
          TP-DRSeg: Improving Diabetic Retinopathy Lesion Segmentation with Explicit Text-Prompts Assisted SAM</h3>
<ul>
<li><strong>Authors: </strong>Wenxue Li, Xinyu Xiong, Peng Xia, Lie Ju, Zongyuan Ge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          TP-DRSeg: Improving Diabetic Retinopathy Lesion Segmentation with Explicit Text-Prompts Assisted SAM(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in large foundation models, such as the Segment Anything Model (SAM), have demonstrated considerable promise across various tasks. Despite their progress, these models still encounter challenges in specialized medical image analysis, especially in recognizing subtle inter-class differences in Diabetic Retinopathy (DR) lesion segmentation. In this paper, we propose a novel framework that customizes SAM for text-prompted DR lesion segmentation, termed TP-DRSeg. Our core idea involves exploiting language cues to inject medical prior knowledge into the vision-only segmentation network, thereby combining the advantages of different foundation models and enhancing the credibility of segmentation. Specifically, to unleash the potential of vision-language models in the recognition of medical concepts, we propose an explicit prior encoder that transfers implicit medical concepts into explicit prior knowledge, providing explainable clues to excavate low-level features associated with lesions. Furthermore, we design a prior-aligned injector to inject explicit priors into the segmentation process, which can facilitate knowledge sharing across multi-modality features and allow our framework to be trained in a parameter-efficient fashion. Experimental results demonstrate the superiority of our framework over other traditional models and foundation model variants.</li>
</ul>

<h3>Title: Title:
          Unveiling and Harnessing Hidden Attention Sinks: Enhancing Large Language Models without Training through Attention Calibration</h3>
<ul>
<li><strong>Authors: </strong>Zhongzhi Yu, Zheng Wang, Yonggan Fu, Huihong Shi, Khalid Shaikh, Yingyan Celine Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Unveiling and Harnessing Hidden Attention Sinks: Enhancing Large Language Models without Training through Attention Calibration(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Attention is a fundamental component behind the remarkable achievements of large language models (LLMs). However, our current understanding of the attention mechanism, especially regarding how attention distributions are established, remains limited. Inspired by recent studies that explore the presence of attention sink in the initial token, which receives disproportionately large attention scores despite their lack of semantic importance, this work delves deeper into this phenomenon. We aim to provide a more profound understanding of the existence of attention sinks within LLMs and to uncover ways to enhance the achievable accuracy of LLMs by directly optimizing the attention distributions, without the need for weight finetuning. Specifically, this work begins with comprehensive visualizations of the attention distributions in LLMs during inference across various inputs and tasks. Based on these visualizations, to the best of our knowledge, we are the first to discover that (1) attention sinks occur not only at the start of sequences but also within later tokens of the input, and (2) not all attention sinks have a positive impact on the achievable accuracy of LLMs. Building upon our findings, we propose a training-free Attention Calibration Technique (ACT) that automatically optimizes the attention distributions on the fly during inference in an input-adaptive manner. Extensive experiments validate that ACT consistently enhances the accuracy of various LLMs across different applications. Specifically, ACT achieves an average improvement of up to 7.30% in accuracy across different datasets when applied to Llama-30B. Our code is available at this https URL.</li>
</ul>

<h3>Title: Title:
          Continual Learning with Diffusion-based Generative Replay for Industrial Streaming Data</h3>
<ul>
<li><strong>Authors: </strong>Jiayi He, Jiao Chen, Qianmiao Liu, Suyan Dai, Jianhua Tang, Dongpo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Continual Learning with Diffusion-based Generative Replay for Industrial Streaming Data(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The Industrial Internet of Things (IIoT) integrates interconnected sensors and devices to support industrial applications, but its dynamic environments pose challenges related to data drift. Considering the limited resources and the need to effectively adapt models to new data distributions, this paper introduces a Continual Learning (CL) approach, i.e., Distillation-based Self-Guidance (DSG), to address challenges presented by industrial streaming data via a novel generative replay mechanism. DSG utilizes knowledge distillation to transfer knowledge from the previous diffusion-based generator to the updated one, improving both the stability of the generator and the quality of reproduced data, thereby enhancing the mitigation of catastrophic forgetting. Experimental results on CWRU, DSA, and WISDM datasets demonstrate the effectiveness of DSG. DSG outperforms the state-of-the-art baseline in accuracy, demonstrating improvements ranging from 2.9% to 5.0% on key datasets, showcasing its potential for practical industrial applications.</li>
</ul>

<h3>Title: Title:
          MR-MLLM: Mutual Reinforcement of Multimodal Comprehension and Vision Perception</h3>
<ul>
<li><strong>Authors: </strong>Guanqun Wang, Xinyu Wei, Jiaming Liu, Ray Zhang, Yichi Zhang, Kevin Zhang, Maurice Chong, Shanghang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          MR-MLLM: Mutual Reinforcement of Multimodal Comprehension and Vision Perception(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>In recent years, multimodal large language models (MLLMs) have shown remarkable capabilities in tasks like visual question answering and common sense reasoning, while visual perception models have made significant strides in perception tasks, such as detection and segmentation. However, MLLMs mainly focus on high-level image-text interpretations and struggle with fine-grained visual understanding, and vision perception models usually suffer from open-world distribution shifts due to their limited model capacity. To overcome these challenges, we propose the Mutually Reinforced Multimodal Large Language Model (MR-MLLM), a novel framework that synergistically enhances visual perception and multimodal comprehension. First, a shared query fusion mechanism is proposed to harmonize detailed visual inputs from vision models with the linguistic depth of language models, enhancing multimodal comprehension and vision perception synergistically. Second, we propose the perception-enhanced cross-modal integration method, incorporating novel modalities from vision perception outputs, like object detection bounding boxes, to capture subtle visual elements, thus enriching the understanding of both visual and textual data. In addition, an innovative perception-embedded prompt generation mechanism is proposed to embed perceptual information into the language model's prompts, aligning the responses contextually and perceptually for a more accurate multimodal interpretation. Extensive experiments demonstrate MR-MLLM's superior performance in various multimodal comprehension and vision perception tasks, particularly those requiring corner case vision perception and fine-grained language comprehension.</li>
</ul>

<h3>Title: Title:
          DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wei Guan, Jian Cao, Jianqi Gao, Haiyan Zhao, Shiyou Qian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Detecting anomalies in business processes is crucial for ensuring operational success. While many existing methods rely on statistical frequency to detect anomalies, it's important to note that infrequent behavior doesn't necessarily imply undesirability. To address this challenge, detecting anomalies from a semantic viewpoint proves to be a more effective approach. However, current semantic anomaly detection methods treat a trace (i.e., process instance) as multiple event pairs, disrupting long-distance dependencies. In this paper, we introduce DABL, a novel approach for detecting semantic anomalies in business processes using large language models (LLMs). We collect 143,137 real-world process models from various domains. By generating normal traces through the playout of these process models and simulating both ordering and exclusion anomalies, we fine-tune Llama 2 using the resulting log. Through extensive experiments, we demonstrate that DABL surpasses existing state-of-the-art semantic anomaly detection methods in terms of both generalization ability and learning of given processes. Users can directly apply DABL to detect semantic anomalies in their own datasets without the need for additional training. Furthermore, DABL offers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies.</li>
</ul>

<h3>Title: Title:
          What Matters in Transformers? Not All Attention is Needed</h3>
<ul>
<li><strong>Authors: </strong>Shwai He, Guoheng Sun, Zheyu Shen, Ang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          What Matters in Transformers? Not All Attention is Needed(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Scaling Transformer-based large language models (LLMs) has demonstrated promising performance across various tasks. However, this scaling also introduces redundant structures, posing challenges for real-world deployment. Despite some recognition of redundancy in LLMs, the variability of redundancy across different structures, such as MLP and Attention layers, is under-explored. In this work, we investigate the varying redundancy across different modules within Transformers, including Blocks, MLP, and Attention layers, using a similarity-based metric. This metric operates on the premise that redundant structures produce outputs highly similar to their inputs. Surprisingly, while attention layers are essential for transformers and distinguish them from other mainstream architectures, we found that a large proportion of attention layers exhibit excessively high similarity and can be safely pruned without degrading performance, leading to reduced memory and computation costs. Additionally, we further propose a method that jointly drops Attention and MLP layers, achieving improved performance and dropping ratios. Extensive experiments demonstrate the effectiveness of our methods, e.g., Llama-3-70B maintains comparable performance even after pruning half of the attention layers. Our findings provide valuable insights for future network architecture design. The code will be released at: \url{this https URL}.</li>
</ul>

<h3>Title: Title:
          Distributionally Robust Constrained Reinforcement Learning under Strong Duality</h3>
<ul>
<li><strong>Authors: </strong>Zhengfei Zhang, Kishan Panaganti, Laixi Shi, Yanan Sui, Adam Wierman, Yisong Yue</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Distributionally Robust Constrained Reinforcement Learning under Strong Duality(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study the problem of Distributionally Robust Constrained RL (DRC-RL), where the goal is to maximize the expected reward subject to environmental distribution shifts and constraints. This setting captures situations where training and testing environments differ, and policies must satisfy constraints motivated by safety or limited budgets. Despite significant progress toward algorithm design for the separate problems of distributionally robust RL and constrained RL, there do not yet exist algorithms with end-to-end convergence guarantees for DRC-RL. We develop an algorithmic framework based on strong duality that enables the first efficient and provable solution in a class of environmental uncertainties. Further, our framework exposes an inherent structure of DRC-RL that arises from the combination of distributional robustness and constraints, which prevents a popular class of iterative methods from tractably solving DRC-RL, despite such frameworks being applicable for each of distributionally robust RL and constrained RL individually. Finally, we conduct experiments on a car racing benchmark to evaluate the effectiveness of the proposed algorithm.</li>
</ul>

<h3>Title: Title:
          Privacy Implications of Explainable AI in Data-Driven Systems</h3>
<ul>
<li><strong>Authors: </strong>Fatima Ezzeddine</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Privacy Implications of Explainable AI in Data-Driven Systems(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, extraction, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) models, demonstrably powerful, suffer from a lack of interpretability. The absence of transparency, often referred to as the black box nature of ML models, undermines trust and urges the need for efforts to enhance their explainability. Explainable AI (XAI) techniques address this challenge by providing frameworks and methods to explain the internal decision-making processes of these complex models. Techniques like Counterfactual Explanations (CF) and Feature Importance play a crucial role in achieving this goal. Furthermore, high-quality and diverse data remains the foundational element for robust and trustworthy ML applications. In many applications, the data used to train ML and XAI explainers contain sensitive information. In this context, numerous privacy-preserving techniques can be employed to safeguard sensitive information in the data, such as differential privacy. Subsequently, a conflict between XAI and privacy solutions emerges due to their opposing goals. Since XAI techniques provide reasoning for the model behavior, they reveal information relative to ML models, such as their decision boundaries, the values of features, or the gradients of deep learning models when explanations are exposed to a third entity. Attackers can initiate privacy breaching attacks using these explanations, to perform model extraction, inference, and membership attacks. This dilemma underscores the challenge of finding the right equilibrium between understanding ML decision-making and safeguarding privacy.</li>
</ul>

<h3>Title: Title:
          Rethinking Entity-level Unlearning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Weitao Ma, Xiaocheng Feng, Weihong Zhong, Lei Huang, Yangfan Ye, Bing Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Rethinking Entity-level Unlearning for Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Large language model unlearning has gained increasing attention due to its potential to mitigate security and privacy concerns. Current research predominantly focuses on Instance-level unlearning, specifically aiming at forgetting predefined instances of sensitive content. However, a notable gap still exists in exploring the deletion of complete entity-related information, which is crucial in many real-world scenarios, such as copyright protection. To this end, we propose a novel task of Entity-level unlearning, where the entity-related knowledge within the target model is supposed to be entirely erased. Given the challenge of practically accessing all entity-related knowledge within a model, we begin by simulating entity-level unlearning scenarios through fine-tuning models to introduce pseudo entities. Following this, we develop baseline methods inspired by trending unlearning techniques and conduct a detailed comparison of their effectiveness in this task. Extensive experiments reveal that current unlearning algorithms struggle to achieve effective entity-level unlearning. Additionally, our analyses further indicate that entity-related knowledge injected through fine-tuning is more susceptible than original entities from pre-training during unlearning, highlighting the necessity for more thorough pseudo-entity injection methods to make them closer to pre-trained knowledge.</li>
</ul>

<h3>Title: Title:
          LaMSUM: A Novel Framework for Extractive Summarization of User Generated Content using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Garima Chhikara, Anurag Sharma, V. Gurucharan, Kripabandhu Ghosh, Abhijnan Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          LaMSUM: A Novel Framework for Extractive Summarization of User Generated Content using LLMs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive performance across a wide range of NLP tasks, including summarization. Inherently LLMs produce abstractive summaries, and the task of achieving extractive summaries through LLMs still remains largely unexplored. To bridge this gap, in this work, we propose a novel framework LaMSUM to generate extractive summaries through LLMs for large user-generated text by leveraging voting algorithms. Our evaluation on three popular open-source LLMs (Llama 3, Mixtral and Gemini) reveal that the LaMSUM outperforms state-of-the-art extractive summarization methods. We further attempt to provide the rationale behind the output summary produced by LLMs. Overall, this is one of the early attempts to achieve extractive summarization for large user-generated text by utilizing LLMs, and likely to generate further interest in the community.</li>
</ul>

<h3>Title: Title:
          PointDreamer: Zero-shot 3D Textured Mesh Reconstruction from Colored Point Cloud by 2D Inpainting</h3>
<ul>
<li><strong>Authors: </strong>Qiao Yu, Xianzhi Li, Yuan Tang, Jinfeng Xu, Long Hu, Yixue Hao, Min Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          PointDreamer: Zero-shot 3D Textured Mesh Reconstruction from Colored Point Cloud by 2D Inpainting(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Reconstructing textured meshes from colored point clouds is an important but challenging task in 3D graphics and vision. Most existing methods predict colors as implicit functions in 3D or UV space, suffering from blurry textures or the lack of generalization capability. Addressing this, we propose PointDreamer, a novel framework for textured mesh reconstruction from colored point cloud. It produces meshes with enhanced fidelity and clarity by 2D image inpainting, taking advantage of the mature techniques and massive data of 2D vision. Specifically, we first project the input point cloud into 2D space to generate sparse multi-view images, and then inpaint empty pixels utilizing a pre-trained 2D diffusion model. Next, we design a novel Non-Border-First strategy to unproject the colors of the inpainted dense images back to 3D space, thus obtaining the final textured mesh. In this way, our PointDreamer works in a zero-shot manner, requiring no extra training. Extensive qualitative and quantitative experiments on various synthetic and real-scanned datasets show the SoTA performance of PointDreamer, by significantly outperforming baseline methods with 30\% improvement in LPIPS score (from 0.118 to 0.068). Code at: this https URL.</li>
</ul>

<h3>Title: Title:
          Reading Is Believing: Revisiting Language Bottleneck Models for Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Honori Udo, Takafumi Koshinaka</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Reading Is Believing: Revisiting Language Bottleneck Models for Image Classification(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>We revisit language bottleneck models as an approach to ensuring the explainability of deep learning models for image classification. Because of inevitable information loss incurred in the step of converting images into language, the accuracy of language bottleneck models is considered to be inferior to that of standard black-box models. Recent image captioners based on large-scale foundation models of Vision and Language, however, have the ability to accurately describe images in verbal detail to a degree that was previously believed to not be realistically possible. In a task of disaster image classification, we experimentally show that a language bottleneck model that combines a modern image captioner with a pre-trained language model can achieve image classification accuracy that exceeds that of black-box models. We also demonstrate that a language bottleneck model and a black-box model may be thought to extract different features from images and that fusing the two can create a synergistic effect, resulting in even higher classification accuracy.</li>
</ul>

<h3>Title: Title:
          MVOC: a training-free multiple video object composition method with diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Wei Wang, Yaosen Chen, Yuegen Liu, Qi Yuan, Shubin Yang, Yanru Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          MVOC: a training-free multiple video object composition method with diffusion models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Video composition is the core task of video editing. Although image composition based on diffusion models has been highly successful, it is not straightforward to extend the achievement to video object composition tasks, which not only exhibit corresponding interaction effects but also ensure that the objects in the composited video maintain motion and identity consistency, which is necessary to composite a physical harmony video. To address this challenge, we propose a Multiple Video Object Composition (MVOC) method based on diffusion models. Specifically, we first perform DDIM inversion on each video object to obtain the corresponding noise features. Secondly, we combine and edit each object by image editing methods to obtain the first frame of the composited video. Finally, we use the image-to-video generation model to composite the video with feature and attention injections in the Video Object Dependence Module, which is a training-free conditional guidance operation for video generation, and enables the coordination of features and attention maps between various objects that can be non-independent in the composited video. The final generative model not only constrains the objects in the generated video to be consistent with the original object motion and identity, but also introduces interaction effects between objects. Extensive experiments have demonstrated that the proposed method outperforms existing state-of-the-art approaches. Project page: this https URL.</li>
</ul>

<h3>Title: Title:
          Shape2.5D: A Dataset of Texture-less Surfaces for Depth and Normals Estimation</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Saif Ullah Khan, Muhammad Zeshan Afzal, Didier Stricker</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Shape2.5D: A Dataset of Texture-less Surfaces for Depth and Normals Estimation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reconstructing texture-less surfaces poses unique challenges in computer vision, primarily due to the lack of specialized datasets that cater to the nuanced needs of depth and normals estimation in the absence of textural information. We introduce "Shape2.5D," a novel, large-scale dataset designed to address this gap. Comprising 364k frames spanning 2635 3D models and 48 unique objects, our dataset provides depth and surface normal maps for texture-less object reconstruction. The proposed dataset includes synthetic images rendered with 3D modeling software to simulate various lighting conditions and viewing angles. It also includes a real-world subset comprising 4672 frames captured with a depth camera. Our comprehensive benchmarks, performed using a modified encoder-decoder network, showcase the dataset's capability to support the development of algorithms that robustly estimate depth and normals from RGB images. Our open-source data generation pipeline allows the dataset to be extended and adapted for future research. The dataset is publicly available at \url{this https URL}.</li>
</ul>

<h3>Title: Title:
          Decentralized Transformers with Centralized Aggregation are Sample-Efficient Multi-Agent World Models</h3>
<ul>
<li><strong>Authors: </strong>Yang Zhang, Chenjia Bai, Bin Zhao, Junchi Yan, Xiu Li, Xuelong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Decentralized Transformers with Centralized Aggregation are Sample-Efficient Multi-Agent World Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Learning a world model for model-free Reinforcement Learning (RL) agents can significantly improve the sample efficiency by learning policies in imagination. However, building a world model for Multi-Agent RL (MARL) can be particularly challenging due to the scalability issue in a centralized architecture arising from a large number of agents, and also the non-stationarity issue in a decentralized architecture stemming from the inter-dependency among agents. To address both challenges, we propose a novel world model for MARL that learns decentralized local dynamics for scalability, combined with a centralized representation aggregation from all agents. We cast the dynamics learning as an auto-regressive sequence modeling problem over discrete tokens by leveraging the expressive Transformer architecture, in order to model complex local dynamics across different agents and provide accurate and consistent long-term imaginations. As the first pioneering Transformer-based world model for multi-agent systems, we introduce a Perceiver Transformer as an effective solution to enable centralized representation aggregation within this context. Results on Starcraft Multi-Agent Challenge (SMAC) show that it outperforms strong model-free approaches and existing model-based methods in both sample efficiency and overall performance.</li>
</ul>

<h3>Title: Title:
          The Effect of Similarity Measures on Accurate Stability Estimates for Local Surrogate Models in Text-based Explainable AI</h3>
<ul>
<li><strong>Authors: </strong>Christopher Burger, Charles Walter, Thai Le</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          The Effect of Similarity Measures on Accurate Stability Estimates for Local Surrogate Models in Text-based Explainable AI(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Recent work has investigated the vulnerability of local surrogate methods to adversarial perturbations on a machine learning (ML) model's inputs, where the explanation is manipulated while the meaning and structure of the original input remains similar under the complex model. While weaknesses across many methods have been shown to exist, the reasons behind why still remain little explored. Central to the concept of adversarial attacks on explainable AI (XAI) is the similarity measure used to calculate how one explanation differs from another A poor choice of similarity measure can result in erroneous conclusions on the efficacy of an XAI method. Too sensitive a measure results in exaggerated vulnerability, while too coarse understates its weakness. We investigate a variety of similarity measures designed for text-based ranked lists including Kendall's Tau, Spearman's Footrule and Rank-biased Overlap to determine how substantial changes in the type of measure or threshold of success affect the conclusions generated from common adversarial attack processes. Certain measures are found to be overly sensitive, resulting in erroneous estimates of stability.</li>
</ul>

<h3>Title: Title:
          Revisiting Interpolation Augmentation for Speech-to-Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Chen Xu, Jie Wang, Xiaoqian Liu, Qianqian Dong, Chunliang Zhang, Tong Xiao, Jingbo Zhu, Dapeng Man, Wu Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Revisiting Interpolation Augmentation for Speech-to-Text Generation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Speech-to-text (S2T) generation systems frequently face challenges in low-resource scenarios, primarily due to the lack of extensive labeled datasets. One emerging solution is constructing virtual training samples by interpolating inputs and labels, which has notably enhanced system generalization in other domains. Despite its potential, this technique's application in S2T tasks has remained under-explored. In this paper, we delve into the utility of interpolation augmentation, guided by several pivotal questions. Our findings reveal that employing an appropriate strategy in interpolation augmentation significantly enhances performance across diverse tasks, architectures, and data scales, offering a promising avenue for more robust S2T systems in resource-constrained settings.</li>
</ul>

<h3>Title: Title:
          EmoAttack: Emotion-to-Image Diffusion Models for Emotional Backdoor Generation</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Wei, Shanmin Pang, Qi Guo, Yizhuo Ma, Qing Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          EmoAttack: Emotion-to-Image Diffusion Models for Emotional Backdoor Generation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models can create realistic images based on input texts. Users can describe an object to convey their opinions visually. In this work, we unveil a previously unrecognized and latent risk of using diffusion models to generate images; we utilize emotion in the input texts to introduce negative contents, potentially eliciting unfavorable emotions in users. Emotions play a crucial role in expressing personal opinions in our daily interactions, and the inclusion of maliciously negative content can lead users astray, exacerbating negative emotions. Specifically, we identify the emotion-aware backdoor attack (EmoAttack) that can incorporate malicious negative content triggered by emotional texts during image generation. We formulate such an attack as a diffusion personalization problem to avoid extensive model retraining and propose the EmoBooth. Unlike existing personalization methods, our approach fine-tunes a pre-trained diffusion model by establishing a mapping between a cluster of emotional words and a given reference image containing malicious negative content. To validate the effectiveness of our method, we built a dataset and conducted extensive analysis and discussion about its effectiveness. Given consumers' widespread use of diffusion models, uncovering this threat is critical for society.</li>
</ul>

<h3>Title: Title:
          DISHA: Low-Energy Sparse Transformer at Edge for Outdoor Navigation for the Visually Impaired Individuals</h3>
<ul>
<li><strong>Authors: </strong>Praveen Nagil, Sumit K. Mandal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          DISHA: Low-Energy Sparse Transformer at Edge for Outdoor Navigation for the Visually Impaired Individuals(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Assistive technology for visually impaired individuals is extremely useful to make them independent of another human being in performing day-to-day chores and instill confidence in them. One of the important aspects of assistive technology is outdoor navigation for visually impaired people. While there exist several techniques for outdoor navigation in the literature, they are mainly limited to obstacle detection. However, navigating a visually impaired person through the sidewalk (while the person is walking outside) is important too. Moreover, the assistive technology should ensure low-energy operation to extend the battery life of the device. Therefore, in this work, we propose an end-to-end technology deployed on an edge device to assist visually impaired people. Specifically, we propose a novel pruning technique for transformer algorithm which detects sidewalk. The pruning technique ensures low latency of execution and low energy consumption when the pruned transformer algorithm is deployed on the edge device. Extensive experimental evaluation shows that our proposed technology provides up to 32.49% improvement in accuracy and 1.4 hours of extension in battery life with respect to a baseline technique.</li>
</ul>

<h3>Title: Title:
          On MDS Property of g-Circulant Matrices</h3>
<ul>
<li><strong>Authors: </strong>Tapas Chatterjee, Ayantika Laha</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          On MDS Property of g-Circulant Matrices(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Circulant Maximum Distance Separable (MDS) matrices have gained significant importance due to their applications in the diffusion layer of the AES block cipher. In $2013$, Gupta and Ray established that circulant involutory matrices of order greater than $3$ cannot be MDS. This finding prompted a generalization of circulant matrices and the involutory property of matrices by various authors. In $2016$, Liu and Sim introduced cyclic matrices by changing the permutation of circulant matrices. In $1961,$ Friedman introduced $g$-circulant matrices which form a subclass of cyclic matrices. In this article, we first discuss $g$-circulant matrices with involutory and MDS properties. We prove that $g$-circulant involutory matrices of order $k \times k$ cannot be MDS unless $g \equiv -1 \pmod k.$ Next, we delve into $g$-circulant semi-involutory and semi-orthogonal matrices with entries from finite fields. We establish that the $k$-th power of the associated diagonal matrices of a $g$-circulant semi-orthogonal (semi-involutory) matrix of order $k \times k$ results in a scalar matrix. These findings can be viewed as an extension of the results concerning circulant matrices established by Chatterjee {\it{et al.}} in $2022.$</li>
</ul>

<h3>Title: Title:
          Fast Tree-Field Integrators: From Low Displacement Rank to Topological Transformers</h3>
<ul>
<li><strong>Authors: </strong>Krzysztof Choromanski, Arijit Sehanobish, Somnath Basu Roy Chowdhury, Han Lin, Avinava Dubey, Tamas Sarlos, Snigdha Chaturvedi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Fast Tree-Field Integrators: From Low Displacement Rank to Topological Transformers(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a new class of fast polylog-linear algorithms based on the theory of structured matrices (in particular low displacement rank) for integrating tensor fields defined on weighted trees. Several applications of the resulting fast tree-field integrators (FTFIs) are presented, including (a) approximation of graph metrics with tree metrics, (b) graph classification, (c) modeling on meshes, and finally (d) Topological Transformers (TTs) (Choromanski et al., 2022) for images. For Topological Transformers, we propose new relative position encoding (RPE) masking mechanisms with as few as three extra learnable parameters per Transformer layer, leading to 1.0-1.5%+ accuracy gains. Importantly, most of FTFIs are exact methods, thus numerically equivalent to their brute-force counterparts. When applied to graphs with thousands of nodes, those exact algorithms provide 5.7-13x speedups. We also provide an extensive theoretical analysis of our methods.</li>
</ul>

<h3>Title: Title:
          SimSMoE: Solving Representational Collapse via Similarity Measure</h3>
<ul>
<li><strong>Authors: </strong>Giang Do, Hung Le, Truyen Tran</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          SimSMoE: Solving Representational Collapse via Similarity Measure(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Sparse mixture of experts (SMoE) have emerged as an effective approach for scaling large language models while keeping a constant computational cost. Regardless of several notable successes of SMoE, effective training such architecture remains elusive due to the representation collapse problem, which in turn harms model performance and causes parameter redundancy. In this work, we present Similarity-based Sparse Mixture of Experts (SimSMoE), a novel similarity of neural network algorithm, that guarantees a solution to address the representation collapse issue between experts given a fixed FLOPs budget. We conduct extensive empirical evaluations on three large language models for both Pre-training and Fine-tuning tasks to illustrate the efficacy, robustness, and scalability of our method. The results demonstrate that SimSMoE significantly enhances existing routing policy and outperforms other SMoE training methods in performance for the tasks.</li>
</ul>

<h3>Title: Title:
          Language Alignment via Nash-learning and Adaptive feedback</h3>
<ul>
<li><strong>Authors: </strong>Ari Azarafrooz, Farshid Faal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Language Alignment via Nash-learning and Adaptive feedback(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent research has shown the potential of Nash Learning via Human Feedback for large language model alignment by incorporating the notion of a preference model in a minimax game setup. We take this idea further by casting the alignment as a mirror descent algorithm against the adaptive feedback of an improved opponent, thereby removing the need for learning a preference model or the existence of an annotated dataset altogether. The resulting algorithm, which we refer to as Language Alignment via Nash-learning and Adaptive feedback (LANA), is capable of self-alignment without the need for a human-annotated preference dataset. We support this statement with various experiments and mathematical discussion.</li>
</ul>

<h3>Title: Title:
          The Unlikely Duel: Evaluating Creative Writing in LLMs through a Unique Scenario</h3>
<ul>
<li><strong>Authors: </strong>Carlos Gómez-Rodríguez, Paul Williams</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          The Unlikely Duel: Evaluating Creative Writing in LLMs through a Unique Scenario(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This is a summary of the paper "A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative Writing", which was published in Findings of EMNLP 2023. We evaluate a range of recent state-of-the-art, instruction-tuned large language models (LLMs) on an English creative writing task, and compare them to human writers. For this purpose, we use a specifically-tailored prompt (based on an epic combat between Ignatius J. Reilly, main character of John Kennedy Toole's "A Confederacy of Dunces", and a pterodactyl) to minimize the risk of training data leakage and force the models to be creative rather than reusing existing stories. The same prompt is presented to LLMs and human writers, and evaluation is performed by humans using a detailed rubric including various aspects like fluency, style, originality or humor. Results show that some state-of-the-art commercial LLMs match or slightly outperform our human writers in most of the evaluated dimensions. Open-source LLMs lag behind. Humans keep a close lead in originality, and only the top three LLMs can handle humor at human-like levels.</li>
</ul>

<h3>Title: Title:
          Soft Masked Mamba Diffusion Model for CT to MRI Conversion</h3>
<ul>
<li><strong>Authors: </strong>Zhenbin Wang, Lei Zhang, Lituan Wang, Zhenwei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Soft Masked Mamba Diffusion Model for CT to MRI Conversion(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) are the predominant modalities utilized in the field of medical imaging. Although MRI capture the complexity of anatomical structures with greater detail than CT, it entails a higher financial costs and requires longer image acquisition times. In this study, we aim to train latent diffusion model for CT to MRI conversion, replacing the commonly-used U-Net or Transformer backbone with a State-Space Model (SSM) called Mamba that operates on latent patches. First, we noted critical oversights in the scan scheme of most Mamba-based vision methods, including inadequate attention to the spatial continuity of patch tokens and the lack of consideration for their varying importance to the target task. Secondly, extending from this insight, we introduce Diffusion Mamba (DiffMa), employing soft masked to integrate Cross-Sequence Attention into Mamba and conducting selective scan in a spiral manner. Lastly, extensive experiments demonstrate impressive performance by DiffMa in medical image generation tasks, with notable advantages in input scaling efficiency over existing benchmark models. The code and models are available at this https URL</li>
</ul>

<h3>Title: Title:
          Credit Attribution and Stable Compression</h3>
<ul>
<li><strong>Authors: </strong>Roi Livni, Shay Moran, Kobbi Nissim, Chirag Pabbaraju</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Credit Attribution and Stable Compression(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative</a></li>
<li><strong>Abstract: </strong>Credit attribution is crucial across various fields. In academic research, proper citation acknowledges prior work and establishes original contributions. Similarly, in generative models, such as those trained on existing artworks or music, it is important to ensure that any generated content influenced by these works appropriately credits the original creators. We study credit attribution by machine learning algorithms. We propose new definitions--relaxations of Differential Privacy--that weaken the stability guarantees for a designated subset of $k$ datapoints. These $k$ datapoints can be used non-stably with permission from their owners, potentially in exchange for compensation. Meanwhile, the remaining datapoints are guaranteed to have no significant influence on the algorithm's output. Our framework extends well-studied notions of stability, including Differential Privacy ($k = 0$), differentially private learning with public data (where the $k$ public datapoints are fixed in advance), and stable sample compression (where the $k$ datapoints are selected adaptively by the algorithm). We examine the expressive power of these stability notions within the PAC learning framework, provide a comprehensive characterization of learnability for algorithms adhering to these principles, and propose directions and questions for future research.</li>
</ul>

<h3>Title: Title:
          DISentangled Counterfactual Visual interpretER (DISCOVER) generalizes to natural images</h3>
<ul>
<li><strong>Authors: </strong>Oded Rotem, Assaf Zaritsky</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          DISentangled Counterfactual Visual interpretER (DISCOVER) generalizes to natural images(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We recently presented DISentangled COunterfactual Visual interpretER (DISCOVER), a method toward systematic visual interpretability of image-based classification models and demonstrated its applicability to two biomedical domains. Here we demonstrate that DISCOVER can be applied to the domain of natural images. First, DISCOVER visually interpreted the nose size, the muzzle area, and the face size as semantic discriminative visual traits discriminating between facial images of dogs versus cats. Second, DISCOVER visually interpreted the cheeks and jawline, eyebrows and hair, and the eyes, as discriminative facial characteristics. These successful visual interpretations across two natural images domains indicate that DISCOVER is a generalized interpretability method.</li>
</ul>

<h3>Title: Title:
          PUDD: Towards Robust Multi-modal Prototype-based Deepfake Detection</h3>
<ul>
<li><strong>Authors: </strong>Alvaro Lopez Pellcier, Yi Li, Plamen Angelov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          PUDD: Towards Robust Multi-modal Prototype-based Deepfake Detection(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Deepfake techniques generate highly realistic data, making it challenging for humans to discern between actual and artificially generated images. Recent advancements in deep learning-based deepfake detection methods, particularly with diffusion models, have shown remarkable progress. However, there is a growing demand for real-world applications to detect unseen individuals, deepfake techniques, and scenarios. To address this limitation, we propose a Prototype-based Unified Framework for Deepfake Detection (PUDD). PUDD offers a detection system based on similarity, comparing input data against known prototypes for video classification and identifying potential deepfakes or previously unseen classes by analyzing drops in similarity. Our extensive experiments reveal three key findings: (1) PUDD achieves an accuracy of 95.1% on Celeb-DF, outperforming state-of-the-art deepfake detection methods; (2) PUDD leverages image classification as the upstream task during training, demonstrating promising performance in both image classification and deepfake detection tasks during inference; (3) PUDD requires only 2.7 seconds for retraining on new data and emits 10$^{5}$ times less carbon compared to the state-of-the-art model, making it significantly more environmentally friendly.</li>
</ul>

<h3>Title: Title:
          Federated Adversarial Learning for Robust Autonomous Landing Runway Detection</h3>
<ul>
<li><strong>Authors: </strong>Yi Li, Plamen Angelov, Zhengxin Yu, Alvaro Lopez Pellicer, Neeraj Suri</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Federated Adversarial Learning for Robust Autonomous Landing Runway Detection(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>As the development of deep learning techniques in autonomous landing systems continues to grow, one of the major challenges is trust and security in the face of possible adversarial attacks. In this paper, we propose a federated adversarial learning-based framework to detect landing runways using paired data comprising of clean local data and its adversarial version. Firstly, the local model is pre-trained on a large-scale lane detection dataset. Then, instead of exploiting large instance-adaptive models, we resort to a parameter-efficient fine-tuning method known as scale and shift deep features (SSF), upon the pre-trained model. Secondly, in each SSF layer, distributions of clean local data and its adversarial version are disentangled for accurate statistics estimation. To the best of our knowledge, this marks the first instance of federated learning work that address the adversarial sample problem in landing runway detection. Our experimental evaluations over both synthesis and real images of Landing Approach Runway Detection (LARD) dataset consistently demonstrate good performance of the proposed federated adversarial learning and robust to adversarial attacks.</li>
</ul>

<h3>Title: Title:
          Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jannik Kossen, Jiatong Han, Muhammed Razzak, Lisa Schut, Shreshth Malik, Yarin Gal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We propose semantic entropy probes (SEPs), a cheap and reliable method for uncertainty quantification in Large Language Models (LLMs). Hallucinations, which are plausible-sounding but factually incorrect and arbitrary model generations, present a major challenge to the practical adoption of LLMs. Recent work by Farquhar et al. (2024) proposes semantic entropy (SE), which can detect hallucinations by estimating uncertainty in the space semantic meaning for a set of model generations. However, the 5-to-10-fold increase in computation cost associated with SE computation hinders practical adoption. To address this, we propose SEPs, which directly approximate SE from the hidden states of a single generation. SEPs are simple to train and do not require sampling multiple model generations at test time, reducing the overhead of semantic uncertainty quantification to almost zero. We show that SEPs retain high performance for hallucination detection and generalize better to out-of-distribution data than previous probing methods that directly predict model accuracy. Our results across models and tasks suggest that model hidden states capture SE, and our ablation studies give further insights into the token positions and model layers for which this is the case.</li>
</ul>

<h3>Title: Title:
          RuleR: Improving LLM Controllability by Rule-based Data Recycling</h3>
<ul>
<li><strong>Authors: </strong>Ming Li, Han Chen, Chenguang Wang, Dang Nguyen, Dianqi Li, Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          RuleR: Improving LLM Controllability by Rule-based Data Recycling(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) still lack delicate controllability over their responses, which is critical to enhancing their performance and the user experience. However, curating supervised fine-tuning (SFT) datasets to improve LLM controllability usually relies on human experts or proprietary LLMs, which requires additional costs. To bridge this gap, we propose Rule-based Data Recycling (RuleR), a data augmentation method incorporating multiple constraints into the original data samples according to predefined rules, which creates new training tasks to consolidate the controllability of LLMs. Instead of creating new data from scratch, RuleR ``recycles'' existing data by simply applying rule-based edits to their responses and appending the rule-instructions in their original instructions. Experimental results demonstrate RuleR's effectiveness in improving LLM controllability while maintaining general instruction-following capabilities. The code will be released on this https URL.</li>
</ul>

<h3>Title: Title:
          Beyond Individual Facts: Investigating Categorical Knowledge Locality of Taxonomy and Meronomy Concepts in GPT Models</h3>
<ul>
<li><strong>Authors: </strong>Christopher Burger, Yifan Hu, Thai Le</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Beyond Individual Facts: Investigating Categorical Knowledge Locality of Taxonomy and Meronomy Concepts in GPT Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>The location of knowledge within Generative Pre-trained Transformer (GPT)-like models has seen extensive recent investigation. However, much of the work is focused towards determining locations of individual facts, with the end goal being the editing of facts that are outdated, erroneous, or otherwise harmful, without the time and expense of retraining the entire model. In this work, we investigate a broader view of knowledge location, that of concepts or clusters of related information, instead of disparate individual facts. To do this, we first curate a novel dataset, called DARC, that includes a total of 34 concepts of ~120K factual statements divided into two types of hierarchical categories, namely taxonomy and meronomy. Next, we utilize existing causal mediation analysis methods developed for determining regions of importance for individual facts and apply them to a series of related categories to provide detailed investigation into whether concepts are associated with distinct regions within these models. We find that related categories exhibit similar areas of importance in contrast to less similar categories. However, fine-grained localization of individual category subsets to specific regions is not apparent.</li>
</ul>

<h3>Title: Title:
          Towards Exact Computation of Inductive Bias</h3>
<ul>
<li><strong>Authors: </strong>Akhilan Boopathy, William Yue, Jaedong Hwang, Abhiram Iyer, Ila Fiete</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Towards Exact Computation of Inductive Bias(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Much research in machine learning involves finding appropriate inductive biases (e.g. convolutional neural networks, momentum-based optimizers, transformers) to promote generalization on tasks. However, quantification of the amount of inductive bias associated with these architectures and hyperparameters has been limited. We propose a novel method for efficiently computing the inductive bias required for generalization on a task with a fixed training data budget; formally, this corresponds to the amount of information required to specify well-generalizing models within a specific hypothesis space of models. Our approach involves modeling the loss distribution of random hypotheses drawn from a hypothesis space to estimate the required inductive bias for a task relative to these hypotheses. Unlike prior work, our method provides a direct estimate of inductive bias without using bounds and is applicable to diverse hypothesis spaces. Moreover, we derive approximation error bounds for our estimation approach in terms of the number of sampled hypotheses. Consistent with prior results, our empirical results demonstrate that higher dimensional tasks require greater inductive bias. We show that relative to other expressive model classes, neural networks as a model class encode large amounts of inductive bias. Furthermore, our measure quantifies the relative difference in inductive bias between different neural network architectures. Our proposed inductive bias metric provides an information-theoretic interpretation of the benefits of specific model architectures for certain tasks and provides a quantitative guide to developing tasks requiring greater inductive bias, thereby encouraging the development of more powerful inductive biases.</li>
</ul>

<h3>Title: Title:
          LaneSegNet Design Study</h3>
<ul>
<li><strong>Authors: </strong>William Stevens, Vishal Urs, Karthik Selvaraj, Gabriel Torres, Gaurish Lakhanpal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          LaneSegNet Design Study(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>With the increasing prevalence of autonomous vehicles, it is essential for computer vision algorithms to accurately assess road features in real-time. This study explores the LaneSegNet architecture, a new approach to lane topology prediction which integrates topological information with lane-line data to provide a more contextual understanding of road environments. The LaneSegNet architecture includes a feature extractor, lane encoder, lane decoder, and prediction head, leveraging components from ResNet-50, BEVFormer, and various attention mechanisms. We experimented with optimizations to the LaneSegNet architecture through feature extractor modification and transformer encoder-decoder stack modification. We found that modifying the encoder and decoder stacks offered an interesting tradeoff between training time and prediction accuracy, with certain combinations showing promising results. Our implementation, trained on a single NVIDIA Tesla A100 GPU, found that a 2:4 ratio reduced training time by 22.3% with only a 7.1% drop in mean average precision, while a 4:8 ratio increased training time by only 11.1% but improved mean average precision by a significant 23.7%. These results indicate that strategic hyperparameter tuning can yield substantial improvements depending on the resources of the user. This study provides valuable insights for optimizing LaneSegNet according to available computation power, making it more accessible for users with limited resources and increasing the capabilities for users with more powerful resources.</li>
</ul>

<h3>Title: Title:
          Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Shangbin Feng, Taylor Sorensen, Yuhan Liu, Jillian Fisher, Chan Young Park, Yejin Choi, Yulia Tsvetkov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While existing alignment paradigms have been integral in developing large language models (LLMs), LLMs often learn an averaged human preference and struggle to model diverse preferences across cultures, demographics, and communities. We propose Modular Pluralism, a modular framework based on multi-LLM collaboration for pluralistic alignment: it "plugs into" a base LLM a pool of smaller but specialized community LMs, where models collaborate in distinct modes to flexibility support three modes of pluralism: Overton, steerable, and distributional. Modular Pluralism is uniquely compatible with black-box LLMs and offers the modular control of adding new community LMs for previously underrepresented communities. We evaluate Modular Pluralism with six tasks and four datasets featuring questions/instructions with value-laden and perspective-informed responses. Extensive experiments demonstrate that Modular Pluralism advances the three pluralism objectives across six black-box and open-source LLMs. Further analysis reveals that LLMs are generally faithful to the inputs from smaller community LLMs, allowing seamless patching by adding a new community LM to better cover previously underrepresented communities.</li>
</ul>

<h3>Title: Title:
          Beyond the Doors of Perception: Vision Transformers Represent Relations Between Objects</h3>
<ul>
<li><strong>Authors: </strong>Michael A. Lepori, Alexa R. Tartaglini, Wai Keen Vong, Thomas Serre, Brenden M. Lake, Ellie Pavlick</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Beyond the Doors of Perception: Vision Transformers Represent Relations Between Objects(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Though vision transformers (ViTs) have achieved state-of-the-art performance in a variety of settings, they exhibit surprising failures when performing tasks involving visual relations. This begs the question: how do ViTs attempt to perform tasks that require computing visual relations between objects? Prior efforts to interpret ViTs tend to focus on characterizing relevant low-level visual features. In contrast, we adopt methods from mechanistic interpretability to study the higher-level visual algorithms that ViTs use to perform abstract visual reasoning. We present a case study of a fundamental, yet surprisingly difficult, relational reasoning task: judging whether two visual entities are the same or different. We find that pretrained ViTs fine-tuned on this task often exhibit two qualitatively different stages of processing despite having no obvious inductive biases to do so: 1) a perceptual stage wherein local object features are extracted and stored in a disentangled representation, and 2) a relational stage wherein object representations are compared. In the second stage, we find evidence that ViTs can learn to represent somewhat abstract visual relations, a capability that has long been considered out of reach for artificial neural networks. Finally, we demonstrate that failure points at either stage can prevent a model from learning a generalizable solution to our fairly simple tasks. By understanding ViTs in terms of discrete processing stages, one can more precisely diagnose and rectify shortcomings of existing and future models.</li>
</ul>

<h3>Title: Title:
          Fair Clustering: Critique, Caveats, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>John Dickerson, Seyed A. Esmaeili, Jamie Morgenstern, Claire Jie Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Fair Clustering: Critique, Caveats, and Future Directions(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Clustering is a fundamental problem in machine learning and operations research. Therefore, given the fact that fairness considerations have become of paramount importance in algorithm design, fairness in clustering has received significant attention from the research community. The literature on fair clustering has resulted in a collection of interesting fairness notions and elaborate algorithms. In this paper, we take a critical view of fair clustering, identifying a collection of ignored issues such as the lack of a clear utility characterization and the difficulty in accounting for the downstream effects of a fair clustering algorithm in machine learning settings. In some cases, we demonstrate examples where the application of a fair clustering algorithm can have significant negative impacts on social welfare. We end by identifying a collection of steps that would lead towards more impactful research in fair clustering.</li>
</ul>

<h3>Title: Title:
          Privacy Preserving Machine Learning for Electronic Health Records using Federated Learning and Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Naif A. Ganadily, Han J. Xia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Privacy Preserving Machine Learning for Electronic Health Records using Federated Learning and Differential Privacy(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>An Electronic Health Record (EHR) is an electronic database used by healthcare providers to store patients' medical records which may include diagnoses, treatments, costs, and other personal information. Machine learning (ML) algorithms can be used to extract and analyze patient data to improve patient care. Patient records contain highly sensitive information, such as social security numbers (SSNs) and residential addresses, which introduces a need to apply privacy-preserving techniques for these ML models using federated learning and differential privacy.</li>
</ul>

<h3>Title: Title:
          Evaluating the Effectiveness of the Foundational Models for Q&A Classification in Mental Health care</h3>
<ul>
<li><strong>Authors: </strong>Hassan Alhuzali, Ashwag Alasmari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Evaluating the Effectiveness of the Foundational Models for Q&A Classification in Mental Health care(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Pre-trained Language Models (PLMs) have the potential to transform mental health support by providing accessible and culturally sensitive resources. However, despite this potential, their effectiveness in mental health care and specifically for the Arabic language has not been extensively explored. To bridge this gap, this study evaluates the effectiveness of foundational models for classification of Questions and Answers (Q&A) in the domain of mental health care. We leverage the MentalQA dataset, an Arabic collection featuring Q&A interactions related to mental health. In this study, we conducted experiments using four different types of learning approaches: traditional feature extraction, PLMs as feature extractors, Fine-tuning PLMs and prompting large language models (GPT-3.5 and GPT-4) in zero-shot and few-shot learning settings. While traditional feature extractors combined with Support Vector Machines (SVM) showed promising performance, PLMs exhibited even better results due to their ability to capture semantic meaning. For example, MARBERT achieved the highest performance with a Jaccard Score of 0.80 for question classification and a Jaccard Score of 0.86 for answer classification. We further conducted an in-depth analysis including examining the effects of fine-tuning versus non-fine-tuning, the impact of varying data size, and conducting error analysis. Our analysis demonstrates that fine-tuning proved to be beneficial for enhancing the performance of PLMs, and the size of the training data played a crucial role in achieving high performance. We also explored prompting, where few-shot learning with GPT-3.5 yielded promising results. There was an improvement of 12% for question and classification and 45% for answer classification. Based on our findings, it can be concluded that PLMs and prompt-based approaches hold promise for mental health support in Arabic.</li>
</ul>

<h3>Title: Title:
          ReCaLL: Membership Inference via Relative Conditional Log-Likelihoods</h3>
<ul>
<li><strong>Authors: </strong>Roy Xie, Junlin Wang, Ruomin Huang, Minxing Zhang, Rong Ge, Jian Pei, Neil Zhenqiang Gong, Bhuwan Dhingra</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          ReCaLL: Membership Inference via Relative Conditional Log-Likelihoods(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, membership infer, fair, large language model</a></li>
<li><strong>Abstract: </strong>The rapid scaling of large language models (LLMs) has raised concerns about the transparency and fair use of the pretraining data used for training them. Detecting such content is challenging due to the scale of the data and limited exposure of each instance during training. We propose ReCaLL (Relative Conditional Log-Likelihood), a novel membership inference attack (MIA) to detect LLMs' pretraining data by leveraging their conditional language modeling capabilities. ReCaLL examines the relative change in conditional log-likelihoods when prefixing target data points with non-member context. Our empirical findings show that conditioning member data on non-member prefixes induces a larger decrease in log-likelihood compared to non-member data. We conduct comprehensive experiments and show that ReCaLL achieves state-of-the-art performance on the WikiMIA dataset, even with random and synthetic prefixes, and can be further improved using an ensemble approach. Moreover, we conduct an in-depth analysis of LLMs' behavior with different membership contexts, providing insights into how LLMs leverage membership information for effective inference at both the sequence and token level.</li>
</ul>

<h3>Title: Title:
          EVCL: Elastic Variational Continual Learning with Weight Consolidation</h3>
<ul>
<li><strong>Authors: </strong>Hunar Batra, Ronald Clark</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          EVCL: Elastic Variational Continual Learning with Weight Consolidation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Continual learning aims to allow models to learn new tasks without forgetting what has been learned before. This work introduces Elastic Variational Continual Learning with Weight Consolidation (EVCL), a novel hybrid model that integrates the variational posterior approximation mechanism of Variational Continual Learning (VCL) with the regularization-based parameter-protection strategy of Elastic Weight Consolidation (EWC). By combining the strengths of both methods, EVCL effectively mitigates catastrophic forgetting and enables better capture of dependencies between model parameters and task-specific data. Evaluated on five discriminative tasks, EVCL consistently outperforms existing baselines in both domain-incremental and task-incremental learning scenarios for deep discriminative models.</li>
</ul>

<h3>Title: Title:
          Serial Position Effects of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaobo Guo, Soroush Vosoughi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Serial Position Effects of Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable capabilities in zero-shot learning applications, generating responses to queries using only pre-training information without the need for additional fine-tuning. This represents a significant departure from traditional machine learning approaches. Previous research has indicated that LLMs may exhibit serial position effects, such as primacy and recency biases, which are well-documented cognitive biases in human psychology. Our extensive testing across various tasks and models confirms the widespread occurrence of these effects, although their intensity varies. We also discovered that while carefully designed prompts can somewhat mitigate these biases, their effectiveness is inconsistent. These findings underscore the significance of serial position effects during the inference process, particularly in scenarios where there are no ground truth labels, highlighting the need for greater focus on addressing these effects in LLM applications.</li>
</ul>

<h3>Title: Title:
          Learning with Noisy Ground Truth: From 2D Classification to 3D Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Yangdi Lu, Wenbo He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Learning with Noisy Ground Truth: From 2D Classification to 3D Reconstruction(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep neural networks has been highly successful in data-intense computer vision applications, while such success relies heavily on the massive and clean data. In real-world scenarios, clean data sometimes is difficult to obtain. For example, in image classification and segmentation tasks, precise annotations of millions samples are generally very expensive and time-consuming. In 3D static scene reconstruction task, most NeRF related methods require the foundational assumption of the static scene (e.g. consistent lighting condition and persistent object positions), which is often violated in real-world scenarios. To address these problem, learning with noisy ground truth (LNGT) has emerged as an effective learning method and shows great potential. In this short survey, we propose a formal definition unify the analysis of LNGT LNGT in the context of different machine learning tasks (classification and regression). Based on this definition, we propose a novel taxonomy to classify the existing work according to the error decomposition with the fundamental definition of machine learning. Further, we provide in-depth analysis on memorization effect and insightful discussion about potential future research opportunities from 2D classification to 3D reconstruction, in the hope of providing guidance to follow-up research.</li>
</ul>

<h3>Title: Title:
          Can LLM Graph Reasoning Generalize beyond Pattern Memorization?</h3>
<ul>
<li><strong>Authors: </strong>Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, Yulia Tsvetkov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Can LLM Graph Reasoning Generalize beyond Pattern Memorization?(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) demonstrate great potential for problems with implicit graphical structures, while recent works seek to enhance the graph reasoning capabilities of LLMs through specialized instruction tuning. The resulting 'graph LLMs' are evaluated with in-distribution settings only, thus it remains underexplored whether LLMs are learning generalizable graph reasoning skills or merely memorizing patterns in the synthetic training data. To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph reasoning generalization: whether LLMs could go beyond semantic, numeric, structural, reasoning patterns in the synthetic training data and improve utility on real-world graph-based tasks. Extensive experiments with two LLMs across four graph reasoning tasks demonstrate that while generalization on simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to generalize across reasoning and real-world patterns, casting doubt on the benefit of synthetic graph tuning for real-world tasks with underlying network structures. We explore three strategies to improve LLM graph reasoning generalization, and we find that while post-training alignment is most promising for real-world tasks, empowering LLM graph reasoning to go beyond pattern memorization remains an open research question.</li>
</ul>

<h3>Title: Title:
          Memorizing Documents with Guidance in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Bumjin Park, Jaesik Choi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Memorizing Documents with Guidance in Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training data plays a pivotal role in AI models. Large language models (LLMs) are trained with massive amounts of documents, and their parameters hold document-related contents. Recently, several studies identified content-specific locations in LLMs by examining the parameters. Instead of the post hoc interpretation, we propose another approach. We propose document-wise memory architecture to track document memories in training. The proposed architecture maps document representations to memory entries, which softly mask memories in the forward process of LLMs. Additionally, we propose document guidance loss, which increases the likelihood of text with document memories and reduces the likelihood of the text with the memories of other documents. Experimental results on Wikitext-103-v1 with Pythia-1B show that the proposed methods provide different memory entries for documents and high recall of document-related content in generation with trained document-wise memories.</li>
</ul>

<h3>Title: Title:
          RepNeXt: A Fast Multi-Scale CNN using Structural Reparameterization</h3>
<ul>
<li><strong>Authors: </strong>Mingshu Zhao, Yi Luo, Yong Ouyang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          RepNeXt: A Fast Multi-Scale CNN using Structural Reparameterization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In the realm of resource-constrained mobile vision tasks, the pursuit of efficiency and performance consistently drives innovation in lightweight Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). While ViTs excel at capturing global context through self-attention mechanisms, their deployment in resource-limited environments is hindered by computational complexity and latency. Conversely, lightweight CNNs are favored for their parameter efficiency and low latency. This study investigates the complementary advantages of CNNs and ViTs to develop a versatile vision backbone tailored for resource-constrained applications. We introduce RepNeXt, a novel model series integrates multi-scale feature representations and incorporates both serial and parallel structural reparameterization (SRP) to enhance network depth and width without compromising inference speed. Extensive experiments demonstrate RepNeXt's superiority over current leading lightweight CNNs and ViTs, providing advantageous latency across various vision benchmarks. RepNeXt-M4 matches RepViT-M1.5's 82.3\% accuracy on ImageNet within 1.5ms on an iPhone 12, outperforms its AP$^{box}$ by 1.1 on MS-COCO, and reduces parameters by 0.7M. Codes and models are available at this https URL.</li>
</ul>

<h3>Title: Title:
          Distributed Rule Vectors is A Key Mechanism in Large Language Models' In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Bowen Zheng, Ming Ma, Zhongqiao Lin, Tianming Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Distributed Rule Vectors is A Key Mechanism in Large Language Models' In-Context Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable abilities, one of the most important being In-Context Learning (ICL). With ICL, LLMs can derive the underlying rule from a few demonstrations and provide answers that comply with the rule. Previous work hypothesized that the network creates a "task vector" in specific positions during ICL. Patching the "task vector" allows LLMs to achieve zero-shot performance similar to few-shot learning. However, we discover that such "task vectors" do not exist in tasks where the rule has to be defined through multiple demonstrations. Instead, the rule information provided by each demonstration is first transmitted to its answer position and forms its own rule vector. Importantly, all the rule vectors contribute to the output in a distributed manner. We further show that the rule vectors encode a high-level abstraction of rules extracted from the demonstrations. These results are further validated in a series of tasks that rely on rules dependent on multiple demonstrations. Our study provides novel insights into the mechanism underlying ICL in LLMs, demonstrating how ICL may be achieved through an information aggregation mechanism.</li>
</ul>

<h3>Title: Title:
          Found in the Middle: Calibrating Positional Attention Bias Improves Long Context Utilization</h3>
<ul>
<li><strong>Authors: </strong>Cheng-Yu Hsieh, Yung-Sung Chuang, Chun-Liang Li, Zifeng Wang, Long T. Le, Abhishek Kumar, James Glass, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Found in the Middle: Calibrating Positional Attention Bias Improves Long Context Utilization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), even when specifically trained to process long input contexts, struggle to capture relevant information located in the middle of their input. This phenomenon has been known as the lost-in-the-middle problem. In this work, we make three contributions. First, we set out to understand the factors that cause this phenomenon. In doing so, we establish a connection between lost-in-the-middle to LLMs' intrinsic attention bias: LLMs exhibit a U-shaped attention bias where the tokens at the beginning and at the end of its input receive higher attention, regardless of their relevance. Second, we mitigate this positional bias through a calibration mechanism, found-in-the-middle, that allows the model to attend to contexts faithfully according to their relevance, even though when they are in the middle. Third, we show found-in-the-middle not only achieves better performance in locating relevant information within a long context, but also eventually leads to improved retrieval-augmented generation (RAG) performance across various tasks, outperforming existing methods by up to 15 percentage points. These findings open up future directions in understanding LLM attention bias and its potential consequences.</li>
</ul>

<h3>Title: Title:
          Harvesting Events from Multiple Sources: Towards a Cross-Document Event Extraction Paradigm</h3>
<ul>
<li><strong>Authors: </strong>Qiang Gao, Zixiang Meng, Bobo Li, Jun Zhou, Fei Li, Chong Teng, Donghong Ji</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Harvesting Events from Multiple Sources: Towards a Cross-Document Event Extraction Paradigm(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Document-level event extraction aims to extract structured event information from unstructured text. However, a single document often contains limited event information and the roles of different event arguments may be biased due to the influence of the information source. This paper addresses the limitations of traditional document-level event extraction by proposing the task of cross-document event extraction (CDEE) to integrate event information from multiple documents and provide a comprehensive perspective on events. We construct a novel cross-document event extraction dataset, namely CLES, which contains 20,059 documents and 37,688 mention-level events, where over 70% of them are cross-document. To build a benchmark, we propose a CDEE pipeline that includes 5 steps, namely event extraction, coreference resolution, entity normalization, role normalization and entity-role resolution. Our CDEE pipeline achieves about 72% F1 in end-to-end cross-document event extraction, suggesting the challenge of this task. Our work builds a new line of information extraction research and will attract new research attention.</li>
</ul>

<h3>Title: Title:
          TimeAutoDiff: Combining Autoencoder and Diffusion model for time series tabular data synthesizing</h3>
<ul>
<li><strong>Authors: </strong>Namjoon Suh, Yuning Yang, Din-Yin Hsieh, Qitong Luan, Shirong Xu, Shixiang Zhu, Guang Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          TimeAutoDiff: Combining Autoencoder and Diffusion model for time series tabular data synthesizing(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this paper, we leverage the power of latent diffusion models to generate synthetic time series tabular data. Along with the temporal and feature correlations, the heterogeneous nature of the feature in the table has been one of the main obstacles in time series tabular data modeling. We tackle this problem by combining the ideas of the variational auto-encoder (VAE) and the denoising diffusion probabilistic model (DDPM). Our model named as \texttt{TimeAutoDiff} has several key advantages including (1) Generality: the ability to handle the broad spectrum of time series tabular data from single to multi-sequence datasets; (2) Good fidelity and utility guarantees: numerical experiments on six publicly available datasets demonstrating significant improvements over state-of-the-art models in generating time series tabular data, across four metrics measuring fidelity and utility; (3) Fast sampling speed: entire time series data generation as opposed to the sequential data sampling schemes implemented in the existing diffusion-based models, eventually leading to significant improvements in sampling speed, (4) Entity conditional generation: the first implementation of conditional generation of multi-sequence time series tabular data with heterogenous features in the literature, enabling scenario exploration across multiple scientific and engineering domains. Codes are in preparation for release to the public, but available upon request.</li>
</ul>

<h3>Title: Title:
          Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Jimin Sohn, Haeji Jung, Alex Cheng, Jooeon Kang, Yilin Du, David R. Mortensen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Existing zero-shot cross-lingual NER approaches require substantial prior knowledge of the target language, which is impractical for low-resource languages. In this paper, we propose a novel approach to NER using phonemic representation based on the International Phonetic Alphabet (IPA) to bridge the gap between representations of different languages. Our experiments show that our method significantly outperforms baseline models in extremely low-resource languages, with the highest average F-1 score (46.38%) and lowest standard deviation (12.67), particularly demonstrating its robustness with non-Latin scripts.</li>
</ul>

<h3>Title: Title:
          Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Planning, as the core module of agents, is crucial in various fields such as embodied agents, web navigation, and tool using. With the development of large language models (LLMs), some researchers treat large language models as intelligent agents to stimulate and evaluate their planning capabilities. However, the planning mechanism is still unclear. In this work, we focus on exploring the look-ahead planning mechanism in large language models from the perspectives of information flow and internal representations. First, we study how planning is done internally by analyzing the multi-layer perception (MLP) and multi-head self-attention (MHSA) components at the last token. We find that the output of MHSA in the middle layers at the last token can directly decode the decision to some extent. Based on this discovery, we further trace the source of MHSA by information flow, and we reveal that MHSA mainly extracts information from spans of the goal states and recent steps. According to information flow, we continue to study what information is encoded within it. Specifically, we explore whether future decisions have been encoded in advance in the representation of flow. We demonstrate that the middle and upper layers encode a few short-term future decisions to some extent when planning is successful. Overall, our research analyzes the look-ahead planning mechanisms of LLMs, facilitating future research on LLMs performing planning tasks.</li>
</ul>

<h3>Title: Title:
          Meta-FL: A Novel Meta-Learning Framework for Optimizing Heterogeneous Model Aggregation in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Zahir Alsulaimawi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Meta-FL: A Novel Meta-Learning Framework for Optimizing Heterogeneous Model Aggregation in Federated Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative model training across diverse entities while safeguarding data privacy. However, FL faces challenges such as data heterogeneity and model diversity. The Meta-Federated Learning (Meta-FL) framework has been introduced to tackle these challenges. Meta-FL employs an optimization-based Meta-Aggregator to navigate the complexities of heterogeneous model updates. The Meta-Aggregator enhances the global model's performance by leveraging meta-features, ensuring a tailored aggregation that accounts for each local model's accuracy. Empirical evaluation across four healthcare-related datasets demonstrates the Meta-FL framework's adaptability, efficiency, scalability, and robustness, outperforming conventional FL approaches. Furthermore, Meta-FL's remarkable efficiency and scalability are evident in its achievement of superior accuracy with fewer communication rounds and its capacity to manage expanding federated networks without compromising performance.</li>
</ul>

<h3>Title: Title:
          CholecInstanceSeg: A Tool Instance Segmentation Dataset for Laparoscopic Surgery</h3>
<ul>
<li><strong>Authors: </strong>Oluwatosin Alabi, Ko Ko Zayar Toe, Zijian Zhou, Charlie Budd, Nicholas Raison, Miaojing Shi, Tom Vercauteren</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          CholecInstanceSeg: A Tool Instance Segmentation Dataset for Laparoscopic Surgery(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In laparoscopic and robotic surgery, precise tool instance segmentation is an essential technology for advanced computer-assisted interventions. Although publicly available procedures of routine surgeries exist, they often lack comprehensive annotations for tool instance segmentation. Additionally, the majority of standard datasets for tool segmentation are derived from porcine(pig) surgeries. To address this gap, we introduce CholecInstanceSeg, the largest open-access tool instance segmentation dataset to date. Derived from the existing CholecT50 and Cholec80 datasets, CholecInstanceSeg provides novel annotations for laparoscopic cholecystectomy procedures in patients. Our dataset comprises 41.9k annotated frames extracted from 85 clinical procedures and 64.4k tool instances, each labelled with semantic masks and instance IDs. To ensure the reliability of our annotations, we perform extensive quality control, conduct label agreement statistics, and benchmark the segmentation results with various instance segmentation baselines. CholecInstanceSeg aims to advance the field by offering a comprehensive and high-quality open-access dataset for the development and evaluation of tool instance segmentation algorithms.</li>
</ul>

<h3>Title: Title:
          Pose-Diversified Augmentation with Diffusion Model for Person Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Inès Hyeonsu Kim, JoungBin Lee, Soowon Son, Woojeong Jin, Kyusun Cho, Junyoung Seo, Min-Seop Kwak, Seokju Cho, JeongYeol Baek, Byeongwon Lee, Seungryong Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Pose-Diversified Augmentation with Diffusion Model for Person Re-Identification(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Person re-identification (Re-ID) often faces challenges due to variations in human poses and camera viewpoints, which significantly affect the appearance of individuals across images. Existing datasets frequently lack diversity and scalability in these aspects, hindering the generalization of Re-ID models to new camera systems. Previous methods have attempted to address these issues through data augmentation; however, they rely on human poses already present in the training dataset, failing to effectively reduce the human pose bias in the dataset. We propose Diff-ID, a novel data augmentation approach that incorporates sparse and underrepresented human pose and camera viewpoint examples into the training data, addressing the limited diversity in the original training data distribution. Our objective is to augment a training dataset that enables existing Re-ID models to learn features unbiased by human pose and camera viewpoint variations. To achieve this, we leverage the knowledge of pre-trained large-scale diffusion models. Using the SMPL model, we simultaneously capture both the desired human poses and camera viewpoints, enabling realistic human rendering. The depth information provided by the SMPL model indirectly conveys the camera viewpoints. By conditioning the diffusion model on both the human pose and camera viewpoint concurrently through the SMPL model, we generate realistic images with diverse human poses and camera viewpoints. Qualitative results demonstrate the effectiveness of our method in addressing human pose bias and enhancing the generalizability of Re-ID models compared to other data augmentation-based Re-ID approaches. The performance gains achieved by training Re-ID models on our offline augmented dataset highlight the potential of our proposed framework in improving the scalability and generalizability of person Re-ID models.</li>
</ul>

<h3>Title: Title:
          PORT: Preference Optimization on Reasoning Traces</h3>
<ul>
<li><strong>Authors: </strong>Salem Lahlou, Abdalgader Abubaker, Hakim Hacid</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          PORT: Preference Optimization on Reasoning Traces(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Preference optimization methods have been successfully applied to improve not only the alignment of large language models (LLMs) with human values, but also specific natural language tasks such as summarization and stylistic continuations. This paper proposes using preference optimization methods on Chain-of-Thought steps in order to improve the reasoning performances of language models. While the chosen answers are obtained from datasets that include reasoning traces, we propose two complementary schemes for generating rejected answers: digit corruption, and weak LLM prompting. Our approach leads to increased accuracy on the GSM8K, AQuA-RAT, and ARC benchmarks for Falcon2-11B and Mistral-7B. For example, the approach can lead to up to a relative 8.47% increase in accuracy on the GSM8K benchmark without any extra annotations. This work suggests that spending resources on creating more datasets of reasoning traces would further boost LLM performances on informal reasoning tasks.</li>
</ul>

<h3>Title: Title:
          FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Junyi Zhu, Shuochen Liu, Yu Yu, Bo Tang, Yibo Yan, Zhiyu Li, Feiyu Xiong, Tong Xu, Matthew B. Blaschko</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel in generating coherent text, but they often struggle with context awareness, leading to inaccuracies in tasks requiring faithful adherence to provided information. We introduce FastMem, a novel method designed to enhance instruction fine-tuned LLMs' context awareness through fast memorization of the prompt. FastMem maximizes the likelihood of the prompt before inference by fine-tuning only the last Feed-Forward Network (FFN) module. This targeted approach ensures efficient optimization without overfitting, significantly improving the model's ability to comprehend and accurately follow the context. Our experiments demonstrate substantial gains in reading comprehension, text summarization and adherence to output structures. For instance, FastMem improves the accuracy of Llama 3-8B-Inst on the NQ-SWAP dataset from 59.1% to 71.6%, and reduces the output structure failure rate of Qwen 1.5-4B-Chat from 34.9% to 25.5%. Extensive experimental results highlight FastMem's potential to offer a robust solution to enhance the reliability and accuracy of LLMs in various applications. Our code is available at: this https URL</li>
</ul>

<h3>Title: Title:
          Dancing in the syntax forest: fast, accurate and explainable sentiment analysis with SALSA</h3>
<ul>
<li><strong>Authors: </strong>Carlos Gómez-Rodríguez, Muhammad Imran, David Vilares, Elena Solera, Olga Kellert</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Dancing in the syntax forest: fast, accurate and explainable sentiment analysis with SALSA(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Sentiment analysis is a key technology for companies and institutions to gauge public opinion on products, services or events. However, for large-scale sentiment analysis to be accessible to entities with modest computational resources, it needs to be performed in a resource-efficient way. While some efficient sentiment analysis systems exist, they tend to apply shallow heuristics, which do not take into account syntactic phenomena that can radically change sentiment. Conversely, alternatives that take syntax into account are computationally expensive. The SALSA project, funded by the European Research Council under a Proof-of-Concept Grant, aims to leverage recently-developed fast syntactic parsing techniques to build sentiment analysis systems that are lightweight and efficient, while still providing accuracy and explainability through the explicit use of syntax. We intend our approaches to be the backbone of a working product of interest for SMEs to use in production.</li>
</ul>

<h3>Title: Title:
          EERPD: Leveraging Emotion and Emotion Regulation for Improving Personality Detection</h3>
<ul>
<li><strong>Authors: </strong>Zheng Li, Dawei Zhu, Qilong Ma, Weimin Xiong, Sujian Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          EERPD: Leveraging Emotion and Emotion Regulation for Improving Personality Detection(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Personality is a fundamental construct in psychology, reflecting an individual's behavior, thinking, and emotional patterns. Previous researches have made some progress in personality detection, primarily by utilizing the whole text to predict personality. However, these studies generally tend to overlook psychological knowledge: they rarely apply the well-established correlations between emotion regulation and personality. Based on this, we propose a new personality detection method called EERPD. This method introduces the use of emotion regulation, a psychological concept highly correlated with personality, for personality prediction. By combining this feature with emotion features, it retrieves few-shot examples and provides process CoTs for inferring labels from text. This approach enhances the understanding of LLM for personality within text and improves the performance in personality detection. Experimental results demonstrate that EERPD significantly enhances the accuracy and robustness of personality detection, outperforming previous SOTA by 15.05/4.29 in average F1 on the two benchmark datasets.</li>
</ul>

<h3>Title: Title:
          A Simple Framework for Open-Vocabulary Zero-Shot Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Thomas Stegmüller, Tim Lebailly, Nikola Dukic, Behzad Bozorgtabar, Jean-Philippe Thiran, Tinne Tuytelaars</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          A Simple Framework for Open-Vocabulary Zero-Shot Segmentation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Zero-shot classification capabilities naturally arise in models trained within a vision-language contrastive framework. Despite their classification prowess, these models struggle in dense tasks like zero-shot open-vocabulary segmentation. This deficiency is often attributed to the absence of localization cues in captions and the intertwined nature of the learning process, which encompasses both image representation learning and cross-modality alignment. To tackle these issues, we propose SimZSS, a Simple framework for open-vocabulary Zero-Shot Segmentation. The method is founded on two key principles: i) leveraging frozen vision-only models that exhibit spatial awareness while exclusively aligning the text encoder and ii) exploiting the discrete nature of text and linguistic knowledge to pinpoint local concepts within captions. By capitalizing on the quality of the visual representations, our method requires only image-caption pairs datasets and adapts to both small curated and large-scale noisy datasets. When trained on COCO Captions across 8 GPUs, SimZSS achieves state-of-the-art results on 7 out of 8 benchmark datasets in less than 15 minutes.</li>
</ul>

<h3>Title: Title:
          SEAM: A Stochastic Benchmark for Multi-Document Tasks</h3>
<ul>
<li><strong>Authors: </strong>Gili Lior, Avi Caciularu, Arie Cattan, Shahar Levy, Ori Shapira, Gabriel Stanovsky</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          SEAM: A Stochastic Benchmark for Multi-Document Tasks(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Various tasks, such as summarization, multi-hop question answering, or coreference resolution, are naturally phrased over collections of real-world documents. Such tasks present a unique set of challenges, revolving around the lack of coherent narrative structure across documents, which often leads to contradiction, omission, or repetition of information. Despite their real-world application and challenging properties, there is currently no benchmark which specifically measures the abilities of large language models (LLMs) on multi-document tasks. To bridge this gap, we present SEAM (a Stochastic Evaluation Approach for Multi-document tasks), a conglomerate benchmark over a diverse set of multi-document datasets, setting conventional evaluation criteria, input-output formats, and evaluation protocols. In particular, SEAM addresses the sensitivity of LLMs to minor prompt variations through repeated evaluations, where in each evaluation we sample uniformly at random the values of arbitrary factors (e.g., the order of documents). We evaluate different LLMs on SEAM finding that multi-document tasks pose a significant challenge for LLMs, even for state-of-the-art models with 70B parameters. In addition, we show that the stochastic approach uncovers underlying statistical trends which cannot be observed in a static benchmark. We hope that SEAM will spur progress via consistent and meaningful evaluation of multi-document tasks.</li>
</ul>

<h3>Title: Title:
          Multi-Scale Temporal Difference Transformer for Video-Text Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Ni Wang, Dongliang Liao, Xing Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Multi-Scale Temporal Difference Transformer for Video-Text Retrieval(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Currently, in the field of video-text retrieval, there are many transformer-based methods. Most of them usually stack frame features and regrade frames as tokens, then use transformers for video temporal modeling. However, they commonly neglect the inferior ability of the transformer modeling local temporal information. To tackle this problem, we propose a transformer variant named Multi-Scale Temporal Difference Transformer (MSTDT). MSTDT mainly addresses the defects of the traditional transformer which has limited ability to capture local temporal information. Besides, in order to better model the detailed dynamic information, we make use of the difference feature between frames, which practically reflects the dynamic movement of a video. We extract the inter-frame difference feature and integrate the difference and frame feature by the multi-scale temporal transformer. In general, our proposed MSTDT consists of a short-term multi-scale temporal difference transformer and a long-term temporal transformer. The former focuses on modeling local temporal information, the latter aims at modeling global temporal information. At last, we propose a new loss to narrow the distance of similar samples. Extensive experiments show that backbone, such as CLIP, with MSTDT has attained a new state-of-the-art result.</li>
</ul>

<h3>Title: Title:
          Diffusion Spectral Representation for Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Dmitry Shribak, Chen-Xiao Gao, Yitong Li, Chenjun Xiao, Bo Dai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Diffusion Spectral Representation for Reinforcement Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion-based models have achieved notable empirical successes in reinforcement learning (RL) due to their expressiveness in modeling complex distributions. Despite existing methods being promising, the key challenge of extending existing methods for broader real-world applications lies in the computational cost at inference time, i.e., sampling from a diffusion model is considerably slow as it often requires tens to hundreds of iterations to generate even one sample. To circumvent this issue, we propose to leverage the flexibility of diffusion models for RL from a representation learning perspective. In particular, by exploiting the connection between diffusion model and energy-based model, we develop Diffusion Spectral Representation (Diff-SR), a coherent algorithm framework that enables extracting sufficient representations for value functions in Markov decision processes (MDP) and partially observable Markov decision processes (POMDP). We further demonstrate how Diff-SR facilitates efficient policy optimization and practical algorithms while explicitly bypassing the difficulty and inference cost of sampling from the diffusion model. Finally, we provide comprehensive empirical studies to verify the benefits of Diff-SR in delivering robust and advantageous performance across various benchmarks with both fully and partially observable settings.</li>
</ul>

<h3>Title: Title:
          CBPF: Filtering Poisoned Data Based on Composite Backdoor Attack</h3>
<ul>
<li><strong>Authors: </strong>Hanfeng Xia, Haibo Hong, Ruili Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          CBPF: Filtering Poisoned Data Based on Composite Backdoor Attack(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Backdoor attacks involve the injection of a limited quantity of poisoned examples containing triggers into the training dataset. During the inference stage, backdoor attacks can uphold a high level of accuracy for normal examples, yet when presented with trigger-containing instances, the model may erroneously predict them as the targeted class designated by the attacker. This paper explores strategies for mitigating the risks associated with backdoor attacks by examining the filtration of poisoned samples.We primarily leverage two key characteristics of backdoor attacks: the ability for multiple backdoors to exist simultaneously within a single model, and the discovery through Composite Backdoor Attack (CBA) that altering two triggers in a sample to new target labels does not compromise the original functionality of the triggers, yet enables the prediction of the data as a new target class when both triggers are present simultaneously.Therefore, a novel three-stage poisoning data filtering approach, known as Composite Backdoor Poison Filtering (CBPF), is proposed as an effective solution. Firstly, utilizing the identified distinctions in output between poisoned and clean samples, a subset of data is partitioned to include both poisoned and clean instances. Subsequently, benign triggers are incorporated and labels are adjusted to create new target and benign target classes, thereby prompting the poisoned and clean data to be classified as distinct entities during the inference stage. The experimental results indicate that CBPF is successful in filtering out malicious data produced by six advanced attacks on CIFAR10 and ImageNet-12. On average, CBPF attains a notable filtering success rate of 99.91% for the six attacks on CIFAR10. Additionally, the model trained on the uncontaminated samples exhibits sustained high accuracy levels.</li>
</ul>

<h3>Title: Title:
          UDHF2-Net: An Uncertainty-diffusion-model-based High-Frequency TransFormer Network for High-accuracy Interpretation of Remotely Sensed Imagery</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Zhang, Chang Li, Yongjun Zhang, Rongjun Qin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          UDHF2-Net: An Uncertainty-diffusion-model-based High-Frequency TransFormer Network for High-accuracy Interpretation of Remotely Sensed Imagery(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, diffusion, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Remotely sensed image high-accuracy interpretation (RSIHI), including tasks such as semantic segmentation and change detection, faces the three major problems: (1) complementarity problem of spatially stationary-and-non-stationary frequency; (2) edge uncertainty problem caused by down-sampling in the encoder step and intrinsic edge noises; and (3) false detection problem caused by imagery registration error in change detection. To solve the aforementioned problems, an uncertainty-diffusion-model-based high-Frequency TransFormer network (UDHF2-Net) is the proposed for RSIHI, the superiority of which is as following: (1) a spatially-stationary-and-non-stationary high-frequency connection paradigm (SHCP) is proposed to enhance the interaction of spatially stationary and non-stationary frequency features to yield high-fidelity edge extraction result. Inspired by HRFormer, SHCP remains the high-frequency stream through the whole encoder-decoder process with parallel high-to-low frequency streams and reduces the edge loss by a downsampling operation; (2) a mask-and-geo-knowledge-based uncertainty diffusion module (MUDM) is proposed to improve the robustness and edge noise resistance. MUDM could further optimize the uncertain region to improve edge extraction result by gradually removing the multiple geo-knowledge-based noises; (3) a semi-pseudo-Siamese UDHF2-Net for change detection task is proposed to reduce the pseudo change by registration error. It adopts semi-pseudo-Siamese architecture to extract above complemental frequency features for adaptively reducing registration differencing, and MUDM to recover the uncertain region by gradually reducing the registration error besides above edge noises. Comprehensive experiments were performed to demonstrate the superiority of UDHF2-Net. Especially ablation experiments indicate the effectiveness of UDHF2-Net.</li>
</ul>

<h3>Title: Title:
          Crosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lynn Chua, Badih Ghazi, Yangsibo Huang, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Amer Sinha, Chulin Xie, Chiyuan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Crosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are typically multilingual due to pretraining on diverse multilingual corpora. But can these models relate corresponding concepts across languages, effectively being crosslingual? This study evaluates six state-of-the-art LLMs on inherently crosslingual tasks. We observe that while these models show promising surface-level crosslingual abilities on machine translation and embedding space analyses, they struggle with deeper crosslingual knowledge transfer, revealing a crosslingual knowledge barrier in both general (MMLU benchmark) and domain-specific (Harry Potter quiz) contexts. We observe that simple inference-time mitigation methods offer only limited improvement. On the other hand, we propose fine-tuning of LLMs on mixed-language data, which effectively reduces these gaps, even when using out-of-domain datasets like WikiText. Our findings suggest the need for explicit optimization to unlock the full crosslingual potential of LLMs. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Title:
          Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step</h3>
<ul>
<li><strong>Authors: </strong>Zezhong Wang, Xingshan Zeng, Weiwen Liu, Yufei Wang, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current research found the issue of Early Answering in large language models (LLMs), where the models already have an answer before generating the Chain-of-Thought (CoT). This phenomenon suggests a potential lack of necessary dependency between the predicted answer and the reasoning process. Consequently, two important questions arise: (1) Is CoT still necessary if the model already has an answer? (2) Can the correctness of the answer serve as valid evidence for the correctness of CoT? To address these questions, we propose a method, namely Chain-of-Probe (CoP), to probe changes in the mind during the model's reasoning. The probing results show that in a significant number of question-answer cases, CoT appears to be unnecessary, and this necessity correlates with the simplicity of the task, defined by reasoning steps required. Furthermore, by analyzing patterns in mind change, we examine the correctness of the model's reasoning. Our validation reveals that many responses, although correct in their final answer, contain errors in their reasoning process. To this end, we propose a strategic approach based on CoP to prioritize answers with correct reasoning among multiple candidates, thereby bolstering the reliability of the model's reasoning.</li>
</ul>

<h3>Title: Title:
          FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Harish Tayyar Madabushi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy in Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a novel extension to Retrieval Augmented Generation with the goal of mitigating factual inaccuracies in the output of large language models. Specifically, our method draws on the cognitive linguistic theory of frame semantics for the indexing and retrieval of factual information relevant to helping large language models answer queries. We conduct experiments to demonstrate the effectiveness of this method both in terms of retrieval effectiveness and in terms of the relevance of the frames and frame relations automatically generated. Our results show that this novel mechanism of Frame Semantic-based retrieval, designed to improve Retrieval Augmented Generation (FS-RAG), is effective and offers potential for providing data-driven insights into frame semantics theory. We provide open access to our program code and prompts.</li>
</ul>

<h3>Title: Title:
          An All-MLP Sequence Modeling Architecture That Excels at Copying</h3>
<ul>
<li><strong>Authors: </strong>Chenwei Cui, Zehao Yan, Gedeon Muhawenayo, Hannah Kerner</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          An All-MLP Sequence Modeling Architecture That Excels at Copying(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent work demonstrated Transformers' ability to efficiently copy strings of exponential sizes, distinguishing them from other architectures. We present the Causal Relation Network (CausalRN), an all-MLP sequence modeling architecture that can match Transformers on the copying task. Extending Relation Networks (RNs), we implemented key innovations to support autoregressive sequence modeling while maintaining computational feasibility. We discovered that exponentially-activated RNs are reducible to linear time complexity, and pre-activation normalization induces an infinitely growing memory pool, similar to a KV cache. In ablation study, we found both exponential activation and pre-activation normalization are indispensable for Transformer-level copying. Our findings provide new insights into what actually constitutes strong in-context retrieval.</li>
</ul>

<h3>Title: Title:
          Evaluation and Comparison of Emotionally Evocative Image Augmentation Methods</h3>
<ul>
<li><strong>Authors: </strong>Jan Ignatowicz, Krzysztof Kutt, Grzegorz J. Nalepa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Evaluation and Comparison of Emotionally Evocative Image Augmentation Methods(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Experiments in affective computing are based on stimulus datasets that, in the process of standardization, receive metadata describing which emotions each stimulus evokes. In this paper, we explore an approach to creating stimulus datasets for affective computing using generative adversarial networks (GANs). Traditional dataset preparation methods are costly and time consuming, prompting our investigation of alternatives. We conducted experiments with various GAN architectures, including Deep Convolutional GAN, Conditional GAN, Auxiliary Classifier GAN, Progressive Augmentation GAN, and Wasserstein GAN, alongside data augmentation and transfer learning techniques. Our findings highlight promising advances in the generation of emotionally evocative synthetic images, suggesting significant potential for future research and improvements in this domain.</li>
</ul>

<h3>Title: Title:
          Accelerating Matrix Diagonalization through Decision Transformers with Epsilon-Greedy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Kshitij Bhatta, Geigh Zollicoffer, Manish Bhattarai, Phil Romero, Christian F. A. Negre, Anders M. N. Niklasson, Adetokunbo Adedoyin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Accelerating Matrix Diagonalization through Decision Transformers with Epsilon-Greedy Optimization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel framework for matrix diagonalization, recasting it as a sequential decision-making problem and applying the power of Decision Transformers (DTs). Our approach determines optimal pivot selection during diagonalization with the Jacobi algorithm, leading to significant speedups compared to the traditional max-element Jacobi method. To bolster robustness, we integrate an epsilon-greedy strategy, enabling success in scenarios where deterministic approaches fail. This work demonstrates the effectiveness of DTs in complex computational tasks and highlights the potential of reimagining mathematical operations through a machine learning lens. Furthermore, we establish the generalizability of our method by using transfer learning to diagonalize matrices of smaller sizes than those trained.</li>
</ul>

<h3>Title: Title:
          Semi-Variance Reduction for Fair Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Saber Malekmohammadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Semi-Variance Reduction for Fair Federated Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, fair</a></li>
<li><strong>Abstract: </strong>Ensuring fairness in a Federated Learning (FL) system, i.e., a satisfactory performance for all of the participating diverse clients, is an important and challenging problem. There are multiple fair FL algorithms in the literature, which have been relatively successful in providing fairness. However, these algorithms mostly emphasize on the loss functions of worst-off clients to improve their performance, which often results in the suppression of well-performing ones. As a consequence, they usually sacrifice the system's overall average performance for achieving fairness. Motivated by this and inspired by two well-known risk modeling methods in Finance, Mean-Variance and Mean-Semi-Variance, we propose and study two new fair FL algorithms, Variance Reduction (VRed) and Semi-Variance Reduction (SemiVRed). VRed encourages equality between clients' loss functions by penalizing their variance. In contrast, SemiVRed penalizes the discrepancy of only the worst-off clients' loss functions from the average loss. Through extensive experiments on multiple vision and language datasets, we show that, SemiVRed achieves SoTA performance in scenarios with heterogeneous data distributions and improves both fairness and system overall average performance.</li>
</ul>

<h3>Title: Title:
          Towards unlocking the mystery of adversarial fragility of neural networks</h3>
<ul>
<li><strong>Authors: </strong>Jingchao Gao, Raghu Mudumbai, Xiaodong Wu, Jirong Yi, Catherine Xu, Hui Xie, Weiyu Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.IT, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Towards unlocking the mystery of adversarial fragility of neural networks(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we study the adversarial robustness of deep neural networks for classification tasks. We look at the smallest magnitude of possible additive perturbations that can change the output of a classification algorithm. We provide a matrix-theoretic explanation of the adversarial fragility of deep neural network for classification. In particular, our theoretical results show that neural network's adversarial robustness can degrade as the input dimension $d$ increases. Analytically we show that neural networks' adversarial robustness can be only $1/\sqrt{d}$ of the best possible adversarial robustness. Our matrix-theoretic explanation is consistent with an earlier information-theoretic feature-compression-based explanation for the adversarial fragility of neural networks.</li>
</ul>

<h3>Title: Title:
          Blind Baselines Beat Membership Inference Attacks for Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Debeshee Das, Jie Zhang, Florian Tramèr</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Blind Baselines Beat Membership Inference Attacks for Foundation Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, membership infer</a></li>
<li><strong>Abstract: </strong>Membership inference (MI) attacks try to determine if a data sample was used to train a machine learning model. For foundation models trained on unknown Web data, MI attacks can be used to detect copyrighted training materials, measure test set contamination, or audit machine unlearning. Unfortunately, we find that evaluations of MI attacks for foundation models are flawed, because they sample members and non-members from different distributions. For 8 published MI evaluation datasets, we show that blind attacks -- that distinguish the member and non-member distributions without looking at any trained model -- outperform state-of-the-art MI attacks. Existing evaluations thus tell us nothing about membership leakage of a foundation model's training data.</li>
</ul>

<h3>Title: Title:
          LLMs' Classification Performance is Overclaimed</h3>
<ul>
<li><strong>Authors: </strong>Hanzi Xu, Renze Lou, Jiangshu Du, Vahid Mahzoon, Elmira Talebianaraki, Zhuoan Zhou, Elizabeth Garrison, Slobodan Vucetic, Wenpeng Yin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          LLMs' Classification Performance is Overclaimed(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In many classification tasks designed for AI or human to solve, gold labels are typically included within the label space by default, often posed as "which of the following is correct?" This standard setup has traditionally highlighted the strong performance of advanced AI, particularly top-performing Large Language Models (LLMs), in routine classification tasks. However, when the gold label is intentionally excluded from the label space, it becomes evident that LLMs still attempt to select from the available label candidates, even when none are correct. This raises a pivotal question: Do LLMs truly demonstrate their intelligence in understanding the essence of classification tasks? In this study, we evaluate both closed-source and open-source LLMs across representative classification tasks, arguing that the perceived performance of LLMs is overstated due to their inability to exhibit the expected comprehension of the task. This paper makes a threefold contribution: i) To our knowledge, this is the first work to identify the limitations of LLMs in classification tasks when gold labels are absent. We define this task as Classify-w/o-Gold and propose it as a new testbed for LLMs. ii) We introduce a benchmark, Know-No, comprising two existing classification tasks and one new task, to evaluate Classify-w/o-Gold. iii) This work defines and advocates for a new evaluation metric, OmniAccuracy, which assesses LLMs' performance in classification tasks both when gold labels are present and absent.</li>
</ul>

<h3>Title: Title:
          Breaking the Frame: Image Retrieval by Visual Overlap Prediction</h3>
<ul>
<li><strong>Authors: </strong>Tong Wei, Philipp Lindenberger, Jiri Matas, Daniel Barath</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Breaking the Frame: Image Retrieval by Visual Overlap Prediction(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We propose a novel visual place recognition approach, VOP, that efficiently addresses occlusions and complex scenes by shifting from traditional reliance on global image similarities and local features to image overlap prediction. The proposed method enables the identification of visible image sections without requiring expensive feature detection and matching. By focusing on obtaining patch-level embeddings by a Vision Transformer backbone and establishing patch-to-patch correspondences, our approach uses a voting mechanism to assess overlap scores for potential database images, thereby providing a nuanced image retrieval metric in challenging scenarios. VOP leads to more accurate relative pose estimation and localization results on the retrieved image pairs than state-of-the-art baselines on a number of large-scale, real-world datasets. The code is available at this https URL.</li>
</ul>

<h3>Title: Title:
          Provable Statistical Rates for Consistency Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zehao Dou, Minshuo Chen, Mengdi Wang, Zhuoran Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Provable Statistical Rates for Consistency Diffusion Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have revolutionized various application domains, including computer vision and audio generation. Despite the state-of-the-art performance, diffusion models are known for their slow sample generation due to the extensive number of steps involved. In response, consistency models have been developed to merge multiple steps in the sampling process, thereby significantly boosting the speed of sample generation without compromising quality. This paper contributes towards the first statistical theory for consistency models, formulating their training as a distribution discrepancy minimization problem. Our analysis yields statistical estimation rates based on the Wasserstein distance for consistency models, matching those of vanilla diffusion models. Additionally, our results encompass the training of consistency models through both distillation and isolation methods, demystifying their underlying advantage.</li>
</ul>

<h3>Title: Title:
          Towards a Formal Foundation for Blockchain Rollups</h3>
<ul>
<li><strong>Authors: </strong>Stefanos Chaliasos, Denis Firsov, Benjamin Livshits</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Towards a Formal Foundation for Blockchain Rollups(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Blockchains like Bitcoin and Ethereum have revolutionized digital transactions, yet scalability issues persist. Layer 2 solutions, such as validity proof Rollups (ZK-Rollups), aim to address these challenges by processing transactions off-chain and validating them on the main chain. However, concerns remain about security and censorship resistance, particularly regarding centralized control in Layer 2 and inadequate mechanisms for enforcing these properties through Layer 1 contracts. This work presents a formal analysis using the Alloy specification language to examine and design key Layer 2 functionalities, including forced transaction queues, safe blacklisting, and upgradeability. Through this analysis, we identify potential vulnerabilities in current mechanisms and propose enhanced models to strengthen security and censorship resistance, setting new standards for the security of rollups.</li>
</ul>

<h3>Title: Title:
          Multi-Objective Linguistic Control of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dang Nguyen, Jiuhai Chen, Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Multi-Objective Linguistic Control of Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), despite their breakthroughs on many challenging benchmark tasks, lean to generate verbose responses and lack the controllability of output complexity, which is usually preferred by human users in practice. In this paper, we study how to precisely control multiple linguistic complexities of LLM output by finetuning using off-the-shelf data. To this end, we propose multi-control tuning (MCTune), which includes multiple linguistic complexity values of ground-truth responses as controls in the input for instruction tuning. We finetune LLaMA2-7B on Alpaca-GPT4 and WizardLM datasets. Evaluations on widely used benchmarks demonstrate that our method does not only improve LLMs' multi-complexity controllability substantially but also retains or even enhances the quality of the responses as a side benefit.</li>
</ul>

<h3>Title: Title:
          Preference Tuning For Toxicity Mitigation Generalizes Across Languages</h3>
<ul>
<li><strong>Authors: </strong>Xiaochen Li, Zheng-Xin Yong, Stephen H. Bach</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Preference Tuning For Toxicity Mitigation Generalizes Across Languages(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Detoxifying multilingual Large Language Models (LLMs) has become crucial due to their increasing global use. In this work, we explore zero-shot cross-lingual generalization of preference tuning in detoxifying LLMs. Unlike previous studies that show limited cross-lingual generalization for other safety tasks, we demonstrate that Direct Preference Optimization (DPO) training with only English data can significantly reduce toxicity in multilingual open-ended generations. For example, the probability of mGPT-1.3B generating toxic continuations drops from 46.8% to 3.9% across 17 different languages after training. Our results also extend to other multilingual LLMs, such as BLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal intervention and activation analysis, we identified the dual multilinguality property of MLP layers in LLMs, which explains the cross-lingual generalization of DPO. Finally, we show that bilingual sentence retrieval can predict the cross-lingual transferability of DPO preference tuning.</li>
</ul>

<h3>Title: Title:
          Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis</h3>
<ul>
<li><strong>Authors: </strong>Ajan Subramanian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Health monitoring systems have revolutionized modern healthcare by enabling the continuous capture of physiological and behavioral data, essential for preventive measures and early health intervention. While integrating this data with Large Language Models (LLMs) has shown promise in delivering interactive health advice, traditional methods like Retrieval-Augmented Generation (RAG) and fine-tuning often fail to fully utilize the complex, multi-dimensional, and temporally relevant data from wearable devices. These conventional approaches typically provide limited actionable and personalized health insights due to their inadequate capacity to dynamically integrate and interpret diverse health data streams. In response, this paper introduces a graph-augmented LLM framework designed to significantly enhance the personalization and clarity of health insights. Utilizing a hierarchical graph structure, the framework captures inter and intra-patient relationships, enriching LLM prompts with dynamic feature importance scores derived from a Random Forest Model. The effectiveness of this approach is demonstrated through a sleep analysis case study involving 20 college students during the COVID-19 lockdown, highlighting the potential of our model to generate actionable and personalized health insights efficiently. We leverage another LLM to evaluate the insights for relevance, comprehensiveness, actionability, and personalization, addressing the critical need for models that process and interpret complex health data effectively. Our findings show that augmenting prompts with our framework yields significant improvements in all 4 criteria. Through our framework, we can elicit well-crafted, more thoughtful responses tailored to a specific patient.</li>
</ul>

<h3>Title: Title:
          LLMs assist NLP Researchers: Critique Paper (Meta-)Reviewing</h3>
<ul>
<li><strong>Authors: </strong>Jiangshu Du, Yibo Wang, Wenting Zhao, Zhongfen Deng, Shuaiqi Liu, Renze Lou, Henry Peng Zou, Pranav Narayanan Venkit, Nan Zhang, Mukund Srinath, Haoran Ranran Zhang, Vipul Gupta, Yinghui Li, Tao Li, Fei Wang, Qin Liu, Tianlin Liu, Pengzhi Gao, Congying Xia, Chen Xing, Jiayang Cheng, Zhaowei Wang, Ying Su, Raj Sanjay Shah, Ruohao Guo, Jing Gu, Haoran Li, Kangda Wei, Zihao Wang, Lu Cheng, Surangika Ranathunga, Meng Fang, Jie Fu, Fei Liu, Ruihong Huang, Eduardo Blanco, Yixin Cao, Rui Zhang, Philip S. Yu, Wenpeng Yin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          LLMs assist NLP Researchers: Critique Paper (Meta-)Reviewing(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>This work is motivated by two key trends. On one hand, large language models (LLMs) have shown remarkable versatility in various generative tasks such as writing, drawing, and question answering, significantly reducing the time required for many routine tasks. On the other hand, researchers, whose work is not only time-consuming but also highly expertise-demanding, face increasing challenges as they have to spend more time reading, writing, and reviewing papers. This raises the question: how can LLMs potentially assist researchers in alleviating their heavy workload? This study focuses on the topic of LLMs assist NLP Researchers, particularly examining the effectiveness of LLM in assisting paper (meta-)reviewing and its recognizability. To address this, we constructed the ReviewCritique dataset, which includes two types of information: (i) NLP papers (initial submissions rather than camera-ready) with both human-written and LLM-generated reviews, and (ii) each review comes with "deficiency" labels and corresponding explanations for individual segments, annotated by experts. Using ReviewCritique, this study explores two threads of research questions: (i) "LLMs as Reviewers", how do reviews generated by LLMs compare with those written by humans in terms of quality and distinguishability? (ii) "LLMs as Metareviewers", how effectively can LLMs identify potential issues, such as Deficient or unprofessional review segments, within individual paper reviews? To our knowledge, this is the first work to provide such a comprehensive analysis.</li>
</ul>

<h3>Title: Title:
          Confidence Regulation Neurons in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Alessandro Stolfo, Ben Wu, Wes Gurnee, Yonatan Belinkov, Xingyi Song, Mrinmaya Sachan, Neel Nanda</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Confidence Regulation Neurons in Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite their widespread use, the mechanisms by which large language models (LLMs) represent and regulate uncertainty in next-token predictions remain largely unexplored. This study investigates two critical components believed to influence this uncertainty: the recently discovered entropy neurons and a new set of components that we term token frequency neurons. Entropy neurons are characterized by an unusually high weight norm and influence the final layer normalization (LayerNorm) scale to effectively scale down the logits. Our work shows that entropy neurons operate by writing onto an unembedding null space, allowing them to impact the residual stream norm with minimal direct effect on the logits themselves. We observe the presence of entropy neurons across a range of models, up to 7 billion parameters. On the other hand, token frequency neurons, which we discover and describe here for the first time, boost or suppress each token's logit proportionally to its log frequency, thereby shifting the output distribution towards or away from the unigram distribution. Finally, we present a detailed case study where entropy neurons actively manage confidence in the setting of induction, i.e. detecting and continuing repeated subsequences.</li>
</ul>

<h3>Title: Title:
          Video-Infinity: Distributed Long Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhenxiong Tan, Xingyi Yang, Songhua Liu, Xinchao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Video-Infinity: Distributed Long Video Generation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently achieved remarkable results for video generation. Despite the encouraging performances, the generated videos are typically constrained to a small number of frames, resulting in clips lasting merely a few seconds. The primary challenges in producing longer videos include the substantial memory requirements and the extended processing time required on a single GPU. A straightforward solution would be to split the workload across multiple GPUs, which, however, leads to two issues: (1) ensuring all GPUs communicate effectively to share timing and context information, and (2) modifying existing video diffusion models, which are usually trained on short sequences, to create longer videos without additional training. To tackle these, in this paper we introduce Video-Infinity, a distributed inference pipeline that enables parallel processing across multiple GPUs for long-form video generation. Specifically, we propose two coherent mechanisms: Clip parallelism and Dual-scope attention. Clip parallelism optimizes the gathering and sharing of context information across GPUs which minimizes communication overhead, while Dual-scope attention modulates the temporal self-attention to balance local and global contexts efficiently across the devices. Together, the two mechanisms join forces to distribute the workload and enable the fast generation of long videos. Under an 8 x Nvidia 6000 Ada GPU (48G) setup, our method generates videos up to 2,300 frames in approximately 5 minutes, enabling long video generation at a speed 100 times faster than the prior methods.</li>
</ul>

<h3>Title: Title:
          Feature-prompting GBMSeg: One-Shot Reference Guided Training-Free Prompt Engineering for Glomerular Basement Membrane Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Xueyu Liu, Guangze Shi, Rui Wang, Yexin Lai, Jianan Zhang, Lele Sun, Quan Yang, Yongfei Wu, MIng Li, Weixia Han, Wen Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Feature-prompting GBMSeg: One-Shot Reference Guided Training-Free Prompt Engineering for Glomerular Basement Membrane Segmentation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Assessment of the glomerular basement membrane (GBM) in transmission electron microscopy (TEM) is crucial for diagnosing chronic kidney disease (CKD). The lack of domain-independent automatic segmentation tools for the GBM necessitates an AI-based solution to automate the process. In this study, we introduce GBMSeg, a training-free framework designed to automatically segment the GBM in TEM images guided only by a one-shot annotated reference. Specifically, GBMSeg first exploits the robust feature matching capabilities of the pretrained foundation model to generate initial prompt points, then introduces a series of novel automatic prompt engineering techniques across the feature and physical space to optimize the prompt scheme. Finally, GBMSeg employs a class-agnostic foundation segmentation model with the generated prompt scheme to obtain accurate segmentation results. Experimental results on our collected 2538 TEM images confirm that GBMSeg achieves superior segmentation performance with a Dice similarity coefficient (DSC) of 87.27% using only one labeled reference image in a training-free manner, outperforming recently proposed one-shot or few-shot methods. In summary, GBMSeg introduces a distinctive automatic prompt framework that facilitates robust domain-independent segmentation performance without training, particularly advancing the automatic prompting of foundation segmentation models for medical images. Future work involves automating the thickness measurement of segmented GBM and quantifying pathological indicators, holding significant potential for advancing pathology assessments in clinical applications. The source code is available on this https URL</li>
</ul>

<h3>Title: Title:
          Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Chang, Mingyang Li, Junjie Wang, Yi Liu, Qing Wang, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-Image Diffusion Models (T2I DMs) have garnered significant attention for their ability to generate high-quality images from textual descriptions. However, these models often produce images that do not fully align with the input prompts, resulting in semantic inconsistencies. The most prominent issue among these semantic inconsistencies is catastrophic-neglect, where the images generated by T2I DMs miss key objects mentioned in the prompt. We first conduct an empirical study on this issue, exploring the prevalence of catastrophic-neglect, potential mitigation strategies with feature enhancement, and the insights gained. Guided by the empirical findings, we propose an automated repair approach named Patcher to address catastrophic-neglect in T2I DMs. Specifically, Patcher first determines whether there are any neglected objects in the prompt, and then applies attention-guided feature enhancement to these neglected objects, resulting in a repaired prompt. Experimental results on three versions of Stable Diffusion demonstrate that Patcher effectively repairs the issue of catastrophic-neglect, achieving 10.1%-16.3% higher Correct Rate in image generation compared to baselines.</li>
</ul>

<h3>Title: Title:
          YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals</h3>
<ul>
<li><strong>Authors: </strong>Sandeep Mishra, Oindrila Saha, Alan C. Bovik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>3D generation guided by text-to-image diffusion models enables the creation of visually compelling assets. However previous methods explore generation based on image or text. The boundaries of creativity are limited by what can be expressed through words or the images that can be sourced. We present YouDream, a method to generate high-quality anatomically controllable animals. YouDream is guided using a text-to-image diffusion model controlled by 2D views of a 3D pose prior. Our method generates 3D animals that are not possible to create using previous text-to-3D generative methods. Additionally, our method is capable of preserving anatomic consistency in the generated animals, an area where prior text-to-3D approaches often struggle. Moreover, we design a fully automated pipeline for generating commonly found animals. To circumvent the need for human intervention to create a 3D pose, we propose a multi-agent LLM that adapts poses from a limited library of animal 3D poses to represent the desired animal. A user study conducted on the outcomes of YouDream demonstrates the preference of the animal models generated by our method over others. Turntable results and code are released at this https URL</li>
</ul>

<h3>Title: Title:
          Investigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection</h3>
<ul>
<li><strong>Authors: </strong>Choonghyun Park, Hyuhng Joon Kim, Junyeob Kim, Youna Kim, Taeuk Kim, Hyunsoo Cho, Hwiyeol Jo, Sang-goo Lee, Kang Min Yoo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Investigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>AI Generated Text (AIGT) detectors are developed with texts from humans and LLMs of common tasks. Despite the diversity of plausible prompt choices, these datasets are generally constructed with a limited number of prompts. The lack of prompt variation can introduce prompt-specific shortcut features that exist in data collected with the chosen prompt, but do not generalize to others. In this paper, we analyze the impact of such shortcuts in AIGT detection. We propose Feedback-based Adversarial Instruction List Optimization (FAILOpt), an attack that searches for instructions deceptive to AIGT detectors exploiting prompt-specific shortcuts. FAILOpt effectively drops the detection performance of the target detector, comparable to other attacks based on adversarial in-context examples. We also utilize our method to enhance the robustness of the detector by mitigating the shortcuts. Based on the findings, we further train the classifier with the dataset augmented by FAILOpt prompt. The augmented classifier exhibits improvements across generation models, tasks, and attacks. Our code will be available at this https URL.</li>
</ul>

<h3>Title: Title:
          SegNet4D: Effective and Efficient 4D LiDAR Semantic Segmentation in Autonomous Driving Environments</h3>
<ul>
<li><strong>Authors: </strong>Neng Wang, Ruibin Guo, Chenghao Shi, Hui Zhang, Huimin Lu, Zhiqiang Zheng, Xieyuanli Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          SegNet4D: Effective and Efficient 4D LiDAR Semantic Segmentation in Autonomous Driving Environments(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>4D LiDAR semantic segmentation, also referred to as multi-scan semantic segmentation, plays a crucial role in enhancing the environmental understanding capabilities of autonomous vehicles. It entails identifying the semantic category of each point in the LiDAR scan and distinguishing whether it is dynamic, a critical aspect in downstream tasks such as path planning and autonomous navigation. Existing methods for 4D semantic segmentation often rely on computationally intensive 4D convolutions for multi-scan input, resulting in poor real-time performance. In this article, we introduce SegNet4D, a novel real-time multi-scan semantic segmentation method leveraging a projection-based approach for fast motion feature encoding, showcasing outstanding performance. SegNet4D treats 4D semantic segmentation as two distinct tasks: single-scan semantic segmentation and moving object segmentation, each addressed by dedicated head. These results are then fused in the proposed motion-semantic fusion module to achieve comprehensive multi-scan semantic segmentation. Besides, we propose extracting instance information from the current scan and incorporating it into the network for instance-aware segmentation. Our approach exhibits state-of-the-art performance across multiple datasets and stands out as a real-time multi-scan semantic segmentation method. The implementation of SegNet4D will be made available at \url{this https URL}.</li>
</ul>

<h3>Title: Title:
          PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection</h3>
<ul>
<li><strong>Authors: </strong>Jooyoung Lee, Toshini Agrawal, Adaku Uchendu, Thai Le, Jinghui Chen, Dongwon Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent literature has highlighted potential risks to academic integrity associated with large language models (LLMs), as they can memorize parts of training instances and reproduce them in the generated texts without proper attribution. In addition, given their capabilities in generating high-quality texts, plagiarists can exploit LLMs to generate realistic paraphrases or summaries indistinguishable from original work. In response to possible malicious use of LLMs in plagiarism, we introduce PlagBench, a comprehensive dataset consisting of 46.5K synthetic plagiarism cases generated using three instruction-tuned LLMs across three writing domains. The quality of PlagBench is ensured through fine-grained automatic evaluation for each type of plagiarism, complemented by human annotation. We then leverage our proposed dataset to evaluate the plagiarism detection performance of five modern LLMs and three specialized plagiarism checkers. Our findings reveal that GPT-3.5 tends to generates paraphrases and summaries of higher quality compared to Llama2 and GPT-4. Despite LLMs' weak performance in summary plagiarism identification, they can surpass current commercial plagiarism detectors. Overall, our results highlight the potential of LLMs to serve as robust plagiarism detection tools.</li>
</ul>

<h3>Title: Title:
          Combining Supervised Learning and Reinforcement Learning for Multi-Label Classification Tasks with Partial Labels</h3>
<ul>
<li><strong>Authors: </strong>Zixia Jia, Junpeng Li, Shichuan Zhang, Anji Liu, Zilong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Combining Supervised Learning and Reinforcement Learning for Multi-Label Classification Tasks with Partial Labels(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Traditional supervised learning heavily relies on human-annotated datasets, especially in data-hungry neural approaches. However, various tasks, especially multi-label tasks like document-level relation extraction, pose challenges in fully manual annotation due to the specific domain knowledge and large class sets. Therefore, we address the multi-label positive-unlabelled learning (MLPUL) problem, where only a subset of positive classes is annotated. We propose Mixture Learner for Partially Annotated Classification (MLPAC), an RL-based framework combining the exploration ability of reinforcement learning and the exploitation ability of supervised learning. Experimental results across various tasks, including document-level relation extraction, multi-label image classification, and binary PU learning, demonstrate the generalization and effectiveness of our framework.</li>
</ul>

<h3>Title: Title:
          LangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments</h3>
<ul>
<li><strong>Authors: </strong>Zixia Jia, Mengmeng Wang, Baichen Tong, Song-Chun Zhu, Zilong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          LangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) have shown inspiring achievements in constructing autonomous agents that rely on language descriptions as inputs. However, it remains unclear how well LLMs can function as few-shot or zero-shot embodied agents in dynamic interactive environments. To address this gap, we introduce LangSuitE, a versatile and simulation-free testbed featuring 6 representative embodied tasks in textual embodied worlds. Compared with previous LLM-based testbeds, LangSuitE (i) offers adaptability to diverse environments without multiple simulation engines, (ii) evaluates agents' capacity to develop ``internalized world knowledge'' with embodied observations, and (iii) allows easy customization of communication and action strategies. To address the embodiment challenge, we devise a novel chain-of-thought (CoT) schema, EmMem, which summarizes embodied states w.r.t. history information. Comprehensive benchmark results illustrate challenges and insights of embodied planning. LangSuitE represents a significant step toward building embodied generalists in the context of language models.</li>
</ul>

<h3>Title: Title:
          Priorformer: A UGC-VQA Method with content and distortion priors</h3>
<ul>
<li><strong>Authors: </strong>Yajing Pei, Shiyu Huang, Yiting Lu, Xin Li, Zhibo Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Priorformer: A UGC-VQA Method with content and distortion priors(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>User Generated Content (UGC) videos are susceptible to complicated and variant degradations and contents, which prevents the existing blind video quality assessment (BVQA) models from good performance since the lack of the adapability of distortions and contents. To mitigate this, we propose a novel prior-augmented perceptual vision transformer (PriorFormer) for the BVQA of UGC, which boots its adaptability and representation capability for divergent contents and distortions. Concretely, we introduce two powerful priors, i.e., the content and distortion priors, by extracting the content and distortion embeddings from two pre-trained feature extractors. Then we adopt these two powerful embeddings as the adaptive prior tokens, which are transferred to the vision transformer backbone jointly with implicit quality features. Based on the above strategy, the proposed PriorFormer achieves state-of-the-art performance on three public UGC VQA datasets including KoNViD-1K, LIVE-VQC and YouTube-UGC.</li>
</ul>

<h3>Title: Title:
          Compensate Quantization Errors: Make Weights Hierarchical to Compensate Each Other</h3>
<ul>
<li><strong>Authors: </strong>Yifei Gao, Jie Ou, Lei Wang, Yuting Xiao, Zhiyuan Xiang, Ruiting Dai, Jun Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Compensate Quantization Errors: Make Weights Hierarchical to Compensate Each Other(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Emergent Large Language Models (LLMs) use their extraordinary performance and powerful deduction capacity to discern from traditional language models. However, the expenses of computational resources and storage for these LLMs are stunning, quantization then arises as a trending conversation. To address accuracy decay caused by quantization, two streams of works in post-training quantization methods stand out. One uses other weights to compensate existing quantization error, while the other transfers the quantization difficulty to other parts in the model. Combining both merits, we introduce Learnable Singular value Increment (LSI) as an advanced solution. LSI uses Singular Value Decomposition to extract singular values of the weights and make them learnable to help weights compensate each other conditioned on activation. Incorporating LSI with existing techniques, we achieve state-of-the-art performance in diverse quantization settings, no matter in weight-only, weight-activation or extremely low bit scenarios. By unleashing the potential of LSI, efficient finetuning on quantized model is no longer a prohibitive problem.</li>
</ul>

<h3>Title: Title:
          UBiSS: A Unified Framework for Bimodal Semantic Summarization of Videos</h3>
<ul>
<li><strong>Authors: </strong>Yuting Mei, Linli Yao, Qin Jin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          UBiSS: A Unified Framework for Bimodal Semantic Summarization of Videos(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>With the surge in the amount of video data, video summarization techniques, including visual-modal(VM) and textual-modal(TM) summarization, are attracting more and more attention. However, unimodal summarization inevitably loses the rich semantics of the video. In this paper, we focus on a more comprehensive video summarization task named Bimodal Semantic Summarization of Videos (BiSSV). Specifically, we first construct a large-scale dataset, BIDS, in (video, VM-Summary, TM-Summary) triplet format. Unlike traditional processing methods, our construction procedure contains a VM-Summary extraction algorithm aiming to preserve the most salient content within long videos. Based on BIDS, we propose a Unified framework UBiSS for the BiSSV task, which models the saliency information in the video and generates a TM-summary and VM-summary simultaneously. We further optimize our model with a list-wise ranking-based objective to improve its capacity to capture highlights. Lastly, we propose a metric, $NDCG_{MS}$, to provide a joint evaluation of the bimodal summary. Experiments show that our unified framework achieves better performance than multi-stage summarization pipelines. Code and data are available at this https URL.</li>
</ul>

<h3>Title: Title:
          Cascade Reward Sampling for Efficient Decoding-Time Alignment</h3>
<ul>
<li><strong>Authors: </strong>Bolian Li, Yifan Wang, Ananth Grama, Ruqi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Cascade Reward Sampling for Efficient Decoding-Time Alignment(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models (LLMs) with human preferences is critical for their deployment. Recently, decoding-time alignment has emerged as an effective plug-and-play technique that requires no fine-tuning of model parameters. However, generating text that achieves both high reward and high likelihood remains a significant challenge. Existing methods often fail to generate high-reward text or incur substantial computational costs. In this paper, we propose Cascade Reward Sampling (CARDS) to address both issues, guaranteeing the generation of high-reward and high-likelihood text with significantly low costs. Based on our analysis of reward models (RMs) on incomplete text and our observation that high-reward prefixes induce high-reward complete text, we use rejection sampling to iteratively generate small semantic segments to form such prefixes. The segment length is dynamically determined by the predictive uncertainty of LLMs. This strategy guarantees desirable prefixes for subsequent generations and significantly reduces wasteful token re-generations and the number of reward model scoring. Our experiments demonstrate substantial gains in both generation efficiency and alignment ratings compared to the baselines, achieving five times faster text generation and 99\% win-ties in GPT-4/Claude-3 helpfulness evaluation.</li>
</ul>

<h3>Title: Title:
          Artistic-style text detector and a new Movie-Poster dataset</h3>
<ul>
<li><strong>Authors: </strong>Aoxiang Ning, Yiting Wei, Minglong Xue, Senming Zhong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Artistic-style text detector and a new Movie-Poster dataset(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Although current text detection algorithms demonstrate effectiveness in general scenarios, their performance declines when confronted with artistic-style text featuring complex structures. This paper proposes a method that utilizes Criss-Cross Attention and residual dense block to address the incomplete and misdiagnosis of artistic-style text detection by current algorithms. Specifically, our method mainly consists of a feature extraction backbone, a feature enhancement network, a multi-scale feature fusion module, and a boundary discrimination module. The feature enhancement network significantly enhances the model's perceptual capabilities in complex environments by fusing horizontal and vertical contextual information, allowing it to capture detailed features overlooked in artistic-style text. We incorporate residual dense block into the Feature Pyramid Network to suppress the effect of background noise during feature fusion. Aiming to omit the complex post-processing, we explore a boundary discrimination module that guides the correct generation of boundary proposals. Furthermore, given that movie poster titles often use stylized art fonts, we collected a Movie-Poster dataset to address the scarcity of artistic-style text data. Extensive experiments demonstrate that our proposed method performs superiorly on the Movie-Poster dataset and produces excellent results on multiple benchmark datasets. The code and the Movie-Poster dataset will be available at: this https URL</li>
</ul>

<h3>Title: Title:
          Anomaly Detection of Tabular Data Using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Aodong Li, Yunhan Zhao, Chen Qiu, Marius Kloft, Padhraic Smyth, Maja Rudolph, Stephan Mandt</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Anomaly Detection of Tabular Data Using LLMs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning. In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zero-shot batch-level anomaly detectors. That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data, demonstrating their ability to identify low-density data regions. For LLMs that are not well aligned with anomaly detection and frequently output factual errors, we apply simple yet effective data-generating processes to simulate synthetic batch-level anomaly detection datasets and propose an end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies. Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art transductive learning-based anomaly detection methods and ii) the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.</li>
</ul>

<h3>Title: Title:
          Thinking Inside The Box: Privacy Against Stronger Adversaries</h3>
<ul>
<li><strong>Authors: </strong>Eldon Chung</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Thinking Inside The Box: Privacy Against Stronger Adversaries(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In this thesis, we study extensions of statistical cryptographic primitives. In particular we study leakage-resilient secret sharing, non-malleable extractors, and immunized ideal one-way functions. The thesis is divided into three main chapters. In the first chapter, we show that 2-out-of-2 leakage resilient (and also non-malleable) secret sharing requires randomness sources that are also extractable. This rules out the possibility of using min-entropic sources. In the second, we introduce collision-resistant seeded extractors and show that any seeded extractor can be made collision resistant at a small overhead in seed length. We then use it to give a two-source non-malleable extractor with entropy rate 0.81 in one source and polylogarithmic in the other. The non-malleable extractor lead to the first statistical privacy amplification protocol against memory tampering adversaries. In the final chapter, we study the hardness of the data structure variant of the 3SUM problem which is motivated by a recent construction to immunise random oracles against pre-processing adversaries. We give worst-case data structure hardness for the 3SUM problem matching known barriers in data structures for adaptive adversaries. We also give a slightly stronger lower bound in the case of non-adaptivity. Lastly, we give a novel result in the bit-probe setting.</li>
</ul>

<h3>Title: Title:
          What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Noise-free Text-Image Corruption and Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Michal Golovanevsky, William Rudman, Vedant Palit, Ritambhara Singh, Carsten Eickhoff</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Noise-free Text-Image Corruption and Evaluation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) have gained community-spanning prominence due to their ability to integrate visual and textual inputs to perform complex tasks. Despite their success, the internal decision-making processes of these models remain opaque, posing challenges in high-stakes applications. To address this, we introduce NOTICE, the first Noise-free Text-Image Corruption and Evaluation pipeline for mechanistic interpretability in VLMs. NOTICE incorporates a Semantic Minimal Pairs (SMP) framework for image corruption and Symmetric Token Replacement (STR) for text. This approach enables semantically meaningful causal mediation analysis for both modalities, providing a robust method for analyzing multimodal integration within models like BLIP. Our experiments on the SVO-Probes, MIT-States, and Facial Expression Recognition datasets reveal crucial insights into VLM decision-making, identifying the significant role of middle-layer cross-attention heads. Further, we uncover a set of ``universal cross-attention heads'' that consistently contribute across tasks and modalities, each performing distinct functions such as implicit image segmentation, object inhibition, and outlier inhibition. This work paves the way for more transparent and interpretable multimodal systems.</li>
</ul>

<h3>Title: Title:
          Multimodal Graph Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Jing Zhu, Yuhang Zhou, Shengyi Qian, Zhongmou He, Tong Zhao, Neil Shah, Danai Koutra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Multimodal Graph Benchmark(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Associating unstructured data with structured information is crucial for real-world tasks that require relevance search. However, existing graph learning benchmarks often overlook the rich semantic information associate with each node. To bridge such gap, we introduce the Multimodal Graph Benchmark (MM-GRAPH), the first comprehensive multi-modal graph benchmark that incorporates both textual and visual information. MM-GRAPH surpasses previous efforts, which have primarily focused on text-attributed graphs with various connectivity patterns. MM-GRAPH consists of five graph learning datasets of various scales that are appropriate for different learning tasks. Their multimodal node features, enabling a more comprehensive evaluation of graph learning algorithms in real-world scenarios. To facilitate research on multimodal graph learning, we further provide an extensive study on the performance of various graph neural networks in the presence of features from various modalities. MM-GRAPH aims to foster research on multimodal graph learning and drive the development of more advanced and robust graph learning algorithms. By providing a diverse set of datasets and benchmarks, MM-GRAPH enables researchers to evaluate and compare their models in realistic settings, ultimately leading to improved performance on real-world applications that rely on multimodal graph data.</li>
</ul>

<h3>Title: Title:
          Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging</h3>
<ul>
<li><strong>Authors: </strong>Deyuan Liu, Zhanyue Qin, Hairu Wang, Zhao Yang, Zecheng Wang, Fangying Rong, Qingbin Liu, Yanchao Hao, Xi Chen, Cunhang Fan, Zhao Lv, Zhiying Tu, Dianhui Chu, Bo Li, Dianbo Sui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) excel in many domains, their complexity and scale challenge deployment in resource-limited environments. Current compression techniques, such as parameter pruning, often fail to effectively utilize the knowledge from pruned parameters. To address these challenges, we propose Manifold-Based Knowledge Alignment and Layer Merging Compression (MKA), a novel approach that uses manifold learning and the Normalized Pairwise Information Bottleneck (NPIB) measure to merge similar layers, reducing model size while preserving essential performance. We evaluate MKA on multiple benchmark datasets and various LLMs. Our findings show that MKA not only preserves model performance but also achieves substantial compression ratios, outperforming traditional pruning methods. Moreover, when coupled with quantization, MKA delivers even greater compression. Specifically, on the MMLU dataset using the Llama3-8B model, MKA achieves a compression ratio of 43.75% with a minimal performance decrease of only 2.82\%. The proposed MKA method offers a resource-efficient and performance-preserving model compression technique for LLMs.</li>
</ul>

<h3>Title: Title:
          Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yichen Sun, Zhixuan Chu, Zhan Qin, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Text-to-Image(T2I) generative models has enabled the synthesis of high-quality images guided by textual descriptions. Despite this significant progress, these models are often susceptible in generating contents that contradict the input text, which poses a challenge to their reliability and practical deployment. To address this problem, we introduce a novel diffusion-based framework to significantly enhance the alignment of generated images with their corresponding descriptions, addressing the inconsistency between visual output and textual input. Our framework is built upon a comprehensive analysis of inconsistency phenomena, categorizing them based on their manifestation in the image. Leveraging a state-of-the-art large language module, we first extract objects and construct a knowledge graph to predict the locations of these objects in potentially generated images. We then integrate a state-of-the-art controllable image generation model with a visual text generation module to generate an image that is consistent with the original prompt, guided by the predicted object locations. Through extensive experiments on an advanced multimodal hallucination benchmark, we demonstrate the efficacy of our approach in accurately generating the images without the inconsistency with the original prompt. The code can be accessed via this https URL.</li>
</ul>

<h3>Title: Title:
          VideoHallucer: Evaluating Intrinsic and Extrinsic Hallucinations in Large Video-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Wang, Yueqian Wang, Dongyan Zhao, Cihang Xie, Zilong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          VideoHallucer: Evaluating Intrinsic and Extrinsic Hallucinations in Large Video-Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Multimodal Large Language Models (MLLMs) have extended their capabilities to video understanding. Yet, these models are often plagued by "hallucinations", where irrelevant or nonsensical content is generated, deviating from the actual video context. This work introduces VideoHallucer, the first comprehensive benchmark for hallucination detection in large video-language models (LVLMs). VideoHallucer categorizes hallucinations into two main types: intrinsic and extrinsic, offering further subcategories for detailed analysis, including object-relation, temporal, semantic detail, extrinsic factual, and extrinsic non-factual hallucinations. We adopt an adversarial binary VideoQA method for comprehensive evaluation, where pairs of basic and hallucinated questions are crafted strategically. By evaluating eleven LVLMs on VideoHallucer, we reveal that i) the majority of current models exhibit significant issues with hallucinations; ii) while scaling datasets and parameters improves models' ability to detect basic visual cues and counterfactuals, it provides limited benefit for detecting extrinsic factual hallucinations; iii) existing models are more adept at detecting facts than identifying hallucinations. As a byproduct, these analyses further instruct the development of our self-PEP framework, achieving an average of 5.38% improvement in hallucination resistance across all model architectures.</li>
</ul>

<h3>Title: Title:
          EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records</h3>
<ul>
<li><strong>Authors: </strong>Yeonsu Kwon, Jiho Kim, Gyubok Lee, Seongsu Bae, Daeun Kyung, Wonchul Cha, Tom Pollard, Alistair Johnson, Edward Choi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Electronic Health Records (EHRs) are integral for storing comprehensive patient medical records, combining structured data (e.g., medications) with detailed clinical notes (e.g., physician notes). These elements are essential for straightforward data retrieval and provide deep, contextual insights into patient care. However, they often suffer from discrepancies due to unintuitive EHR system designs and human errors, posing serious risks to patient safety. To address this, we developed EHRCon, a new dataset and task specifically designed to ensure data consistency between structured tables and unstructured notes in EHRs. EHRCon was crafted in collaboration with healthcare professionals using the MIMIC-III EHR dataset, and includes manual annotations of 3,943 entities across 105 clinical notes checked against database entries for consistency. EHRCon has two versions, one using the original MIMIC-III schema, and another using the OMOP CDM schema, in order to increase its applicability and generalizability. Furthermore, leveraging the capabilities of large language models, we introduce CheckEHR, a novel framework for verifying the consistency between clinical notes and database tables. CheckEHR utilizes an eight-stage process and shows promising results in both few-shot and zero-shot settings. The code is available at this https URL.</li>
</ul>

<h3>Title: Title:
          Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks</h3>
<ul>
<li><strong>Authors: </strong>Daniel Wen, Nafisa Hussain</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) and large visual language models (LVLMs) have been at the forefront of the artificial intelligence field, particularly for tasks like text generation, video captioning, and question-answering. Typically, it is more applicable to train these models on broader knowledge bases or datasets to increase generalizability, learn relationships between topics, and recognize patterns. Instead, we propose to provide instructional datasets specific to the task of each modality within a distinct domain and then fine-tune the parameters of the model using LORA. With our approach, we can eliminate all noise irrelevant to the given task while also ensuring that the model generates with enhanced precision. For this work, we use Video-LLaVA to generate recipes given cooking videos without transcripts. Video-LLaVA's multimodal architecture allows us to provide cooking images to its image encoder, cooking videos to its video encoder, and general cooking questions to its text encoder. Thus, we aim to remove all noise unrelated to cooking while improving our model's capabilities to generate specific ingredient lists and detailed instructions. As a result, our approach to fine-tuning Video-LLaVA leads to gains over the baseline Video-LLaVA by 2% on the YouCook2 dataset. While this may seem like a marginal increase, our model trains on an image instruction dataset 2.5% the size of Video-LLaVA's and a video instruction dataset 23.76% of Video-LLaVA's.</li>
</ul>

<h3>Title: Title:
          VulZoo: A Comprehensive Vulnerability Intelligence Dataset</h3>
<ul>
<li><strong>Authors: </strong>Bonan Ruan, Jiahao Liu, Weibo Zhao, Zhenkai Liang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          VulZoo: A Comprehensive Vulnerability Intelligence Dataset(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Software vulnerabilities pose critical security and risk concerns for many software systems. Many techniques have been proposed to effectively assess and prioritize these vulnerabilities before they cause serious consequences. To evaluate their performance, these solutions often craft their own experimental datasets from limited information sources, such as MITRE CVE and NVD, lacking a global overview of broad vulnerability intelligence. The repetitive data preparation process further complicates the verification and comparison of new solutions. To resolve this issue, in this paper, we propose VulZoo, a comprehensive vulnerability intelligence dataset that covers 17 popular vulnerability information sources. We also construct connections among these sources, enabling more straightforward configuration and adaptation for different vulnerability assessment tasks (e.g., vulnerability type prediction). Additionally, VulZoo provides utility scripts for automatic data synchronization and cleaning, relationship mining, and statistics generation. We make VulZoo publicly available and maintain it with incremental updates to facilitate future research. We believe that VulZoo serves as a valuable input to vulnerability assessment and prioritization studies. The dataset with utility scripts is available at this https URL.</li>
</ul>

<h3>Title: Title:
          METRIK: Measurement-Efficient Randomized Controlled Trials using Transformers with Input Masking</h3>
<ul>
<li><strong>Authors: </strong>Sayeri Lala (1), Niraj K. Jha (1) ((1) Princeton University, Princeton, USA)</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          METRIK: Measurement-Efficient Randomized Controlled Trials using Transformers with Input Masking(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Clinical randomized controlled trials (RCTs) collect hundreds of measurements spanning various metric types (e.g., laboratory tests, cognitive/motor assessments, etc.) across 100s-1000s of subjects to evaluate the effect of a treatment, but do so at the cost of significant trial expense. To reduce the number of measurements, trial protocols can be revised to remove metrics extraneous to the study's objective, but doing so requires additional human labor and limits the set of hypotheses that can be studied with the collected data. In contrast, a planned missing design (PMD) can reduce the amount of data collected without removing any metric by imputing the unsampled data. Standard PMDs randomly sample data to leverage statistical properties of imputation algorithms, but are ad hoc, hence suboptimal. Methods that learn PMDs produce more sample-efficient PMDs, but are not suitable for RCTs because they require ample prior data (150+ subjects) to model the data distribution. Therefore, we introduce a framework called Measurement EfficienT Randomized Controlled Trials using Transformers with Input MasKing (METRIK), which, for the first time, calculates a PMD specific to the RCT from a modest amount of prior data (e.g., 60 subjects). Specifically, METRIK models the PMD as a learnable input masking layer that is optimized with a state-of-the-art imputer based on the Transformer architecture. METRIK implements a novel sampling and selection algorithm to generate a PMD that satisfies the trial designer's objective, i.e., whether to maximize sampling efficiency or imputation performance for a given sampling budget. Evaluated across five real-world clinical RCT datasets, METRIK increases the sampling efficiency of and imputation performance under the generated PMD by leveraging correlations over time and across metrics, thereby removing the need to manually remove metrics from the RCT.</li>
</ul>

<h3>Title: Title:
          Compact Model Parameter Extraction via Derivative-Free Optimization</h3>
<ul>
<li><strong>Authors: </strong>Rafael Perez Martinez, Masaya Iwamoto, Kelly Woo, Zhengliang Bian, Roberto Tinti, Stephen Boyd, Srabanti Chowdhury</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Compact Model Parameter Extraction via Derivative-Free Optimization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this paper, we address the problem of compact model parameter extraction to simultaneously extract tens of parameters via derivative-free optimization. Traditionally, parameter extraction is performed manually by dividing the complete set of parameters into smaller subsets, each targeting different operational regions of the device, a process that can take several days or even weeks. Our approach streamlines this process by employing derivative-free optimization to identify a good parameter set that best fits the compact model without performing an exhaustive number of simulations. We further enhance the optimization process to address critical issues in device modeling by carefully choosing a loss function that evaluates model performance consistently across varying magnitudes by focusing on relative errors (as opposed to absolute errors), prioritizing accuracy in key operational regions of the device above a certain threshold, and reducing sensitivity to outliers. Furthermore, we utilize the concept of train-test split to assess the model fit and avoid overfitting. This is done by fitting 80% of the data and testing the model efficacy with the remaining 20%. We demonstrate the effectiveness of our methodology by successfully modeling two semiconductor devices: a diamond Schottky diode and a GaN-on-SiC HEMT, with the latter involving the ASM-HEMT DC model, which requires simultaneously extracting 35 model parameters to fit the model to the measured data. These examples demonstrate the effectiveness of our approach and showcase the practical benefits of derivative-free optimization in device modeling.</li>
</ul>

<h3>Title: Title:
          Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation</h3>
<ul>
<li><strong>Authors: </strong>Rem Hida, Junki Ohmura, Toshiyuki Sekiya</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction-tuned Large Language Models (LLMs) have achieved remarkable performance across various benchmark tasks. While providing instructions to LLMs for guiding their generations is user-friendly, assessing their instruction-following capabilities is still unclarified due to a lack of evaluation metrics. In this paper, we focus on evaluating the instruction-following ability of LLMs in the context of story-ending generation, which requires diverse and context-specific instructions. We propose an automatic evaluation pipeline that utilizes a machine reading comprehension (MRC) model to determine whether the generated story-ending reflects instruction. Our findings demonstrate that our proposed metric aligns with human evaluation. Furthermore, our experiments confirm that recent open-source LLMs can achieve instruction-following performance close to GPT-3.5, as assessed through automatic evaluation.</li>
</ul>

<h3>Title: Title:
          Machine Learning with Real-time and Small Footprint Anomaly Detection System for In-Vehicle Gateway</h3>
<ul>
<li><strong>Authors: </strong>Yi Wang, Yuanjin Zheng, Yajun Ha</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Machine Learning with Real-time and Small Footprint Anomaly Detection System for In-Vehicle Gateway(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Anomaly Detection System (ADS) is an essential part of a modern gateway Electronic Control Unit (ECU) to detect abnormal behaviors and attacks in vehicles. Among the existing attacks, ``one-time`` attack is the most challenging to be detected, together with the strict gateway ECU constraints of both microsecond or even nanosecond level real-time budget and limited footprint of code. To address the challenges, we propose to use the self-information theory to generate values for training and testing models, aiming to achieve real-time detection performance for the ``one-time`` attack that has not been well studied in the past. Second, the generation of self-information is based on logarithm calculation, which leads to the smallest footprint to reduce the cost in Gateway. Finally, our proposed method uses an unsupervised model without the need of training data for anomalies or attacks. We have compared different machine learning methods ranging from typical machine learning models to deep learning models, e.g., Hidden Markov Model (HMM), Support Vector Data Description (SVDD), and Long Short Term Memory (LSTM). Experimental results show that our proposed method achieves 8.7 times lower False Positive Rate (FPR), 1.77 times faster testing time, and 4.88 times smaller footprint.</li>
</ul>

<h3>Title: Title:
          UniPSDA: Unsupervised Pseudo Semantic Data Augmentation for Zero-Shot Cross-Lingual Natural Language Understanding</h3>
<ul>
<li><strong>Authors: </strong>Dongyang Li, Taolin Zhang, Jiali Deng, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          UniPSDA: Unsupervised Pseudo Semantic Data Augmentation for Zero-Shot Cross-Lingual Natural Language Understanding(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Cross-lingual representation learning transfers knowledge from resource-rich data to resource-scarce ones to improve the semantic understanding abilities of different languages. However, previous works rely on shallow unsupervised data generated by token surface matching, regardless of the global context-aware semantics of the surrounding text tokens. In this paper, we propose an Unsupervised Pseudo Semantic Data Augmentation (UniPSDA) mechanism for cross-lingual natural language understanding to enrich the training data without human interventions. Specifically, to retrieve the tokens with similar meanings for the semantic data augmentation across different languages, we propose a sequential clustering process in 3 stages: within a single language, across multiple languages of a language family, and across languages from multiple language families. Meanwhile, considering the multi-lingual knowledge infusion with context-aware semantics while alleviating computation burden, we directly replace the key constituents of the sentences with the above-learned multi-lingual family knowledge, viewed as pseudo-semantic. The infusion process is further optimized via three de-biasing techniques without introducing any neural parameters. Extensive experiments demonstrate that our model consistently improves the performance on general zero-shot cross-lingual natural language understanding tasks, including sequence classification, information extraction, and question answering.</li>
</ul>

<h3>Title: Title:
          On the Transformations across Reward Model, Parameter Update, and In-Context Prompt</h3>
<ul>
<li><strong>Authors: </strong>Deng Cai, Huayang Li, Tingchen Fu, Siheng Li, Weiwen Xu, Shuaiyi Li, Bowen Cao, Zhisong Zhang, Xinting Huang, Leyang Cui, Yan Wang, Lemao Liu, Taro Watanabe, Shuming Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          On the Transformations across Reward Model, Parameter Update, and In-Context Prompt(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the general capabilities of pre-trained large language models (LLMs), they still need further adaptation to better serve practical applications. In this paper, we demonstrate the interchangeability of three popular and distinct adaptation tools: parameter updating, reward modeling, and in-context prompting. This interchangeability establishes a triangular framework with six transformation directions, each of which facilitates a variety of applications. Our work offers a holistic view that unifies numerous existing studies and suggests potential research directions. We envision our work as a useful roadmap for future research on LLMs.</li>
</ul>

<h3>Title: Title:
          UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhanyue Qin, Haochuan Wang, Deyuan Liu, Ziyang Song, Cunhang Fan, Zhao Lv, Jinlin Wu, Zhen Lei, Zhiying Tu, Dianhui Chu, Xiaoyan Yu, Dianbo Sui</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sequential decision-making refers to algorithms that take into account the dynamics of the environment, where early decisions affect subsequent decisions. With large language models (LLMs) demonstrating powerful capabilities between tasks, we can't help but ask: Can Current LLMs Effectively Make Sequential Decisions? In order to answer this question, we propose the UNO Arena based on the card game UNO to evaluate the sequential decision-making capability of LLMs and explain in detail why we choose UNO. In UNO Arena, We evaluate the sequential decision-making capability of LLMs dynamically with novel metrics based Monte Carlo methods. We set up random players, DQN-based reinforcement learning players, and LLM players (e.g. GPT-4, Gemini-pro) for comparison testing. Furthermore, in order to improve the sequential decision-making capability of LLMs, we propose the TUTRI player, which can involves having LLMs reflect their own actions wtih the summary of game history and the game strategy. Numerous experiments demonstrate that the TUTRI player achieves a notable breakthrough in the performance of sequential decision-making compared to the vanilla LLM player.</li>
</ul>

<h3>Title: Title:
          Multilingual Knowledge Editing with Language-Agnostic Factual Neurons</h3>
<ul>
<li><strong>Authors: </strong>Xue zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Multilingual Knowledge Editing with Language-Agnostic Factual Neurons(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multilingual knowledge editing (MKE) aims to simultaneously revise factual knowledge across multilingual languages within large language models (LLMs). However, most existing MKE methods just adapt existing monolingual editing methods to multilingual scenarios, overlooking the deep semantic connections of the same factual knowledge between different languages, thereby limiting edit performance. To address this issue, we first investigate how LLMs represent multilingual factual knowledge and discover that the same factual knowledge in different languages generally activates a shared set of neurons, which we call language-agnostic factual neurons. These neurons represent the semantic connections between multilingual knowledge and are mainly located in certain layers. Inspired by this finding, we propose a new MKE method by locating and modifying Language-Agnostic Factual Neurons (LAFN) to simultaneously edit multilingual knowledge. Specifically, we first generate a set of paraphrases for each multilingual knowledge to be edited to precisely locate the corresponding language-agnostic factual neurons. Then we optimize the update values for modifying these located neurons to achieve simultaneous modification of the same factual knowledge in multiple languages. Experimental results on Bi-ZsRE and MzsRE benchmarks demonstrate that our method outperforms existing MKE methods and achieves remarkable edit performance, indicating the importance of considering the semantic connections among multilingual knowledge.</li>
</ul>

<h3>Title: Title:
          Exploring Cross-Domain Few-Shot Classification via Frequency-Aware Prompting</h3>
<ul>
<li><strong>Authors: </strong>Tiange Zhang, Qing Cai, Feng Gao, Lin Qi, Junyu Dong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Exploring Cross-Domain Few-Shot Classification via Frequency-Aware Prompting(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cross-Domain Few-Shot Learning has witnessed great stride with the development of meta-learning. However, most existing methods pay more attention to learning domain-adaptive inductive bias (meta-knowledge) through feature-wise manipulation or task diversity improvement while neglecting the phenomenon that deep networks tend to rely more on high-frequency cues to make the classification decision, which thus degenerates the robustness of learned inductive bias since high-frequency information is vulnerable and easy to be disturbed by noisy information. Hence in this paper, we make one of the first attempts to propose a Frequency-Aware Prompting method with mutual attention for Cross-Domain Few-Shot classification, which can let networks simulate the human visual perception of selecting different frequency cues when facing new recognition tasks. Specifically, a frequency-aware prompting mechanism is first proposed, in which high-frequency components of the decomposed source image are switched either with normal distribution sampling or zeroing to get frequency-aware augment samples. Then, a mutual attention module is designed to learn generalizable inductive bias under CD-FSL settings. More importantly, the proposed method is a plug-and-play module that can be directly applied to most off-the-shelf CD-FLS methods. Experimental results on CD-FSL benchmarks demonstrate the effectiveness of our proposed method as well as robustly improve the performance of existing CD-FLS methods. Resources at this https URL.</li>
</ul>

<h3>Title: Title:
          Dynamic Pseudo Label Optimization in Point-Supervised Nuclei Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ziyue Wang, Ye Zhang, Yifeng Wang, Linghan Cai, Yongbing Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Dynamic Pseudo Label Optimization in Point-Supervised Nuclei Segmentation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning has achieved impressive results in nuclei segmentation, but the massive requirement for pixel-wise labels remains a significant challenge. To alleviate the annotation burden, existing methods generate pseudo masks for model training using point labels. However, the generated masks are inevitably different from the ground truth, and these dissimilarities are not handled reasonably during the network training, resulting in the subpar performance of the segmentation model. To tackle this issue, we propose a framework named DoNuSeg, enabling \textbf{D}ynamic pseudo label \textbf{O}ptimization in point-supervised \textbf{Nu}clei \textbf{Seg}mentation. Specifically, DoNuSeg takes advantage of class activation maps (CAMs) to adaptively capture regions with semantics similar to annotated points. To leverage semantic diversity in the hierarchical feature levels, we design a dynamic selection module to choose the optimal one among CAMs from different encoder blocks as pseudo masks. Meanwhile, a CAM-guided contrastive module is proposed to further enhance the accuracy of pseudo masks. In addition to exploiting the semantic information provided by CAMs, we consider location priors inherent to point labels, developing a task-decoupled structure for effectively differentiating nuclei. Extensive experiments demonstrate that DoNuSeg outperforms state-of-the-art point-supervised methods. The code is available at this https URL.</li>
</ul>

<h3>Title: Title:
          UniCoder: Scaling Code Large Language Model via Universal Code</h3>
<ul>
<li><strong>Authors: </strong>Tao Sun, Linzheng Chai, Jian Yang, Yuwei Yin, Hongcheng Guo, Jiaheng Liu, Bing Wang, Liqun Yang, Zhoujun Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          UniCoder: Scaling Code Large Language Model via Universal Code(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Intermediate reasoning or acting steps have successfully improved large language models (LLMs) for handling various downstream natural language processing (NLP) tasks. When applying LLMs for code generation, recent works mainly focus on directing the models to articulate intermediate natural-language reasoning steps, as in chain-of-thought (CoT) prompting, and then output code with the natural language or other structured intermediate steps. However, such output is not suitable for code translation or generation tasks since the standard CoT has different logical structures and forms of expression with the code. In this work, we introduce the universal code (UniCode) as the intermediate representation. It is a description of algorithm steps using a mix of conventions of programming languages, such as assignment operator, conditional operator, and loop. Hence, we collect an instruction dataset UniCoder-Instruct to train our model UniCoder on multi-task learning objectives. UniCoder-Instruct comprises natural-language questions, code solutions, and the corresponding universal code. The alignment between the intermediate universal code representation and the final code solution significantly improves the quality of the generated code. The experimental results demonstrate that UniCoder with the universal code significantly outperforms the previous prompting methods by a large margin, showcasing the effectiveness of the structural clues in pseudo-code.</li>
</ul>

<h3>Title: Title:
          EmoLLM: Multimodal Emotional Understanding Meets Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qu Yang, Mang Ye, Bo Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          EmoLLM: Multimodal Emotional Understanding Meets Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal large language models (MLLMs) have achieved remarkable performance on objective multimodal perception tasks, but their ability to interpret subjective, emotionally nuanced multimodal content remains largely unexplored. Thus, it impedes their ability to effectively understand and react to the intricate emotions expressed by humans through multimodal media. To bridge this gap, we introduce EmoBench, the first comprehensive benchmark designed specifically to evaluate the emotional capabilities of MLLMs across five popular emotional tasks, using a diverse dataset of 287k images and videos paired with corresponding textual instructions. Meanwhile, we propose EmoLLM, a novel model for multimodal emotional understanding, incorporating with two core techniques. 1) Multi-perspective Visual Projection, it captures diverse emotional cues from visual data from multiple perspectives. 2) EmoPrompt, it guides MLLMs to reason about emotions in the correct direction. Experimental results demonstrate that EmoLLM significantly elevates multimodal emotional understanding performance, with an average improvement of 12.1% across multiple foundation models on EmoBench. Our work contributes to the advancement of MLLMs by facilitating a deeper and more nuanced comprehension of intricate human emotions, paving the way for the development of artificial emotional intelligence capabilities with wide-ranging applications in areas such as human-computer interaction, mental health support, and empathetic AI systems. Code, data, and model will be released.</li>
</ul>

<h3>Title: Title:
          Evaluating and Analyzing Relationship Hallucinations in LVLMs</h3>
<ul>
<li><strong>Authors: </strong>Mingrui Wu, Jiayi Ji, Oucheng Huang, Jiale Li, Yuhang Wu, Xiaoshuai Sun, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Evaluating and Analyzing Relationship Hallucinations in LVLMs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The issue of hallucinations is a prevalent concern in existing Large Vision-Language Models (LVLMs). Previous efforts have primarily focused on investigating object hallucinations, which can be easily alleviated by introducing object detectors. However, these efforts neglect hallucinations in inter-object relationships, which is essential for visual comprehension. In this work, we introduce R-Bench, a novel benchmark for evaluating Vision Relationship Hallucination. R-Bench features image-level questions that focus on the existence of relationships and instance-level questions that assess local visual comprehension. We identify three types of relationship co-occurrences that lead to hallucinations: relationship-relationship, subject-relationship, and relationship-object. The visual instruction tuning dataset's long-tail distribution significantly impacts LVLMs' understanding of visual relationships. Furthermore, our analysis reveals that current LVLMs tend to disregard visual content and overly rely on the common sense knowledge of Large Language Models. They also struggle with reasoning about spatial relationships based on contextual information.</li>
</ul>

<h3>Title: Title:
          Building on Efficient Foundations: Effectively Training LLMs with Structured Feedforward Layers</h3>
<ul>
<li><strong>Authors: </strong>Xiuying Wei, Skander Moalla, Razvan Pascanu, Caglar Gulcehre</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Building on Efficient Foundations: Effectively Training LLMs with Structured Feedforward Layers(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>State-of-the-art results in large language models (LLMs) often rely on scale, which becomes computationally expensive. This has sparked a research agenda to reduce these models' parameter count and computational costs without significantly impacting their performance. Our study focuses on transformer-based LLMs, specifically targeting the computationally intensive feedforward networks (FFN), which are less studied than attention blocks. We consider three candidate linear layer approximations in the FFN by combining efficient low-rank and block-diagonal matrices. In contrast to many previous works that examined these approximations, our study i) explores these structures from the training-from-scratch perspective, ii) scales up to 1.3B parameters, and iii) is conducted within recent Transformer-based LLMs rather than convolutional architectures. We first demonstrate they can lead to actual computational gains in various scenarios, including online decoding when using a pre-merge technique. Additionally, we propose a novel training regime, called \textit{self-guided training}, aimed at improving the poor training dynamics that these approximations exhibit when used from initialization. Experiments on the large RefinedWeb dataset show that our methods are both efficient and effective for training and inference. Interestingly, these structured FFNs exhibit steeper scaling curves than the original models. Further applying self-guided training to the structured matrices with 32\% FFN parameters and 2.5$\times$ speed-up enables only a 0.4 perplexity increase under the same training FLOPs. Finally, we develop the wide and structured networks surpassing the current medium-sized and large-sized Transformer in perplexity and throughput performance. Our code is available at \url{this https URL}.</li>
</ul>

<h3>Title: Title:
          Automated Privacy-Preserving Techniques via Meta-Learning</h3>
<ul>
<li><strong>Authors: </strong>Tânia Carvalho, Nuno Moniz, Luís Antunes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Automated Privacy-Preserving Techniques via Meta-Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Sharing private data for learning tasks is pivotal for transparent and secure machine learning applications. Many privacy-preserving techniques have been proposed for this task aiming to transform the data while ensuring the privacy of individuals. Some of these techniques have been incorporated into tools, whereas others are accessed through various online platforms. However, such tools require manual configuration, which can be complex and time-consuming. Moreover, they require substantial expertise, potentially restricting their use to those with advanced technical knowledge. In this paper, we propose AUTOPRIV, the first automated privacy-preservation method, that eliminates the need for any manual configuration. AUTOPRIV employs meta-learning to automate the de-identification process, facilitating the secure release of data for machine learning tasks. The main goal is to anticipate the predictive performance and privacy risk of a large set of privacy configurations. We provide a ranked list of the most promising solutions, which are likely to achieve an optimal approximation within a new domain. AUTOPRIV is highly effective as it reduces computational complexity and energy consumption considerably.</li>
</ul>

<h3>Title: Title:
          Suppressing Uncertainties in Degradation Estimation for Blind Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Junxiong Lin, Zeng Tao, Xuan Tong, Xinji Mai, Haoran Wang, Boyang Wang, Yan Wang, Qing Zhao, Jiawen Yu, Yuxuan Lin, Shaoqi Yan, Shuyong Gao, Wenqiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Suppressing Uncertainties in Degradation Estimation for Blind Super-Resolution(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The problem of blind image super-resolution aims to recover high-resolution (HR) images from low-resolution (LR) images with unknown degradation modes. Most existing methods model the image degradation process using blur kernels. However, this explicit modeling approach struggles to cover the complex and varied degradation processes encountered in the real world, such as high-order combinations of JPEG compression, blur, and noise. Implicit modeling for the degradation process can effectively overcome this issue, but a key challenge of implicit modeling is the lack of accurate ground truth labels for the degradation process to conduct supervised training. To overcome this limitations inherent in implicit modeling, we propose an \textbf{U}ncertainty-based degradation representation for blind \textbf{S}uper-\textbf{R}esolution framework (\textbf{USR}). By suppressing the uncertainty of local degradation representations in images, USR facilitated self-supervised learning of degradation representations. The USR consists of two components: Adaptive Uncertainty-Aware Degradation Extraction (AUDE) and a feature extraction network composed of Variable Depth Dynamic Convolution (VDDC) blocks. To extract Uncertainty-based Degradation Representation from LR images, the AUDE utilizes the Self-supervised Uncertainty Contrast module with Uncertainty Suppression Loss to suppress the inherent model uncertainty of the Degradation Extractor. Furthermore, VDDC block integrates degradation information through dynamic convolution. Rhe VDDC also employs an Adaptive Intensity Scaling operation that adaptively adjusts the degradation representation according to the network hierarchy, thereby facilitating the effective integration of degradation information. Quantitative and qualitative experiments affirm the superiority of our approach.</li>
</ul>

<h3>Title: Title:
          InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection</h3>
<ul>
<li><strong>Authors: </strong>Junjie Chen, Subin Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The prevalence of sarcasm in social media, conveyed through text-image combinations, presents significant challenges for sentiment analysis and intention mining. Current multi-modal sarcasm detection methods have been proven to struggle with biases from spurious cues, leading to a superficial understanding of the complex interactions between text and image. To address these issues, we propose InterCLIP-MEP, a robust framework for multi-modal sarcasm detection. InterCLIP-MEP introduces a refined variant of CLIP, Interactive CLIP (InterCLIP), as the backbone, enhancing sample representations by embedding cross-modality information in each encoder. Furthermore, a novel training strategy is designed to adapt InterCLIP for a Memory-Enhanced Predictor (MEP). MEP uses dynamic dual-channel memory to store valuable historical knowledge of test samples and then leverages this memory as a non-parametric classifier to derive the final prediction. By using InterCLIP to encode text-image interactions more effectively and incorporating MEP, InterCLIP-MEP offers a more robust recognition of multi-modal sarcasm. Experiments demonstrate that InterCLIP-MEP achieves state-of-the-art performance on the MMSD2.0 benchmark. Code and data are available at [this https URL](this https URL).</li>
</ul>

<h3>Title: Title:
          ResMaster: Mastering High-Resolution Image Generation via Structural and Fine-Grained Guidance</h3>
<ul>
<li><strong>Authors: </strong>Shuwei Shi, Wenbo Li, Yuechen Zhang, Jingwen He, Biao Gong, Yinqiang Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          ResMaster: Mastering High-Resolution Image Generation via Structural and Fine-Grained Guidance(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models excel at producing high-quality images; however, scaling to higher resolutions, such as 4K, often results in over-smoothed content, structural distortions, and repetitive patterns. To this end, we introduce ResMaster, a novel, training-free method that empowers resolution-limited diffusion models to generate high-quality images beyond resolution restrictions. Specifically, ResMaster leverages a low-resolution reference image created by a pre-trained diffusion model to provide structural and fine-grained guidance for crafting high-resolution images on a patch-by-patch basis. To ensure a coherent global structure, ResMaster meticulously aligns the low-frequency components of high-resolution patches with the low-resolution reference at each denoising step. For fine-grained guidance, tailored image prompts based on the low-resolution reference and enriched textual prompts produced by a vision-language model are incorporated. This approach could significantly mitigate local pattern distortions and improve detail refinement. Extensive experiments validate that ResMaster sets a new benchmark for high-resolution image generation and demonstrates promising efficiency. The project page is this https URL .</li>
</ul>

<h3>Title: Title:
          DaLPSR: Leverage Degradation-Aligned Language Prompt for Real-World Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Aiwen Jiang, Zhi Wei, Long Peng, Feiqiang Liu, Wenbo Li, Mingwen Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          DaLPSR: Leverage Degradation-Aligned Language Prompt for Real-World Image Super-Resolution(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Image super-resolution pursuits reconstructing high-fidelity high-resolution counterpart for low-resolution image. In recent years, diffusion-based models have garnered significant attention due to their capabilities with rich prior knowledge. The success of diffusion models based on general text prompts has validated the effectiveness of textual control in the field of text2image. However, given the severe degradation commonly presented in low-resolution images, coupled with the randomness characteristics of diffusion models, current models struggle to adequately discern semantic and degradation information within severely degraded images. This often leads to obstacles such as semantic loss, visual artifacts, and visual hallucinations, which pose substantial challenges for practical use. To address these challenges, this paper proposes to leverage degradation-aligned language prompt for accurate, fine-grained, and high-fidelity image restoration. Complementary priors including semantic content descriptions and degradation prompts are explored. Specifically, on one hand, image-restoration prompt alignment decoder is proposed to automatically discern the degradation degree of LR images, thereby generating beneficial degradation priors for image restoration. On the other hand, much richly tailored descriptions from pretrained multimodal large language model elicit high-level semantic priors closely aligned with human perception, ensuring fidelity control for image restoration. Comprehensive comparisons with state-of-the-art methods have been done on several popular synthetic and real-world benchmark datasets. The quantitative and qualitative analysis have demonstrated that the proposed method achieves a new state-of-the-art perceptual quality level, especially in real-world cases based on reference-free metrics.</li>
</ul>

<h3>Title: Title:
          eagerlearners at SemEval2024 Task 5: The Legal Argument Reasoning Task in Civil Procedure</h3>
<ul>
<li><strong>Authors: </strong>Hoorieh Sabzevari, Mohammadmostafa Rostamkhani, Sauleh Eetemadi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          eagerlearners at SemEval2024 Task 5: The Legal Argument Reasoning Task in Civil Procedure(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study investigates the performance of the zero-shot method in classifying data using three large language models, alongside two models with large input token sizes and the two pre-trained models on legal data. Our main dataset comes from the domain of U.S. civil procedure. It includes summaries of legal cases, specific questions, potential answers, and detailed explanations for why each solution is relevant, all sourced from a book aimed at law students. By comparing different methods, we aimed to understand how effectively they handle the complexities found in legal datasets. Our findings show how well the zero-shot method of large language models can understand complicated data. We achieved our highest F1 score of 64% in these experiments.</li>
</ul>

<h3>Title: Title:
          OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to construct Observer-Thinker-Conceiver-Expresser</h3>
<ul>
<li><strong>Authors: </strong>Jingze Shi, Ting Xie, Bingheng Wu, Chunjun Zheng, Kai Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to construct Observer-Thinker-Conceiver-Expresser(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent research has shown that combining Mamba with Transformer architecture, which has selective state space and quadratic self-attention mechanism, outperforms using Mamba or Transformer architecture alone in language modeling tasks. The quadratic self-attention mechanism effectively alleviates the shortcomings of selective state space in handling long-term dependencies of any element in the sequence. We propose a position information injection method that connects the selective state space model with the quadratic attention, and integrates these two architectures with hybrid experts with cross-sharing domains, so that we can enjoy the advantages of both. We design a new architecture with a more biomimetic idea: Observer-Thinker-Conceiver-Expresser (OTCE), which can compete with well-known medium-scale open-source language models on a small scale in language modeling tasks.</li>
</ul>

<h3>Title: Title:
          UNICAD: A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification</h3>
<ul>
<li><strong>Authors: </strong>Alvaro Lopez Pellicer, Kittipos Giatgong, Yi Li, Neeraj Suri, Plamen Angelov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          UNICAD: A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>As the use of Deep Neural Networks (DNNs) becomes pervasive, their vulnerability to adversarial attacks and limitations in handling unseen classes poses significant challenges. The state-of-the-art offers discrete solutions aimed to tackle individual issues covering specific adversarial attack scenarios, classification or evolving learning. However, real-world systems need to be able to detect and recover from a wide range of adversarial attacks without sacrificing classification accuracy and to flexibly act in {\bf unseen} scenarios. In this paper, UNICAD, is proposed as a novel framework that integrates a variety of techniques to provide an adaptive solution. For the targeted image classification, UNICAD achieves accurate image classification, detects unseen classes, and recovers from adversarial attacks using Prototype and Similarity-based DNNs with denoising autoencoders. Our experiments performed on the CIFAR-10 dataset highlight UNICAD's effectiveness in adversarial mitigation and unseen class classification, outperforming traditional models.</li>
</ul>

<h3>Title: Title:
          LOGCAN++: Local-global class-aware network for semantic segmentation of remote sensing images</h3>
<ul>
<li><strong>Authors: </strong>Xiaowen Ma, Rongrong Lian, Zhenkai Wu, Hongbo Guo, Mengting Ma, Sensen Wu, Zhenhong Du, Siyang Song, Wei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          LOGCAN++: Local-global class-aware network for semantic segmentation of remote sensing images(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Remote sensing images usually characterized by complex backgrounds, scale and orientation variations, and large intra-class variance. General semantic segmentation methods usually fail to fully investigate the above issues, and thus their performances on remote sensing image segmentation are limited. In this paper, we propose our LOGCAN++, a semantic segmentation model customized for remote sensing images, which is made up of a Global Class Awareness (GCA) module and several Local Class Awareness (LCA) modules. The GCA module captures global representations for class-level context modeling to reduce the interference of background noise. The LCA module generates local class representations as intermediate perceptual elements to indirectly associate pixels with the global class representations, targeting at dealing with the large intra-class variance problem. In particular, we introduce affine transformations in the LCA module for adaptive extraction of local class representations to effectively tolerate scale and orientation variations in remotely sensed images. Extensive experiments on three benchmark datasets show that our LOGCAN++ outperforms current mainstream general and remote sensing semantic segmentation methods and achieves a better trade-off between speed and accuracy. Code is available at this https URL.</li>
</ul>

<h3>Title: Title:
          Large Vocabulary Size Improves Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sho Takase, Ryokan Ri, Shun Kiyono, Takuya Kato</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Large Vocabulary Size Improves Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper empirically investigates the relationship between subword vocabulary size and the performance of large language models (LLMs) to provide insights on how to define the vocabulary size. Experimental results show that larger vocabulary sizes lead to better performance in LLMs. Moreover, we consider a continual training scenario where a pre-trained language model is trained on a different target language. We introduce a simple method to use a new vocabulary instead of the pre-defined one. We show that using the new vocabulary outperforms the model with the vocabulary used in pre-training.</li>
</ul>

<h3>Title: Title:
          Multi-Modal Vision Transformers for Crop Mapping from Satellite Image Time Series</h3>
<ul>
<li><strong>Authors: </strong>Theresa Follath, David Mickisch, Jan Hemmerling, Stefan Erasmi, Marcel Schwieder, Begüm Demir</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Multi-Modal Vision Transformers for Crop Mapping from Satellite Image Time Series(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Using images acquired by different satellite sensors has shown to improve classification performance in the framework of crop mapping from satellite image time series (SITS). Existing state-of-the-art architectures use self-attention mechanisms to process the temporal dimension and convolutions for the spatial dimension of SITS. Motivated by the success of purely attention-based architectures in crop mapping from single-modal SITS, we introduce several multi-modal multi-temporal transformer-based architectures. Specifically, we investigate the effectiveness of Early Fusion, Cross Attention Fusion and Synchronized Class Token Fusion within the Temporo-Spatial Vision Transformer (TSViT). Experimental results demonstrate significant improvements over state-of-the-art architectures with both convolutional and self-attention components.</li>
</ul>

<h3>Title: Title:
          Vision Mamba-based autonomous crack segmentation on concrete, asphalt, and masonry surfaces</h3>
<ul>
<li><strong>Authors: </strong>Zhaohui Chen, Elyas Asadi Shamsabadi, Sheng Jiang, Luming Shen, Daniel Dias-da-Costa</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Vision Mamba-based autonomous crack segmentation on concrete, asphalt, and masonry surfaces(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Convolutional neural networks (CNNs) and Transformers have shown advanced accuracy in crack detection under certain conditions. Yet, the fixed local attention can compromise the generalisation of CNNs, and the quadratic complexity of the global self-attention restricts the practical deployment of Transformers. Given the emergence of the new-generation architecture of Mamba, this paper proposes a Vision Mamba (VMamba)-based framework for crack segmentation on concrete, asphalt, and masonry surfaces, with high accuracy, generalisation, and less computational complexity. Having 15.6% - 74.5% fewer parameters, the encoder-decoder network integrated with VMamba could obtain up to 2.8% higher mDS than representative CNN-based models while showing about the same performance as Transformer-based models. Moreover, the VMamba-based encoder-decoder network could process high-resolution image input with up to 90.6% lower floating-point operations.</li>
</ul>

<h3>Title: Title:
          SyROCCo: Enhancing Systematic Reviews using Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Zheng Fang, Miguel Arana-Catania, Felix-Anselm van Lier, Juliana Outes Velarde, Harry Bregazzi, Mara Airoldi, Eleanor Carter, Rob Procter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.DL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          SyROCCo: Enhancing Systematic Reviews using Machine Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The sheer number of research outputs published every year makes systematic reviewing increasingly time- and resource-intensive. This paper explores the use of machine learning techniques to help navigate the systematic review process. ML has previously been used to reliably 'screen' articles for review - that is, identify relevant articles based on reviewers' inclusion criteria. The application of ML techniques to subsequent stages of a review, however, such as data extraction and evidence mapping, is in its infancy. We therefore set out to develop a series of tools that would assist in the profiling and analysis of 1,952 publications on the theme of 'outcomes-based contracting'. Tools were developed for the following tasks: assign publications into 'policy area' categories; identify and extract key information for evidence mapping, such as organisations, laws, and geographical information; connect the evidence base to an existing dataset on the same topic; and identify subgroups of articles that may share thematic content. An interactive tool using these techniques and a public dataset with their outputs have been released. Our results demonstrate the utility of ML techniques to enhance evidence accessibility and analysis within the systematic review processes. These efforts show promise in potentially yielding substantial efficiencies for future systematic reviewing and for broadening their analytical scope. Our work suggests that there may be implications for the ease with which policymakers and practitioners can access evidence. While ML techniques seem poised to play a significant role in bridging the gap between research and policy by offering innovative ways of gathering, accessing, and analysing data from systematic reviews, we also highlight their current limitations and the need to exercise caution in their application, particularly given the potential for errors and biases.</li>
</ul>

<h3>Title: Title:
          Evaluating the Ability of Large Language Models to Reason about Cardinal Directions</h3>
<ul>
<li><strong>Authors: </strong>Anthony G Cohn, Robert E Blackwell</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Evaluating the Ability of Large Language Models to Reason about Cardinal Directions(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate the abilities of a representative set of Large language Models (LLMs) to reason about cardinal directions (CDs). To do so, we create two datasets: the first, co-created with ChatGPT, focuses largely on recall of world knowledge about CDs; the second is generated from a set of templates, comprehensively testing an LLM's ability to determine the correct CD given a particular scenario. The templates allow for a number of degrees of variation such as means of locomotion of the agent involved, and whether set in the first , second or third person. Even with a temperature setting of zero, Our experiments show that although LLMs are able to perform well in the simpler dataset, in the second more complex dataset no LLM is able to reliably determine the correct CD, even with a temperature setting of zero.</li>
</ul>

<h3>Title: Title:
          Towards Better Graph-based Cross-document Relation Extraction via Non-bridge Entity Enhancement and Prediction Debiasing</h3>
<ul>
<li><strong>Authors: </strong>Hao Yue, Shaopeng Lai, Chengyi Yang, Liang Zhang, Junfeng Yao, Jinsong Su</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Towards Better Graph-based Cross-document Relation Extraction via Non-bridge Entity Enhancement and Prediction Debiasing(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Cross-document Relation Extraction aims to predict the relation between target entities located in different documents. In this regard, the dominant models commonly retain useful information for relation prediction via bridge entities, which allows the model to elaborately capture the intrinsic interdependence between target entities. However, these studies ignore the non-bridge entities, each of which co-occurs with only one target entity and offers the semantic association between target entities for relation prediction. Besides, the commonly-used dataset--CodRED contains substantial NA instances, leading to the prediction bias during inference. To address these issues, in this paper, we propose a novel graph-based cross-document RE model with non-bridge entity enhancement and prediction debiasing. Specifically, we use a unified entity graph to integrate numerous non-bridge entities with target entities and bridge entities, modeling various associations between them, and then use a graph recurrent network to encode this graph. Finally, we introduce a novel debiasing strategy to calibrate the original prediction distribution. Experimental results on the closed and open settings show that our model significantly outperforms all baselines, including the GPT-3.5-turbo and InstructUIE, achieving state-of-the-art performance. Particularly, our model obtains 66.23% and 55.87% AUC points in the official leaderboard\footnote{\url{this https URL}} under the two settings, respectively, ranking the first place in all submissions since December 2023. Our code is available at this https URL.</li>
</ul>

<h3>Title: Title:
          GIM: A Million-scale Benchmark for Generative Image Manipulation Detection and Localization</h3>
<ul>
<li><strong>Authors: </strong>Yirui Chen, Xudong Huang, Quan Zhang, Wei Li, Mingjian Zhu, Qiangyu Yan, Simiao Li, Hanting Chen, Hailin Hu, Jie Yang, Wei Liu, Jie Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          GIM: A Million-scale Benchmark for Generative Image Manipulation Detection and Localization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The extraordinary ability of generative models emerges as a new trend in image editing and generating realistic images, posing a serious threat to the trustworthiness of multimedia data and driving the research of image manipulation detection and location(IMDL). However, the lack of a large-scale data foundation makes IMDL task unattainable. In this paper, a local manipulation pipeline is designed, incorporating the powerful SAM, ChatGPT and generative models. Upon this basis, We propose the GIM dataset, which has the following advantages: 1) Large scale, including over one million pairs of AI-manipulated images and real images. 2) Rich Image Content, encompassing a broad range of image classes 3) Diverse Generative Manipulation, manipulated images with state-of-the-art generators and various manipulation tasks. The aforementioned advantages allow for a more comprehensive evaluation of IMDL methods, extending their applicability to diverse images. We introduce two benchmark settings to evaluate the generalization capability and comprehensive performance of baseline methods. In addition, we propose a novel IMDL framework, termed GIMFormer, which consists of a ShadowTracer, Frequency-Spatial Block (FSB), and a Multi-window Anomalous Modelling (MWAM) Module. Extensive experiments on the GIM demonstrate that GIMFormer surpasses previous state-of-the-art works significantly on two different benchmarks.</li>
</ul>

<h3>Title: Title:
          C-LLM: Learn to Check Chinese Spelling Errors Character by Character</h3>
<ul>
<li><strong>Authors: </strong>Kunting Li, Yong Hu, Liang He, Fandong Meng, Jie Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          C-LLM: Learn to Check Chinese Spelling Errors Character by Character(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Chinese Spell Checking (CSC) aims to detect and correct spelling errors in sentences. Despite Large Language Models (LLMs) exhibit robust capabilities and are widely applied in various tasks, their performance on CSC is often unsatisfactory. We find that LLMs fail to meet the Chinese character-level constraints of the CSC task, namely equal length and phonetic similarity, leading to a performance bottleneck. Further analysis reveal that this issue stems from the granularity of tokenization, as current mixed character-word tokenization struggles to satisfy these character-level constraints. To address this issue, we propose C-LLM, a Large Language Model-based Chinese Spell Checking method that learns to check errors Character by Character. Character-level tokenization enables the model to learn character-level alignment, effectively mitigating issues related to character-level constraints. Furthermore, CSC is simplified to replication-dominated and substitution-supplemented tasks. Experiments on two CSC benchmarks demonstrate that C-LLM achieves an average improvement of 10% over existing methods. Specifically, it shows a 2.1% improvement in general scenarios and a significant 12% improvement in vertical domain scenarios, establishing state-of-the-art performance. The source code can be accessed at this https URL.</li>
</ul>

<h3>Title: Title:
          Character-Adapter: Prompt-Guided Region Control for High-Fidelity Character Customization</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Ma, Wenting Xu, Jiji Tang, Qinfeng Jin, Rongsheng Zhang, Zeng Zhao, Changjie Fan, Zhipeng Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Character-Adapter: Prompt-Guided Region Control for High-Fidelity Character Customization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Customized image generation, which seeks to synthesize images with consistent characters, holds significant relevance for applications such as storytelling, portrait generation, and character design. However, previous approaches have encountered challenges in preserving characters with high-fidelity consistency due to inadequate feature extraction and concept confusion of reference characters. Therefore, we propose Character-Adapter, a plug-and-play framework designed to generate images that preserve the details of reference characters, ensuring high-fidelity consistency. Character-Adapter employs prompt-guided segmentation to ensure fine-grained regional features of reference characters and dynamic region-level adapters to mitigate concept confusion. Extensive experiments are conducted to validate the effectiveness of Character-Adapter. Both quantitative and qualitative results demonstrate that Character-Adapter achieves the state-of-the-art performance of consistent character generation, with an improvement of 24.8% compared with other methods</li>
</ul>

<h3>Title: Title:
          Improving robustness to corruptions with multiplicative weight perturbations</h3>
<ul>
<li><strong>Authors: </strong>Trung Trinh, Markus Heinonen, Luigi Acerbi, Samuel Kaski</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Improving robustness to corruptions with multiplicative weight perturbations(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) excel on clean images but struggle with corrupted ones. Incorporating specific corruptions into the data augmentation pipeline can improve robustness to those corruptions but may harm performance on clean images and other types of distortion. In this paper, we introduce an alternative approach that improves the robustness of DNNs to a wide range of corruptions without compromising accuracy on clean images. We first demonstrate that input perturbations can be mimicked by multiplicative perturbations in the weight space. Leveraging this, we propose Data Augmentation via Multiplicative Perturbation (DAMP), a training method that optimizes DNNs under random multiplicative weight perturbations. We also examine the recently proposed Adaptive Sharpness-Aware Minimization (ASAM) and show that it optimizes DNNs under adversarial multiplicative weight perturbations. Experiments on image classification datasets (CIFAR-10/100, TinyImageNet and ImageNet) and neural network architectures (ResNet50, ViT-S/16) show that DAMP enhances model generalization performance in the presence of corruptions across different settings. Notably, DAMP is able to train a ViT-S/16 on ImageNet from scratch, reaching the top-1 error of 23.7% which is comparable to ResNet50 without extensive data augmentations.</li>
</ul>

<h3>Title: Title:
          Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs</h3>
<ul>
<li><strong>Authors: </strong>Jan von Pichowski, Vincenzo Perri, Lisi Qarkaxhija, Ingo Scholtes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The modelling of temporal patterns in dynamic graphs is an important current research issue in the development of time-aware GNNs. Whether or not a specific sequence of events in a temporal graph constitutes a temporal pattern not only depends on the frequency of its occurrence. We consider whether it deviates from what is expected in a temporal graph where timestamps are randomly shuffled. While accounting for such a random baseline is important to model temporal patterns, it has mostly been ignored by current temporal graph neural networks. To address this issue we propose HYPA-DBGNN, a novel two-step approach that combines (i) the inference of anomalous sequential patterns in time series data on graphs based on a statistically principled null model, with (ii) a neural message passing approach that utilizes a higher-order De Bruijn graph whose edges capture overrepresented sequential patterns. Our method leverages hypergeometric graph ensembles to identify anomalous edges within both first- and higher-order De Bruijn graphs, which encode the temporal ordering of events. The model introduces an inductive bias that enhances model interpretability. We evaluate our approach for static node classification using benchmark datasets and a synthetic dataset that showcases its ability to incorporate the observed inductive bias regarding over- and under-represented temporal edges. We demonstrate the framework's effectiveness in detecting similar patterns within empirical datasets, resulting in superior performance compared to baseline methods in node classification tasks. To the best of our knowledge, our work is the first to introduce statistically informed GNNs that leverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path for bridging the gap between statistical graph inference and neural graph representation learning, with potential applications to static GNNs.</li>
</ul>

<h3>Title: Title:
          LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Tong Zhu, Xiaoye Qu, Daize Dong, Jiacheng Ruan, Jingqi Tong, Conghui He, Yu Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-training(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) has gained increasing popularity as a promising framework for scaling up large language models (LLMs). However, training MoE from scratch in a large-scale setting still suffers from data-hungry and instability problems. Motivated by this limit, we investigate building MoE models from existing dense large language models. Specifically, based on the well-known LLaMA-2 7B model, we obtain an MoE model by: (1) Expert Construction, which partitions the parameters of original Feed-Forward Networks (FFNs) into multiple experts; (2) Continual Pre-training, which further trains the transformed MoE model and additional gate networks. In this paper, we comprehensively explore different methods for expert construction and various data sampling strategies for continual pre-training. After these stages, our LLaMA-MoE models could maintain language abilities and route the input tokens to specific experts with part of the parameters activated. Empirically, by training 200B tokens, LLaMA-MoE-3.5B models significantly outperform dense models that contain similar activation parameters. The source codes and models are available at this https URL .</li>
</ul>

<h3>Title: Title:
          Efficient k-means with Individual Fairness via Exponential Tilting</h3>
<ul>
<li><strong>Authors: </strong>Shengkun Zhu, Jinshan Zeng, Yuan Sun, Sheng Wang, Xiaodong Li, Zhiyong Peng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Efficient k-means with Individual Fairness via Exponential Tilting(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>In location-based resource allocation scenarios, the distances between each individual and the facility are desired to be approximately equal, thereby ensuring fairness. Individually fair clustering is often employed to achieve the principle of treating all points equally, which can be applied in these scenarios. This paper proposes a novel algorithm, tilted k-means (TKM), aiming to achieve individual fairness in clustering. We integrate the exponential tilting into the sum of squared errors (SSE) to formulate a novel objective function called tilted SSE. We demonstrate that the tilted SSE can generalize to SSE and employ the coordinate descent and first-order gradient method for optimization. We propose a novel fairness metric, the variance of the distances within each cluster, which can alleviate the Matthew Effect typically caused by existing fairness metrics. Our theoretical analysis demonstrates that the well-known k-means++ incurs a multiplicative error of O(k log k), and we establish the convergence of TKM under mild conditions. In terms of fairness, we prove that the variance generated by TKM decreases with a scaled hyperparameter. In terms of efficiency, we demonstrate the time complexity is linear with the dataset size. Our experiments demonstrate that TKM outperforms state-of-the-art methods in effectiveness, fairness, and efficiency.</li>
</ul>

<h3>Title: Title:
          EvalAlign: Evaluating Text-to-Image Models through Precision Alignment of Multimodal Large Models with Supervised Fine-Tuning to Human Annotations</h3>
<ul>
<li><strong>Authors: </strong>Zhiyu Tan, Xiaomeng Yang, Luozheng Qin, Mengping Yang, Cheng Zhang, Hao Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          EvalAlign: Evaluating Text-to-Image Models through Precision Alignment of Multimodal Large Models with Supervised Fine-Tuning to Human Annotations(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>The recent advancements in text-to-image generative models have been remarkable. Yet, the field suffers from a lack of evaluation metrics that accurately reflect the performance of these models, particularly lacking fine-grained metrics that can guide the optimization of the models. In this paper, we propose EvalAlign, a metric characterized by its accuracy, stability, and fine granularity. Our approach leverages the capabilities of Multimodal Large Language Models (MLLMs) pre-trained on extensive datasets. We develop evaluation protocols that focus on two key dimensions: image faithfulness and text-image alignment. Each protocol comprises a set of detailed, fine-grained instructions linked to specific scoring options, enabling precise manual scoring of the generated images. We Supervised Fine-Tune (SFT) the MLLM to align closely with human evaluative judgments, resulting in a robust evaluation model. Our comprehensive tests across 24 text-to-image generation models demonstrate that EvalAlign not only provides superior metric stability but also aligns more closely with human preferences than existing metrics, confirming its effectiveness and utility in model assessment.</li>
</ul>

<h3>Title: Title:
          Are there identifiable structural parts in the sentence embedding whole?</h3>
<ul>
<li><strong>Authors: </strong>Vivi Nastase, Paola Merlo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Are there identifiable structural parts in the sentence embedding whole?(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sentence embeddings from transformer models encode in a fixed length vector much linguistic information. We explore the hypothesis that these embeddings consist of overlapping layers of information that can be separated, and on which specific types of information -- such as information about chunks and their structural and semantic properties -- can be detected. We show that this is the case using a dataset consisting of sentences with known chunk structure, and two linguistic intelligence datasets, solving which relies on detecting chunks and their grammatical number, and respectively, their semantic roles, and through analyses of the performance on the tasks and of the internal representations built during learning.</li>
</ul>

<h3>Title: Title:
          FASTC: A Fast Attentional Framework for Semantic Traversability Classification Using Point Cloud</h3>
<ul>
<li><strong>Authors: </strong>Yirui Chen, Pengjin Wei, Zhenhuan Liu, Bingchao Wang, Jie Yang, Wei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          FASTC: A Fast Attentional Framework for Semantic Traversability Classification Using Point Cloud(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Producing traversability maps and understanding the surroundings are crucial prerequisites for autonomous navigation. In this paper, we address the problem of traversability assessment using point clouds. We propose a novel pillar feature extraction module that utilizes PointNet to capture features from point clouds organized in vertical volume and a 2D encoder-decoder structure to conduct traversability classification instead of the widely used 3D convolutions. This results in less computational cost while even better performance is achieved at the same time. We then propose a new spatio-temporal attention module to fuse multi-frame information, which can properly handle the varying density problem of LIDAR point clouds, and this makes our module able to assess distant areas more accurately. Comprehensive experimental results on augmented Semantic KITTI and RELLIS-3D datasets show that our method is able to achieve superior performance over existing approaches both quantitatively and quantitatively.</li>
</ul>

<h3>Title: Title:
          Noisy Neighbors: Efficient membership inference attacks against LLMs</h3>
<ul>
<li><strong>Authors: </strong>Filippo Galli, Luca Melis, Tommaso Cucinotta</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Noisy Neighbors: Efficient membership inference attacks against LLMs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, membership infer, transformer</a></li>
<li><strong>Abstract: </strong>The potential of transformer-based LLMs risks being hindered by privacy concerns due to their reliance on extensive datasets, possibly including sensitive information. Regulatory measures like GDPR and CCPA call for using robust auditing tools to address potential privacy issues, with Membership Inference Attacks (MIA) being the primary method for assessing LLMs' privacy risks. Differently from traditional MIA approaches, often requiring computationally intensive training of additional models, this paper introduces an efficient methodology that generates \textit{noisy neighbors} for a target sample by adding stochastic noise in the embedding space, requiring operating the target model in inference mode only. Our findings demonstrate that this approach closely matches the effectiveness of employing shadow models, showing its usability in practical privacy auditing scenarios.</li>
</ul>

<h3>Title: Title:
          Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting</h3>
<ul>
<li><strong>Authors: </strong>Jiyue Jiang, Liheng Chen, Sheng Wang, Lingpeng Kong, Yu Li, Chuan Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing dialogue data augmentation (DA) techniques predominantly focus on augmenting utterance-level dialogues, which makes it difficult to take dialogue contextual information into account. The advent of large language models (LLMs) has simplified the implementation of multi-turn dialogues. Due to absence of professional understanding and knowledge, it remains challenging to deliver satisfactory performance in low-resource domain, like psychological dialogue dialogue. DA involves creating new training or prompting data based on the existing data, which help the model better understand and generate psychology-related responses. In this paper, we aim to address the issue of multi-turn dialogue data augmentation for boosted performance in the psychology domain. We propose a knowledge-driven progressive thought prompting method to guide LLM to generate multi-turn psychology-related dialogue. This method integrates a progressive thought generator, a psychology knowledge generator, and a multi-turn dialogue generator. The thought generated by the progressive thought generator serves as a prompt to prevent the generated dialogue from having significant semantic deviations, while the psychology knowledge generator produces psychological knowledge to serve as the dialogue history for the LLM, guiding the dialogue generator to create multi-turn psychological dialogue. To ensure the precision of multi-turn psychological dialogue generation by LLM, a meticulous professional evaluation is required. Extensive experiments conducted on three datasets related to psychological dialogue verify the effectiveness of the proposed method.</li>
</ul>

<h3>Title: Title:
          Personalized federated learning based on feature fusion</h3>
<ul>
<li><strong>Authors: </strong>Wolong Xing, Zhenkui Shi, Hongyan Peng, Xiantao Hu, Xianxian Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Personalized federated learning based on feature fusion(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated learning enables distributed clients to collaborate on training while storing their data locally to protect client privacy. However, due to the heterogeneity of data, models, and devices, the final global model may need to perform better for tasks on each client. Communication bottlenecks, data heterogeneity, and model heterogeneity have been common challenges in federated learning. In this work, we considered a label distribution skew problem, a type of data heterogeneity easily overlooked. In the context of classification, we propose a personalized federated learning approach called pFedPM. In our process, we replace traditional gradient uploading with feature uploading, which helps reduce communication costs and allows for heterogeneous client models. These feature representations play a role in preserving privacy to some extent. We use a hyperparameter $a$ to mix local and global features, which enables us to control the degree of personalization. We also introduced a relation network as an additional decision layer, which provides a non-linear learnable classifier to predict labels. Experimental results show that, with an appropriate setting of $a$, our scheme outperforms several recent FL methods on MNIST, FEMNIST, and CRIFAR10 datasets and achieves fewer communications.</li>
</ul>

<h3>Title: Title:
          Toward Fairer Face Recognition Datasets</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Fournier-Mongieux, Michael Soumm, Adrian Popescu, Bertrand Luvison, Hervé Le Borgne</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Toward Fairer Face Recognition Datasets(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Face recognition and verification are two computer vision tasks whose performance has progressed with the introduction of deep representations. However, ethical, legal, and technical challenges due to the sensitive character of face data and biases in real training datasets hinder their development. Generative AI addresses privacy by creating fictitious identities, but fairness problems persist. We promote fairness by introducing a demographic attributes balancing mechanism in generated training datasets. We experiment with an existing real dataset, three generated training datasets, and the balanced versions of a diffusion-based dataset. We propose a comprehensive evaluation that considers accuracy and fairness equally and includes a rigorous regression-based statistical analysis of attributes. The analysis shows that balancing reduces demographic unfairness. Also, a performance gap persists despite generation becoming more accurate with time. The proposed balancing method and comprehensive verification evaluation promote fairer and transparent face recognition and verification.</li>
</ul>

<h3>Title: Title:
          Cherry on the Cake: Fairness is NOT an Optimization Problem</h3>
<ul>
<li><strong>Authors: </strong>Marco Favier, Toon Calders</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Cherry on the Cake: Fairness is NOT an Optimization Problem(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fair cake-cutting is a mathematical subfield that studies the problem of fairly dividing a resource among a number of participants. The so-called ``cake,'' as an object, represents any resource that can be distributed among players. This concept is connected to supervised multi-label classification: any dataset can be thought of as a cake that needs to be distributed, where each label is a player that receives its share of the dataset. In particular, any efficient cake-cutting solution for the dataset is equivalent to an optimal decision function. Although we are not the first to demonstrate this connection, the important ramifications of this parallel seem to have been partially forgotten. We revisit these classical results and demonstrate how this connection can be prolifically used for fairness in machine learning problems. Understanding the set of achievable fair decisions is a fundamental step in finding optimal fair solutions and satisfying fairness requirements. By employing the tools of cake-cutting theory, we have been able to describe the behavior of optimal fair decisions, which, counterintuitively, often exhibit quite unfair properties. Specifically, in order to satisfy fairness constraints, it is sometimes preferable, in the name of optimality, to purposefully make mistakes and deny giving the positive label to deserving individuals in a community in favor of less worthy individuals within the same community. This practice is known in the literature as cherry-picking and has been described as ``blatantly unfair.''</li>
</ul>

<h3>Title: Title:
          Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings</h3>
<ul>
<li><strong>Authors: </strong>Andrea Posada, Daniel Rueckert, Felix Meissen, Philip Müller</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Since the emergence of the Transformer architecture, language model development has increased, driven by their promising potential. However, releasing these models into production requires properly understanding their behavior, particularly in sensitive domains such as medicine. Despite this need, the medical literature still lacks technical assessments of pre-trained language models, which are especially valuable in resource-constrained settings in terms of computational power or limited budget. To address this gap, we provide a comprehensive survey of language models in the medical domain. In addition, we selected a subset of these models for thorough evaluation, focusing on classification and text generation tasks. Our subset encompasses 53 models, ranging from 110 million to 13 billion parameters, spanning the three families of Transformer-based models and from diverse knowledge domains. This study employs a series of approaches for text classification together with zero-shot prompting instead of model training or fine-tuning, which closely resembles the limited resource setting in which many users of language models find themselves. Encouragingly, our findings reveal remarkable performance across various tasks and datasets, underscoring the latent potential of certain models to contain medical knowledge, even without domain specialization. Consequently, our study advocates for further exploration of model applications in medical contexts, particularly in resource-constrained settings. The code is available on this https URL.</li>
</ul>

<h3>Title: Title:
          OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer</h3>
<ul>
<li><strong>Authors: </strong>Lu Zhang, Tiancheng Zhao, Heting Ying, Yibo Ma, Kyusong Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have expanded their capabilities to multimodal contexts, including comprehensive video understanding. However, processing extensive videos such as 24-hour CCTV footage or full-length films presents significant challenges due to the vast data and processing demands. Traditional methods, like extracting key frames or converting frames to text, often result in substantial information loss. To address these shortcomings, we develop OmAgent, efficiently stores and retrieves relevant video frames for specific queries, preserving the detailed content of videos. Additionally, it features an Divide-and-Conquer Loop capable of autonomous reasoning, dynamically invoking APIs and tools to enhance query processing and accuracy. This approach ensures robust video understanding, significantly reducing information loss. Experimental results affirm OmAgent's efficacy in handling various types of videos and complex tasks. Moreover, we have endowed it with greater autonomy and a robust tool-calling system, enabling it to accomplish even more intricate tasks.</li>
</ul>

<h3>Title: Title:
          Articulate your NeRF: Unsupervised articulated object modeling via conditional view synthesis</h3>
<ul>
<li><strong>Authors: </strong>Jianning Deng, Kartic Subr, Hakan Bilen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Articulate your NeRF: Unsupervised articulated object modeling via conditional view synthesis(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We propose a novel unsupervised method to learn the pose and part-segmentation of articulated objects with rigid parts. Given two observations of an object in different articulation states, our method learns the geometry and appearance of object parts by using an implicit model from the first observation, distils the part segmentation and articulation from the second observation while rendering the latter observation. Additionally, to tackle the complexities in the joint optimization of part segmentation and articulation, we propose a voxel grid-based initialization strategy and a decoupled optimization procedure. Compared to the prior unsupervised work, our model obtains significantly better performance, and generalizes to objects with multiple parts while it can be efficiently from few views for the latter observation.</li>
</ul>

<h3>Title: Title:
          MLAAN: Scaling Supervised Local Learning with Multilaminar Leap Augmented Auxiliary Network</h3>
<ul>
<li><strong>Authors: </strong>Yuming Zhang, Shouxin Zhang, Peizhe Wang, Feiyu Zhu, Dongzhi Guan, Jiabin Liu, Changpeng Cai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          MLAAN: Scaling Supervised Local Learning with Multilaminar Leap Augmented Auxiliary Network(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>End-to-end (E2E) training approaches are commonly plagued by high memory consumption, reduced efficiency in training, challenges in model parallelization, and suboptimal biocompatibility. Local learning is considered a novel interactive training method that holds promise as an alternative to E2E. Nonetheless, conventional local learning methods fall short in achieving high model accuracy due to inadequate local inter-module interactions. In this paper, we introduce a new model known as the Scaling Supervised Local Learning with Multilaminar Leap Augmented Auxiliary Network (MLAAN). MLAAN features an innovative supervised local learning approach coupled with a robust reinforcement module. This dual-component design enables the MLAAN to integrate smoothly with established local learning techniques, thereby enhancing the efficacy of the foundational methods. The method simultaneously acquires the local and global features of the model separately by constructing an independent auxiliary network and a cascade auxiliary network on the one hand and incorporates a leap augmented module, which serves to counteract the reduced learning capacity often associated with weaker supervision. This architecture not only augments the exchange of information amongst the local modules but also effectively mitigates the model's tendency toward myopia. The experimental evaluations conducted on four benchmark datasets, CIFAR-10, STL-10, SVHN, and ImageNet, demonstrate that the integration of MLAAN with existing supervised local learning methods significantly enhances the original methodologies. Of particular note, MLAAN enables local learning methods to comprehensively outperform end-to-end training approaches in terms of optimal performance while saving GPU memory.</li>
</ul>

<h3>Title: Title:
          ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yash Akhauri, Ahmed F AbouElhamayed, Jordan Dotzel, Zhiru Zhang, Alexander M Rush, Safeen Huda, Mohamed S Abdelfattah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The high power consumption and latency-sensitive deployments of large language models (LLMs) have motivated techniques like quantization and sparsity. Contextual sparsity, where the sparsity pattern is input-dependent, is crucial in LLMs because the permanent removal of attention heads or neurons from LLMs can significantly degrade accuracy. Prior work has attempted to model contextual sparsity using neural networks trained to predict activation magnitudes, which can be used to dynamically prune structures with low predicted activation magnitude. In this paper, we look beyond magnitude-based pruning criteria to assess attention head and neuron importance in LLMs. We developed a novel predictor called ShadowLLM, which can shadow the LLM behavior and enforce better sparsity patterns, resulting in over 15% improvement in end-to-end accuracy without increasing latency compared to previous methods. ShadowLLM achieves up to a 20\% speed-up over the state-of-the-art DejaVu framework. These enhancements are validated on models with up to 30 billion parameters. Our code is available at \href{this https URL}{ShadowLLM}.</li>
</ul>

<h3>Title: Title:
          Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Belal (1), Taimur Hassan (2), Abdelfatah Ahmed (1), Ahmad Aljarah (1), Nael Alsheikh (1), Irfan Hussain (1) ((1) Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates, (2) Abu Dhabi University, Abu Dhabi, United Arab Emirates)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Human activity recognition (HAR) is a crucial area of research that involves understanding human movements using computer and machine vision technology. Deep learning has emerged as a powerful tool for this task, with models such as Convolutional Neural Networks (CNNs) and Transformers being employed to capture various aspects of human motion. One of the key contributions of this work is the demonstration of the effectiveness of feature fusion in improving HAR accuracy by capturing spatial and temporal features, which has important implications for the development of more accurate and robust activity recognition systems. The study uses sensory data from HuGaDB, PKU-MMD, LARa, and TUG datasets. Two model, the PO-MS-GCN and a Transformer were trained and evaluated, with PO-MS-GCN outperforming state-of-the-art models. HuGaDB and TUG achieved high accuracies and f1-scores, while LARa and PKU-MMD had lower scores. Feature fusion improved results across datasets.</li>
</ul>

<h3>Title: Title:
          Large Language Models Are Cross-Lingual Knowledge-Free Reasoners</h3>
<ul>
<li><strong>Authors: </strong>Peng Hu, Sizhe Liu, Changjiang Gao, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Shujian Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Large Language Models Are Cross-Lingual Knowledge-Free Reasoners(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have demonstrated impressive reasoning capabilities across multiple languages. However, the relationship between capabilities in different languages is less explored. In this work, we decompose the process of reasoning tasks into two separated parts: knowledge retrieval and knowledge-free reasoning, and analyze the cross-lingual transferability of them. With adapted and constructed knowledge-free reasoning datasets, we show that the knowledge-free reasoning capability can be nearly perfectly transferred across various source-target language directions despite the secondary impact of resource in some specific target languages, while cross-lingual knowledge retrieval significantly hinders the transfer. Moreover, by analyzing the hidden states and feed-forward network neuron activation during the reasoning tasks, we show that higher similarity of hidden representations and larger overlap of activated neurons could explain the better cross-lingual transferability of knowledge-free reasoning than knowledge retrieval. Thus, we hypothesize that knowledge-free reasoning embeds in some language-shared mechanism, while knowledge is stored separately in different languages.</li>
</ul>

<h3>Title: Title:
          Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Markus Frohmann, Igor Sterner, Ivan Vulić, Benjamin Minixhofer, Markus Schedl</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Segmenting text into sentences plays an early and crucial role in many NLP systems. This is commonly achieved by using rule-based or statistical methods relying on lexical features such as punctuation. Although some recent works no longer exclusively rely on punctuation, we find that no prior method achieves all of (i) robustness to missing punctuation, (ii) effective adaptability to new domains, and (iii) high efficiency. We introduce a new model - Segment any Text (SaT) - to solve this problem. To enhance robustness, we propose a new pretraining scheme that ensures less reliance on punctuation. To address adaptability, we introduce an extra stage of parameter-efficient fine-tuning, establishing state-of-the-art performance in distinct domains such as verses from lyrics and legal documents. Along the way, we introduce architectural modifications that result in a threefold gain in speed over the previous state of the art and solve spurious reliance on context far in the future. Finally, we introduce a variant of our model with fine-tuning on a diverse, multilingual mixture of sentence-segmented data, acting as a drop-in replacement and enhancement for existing segmentation tools. Overall, our contributions provide a universal approach for segmenting any text. Our method outperforms all baselines - including strong LLMs - across 8 corpora spanning diverse domains and languages, especially in practically relevant situations where text is poorly formatted. Our models and code, including documentation, are available at this https URL under the MIT license.</li>
</ul>

<h3>Title: Title:
          Repulsive Score Distillation for Diverse Sampling of Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Nicolas Zilberstein, Morteza Mardani, Santiago Segarra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Repulsive Score Distillation for Diverse Sampling of Diffusion Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Score distillation sampling has been pivotal for integrating diffusion models into generation of complex visuals. Despite impressive results it suffers from mode collapse and lack of diversity. To cope with this challenge, we leverage the gradient flow interpretation of score distillation to propose Repulsive Score Distillation (RSD). In particular, we propose a variational framework based on repulsion of an ensemble of particles that promotes diversity. Using a variational approximation that incorporates a coupling among particles, the repulsion appears as a simple regularization that allows interaction of particles based on their relative pairwise similarity, measured e.g., via radial basis kernels. We design RSD for both unconstrained and constrained sampling scenarios. For constrained sampling we focus on inverse problems in the latent space that leads to an augmented variational formulation, that strikes a good balance between compute, quality and diversity. Our extensive experiments for text-to-image generation, and inverse problems demonstrate that RSD achieves a superior trade-off between diversity and quality compared with state-of-the-art alternatives.</li>
</ul>

<h3>Title: Title:
          Scaling Laws for Linear Complexity Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xuyang Shen, Dong Li, Ruitao Leng, Zhen Qin, Weigao Sun, Yiran Zhong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Scaling Laws for Linear Complexity Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The interest in linear complexity models for large language models is on the rise, although their scaling capacity remains uncertain. In this study, we present the scaling laws for linear complexity language models to establish a foundation for their scalability. Specifically, we examine the scaling behaviors of three efficient linear architectures. These include TNL, a linear attention model with data-independent decay; HGRN2, a linear RNN with data-dependent decay; and cosFormer2, a linear attention model without decay. We also include LLaMA as a baseline architecture for softmax attention for comparison. These models were trained with six variants, ranging from 70M to 7B parameters on a 300B-token corpus, and evaluated with a total of 1,376 intermediate checkpoints on various downstream tasks. These tasks include validation loss, commonsense reasoning, and information retrieval and generation. The study reveals that existing linear complexity language models exhibit similar scaling capabilities as conventional transformer-based models while also demonstrating superior linguistic proficiency and knowledge retention.</li>
</ul>

<h3>Title: Title:
          Task Oriented In-Domain Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Xiao Liang, Xinyu Hu, Simiao Zuo, Yeyun Gong, Qiang Lou, Yi Liu, Shao-Lun Huang, Jian Jiao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Task Oriented In-Domain Data Augmentation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown superior performance in various applications and fields. To achieve better performance on specialized domains such as law and advertisement, LLMs are often continue pre-trained on in-domain data. However, existing approaches suffer from two major issues. First, in-domain data are scarce compared with general domain-agnostic data. Second, data used for continual pre-training are not task-aware, such that they may not be helpful to downstream applications. We propose TRAIT, a task-oriented in-domain data augmentation framework. Our framework is divided into two parts: in-domain data selection and task-oriented synthetic passage generation. The data selection strategy identifies and selects a large amount of in-domain data from general corpora, and thus significantly enriches domain knowledge in the continual pre-training data. The synthetic passages contain guidance on how to use domain knowledge to answer questions about downstream tasks. By training on such passages, the model aligns with the need of downstream applications. We adapt LLMs to two domains: advertisement and math. On average, TRAIT improves LLM performance by 8% in the advertisement domain and 7.5% in the math domain.</li>
</ul>

<h3>Title: Title:
          Geometry-Aware Score Distillation via 3D Consistent Noising and Gradient Consistency Modeling</h3>
<ul>
<li><strong>Authors: </strong>Min-Seop Kwak, Donghoon Ahn, Ines Hyeonsu Kim, Jin-wha Kim, Seungryong Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Geometry-Aware Score Distillation via 3D Consistent Noising and Gradient Consistency Modeling(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Score distillation sampling (SDS), the methodology in which the score from pretrained 2D diffusion models is distilled into 3D representation, has recently brought significant advancements in text-to-3D generation task. However, this approach is still confronted with critical geometric inconsistency problems such as the Janus problem. Starting from a hypothesis that such inconsistency problems may be induced by multiview inconsistencies between 2D scores predicted from various viewpoints, we introduce GSD, a simple and general plug-and-play framework for incorporating 3D consistency and therefore geometry awareness into the SDS process. Our methodology is composed of three components: 3D consistent noising, designed to produce 3D consistent noise maps that perfectly follow the standard Gaussian distribution, geometry-based gradient warping for identifying correspondences between predicted gradients of different viewpoints, and novel gradient consistency loss to optimize the scene geometry toward producing more consistent gradients. We demonstrate that our method significantly improves performance, successfully addressing the geometric inconsistency problems in text-to-3D generation task with minimal computation cost and being compatible with existing score distillation-based models. Our project page is available at this https URL.</li>
</ul>

<h3>Title: Title:
          Learning Interpretable Fair Representations</h3>
<ul>
<li><strong>Authors: </strong>Tianhao Wang, Zana Buçinca, Zilin Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Learning Interpretable Fair Representations(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Numerous approaches have been recently proposed for learning fair representations that mitigate unfair outcomes in prediction tasks. A key motivation for these methods is that the representations can be used by third parties with unknown objectives. However, because current fair representations are generally not interpretable, the third party cannot use these fair representations for exploration, or to obtain any additional insights, besides the pre-contracted prediction tasks. Thus, to increase data utility beyond prediction tasks, we argue that the representations need to be fair, yet interpretable. We propose a general framework for learning interpretable fair representations by introducing an interpretable "prior knowledge" during the representation learning process. We implement this idea and conduct experiments with ColorMNIST and Dsprite datasets. The results indicate that in addition to being interpretable, our representations attain slightly higher accuracy and fairer outcomes in a downstream classification task compared to state-of-the-art fair representations.</li>
</ul>

<h3>Title: Title:
          CausalFormer: An Interpretable Transformer for Temporal Causal Discovery</h3>
<ul>
<li><strong>Authors: </strong>Lingbai Kong, Wengen Li, Hanchen Yang, Yichao Zhang, Jihong Guan, Shuigeng Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          CausalFormer: An Interpretable Transformer for Temporal Causal Discovery(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Temporal causal discovery is a crucial task aimed at uncovering the causal relations within time series data. The latest temporal causal discovery methods usually train deep learning models on prediction tasks to uncover the causality between time series. They capture causal relations by analyzing the parameters of some components of the trained models, e.g., attention weights and convolution weights. However, this is an incomplete mapping process from the model parameters to the causality and fails to investigate the other components, e.g., fully connected layers and activation functions, that are also significant for causal discovery. To facilitate the utilization of the whole deep learning models in temporal causal discovery, we proposed an interpretable transformer-based causal discovery model termed CausalFormer, which consists of the causality-aware transformer and the decomposition-based causality detector. The causality-aware transformer learns the causal representation of time series data using a prediction task with the designed multi-kernel causal convolution which aggregates each input time series along the temporal dimension under the temporal priority constraint. Then, the decomposition-based causality detector interprets the global structure of the trained causality-aware transformer with the proposed regression relevance propagation to identify potential causal relations and finally construct the causal graph. Experiments on synthetic, simulated, and real datasets demonstrate the state-of-the-art performance of CausalFormer on discovering temporal causality. Our code is available at this https URL.</li>
</ul>

<h3>Title: Title:
          Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image</h3>
<ul>
<li><strong>Authors: </strong>Jinkun Hao, Junshu Tang, Jiangning Zhang, Ran Yi, Yijia Hong, Moran Li, Weijian Cao, Yating Wang, Lizhuang Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While recent works have achieved great success on one-shot 3D common object generation, high quality and fidelity 3D head generation from a single image remains a great challenge. Previous text-based methods for generating 3D heads were limited by text descriptions and image-based methods struggled to produce high-quality head geometry. To handle this challenging problem, we propose a novel framework, Portrait3D, to generate high-quality 3D heads while preserving their identities. Our work incorporates the identity information of the portrait image into three parts: 1) geometry initialization, 2) geometry sculpting, and 3) texture generation stages. Given a reference portrait image, we first align the identity features with text features to realize ID-aware guidance enhancement, which contains the control signals representing the face information. We then use the canny map, ID features of the portrait image, and a pre-trained text-to-normal/depth diffusion model to generate ID-aware geometry supervision, and 3D-GAN inversion is employed to generate ID-aware geometry initialization. Furthermore, with the ability to inject identity information into 3D head generation, we use ID-aware guidance to calculate ID-aware Score Distillation (ISD) for geometry sculpting. For texture generation, we adopt the ID Consistent Texture Inpainting and Refinement which progressively expands the view for texture inpainting to obtain an initialization UV texture map. We then use the id-aware guidance to provide image-level supervision for noisy multi-view images to obtain a refined texture map. Extensive experiments demonstrate that we can generate high-quality 3D heads with accurate geometry and texture from single in-the-wild portrait images. The project page is at this https URL.</li>
</ul>

<h3>Title: Title:
          AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiale Cheng, Yida Lu, Xiaotao Gu, Pei Ke, Xiao Liu, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although Large Language Models (LLMs) are becoming increasingly powerful, they still exhibit significant but subtle weaknesses, such as mistakes in instruction-following or coding tasks. As these unexpected errors could lead to severe consequences in practical deployments, it is crucial to investigate the limitations within LLMs systematically. Traditional benchmarking approaches cannot thoroughly pinpoint specific model deficiencies, while manual inspections are costly and not scalable. In this paper, we introduce a unified framework, AutoDetect, to automatically expose weaknesses in LLMs across various tasks. Inspired by the educational assessment process that measures students' learning outcomes, AutoDetect consists of three LLM-powered agents: Examiner, Questioner, and Assessor. The collaboration among these three agents is designed to realize comprehensive and in-depth weakness identification. Our framework demonstrates significant success in uncovering flaws, with an identification success rate exceeding 30% in prominent models such as ChatGPT and Claude. More importantly, these identified weaknesses can guide specific model improvements, proving more effective than untargeted data augmentation methods like Self-Instruct. Our approach has led to substantial enhancements in popular LLMs, including the Llama series and Mistral-7b, boosting their performance by over 10% across several benchmarks. Code and data are publicly available at this https URL.</li>
</ul>

<h3>Title: Title:
          GC-Bench: A Benchmark Framework for Graph Condensation with New Insights</h3>
<ul>
<li><strong>Authors: </strong>Shengbo Gong, Juntong Ni, Noveen Sachdeva, Carl Yang, Wei Jin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          GC-Bench: A Benchmark Framework for Graph Condensation with New Insights(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph condensation (GC) is an emerging technique designed to learn a significantly smaller graph that retains the essential information of the original graph. This condensed graph has shown promise in accelerating graph neural networks while preserving performance comparable to those achieved with the original, larger graphs. Additionally, this technique facilitates downstream applications such as neural architecture search and enhances our understanding of redundancy in large graphs. Despite the rapid development of GC methods, a systematic evaluation framework remains absent, which is necessary to clarify the critical designs for particular evaluative aspects. Furthermore, several meaningful questions have not been investigated, such as whether GC inherently preserves certain graph properties and offers robustness even without targeted design efforts. In this paper, we introduce GC-Bench, a comprehensive framework to evaluate recent GC methods across multiple dimensions and to generate new insights. Our experimental findings provide a deeper insights into the GC process and the characteristics of condensed graphs, guiding future efforts in enhancing performance and exploring new applications. Our code is available at \url{this https URL}.</li>
</ul>

<h3>Title: Title:
          Venturing into Uncharted Waters: The Navigation Compass from Transformer to Mamba</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Zou, Yineng Chen, Zuchao Li, Lefei Zhang, Hai Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Venturing into Uncharted Waters: The Navigation Compass from Transformer to Mamba(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer, a deep neural network architecture, has long dominated the field of natural language processing and beyond. Nevertheless, the recent introduction of Mamba challenges its supremacy, sparks considerable interest among researchers, and gives rise to a series of Mamba-based models that have exhibited notable potential. This survey paper orchestrates a comprehensive discussion, diving into essential research dimensions, covering: (i) the functioning of the Mamba mechanism and its foundation on the principles of structured state space models; (ii) the proposed improvements and the integration of Mamba with various networks, exploring its potential as a substitute for Transformers; (iii) the combination of Transformers and Mamba to compensate for each other's shortcomings. We have also made efforts to interpret Mamba and Transformer in the framework of kernel functions, allowing for a comparison of their mathematical nature within a unified context. Our paper encompasses the vast majority of improvements related to Mamba to date.</li>
</ul>

<h3>Title: Title:
          Inducing Group Fairness in LLM-Based Decisions</h3>
<ul>
<li><strong>Authors: </strong>James Atwood, Preethi Lahoti, Ananth Balashankar, Flavien Prost, Ahmad Beirami</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Inducing Group Fairness in LLM-Based Decisions(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Prompting Large Language Models (LLMs) has created new and interesting means for classifying textual data. While evaluating and remediating group fairness is a well-studied problem in classifier fairness literature, some classical approaches (e.g., regularization) do not carry over, and some new opportunities arise (e.g., prompt-based remediation). We measure fairness of LLM-based classifiers on a toxicity classification task, and empirically show that prompt-based classifiers may lead to unfair decisions. We introduce several remediation techniques and benchmark their fairness and performance trade-offs. We hope our work encourages more research on group fairness in LLM-based classifiers.</li>
</ul>

<h3>Title: Title:
          Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zhengyue Zhao, Xiaoyun Zhang, Kaidi Xu, Xing Hu, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the widespread application of Large Language Models (LLMs), it has become a significant concern to ensure their safety and prevent harmful responses. While current safe-alignment methods based on instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) can effectively reduce harmful responses from LLMs, they often require high-quality datasets and heavy computational overhead during model training. Another way to align language models is to modify the logit of tokens in model outputs without heavy training. Recent studies have shown that contrastive decoding can enhance the performance of language models by reducing the likelihood of confused tokens. However, these methods require the manual selection of contrastive models or instruction templates. To this end, we propose Adversarial Contrastive Decoding (ACD), an optimization-based framework to generate two opposite system prompts for prompt-based contrastive decoding. ACD only needs to apply a lightweight prompt tuning on a rather small anchor dataset (< 3 min for each model) without training the target model. Experiments conducted on extensive models and benchmarks demonstrate that the proposed method achieves much better safety performance than previous model training-free decoding methods without sacrificing its original generation ability.</li>
</ul>

<h3>Title: Title:
          Bandits with Preference Feedback: A Stackelberg Game Perspective</h3>
<ul>
<li><strong>Authors: </strong>Barna Pásztor, Parnian Kassraie, Andreas Krause</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Bandits with Preference Feedback: A Stackelberg Game Perspective(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Bandits with preference feedback present a powerful tool for optimizing unknown target functions when only pairwise comparisons are allowed instead of direct value queries. This model allows for incorporating human feedback into online inference and optimization and has been employed in systems for fine-tuning large language models. The problem is well understood in simplified settings with linear target functions or over finite small domains that limit practical interest. Taking the next step, we consider infinite domains and nonlinear (kernelized) rewards. In this setting, selecting a pair of actions is quite challenging and requires balancing exploration and exploitation at two levels: within the pair, and along the iterations of the algorithm. We propose MAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and chooses action pairs that are informative and yield favorable rewards. MAXMINLCB consistently outperforms existing algorithms and satisfies an anytime-valid rate-optimal regret guarantee. This is due to our novel preference-based confidence sequences for kernelized logistic estimators.</li>
</ul>

<h3>Title: Title:
          Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers</h3>
<ul>
<li><strong>Authors: </strong>Chao Lou, Zixia Jia, Zilong Zheng, Kewei Tu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Accommodating long sequences efficiently in autoregressive Transformers, especially within an extended context window, poses significant challenges due to the quadratic computational complexity and substantial KV memory requirements inherent in self-attention mechanisms. In this work, we introduce SPARSEK Attention, a novel sparse attention mechanism designed to overcome these computational and memory obstacles while maintaining performance. Our approach integrates a scoring network and a differentiable top-k mask operator, SPARSEK, to select a constant number of KV pairs for each query, thereby enabling gradient-based optimization. As a result, SPARSEK Attention offers linear time complexity and constant memory footprint during generation. Experimental results reveal that SPARSEK Attention outperforms previous sparse attention methods and provides significant speed improvements during both training and inference, particularly in language modeling and downstream tasks. Furthermore, our method can be seamlessly integrated into pre-trained Large Language Models (LLMs) with minimal fine-tuning, offering a practical solution for effectively managing long-range dependencies in diverse applications.</li>
</ul>

<h3>Title: Title:
          OCALM: Object-Centric Assessment with Language Models</h3>
<ul>
<li><strong>Authors: </strong>Timo Kaufmann, Jannis Blüml, Antonia Wüst, Quentin Delfosse, Kristian Kersting, Eyke Hüllermeier</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          OCALM: Object-Centric Assessment with Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Properly defining a reward signal to efficiently train a reinforcement learning (RL) agent is a challenging task. Designing balanced objective functions from which a desired behavior can emerge requires expert knowledge, especially for complex environments. Learning rewards from human feedback or using large language models (LLMs) to directly provide rewards are promising alternatives, allowing non-experts to specify goals for the agent. However, black-box reward models make it difficult to debug the reward. In this work, we propose Object-Centric Assessment with Language Models (OCALM) to derive inherently interpretable reward functions for RL agents from natural language task descriptions. OCALM uses the extensive world-knowledge of LLMs while leveraging the object-centric nature common to many environments to derive reward functions focused on relational concepts, providing RL agents with the ability to derive policies from task descriptions.</li>
</ul>

<h3>Title: Title:
          Inferring stochastic low-rank recurrent neural networks from neural data</h3>
<ul>
<li><strong>Authors: </strong>Matthijs Pals, A Erdem Sağtekin, Felix Pei, Manuel Gloeckler, Jakob H Macke</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.NC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Inferring stochastic low-rank recurrent neural networks from neural data(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>A central aim in computational neuroscience is to relate the activity of large populations of neurons to an underlying dynamical system. Models of these neural dynamics should ideally be both interpretable and fit the observed data well. Low-rank recurrent neural networks (RNNs) exhibit such interpretability by having tractable dynamics. However, it is unclear how to best fit low-rank RNNs to data consisting of noisy observations of an underlying stochastic system. Here, we propose to fit stochastic low-rank RNNs with variational sequential Monte Carlo methods. We validate our method on several datasets consisting of both continuous and spiking neural data, where we obtain lower dimensional latent dynamics than current state of the art methods. Additionally, for low-rank models with piecewise linear nonlinearities, we show how to efficiently identify all fixed points in polynomial rather than exponential cost in the number of units, making analysis of the inferred dynamics tractable for large RNNs. Our method both elucidates the dynamical systems underlying experimental recordings and provides a generative model whose trajectories match observed trial-to-trial variability.</li>
</ul>

<h3>Title: Title:
          Addressing Polarization and Unfairness in Performative Prediction</h3>
<ul>
<li><strong>Authors: </strong>Kun Jin, Tian Xie, Yang Liu, Xueru Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Addressing Polarization and Unfairness in Performative Prediction(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>When machine learning (ML) models are used in applications that involve humans (e.g., online recommendation, school admission, hiring, lending), the model itself may trigger changes in the distribution of targeted data it aims to predict. Performative prediction (PP) is a framework that explicitly considers such model-dependent distribution shifts when learning ML models. While significant efforts have been devoted to finding performative stable (PS) solutions in PP for system robustness, their societal implications are less explored and it is unclear whether PS solutions are aligned with social norms such as fairness. In this paper, we set out to examine the fairness property of PS solutions in performative prediction. We first show that PS solutions can incur severe polarization effects and group-wise loss disparity. Although existing fairness mechanisms commonly used in literature can help mitigate unfairness, they may fail and disrupt the stability under model-dependent distribution shifts. We thus propose novel fairness intervention mechanisms that can simultaneously achieve both stability and fairness in PP settings. Both theoretical analysis and experiments are provided to validate the proposed method.</li>
</ul>

<h3>Title: Title:
          Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters</h3>
<ul>
<li><strong>Authors: </strong>Euiin Yi, Taehyeon Kim, Hongseok Jeung, Du-Seong Chang, Se-Young Yun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have revolutionized natural language processing and broadened their applicability across diverse commercial applications. However, the deployment of these models is constrained by high inference time in multilingual settings. To mitigate this challenge, this paper explores a training recipe of an assistant model in speculative decoding, which are leveraged to draft and-then its future tokens are verified by the target LLM. We show that language-specific draft models, optimized through a targeted pretrain-and-finetune strategy, substantially brings a speedup of inference time compared to the previous methods. We validate these models across various languages in inference time, out-of-domain speedup, and GPT-4o evaluation.</li>
</ul>

<h3>Title: Title:
          The GPT-WritingPrompts Dataset: A Comparative Analysis of Character Portrayal in Short Stories</h3>
<ul>
<li><strong>Authors: </strong>Xi Yu Huang, Krishnapriya Vishnubhotla, Frank Rudzicz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          The GPT-WritingPrompts Dataset: A Comparative Analysis of Character Portrayal in Short Stories(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The improved generative capabilities of large language models have made them a powerful tool for creative writing and storytelling. It is therefore important to quantitatively understand the nature of generated stories, and how they differ from human storytelling. We augment the Reddit WritingPrompts dataset with short stories generated by GPT-3.5, given the same prompts. We quantify and compare the emotional and descriptive features of storytelling from both generative processes, human and machine, along a set of six dimensions. We find that generated stories differ significantly from human stories along all six dimensions, and that human and machine generations display similar biases when grouped according to the narrative point-of-view and gender of the main protagonist. We release our dataset and code at this https URL.</li>
</ul>

<h3>Title: Title:
          WARP: On the Benefits of Weight Averaged Rewarded Policies</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Ramé, Johan Ferret, Nino Vieillard, Robert Dadashi, Léonard Hussenot, Pierre-Louis Cedoz, Pier Giuseppe Sessa, Sertan Girgin, Arthur Douillard, Olivier Bachem</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          WARP: On the Benefits of Weight Averaged Rewarded Policies(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning from human feedback (RLHF) aligns large language models (LLMs) by encouraging their generations to have high rewards, using a reward model trained on human preferences. To prevent the forgetting of pre-trained knowledge, RLHF usually incorporates a KL regularization; this forces the policy to remain close to its supervised fine-tuned initialization, though it hinders the reward optimization. To tackle the trade-off between KL and reward, in this paper we introduce a novel alignment strategy named Weight Averaged Rewarded Policies (WARP). WARP merges policies in the weight space at three distinct stages. First, it uses the exponential moving average of the policy as a dynamic anchor in the KL regularization. Second, it applies spherical interpolation to merge independently fine-tuned policies into a new enhanced one. Third, it linearly interpolates between this merged model and the initialization, to recover features from pre-training. This procedure is then applied iteratively, with each iteration's final model used as an advanced initialization for the next, progressively refining the KL-reward Pareto front, achieving superior rewards at fixed KL. Experiments with GEMMA policies validate that WARP improves their quality and alignment, outperforming other open-source LLMs.</li>
</ul>

<h3>Title: Title:
          Instance Consistency Regularization for Semi-Supervised 3D Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yizheng Wu, Zhiyu Pan, Kewei Wang, Xingyi Li, Jiahao Cui, Liwen Xiao, Guosheng Lin, Zhiguo Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Instance Consistency Regularization for Semi-Supervised 3D Instance Segmentation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Large-scale datasets with point-wise semantic and instance labels are crucial to 3D instance segmentation but also expensive. To leverage unlabeled data, previous semi-supervised 3D instance segmentation approaches have explored self-training frameworks, which rely on high-quality pseudo labels for consistency regularization. They intuitively utilize both instance and semantic pseudo labels in a joint learning manner. However, semantic pseudo labels contain numerous noise derived from the imbalanced category distribution and natural confusion of similar but distinct categories, which leads to severe collapses in self-training. Motivated by the observation that 3D instances are non-overlapping and spatially separable, we ask whether we can solely rely on instance consistency regularization for improved semi-supervised segmentation. To this end, we propose a novel self-training network InsTeacher3D to explore and exploit pure instance knowledge from unlabeled data. We first build a parallel base 3D instance segmentation model DKNet, which distinguishes each instance from the others via discriminative instance kernels without reliance on semantic segmentation. Based on DKNet, we further design a novel instance consistency regularization framework to generate and leverage high-quality instance pseudo labels. Experimental results on multiple large-scale datasets show that the InsTeacher3D significantly outperforms prior state-of-the-art semi-supervised approaches. Code is available: this https URL.</li>
</ul>

<h3>Title: Title:
          Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech Translation System for IWSLT 2024</h3>
<ul>
<li><strong>Authors: </strong>Sai Koneru, Thai-Binh Nguyen, Ngoc-Quan Pham, Danni Liu, Zhaolin Li, Alexander Waibel, Jan Niehues</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech Translation System for IWSLT 2024(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are currently under exploration for various tasks, including Automatic Speech Recognition (ASR), Machine Translation (MT), and even End-to-End Speech Translation (ST). In this paper, we present KIT's offline submission in the constrained + LLM track by incorporating recently proposed techniques that can be added to any cascaded speech translation. Specifically, we integrate Mistral-7B\footnote{mistralai/Mistral-7B-Instruct-v0.1} into our system to enhance it in two ways. Firstly, we refine the ASR outputs by utilizing the N-best lists generated by our system and fine-tuning the LLM to predict the transcript accurately. Secondly, we refine the MT outputs at the document level by fine-tuning the LLM, leveraging both ASR and MT predictions to improve translation quality. We find that integrating the LLM into the ASR and MT systems results in an absolute improvement of $0.3\%$ in Word Error Rate and $0.65\%$ in COMET for tst2019 test set. In challenging test sets with overlapping speakers and background noise, we find that integrating LLM is not beneficial due to poor ASR performance. Here, we use ASR with chunked long-form decoding to improve context usage that may be unavailable when transcribing with Voice Activity Detection segmentation alone.</li>
</ul>

<h3>Title: Title:
          Finding Transformer Circuits with Edge Pruning</h3>
<ul>
<li><strong>Authors: </strong>Adithya Bhaskar, Alexander Wettig, Dan Friedman, Danqi Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Finding Transformer Circuits with Edge Pruning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>The path to interpreting a language model often proceeds via analysis of circuits -- sparse computational subgraphs of the model that capture specific aspects of its behavior. Recent work has automated the task of discovering circuits. Yet, these methods have practical limitations, as they rely either on inefficient search algorithms or inaccurate approximations. In this paper, we frame automated circuit discovery as an optimization problem and propose *Edge Pruning* as an effective and scalable solution. Edge Pruning leverages gradient-based pruning techniques, but instead of removing neurons or components, it prunes the \emph{edges} between components. Our method finds circuits in GPT-2 that use less than half the number of edges compared to circuits found by previous methods while being equally faithful to the full model predictions on standard circuit-finding tasks. Edge Pruning is efficient even with as many as 100K examples, outperforming previous methods in speed and producing substantially better circuits. It also perfectly recovers the ground-truth circuits in two models compiled with Tracr. Thanks to its efficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale that prior methods operate on. We use this setting for a case study comparing the mechanisms behind instruction prompting and in-context learning. We find two circuits with more than 99.96% sparsity that match the performance of the full model and reveal that the mechanisms in the two settings overlap substantially. Our case study shows that Edge Pruning is a practical and scalable tool for interpretability and sheds light on behaviors that only emerge in large models.</li>
</ul>

<h3>Title: Title:
          It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Sagi Shaier, Lawrence E Hunter, Katharina von der Wense</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Natural language processing has seen rapid progress over the past decade. Due to the speed of developments, some practices get established without proper evaluation. Considering one such case and focusing on reading comprehension, we ask our first research question: 1) How does the order of inputs -- i.e., question and context -- affect model performance? Additionally, given recent advancements in input emphasis, we ask a second research question: 2) Does emphasizing either the question, the context, or both enhance performance? Experimenting with 9 large language models across 3 datasets, we find that presenting the context before the question improves model performance, with an accuracy increase of up to $31\%$. Furthermore, emphasizing the context yields superior results compared to question emphasis, and in general, emphasizing parts of the input is particularly effective for addressing questions that models lack the parametric knowledge to answer. Experimenting with both prompt-based and attention-based emphasis methods, we additionally find that the best method is surprisingly simple: it only requires concatenating a few tokens to the input and results in an accuracy improvement of up to $36\%$, allowing smaller models to outperform their significantly larger counterparts.</li>
</ul>

<h3>Title: Title:
          M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Rishabh Maheshwary, Vikas Yadav, Hoang Nguyen, Khyati Mahajan, Sathwik Tejaswi Madhusudhan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction finetuning (IFT) is critical for aligning Large Language Models (LLMs) to follow instructions. Numerous effective IFT datasets have been proposed in the recent past, but most focus on high resource languages such as English. In this work, we propose a fully synthetic, novel taxonomy (Evol) guided Multilingual, Multi-turn instruction finetuning dataset, called M2Lingual, to better align LLMs on a diverse set of languages and tasks. M2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds, covering 70 languages, 17 NLP tasks and general instruction-response pairs. LLMs finetuned with M2Lingual substantially outperform the majority of existing multilingual IFT datasets. Importantly, LLMs trained with M2Lingual consistently achieve competitive results across a wide variety of evaluation benchmarks compared to existing multilingual IFT datasets. Specifically, LLMs finetuned with M2Lingual achieve strong performance on our translated multilingual, multi-turn evaluation benchmark as well as a wide variety of multilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for its creation. M2Lingual repository - this https URL</li>
</ul>

<h3>Title: Title:
          The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Abhi Kamboj</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The transformer neural network architecture allows for autoregressive sequence-to-sequence modeling through the use of attention layers. It was originally created with the application of machine translation but has revolutionized natural language processing. Recently, transformers have also been applied across a wide variety of pattern recognition tasks, particularly in computer vision. In this literature review, we describe major advances in computer vision utilizing transformers. We then focus specifically on Multi-Object Tracking (MOT) and discuss how transformers are increasingly becoming competitive in state-of-the-art MOT works, yet still lag behind traditional deep learning methods.</li>
</ul>

<h3>Title: Title:
          Enabling more efficient and cost-effective AI/ML systems with Collective Mind, virtualized MLOps, MLPerf, Collective Knowledge Playground and reproducible optimization tournaments</h3>
<ul>
<li><strong>Authors: </strong>Grigori Fursin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.ET, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Enabling more efficient and cost-effective AI/ML systems with Collective Mind, virtualized MLOps, MLPerf, Collective Knowledge Playground and reproducible optimization tournaments(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>In this white paper, I present my community effort to automatically co-design cheaper, faster and more energy-efficient software and hardware for AI, ML and other popular workloads with the help of the Collective Mind framework (CM), virtualized MLOps, MLPerf benchmarks and reproducible optimization tournaments. I developed CM to modularize, automate and virtualize the tedious process of building, running, profiling and optimizing complex applications across rapidly evolving open-source and proprietary AI/ML models, datasets, software and hardware. I achieved that with the help of portable, reusable and technology-agnostic automation recipes (ResearchOps) for MLOps and DevOps (CM4MLOps) discovered in close collaboration with academia and industry when reproducing more than 150 research papers and organizing the 1st mass-scale community benchmarking of ML and AI systems using CM and MLPerf. I donated CM and CM4MLOps to MLCommons to help connect academia and industry to learn how to build and run AI and other emerging workloads in the most efficient and cost-effective way using a common and technology-agnostic automation, virtualization and reproducibility framework while unifying knowledge exchange, protecting everyone's intellectual property, enabling portable skills, and accelerating transfer of the state-of-the-art research to production. My long-term vision is to make AI accessible to everyone by making it a commodity automatically produced from the most suitable open-source and proprietary components from different vendors based on user demand, requirements and constraints such as cost, latency, throughput, accuracy, energy, size and other important characteristics.</li>
</ul>

<h3>Title: Title:
          Deep Learning and Chaos: A combined Approach To Image Encryption and Decryption</h3>
<ul>
<li><strong>Authors: </strong>Bharath V Nair, Vismaya V S, Sishu Shankar Muni, Ali Durdu</a></li>
<li><strong>Subjects: </strong>cs.CR, nlin.CD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Deep Learning and Chaos: A combined Approach To Image Encryption and Decryption(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce a novel image encryption and decryption algorithm using hyperchaotic signals from the novel 3D hyperchaotic map, 2D memristor map, Convolutional Neural Network (CNN), and key sensitivity analysis to achieve robust security and high efficiency. The encryption starts with the scrambling of gray images by using a 3D hyperchaotic map to yield complex sequences under disruption of pixel values; the robustness of this original encryption is further reinforced by employing a CNN to learn the intricate patterns and add the safety layer. The robustness of the encryption algorithm is shown by key sensitivity analysis, i.e., the average sensitivity of the algorithm to key elements. The other factors and systems of unauthorized decryption, even with slight variations in the keys, can alter the decryption procedure, resulting in the ineffective recreation of the decrypted image. Statistical analysis includes entropy analysis, correlation analysis, histogram analysis, and other security analyses like anomaly detection, all of which confirm the high security and effectiveness of the proposed encryption method. Testing of the algorithm under various noisy conditions is carried out to test robustness against Gaussian noise. Metrics for differential analysis, such as the NPCR (Number of Pixel Change Rate)and UACI (Unified Average Change Intensity), are also used to determine the strength of encryption. At the same time, the empirical validation was performed on several test images, which showed that the proposed encryption techniques have practical applicability and are robust to noise. Simulation results and comparative analyses illustrate that our encryption scheme possesses excellent visual security, decryption quality, and computational efficiency, and thus, it is efficient for secure image transmission and storage in big data applications.</li>
</ul>

<h3>Title: Title:
          Adam-mini: Use Fewer Learning Rates To Gain More</h3>
<ul>
<li><strong>Authors: </strong>Yushun Zhang, Congliang Chen, Ziniu Li, Tian Ding, Chenwei Wu, Yinyu Ye, Zhi-Quan Luo, Ruoyu Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Adam-mini: Use Fewer Learning Rates To Gain More(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We propose Adam-mini, an optimizer that achieves on-par or better performance than AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by cutting down the number of learning rates in Adam: Instead of assigning an individual learning rate for each parameter using $1/\sqrt{v}$, Adam-mini uses the average of $v$ within a pre-defined parameter block as the learning rate for that block. Such a design is inspired by two empirical findings. First, the Hessian of Transformers exhibits a near-block diagonal structure with different sizes of dense sub-blocks. Second, for each of these dense sub-blocks, there exists a single high-quality learning rate that can outperform Adam, provided that sufficient resources are available to search it out. Adam-mini provides one cost-effective way to find these good learning rates and manage to cut down $\geq 90% v$ in Adam. Empirically, we verify that Adam-mini performs on par or better than AdamW on various language models sized from 125M to 7B for pre-training, supervised fine-tuning, and RLHF. The reduced memory footprint of Adam-mini also alleviates communication overheads among GPUs and CPUs, thereby increasing throughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamW when pre-training Llama2-7B on 2x A800-80GB GPUs, which saves 33% wall-clock time for pre-training.</li>
</ul>

<h3>Title: Title:
          Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ashwinee Panda, Berivan Isik, Xiangyu Qi, Sanmi Koyejo, Tsachy Weissman, Prateek Mittal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing methods for adapting large language models (LLMs) to new tasks are not suited to multi-task adaptation because they modify all the model weights -- causing destructive interference between tasks. The resulting effects, such as catastrophic forgetting of earlier tasks, make it challenging to obtain good performance on multiple tasks at the same time. To mitigate this, we propose Lottery Ticket Adaptation (LoTA), a sparse adaptation method that identifies and optimizes only a sparse subnetwork of the model. We evaluate LoTA on a wide range of challenging tasks such as instruction following, reasoning, math, and summarization. LoTA obtains better performance than full fine-tuning and low-rank adaptation (LoRA), and maintains good performance even after training on other tasks -- thus, avoiding catastrophic forgetting. By extracting and fine-tuning over \emph{lottery tickets} (or \emph{sparse task vectors}), LoTA also enables model merging over highly dissimilar tasks.</li>
</ul>

<h3>Title: Title:
          RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale</h3>
<ul>
<li><strong>Authors: </strong>Beck LaBash, August Rosedale, Alex Reents, Colin Wiel</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The instruction-following ability of Large Language Models (LLMs) has cultivated a class of LLM-based systems capable of approaching complex tasks such as making edits to large code repositories. Due to the high sensitivity and unpredictability of LLM behavior in response to changes in prompting, robust evaluation tools are needed to drive future iteration of these systems. We propose RES-Q, a natural language instruction-based benchmark for evaluating $\textbf{R}$epository $\textbf{E}$diting $\textbf{S}$ystems, which consists of 100 repository editing tasks derived from real GitHub commits. Given an edit instruction and a code repository, RES-Q evaluates an LLM system's ability to gather information and construct an edit that satisfies the criteria set by the instruction. We argue that evaluating LLMs in this way addresses issues with traditional benchmarks and provides a more holistic assessment of a model's abilities. We evaluate various state-of-the-art LLMs as language agents in a repository-editing system built on Qurrent OS, our language agent development software. Despite their 1% pass@1 performance difference on HumanEval, we find Claude Sonnet 3.5 outperforms GPT-4o by 12% pass@1 on RES-Q, indicating RES-Q's capacity to differentiate model capability as traditional benchmarks approach saturation. We further investigate token efficiency, performance relationships with existing benchmarks, and interesting disparities between closed and open-source LLMs. Code and dataset are available at this https URL.</li>
</ul>

<h3>Title: Title:
          Comment on Chen et al.'s Authentication Protocol for Internet of Health Things</h3>
<ul>
<li><strong>Authors: </strong>Iman Jafarian, Siavash Khorsandi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Comment on Chen et al.'s Authentication Protocol for Internet of Health Things(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>The Internet of Medical Things has revolutionized the healthcare industry, enabling the seamless integration of connected medical devices and wearable sensors to enhance patient care and optimize healthcare services. However, the rapid adoption of the Internet of Medical Things also introduces significant security challenges that must be effectively addressed to preserve patient privacy, protect sensitive medical data, and ensure the overall reliability and safety of Internet of Medical Things systems. In this context, a key agreement protocol is used to securely establish shared cryptographic keys between interconnected medical devices and the central system, ensuring confidential and authenticated communication. Recently Chen et al. proposed a lightweight authentication and key agreement protocol for the Internet of health things. In this article, we provide a descriptive analysis of their proposed scheme and prove that Chen et al.'s scheme is vulnerable to Known session-specific temporary information attacks and stolen verifier attacks.</li>
</ul>

<h3>Title: Title:
          PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xinchi Qiu, William F. Shen, Yihong Chen, Nicola Cancedda, Pontus Stenetorp, Nicholas D. Lane</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust</a></li>
<li><strong>Abstract: </strong>Recently, machine unlearning, which seeks to erase specific data stored in the pre-trained or fine-tuned models, has emerged as a crucial protective measure for LLMs. However, unlearning approaches for LLMs that have been considered thus far have focused on the removal of independent data points and have not taken into account that the stored facts are logically connected to one another and form an implicit knowledge graph. To facilitate the development of structural unlearning methods, which are essential for the practical application of unlearning, we propose PISTOL, a pipeline for compiling multi-scenario datasets for benchmarking structural LLM unlearning. Additionally, leveraging sample datasets synthesized using PISTOL, we conducted benchmarks with four distinct unlearning methods on both Llama2-7B and Mistral-7B models. This analysis helps to illustrate the prevailing challenges in effectively and robustly removing highly inter-connected data, batched data, or data skewed towards a specific domain. It also highlights the choice of pre-trained model can impact unlearning performance. This work not only advances our understandings on the limitation of current LLMs unlearning methods and proposes future research directions, but also provides a replicable framework for ongoing exploration and validation in the field.</li>
</ul>

<h3>Title: Title:
          ClotheDreamer: Text-Guided Garment Generation with 3D Gaussians</h3>
<ul>
<li><strong>Authors: </strong>Yufei Liu, Junshu Tang, Chu Zheng, Shijie Zhang, Jinkun Hao, Junwei Zhu, Dongjin Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          ClotheDreamer: Text-Guided Garment Generation with 3D Gaussians(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>High-fidelity 3D garment synthesis from text is desirable yet challenging for digital avatar creation. Recent diffusion-based approaches via Score Distillation Sampling (SDS) have enabled new possibilities but either intricately couple with human body or struggle to reuse. We introduce ClotheDreamer, a 3D Gaussian-based method for generating wearable, production-ready 3D garment assets from text prompts. We propose a novel representation Disentangled Clothe Gaussian Splatting (DCGS) to enable separate optimization. DCGS represents clothed avatar as one Gaussian model but freezes body Gaussian splats. To enhance quality and completeness, we incorporate bidirectional SDS to supervise clothed avatar and garment RGBD renderings respectively with pose conditions and propose a new pruning strategy for loose clothing. Our approach can also support custom clothing templates as input. Benefiting from our design, the synthetic 3D garment can be easily applied to virtual try-on and support physically accurate animation. Extensive experiments showcase our method's superior and competitive performance. Our project page is at this https URL.</li>
</ul>

<h3>Title: Title:
          GPT-4V Explorations: Mining Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Zixuan Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          GPT-4V Explorations: Mining Autonomous Driving(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper explores the application of the GPT-4V(ision) large visual language model to autonomous driving in mining environments, where traditional systems often falter in understanding intentions and making accurate decisions during emergencies. GPT-4V introduces capabilities for visual question answering and complex scene comprehension, addressing challenges in these specialized settings.Our evaluation focuses on its proficiency in scene understanding, reasoning, and driving functions, with specific tests on its ability to recognize and interpret elements such as pedestrians, various vehicles, and traffic devices. While GPT-4V showed robust comprehension and decision-making skills, it faced difficulties in accurately identifying specific vehicle types and managing dynamic interactions. Despite these challenges, its effective navigation and strategic decision-making demonstrate its potential as a reliable agent for autonomous driving in the complex conditions of mining environments, highlighting its adaptability and operational viability in industrial settings.</li>
</ul>

<h3>Title: Title:
          General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design</h3>
<ul>
<li><strong>Authors: </strong>Yue Jian, Curtis Wu, Danny Reidenbach, Aditi S. Krishnapriyan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.bio-ph, physics.chem-ph, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Structure-Based Drug Design (SBDD) focuses on generating valid ligands that strongly and specifically bind to a designated protein pocket. Several methods use machine learning for SBDD to generate these ligands in 3D space, conditioned on the structure of a desired protein pocket. Recently, diffusion models have shown success here by modeling the underlying distributions of atomic positions and types. While these methods are effective in considering the structural details of the protein pocket, they often fail to explicitly consider the binding affinity. Binding affinity characterizes how tightly the ligand binds to the protein pocket, and is measured by the change in free energy associated with the binding process. It is one of the most crucial metrics for benchmarking the effectiveness of the interaction between a ligand and protein pocket. To address this, we propose BADGER: Binding Affinity Diffusion Guidance with Enhanced Refinement. BADGER is a general guidance method to steer the diffusion sampling process towards improved protein-ligand binding, allowing us to adjust the distribution of the binding affinity between ligands and proteins. Our method is enabled by using a neural network (NN) to model the energy function, which is commonly approximated by AutoDock Vina (ADV). ADV's energy function is non-differentiable, and estimates the affinity based on the interactions between a ligand and target protein receptor. By using a NN as a differentiable energy function proxy, we utilize the gradient of our learned energy function as a guidance method on top of any trained diffusion model. We show that our method improves the binding affinity of generated ligands to their protein receptors by up to 60\%, significantly surpassing previous machine learning methods. We also show that our guidance method is flexible and can be easily applied to other diffusion-based SBDD frameworks.</li>
</ul>

<h3>Title: Title:
          A Multi-Party, Multi-Blockchain Atomic Swap Protocol with Universal Adaptor Secret</h3>
<ul>
<li><strong>Authors: </strong>Shengewei You, Aditya Joshi, Andrey Kuehlkamp, Jarek Nabrzyski</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          A Multi-Party, Multi-Blockchain Atomic Swap Protocol with Universal Adaptor Secret(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust</a></li>
<li><strong>Abstract: </strong>The increasing complexity of digital asset transactions across multiple blockchains necessitates a robust atomic swap protocol that can securely handle more than two participants. Traditional atomic swap protocols, including those based on adaptor signatures, are vulnerable to malicious dropout attacks, which break atomicity and compromise the security of the transaction. This paper presents a novel multi-party atomic swap protocol that operates almost entirely off-chain, requiring only a single on-chain transaction for finalization. Our protocol leverages Schnorr-like signature verification and a universal adaptor secret to ensure atomicity and scalability across any number of participants and blockchains without the need for smart contracts or trusted third parties. By addressing key challenges such as collusion attacks and malicious dropouts, our protocol significantly enhances the security and efficiency of multi-party atomic swaps. Our contributions include the first scalable, fully off-chain protocol for atomic swaps involving any number of participants, adding zero overhead to native blockchains, and providing a practical and cost-effective solution for decentralized asset exchanges.</li>
</ul>

<h3>Title: Title:
          USDC: A Dataset of $\underline{U}$ser $\underline{S}$tance and $\underline{D}$ogmatism in Long $\underline{C}$onversations</h3>
<ul>
<li><strong>Authors: </strong>Mounika Marreddy, Subba Reddy Oota, Venkata Charan Chinni, Manish Gupta, Lucie Flek</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          USDC: A Dataset of $\underline{U}$ser $\underline{S}$tance and $\underline{D}$ogmatism in Long $\underline{C}$onversations(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Identifying user's opinions and stances in long conversation threads on various topics can be extremely critical for enhanced personalization, market research, political campaigns, customer service, conflict resolution, targeted advertising, and content moderation. Hence, training language models to automate this task is critical. However, to train such models, gathering manual annotations has multiple challenges: 1) It is time-consuming and costly; 2) Conversation threads could be very long, increasing chances of noisy annotations; and 3) Interpreting instances where a user changes their opinion within a conversation is difficult because often such transitions are subtle and not expressed explicitly. Inspired by the recent success of large language models (LLMs) for complex natural language processing (NLP) tasks, we leverage Mistral Large and GPT-4 to automate the human annotation process on the following two tasks while also providing reasoning: i) User Stance classification, which involves labeling a user's stance of a post in a conversation on a five-point scale; ii) User Dogmatism classification, which deals with labeling a user's overall opinion in the conversation on a four-point scale. The majority voting on zero-shot, one-shot, and few-shot annotations from these two LLMs on 764 multi-user Reddit conversations helps us curate the USDC dataset. USDC is then used to finetune and instruction-tune multiple deployable small language models for the 5-class stance and 4-class dogmatism classification tasks. We make the code and dataset publicly available [https://anonymous.4open.science/r/USDC-0F7F].</li>
</ul>

<h3>Title: Title:
          From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig, Ilia Kulikov, Zaid Harchaoui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>One of the most striking findings in modern research on large language models (LLMs) is that scaling up compute during training leads to better results. However, less attention has been given to the benefits of scaling compute during inference. This survey focuses on these inference-time approaches. We explore three areas under a unified mathematical formalism: token-level generation algorithms, meta-generation algorithms, and efficient generation. Token-level generation algorithms, often called decoding algorithms, operate by sampling a single token at a time or constructing a token-level search space and then selecting an output. These methods typically assume access to a language model's logits, next-token distributions, or probability scores. Meta-generation algorithms work on partial or full sequences, incorporating domain knowledge, enabling backtracking, and integrating external information. Efficient generation methods aim to reduce token costs and improve the speed of generation. Our survey unifies perspectives from three research communities: traditional natural language processing, modern LLMs, and machine learning systems.</li>
</ul>

<h3>Title: Title:
          RaTEScore: A Metric for Radiology Report Generation</h3>
<ul>
<li><strong>Authors: </strong>Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          RaTEScore: A Metric for Radiology Report Generation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel, entity-aware metric, termed as Radiological Report (Text) Evaluation (RaTEScore), to assess the quality of medical reports generated by AI models. RaTEScore emphasizes crucial medical entities such as diagnostic outcomes and anatomical details, and is robust against complex medical synonyms and sensitive to negation expressions. Technically, we developed a comprehensive medical NER dataset, RaTE-NER, and trained an NER model specifically for this purpose. This model enables the decomposition of complex radiological reports into constituent medical entities. The metric itself is derived by comparing the similarity of entity embeddings, obtained from a language model, based on their types and relevance to clinical significance. Our evaluations demonstrate that RaTEScore aligns more closely with human preference than existing metrics, validated both on established public benchmarks and our newly proposed RaTE-Eval benchmark.</li>
</ul>

<h3>Title: Title:
          Data Debiasing with Datamodels (D3M): Improving Subgroup Robustness via Data Selection</h3>
<ul>
<li><strong>Authors: </strong>Saachi Jain, Kimia Hamidieh, Kristian Georgiev, Andrew Ilyas, Marzyeh Ghassemi, Aleksander Madry</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          Data Debiasing with Datamodels (D3M): Improving Subgroup Robustness via Data Selection(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine learning models can fail on subgroups that are underrepresented during training. While techniques such as dataset balancing can improve performance on underperforming groups, they require access to training group annotations and can end up removing large portions of the dataset. In this paper, we introduce Data Debiasing with Datamodels (D3M), a debiasing approach which isolates and removes specific training examples that drive the model's failures on minority groups. Our approach enables us to efficiently train debiased classifiers while removing only a small number of examples, and does not require training group annotations or additional hyperparameter tuning.</li>
</ul>

<h3>Title: Title:
          From Perfect to Noisy World Simulation: Customizable Embodied Multi-modal Perturbations for SLAM Robustness Benchmarking</h3>
<ul>
<li><strong>Authors: </strong>Xiaohao Xu, Tianyi Zhang, Sibo Wang, Xiang Li, Yongqi Chen, Ye Li, Bhiksha Raj, Matthew Johnson-Roberson, Xiaonan Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          From Perfect to Noisy World Simulation: Customizable Embodied Multi-modal Perturbations for SLAM Robustness Benchmarking(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Embodied agents require robust navigation systems to operate in unstructured environments, making the robustness of Simultaneous Localization and Mapping (SLAM) models critical to embodied agent autonomy. While real-world datasets are invaluable, simulation-based benchmarks offer a scalable approach for robustness evaluations. However, the creation of a challenging and controllable noisy world with diverse perturbations remains under-explored. To this end, we propose a novel, customizable pipeline for noisy data synthesis, aimed at assessing the resilience of multi-modal SLAM models against various perturbations. The pipeline comprises a comprehensive taxonomy of sensor and motion perturbations for embodied multi-modal (specifically RGB-D) sensing, categorized by their sources and propagation order, allowing for procedural composition. We also provide a toolbox for synthesizing these perturbations, enabling the transformation of clean environments into challenging noisy simulations. Utilizing the pipeline, we instantiate the large-scale Noisy-Replica benchmark, which includes diverse perturbation types, to evaluate the risk tolerance of existing advanced RGB-D SLAM models. Our extensive analysis uncovers the susceptibilities of both neural (NeRF and Gaussian Splatting -based) and non-neural SLAM models to disturbances, despite their demonstrated accuracy in standard benchmarks. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Title:
          GeoMFormer: A General Architecture for Geometric Molecular Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Tianlang Chen, Shengjie Luo, Di He, Shuxin Zheng, Tie-Yan Liu, Liwei Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          GeoMFormer: A General Architecture for Geometric Molecular Representation Learning(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Molecular modeling, a central topic in quantum mechanics, aims to accurately calculate the properties and simulate the behaviors of molecular systems. The molecular model is governed by physical laws, which impose geometric constraints such as invariance and equivariance to coordinate rotation and translation. While numerous deep learning approaches have been developed to learn molecular representations under these constraints, most of them are built upon heuristic and costly modules. We argue that there is a strong need for a general and flexible framework for learning both invariant and equivariant features. In this work, we introduce a novel Transformer-based molecular model called GeoMFormer to achieve this goal. Using the standard Transformer modules, two separate streams are developed to maintain and learn invariant and equivariant representations. Carefully designed cross-attention modules bridge the two streams, allowing information fusion and enhancing geometric modeling in each stream. As a general and flexible architecture, we show that many previous architectures can be viewed as special instantiations of GeoMFormer. Extensive experiments are conducted to demonstrate the power of GeoMFormer. All empirical results show that GeoMFormer achieves strong performance on both invariant and equivariant tasks of different types and scales. Code and models will be made publicly available at this https URL.</li>
</ul>

<h3>Title: Title:
          DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Yuang Peng, Yuxin Cui, Haomiao Tang, Zekun Qi, Runpei Dong, Jing Bai, Chunrui Han, Zheng Ge, Xiangyu Zhang, Shu-Tao Xia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Personalized image generation holds great promise in assisting humans in everyday work and life due to its impressive function in creatively generating personalized content. However, current evaluations either are automated but misalign with humans or require human evaluations that are time-consuming and expensive. In this work, we present DreamBench++, a human-aligned benchmark automated by advanced multimodal GPT models. Specifically, we systematically design the prompts to let GPT be both human-aligned and self-aligned, empowered with task reinforcement. Further, we construct a comprehensive dataset comprising diverse images and prompts. By benchmarking 7 modern generative models, we demonstrate that DreamBench++ results in significantly more human-aligned evaluation, helping boost the community with innovative findings.</li>
</ul>

<h3>Title: Title:
          EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees</h3>
<ul>
<li><strong>Authors: </strong>Yuhui Li, Fangyun Wei, Chao Zhang, Hongyang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inference with modern Large Language Models (LLMs) is expensive and time-consuming, and speculative sampling has proven to be an effective solution. Most speculative sampling methods such as EAGLE use a static draft tree, implicitly assuming that the acceptance rate of draft tokens depends only on their position. Interestingly, we found that the acceptance rate of draft tokens is also context-dependent. In this paper, building upon EAGLE, we propose EAGLE-2, which introduces a new technique of context-aware dynamic draft tree into drafting modeling. This improvement leverages the fact that the draft model of EAGLE is well-calibrated: the confidence scores from the draft model approximate acceptance rates with small errors. We conducted extensive evaluations on three series of LLMs and six tasks, with EAGLE-2 achieving speedup ratios 3.05x-4.26x, which is 20%-40% faster than EAGLE-1. EAGLE-2 also ensures that the distribution of the generated text remains unchanged, making it a lossless acceleration algorithm.</li>
</ul>

<h3>Title: Title:
          FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Haonan Qiu, Zhaoxi Chen, Zhouxia Wang, Yingqing He, Menghan Xia, Ziwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion model has demonstrated remarkable capability in video generation, which further sparks interest in introducing trajectory control into the generation process. While existing works mainly focus on training-based methods (e.g., conditional adapter), we argue that diffusion model itself allows decent control over the generated content without requiring any training. In this study, we introduce a tuning-free framework to achieve trajectory-controllable video generation, by imposing guidance on both noise construction and attention computation. Specifically, 1) we first show several instructive phenomenons and analyze how initial noises influence the motion trajectory of generated content. 2) Subsequently, we propose FreeTraj, a tuning-free approach that enables trajectory control by modifying noise sampling and attention mechanisms. 3) Furthermore, we extend FreeTraj to facilitate longer and larger video generation with controllable trajectories. Equipped with these designs, users have the flexibility to provide trajectories manually or opt for trajectories automatically generated by the LLM trajectory planner. Extensive experiments validate the efficacy of our approach in enhancing the trajectory controllability of video diffusion models.</li>
</ul>

<h3>Title: Title:
          StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal</h3>
<ul>
<li><strong>Authors: </strong>Chongjie Ye, Lingteng Qiu, Xiaodong Gu, Qi Zuo, Yushuang Wu, Zilong Dong, Liefeng Bo, Yuliang Xiu, Xiaoguang Han</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/">https://arxiv.org/abs/</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/">https://arxiv.org/pdf/</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[]] Title:
          StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal(https://arxiv.org/abs/)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>This work addresses the challenge of high-quality surface normal estimation from monocular colored inputs (i.e., images and videos), a field which has recently been revolutionized by repurposing diffusion priors. However, previous attempts still struggle with stochastic inference, conflicting with the deterministic nature of the Image2Normal task, and costly ensembling step, which slows down the estimation process. Our method, StableNormal, mitigates the stochasticity of the diffusion process by reducing inference variance, thus producing "Stable-and-Sharp" normal estimates without any additional ensembling process. StableNormal works robustly under challenging imaging conditions, such as extreme lighting, blurring, and low quality. It is also robust against transparent and reflective surfaces, as well as cluttered scenes with numerous objects. Specifically, StableNormal employs a coarse-to-fine strategy, which starts with a one-step normal estimator (YOSO) to derive an initial normal guess, that is relatively coarse but reliable, then followed by a semantic-guided refinement process (SG-DRN) that refines the normals to recover geometric details. The effectiveness of StableNormal is demonstrated through competitive performance in standard datasets such as DIODE-indoor, iBims, ScannetV2 and NYUv2, and also in various downstream tasks, such as surface reconstruction and normal enhancement. These results evidence that StableNormal retains both the "stability" and "sharpness" for accurate normal estimation. StableNormal represents a baby attempt to repurpose diffusion priors for deterministic estimation. To democratize this, code and models have been publicly available in this http URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
