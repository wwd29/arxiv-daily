<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-02-26</h1>
<h3>Title: Decentralized and Robust Privacy-Preserving Model Using Blockchain-Enabled Federated Deep Learning in Intelligent Enterprises</h3>
<ul>
<li><strong>Authors: </strong>Reza Fotohi, Fereidoon Shams Aliee, Bahar Farahani</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17485">https://arxiv.org/abs/2502.17485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17485">https://arxiv.org/pdf/2502.17485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17485]] Decentralized and Robust Privacy-Preserving Model Using Blockchain-Enabled Federated Deep Learning in Intelligent Enterprises(https://arxiv.org/abs/2502.17485)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>In Federated Deep Learning (FDL), multiple local enterprises are allowed to train a model jointly. Then, they submit their local updates to the central server, and the server aggregates the updates to create a global model. However, trained models usually perform worse than centralized models, especially when the training data distribution is non-independent and identically distributed (nonIID). NonIID data harms the accuracy and performance of the model. Additionally, due to the centrality of federated learning (FL) and the untrustworthiness of enterprises, traditional FL solutions are vulnerable to security and privacy attacks. To tackle this issue, we propose FedAnil, a secure blockchain enabled Federated Deep Learning Model that improves enterprise models decentralization, performance, and tamper proof properties, incorporating two main phases. The first phase addresses the nonIID challenge (label and feature distribution skew). The second phase addresses security and privacy concerns against poisoning and inference attacks through three steps. Extensive experiments were conducted using the Sent140, FashionMNIST, FEMNIST, and CIFAR10 new real world datasets to evaluate FedAnils robustness and performance. The simulation results demonstrate that FedAnil satisfies FDL privacy preserving requirements. In terms of convergence analysis, the model parameter obtained with FedAnil converges to the optimum of the model parameter. In addition, it performs better in terms of accuracy (more than 11, 15, and 24%) and computation overhead (less than 8, 10, and 15%) compared with baseline approaches, namely ShieldFL, RVPFL, and RFA.</li>
</ul>

<h3>Title: A generalized dual potential for inelastic Constitutive Artificial Neural Networks: A JAX implementation at finite strains</h3>
<ul>
<li><strong>Authors: </strong>Hagen Holthusen, Kevin Linka, Ellen Kuhl, Tim Brepols</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17490">https://arxiv.org/abs/2502.17490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17490">https://arxiv.org/pdf/2502.17490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17490]] A generalized dual potential for inelastic Constitutive Artificial Neural Networks: A JAX implementation at finite strains(https://arxiv.org/abs/2502.17490)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a methodology for designing a generalized dual potential, or pseudo potential, for inelastic Constitutive Artificial Neural Networks (iCANNs). This potential, expressed in terms of stress invariants, inherently satisfies thermodynamic consistency for large deformations. In comparison to our previous work, the new potential captures a broader spectrum of material behaviors, including pressure-sensitive inelasticity. To this end, we revisit the underlying thermodynamic framework of iCANNs for finite strain inelasticity and derive conditions for constructing a convex, zero-valued, and non-negative dual potential. To embed these principles in a neural network, we detail the architecture's design, ensuring a priori compliance with thermodynamics. To evaluate the proposed architecture, we study its performance and limitations discovering visco-elastic material behavior, though the method is not limited to visco-elasticity. In this context, we investigate different aspects in the strategy of discovering inelastic materials. Our results indicate that the novel architecture robustly discovers interpretable models and parameters, while autonomously revealing the degree of inelasticity. The iCANN framework, implemented in JAX, is publicly accessible at this https URL.</li>
</ul>

<h3>Title: Pursuing Top Growth with Novel Loss Function</h3>
<ul>
<li><strong>Authors: </strong>Ruoyu Guo, Haochen Qiu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17493">https://arxiv.org/abs/2502.17493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17493">https://arxiv.org/pdf/2502.17493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17493]] Pursuing Top Growth with Novel Loss Function(https://arxiv.org/abs/2502.17493)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Making consistently profitable financial decisions in a continuously evolving and volatile stock market has always been a difficult task. Professionals from different disciplines have developed foundational theories to anticipate price movement and evaluate securities such as the famed Capital Asset Pricing Model (CAPM). In recent years, the role of artificial intelligence (AI) in asset pricing has been growing. Although the black-box nature of deep learning models lacks interpretability, they have continued to solidify their position in the financial industry. We aim to further enhance AI's potential and utility by introducing a return-weighted loss function that will drive top growth while providing the ML models a limited amount of information. Using only publicly accessible stock data (open/close/high/low, trading volume, sector information) and several technical indicators constructed from them, we propose an efficient daily trading system that detects top growth opportunities. Our best models achieve 61.73% annual return on daily rebalancing with an annualized Sharpe Ratio of 1.18 over 1340 testing days from 2019 to 2024, and 37.61% annual return with an annualized Sharpe Ratio of 0.97 over 1360 testing days from 2005 to 2010. The main drivers for success, especially independent of any domain knowledge, are the novel return-weighted loss function, the integration of categorical and continuous data, and the ML model architecture. We also demonstrate the superiority of our novel loss function over traditional loss functions via several performance metrics and statistical evidence.</li>
</ul>

<h3>Title: Improving Value-based Process Verifier via Structural Prior Injection</h3>
<ul>
<li><strong>Authors: </strong>Zetian Sun, Dongfang Li, Baotian Hu, Jun Yu, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17498">https://arxiv.org/abs/2502.17498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17498">https://arxiv.org/pdf/2502.17498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17498]] Improving Value-based Process Verifier via Structural Prior Injection(https://arxiv.org/abs/2502.17498)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the Large Language Model(LLM) reasoning scenario, people often estimate state value via Monte Carlo sampling. Though Monte Carlo estimation is an elegant method with less inductive bias, noise and errors are inevitably introduced due to the limited sampling. To handle the problem, we inject the structural prior into the value representation and transfer the scalar value into the expectation of a pre-defined categorical distribution, representing the noise and errors from a distribution perspective. Specifically, by treating the result of Monte Carlo sampling as a single sample from the prior ground-truth Binomial distribution, we quantify the sampling error as the mismatch between posterior estimated distribution and ground-truth distribution, which is thus optimized via distribution selection optimization. We test the performance of value-based process verifiers on Best-of-N task and Beam search task. Compared with the scalar value representation, we show that reasonable structural prior injection induced by different objective functions or optimization methods can improve the performance of value-based process verifiers for about 1$\sim$2 points at little-to-no cost. We also show that under different structural prior, the verifiers' performances vary greatly despite having the same optimal solution, indicating the importance of reasonable structural prior injection.</li>
</ul>

<h3>Title: Generalized Exponentiated Gradient Algorithms Using the Euler Two-Parameter Logarithm</h3>
<ul>
<li><strong>Authors: </strong>Andrzej Cichocki</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17500">https://arxiv.org/abs/2502.17500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17500">https://arxiv.org/pdf/2502.17500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17500]] Generalized Exponentiated Gradient Algorithms Using the Euler Two-Parameter Logarithm(https://arxiv.org/abs/2502.17500)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper we propose and investigate a new class of Generalized Exponentiated Gradient (GEG) algorithms using Mirror Descent (MD) approaches, and applying as a regularization function the Bregman divergence with two-parameter deformation of logarithm as a link function. This link function (referred to as the Euler logarithm) is associated with a wide class of generalized entropies. In order to derive novel GEG/MD updates, we estimate generalized exponential function, which closely approximates the inverse of the Euler two-parameter logarithm. The characteristic/shape and properties of the Euler logarithm and its inverse -- deformed exponential functions are tuned by two or even more hyperparameters. By learning these hyperparameters, we can adapt to distribution of training data, and we can adjust them to achieve desired properties of gradient descent algorithms. The concept of generalized entropies and associated deformed logarithms provide deeper insight into novel gradient descent updates. In literature, there exist nowadays over fifty mathematically well-defined entropic functionals and associated deformed logarithms, so impossible to investigate all of them in one research paper. Therefore, we focus here on a wide-class of trace-form entropies and associated generalized logarithm. We applied the developed algorithms for Online Portfolio Selection (OPLS) in order to improve its performance and robustness.</li>
</ul>

<h3>Title: CoKV: Optimizing KV Cache Allocation via Cooperative Game</h3>
<ul>
<li><strong>Authors: </strong>Qiheng Sun, Hongwei Zhang, Haocheng Xia, Jiayao Zhang, Jinfei Liu, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17501">https://arxiv.org/abs/2502.17501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17501">https://arxiv.org/pdf/2502.17501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17501]] CoKV: Optimizing KV Cache Allocation via Cooperative Game(https://arxiv.org/abs/2502.17501)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable success on various aspects of human life. However, one of the major challenges in deploying these models is the substantial memory consumption required to store key-value pairs (KV), which imposes significant resource demands. Recent research has focused on KV cache budget allocation, with several approaches proposing head-level budget distribution by evaluating the importance of individual attention heads. These methods, however, assess the importance of heads independently, overlooking their cooperative contributions within the model, which may result in a deviation from their true impact on model performance. In light of this limitation, we propose CoKV, a novel method that models the cooperation between heads in model inference as a cooperative game. By evaluating the contribution of each head within the cooperative game, CoKV can allocate the cache budget more effectively. Extensive experiments show that CoKV achieves state-of-the-art performance on the LongBench benchmark using LLama-3-8B-Instruct and Mistral-7B models.</li>
</ul>

<h3>Title: Doctor-in-the-Loop: An Explainable, Multi-View Deep Learning Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer</h3>
<ul>
<li><strong>Authors: </strong>Alice Natalina Caragliano, Filippo Ruffini, Carlo Greco, Edy Ippolito, Michele Fiore, Claudia Tacconi, Lorenzo Nibid, Giuseppe Perrone, Sara Ramella, Paolo Soda, Valerio Guarrasi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17503">https://arxiv.org/abs/2502.17503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17503">https://arxiv.org/pdf/2502.17503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17503]] Doctor-in-the-Loop: An Explainable, Multi-View Deep Learning Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer(https://arxiv.org/abs/2502.17503)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Non-small cell lung cancer (NSCLC) remains a major global health challenge, with high post-surgical recurrence rates underscoring the need for accurate pathological response predictions to guide personalized treatments. Although artificial intelligence models show promise in this domain, their clinical adoption is limited by the lack of medically grounded guidance during training, often resulting in non-explainable intrinsic predictions. To address this, we propose Doctor-in-the-Loop, a novel framework that integrates expert-driven domain knowledge with explainable artificial intelligence techniques, directing the model toward clinically relevant anatomical regions and improving both interpretability and trustworthiness. Our approach employs a gradual multi-view strategy, progressively refining the model's focus from broad contextual features to finer, lesion-specific details. By incorporating domain insights at every stage, we enhance predictive accuracy while ensuring that the model's decision-making process aligns more closely with clinical reasoning. Evaluated on a dataset of NSCLC patients, Doctor-in-the-Loop delivers promising predictive performance and provides transparent, justifiable outputs, representing a significant step toward clinically explainable artificial intelligence in oncology.</li>
</ul>

<h3>Title: RAG-Enhanced Collaborative LLM Agents for Drug Discovery</h3>
<ul>
<li><strong>Authors: </strong>Namkyeong Lee, Edward De Brouwer, Ehsan Hajiramezanali, Chanyoung Park, Gabriele Scalia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17506">https://arxiv.org/abs/2502.17506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17506">https://arxiv.org/pdf/2502.17506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17506]] RAG-Enhanced Collaborative LLM Agents for Drug Discovery(https://arxiv.org/abs/2502.17506)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have shown great potential to accelerate drug discovery. However, the specialized nature of biochemical data often necessitates costly domain-specific fine-tuning, posing critical challenges. First, it hinders the application of more flexible general-purpose LLMs in cutting-edge drug discovery tasks. More importantly, it impedes the rapid integration of the vast amounts of scientific data continuously generated through experiments and research. To investigate these challenges, we propose CLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored to drug discovery tasks. Through the collaboration of multiple LLM agents, CLADD dynamically retrieves information from biomedical knowledge bases, contextualizes query molecules, and integrates relevant evidence to generate responses -- all without the need for domain-specific fine-tuning. Crucially, we tackle key obstacles in applying RAG workflows to biochemical data, including data heterogeneity, ambiguity, and multi-source integration. We demonstrate the flexibility and effectiveness of this framework across a variety of drug discovery tasks, showing that it outperforms general-purpose and domain-specific LLMs as well as traditional deep learning approaches.</li>
</ul>

<h3>Title: C-3DPO: Constrained Controlled Classification for Direct Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Kavosh Asadi, Julien Han, Xingzi Xu, Dominique Perrault-Joncas, Shoham Sabach, Karim Bouyarmane, Mohammad Ghavamzadeh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17507">https://arxiv.org/abs/2502.17507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17507">https://arxiv.org/pdf/2502.17507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17507]] C-3DPO: Constrained Controlled Classification for Direct Preference Optimization(https://arxiv.org/abs/2502.17507)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Direct preference optimization (DPO)-style algorithms have emerged as a promising approach for solving the alignment problem in AI. We present a novel perspective that formulates these algorithms as implicit classification algorithms. This classification framework enables us to recover many variants of DPO-style algorithms by choosing appropriate classification labels and loss functions. We then leverage this classification framework to demonstrate that the underlying problem solved in these algorithms is under-specified, making them susceptible to probability collapse of the winner-loser responses. We address this by proposing a set of constraints designed to control the movement of probability mass between the winner and loser in the reference and target policies. Our resulting algorithm, which we call Constrained Controlled Classification DPO (\texttt{C-3DPO}), has a meaningful RLHF interpretation. By hedging against probability collapse, \texttt{C-3DPO} provides practical improvements over vanilla \texttt{DPO} when aligning several large language models using standard preference datasets.</li>
</ul>

<h3>Title: Recurrent Knowledge Identification and Fusion for Language Model Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Yujie Feng, Xujia Wang, Zexin Lu, Shenghong Fu, Guangyuan Shi, Yongxin Xu, Yasha Wang, Philip S. Yu, Xu Chu, Xiao-Ming Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17510">https://arxiv.org/abs/2502.17510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17510">https://arxiv.org/pdf/2502.17510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17510]] Recurrent Knowledge Identification and Fusion for Language Model Continual Learning(https://arxiv.org/abs/2502.17510)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Continual learning (CL) is crucial for deploying large language models (LLMs) in dynamic real-world environments without costly retraining. While recent model ensemble and model merging methods guided by parameter importance have gained popularity, they often struggle to balance knowledge transfer and forgetting, mainly due to the reliance on static importance estimates during sequential training. In this paper, we present Recurrent-KIF, a novel CL framework for Recurrent Knowledge Identification and Fusion, which enables dynamic estimation of parameter importance distributions to enhance knowledge transfer. Inspired by human continual learning, Recurrent-KIF employs an inner loop that rapidly adapts to new tasks while identifying important parameters, coupled with an outer loop that globally manages the fusion of new and historical knowledge through redundant knowledge pruning and key knowledge merging. These inner-outer loops iteratively perform multiple rounds of fusion, allowing Recurrent-KIF to leverage intermediate training information and adaptively adjust fusion strategies based on evolving importance distributions. Extensive experiments on two CL benchmarks with various model sizes (from 770M to 13B) demonstrate that Recurrent-KIF effectively mitigates catastrophic forgetting and enhances knowledge transfer.</li>
</ul>

<h3>Title: Int2Int: a framework for mathematics with transformers</h3>
<ul>
<li><strong>Authors: </strong>François Charton</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17513">https://arxiv.org/abs/2502.17513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17513">https://arxiv.org/pdf/2502.17513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17513]] Int2Int: a framework for mathematics with transformers(https://arxiv.org/abs/2502.17513)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper documents Int2Int, an open source code base for using transformers on problems of mathematical research, with a focus on number theory and other problems involving integers. Int2Int is a complete PyTorch implementation of a transformer architecture, together with training and evaluation loops, and classes and functions to represent, generate and decode common mathematical objects. Ancillary code for data preparation, and Jupyter Notebooks for visualizing experimental results are also provided. This document presents the main features of Int2Int, serves as its user manual, and provides guidelines on how to extend it. Int2Int is released under the MIT licence, at this https URL.</li>
</ul>

<h3>Title: SAE-V: Interpreting Multimodal Models for Enhanced Alignment</h3>
<ul>
<li><strong>Authors: </strong>Hantao Lou, Changye Li, Jiaming Ji, Yaodong Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17514">https://arxiv.org/abs/2502.17514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17514">https://arxiv.org/pdf/2502.17514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17514]] SAE-V: Interpreting Multimodal Models for Enhanced Alignment(https://arxiv.org/abs/2502.17514)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>With the integration of image modality, the semantic space of multimodal large language models (MLLMs) is more complex than text-only models, making their interpretability more challenging and their alignment less stable, particularly susceptible to low-quality data, which can lead to inconsistencies between modalities, hallucinations, and biased outputs. As a result, developing interpretability methods for MLLMs is crucial for improving alignment quality and efficiency. In text-only LLMs, Sparse Autoencoders (SAEs) have gained attention for their ability to interpret latent representations. However, extending SAEs to multimodal settings presents new challenges due to modality fusion and the difficulty of isolating cross-modal representations. To address these challenges, we introduce SAE-V, a mechanistic interpretability framework that extends the SAE paradigm to MLLMs. By identifying and analyzing interpretable features along with their corresponding data, SAE-V enables fine-grained interpretation of both model behavior and data quality, facilitating a deeper understanding of cross-modal interactions and alignment dynamics. Moreover, by utilizing cross-modal feature weighting, SAE-V provides an intrinsic data filtering mechanism to enhance model alignment without requiring additional models. Specifically, when applied to the alignment process of MLLMs, SAE-V-based data filtering methods could achieve more than 110% performance with less than 50% data. Our results highlight SAE-V's ability to enhance interpretability and alignment in MLLMs, providing insights into their internal mechanisms.</li>
</ul>

<h3>Title: Towards User-level Private Reinforcement Learning with Human Feedback</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Zhang, Mingxi Lei, Meng Ding, Mengdi Li, Zihang Xiang, Difei Xu, Jinhui Xu, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17515">https://arxiv.org/abs/2502.17515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17515">https://arxiv.org/pdf/2502.17515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17515]] Towards User-level Private Reinforcement Learning with Human Feedback(https://arxiv.org/abs/2502.17515)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning with Human Feedback (RLHF) has emerged as an influential technique, enabling the alignment of large language models (LLMs) with human preferences. Despite the promising potential of RLHF, how to protect user preference privacy has become a crucial issue. Most previous work has focused on using differential privacy (DP) to protect the privacy of individual data. However, they have concentrated primarily on item-level privacy protection and have unsatisfactory performance for user-level privacy, which is more common in RLHF. This study proposes a novel framework, AUP-RLHF, which integrates user-level label DP into RLHF. We first show that the classical random response algorithm, which achieves an acceptable performance in item-level privacy, leads to suboptimal utility when in the user-level settings. We then establish a lower bound for the user-level label DP-RLHF and develop the AUP-RLHF algorithm, which guarantees $(\varepsilon, \delta)$ user-level privacy and achieves an improved estimation error. Experimental results show that AUP-RLHF outperforms existing baseline methods in sentiment generation and summarization tasks, achieving a better privacy-utility trade-off.</li>
</ul>

<h3>Title: A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Zihao Lin, Samyadeep Basu, Mohammad Beigi, Varun Manjunatha, Ryan A. Rossi, Zichao Wang, Yufan Zhou, Sriram Balasubramanian, Arman Zarei, Keivan Rezaei, Ying Shen, Barry Menglong Yao, Zhiyang Xu, Qin Liu, Yuxiang Zhang, Yan Sun, Shilong Liu, Li Shen, Hongxuan Li, Soheil Feizi, Lifu Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17516">https://arxiv.org/abs/2502.17516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17516">https://arxiv.org/pdf/2502.17516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17516]] A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models(https://arxiv.org/abs/2502.17516)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative, large language model</a></li>
<li><strong>Abstract: </strong>The rise of foundation models has transformed machine learning research, prompting efforts to uncover their inner workings and develop more efficient and reliable applications for better control. While significant progress has been made in interpreting Large Language Models (LLMs), multimodal foundation models (MMFMs) - such as contrastive vision-language models, generative vision-language models, and text-to-image models - pose unique interpretability challenges beyond unimodal frameworks. Despite initial studies, a substantial gap remains between the interpretability of LLMs and MMFMs. This survey explores two key aspects: (1) the adaptation of LLM interpretability methods to multimodal models and (2) understanding the mechanistic differences between unimodal language models and crossmodal systems. By systematically reviewing current MMFM analysis techniques, we propose a structured taxonomy of interpretability methods, compare insights across unimodal and multimodal architectures, and highlight critical research gaps.</li>
</ul>

<h3>Title: On Neural Inertial Classification Networks for Pedestrian Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Zeev Yampolsky, Ofir Kruzel, Victoria Khalfin Fekson, Itzik Klein</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17520">https://arxiv.org/abs/2502.17520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17520">https://arxiv.org/pdf/2502.17520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17520]] On Neural Inertial Classification Networks for Pedestrian Activity Recognition(https://arxiv.org/abs/2502.17520)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Inertial sensors are crucial for recognizing pedestrian activity. Recent advances in deep learning have greatly improved inertial sensing performance and robustness. Different domains and platforms use deep-learning techniques to enhance network performance, but there is no common benchmark. The latter is crucial for fair comparison and evaluation within a standardized framework. The aim of this paper is to fill this gap by defining and analyzing ten data-driven techniques for improving neural inertial classification networks. In order to accomplish this, we focused on three aspects of neural networks: network architecture, data augmentation, and data preprocessing. The experiments were conducted across four datasets collected from 78 participants. In total, over 936 minutes of inertial data sampled between 50-200Hz were analyzed. Data augmentation through rotation and multi-head architecture consistently yields the most significant improvements. Additionally, this study outlines benchmarking strategies for enhancing neural inertial classification networks.</li>
</ul>

<h3>Title: Recent Advances in Large Langauge Model Benchmarks against Data Contamination: From Static to Dynamic Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Simin Chen, Yiming Chen, Zexin Li, Yifan Jiang, Zhongwei Wan, Yixin He, Dezhi Ran, Tianle Gu, Haizhou Li, Tao Xie, Baishakhi Ray</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17521">https://arxiv.org/abs/2502.17521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17521">https://arxiv.org/pdf/2502.17521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17521]] Recent Advances in Large Langauge Model Benchmarks against Data Contamination: From Static to Dynamic Evaluation(https://arxiv.org/abs/2502.17521)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Data contamination has received increasing attention in the era of large language models (LLMs) due to their reliance on vast Internet-derived training corpora. To mitigate the risk of potential data contamination, LLM benchmarking has undergone a transformation from static to dynamic benchmarking. In this work, we conduct an in-depth analysis of existing static to dynamic benchmarking methods aimed at reducing data contamination risks. We first examine methods that enhance static benchmarks and identify their inherent limitations. We then highlight a critical gap-the lack of standardized criteria for evaluating dynamic benchmarks. Based on this observation, we propose a series of optimal design principles for dynamic benchmarking and analyze the limitations of existing dynamic benchmarks. This survey provides a concise yet comprehensive overview of recent advancements in data contamination research, offering valuable insights and a clear guide for future research efforts. We maintain a GitHub repository to continuously collect both static and dynamic benchmarking methods for LLMs. The repository can be found at this link.</li>
</ul>

<h3>Title: UNCA: A Neutrosophic-Based Framework for Robust Clustering and Enhanced Data Interpretation</h3>
<ul>
<li><strong>Authors: </strong>D. Dhinakaran, S. Edwin Raja, S. Gopalakrishnan, D. Selvaraj, S. D. Lalitha</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17523">https://arxiv.org/abs/2502.17523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17523">https://arxiv.org/pdf/2502.17523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17523]] UNCA: A Neutrosophic-Based Framework for Robust Clustering and Enhanced Data Interpretation(https://arxiv.org/abs/2502.17523)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Accurately representing the complex linkages and inherent uncertainties included in huge datasets is still a major difficulty in the field of data clustering. We address these issues with our proposed Unified Neutrosophic Clustering Algorithm (UNCA), which combines a multifaceted strategy with Neutrosophic logic to improve clustering performance. UNCA starts with a full-fledged similarity examination via a {\lambda}-cutting matrix that filters meaningful relationships between each two points of data. Then, we initialize centroids for Neutrosophic K-Means clustering, where the membership values are based on their degrees of truth, indeterminacy and falsity. The algorithm then integrates with a dynamic network visualization and MST (Minimum Spanning Tree) so that a visual interpretation of the relationships between the clusters can be clearly represented. UNCA employs SingleValued Neutrosophic Sets (SVNSs) to refine cluster assignments, and after fuzzifying similarity measures, guarantees a precise clustering result. The final step involves solidifying the clustering results through defuzzification methods, offering definitive cluster assignments. According to the performance evaluation results, UNCA outperforms conventional approaches in several metrics: it achieved a Silhouette Score of 0.89 on the Iris Dataset, a Davies-Bouldin Index of 0.59 on the Wine Dataset, an Adjusted Rand Index (ARI) of 0.76 on the Digits Dataset, and a Normalized Mutual Information (NMI) of 0.80 on the Customer Segmentation Dataset. These results demonstrate how UNCA enhances interpretability and resilience in addition to improving clustering accuracy when contrasted with Fuzzy C-Means (FCM), Neutrosophic C-Means (NCM), as well as Kernel Neutrosophic C-Means (KNCM). This makes UNCA a useful tool for complex data processing tasks</li>
</ul>

<h3>Title: FedSV: Byzantine-Robust Federated Learning via Shapley Value</h3>
<ul>
<li><strong>Authors: </strong>Khaoula Otmani (AU, LIA), Rachid Elazouzi (LIA, CMU), Vincent Labatut (AU, LIA)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17526">https://arxiv.org/abs/2502.17526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17526">https://arxiv.org/pdf/2502.17526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17526]] FedSV: Byzantine-Robust Federated Learning via Shapley Value(https://arxiv.org/abs/2502.17526)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>In Federated Learning (FL), several clients jointly learn a machine learning model: each client maintains a local model for its local learning dataset, while a master server maintains a global model by aggregating the local models of the client devices. However, the repetitive communication between server and clients leaves room for attacks aimed at compromising the integrity of the global model, causing errors in its targeted predictions. In response to such threats on FL, various defense measures have been proposed in the literature. In this paper, we present a powerful defense against malicious clients in FL, called FedSV, using the Shapley Value (SV), which has been proposed recently to measure user contribution in FL by computing the marginal increase of average accuracy of the model due to the addition of local data of a user. Our approach makes the identification of malicious clients more robust, since during the learning phase, it estimates the contribution of each client according to the different groups to which the target client belongs. FedSV's effectiveness is demonstrated by extensive experiments on MNIST datasets in a cross-silo context under various attacks.</li>
</ul>

<h3>Title: On the Vulnerability of Concept Erasure in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Lucas Beerens, Alex D. Richardson, Kaicheng Zhang, Dongdong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17537">https://arxiv.org/abs/2502.17537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17537">https://arxiv.org/pdf/2502.17537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17537]] On the Vulnerability of Concept Erasure in Diffusion Models(https://arxiv.org/abs/2502.17537)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>The proliferation of text-to-image diffusion models has raised significant privacy and security concerns, particularly regarding the generation of copyrighted or harmful images. To address these issues, research on machine unlearning has developed various concept erasure methods, which aim to remove the effect of unwanted data through post-hoc training. However, we show these erasure techniques are vulnerable, where images of supposedly erased concepts can still be generated using adversarially crafted prompts. We introduce RECORD, a coordinate-descent-based algorithm that discovers prompts capable of eliciting the generation of erased content. We demonstrate that RECORD significantly beats the attack success rate of current state-of-the-art attack methods. Furthermore, our findings reveal that models subjected to concept erasure are more susceptible to adversarial attacks than previously anticipated, highlighting the urgency for more robust unlearning approaches. We open source all our code at this https URL</li>
</ul>

<h3>Title: PosterSum: A Multimodal Benchmark for Scientific Poster Summarization</h3>
<ul>
<li><strong>Authors: </strong>Rohit Saxena, Pasquale Minervini, Frank Keller</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17540">https://arxiv.org/abs/2502.17540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17540">https://arxiv.org/pdf/2502.17540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17540]] PosterSum: A Multimodal Benchmark for Scientific Poster Summarization(https://arxiv.org/abs/2502.17540)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Generating accurate and concise textual summaries from multimodal documents is challenging, especially when dealing with visually complex content like scientific posters. We introduce PosterSum, a novel benchmark to advance the development of vision-language models that can understand and summarize scientific posters into research paper abstracts. Our dataset contains 16,305 conference posters paired with their corresponding abstracts as summaries. Each poster is provided in image format and presents diverse visual understanding challenges, such as complex layouts, dense text regions, tables, and figures. We benchmark state-of-the-art Multimodal Large Language Models (MLLMs) on PosterSum and demonstrate that they struggle to accurately interpret and summarize scientific posters. We propose Segment & Summarize, a hierarchical method that outperforms current MLLMs on automated metrics, achieving a 3.14% gain in ROUGE-L. This will serve as a starting point for future research on poster summarization.</li>
</ul>

<h3>Title: Towards Conditioning Clinical Text Generation for User Control</h3>
<ul>
<li><strong>Authors: </strong>Osman Alperen Koraş, Rabi Bahnan, Jens Kleesiek, Amin Dada</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17571">https://arxiv.org/abs/2502.17571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17571">https://arxiv.org/pdf/2502.17571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17571]] Towards Conditioning Clinical Text Generation for User Control(https://arxiv.org/abs/2502.17571)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Deploying natural language generation systems in clinical settings remains challenging despite advances in Large Language Models (LLMs), which continue to exhibit hallucinations and factual inconsistencies, necessitating human oversight. This paper explores automated dataset augmentation using LLMs as human proxies to condition LLMs for clinician control without increasing cognitive workload. On the BioNLP ACL'24 Discharge Me! Shared Task, we achieve new state-of-the-art results with simpler methods than prior submissions through more efficient training, yielding a 9\% relative improvement without augmented training and up to 34\% with dataset augmentation. Preliminary human evaluation further supports the effectiveness of our approach, highlighting the potential of augmenting clinical text generation for control to enhance relevance, accuracy, and factual consistency.</li>
</ul>

<h3>Title: End-to-End Chart Summarization via Visual Chain-of-Thought in Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Raymond Choi, Frank Burns, Chase Lawrence</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17589">https://arxiv.org/abs/2502.17589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17589">https://arxiv.org/pdf/2502.17589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17589]] End-to-End Chart Summarization via Visual Chain-of-Thought in Vision-Language Models(https://arxiv.org/abs/2502.17589)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Automated chart summarization is crucial for enhancing data accessibility and enabling efficient information extraction from visual data. While recent advances in visual-language models (VLMs) have demonstrated promise, existing methods often suffer from limitations in matching the generated summary to the chart data and in reasoning about complex chart patterns. This paper introduces End-to-End Visual Chain-of-Thought (V-CoT) for chart summarization, a novel approach optimized for Large Vision-Language Models (LVLMs). Our method directly trains an LVLM to process chart images and generate textual summaries in an end-to-end fashion, eliminating the need for explicit chart parsing modules. We incorporate a visual Chain-of-Thought mechanism through instruction fine-tuning, implicitly guiding the LVLM to perform visual reasoning steps during summary generation. Evaluated on the large-scale Chart-Sum-QA dataset, our V-CoT method significantly outperforms state-of-the-art baselines across a range of automatic metrics, including BLEU, BLEURT, CIDEr, and CS, and demonstrates superior matching degree and reasoning correctness in human evaluations. Ablation studies and detailed analyses further validate the effectiveness and robustness of our proposed approach, establishing a new benchmark for end-to-end chart summarization.</li>
</ul>

<h3>Title: Proactive Privacy Amnesia for Large Language Models: Safeguarding PII with Negligible Impact on Model Utility</h3>
<ul>
<li><strong>Authors: </strong>Martin Kuo, Jingyang Zhang, Jianyi Zhang, Minxue Tang, Louis DiValentin, Aolin Ding, Jingwei Sun, William Chen, Amin Hass, Tianlong Chen, Yiran Chen, Hai Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17591">https://arxiv.org/abs/2502.17591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17591">https://arxiv.org/pdf/2502.17591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17591]] Proactive Privacy Amnesia for Large Language Models: Safeguarding PII with Negligible Impact on Model Utility(https://arxiv.org/abs/2502.17591)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, large language model</a></li>
<li><strong>Abstract: </strong>With the rise of large language models (LLMs), increasing research has recognized their risk of leaking personally identifiable information (PII) under malicious attacks. Although efforts have been made to protect PII in LLMs, existing methods struggle to balance privacy protection with maintaining model utility. In this paper, inspired by studies of amnesia in cognitive science, we propose a novel approach, Proactive Privacy Amnesia (PPA), to safeguard PII in LLMs while preserving their utility. This mechanism works by actively identifying and forgetting key memories most closely associated with PII in sequences, followed by a memory implanting using suitable substitute memories to maintain the LLM's functionality. We conduct evaluations across multiple models to protect common PII, such as phone numbers and physical addresses, against prevalent PII-targeted attacks, demonstrating the superiority of our method compared with other existing defensive techniques. The results show that our PPA method completely eliminates the risk of phone number exposure by 100% and significantly reduces the risk of physical address exposure by 9.8% - 87.6%, all while maintaining comparable model utility performance.</li>
</ul>

<h3>Title: Hallucination Detection in LLMs Using Spectral Features of Attention Maps</h3>
<ul>
<li><strong>Authors: </strong>Jakub Binkowski, Denis Janiak, Albert Sawczyn, Bogdan Gabrys, Tomasz Kajdanowicz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17598">https://arxiv.org/abs/2502.17598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17598">https://arxiv.org/pdf/2502.17598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17598]] Hallucination Detection in LLMs Using Spectral Features of Attention Maps(https://arxiv.org/abs/2502.17598)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable performance across various tasks but remain prone to hallucinations. Detecting hallucinations is essential for safety-critical applications, and recent methods leverage attention map properties to this end, though their effectiveness remains limited. In this work, we investigate the spectral features of attention maps by interpreting them as adjacency matrices of graph structures. We propose the $\text{LapEigvals}$ method, which utilises the top-$k$ eigenvalues of the Laplacian matrix derived from the attention maps as an input to hallucination detection probes. Empirical evaluations demonstrate that our approach achieves state-of-the-art hallucination detection performance among attention-based methods. Extensive ablation studies further highlight the robustness and generalisation of $\text{LapEigvals}$, paving the way for future advancements in the hallucination detection domain.</li>
</ul>

<h3>Title: MEDA: Dynamic KV Cache Allocation for Efficient Multimodal Long-Context Inference</h3>
<ul>
<li><strong>Authors: </strong>Zhongwei Wan, Hui Shen, Xin Wang, Che Liu, Zheda Mai, Mi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17599">https://arxiv.org/abs/2502.17599</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17599">https://arxiv.org/pdf/2502.17599</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17599]] MEDA: Dynamic KV Cache Allocation for Efficient Multimodal Long-Context Inference(https://arxiv.org/abs/2502.17599)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-context Multimodal Large Language Models (MLLMs) that incorporate long text-image and text-video modalities, demand substantial resources as their multimodal Key-Value (KV) caches grow with increasing input lengths, challenging inference efficiency. Existing methods for KV cache compression, in both text-only and multimodal LLMs, have neglected attention density variations across layers, thus often adopting uniform or progressive reduction strategies for layer-wise cache allocation. In this work, we propose MEDA, a dynamic layer-wise KV cache allocation method for efficient multimodal long-context inference. As its core, MEDA utilizes cross-modal attention entropy to determine the KV cache size at each MLLMs layer. Given the dynamically allocated KV cache size at each layer, MEDA also employs a KV pair selection scheme to identify which KV pairs to select and a KV pair merging strategy that merges the selected and non-selected ones to preserve information from the entire context. MEDA achieves up to 72% KV cache memory reduction and 2.82 times faster decoding speed, while maintaining or enhancing performance on various multimodal tasks in long-context settings, including multi-images and long-video scenarios. Our code is released at this https URL.</li>
</ul>

<h3>Title: PICASO: Permutation-Invariant Context Composition with State Space Models</h3>
<ul>
<li><strong>Authors: </strong>Tian Yu Liu, Alessandro Achille, Matthew Trager, Aditya Golatkar, Luca Zancato, Stefano Soatto</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17605">https://arxiv.org/abs/2502.17605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17605">https://arxiv.org/pdf/2502.17605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17605]] PICASO: Permutation-Invariant Context Composition with State Space Models(https://arxiv.org/abs/2502.17605)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Providing Large Language Models with relevant contextual knowledge at inference time has been shown to greatly improve the quality of their generations. This is often achieved by prepending informative passages of text, or 'contexts', retrieved from external knowledge bases to their input. However, processing additional contexts online incurs significant computation costs that scale with their length. State Space Models (SSMs) offer a promising solution by allowing a database of contexts to be mapped onto fixed-dimensional states from which to start the generation. A key challenge arises when attempting to leverage information present across multiple contexts, since there is no straightforward way to condition generation on multiple independent states in existing SSMs. To address this, we leverage a simple mathematical relation derived from SSM dynamics to compose multiple states into one that efficiently approximates the effect of concatenating textual contexts. Since the temporal ordering of contexts can often be uninformative, we enforce permutation-invariance by efficiently averaging states obtained via our composition algorithm across all possible context orderings. We evaluate our resulting method on WikiText and MSMARCO in both zero-shot and fine-tuned settings, and show that we can match the strongest performing baseline while enjoying on average 5.4x speedup.</li>
</ul>

<h3>Title: Synthetic Text Generation for Training Large Language Models via Gradient Matching</h3>
<ul>
<li><strong>Authors: </strong>Dang Nguyen, Zeman Li, Mohammadhossein Bateni, Vahab Mirrokni, Meisam Razaviyayn, Baharan Mirzasoleiman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17607">https://arxiv.org/abs/2502.17607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17607">https://arxiv.org/pdf/2502.17607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17607]] Synthetic Text Generation for Training Large Language Models via Gradient Matching(https://arxiv.org/abs/2502.17607)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Synthetic data has the potential to improve the performance, training efficiency, and privacy of real training examples. Nevertheless, existing approaches for synthetic text generation are mostly heuristics and cannot generate human-readable text without compromising the privacy of real data or provide performance guarantees for training Large Language Models (LLMs). In this work, we propose the first theoretically rigorous approach for generating synthetic human-readable text that guarantees the convergence and performance of LLMs during fine-tuning on a target task. To do so, we leverage Alternating Direction Method of Multipliers (ADMM) that iteratively optimizes the embeddings of synthetic examples to match the gradient of the target training or validation data, and maps them to a sequence of text tokens with low perplexity. In doing so, the generated synthetic text can guarantee convergence of the model to a close neighborhood of the solution obtained by fine-tuning on real data. Experiments on various classification tasks confirm the effectiveness of our proposed approach.</li>
</ul>

<h3>Title: Evaluating the Effect of Retrieval Augmentation on Social Biases</h3>
<ul>
<li><strong>Authors: </strong>Tianhui Zhang, Yi Zhou, Danushka Bollegala</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17611">https://arxiv.org/abs/2502.17611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17611">https://arxiv.org/pdf/2502.17611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17611]] Evaluating the Effect of Retrieval Augmentation on Social Biases(https://arxiv.org/abs/2502.17611)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) has gained popularity as a method for conveniently incorporating novel facts that were not seen during the pre-training stage in Large Language Model (LLM)-based Natural Language Generation (NLG) systems. However, LLMs are known to encode significant levels of unfair social biases. The modulation of these biases by RAG in NLG systems is not well understood. In this paper, we systematically study the relationship between the different components of a RAG system and the social biases presented in the text generated across three languages (i.e. English, Japanese and Chinese) and four social bias types (i.e. gender, race, age and religion). Specifically, using the Bias Question Answering (BBQ) benchmark datasets, we evaluate the social biases in RAG responses from document collections with varying levels of stereotypical biases, employing multiple LLMs used as generators. We find that the biases in document collections are often amplified in the generated responses, even when the generating LLM exhibits a low-level of bias. Our findings raise concerns about the use of RAG as a technique for injecting novel facts into NLG systems and call for careful evaluation of potential social biases in RAG applications before their real-world deployment.</li>
</ul>

<h3>Title: Flexible Counterfactual Explanations with Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Stig Hellemans, Andres Algaba, Sam Verboven, Vincent Ginis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17613">https://arxiv.org/abs/2502.17613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17613">https://arxiv.org/pdf/2502.17613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17613]] Flexible Counterfactual Explanations with Generative Models(https://arxiv.org/abs/2502.17613)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Counterfactual explanations provide actionable insights to achieve desired outcomes by suggesting minimal changes to input features. However, existing methods rely on fixed sets of mutable features, which makes counterfactual explanations inflexible for users with heterogeneous real-world constraints. Here, we introduce Flexible Counterfactual Explanations, a framework incorporating counterfactual templates, which allows users to dynamically specify mutable features at inference time. In our implementation, we use Generative Adversarial Networks (FCEGAN), which align explanations with user-defined constraints without requiring model retraining or additional optimization. Furthermore, FCEGAN is designed for black-box scenarios, leveraging historical prediction datasets to generate explanations without direct access to model internals. Experiments across economic and healthcare datasets demonstrate that FCEGAN significantly improves counterfactual explanations' validity compared to traditional benchmark methods. By integrating user-driven flexibility and black-box compatibility, counterfactual templates support personalized explanations tailored to user constraints.</li>
</ul>

<h3>Title: Scalable Graph Condensation with Evolving Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Shengbo Gong, Mohammad Hashemi, Juntong Ni, Carl Yang, Wei Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17614">https://arxiv.org/abs/2502.17614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17614">https://arxiv.org/pdf/2502.17614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17614]] Scalable Graph Condensation with Evolving Capabilities(https://arxiv.org/abs/2502.17614)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph data has become a pivotal modality due to its unique ability to model relational datasets. However, real-world graph data continues to grow exponentially, resulting in a quadratic increase in the complexity of most graph algorithms as graph sizes expand. Although graph condensation (GC) methods have been proposed to address these scalability issues, existing approaches often treat the training set as static, overlooking the evolving nature of real-world graph data. This limitation leads to inefficiencies when condensing growing training sets. In this paper, we introduce GECC (Graph Evolving Clustering Condensation), a scalable graph condensation method designed to handle large-scale and evolving graph data. GECC employs a traceable and efficient approach by performing class-wise clustering on aggregated features. Furthermore, it can inherits previous condensation results as clustering centroids when the condensed graph expands, thereby attaining an evolving capability. This methodology is supported by robust theoretical foundations and demonstrates superior empirical performance. Comprehensive experiments show that GECC achieves better performance than most state-of-the-art graph condensation methods while delivering an around 1,000x speedup on large datasets.</li>
</ul>

<h3>Title: A Priori Generalizability Estimate for a CNN</h3>
<ul>
<li><strong>Authors: </strong>Cito Balsells, Beatrice Riviere, David Fuentes</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17622">https://arxiv.org/abs/2502.17622</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17622">https://arxiv.org/pdf/2502.17622</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17622]] A Priori Generalizability Estimate for a CNN(https://arxiv.org/abs/2502.17622)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We formulate truncated singular value decompositions of entire convolutional neural networks. We demonstrate the computed left and right singular vectors are useful in identifying which images the convolutional neural network is likely to perform poorly on. To create this diagnostic tool, we define two metrics: the Right Projection Ratio and the Left Projection Ratio. The Right (Left) Projection Ratio evaluates the fidelity of the projection of an image (label) onto the computed right (left) singular vectors. We observe that both ratios are able to identify the presence of class imbalance for an image classification problem. Additionally, the Right Projection Ratio, which only requires unlabeled data, is found to be correlated to the model's performance when applied to image segmentation. This suggests the Right Projection Ratio could be a useful metric to estimate how likely the model is to perform well on a sample.</li>
</ul>

<h3>Title: CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement</h3>
<ul>
<li><strong>Authors: </strong>Lei Chenga, Lihao Guoa, Tianya Zhangb, Tam Bangb, Austin Harrisb, Mustafa Hajijc, Mina Sartipib, Siyang Cao</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17648">https://arxiv.org/abs/2502.17648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17648">https://arxiv.org/pdf/2502.17648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17648]] CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement(https://arxiv.org/abs/2502.17648)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Accurate multi-sensor calibration is essential for deploying robust perception systems in applications such as autonomous driving, robotics, and intelligent transportation. Existing LiDAR-camera calibration methods often rely on manually placed targets, preliminary parameter estimates, or intensive data preprocessing, limiting their scalability and adaptability in real-world settings. In this work, we propose a fully automatic, targetless, and online calibration framework, CalibRefine, which directly processes raw LiDAR point clouds and camera images. Our approach is divided into four stages: (1) a Common Feature Discriminator that trains on automatically detected objects--using relative positions, appearance embeddings, and semantic classes--to generate reliable LiDAR-camera correspondences, (2) a coarse homography-based calibration, (3) an iterative refinement to incrementally improve alignment as additional data frames become available, and (4) an attention-based refinement that addresses non-planar distortions by leveraging a Vision Transformer and cross-attention mechanisms. Through extensive experiments on two urban traffic datasets, we show that CalibRefine delivers high-precision calibration results with minimal human involvement, outperforming state-of-the-art targetless methods and remaining competitive with, or surpassing, manually tuned baselines. Our findings highlight how robust object-level feature matching, together with iterative and self-supervised attention-based adjustments, enables consistent sensor fusion in complex, real-world conditions without requiring ground-truth calibration matrices or elaborate data preprocessing.</li>
</ul>

<h3>Title: Formally-verified Security against Forgery of Remote Attestation using SSProve</h3>
<ul>
<li><strong>Authors: </strong>Sara Zain, Jannik Mähn, Stefan Köpsell, Sebastian Ertel</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17653">https://arxiv.org/abs/2502.17653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17653">https://arxiv.org/pdf/2502.17653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17653]] Formally-verified Security against Forgery of Remote Attestation using SSProve(https://arxiv.org/abs/2502.17653)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Remote attestation (RA) is the foundation for trusted execution environments in the cloud and trusted device driver onboarding in operating systems. However, RA misses a rigorous mechanized definition of its security properties in one of the strongest models, i.e., the semantic model. Such a mechanization requires the concept of State-Separating Proofs (SSP). However, SSP was only recently implemented as a foundational framework in the Rocq Prover. Based on this framework, this paper presents the first mechanized formalization of the fundamental security properties of RA. Our Rocq Prover development first defines digital signatures and formally verifies security against forgery in the strong existential attack model. Based on these results, we define RA and reduce the security of RA to the security of digital signatures. Our development provides evidence that the RA protocol is secure against forgery. Additionally, we extend our reasoning to the primitives of RA and reduce their security to the security of the primitives of the digital signatures. Finally, we found that proving the security of the primitives for digital signatures was not feasible. This observation contrasts textbook formalizations and sparks a discussion on reasoning about the security of libraries in SSP-based frameworks.</li>
</ul>

<h3>Title: THOR: A Non-Speculative Value Dependent Timing Side Channel Attack Exploiting Intel AMX</h3>
<ul>
<li><strong>Authors: </strong>Farshad Dizani, Azam Ghanbari, Joshua Kalyanapu, Darsh Asher, Samira Mirbagher Ajorpaz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17658">https://arxiv.org/abs/2502.17658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17658">https://arxiv.org/pdf/2502.17658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17658]] THOR: A Non-Speculative Value Dependent Timing Side Channel Attack Exploiting Intel AMX(https://arxiv.org/abs/2502.17658)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The rise of on-chip accelerators signifies a major shift in computing, driven by the growing demands of artificial intelligence (AI) and specialized applications. These accelerators have gained popularity due to their ability to substantially boost performance, cut energy usage, lower total cost of ownership (TCO), and promote sustainability. Intel's Advanced Matrix Extensions (AMX) is one such on-chip accelerator, specifically designed for handling tasks involving large matrix multiplications commonly used in machine learning (ML) models, image processing, and other computational-heavy operations. In this paper, we introduce a novel value-dependent timing side-channel vulnerability in Intel AMX. By exploiting this weakness, we demonstrate a software-based, value-dependent timing side-channel attack capable of inferring the sparsity of neural network weights without requiring any knowledge of the confidence score, privileged access or physical proximity. Our attack method can fully recover the sparsity of weights assigned to 64 input elements within 50 minutes, which is 631% faster than the maximum leakage rate achieved in the Hertzbleed attack.</li>
</ul>

<h3>Title: Towards Typologically Aware Rescoring to Mitigate Unfaithfulness in Lower-Resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Tsan Tsai Chan, Xin Tong, Thi Thu Uyen Hoang, Barbare Tepnadze, Wojciech Stempniak</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17664">https://arxiv.org/abs/2502.17664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17664">https://arxiv.org/pdf/2502.17664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17664]] Towards Typologically Aware Rescoring to Mitigate Unfaithfulness in Lower-Resource Languages(https://arxiv.org/abs/2502.17664)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multilingual large language models (LLMs) are known to more frequently generate non-faithful output in resource-constrained languages (Guerreiro et al., 2023 - arXiv:2303.16104), potentially because these typologically diverse languages are underrepresented in their training data. To mitigate unfaithfulness in such settings, we propose using computationally light auxiliary models to rescore the outputs of larger architectures. As proof of the feasibility of such an approach, we show that monolingual 4-layer BERT models pretrained from scratch on less than 700 MB of data without fine-tuning are able to identify faithful summaries with a mean accuracy of 88.33% in three genetically unrelated languages that differ in their morphological complexity - Vietnamese, Polish and Georgian. The same hyperparameter combination moreover generalises well to three other tasks, suggesting applications for rescoring beyond improving faithfulness. In order to inform typologically aware model selection, we also investigate how morphological complexity interacts with regularisation, model depth and training objectives, ultimately demonstrating that morphologically complex languages are more likely to benefit from dropout, while across languages downstream performance is enhanced most by shallow architectures as well as training using the standard BERT objectives.</li>
</ul>

<h3>Title: Towards Human Cognition: Visual Context Guides Syntactic Priming in Fusion-Encoded Models</h3>
<ul>
<li><strong>Authors: </strong>Bushi Xiao, Michael Bennie, Jayetri Bardhan, Daisy Zhe Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17669">https://arxiv.org/abs/2502.17669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17669">https://arxiv.org/pdf/2502.17669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17669]] Towards Human Cognition: Visual Context Guides Syntactic Priming in Fusion-Encoded Models(https://arxiv.org/abs/2502.17669)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduced PRISMATIC, the first multimodal structural priming dataset, and proposed a reference-free evaluation metric that assesses priming effects without predefined target sentences. Using this metric, we constructed and tested models with different multimodal encoding architectures (dual encoder and fusion encoder) to investigate their structural preservation capabilities. Our findings show that models with both encoding methods demonstrate comparable syntactic priming effects. However, only fusion-encoded models exhibit robust positive correlations between priming effects and visual similarity, suggesting a cognitive process more aligned with human psycholinguistic patterns. This work provides new insights into evaluating and understanding how syntactic information is processed in multimodal language models.</li>
</ul>

<h3>Title: Semi-Supervised Weed Detection in Vegetable Fields: In-domain and Cross-domain Experiments</h3>
<ul>
<li><strong>Authors: </strong>Boyang Deng, Yuzhen Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17673">https://arxiv.org/abs/2502.17673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17673">https://arxiv.org/pdf/2502.17673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17673]] Semi-Supervised Weed Detection in Vegetable Fields: In-domain and Cross-domain Experiments(https://arxiv.org/abs/2502.17673)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robust weed detection remains a challenging task in precision weeding, requiring not only potent weed detection models but also large-scale, labeled data. However, the labeled data adequate for model training is practically difficult to come by due to the time-consuming, labor-intensive process that requires specialized expertise to recognize plant species. This study introduces semi-supervised object detection (SSOD) methods for leveraging unlabeled data for enhanced weed detection and proposes a new YOLOv8-based SSOD method, i.e., WeedTeacher. An experimental comparison of four SSOD methods, including three existing frameworks (i.e., DenseTeacher, EfficientTeacher, and SmallTeacher) and WeedTeacher, alongside fully supervised baselines, was conducted for weed detection in both in-domain and cross-domain contexts. A new, diverse weed dataset was created as the testbed, comprising a total of 19,931 field images from two differing domains, including 8,435 labeled (basic-domain) images acquired by handholding devices from 2021 to 2023 and 11,496 unlabeled (new-domain) images acquired by a ground-based mobile platform in 2024. The in-domain experiment with models trained using 10% of the labeled, basic-domain images and tested on the remaining 90% of the data, showed that the YOLOv8-basedWeedTeacher achieved the highest accuracy among all four SSOD methods, with an improvement of 2.6% mAP@50 and 3.1% mAP@50:95 over its supervised baseline (i.e., YOLOv8l). In the cross-domain experiment where the unlabeled new-domain data was incorporated, all four SSOD methods, however, resulted in no or limited improvements over their supervised counterparts. Research is needed to address the difficulty of cross-domain data utilization for robust weed detection.</li>
</ul>

<h3>Title: Robust Federated Learning with Global Sensitivity Estimation for Financial Risk Management</h3>
<ul>
<li><strong>Authors: </strong>Lei Zhao, Lin Cai, Wu-Sheng Lu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17694">https://arxiv.org/abs/2502.17694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17694">https://arxiv.org/pdf/2502.17694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17694]] Robust Federated Learning with Global Sensitivity Estimation for Financial Risk Management(https://arxiv.org/abs/2502.17694)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>In decentralized financial systems, robust and efficient Federated Learning (FL) is promising to handle diverse client environments and ensure resilience to systemic risks. We propose Federated Risk-Aware Learning with Central Sensitivity Estimation (FRAL-CSE), an innovative FL framework designed to enhance scalability, stability, and robustness in collaborative financial decision-making. The framework's core innovation lies in a central acceleration mechanism, guided by a quadratic sensitivity-based approximation of global model dynamics. By leveraging local sensitivity information derived from robust risk measurements, FRAL-CSE performs a curvature-informed global update that efficiently incorporates second-order information without requiring repeated local re-evaluations, thereby enhancing training efficiency and improving optimization stability. Additionally, distortion risk measures are embedded into the training objectives to capture tail risks and ensure robustness against extreme scenarios. Extensive experiments validate the effectiveness of FRAL-CSE in accelerating convergence and improving resilience across heterogeneous datasets compared to state-of-the-art baselines.</li>
</ul>

<h3>Title: The Cyber Immune System: Harnessing Adversarial Forces for Security Resilience</h3>
<ul>
<li><strong>Authors: </strong>Krti Tallam</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17698">https://arxiv.org/abs/2502.17698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17698">https://arxiv.org/pdf/2502.17698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17698]] The Cyber Immune System: Harnessing Adversarial Forces for Security Resilience(https://arxiv.org/abs/2502.17698)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense</a></li>
<li><strong>Abstract: </strong>Both parasites in biological systems and adversarial forces in cybersecurity are often perceived as threats: disruptive elements that must be eliminated. However, these entities play a critical role in revealing systemic weaknesses, driving adaptation, and ultimately strengthening resilience. This paper draws from environmental epidemiology and cybersecurity to reframe parasites and cyber exploiters as essential stress-testers of complex systems, exposing hidden vulnerabilities and pushing defensive innovations forward. By examining how biological and digital systems evolve in response to persistent threats, we highlight the necessity of adversarial engagement in fortifying security frameworks. The recent breach of the DOGE website serves as a timely case study, illustrating how adversarial forces, whether biological or digital, compel systems to reassess and reinforce their defenses.</li>
</ul>

<h3>Title: To Patch or Not to Patch: Motivations, Challenges, and Implications for Cybersecurity</h3>
<ul>
<li><strong>Authors: </strong>Jason R. C. Nurse</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17703">https://arxiv.org/abs/2502.17703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17703">https://arxiv.org/pdf/2502.17703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17703]] To Patch or Not to Patch: Motivations, Challenges, and Implications for Cybersecurity(https://arxiv.org/abs/2502.17703)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>As technology has become more embedded into our society, the security of modern-day systems is paramount. One topic which is constantly under discussion is that of patching, or more specifically, the installation of updates that remediate security vulnerabilities in software or hardware systems. This continued deliberation is motivated by complexities involved with patching; in particular, the various incentives and disincentives for organizations and their cybersecurity teams when deciding whether to patch. In this paper, we take a fresh look at the question of patching and critically explore why organizations and IT/security teams choose to patch or decide against it (either explicitly or due to inaction). We tackle this question by aggregating and synthesizing prominent research and industry literature on the incentives and disincentives for patching, specifically considering the human aspects in the context of these motives. Through this research, this study identifies key motivators such as organizational needs, the IT/security team's relationship with vendors, and legal and regulatory requirements placed on the business and its staff. There are also numerous significant reasons discovered for why the decision is taken not to patch, including limited resources (e.g., person-power), challenges with manual patch management tasks, human error, bad patches, unreliable patch management tools, and the perception that related vulnerabilities would not be exploited. These disincentives, in combination with the motivators above, highlight the difficult balance that organizations and their security teams need to maintain on a daily basis. Finally, we conclude by discussing implications of these findings and important future considerations.</li>
</ul>

<h3>Title: IBURD: Image Blending for Underwater Robotic Detection</h3>
<ul>
<li><strong>Authors: </strong>Jungseok Hong, Sakshi Singh, Junaed Sattar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17706">https://arxiv.org/abs/2502.17706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17706">https://arxiv.org/pdf/2502.17706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17706]] IBURD: Image Blending for Underwater Robotic Detection(https://arxiv.org/abs/2502.17706)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present an image blending pipeline, \textit{IBURD}, that creates realistic synthetic images to assist in the training of deep detectors for use on underwater autonomous vehicles (AUVs) for marine debris detection tasks. Specifically, IBURD generates both images of underwater debris and their pixel-level annotations, using source images of debris objects, their annotations, and target background images of marine environments. With Poisson editing and style transfer techniques, IBURD is even able to robustly blend transparent objects into arbitrary backgrounds and automatically adjust the style of blended images using the blurriness metric of target background images. These generated images of marine debris in actual underwater backgrounds address the data scarcity and data variety problems faced by deep-learned vision algorithms in challenging underwater conditions, and can enable the use of AUVs for environmental cleanup missions. Both quantitative and robotic evaluations of IBURD demonstrate the efficacy of the proposed approach for robotic detection of marine debris.</li>
</ul>

<h3>Title: Contrastive Visual Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Yu Zhou, Bingxuan Li, Mohan Tang, Xiaomeng Jin, Te-Lin Wu, Kuan-Hao Huang, Heng Ji, Kai-Wei Chang, Nanyun Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17709">https://arxiv.org/abs/2502.17709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17709">https://arxiv.org/pdf/2502.17709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17709]] Contrastive Visual Data Augmentation(https://arxiv.org/abs/2502.17709)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large multimodal models (LMMs) often struggle to recognize novel concepts, as they rely on pre-trained knowledge and have limited ability to capture subtle visual details. Domain-specific knowledge gaps in training also make them prone to confusing visually similar, commonly misrepresented, or low-resource concepts. To help LMMs better align nuanced visual features with language, improving their ability to recognize and reason about novel or rare concepts, we propose a Contrastive visual Data Augmentation (CoDA) strategy. CoDA extracts key contrastive textual and visual features of target concepts against the known concepts they are misrecognized as, and then uses multimodal generative models to produce targeted synthetic data. Automatic filtering of extracted features and augmented images is implemented to guarantee their quality, as verified by human annotators. We show the effectiveness and efficiency of CoDA on low-resource concept and diverse scene recognition datasets including INaturalist and SUN. We additionally collect NovelSpecies, a benchmark dataset consisting of newly discovered animal species that are guaranteed to be unseen by LMMs. LLaVA-1.6 1-shot updating results on these three datasets show CoDA significantly improves SOTA visual data augmentation strategies by 12.3% (NovelSpecies), 5.1% (SUN), and 6.0% (iNat) absolute gains in accuracy.</li>
</ul>

<h3>Title: Knowledge Distillation with Training Wheels</h3>
<ul>
<li><strong>Authors: </strong>Guanlin Liu, Anand Ramachandran, Tanmay Gangwani, Yan Fu, Abhinav Sethy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17717">https://arxiv.org/abs/2502.17717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17717">https://arxiv.org/pdf/2502.17717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17717]] Knowledge Distillation with Training Wheels(https://arxiv.org/abs/2502.17717)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Knowledge distillation is used, in generative language modeling, to train a smaller student model using the help of a larger teacher model, resulting in improved capabilities for the student model. In this paper, we formulate a more general framework for knowledge distillation where the student learns from the teacher during training, and also learns to ask for the teacher's help at test-time following rules specifying test-time restrictions. Towards this, we first formulate knowledge distillation as an entropy-regularized value optimization problem. Adopting Path Consistency Learning to solve this, leads to a new knowledge distillation algorithm using on-policy and off-policy demonstrations. We extend this using constrained reinforcement learning to a framework that incorporates the use of the teacher model as a test-time reference, within constraints. In this situation, akin to a human learner, the model needs to learn not only the learning material, but also the relative difficulty of different sections to prioritize for seeking teacher help. We examine the efficacy of our method through experiments in translation and summarization tasks, observing trends in accuracy and teacher use, noting that our approach unlocks operating points not available to the popular Speculative Decoding approach.</li>
</ul>

<h3>Title: Spontaneous Giving and Calculated Greed in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Li, Hirokazu Shirado</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17720">https://arxiv.org/abs/2502.17720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17720">https://arxiv.org/pdf/2502.17720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17720]] Spontaneous Giving and Calculated Greed in Language Models(https://arxiv.org/abs/2502.17720)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models, when trained with reinforcement learning, demonstrate advanced problem-solving capabilities through reasoning techniques like chain of thoughts and reflection. However, it is unclear how these reasoning capabilities extend to social intelligence. In this study, we investigate how reasoning influences model outcomes in social dilemmas. First, we examine the effects of chain-of-thought and reflection techniques in a public goods game. We then extend our analysis to six economic games on cooperation and punishment, comparing off-the-shelf non-reasoning and reasoning models. We find that reasoning models reduce cooperation and norm enforcement, prioritizing individual rationality. Consequently, groups with more reasoning models exhibit less cooperation and lower gains through repeated interactions. These behaviors parallel human tendencies of "spontaneous giving and calculated greed." Our results suggest the need for AI architectures that incorporate social intelligence alongside reasoning capabilities to ensure that AI supports, rather than disrupts, human cooperative intuition.</li>
</ul>

<h3>Title: Aligning Compound AI Systems via System-level DPO</h3>
<ul>
<li><strong>Authors: </strong>Xiangwen Wang, Yibo Jacky Zhang, Zhoujie Ding, Katherine Tsai, Sanmi Koyejo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17721">https://arxiv.org/abs/2502.17721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17721">https://arxiv.org/pdf/2502.17721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17721]] Aligning Compound AI Systems via System-level DPO(https://arxiv.org/abs/2502.17721)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Compound AI systems, comprising multiple interacting components such as LLM agents and external tools, demonstrate state-of-the-art results across diverse tasks. It is hence crucial to align components within the system to produce consistent results that match human expectations. However, conventional alignment methods, such as Direct Preference Optimization (DPO), are not directly applicable to compound AI systems. These challenges include the non-differentiable interactions between components, making end-to-end gradient optimization infeasible. Additionally, system-level preferences cannot be directly translated into component-level preferences, further complicating alignment. We address the issues by formulating compound AI systems as Directed Acyclic Graphs (DAGs), capturing the connections between agents and the data generation processes. We propose a system-level DPO (SysDPO) to jointly align compound systems by adapting the DPO to operate on these DAGs. We study the joint alignment of an LLM and a diffusion model to demonstrate the effectiveness of our approach. Our exploration provides insights into the alignment of compound AI systems and lays a foundation for future advancements.</li>
</ul>

<h3>Title: Can Score-Based Generative Modeling Effectively Handle Medical Image Classification?</h3>
<ul>
<li><strong>Authors: </strong>Sushmita Sarker, Prithul Sarker, George Bebis, Alireza Tavakkoli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17727">https://arxiv.org/abs/2502.17727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17727">https://arxiv.org/pdf/2502.17727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17727]] Can Score-Based Generative Modeling Effectively Handle Medical Image Classification?(https://arxiv.org/abs/2502.17727)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The remarkable success of deep learning in recent years has prompted applications in medical image classification and diagnosis tasks. While classification models have demonstrated robustness in classifying simpler datasets like MNIST or natural images such as ImageNet, this resilience is not consistently observed in complex medical image datasets where data is more scarce and lacks diversity. Moreover, previous findings on natural image datasets have indicated a potential trade-off between data likelihood and classification accuracy. In this study, we explore the use of score-based generative models as classifiers for medical images, specifically mammographic images. Our findings suggest that our proposed generative classifier model not only achieves superior classification results on CBIS-DDSM, INbreast and Vin-Dr Mammo datasets, but also introduces a novel approach to image classification in a broader context. Our code is publicly available at this https URL</li>
</ul>

<h3>Title: LLM Inference Acceleration via Efficient Operation Fusion</h3>
<ul>
<li><strong>Authors: </strong>Mahsa Salmani, Ilya Soloveychik</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17728">https://arxiv.org/abs/2502.17728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17728">https://arxiv.org/pdf/2502.17728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17728]] LLM Inference Acceleration via Efficient Operation Fusion(https://arxiv.org/abs/2502.17728)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of the Transformer-based Large Language Models (LLMs) in recent years has been closely linked to their ever-growing and already enormous sizes. Many LLMs contain hundreds of billions of parameters and require dedicated hardware resources for training and inference. One of the key challenges inherent to the Transformer architecture is the requirement to support numerous non-linear transformations that involves normalization. For instance, each decoder block typically contains at least one Softmax operation and two Layernorms. The computation of the corresponding normalization scaling factors becomes a major bottleneck as it requires spatial collective operations. In other words, when it comes to the computation of denominators for Softmax and Layernorm, all vector elements must be aggregated into a single location, requiring significant communication. These collective operations slow down inference on Transformers by approximately 20%, defeating the whole purpose of distributed in-memory compute. In this work, we propose an extremely efficient technique that can completely hide the overhead caused by such collective operations. Note that each Softmax and Layernorm operation is typically followed by a linear layer. Since non-linear and linear operations are performed on different hardware engines, they can be easily parallelized once the algebra allows such commutation. By leveraging the inherent properties of linear operations, we can defer the normalization of the preceding Softmax and Layernorm until after the linear layer is computed. Now we can compute the collective scaling factors concurrently with the matrix multiplication and completely hide the latency of the former behind the latter. Such parallelization preserves the numerical accuracy while significantly improving the hardware utilization and reducing the overall latency.</li>
</ul>

<h3>Title: Phoeni6: a Systematic Approach for Evaluating the Energy Consumption of Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Antônio Oliveira-Filho, Wellington Silva-de-Souza, Carlos Alberto Valderrama Sakuyama, Samuel Xavier-de-Souza</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17734">https://arxiv.org/abs/2502.17734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17734">https://arxiv.org/pdf/2502.17734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17734]] Phoeni6: a Systematic Approach for Evaluating the Energy Consumption of Neural Networks(https://arxiv.org/abs/2502.17734)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>This paper presents Phoeni6, a systematic approach for assessing the energy consumption of neural networks while upholding the principles of fair comparison and reproducibility. Phoeni6 offers a comprehensive solution for managing energy-related data and configurations, ensuring portability, transparency, and coordination during evaluations. The methodology automates energy evaluations through containerized tools, robust database management, and versatile data models. In the first case study, the energy consumption of AlexNet and MobileNet was compared using raw and resized images. Results showed that MobileNet is up to 6.25% more energy-efficient for raw images and 2.32% for resized datasets, while maintaining competitive accuracy levels. In the second study, the impact of image file formats on energy consumption was evaluated. BMP images reduced energy usage by up to 30% compared to PNG, highlighting the influence of file formats on energy efficiency. These findings emphasize the importance of Phoeni6 in optimizing energy consumption for diverse neural network applications and establishing sustainable artificial intelligence practices.</li>
</ul>

<h3>Title: FinP: Fairness-in-Privacy in Federated Learning by Addressing Disparities in Privacy Risk</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Zhao, Mahmoud Srewa, Salma Elmalaki</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17748">https://arxiv.org/abs/2502.17748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17748">https://arxiv.org/pdf/2502.17748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17748]] FinP: Fairness-in-Privacy in Federated Learning by Addressing Disparities in Privacy Risk(https://arxiv.org/abs/2502.17748)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate, fair</a></li>
<li><strong>Abstract: </strong>Ensuring fairness in machine learning, particularly in human-centric applications, extends beyond algorithmic bias to encompass fairness in privacy, specifically the equitable distribution of privacy risk. This is critical in federated learning (FL), where decentralized data necessitates balanced privacy preservation across clients. We introduce FinP, a framework designed to achieve fairness in privacy by mitigating disproportionate exposure to source inference attacks (SIA). FinP employs a dual approach: (1) server-side adaptive aggregation to address unfairness in client contributions in global model, and (2) client-side regularization to reduce client vulnerability. This comprehensive strategy targets both the symptoms and root causes of privacy unfairness. Evaluated on the Human Activity Recognition (HAR) and CIFAR-10 datasets, FinP demonstrates ~20% improvement in fairness in privacy on HAR with minimal impact on model utility, and effectively mitigates SIA risks on CIFAR-10, showcasing its ability to provide fairness in privacy in FL systems without compromising performance.</li>
</ul>

<h3>Title: Robust and Efficient Deep Hedging via Linearized Objective Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Lei Zhao, Lin Cai</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.RM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17757">https://arxiv.org/abs/2502.17757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17757">https://arxiv.org/pdf/2502.17757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17757]] Robust and Efficient Deep Hedging via Linearized Objective Neural Network(https://arxiv.org/abs/2502.17757)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep hedging represents a cutting-edge approach to risk management for financial derivatives by leveraging the power of deep learning. However, existing methods often face challenges related to computational inefficiency, sensitivity to noisy data, and optimization complexity, limiting their practical applicability in dynamic and volatile markets. To address these limitations, we propose Deep Hedging with Linearized-objective Neural Network (DHLNN), a robust and generalizable framework that enhances the training procedure of deep learning models. By integrating a periodic fixed-gradient optimization method with linearized training dynamics, DHLNN stabilizes the training process, accelerates convergence, and improves robustness to noisy financial data. The framework incorporates trajectory-wide optimization and Black-Scholes Delta anchoring, ensuring alignment with established financial theory while maintaining flexibility to adapt to real-world market conditions. Extensive experiments on synthetic and real market data validate the effectiveness of DHLNN, demonstrating its ability to achieve faster convergence, improved stability, and superior hedging performance across diverse market scenarios.</li>
</ul>

<h3>Title: Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM</h3>
<ul>
<li><strong>Authors: </strong>Yuqing Wang, Xiao Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17763">https://arxiv.org/abs/2502.17763</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17763">https://arxiv.org/pdf/2502.17763</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17763]] Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM(https://arxiv.org/abs/2502.17763)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack, federate, large language model</a></li>
<li><strong>Abstract: </strong>Traditional security protection methods struggle to address sophisticated attack vectors in large-scale distributed systems, particularly when balancing detection accuracy with data privacy concerns. This paper presents a novel distributed security threat detection system that integrates federated learning with multimodal large language models (LLMs). Our system leverages federated learning to ensure data privacy while employing multimodal LLMs to process heterogeneous data sources including network traffic, system logs, images, and sensor data. Experimental evaluation on a 10TB distributed dataset demonstrates that our approach achieves 96.4% detection accuracy, outperforming traditional baseline models by 4.1 percentage points. The system reduces both false positive and false negative rates by 1.8 and 2.4 percentage points respectively. Performance analysis shows that our system maintains efficient processing capabilities in distributed environments, requiring 180 seconds for model training and 3.8 seconds for threat detection across the distributed network. These results demonstrate significant improvements in detection accuracy and computational efficiency while preserving data privacy, suggesting strong potential for real-world deployment in large-scale security systems.</li>
</ul>

<h3>Title: DeepSeek vs. ChatGPT: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks</h3>
<ul>
<li><strong>Authors: </strong>Qile Jiang, Zhiwei Gao, George Em Karniadakis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17764">https://arxiv.org/abs/2502.17764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17764">https://arxiv.org/pdf/2502.17764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17764]] DeepSeek vs. ChatGPT: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks(https://arxiv.org/abs/2502.17764)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have emerged as powerful tools for tackling a wide range of problems, including those in scientific computing, particularly in solving partial differential equations (PDEs). However, different models exhibit distinct strengths and preferences, resulting in varying levels of performance. In this paper, we compare the capabilities of the most advanced LLMs--ChatGPT and DeepSeek--along with their reasoning-optimized versions in addressing computational challenges. Specifically, we evaluate their proficiency in solving traditional numerical problems in scientific computing as well as leveraging scientific machine learning techniques for PDE-based problems. We designed all our experiments so that a non-trivial decision is required, e.g. defining the proper space of input functions for neural operator learning. Our findings reveal that the latest model, ChatGPT o3-mini-high, usually delivers the most accurate results while also responding significantly faster than its reasoning counterpart, DeepSeek R1. This enhanced speed and accuracy make ChatGPT o3-mini-high a more practical and efficient choice for diverse computational tasks at this juncture.</li>
</ul>

<h3>Title: Improving Transformer Based Line Segment Detection with Matched Predicting and Re-ranking</h3>
<ul>
<li><strong>Authors: </strong>Xin Tong, Shi Peng, Baojie Tian, Yufei Guo, Xuhui Huang, Zhe Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17766">https://arxiv.org/abs/2502.17766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17766">https://arxiv.org/pdf/2502.17766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17766]] Improving Transformer Based Line Segment Detection with Matched Predicting and Re-ranking(https://arxiv.org/abs/2502.17766)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Classical Transformer-based line segment detection methods have delivered impressive results. However, we observe that some accurately detected line segments are assigned low confidence scores during prediction, causing them to be ranked lower and potentially suppressed. Additionally, these models often require prolonged training periods to achieve strong performance, largely due to the necessity of bipartite matching. In this paper, we introduce RANK-LETR, a novel Transformer-based line segment detection method. Our approach leverages learnable geometric information to refine the ranking of predicted line segments by enhancing the confidence scores of high-quality predictions in a posterior verification step. We also propose a new line segment proposal method, wherein the feature point nearest to the centroid of the line segment directly predicts the location, significantly improving training efficiency and stability. Moreover, we introduce a line segment ranking loss to stabilize rankings during training, thereby enhancing the generalization capability of the model. Experimental results demonstrate that our method outperforms other Transformer-based and CNN-based approaches in prediction accuracy while requiring fewer training epochs than previous Transformer-based models.</li>
</ul>

<h3>Title: Sample Selection via Contrastive Fragmentation for Noisy Label Regression</h3>
<ul>
<li><strong>Authors: </strong>Chris Dongjoo Kim, Sangwoo Moon, Jihwan Moon, Dongyeon Woo, Gunhee Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17771">https://arxiv.org/abs/2502.17771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17771">https://arxiv.org/pdf/2502.17771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17771]] Sample Selection via Contrastive Fragmentation for Noisy Label Regression(https://arxiv.org/abs/2502.17771)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As with many other problems, real-world regression is plagued by the presence of noisy labels, an inevitable issue that demands our attention. Fortunately, much real-world data often exhibits an intrinsic property of continuously ordered correlations between labels and features, where data points with similar labels are also represented with closely related features. In response, we propose a novel approach named ConFrag, where we collectively model the regression data by transforming them into disjoint yet contrasting fragmentation pairs. This enables the training of more distinctive representations, enhancing the ability to select clean samples. Our ConFrag framework leverages a mixture of neighboring fragments to discern noisy labels through neighborhood agreement among expert feature extractors. We extensively perform experiments on six newly curated benchmark datasets of diverse domains, including age prediction, price prediction, and music production year estimation. We also introduce a metric called Error Residual Ratio (ERR) to better account for varying degrees of label noise. Our approach consistently outperforms fourteen state-of-the-art baselines, being robust against symmetric and random Gaussian label noise.</li>
</ul>

<h3>Title: An Improved Privacy and Utility Analysis of Differentially Private SGD with Bounded Domain and Smooth Losses</h3>
<ul>
<li><strong>Authors: </strong>Hao Liang, Wanrong Zhang, Xinlei He, Kaishun He, Hong Xing</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17772">https://arxiv.org/abs/2502.17772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17772">https://arxiv.org/pdf/2502.17772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17772]] An Improved Privacy and Utility Analysis of Differentially Private SGD with Bounded Domain and Smooth Losses(https://arxiv.org/abs/2502.17772)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Differentially Private Stochastic Gradient Descent (DPSGD) is widely used to protect sensitive data during the training of machine learning models, but its privacy guarantees often come at the cost of model performance, largely due to the inherent challenge of accurately quantifying privacy loss. While recent efforts have strengthened privacy guarantees by focusing solely on the final output and bounded domain cases, they still impose restrictive assumptions, such as convexity and other parameter limitations, and often lack a thorough analysis of utility. In this paper, we provide rigorous privacy and utility characterization for DPSGD for smooth loss functions in both bounded and unbounded domains. We track the privacy loss over multiple iterations by exploiting the noisy smooth-reduction property and establish the utility analysis by leveraging the projection's non-expansiveness and clipped SGD properties. In particular, we show that for DPSGD with a bounded domain, (i) the privacy loss can still converge without the convexity assumption, and (ii) a smaller bounded diameter can improve both privacy and utility simultaneously under certain conditions. Numerical results validate our results.</li>
</ul>

<h3>Title: FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks</h3>
<ul>
<li><strong>Authors: </strong>Tanawan Premsri, Parisa Kordjamshidi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17775">https://arxiv.org/abs/2502.17775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17775">https://arxiv.org/pdf/2502.17775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17775]] FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks(https://arxiv.org/abs/2502.17775)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Spatial reasoning is a fundamental aspect of human intelligence. One key concept in spatial cognition is the Frame of Reference (FoR), which identifies the perspective of spatial expressions. Despite its significance, FoR has received limited attention in AI models that need spatial intelligence. There is a lack of dedicated benchmarks and in-depth evaluation of large language models (LLMs) in this area. To address this issue, we introduce the Frame of Reference Evaluation in Spatial Reasoning Tasks (FoREST) benchmark, designed to assess FoR comprehension in LLMs. We evaluate LLMs on answering questions that require FoR comprehension and layout generation in text-to-image models using FoREST. Our results reveal a notable performance gap across different FoR classes in various LLMs, affecting their ability to generate accurate layouts for text-to-image generation. This highlights critical shortcomings in FoR comprehension. To improve FoR understanding, we propose Spatial-Guided prompting, which improves LLMs ability to extract essential spatial concepts. Our proposed method improves overall performance across spatial reasoning tasks.</li>
</ul>

<h3>Title: Adaptive Nesterov Accelerated Distributional Deep Hedging for Efficient Volatility Risk Management</h3>
<ul>
<li><strong>Authors: </strong>Lei Zhao, Lin Cai, Wu-Sheng Lu</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17777">https://arxiv.org/abs/2502.17777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17777">https://arxiv.org/pdf/2502.17777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17777]] Adaptive Nesterov Accelerated Distributional Deep Hedging for Efficient Volatility Risk Management(https://arxiv.org/abs/2502.17777)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>In the field of financial derivatives trading, managing volatility risk is crucial for protecting investment portfolios from market changes. Traditional Vega hedging strategies, which often rely on basic and rule-based models, are hard to adapt well to rapidly changing market conditions. We introduce a new framework for dynamic Vega hedging, the Adaptive Nesterov Accelerated Distributional Deep Hedging (ANADDH), which combines distributional reinforcement learning with a tailored design based on adaptive Nesterov acceleration. This approach improves the learning process in complex financial environments by modeling the hedging efficiency distribution, providing a more accurate and responsive hedging strategy. The design of adaptive Nesterov acceleration refines gradient momentum adjustments, significantly enhancing the stability and speed of convergence of the model. Through empirical analysis and comparisons, our method demonstrates substantial performance gains over existing hedging techniques. Our results confirm that this innovative combination of distributional reinforcement learning with the proposed optimization techniques improves financial risk management and highlights the practical benefits of implementing advanced neural network architectures in the finance sector.</li>
</ul>

<h3>Title: Exploring the Potential of Large Language Models for Estimating the Reading Comprehension Question Difficulty</h3>
<ul>
<li><strong>Authors: </strong>Yoshee Jain, John Hollander, Amber He, Sunny Tang, Liang Zhang, John Sabatini</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17785">https://arxiv.org/abs/2502.17785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17785">https://arxiv.org/pdf/2502.17785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17785]] Exploring the Potential of Large Language Models for Estimating the Reading Comprehension Question Difficulty(https://arxiv.org/abs/2502.17785)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reading comprehension is a key for individual success, yet the assessment of question difficulty remains challenging due to the extensive human annotation and large-scale testing required by traditional methods such as linguistic analysis and Item Response Theory (IRT). While these robust approaches provide valuable insights, their scalability is limited. There is potential for Large Language Models (LLMs) to automate question difficulty estimation; however, this area remains underexplored. Our study investigates the effectiveness of LLMs, specifically OpenAI's GPT-4o and o1, in estimating the difficulty of reading comprehension questions using the Study Aid and Reading Assessment (SARA) dataset. We evaluated both the accuracy of the models in answering comprehension questions and their ability to classify difficulty levels as defined by IRT. The results indicate that, while the models yield difficulty estimates that align meaningfully with derived IRT parameters, there are notable differences in their sensitivity to extreme item characteristics. These findings suggest that LLMs can serve as the scalable method for automated difficulty assessment, particularly in dynamic interactions between learners and Adaptive Instructional Systems (AIS), bridging the gap between traditional psychometric techniques and modern AIS for reading comprehension and paving the way for more adaptive and personalized educational assessments.</li>
</ul>

<h3>Title: AIR: Complex Instruction Generation via Automatic Iterative Refinement</h3>
<ul>
<li><strong>Authors: </strong>Wei Liu, Yancheng He, Hui Huang, Chengwei Hu, Jiaheng Liu, Shilong Li, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17787">https://arxiv.org/abs/2502.17787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17787">https://arxiv.org/pdf/2502.17787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17787]] AIR: Complex Instruction Generation via Automatic Iterative Refinement(https://arxiv.org/abs/2502.17787)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the development of large language models, their ability to follow simple instructions has significantly improved. However, adhering to complex instructions remains a major challenge. Current approaches to generating complex instructions are often irrelevant to the current instruction requirements or suffer from limited scalability and diversity. Moreover, methods such as back-translation, while effective for simple instruction generation, fail to leverage the rich contents and structures in large web corpora. In this paper, we propose a novel automatic iterative refinement framework to generate complex instructions with constraints, which not only better reflects the requirements of real scenarios but also significantly enhances LLMs' ability to follow complex instructions. The AIR framework consists of two stages: (1)Generate an initial instruction from a document; (2)Iteratively refine instructions with LLM-as-judge guidance by comparing the model's output with the document to incorporate valuable constraints. Finally, we construct the AIR-10K dataset with 10K complex instructions and demonstrate that instructions generated with our approach significantly improve the model's ability to follow complex instructions, outperforming existing methods for instruction generation.</li>
</ul>

<h3>Title: LAM: Large Avatar Model for One-shot Animatable Gaussian Head</h3>
<ul>
<li><strong>Authors: </strong>Yisheng He, Xiaodong Gu, Xiaodan Ye, Chao Xu, Zhengyi Zhao, Yuan Dong, Weihao Yuan, Zilong Dong, Liefeng Bo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17796">https://arxiv.org/abs/2502.17796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17796">https://arxiv.org/pdf/2502.17796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17796]] LAM: Large Avatar Model for One-shot Animatable Gaussian Head(https://arxiv.org/abs/2502.17796)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present LAM, an innovative Large Avatar Model for animatable Gaussian head reconstruction from a single image. Unlike previous methods that require extensive training on captured video sequences or rely on auxiliary neural networks for animation and rendering during inference, our approach generates Gaussian heads that are immediately animatable and renderable. Specifically, LAM creates an animatable Gaussian head in a single forward pass, enabling reenactment and rendering without additional networks or post-processing steps. This capability allows for seamless integration into existing rendering pipelines, ensuring real-time animation and rendering across a wide range of platforms, including mobile phones. The centerpiece of our framework is the canonical Gaussian attributes generator, which utilizes FLAME canonical points as queries. These points interact with multi-scale image features through a Transformer to accurately predict Gaussian attributes in the canonical space. The reconstructed canonical Gaussian avatar can then be animated utilizing standard linear blend skinning (LBS) with corrective blendshapes as the FLAME model did and rendered in real-time on various platforms. Our experimental results demonstrate that LAM outperforms state-of-the-art methods on existing benchmarks.</li>
</ul>

<h3>Title: Your Language Model May Think Too Rigidly: Achieving Reasoning Consistency with Symmetry-Enhanced Training</h3>
<ul>
<li><strong>Authors: </strong>Yihang Yao, Zhepeng Cen, Miao Li, William Han, Yuyou Zhang, Emerson Liu, Zuxin Liu, Chuang Gan, Ding Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17800">https://arxiv.org/abs/2502.17800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17800">https://arxiv.org/pdf/2502.17800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17800]] Your Language Model May Think Too Rigidly: Achieving Reasoning Consistency with Symmetry-Enhanced Training(https://arxiv.org/abs/2502.17800)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated strong reasoning capabilities across various tasks. However, even minor variations in query phrasing, despite preserving the underlying semantic meaning, can significantly affect their performance. To address this, we focus on enhancing LLMs' awareness of symmetry in query variations and propose syMmetry-ENhanceD (MEND) Data Augmentation, a data-centric approach that improves the model's ability to extract useful information from context. Unlike existing methods that emphasize reasoning chain augmentation, our approach improves model robustness at the knowledge extraction stage through query augmentations, enabling more data-efficient training and stronger generalization to Out-of-Distribution (OOD) settings. Extensive experiments on both logical and arithmetic reasoning tasks show that MEND enhances reasoning performance across diverse query variations, providing new insight into improving LLM robustness through structured dataset curation.</li>
</ul>

<h3>Title: Research on Enhancing Cloud Computing Network Security using Artificial Intelligence Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Yuqing Wang, Xiao Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17801">https://arxiv.org/abs/2502.17801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17801">https://arxiv.org/pdf/2502.17801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17801]] Research on Enhancing Cloud Computing Network Security using Artificial Intelligence Algorithms(https://arxiv.org/abs/2502.17801)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack</a></li>
<li><strong>Abstract: </strong>Cloud computing environments are increasingly vulnerable to security threats such as distributed denial-of-service (DDoS) attacks and SQL injection. Traditional security mechanisms, based on rule matching and feature recognition, struggle to adapt to evolving attack strategies. This paper proposes an adaptive security protection framework leveraging deep learning to construct a multi-layered defense architecture. The proposed system is evaluated in a real-world business environment, achieving a detection accuracy of 97.3%, an average response time of 18 ms, and an availability rate of 99.999%. Experimental results demonstrate that the proposed method significantly enhances detection accuracy, response efficiency, and resource utilization, offering a novel and effective approach to cloud computing security.</li>
</ul>

<h3>Title: URO-Bench: A Comprehensive Benchmark for End-to-End Spoken Dialogue Models</h3>
<ul>
<li><strong>Authors: </strong>Ruiqi Yan, Xiquan Li, Wenxi Chen, Zhikang Niu, Chen Yang, Ziyang Ma, Kai Yu, Xie Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17810">https://arxiv.org/abs/2502.17810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17810">https://arxiv.org/pdf/2502.17810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17810]] URO-Bench: A Comprehensive Benchmark for End-to-End Spoken Dialogue Models(https://arxiv.org/abs/2502.17810)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, with advances in large language models (LLMs), end-to-end spoken dialogue models (SDMs) have made significant strides. Compared to text-based LLMs, the evaluation of SDMs needs to take speech-related aspects into account, such as paralinguistic information and speech quality. However, there is still a lack of comprehensive evaluations for SDMs in speech-to-speech (S2S) scenarios. To address this gap, we propose URO-Bench, an extensive benchmark for SDMs. Notably, URO-Bench is the first S2S benchmark that covers evaluations about multilingualism, multi-round dialogues, and paralinguistics. Our benchmark is divided into two difficulty levels: basic track and pro track, consisting of 16 and 20 datasets respectively, evaluating the model's abilities in Understanding, Reasoning, and Oral conversation. Evaluations on our proposed benchmark reveal that current open-source SDMs perform rather well in daily QA tasks, but lag behind their backbone LLMs in terms of instruction-following ability and also suffer from catastrophic forgetting. Their performance in advanced evaluations of paralinguistic information and audio understanding remains subpar, highlighting the need for further research in this direction. We hope that URO-Bench can effectively facilitate the development of spoken dialogue models by providing a multifaceted evaluation of existing models and helping to track progress in this area.</li>
</ul>

<h3>Title: Can Multimodal LLMs Perform Time Series Anomaly Detection?</h3>
<ul>
<li><strong>Authors: </strong>Xiongxiao Xu, Haoran Wang, Yueqing Liang, Philip S. Yu, Yue Zhao, Kai Shu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17812">https://arxiv.org/abs/2502.17812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17812">https://arxiv.org/pdf/2502.17812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17812]] Can Multimodal LLMs Perform Time Series Anomaly Detection?(https://arxiv.org/abs/2502.17812)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have been increasingly used in time series analysis. However, the potential of multimodal LLMs (MLLMs), particularly vision-language models, for time series remains largely under-explored. One natural way for humans to detect time series anomalies is through visualization and textual description. Motivated by this, we raise a critical and practical research question: Can multimodal LLMs perform time series anomaly detection? To answer this, we propose VisualTimeAnomaly benchmark to evaluate MLLMs in time series anomaly detection (TSAD). Our approach transforms time series numerical data into the image format and feed these images into various MLLMs, including proprietary models (GPT-4o and Gemini-1.5) and open-source models (LLaVA-NeXT and Qwen2-VL), each with one larger and one smaller variant. In total, VisualTimeAnomaly contains 12.4k time series images spanning 3 scenarios and 3 anomaly granularities with 9 anomaly types across 8 MLLMs. Starting with the univariate case (point- and range-wise anomalies), we extend our evaluation to more practical scenarios, including multivariate and irregular time series scenarios, and variate-wise anomalies. Our study reveals several key insights: 1) MLLMs detect range- and variate-wise anomalies more effectively than point-wise anomalies. 2) MLLMs are highly robust to irregular time series, even with 25% of the data missing. 3) Open-source MLLMs perform comparably to proprietary models in TSAD. While open-source MLLMs excel on univariate time series, proprietary MLLMs demonstrate superior effectiveness on multivariate time series. To the best of our knowledge, this is the first work to comprehensively investigate MLLMs for TSAD, particularly for multivariate and irregular time series scenarios. We release our dataset and code at this https URL to support future research.</li>
</ul>

<h3>Title: Easy-Poly: A Easy Polyhedral Framework For 3D Multi-Object Tracking</h3>
<ul>
<li><strong>Authors: </strong>Peng Zhang, Xin Li, Xin Lin, Liang He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17822">https://arxiv.org/abs/2502.17822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17822">https://arxiv.org/pdf/2502.17822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17822]] Easy-Poly: A Easy Polyhedral Framework For 3D Multi-Object Tracking(https://arxiv.org/abs/2502.17822)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in 3D multi-object tracking (3D MOT) have predominantly relied on tracking-by-detection pipelines. However, these approaches often neglect potential enhancements in 3D detection processes, leading to high false positives (FP), missed detections (FN), and identity switches (IDS), particularly in challenging scenarios such as crowded scenes, small-object configurations, and adverse weather conditions. Furthermore, limitations in data preprocessing, association mechanisms, motion modeling, and life-cycle management hinder overall tracking robustness. To address these issues, we present Easy-Poly, a real-time, filter-based 3D MOT framework for multiple object categories. Our contributions include: (1) An Augmented Proposal Generator utilizing multi-modal data augmentation and refined SpConv operations, significantly improving mAP and NDS on nuScenes; (2) A Dynamic Track-Oriented (DTO) data association algorithm that effectively manages uncertainties and occlusions through optimal assignment and multiple hypothesis handling; (3) A Dynamic Motion Modeling (DMM) incorporating a confidence-weighted Kalman filter and adaptive noise covariances, enhancing MOTA and AMOTA in challenging conditions; and (4) An extended life-cycle management system with adjustive thresholds to reduce ID switches and false terminations. Experimental results show that Easy-Poly outperforms state-of-the-art methods such as Poly-MOT and Fast-Poly, achieving notable gains in mAP (e.g., from 63.30% to 64.96% with LargeKernel3D) and AMOTA (e.g., from 73.1% to 74.5%), while also running in real-time. These findings highlight Easy-Poly's adaptability and robustness in diverse scenarios, making it a compelling choice for autonomous driving and related 3D MOT applications. The source code of this paper will be published upon acceptance.</li>
</ul>

<h3>Title: A General Framework to Enhance Fine-tuning-based LLM Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Jie Ren, Zhenwei Dai, Xianfeng Tang, Hui Liu, Jingying Zeng, Zhen Li, Rahul Goutam, Suhang Wang, Yue Xing, Qi He, Hui Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17823">https://arxiv.org/abs/2502.17823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17823">https://arxiv.org/pdf/2502.17823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17823]] A General Framework to Enhance Fine-tuning-based LLM Unlearning(https://arxiv.org/abs/2502.17823)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Unlearning has been proposed to remove copyrighted and privacy-sensitive data from Large Language Models (LLMs). Existing approaches primarily rely on fine-tuning-based methods, which can be categorized into gradient ascent-based (GA-based) and suppression-based methods. However, they often degrade model utility (the ability to respond to normal prompts). In this work, we aim to develop a general framework that enhances the utility of fine-tuning-based unlearning methods. To achieve this goal, we first investigate the common property between GA-based and suppression-based methods. We unveil that GA-based methods unlearn by distinguishing the target data (i.e., the data to be removed) and suppressing related generations, which is essentially the same strategy employed by suppression-based methods. Inspired by this finding, we introduce Gated Representation UNlearning (GRUN) which has two components: a soft gate function for distinguishing target data and a suppression module using Representation Fine-tuning (ReFT) to adjust representations rather than model parameters. Experiments show that GRUN significantly improves the unlearning and utility. Meanwhile, it is general for fine-tuning-based methods, efficient and promising for sequential unlearning.</li>
</ul>

<h3>Title: Weakly Supervised Pixel-Level Annotation with Visual Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Basma Nasir, Tehseen Zia, Muhammad Nawaz, Catarina Moreira</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17824">https://arxiv.org/abs/2502.17824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17824">https://arxiv.org/pdf/2502.17824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17824]] Weakly Supervised Pixel-Level Annotation with Visual Interpretability(https://arxiv.org/abs/2502.17824)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image annotation is essential for diagnosing diseases, yet manual annotation is time-consuming, costly, and prone to variability among experts. To address these challenges, we propose an automated explainable annotation system that integrates ensemble learning, visual explainability, and uncertainty quantification. Our approach combines three pre-trained deep learning models - ResNet50, EfficientNet, and DenseNet - enhanced with XGrad-CAM for visual explanations and Monte Carlo Dropout for uncertainty quantification. This ensemble mimics the consensus of multiple radiologists by intersecting saliency maps from models that agree on the diagnosis while uncertain predictions are flagged for human review. We evaluated our system using the TBX11K medical imaging dataset and a Fire segmentation dataset, demonstrating its robustness across different domains. Experimental results show that our method outperforms baseline models, achieving 93.04% accuracy on TBX11K and 96.4% accuracy on the Fire dataset. Moreover, our model produces precise pixel-level annotations despite being trained with only image-level labels, achieving Intersection over Union IoU scores of 36.07% and 64.7%, respectively. By enhancing the accuracy and interpretability of image annotations, our approach offers a reliable and transparent solution for medical diagnostics and other image analysis tasks.</li>
</ul>

<h3>Title: MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks</h3>
<ul>
<li><strong>Authors: </strong>Hyeonjeong Ha, Qiusi Zhan, Jeonghwan Kim, Dimitrios Bralios, Saikrishna Sanniboina, Nanyun Peng, Kai-wei Chang, Daniel Kang, Heng Ji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17832">https://arxiv.org/abs/2502.17832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17832">https://arxiv.org/pdf/2502.17832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17832]] MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks(https://arxiv.org/abs/2502.17832)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) equipped with Retrieval Augmented Generation (RAG) leverage both their rich parametric knowledge and the dynamic, external knowledge to excel in tasks such as Question Answering. While RAG enhances MLLMs by grounding responses in query-relevant external knowledge, this reliance poses a critical yet underexplored safety risk: knowledge poisoning attacks, where misinformation or irrelevant knowledge is intentionally injected into external knowledge bases to manipulate model outputs to be incorrect and even harmful. To expose such vulnerabilities in multimodal RAG, we propose MM-PoisonRAG, a novel knowledge poisoning attack framework with two attack strategies: Localized Poisoning Attack (LPA), which injects query-specific misinformation in both text and images for targeted manipulation, and Globalized Poisoning Attack (GPA) to provide false guidance during MLLM generation to elicit nonsensical responses across all queries. We evaluate our attacks across multiple tasks, models, and access settings, demonstrating that LPA successfully manipulates the MLLM to generate attacker-controlled answers, with a success rate of up to 56% on MultiModalQA. Moreover, GPA completely disrupts model generation to 0% accuracy with just a single irrelevant knowledge injection. Our results highlight the urgent need for robust defenses against knowledge poisoning to safeguard multimodal RAG frameworks.</li>
</ul>

<h3>Title: Task-Driven Semantic Quantization and Imitation Learning for Goal-Oriented Communications</h3>
<ul>
<li><strong>Authors: </strong>Yu-Chieh Chao, Yubei Chen, Weiwei Wang, Achintha Wijesinghe, Suchinthaka Wanninayaka, Songyang Zhang, Zhi Ding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17842">https://arxiv.org/abs/2502.17842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17842">https://arxiv.org/pdf/2502.17842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17842]] Task-Driven Semantic Quantization and Imitation Learning for Goal-Oriented Communications(https://arxiv.org/abs/2502.17842)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Semantic communication marks a new paradigm shift from bit-wise data transmission to semantic information delivery for the purpose of bandwidth reduction. To more effectively carry out specialized downstream tasks at the receiver end, it is crucial to define the most critical semantic message in the data based on the task or goal-oriented features. In this work, we propose a novel goal-oriented communication (GO-COM) framework, namely Goal-Oriented Semantic Variational Autoencoder (GOS-VAE), by focusing on the extraction of the semantics vital to the downstream tasks. Specifically, we adopt a Vector Quantized Variational Autoencoder (VQ-VAE) to compress media data at the transmitter side. Instead of targeting the pixel-wise image data reconstruction, we measure the quality-of-service at the receiver end based on a pre-defined task-incentivized model. Moreover, to capture the relevant semantic features in the data reconstruction, imitation learning is adopted to measure the data regeneration quality in terms of goal-oriented semantics. Our experimental results demonstrate the power of imitation learning in characterizing goal-oriented semantics and bandwidth efficiency of our proposed GOS-VAE.</li>
</ul>

<h3>Title: Automatic Vehicle Detection using DETR: A Transformer-Based Approach for Navigating Treacherous Roads</h3>
<ul>
<li><strong>Authors: </strong>Istiaq Ahmed Fahad, Abdullah Ibne Hanif Arean, Nazmus Sakib Ahmed, Mahmudul Hasan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17843">https://arxiv.org/abs/2502.17843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17843">https://arxiv.org/pdf/2502.17843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17843]] Automatic Vehicle Detection using DETR: A Transformer-Based Approach for Navigating Treacherous Roads(https://arxiv.org/abs/2502.17843)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Automatic Vehicle Detection (AVD) in diverse driving environments presents unique challenges due to varying lighting conditions, road types, and vehicle types. Traditional methods, such as YOLO and Faster R-CNN, often struggle to cope with these complexities. As computer vision evolves, combining Convolutional Neural Networks (CNNs) with Transformer-based approaches offers promising opportunities for improving detection accuracy and efficiency. This study is the first to experiment with Detection Transformer (DETR) for automatic vehicle detection in complex and varied settings. We employ a Collaborative Hybrid Assignments Training scheme, Co-DETR, to enhance feature learning and attention mechanisms in DETR. By leveraging versatile label assignment strategies and introducing multiple parallel auxiliary heads, we provide more effective supervision during training and extract positive coordinates to boost training efficiency. Through extensive experiments on DETR variants and YOLO models, conducted using the BadODD dataset, we demonstrate the advantages of our approach. Our method achieves superior results, and improved accuracy in diverse conditions, making it practical for real-world deployment. This work significantly advances autonomous navigation technology and opens new research avenues in object detection for autonomous vehicles. By integrating the strengths of CNNs and Transformers, we highlight the potential of DETR for robust and efficient vehicle detection in challenging driving environments.</li>
</ul>

<h3>Title: LR${}^{2}$Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems</h3>
<ul>
<li><strong>Authors: </strong>Jianghao Chen, Zhenlin Wei, Zhenjiang Ren, Ziyong Li, Jiajun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17848">https://arxiv.org/abs/2502.17848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17848">https://arxiv.org/pdf/2502.17848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17848]] LR${}^{2}$Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems(https://arxiv.org/abs/2502.17848)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in o1-like models has significantly enhanced the reasoning abilities of Large Language Models (LLMs), empowering them to tackle increasingly complex tasks through reflection capabilities, such as making assumptions, backtracking, and self-refinement. However, effectively evaluating such reflection capabilities remains challenging due to the lack of appropriate benchmarks. To bridge this gap, we introduce LR${}^{2}$Bench, a novel benchmark designed to evaluate the Long-chain Reflective Reasoning capabilities of LLMs. LR${}^{2}$Bench comprises 850 samples across six Constraint Satisfaction Problems (CSPs) where reflective reasoning is crucial for deriving solutions that meet all given constraints. Each type of task focuses on distinct constraint patterns, such as knowledge-based, logical, and spatial constraints, providing a comprehensive evaluation of diverse problem-solving scenarios. We conduct extensive evaluation on both conventional models and o1-like models. Our experimental results reveal that even the most advanced reasoning-specific models, such as DeepSeek-R1 and OpenAI o1-preview, struggle with tasks in LR${}^{2}$Bench, achieving an average Exact Match score of only 20.0% and 23.6%, respectively. These findings underscore the significant room for improvement in the reflective reasoning capabilities of current LLMs. The leaderboard of our benchmark is available at this https URL</li>
</ul>

<h3>Title: A Novel Retinial Image Contrast Enhancement -- Fuzzy-Based Method</h3>
<ul>
<li><strong>Authors: </strong>Adnan Shaout, Jiho Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17850">https://arxiv.org/abs/2502.17850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17850">https://arxiv.org/pdf/2502.17850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17850]] A Novel Retinial Image Contrast Enhancement -- Fuzzy-Based Method(https://arxiv.org/abs/2502.17850)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>The vascular structure in retinal images plays a crucial role in ophthalmic diagnostics, and its accuracies are directly influenced by the quality of the retinal image. Contrast enhancement is one of the crucial steps in any segmentation algorithm - the more so since the retinal images are related to medical diagnosis. Contrast enhancement is a vital step that not only intensifies the darkness of the blood vessels but also prevents minor capillaries from being disregarded during the process. This paper proposes a novel model that utilizes the linear blending of Fuzzy Contrast Enhancement (FCE) and Contrast Limited Adaptive Histogram Equalization (CLAHE) to enhance the retinal image for retinal vascular structure segmentation. The scheme is tested using the Digital Retinal Images for Vessel Extraction (DRIVE) dataset. The assertion was then evaluated through performance comparison among other methodologies which are Gray-scaling, Histogram Equalization (HE), FCE, and CLAHE. It was evident in this paper that the combination of FCE and CLAHE methods showed major improvement. Both FCE and CLAHE methods dominating with 88% as better enhancement methods proved that preprocessing through fuzzy logic is effective.</li>
</ul>

<h3>Title: Sketch-1-to-3: One Single Sketch to 3D Detailed Face Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Liting Wen, Zimo Yang, Xianlin Zhang, Chi Ding, Yue Zhang, Mingdao Wang, Xueming Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17852">https://arxiv.org/abs/2502.17852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17852">https://arxiv.org/pdf/2502.17852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17852]] Sketch-1-to-3: One Single Sketch to 3D Detailed Face Reconstruction(https://arxiv.org/abs/2502.17852)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>3D face reconstruction from a single sketch is a critical yet underexplored task with significant practical applications. The primary challenges stem from the substantial modality gap between 2D sketches and 3D facial structures, including: (1) accurately extracting facial keypoints from 2D sketches; (2) preserving diverse facial expressions and fine-grained texture details; and (3) training a high-performing model with limited data. In this paper, we propose Sketch-1-to-3, a novel framework for realistic 3D face reconstruction from a single sketch, to address these challenges. Specifically, we first introduce the Geometric Contour and Texture Detail (GCTD) module, which enhances the extraction of geometric contours and texture details from facial sketches. Additionally, we design a deep learning architecture with a domain adaptation module and a tailored loss function to align sketches with the 3D facial space, enabling high-fidelity expression and texture reconstruction. To facilitate evaluation and further research, we construct SketchFaces, a real hand-drawn facial sketch dataset, and Syn-SketchFaces, a synthetic facial sketch dataset. Extensive experiments demonstrate that Sketch-1-to-3 achieves state-of-the-art performance in sketch-based 3D face reconstruction.</li>
</ul>

<h3>Title: UniGS: Unified Language-Image-3D Pretraining with Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Haoyuan Li, Yanpeng Zhou, Tao Tang, Jifei Song, Yihan Zeng, Michael Kampffmeyer, Hang Xu, Xiaodan Liang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17860">https://arxiv.org/abs/2502.17860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17860">https://arxiv.org/pdf/2502.17860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17860]] UniGS: Unified Language-Image-3D Pretraining with Gaussian Splatting(https://arxiv.org/abs/2502.17860)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Recent advancements in multi-modal 3D pre-training methods have shown promising efficacy in learning joint representations of text, images, and point clouds. However, adopting point clouds as 3D representation fails to fully capture the intricacies of the 3D world and exhibits a noticeable gap between the discrete points and the dense 2D pixels of images. To tackle this issue, we propose UniGS, integrating 3D Gaussian Splatting (3DGS) into multi-modal pre-training to enhance the 3D representation. We first rely on the 3DGS representation to model the 3D world as a collection of 3D Gaussians with color and opacity, incorporating all the information of the 3D scene while establishing a strong connection with 2D images. Then, to achieve Language-Image-3D pertaining, UniGS starts with a pre-trained vision-language model to establish a shared visual and textual space through extensive real-world image-text pairs. Subsequently, UniGS employs a 3D encoder to align the optimized 3DGS with the Language-Image representations to learn unified multi-modal representations. To facilitate the extraction of global explicit 3D features by the 3D encoder and achieve better cross-modal alignment, we additionally introduce a novel Gaussian-Aware Guidance module that guides the learning of fine-grained representations of the 3D domain. Through extensive experiments across the Objaverse, ABO, MVImgNet and SUN RGBD datasets with zero-shot classification, text-driven retrieval and open-world understanding tasks, we demonstrate the effectiveness of UniGS in learning a more general and stronger aligned multi-modal representation. Specifically, UniGS achieves leading results across different 3D tasks with remarkable improvements over previous SOTA, Uni3D, including on zero-shot classification (+9.36%), text-driven retrieval (+4.3%) and open-world understanding (+7.92%).</li>
</ul>

<h3>Title: HRR: Hierarchical Retrospection Refinement for Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Peipei Yuan, Zijing Xie, Shuo Ye, Hong Chen, Yulong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17862">https://arxiv.org/abs/2502.17862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17862">https://arxiv.org/pdf/2502.17862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17862]] HRR: Hierarchical Retrospection Refinement for Generated Image Detection(https://arxiv.org/abs/2502.17862)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative artificial intelligence holds significant potential for abuse, and generative image detection has become a key focus of research. However, existing methods primarily focused on detecting a specific generative model and emphasizing the localization of synthetic regions, while neglecting the interference caused by image size and style on model learning. Our goal is to reach a fundamental conclusion: Is the image real or generated? To this end, we propose a diffusion model-based generative image detection framework termed Hierarchical Retrospection Refinement~(HRR). It designs a multi-scale style retrospection module that encourages the model to generate detailed and realistic multi-scale representations, while alleviating the learning biases introduced by dataset styles and generative models. Additionally, based on the principle of correntropy sparse additive machine, a feature refinement module is designed to reduce the impact of redundant features on learning and capture the intrinsic structure and patterns of the data, thereby improving the model's generalization ability. Extensive experiments demonstrate the HRR framework consistently delivers significant performance improvements, outperforming state-of-the-art methods in generated image detection task.</li>
</ul>

<h3>Title: Mitigating Attrition: Data-Driven Approach Using Machine Learning and Data Engineering</h3>
<ul>
<li><strong>Authors: </strong>Naveen Edapurath Vijayan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17865">https://arxiv.org/abs/2502.17865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17865">https://arxiv.org/pdf/2502.17865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17865]] Mitigating Attrition: Data-Driven Approach Using Machine Learning and Data Engineering(https://arxiv.org/abs/2502.17865)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a novel data-driven approach to mitigating employee attrition using machine learning and data engineering techniques. The proposed framework integrates data from various human resources systems and leverages advanced feature engineering to capture a comprehensive set of factors influencing attrition. The study outlines a robust modeling approach that addresses challenges such as imbalanced datasets, categorical data handling, and model interpretation. The methodology includes careful consideration of training and testing strategies, baseline model establishment, and the development of calibrated predictive models. The research emphasizes the importance of model interpretation using techniques like SHAP values to provide actionable insights for organizations. Key design choices in algorithm selection, hyperparameter tuning, and probability calibration are discussed. This approach enables organizations to proactively identify attrition risks and develop targeted retention strategies, ultimately redu</li>
</ul>

<h3>Title: EEGM2: An Efficient Mamba-2-Based Self-Supervised Framework for Long-Sequence EEG Modeling</h3>
<ul>
<li><strong>Authors: </strong>Jiazhen Hong, Geoffrey Mackellar, Soheila Ghane</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17873">https://arxiv.org/abs/2502.17873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17873">https://arxiv.org/pdf/2502.17873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17873]] EEGM2: An Efficient Mamba-2-Based Self-Supervised Framework for Long-Sequence EEG Modeling(https://arxiv.org/abs/2502.17873)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning has achieved significant progress in the development of electroencephalogram (EEG) foundation models, with Transformer-based architectures excelling at capturing long-range dependencies. However, their quadratic computational complexity presents challenges in memory efficiency, training, and inference speed, limiting their scalability and generalizability as a foundation model. In this paper, we propose EEGM2, a self-supervised framework based on structured state space duality (SSD) that overcomes these limitations. EEGM2 introduces three key innovations: (1) a reconstruction-based framework that captures both local and global EEG features through Mamba-2 structured state space models, (2) a spatiotemporal-aware loss function that enhances robustness to noise and preserves spectral information, and (3) a multi-branch receptive field input embedding strategy that improves cross-subject generalization and stability for EEG sequences of varying lengths. In comparison to traditional pretraining methods, on raw EEG or latent representation spaces, EEGM2 shows superior performance on long-sequence tasks, where conventional models struggle. Our experimental results on six EEG datasets validate that EEGM2 not only achieves state-of-the-art cross-domain accuracy but also reduces computational overhead, making it a more efficient solution for deployment on resource-constrained BCI devices.</li>
</ul>

<h3>Title: Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Runzhong Wang, Rui-Xi Wang, Mrunali Manjrekar, Connor W. Coley</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17874">https://arxiv.org/abs/2502.17874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17874">https://arxiv.org/pdf/2502.17874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17874]] Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning(https://arxiv.org/abs/2502.17874)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Molecular machine learning has gained popularity with the advancements of geometric deep learning. In parallel, retrieval-augmented generation has become a principled approach commonly used with language models. However, the optimal integration of retrieval augmentation into molecular machine learning remains unclear. Graph neural networks stand to benefit from clever matching to understand the structural alignment of retrieved molecules to a query molecule. Neural graph matching offers a compelling solution by explicitly modeling node and edge affinities between two structural graphs while employing a noise-robust, end-to-end neural network to learn affinity metrics. We apply this approach to mass spectrum simulation and introduce MARASON, a novel model that incorporates neural graph matching to enhance a fragmentation-based neural network. Experimental results highlight the effectiveness of our design, with MARASON achieving 28% top-1 accuracy, a substantial improvement over the non-retrieval state-of-the-art accuracy of 19%. Moreover, MARASON outperforms both naive retrieval-augmented generation methods and traditional graph matching approaches.</li>
</ul>

<h3>Title: VVRec: Reconstruction Attacks on DL-based Volumetric Video Upstreaming via Latent Diffusion Model with Gamma Distribution</h3>
<ul>
<li><strong>Authors: </strong>Rui Lu, Bihai Zhang, Dan Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17880">https://arxiv.org/abs/2502.17880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17880">https://arxiv.org/pdf/2502.17880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17880]] VVRec: Reconstruction Attacks on DL-based Volumetric Video Upstreaming via Latent Diffusion Model with Gamma Distribution(https://arxiv.org/abs/2502.17880)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, diffusion</a></li>
<li><strong>Abstract: </strong>With the popularity of 3D volumetric video applications, such as Autonomous Driving, Virtual Reality, and Mixed Reality, current developers have turned to deep learning for compressing volumetric video frames, i.e., point clouds for video upstreaming. The latest deep learning-based solutions offer higher efficiency, lower distortion, and better hardware support compared to traditional ones like MPEG and JPEG. However, privacy threats arise, especially reconstruction attacks targeting to recover the original input point cloud from the intermediate results. In this paper, we design VVRec, to the best of our knowledge, which is the first targeting DL-based Volumetric Video Reconstruction attack scheme. VVRec demonstrates the ability to reconstruct high-quality point clouds from intercepted transmission intermediate results using four well-trained neural network modules we design. Leveraging the latest latent diffusion models with Gamma distribution and a refinement algorithm, VVRec excels in reconstruction quality, color recovery, and surpasses existing defenses. We evaluate VVRec using three volumetric video datasets. The results demonstrate that VVRec achieves 64.70dB reconstruction accuracy, with an impressive 46.39% reduction of distortion over baselines.</li>
</ul>

<h3>Title: From underwater to aerial: a novel multi-scale knowledge distillation approach for coral reef monitoring</h3>
<ul>
<li><strong>Authors: </strong>Matteo Contini, Victor Illien, Julien Barde, Sylvain Poulain, Serge Bernard, Alexis Joly, Sylvain Bonhommeau</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17883">https://arxiv.org/abs/2502.17883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17883">https://arxiv.org/pdf/2502.17883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17883]] From underwater to aerial: a novel multi-scale knowledge distillation approach for coral reef monitoring(https://arxiv.org/abs/2502.17883)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Drone-based remote sensing combined with AI-driven methodologies has shown great potential for accurate mapping and monitoring of coral reef ecosystems. This study presents a novel multi-scale approach to coral reef monitoring, integrating fine-scale underwater imagery with medium-scale aerial imagery. Underwater images are captured using an Autonomous Surface Vehicle (ASV), while aerial images are acquired with an aerial drone. A transformer-based deep-learning model is trained on underwater images to detect the presence of 31 classes covering various coral morphotypes, associated fauna, and habitats. These predictions serve as annotations for training a second model applied to aerial images. The transfer of information across scales is achieved through a weighted footprint method that accounts for partial overlaps between underwater image footprints and aerial image tiles. The results show that the multi-scale methodology successfully extends fine-scale classification to larger reef areas, achieving a high degree of accuracy in predicting coral morphotypes and associated habitats. The method showed a strong alignment between underwater-derived annotations and ground truth data, reflected by an AUC (Area Under the Curve) score of 0.9251. This shows that the integration of underwater and aerial imagery, supported by deep-learning models, can facilitate scalable and accurate reef assessments. This study demonstrates the potential of combining multi-scale imaging and AI to facilitate the monitoring and conservation of coral reefs. Our approach leverages the strengths of underwater and aerial imagery, ensuring the precision of fine-scale analysis while extending it to cover a broader reef area.</li>
</ul>

<h3>Title: Arrhythmia Classification from 12-Lead ECG Signals Using Convolutional and Transformer-Based Deep Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Andrei Apostol, Maria Nutu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17887">https://arxiv.org/abs/2502.17887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17887">https://arxiv.org/pdf/2502.17887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17887]] Arrhythmia Classification from 12-Lead ECG Signals Using Convolutional and Transformer-Based Deep Learning Models(https://arxiv.org/abs/2502.17887)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In Romania, cardiovascular problems are the leading cause of death, accounting for nearly one-third of annual fatalities. The severity of this situation calls for innovative diagnosis method for cardiovascular diseases. This article aims to explore efficient, light-weight and rapid methods for arrhythmia diagnosis, in resource-constrained healthcare settings. Due to the lack of Romanian public medical data, we trained our systems using international public datasets, having in mind that the ECG signals are the same regardless the patients' nationality. Within this purpose, we combined multiple datasets, usually used in the field of arrhythmias classification: PTB-XL electrocardiography dataset , PTB Diagnostic ECG Database, China 12-Lead ECG Challenge Database, Georgia 12-Lead ECG Challenge Database, and St. Petersburg INCART 12-lead Arrhythmia Database. For the input data, we employed ECG signal processing methods, specifically a variant of the Pan-Tompkins algorithm, useful in arrhythmia classification because it provides a robust and efficient method for detecting QRS complexes in ECG signals. Additionally, we used machine learning techniques, widely used for the task of classification, including convolutional neural networks (1D CNNs, 2D CNNs, ResNet) and Vision Transformers (ViTs). The systems were evaluated in terms of accuracy and F1 score. We annalysed our dataset from two perspectives. First, we fed the systems with the ECG signals and the GRU-based 1D CNN model achieved the highest accuracy of 93.4% among all the tested architectures. Secondly, we transformed ECG signals into images and the CNN2D model achieved an accuracy of 92.16%.</li>
</ul>

<h3>Title: RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts</h3>
<ul>
<li><strong>Authors: </strong>Mingyan Wu, Zhenghao Liu, Yukun Yan, Xinze Li, Shi Yu, Zheni Zeng, Yu Gu, Ge Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17888">https://arxiv.org/abs/2502.17888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17888">https://arxiv.org/pdf/2502.17888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17888]] RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts(https://arxiv.org/abs/2502.17888)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) enhances the performance of Large Language Models (LLMs) by incorporating external knowledge. However, LLMs still encounter challenges in effectively utilizing the knowledge from retrieved documents, often being misled by irrelevant or noisy information. To address this issue, we introduce RankCoT, a knowledge refinement method that incorporates reranking signals in generating CoT-based summarization for knowledge refinement based on given query and all retrieval documents. During training, RankCoT prompts the LLM to generate Chain-of-Thought (CoT) candidates based on the query and individual documents. It then fine-tunes the LLM to directly reproduce the best CoT from these candidate outputs based on all retrieved documents, which requires LLM to filter out irrelevant documents during generating CoT-style summarization. Additionally, RankCoT incorporates a self-reflection mechanism that further refines the CoT outputs, resulting in higher-quality training data. Our experiments demonstrate the effectiveness of RankCoT, showing its superior performance over other knowledge refinement models. Further analysis reveals that RankCoT can provide shorter but effective refinement results, enabling the generator to produce more accurate answers. All code and data are available at this https URL.</li>
</ul>

<h3>Title: Can Large Language Models Identify Implicit Suicidal Ideation? An Empirical Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Tong Li, Shu Yang, Junchao Wu, Jiyao Wei, Lijie Hu, Mengdi Li, Derek F. Wong, Joshua R. Oltmanns, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17899">https://arxiv.org/abs/2502.17899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17899">https://arxiv.org/pdf/2502.17899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17899]] Can Large Language Models Identify Implicit Suicidal Ideation? An Empirical Evaluation(https://arxiv.org/abs/2502.17899)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a comprehensive evaluation framework for assessing Large Language Models' (LLMs) capabilities in suicide prevention, focusing on two critical aspects: the Identification of Implicit Suicidal ideation (IIS) and the Provision of Appropriate Supportive responses (PAS). We introduce \ourdata, a novel dataset of 1,308 test cases built upon psychological frameworks including D/S-IAT and Negative Automatic Thinking, alongside real-world scenarios. Through extensive experiments with 8 widely used LLMs under different contextual settings, we find that current models struggle significantly with detecting implicit suicidal ideation and providing appropriate support, highlighting crucial limitations in applying LLMs to mental health contexts. Our findings underscore the need for more sophisticated approaches in developing and evaluating LLMs for sensitive psychological applications.</li>
</ul>

<h3>Title: Knowledge-enhanced Multimodal ECG Representation Learning with Arbitrary-Lead Inputs</h3>
<ul>
<li><strong>Authors: </strong>Che Liu, Cheng Ouyang, Zhongwei Wan, Haozhe Wang, Wenjia Bai, Rossella Arcucci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17900">https://arxiv.org/abs/2502.17900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17900">https://arxiv.org/pdf/2502.17900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17900]] Knowledge-enhanced Multimodal ECG Representation Learning with Arbitrary-Lead Inputs(https://arxiv.org/abs/2502.17900)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in multimodal ECG representation learning center on aligning ECG signals with paired free-text reports. However, suboptimal alignment persists due to the complexity of medical language and the reliance on a full 12-lead setup, which is often unavailable in under-resourced settings. To tackle these issues, we propose **K-MERL**, a knowledge-enhanced multimodal ECG representation learning framework. **K-MERL** leverages large language models to extract structured knowledge from free-text reports and employs a lead-aware ECG encoder with dynamic lead masking to accommodate arbitrary lead inputs. Evaluations on six external ECG datasets show that **K-MERL** achieves state-of-the-art performance in zero-shot classification and linear probing tasks, while delivering an average **16%** AUC improvement over existing methods in partial-lead zero-shot classification.</li>
</ul>

<h3>Title: BD Currency Detection: A CNN Based Approach with Mobile App Integration</h3>
<ul>
<li><strong>Authors: </strong>Syed Jubayer Jaman, Md. Zahurul Haque, Md Robiul Islam, Usama Abdun Noor</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17907">https://arxiv.org/abs/2502.17907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17907">https://arxiv.org/pdf/2502.17907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17907]] BD Currency Detection: A CNN Based Approach with Mobile App Integration(https://arxiv.org/abs/2502.17907)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Currency recognition plays a vital role in banking, commerce, and assistive technology for visually impaired individuals. Traditional methods, such as manual verification and optical scanning, often suffer from limitations in accuracy and efficiency. This study introduces an advanced currency recognition system utilizing Convolutional Neural Networks (CNNs) to accurately classify Bangladeshi banknotes. A dataset comprising 50,334 images was collected, preprocessed, and used to train a CNN model optimized for high performance classification. The trained model achieved an accuracy of 98.5%, surpassing conventional image based currency recognition approaches. To enable real time and offline functionality, the model was converted into TensorFlow Lite format and integrated into an Android mobile application. The results highlight the effectiveness of deep learning in currency recognition, providing a fast, secure, and accessible solution that enhances financial transactions and assistive technologies.</li>
</ul>

<h3>Title: FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hongzhan Lin, Yang Deng, Yuxuan Gu, Wenxuan Zhang, Jing Ma, See-Kiong Ng, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17924">https://arxiv.org/abs/2502.17924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17924">https://arxiv.org/pdf/2502.17924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17924]] FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models(https://arxiv.org/abs/2502.17924)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs' fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs' factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis.</li>
</ul>

<h3>Title: Advantage-Guided Distillation for Preference Alignment in Small Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shiping Gao, Fanqi Wan, Jiajian Guo, Xiaojun Quan, Qifan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17927">https://arxiv.org/abs/2502.17927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17927">https://arxiv.org/pdf/2502.17927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17927]] Advantage-Guided Distillation for Preference Alignment in Small Language Models(https://arxiv.org/abs/2502.17927)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Alignment techniques enable Large Language Models (LLMs) to generate outputs that align with human preferences and play a crucial role in their effectiveness. However, their impact often diminishes when applied to Small Language Models (SLMs), likely due to the limited capacity of these models. Instead of directly applying existing alignment techniques to SLMs, we propose to utilize a well-aligned teacher LLM to guide the alignment process for these models, thereby facilitating the transfer of the teacher's knowledge of human preferences to the student model. To achieve this, we first explore a straightforward approach, Dual-Constrained Knowledge Distillation (DCKD), that employs knowledge distillation with two KL-divergence constraints from the aligned teacher to the unaligned student. To further enhance the student's ability to distinguish between preferred and dispreferred responses, we then propose Advantage-Guided Distillation for Preference Alignment (ADPA), which leverages an advantage function from the aligned teacher to deliver more nuanced, distribution-level reward signals for the student's alignment. Our experimental results show that these two approaches appreciably improve the alignment of SLMs and narrow the performance gap with larger counterparts. Among them, ADPA demonstrates superior performance and achieves even greater effectiveness when integrated with DCKD. Our code is available at this https URL.</li>
</ul>

<h3>Title: Integrating Boosted learning with Differential Evolution (DE) Optimizer: A Prediction of Groundwater Quality Risk Assessment in Odisha</h3>
<ul>
<li><strong>Authors: </strong>Sonalika Subudhi, Alok Kumar Pati, Sephali Bose, Subhasmita Sahoo, Avipsa Pattanaik, Biswa Mohan Acharya</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17929">https://arxiv.org/abs/2502.17929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17929">https://arxiv.org/pdf/2502.17929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17929]] Integrating Boosted learning with Differential Evolution (DE) Optimizer: A Prediction of Groundwater Quality Risk Assessment in Odisha(https://arxiv.org/abs/2502.17929)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Groundwater is eventually undermined by human exercises, such as fast industrialization, urbanization, over-extraction, and contamination from agrarian and urban sources. From among the different contaminants, the presence of heavy metals like cadmium (Cd), chromium (Cr), arsenic (As), and lead (Pb) proves to have serious dangers when present in huge concentrations in groundwater. Long-term usage of these poisonous components may lead to neurological disorders, kidney failure and different sorts of cancer. To address these issues, this study developed a machine learning-based predictive model to evaluate the Groundwater Quality Index (GWQI) and identify the main contaminants which are affecting the water quality. It has been achieved with the help of a hybrid machine learning model i.e. LCBoost Fusion . The model has undergone several processes like data preprocessing, hyperparameter tuning using Differential Evolution (DE) optimization, and evaluation through cross-validation. The LCBoost Fusion model outperforms individual models (CatBoost and LightGBM), by achieving low RMSE (0.6829), MSE (0.5102), MAE (0.3147) and a high R$^2$ score of 0.9809. Feature importance analysis highlights Potassium (K), Fluoride (F) and Total Hardness (TH) as the most influential indicators of groundwater contamination. This research successfully demonstrates the application of machine learning in assessing groundwater quality risks in Odisha. The proposed LCBoost Fusion model offers a reliable and efficient approach for real-time groundwater monitoring and risk mitigation. These findings will help the environmental organizations and the policy makers to map out targeted places for sustainable groundwater management. Future work will focus on using remote sensing data and developing an interactive decision-making system for groundwater quality assessment.</li>
</ul>

<h3>Title: Optimal Brain Apoptosis</h3>
<ul>
<li><strong>Authors: </strong>Mingyuan Sun, Zheng Fang, Jiaxu Wang, Junjie Jiang, Delei Kong, Chenming Hu, Yuetong Fang, Renjing Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17941">https://arxiv.org/abs/2502.17941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17941">https://arxiv.org/pdf/2502.17941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17941]] Optimal Brain Apoptosis(https://arxiv.org/abs/2502.17941)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The increasing complexity and parameter count of Convolutional Neural Networks (CNNs) and Transformers pose challenges in terms of computational efficiency and resource demands. Pruning has been identified as an effective strategy to address these challenges by removing redundant elements such as neurons, channels, or connections, thereby enhancing computational efficiency without heavily compromising performance. This paper builds on the foundational work of Optimal Brain Damage (OBD) by advancing the methodology of parameter importance estimation using the Hessian matrix. Unlike previous approaches that rely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel pruning method that calculates the Hessian-vector product value directly for each parameter. By decomposing the Hessian matrix across network layers and identifying conditions under which inter-layer Hessian submatrices are non-zero, we propose a highly efficient technique for computing the second-order Taylor expansion of parameters. This approach allows for a more precise pruning process, particularly in the context of CNNs and Transformers, as validated in our experiments including VGG19, ResNet32, ResNet50, and ViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at this https URL.</li>
</ul>

<h3>Title: CaseGen: A Benchmark for Multi-Stage Legal Case Documents Generation</h3>
<ul>
<li><strong>Authors: </strong>Haitao Li, Jiaying Ye, Yiran Hu, Jia Chen, Qingyao Ai, Yueyue Wu, Junjie Chen, Yifan Chen, Cheng Luo, Quan Zhou, Yiqun Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17943">https://arxiv.org/abs/2502.17943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17943">https://arxiv.org/pdf/2502.17943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17943]] CaseGen: A Benchmark for Multi-Stage Legal Case Documents Generation(https://arxiv.org/abs/2502.17943)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, large language model</a></li>
<li><strong>Abstract: </strong>Legal case documents play a critical role in judicial proceedings. As the number of cases continues to rise, the reliance on manual drafting of legal case documents is facing increasing pressure and challenges. The development of large language models (LLMs) offers a promising solution for automating document generation. However, existing benchmarks fail to fully capture the complexities involved in drafting legal case documents in real-world scenarios. To address this gap, we introduce CaseGen, the benchmark for multi-stage legal case documents generation in the Chinese legal domain. CaseGen is based on 500 real case samples annotated by legal experts and covers seven essential case sections. It supports four key tasks: drafting defense statements, writing trial facts, composing legal reasoning, and generating judgment results. To the best of our knowledge, CaseGen is the first benchmark designed to evaluate LLMs in the context of legal case document generation. To ensure an accurate and comprehensive evaluation, we design the LLM-as-a-judge evaluation framework and validate its effectiveness through human annotations. We evaluate several widely used general-domain LLMs and legal-specific LLMs, highlighting their limitations in case document generation and pinpointing areas for potential improvement. This work marks a step toward a more effective framework for automating legal case documents drafting, paving the way for the reliable application of AI in the legal field. The dataset and code are publicly available at this https URL.</li>
</ul>

<h3>Title: Assessing Large Language Models in Agentic Multilingual National Bias</h3>
<ul>
<li><strong>Authors: </strong>Qianying Liu, Katrina Qiyao Wang, Fei Cheng, Sadao Kurohashi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17945">https://arxiv.org/abs/2502.17945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17945">https://arxiv.org/pdf/2502.17945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17945]] Assessing Large Language Models in Agentic Multilingual National Bias(https://arxiv.org/abs/2502.17945)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have garnered significant attention for their capabilities in multilingual natural language processing, while studies on risks associated with cross biases are limited to immediate context preferences. Cross-language disparities in reasoning-based recommendations remain largely unexplored, with a lack of even descriptive analysis. This study is the first to address this gap. We test LLM's applicability and capability in providing personalized advice across three key scenarios: university applications, travel, and relocation. We investigate multilingual bias in state-of-the-art LLMs by analyzing their responses to decision-making tasks across multiple languages. We quantify bias in model-generated scores and assess the impact of demographic factors and reasoning strategies (e.g., Chain-of-Thought prompting) on bias patterns. Our findings reveal that local language bias is prevalent across different tasks, with GPT-4 and Sonnet reducing bias for English-speaking countries compared to GPT-3.5 but failing to achieve robust multilingual alignment, highlighting broader implications for multilingual AI agents and applications such as education.</li>
</ul>

<h3>Title: DeepSeek-R1 Outperforms Gemini 2.0 Pro, OpenAI o1, and o3-mini in Bilingual Complex Ophthalmology Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Pusheng Xu, Yue Wu, Kai Jin, Xiaolan Chen, Mingguang He, Danli Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17947">https://arxiv.org/abs/2502.17947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17947">https://arxiv.org/pdf/2502.17947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17947]] DeepSeek-R1 Outperforms Gemini 2.0 Pro, OpenAI o1, and o3-mini in Bilingual Complex Ophthalmology Reasoning(https://arxiv.org/abs/2502.17947)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Purpose: To evaluate the accuracy and reasoning ability of DeepSeek-R1 and three other recently released large language models (LLMs) in bilingual complex ophthalmology cases. Methods: A total of 130 multiple-choice questions (MCQs) related to diagnosis (n = 39) and management (n = 91) were collected from the Chinese ophthalmology senior professional title examination and categorized into six topics. These MCQs were translated into English using DeepSeek-R1. The responses of DeepSeek-R1, Gemini 2.0 Pro, OpenAI o1 and o3-mini were generated under default configurations between February 15 and February 20, 2025. Accuracy was calculated as the proportion of correctly answered questions, with omissions and extra answers considered incorrect. Reasoning ability was evaluated through analyzing reasoning logic and the causes of reasoning error. Results: DeepSeek-R1 demonstrated the highest overall accuracy, achieving 0.862 in Chinese MCQs and 0.808 in English MCQs. Gemini 2.0 Pro, OpenAI o1, and OpenAI o3-mini attained accuracies of 0.715, 0.685, and 0.692 in Chinese MCQs (all P<0.001 compared with DeepSeek-R1), and 0.746 (P=0.115), 0.723 (P=0.027), and 0.577 (P<0.001) in English MCQs, respectively. DeepSeek-R1 achieved the highest accuracy across five topics in both Chinese and English MCQs. It also excelled in management questions conducted in Chinese (all P<0.05). Reasoning ability analysis showed that the four LLMs shared similar reasoning logic. Ignoring key positive history, ignoring key positive signs, misinterpretation medical data, and too aggressive were the most common causes of reasoning errors. Conclusion: DeepSeek-R1 demonstrated superior performance in bilingual complex ophthalmology reasoning tasks than three other state-of-the-art LLMs. While its clinical applicability remains challenging, it shows promise for supporting diagnosis and clinical decision-making.</li>
</ul>

<h3>Title: Robust Polyp Detection and Diagnosis through Compositional Prompt-Guided Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Jia Yu, Yan Zhu, Peiyao Fu, Tianyi Chen, Junbo Huang, Quanlin Li, Pinghong Zhou, Zhihua Wang, Fei Wu, Shuo Wang, Xian Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17951">https://arxiv.org/abs/2502.17951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17951">https://arxiv.org/pdf/2502.17951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17951]] Robust Polyp Detection and Diagnosis through Compositional Prompt-Guided Diffusion Models(https://arxiv.org/abs/2502.17951)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Colorectal cancer (CRC) is a significant global health concern, and early detection through screening plays a critical role in reducing mortality. While deep learning models have shown promise in improving polyp detection, classification, and segmentation, their generalization across diverse clinical environments, particularly with out-of-distribution (OOD) data, remains a challenge. Multi-center datasets like PolypGen have been developed to address these issues, but their collection is costly and time-consuming. Traditional data augmentation techniques provide limited variability, failing to capture the complexity of medical images. Diffusion models have emerged as a promising solution for generating synthetic polyp images, but the image generation process in current models mainly relies on segmentation masks as the condition, limiting their ability to capture the full clinical context. To overcome these limitations, we propose a Progressive Spectrum Diffusion Model (PSDM) that integrates diverse clinical annotations-such as segmentation masks, bounding boxes, and colonoscopy reports-by transforming them into compositional prompts. These prompts are organized into coarse and fine components, allowing the model to capture both broad spatial structures and fine details, generating clinically accurate synthetic images. By augmenting training data with PSDM-generated samples, our model significantly improves polyp detection, classification, and segmentation. For instance, on the PolypGen dataset, PSDM increases the F1 score by 2.12% and the mean average precision by 3.09%, demonstrating superior performance in OOD scenarios and enhanced generalization.</li>
</ul>

<h3>Title: Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments</h3>
<ul>
<li><strong>Authors: </strong>Patomporn Payoungkhamdee, Pume Tuchinda, Jinheon Baek, Samuel Cahyawijaya, Can Udomcharoenchaikit, Potsawee Manakul, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17956">https://arxiv.org/abs/2502.17956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17956">https://arxiv.org/pdf/2502.17956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17956]] Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments(https://arxiv.org/abs/2502.17956)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-step reasoning is essential for large language models (LLMs), yet multilingual performance remains challenging. While Chain-of-Thought (CoT) prompting improves reasoning, it struggles with non-English languages due to the entanglement of reasoning and execution. Program-of-Thought (PoT) prompting separates reasoning from execution, offering a promising alternative but shifting the challenge to generating programs from non-English questions. We propose a framework to evaluate PoT by separating multilingual reasoning from code execution to examine (i) the impact of fine-tuning on question-reasoning alignment and (ii) how reasoning quality affects answer correctness. Our findings demonstrate that PoT fine-tuning substantially enhances multilingual reasoning, outperforming CoT fine-tuned models. We further demonstrate a strong correlation between reasoning quality (measured through code quality) and answer accuracy, highlighting its potential as a test-time performance improvement heuristic.</li>
</ul>

<h3>Title: On Synthetic Data Strategies for Domain-Specific Generative Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Haoyang Wen, Jiang Guo, Yi Zhang, Jiarong Jiang, Zhiguo Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17957">https://arxiv.org/abs/2502.17957</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17957">https://arxiv.org/pdf/2502.17957</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17957]] On Synthetic Data Strategies for Domain-Specific Generative Retrieval(https://arxiv.org/abs/2502.17957)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper investigates synthetic data generation strategies in developing generative retrieval models for domain-specific corpora, thereby addressing the scalability challenges inherent in manually annotating in-domain queries. We study the data strategies for a two-stage training framework: in the first stage, which focuses on learning to decode document identifiers from queries, we investigate LLM-generated queries across multiple granularity (e.g. chunks, sentences) and domain-relevant search constraints that can better capture nuanced relevancy signals. In the second stage, which aims to refine document ranking through preference learning, we explore the strategies for mining hard negatives based on the initial model's predictions. Experiments on public datasets over diverse domains demonstrate the effectiveness of our synthetic data generation and hard negative sampling approach.</li>
</ul>

<h3>Title: Improved YOLOv7x-Based Defect Detection Algorithm for Power Equipment</h3>
<ul>
<li><strong>Authors: </strong>Jin Hou, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17961">https://arxiv.org/abs/2502.17961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17961">https://arxiv.org/pdf/2502.17961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17961]] Improved YOLOv7x-Based Defect Detection Algorithm for Power Equipment(https://arxiv.org/abs/2502.17961)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The normal operation of power equipment plays a critical role in the power system, making anomaly detection for power equipment highly significant. This paper proposes an improved YOLOv7x-based anomaly detection algorithm for power equipment. First, the ACmix convolutional mixed attention mechanism module is introduced to effectively suppress background noise and irrelevant features, thereby enhancing the network's feature extraction capability. Second, the Biformer attention mechanism is added to the network to strengthen the focus on key features, improving the network's ability to flexibly recognize feature images. Finally, to more comprehensively evaluate the relationship between predicted and ground truth bounding boxes, the original loss function is replaced with the MPDIoU function, addressing the issue of mismatched predicted bounding boxes. The improved algorithm enhances detection accuracy, achieving a mAP@0.5/% of 93.5% for all target categories, a precision of 97.1%, and a recall of 97%.</li>
</ul>

<h3>Title: LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena</h3>
<ul>
<li><strong>Authors: </strong>Tianmi Ma, Jiawei Du, Wenxin Huang, Wenjie Wang, Liang Xie, Xian Zhong, Joey Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.MA, q-fin.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17967">https://arxiv.org/abs/2502.17967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17967">https://arxiv.org/pdf/2502.17967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17967]] LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena(https://arxiv.org/abs/2502.17967)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have significantly improved performance in natural language processing tasks. However, their ability to generalize to dynamic, unseen tasks, particularly in numerical reasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on problems with predefined optimal solutions, which may not align with real-world scenarios where clear answers are absent. To bridge this gap, we design the Agent Trading Arena, a virtual numerical game simulating complex economic systems through zero-sum games, where agents invest in stock portfolios. Our experiments reveal that LLMs, including GPT-4o, struggle with algebraic reasoning when dealing with plain-text stock data, often focusing on local details rather than global trends. In contrast, LLMs perform significantly better with geometric reasoning when presented with visual data, such as scatter plots or K-line charts, suggesting that visual representations enhance numerical reasoning. This capability is further improved by incorporating the reflection module, which aids in the analysis and interpretation of complex data. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate stronger reasoning with visual data compared to text. Our code and data are publicly available at this https URL.</li>
</ul>

<h3>Title: Model-Free Adversarial Purification via Coarse-To-Fine Tensor Network Representation</h3>
<ul>
<li><strong>Authors: </strong>Guang Lin, Duc Thien Nguyen, Zerui Tao, Konstantinos Slavakis, Toshihisa Tanaka, Qibin Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17972">https://arxiv.org/abs/2502.17972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17972">https://arxiv.org/pdf/2502.17972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17972]] Model-Free Adversarial Purification via Coarse-To-Fine Tensor Network Representation(https://arxiv.org/abs/2502.17972)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Deep neural networks are known to be vulnerable to well-designed adversarial attacks. Although numerous defense strategies have been proposed, many are tailored to the specific attacks or tasks and often fail to generalize across diverse scenarios. In this paper, we propose Tensor Network Purification (TNP), a novel model-free adversarial purification method by a specially designed tensor network decomposition algorithm. TNP depends neither on the pre-trained generative model nor the specific dataset, resulting in strong robustness across diverse adversarial scenarios. To this end, the key challenge lies in relaxing Gaussian-noise assumptions of classical decompositions and accommodating the unknown distribution of adversarial perturbations. Unlike the low-rank representation of classical decompositions, TNP aims to reconstruct the unobserved clean examples from an adversarial example. Specifically, TNP leverages progressive downsampling and introduces a novel adversarial optimization objective to address the challenge of minimizing reconstruction error but without inadvertently restoring adversarial perturbations. Extensive experiments conducted on CIFAR-10, CIFAR-100, and ImageNet demonstrate that our method generalizes effectively across various norm threats, attack types, and tasks, providing a versatile and promising adversarial purification technique.</li>
</ul>

<h3>Title: XGBoost-Based Prediction of ICU Mortality in Sepsis-Associated Acute Kidney Injury Patients Using MIMIC-IV Database with Validation from eICU Database</h3>
<ul>
<li><strong>Authors: </strong>Shuheng Chen, Junyi Fan, Elham Pishgar, Kamiar Alaei, Greg Placencia, Maryam Pishgar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17978">https://arxiv.org/abs/2502.17978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17978">https://arxiv.org/pdf/2502.17978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17978]] XGBoost-Based Prediction of ICU Mortality in Sepsis-Associated Acute Kidney Injury Patients Using MIMIC-IV Database with Validation from eICU Database(https://arxiv.org/abs/2502.17978)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Background: Sepsis-Associated Acute Kidney Injury (SA-AKI) leads to high mortality in intensive care. This study develops machine learning models using the Medical Information Mart for Intensive Care IV (MIMIC-IV) database to predict Intensive Care Unit (ICU) mortality in SA-AKI patients. External validation is conducted using the eICU Collaborative Research Database. Methods: For 9,474 identified SA-AKI patients in MIMIC-IV, key features like lab results, vital signs, and comorbidities were selected using Variance Inflation Factor (VIF), Recursive Feature Elimination (RFE), and expert input, narrowing to 24 predictive variables. An Extreme Gradient Boosting (XGBoost) model was built for in-hospital mortality prediction, with hyperparameters optimized using GridSearch. Model interpretability was enhanced with SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME). External validation was conducted using the eICU database. Results: The proposed XGBoost model achieved an internal Area Under the Receiver Operating Characteristic curve (AUROC) of 0.878 (95% Confidence Interval: 0.859-0.897). SHAP identified Sequential Organ Failure Assessment (SOFA), serum lactate, and respiratory rate as key mortality predictors. LIME highlighted serum lactate, Acute Physiology and Chronic Health Evaluation II (APACHE II) score, total urine output, and serum calcium as critical features. Conclusions: The integration of advanced techniques with the XGBoost algorithm yielded a highly accurate and interpretable model for predicting SA-AKI mortality across diverse populations. It supports early identification of high-risk patients, enhancing clinical decision-making in intensive care. Future work needs to focus on enhancing adaptability, versatility, and real-world applications.</li>
</ul>

<h3>Title: Generalized Decision Focused Learning under Imprecise Uncertainty--Theoretical Study</h3>
<ul>
<li><strong>Authors: </strong>Keivan Shariatmadar, Neil Yorke-Smith, Ahmad Osman, Fabio Cuzzolin, Hans Hallez, David Moens</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, math.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17984">https://arxiv.org/abs/2502.17984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17984">https://arxiv.org/pdf/2502.17984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17984]] Generalized Decision Focused Learning under Imprecise Uncertainty--Theoretical Study(https://arxiv.org/abs/2502.17984)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Decision Focused Learning has emerged as a critical paradigm for integrating machine learning with downstream optimisation. Despite its promise, existing methodologies predominantly rely on probabilistic models and focus narrowly on task objectives, overlooking the nuanced challenges posed by epistemic uncertainty, non-probabilistic modelling approaches, and the integration of uncertainty into optimisation constraints. This paper bridges these gaps by introducing innovative frameworks: (i) a non-probabilistic lens for epistemic uncertainty representation, leveraging intervals (the least informative uncertainty model), Contamination (hybrid model), and probability boxes (the most informative uncertainty model); (ii) methodologies to incorporate uncertainty into constraints, expanding Decision-Focused Learning's utility in constrained environments; (iii) the adoption of Imprecise Decision Theory for ambiguity-rich decision-making contexts; and (iv) strategies for addressing sparse data challenges. Empirical evaluations on benchmark optimisation problems demonstrate the efficacy of these approaches in improving decision quality and robustness and dealing with said gaps.</li>
</ul>

<h3>Title: MAGE: Multi-Head Attention Guided Embeddings for Low Resource Sentiment Classification</h3>
<ul>
<li><strong>Authors: </strong>Varun Vashisht, Samar Singh, Mihir Konduskar, Jaskaran Singh Walia, Vukosi Marivate</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17987">https://arxiv.org/abs/2502.17987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17987">https://arxiv.org/pdf/2502.17987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17987]] MAGE: Multi-Head Attention Guided Embeddings for Low Resource Sentiment Classification(https://arxiv.org/abs/2502.17987)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Due to the lack of quality data for low-resource Bantu languages, significant challenges are presented in text classification and other practical implementations. In this paper, we introduce an advanced model combining Language-Independent Data Augmentation (LiDA) with Multi-Head Attention based weighted embeddings to selectively enhance critical data points and improve text classification performance. This integration allows us to create robust data augmentation strategies that are effective across various linguistic contexts, ensuring that our model can handle the unique syntactic and semantic features of Bantu languages. This approach not only addresses the data scarcity issue but also sets a foundation for future research in low-resource language processing and classification tasks.</li>
</ul>

<h3>Title: Shedding Light on the Polymer's Identity: Microplastic Detection and Identification Through Nile Red Staining and Multispectral Imaging (FIMAP)</h3>
<ul>
<li><strong>Authors: </strong>Derek Ho, Haotian Feng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.ET, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.17997">https://arxiv.org/abs/2502.17997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.17997">https://arxiv.org/pdf/2502.17997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.17997]] Shedding Light on the Polymer's Identity: Microplastic Detection and Identification Through Nile Red Staining and Multispectral Imaging (FIMAP)(https://arxiv.org/abs/2502.17997)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The widespread distribution of microplastics (MPs) in the environment presents significant challenges for their detection and identification. Fluorescence imaging has emerged as a promising technique for enhancing plastic particle detectability and enabling accurate classification based on fluorescence behavior. However, conventional segmentation techniques face limitations, including poor signal-to-noise ratio, inconsistent illumination, thresholding difficulties, and false positives from natural organic matter (NOM). To address these challenges, this study introduces the Fluorescence Imaging Microplastic Analysis Platform (FIMAP), a retrofitted multispectral camera with four optical filters and five excitation wavelengths. FIMAP enables comprehensive characterization of the fluorescence behavior of ten Nile Red-stained MPs: HDPE, LDPE, PP, PS, EPS, ABS, PVC, PC, PET, and PA, while effectively excluding NOM. Using K-means clustering for robust segmentation (Intersection over Union = 0.877) and a 20-dimensional color coordinate multivariate nearest neighbor approach for MP classification (>3.14 mm), FIMAP achieves 90% precision, 90% accuracy, 100% recall, and an F1 score of 94.7%. Only PS was occasionally misclassified as EPS. For smaller MPs (35-104 microns), classification accuracy declined, likely due to reduced stain sorption, fewer detectable pixels, and camera instability. Integrating FIMAP with higher-magnification instruments, such as a microscope, may enhance MP identification. This study presents FIMAP as an automated, high-throughput framework for detecting and classifying MPs across large environmental sample volumes.</li>
</ul>

<h3>Title: Unveiling the Key Factors for Distilling Chain-of-Thought Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Xinghao Chen, Zhijing Sun, Wenjin Guo, Miaoran Zhang, Yanjun Chen, Yirong Sun, Hui Su, Yijie Pan, Dietrich Klakow, Wenjie Li, Xiaoyu Shen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18001">https://arxiv.org/abs/2502.18001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18001">https://arxiv.org/pdf/2502.18001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18001]] Unveiling the Key Factors for Distilling Chain-of-Thought Reasoning(https://arxiv.org/abs/2502.18001)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in reasoning tasks through Chain-of-Thought (CoT) prompting. However, CoT prompting greatly increases computational demands, which has prompted growing interest in distilling CoT capabilities into Small Language Models (SLMs). This study systematically examines the factors influencing CoT distillation, including the choice of granularity, format and teacher model. Through experiments involving four teacher models and seven student models across seven mathematical and commonsense reasoning datasets, we uncover three key findings: (1) Unlike LLMs, SLMs exhibit a non-monotonic relationship with granularity, with stronger models benefiting from finer-grained reasoning and weaker models performing better with simpler CoT supervision; (2) CoT format significantly impacts LLMs but has minimal effect on SLMs, likely due to their reliance on supervised fine-tuning rather than pretraining preferences; (3) Stronger teacher models do NOT always produce better student models, as diversity and complexity in CoT supervision can outweigh accuracy alone. These findings emphasize the need to tailor CoT strategies to specific student model, offering actionable insights for optimizing CoT distillation in SLMs. The code and datasets are available at this https URL.</li>
</ul>

<h3>Title: Radon-Nikodým Derivative: Re-imagining Anomaly Detection from a Measure Theoretic Perspective</h3>
<ul>
<li><strong>Authors: </strong>Shlok Mehendale, Aditya Challa, Rahul Yedida, Sravan Danda, Santonu Sarkar, Snehanshu Saha</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18002">https://arxiv.org/abs/2502.18002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18002">https://arxiv.org/pdf/2502.18002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18002]] Radon-Nikodým Derivative: Re-imagining Anomaly Detection from a Measure Theoretic Perspective(https://arxiv.org/abs/2502.18002)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Which principle underpins the design of an effective anomaly detection loss function? The answer lies in the concept of \rnthm{} theorem, a fundamental concept in measure theory. The key insight is -- Multiplying the vanilla loss function with the \rnthm{} derivative improves the performance across the board. We refer to this as RN-Loss. This is established using PAC learnability of anomaly detection. We further show that the \rnthm{} derivative offers important insights into unsupervised clustering based anomaly detections as well. We evaluate our algorithm on 96 datasets, including univariate and multivariate data from diverse domains, including healthcare, cybersecurity, and finance. We show that RN-Derivative algorithms outperform state-of-the-art methods on 68\% of Multivariate datasets (based on F-1 scores) and also achieves peak F1-scores on 72\% of time series (Univariate) datasets.</li>
</ul>

<h3>Title: Patient Trajectory Prediction: Integrating Clinical Notes with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Sifal Klioui, Sana Sellami, Youssef Trardi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18009">https://arxiv.org/abs/2502.18009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18009">https://arxiv.org/pdf/2502.18009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18009]] Patient Trajectory Prediction: Integrating Clinical Notes with Transformers(https://arxiv.org/abs/2502.18009)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Predicting disease trajectories from electronic health records (EHRs) is a complex task due to major challenges such as data non-stationarity, high granularity of medical codes, and integration of multimodal data. EHRs contain both structured data, such as diagnostic codes, and unstructured data, such as clinical notes, which hold essential information often overlooked. Current models, primarily based on structured data, struggle to capture the complete medical context of patients, resulting in a loss of valuable information. To address this issue, we propose an approach that integrates unstructured clinical notes into transformer-based deep learning models for sequential disease prediction. This integration enriches the representation of patients' medical histories, thereby improving the accuracy of diagnosis predictions. Experiments on MIMIC-IV datasets demonstrate that the proposed approach outperforms traditional models relying solely on structured data.</li>
</ul>

<h3>Title: High-precision visual navigation device calibration method based on collimator</h3>
<ul>
<li><strong>Authors: </strong>Shunkun Liang, Dongcai Tan, Banglei Guan, Zhang Li, Guangcheng Dai, Nianpeng Pan, Liang Shen, Yang Shang, Qifeng Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18012">https://arxiv.org/abs/2502.18012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18012">https://arxiv.org/pdf/2502.18012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18012]] High-precision visual navigation device calibration method based on collimator(https://arxiv.org/abs/2502.18012)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual navigation devices require precise calibration to achieve high-precision localization and navigation, which includes camera and attitude calibration. To address the limitations of time-consuming camera calibration and complex attitude adjustment processes, this study presents a collimator-based calibration method and system. Based on the optical characteristics of the collimator, a single-image camera calibration algorithm is introduced. In addition, integrated with the precision adjustment mechanism of the calibration frame, a rotation transfer model between coordinate systems enables efficient attitude calibration. Experimental results demonstrate that the proposed method achieves accuracy and stability comparable to traditional multi-image calibration techniques. Specifically, the re-projection errors are less than 0.1463 pixels, and average attitude angle errors are less than 0.0586 degrees with a standard deviation less than 0.0257 degrees, demonstrating high precision and robustness.</li>
</ul>

<h3>Title: Verdict: A Library for Scaling Judge-Time Compute</h3>
<ul>
<li><strong>Authors: </strong>Nimit Kalra, Leonard Tang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18018">https://arxiv.org/abs/2502.18018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18018">https://arxiv.org/pdf/2502.18018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18018]] Verdict: A Library for Scaling Judge-Time Compute(https://arxiv.org/abs/2502.18018)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The use of LLMs as automated judges ("LLM-as-a-judge") is now widespread, yet standard judges suffer from a multitude of reliability issues. To address these challenges, we introduce Verdict, an open-source library for scaling judge-time compute to enhance the accuracy, reliability, and interpretability of automated evaluators. Verdict leverages the composition of modular reasoning units -- such as verification, debate, and aggregation -- and increased inference-time compute to improve LLM judge quality. Across a variety of challenging tasks such as content moderation, fact-checking, and hallucination detection, Verdict judges achieve state-of-the-art (SOTA) or near-SOTA performance, surpassing orders-of-magnitude larger fine-tuned judges, prompted judges, and reasoning models. Ultimately, we hope Verdict serves as a useful framework for researchers and practitioners building scalable, interpretable, and reliable LLM-based evaluators.</li>
</ul>

<h3>Title: AfroXLMR-Comet: Multilingual Knowledge Distillation with Attention Matching for Low-Resource languages</h3>
<ul>
<li><strong>Authors: </strong>Joshua Sakthivel Raju, Sanjay S, Jaskaran Singh Walia, Srinivas Raghav, Vukosi Marivate</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18020">https://arxiv.org/abs/2502.18020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18020">https://arxiv.org/pdf/2502.18020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18020]] AfroXLMR-Comet: Multilingual Knowledge Distillation with Attention Matching for Low-Resource languages(https://arxiv.org/abs/2502.18020)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Language model compression through knowledge distillation has emerged as a promising approach for deploying large language models in resource-constrained environments. However, existing methods often struggle to maintain performance when distilling multilingual models, especially for low-resource languages. In this paper, we present a novel hybrid distillation approach that combines traditional knowledge distillation with a simplified attention matching mechanism, specifically designed for multilingual contexts. Our method introduces an extremely compact student model architecture, significantly smaller than conventional multilingual models. We evaluate our approach on five African languages: Kinyarwanda, Swahili, Hausa, Igbo, and Yoruba. The distilled student model; AfroXLMR-Comet successfully captures both the output distribution and internal attention patterns of a larger teacher model (AfroXLMR-Large) while reducing the model size by over 85%. Experimental results demonstrate that our hybrid approach achieves competitive performance compared to the teacher model, maintaining an accuracy within 85% of the original model's performance while requiring substantially fewer computational resources. Our work provides a practical framework for deploying efficient multilingual models in resource-constrained environments, particularly benefiting applications involving African languages.</li>
</ul>

<h3>Title: Detecting Knowledge Boundary of Vision Large Language Models by Sampling-Based Inference</h3>
<ul>
<li><strong>Authors: </strong>Zhuo Chen, Xinyu Wang, Yong Jiang, Zhen Zhang, Xinyu Geng, Pengjun Xie, Fei Huang, Kewei Tu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18023">https://arxiv.org/abs/2502.18023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18023">https://arxiv.org/pdf/2502.18023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18023]] Detecting Knowledge Boundary of Vision Large Language Models by Sampling-Based Inference(https://arxiv.org/abs/2502.18023)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the advancements made in Visual Large Language Models (VLLMs), like text Large Language Models (LLMs), they have limitations in addressing questions that require real-time information or are knowledge-intensive. Indiscriminately adopting Retrieval Augmented Generation (RAG) techniques is an effective yet expensive way to enable models to answer queries beyond their knowledge scopes. To mitigate the dependence on retrieval and simultaneously maintain, or even improve, the performance benefits provided by retrieval, we propose a method to detect the knowledge boundary of VLLMs, allowing for more efficient use of techniques like RAG. Specifically, we propose a method with two variants that fine-tunes a VLLM on an automatically constructed dataset for boundary identification. Experimental results on various types of Visual Question Answering datasets show that our method successfully depicts a VLLM's knowledge boundary based on which we are able to reduce indiscriminate retrieval while maintaining or improving the performance. In addition, we show that the knowledge boundary identified by our method for one VLLM can be used as a surrogate boundary for other VLLMs. Code will be released at this https URL</li>
</ul>

<h3>Title: Harnessing Multiple Large Language Models: A Survey on LLM Ensemble</h3>
<ul>
<li><strong>Authors: </strong>Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Dingqi Yang, Hailong Sun, Philip S. Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18036">https://arxiv.org/abs/2502.18036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18036">https://arxiv.org/pdf/2502.18036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18036]] Harnessing Multiple Large Language Models: A Survey on LLM Ensemble(https://arxiv.org/abs/2502.18036)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LLM Ensemble -- which involves the comprehensive use of multiple large language models (LLMs), each aimed at handling user queries during downstream inference, to benefit from their individual strengths -- has gained substantial attention recently. The widespread availability of LLMs, coupled with their varying strengths and out-of-the-box usability, has profoundly advanced the field of LLM Ensemble. This paper presents the first systematic review of recent developments in LLM Ensemble. First, we introduce our taxonomy of LLM Ensemble and discuss several related research problems. Then, we provide a more in-depth classification of the methods under the broad categories of "ensemble-before-inference, ensemble-during-inference, ensemble-after-inference", and review all relevant methods. Finally, we introduce related benchmarks and applications, summarize existing studies, and suggest several future research directions. A curated list of papers on LLM Ensemble is available at this https URL.</li>
</ul>

<h3>Title: OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation</h3>
<ul>
<li><strong>Authors: </strong>Yunpeng Gao, Chenhui Li, Zhongrui You, Junli Liu, Zhen Li, Pengan Chen, Qizhi Chen, Zhonghan Tang, Liansheng Wang, Penghui Yang, Yiwen Tang, Yuhang Tang, Shuai Liang, Songyi Zhu, Ziqin Xiong, Yifei Su, Xinyi Ye, Jianan Li, Yan Ding, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18041">https://arxiv.org/abs/2502.18041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18041">https://arxiv.org/pdf/2502.18041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18041]] OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation(https://arxiv.org/abs/2502.18041)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Vision-Language Navigation (VLN) aims to guide agents through an environment by leveraging both language instructions and visual cues, playing a pivotal role in embodied AI. Indoor VLN has been extensively studied, whereas outdoor aerial VLN remains underexplored. The potential reason is that outdoor aerial view encompasses vast areas, making data collection more challenging, which results in a lack of benchmarks. To address this problem, we propose OpenFly, a platform comprising a versatile toolchain and large-scale benchmark for aerial VLN. Firstly, we develop a highly automated toolchain for data collection, enabling automatic point cloud acquisition, scene semantic segmentation, flight trajectory creation, and instruction generation. Secondly, based on the toolchain, we construct a large-scale aerial VLN dataset with 100k trajectories, covering diverse heights and lengths across 18 scenes. The corresponding visual data are generated using various rendering engines and advanced techniques, including Unreal Engine, GTA V, Google Earth, and 3D Gaussian Splatting (3D GS). All data exhibit high visual quality. Particularly, 3D GS supports real-to-sim rendering, further enhancing the realism of the dataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, which takes language instructions, current observations, and historical keyframes as input, and outputs flight actions directly. Extensive analyses and experiments are conducted, showcasing the superiority of our OpenFly platform and OpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.</li>
</ul>

<h3>Title: VLM-E2E: Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion</h3>
<ul>
<li><strong>Authors: </strong>Pei Liu (1), Haipeng Liu (2), Haichao Liu (1), Xin Liu (1), Jinxin Ni (3), Jun Ma (1 and 4) ((1) The Hong Kong University of Science and Technology (Guangzhou), (2) Li Auto Inc., (3) Xiamen University, (4) The Hong Kong University of Science and Technology)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18042">https://arxiv.org/abs/2502.18042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18042">https://arxiv.org/pdf/2502.18042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18042]] VLM-E2E: Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion(https://arxiv.org/abs/2502.18042)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Human drivers adeptly navigate complex scenarios by utilizing rich attentional semantics, but the current autonomous systems struggle to replicate this ability, as they often lose critical semantic information when converting 2D observations into 3D space. In this sense, it hinders their effective deployment in dynamic and complex environments. Leveraging the superior scene understanding and reasoning abilities of Vision-Language Models (VLMs), we propose VLM-E2E, a novel framework that uses the VLMs to enhance training by providing attentional cues. Our method integrates textual representations into Bird's-Eye-View (BEV) features for semantic supervision, which enables the model to learn richer feature representations that explicitly capture the driver's attentional semantics. By focusing on attentional semantics, VLM-E2E better aligns with human-like driving behavior, which is critical for navigating dynamic and complex environments. Furthermore, we introduce a BEV-Text learnable weighted fusion strategy to address the issue of modality importance imbalance in fusing multimodal information. This approach dynamically balances the contributions of BEV and text features, ensuring that the complementary information from visual and textual modality is effectively utilized. By explicitly addressing the imbalance in multimodal fusion, our method facilitates a more holistic and robust representation of driving environments. We evaluate VLM-E2E on the nuScenes dataset and demonstrate its superiority over state-of-the-art approaches, showcasing significant improvements in performance.</li>
</ul>

<h3>Title: Progressive Local Alignment for Medical Multimodal Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Huimin Yan, Xian Yang, Liang Bai, Jiye Liang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18047">https://arxiv.org/abs/2502.18047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18047">https://arxiv.org/pdf/2502.18047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18047]] Progressive Local Alignment for Medical Multimodal Pre-training(https://arxiv.org/abs/2502.18047)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Local alignment between medical images and text is essential for accurate diagnosis, though it remains challenging due to the absence of natural local pairings and the limitations of rigid region recognition methods. Traditional approaches rely on hard boundaries, which introduce uncertainty, whereas medical imaging demands flexible soft region recognition to handle irregular structures. To overcome these challenges, we propose the Progressive Local Alignment Network (PLAN), which designs a novel contrastive learning-based approach for local alignment to establish meaningful word-pixel relationships and introduces a progressive learning strategy to iteratively refine these relationships, enhancing alignment precision and robustness. By combining these techniques, PLAN effectively improves soft region recognition while suppressing noise interference. Extensive experiments on multiple medical datasets demonstrate that PLAN surpasses state-of-the-art methods in phrase grounding, image-text retrieval, object detection, and zero-shot classification, setting a new benchmark for medical image-text alignment.</li>
</ul>

<h3>Title: Escaping The Big Data Paradigm in Self-Supervised Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Carlos Vélez García, Miguel Cazorla, Jorge Pomares</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18056">https://arxiv.org/abs/2502.18056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18056">https://arxiv.org/pdf/2502.18056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18056]] Escaping The Big Data Paradigm in Self-Supervised Representation Learning(https://arxiv.org/abs/2502.18056)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The reliance on large-scale datasets and extensive computational resources has become a major barrier to advancing representation learning in vision, especially in data-scarce domains. In this paper, we address the critical question: Can we escape the big data paradigm in self-supervised representation learning from images? We introduce SCOTT (Sparse Convolutional Tokenizer for Transformers), a shallow tokenization architecture that is compatible with Masked Image Modeling (MIM) tasks. SCOTT injects convolutional inductive biases into Vision Transformers (ViTs), enhancing their efficacy in small-scale data regimes. Alongside, we propose to train on a Joint-Embedding Predictive Architecture within a MIM framework (MIM-JEPA), operating in latent representation space to capture more semantic features. Our approach enables ViTs to be trained from scratch on datasets orders of magnitude smaller than traditionally required --without relying on massive external datasets for pretraining. We validate our method on three small-size, standard-resoultion, fine-grained datasets: Oxford Flowers-102, Oxford IIIT Pets-37, and ImageNet-100. Despite the challenges of limited data and high intra-class similarity, frozen SCOTT models pretrained with MIM-JEPA significantly outperform fully supervised methods and achieve competitive results with SOTA approaches that rely on large-scale pretraining, complex image augmentations and bigger model sizes. By demonstrating that robust off-the-shelf representations can be learned with limited data, compute, and model sizes, our work paves the way for computer applications in resource constrained environments such as medical imaging or robotics. Our findings challenge the prevailing notion that vast amounts of data are indispensable for effective representation learning in vision, offering a new pathway toward more accessible and inclusive advancements in the field.</li>
</ul>

<h3>Title: Examining the Threat Landscape: Foundation Models and Model Stealing</h3>
<ul>
<li><strong>Authors: </strong>Ankita Raj, Deepankar Varma, Chetan Arora</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18077">https://arxiv.org/abs/2502.18077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18077">https://arxiv.org/pdf/2502.18077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18077]] Examining the Threat Landscape: Foundation Models and Model Stealing(https://arxiv.org/abs/2502.18077)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal, transformer</a></li>
<li><strong>Abstract: </strong>Foundation models (FMs) for computer vision learn rich and robust representations, enabling their adaptation to task/domain-specific deployments with little to no fine-tuning. However, we posit that the very same strength can make applications based on FMs vulnerable to model stealing attacks. Through empirical analysis, we reveal that models fine-tuned from FMs harbor heightened susceptibility to model stealing, compared to conventional vision architectures like ResNets. We hypothesize that this behavior is due to the comprehensive encoding of visual patterns and features learned by FMs during pre-training, which are accessible to both the attacker and the victim. We report that an attacker is able to obtain 94.28% agreement (matched predictions with victim) for a Vision Transformer based victim model (ViT-L/16) trained on CIFAR-10 dataset, compared to only 73.20% agreement for a ResNet-18 victim, when using ViT-L/16 as the thief model. We arguably show, for the first time, that utilizing FMs for downstream tasks may not be the best choice for deployment in commercial APIs due to their susceptibility to model theft. We thereby alert model owners towards the associated security risks, and highlight the need for robust security measures to safeguard such models against theft. Code is available at this https URL.</li>
</ul>

<h3>Title: Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Wenkai Yang, Shuming Ma, Yankai Lin, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18080">https://arxiv.org/abs/2502.18080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18080">https://arxiv.org/pdf/2502.18080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18080]] Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning(https://arxiv.org/abs/2502.18080)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that making a model spend more time thinking through longer Chain of Thoughts (CoTs) enables it to gain significant improvements in complex reasoning tasks. While current researches continue to explore the benefits of increasing test-time compute by extending the CoT lengths of Large Language Models (LLMs), we are concerned about a potential issue hidden behind the current pursuit of test-time scaling: Would excessively scaling the CoT length actually bring adverse effects to a model's reasoning performance? Our explorations on mathematical reasoning tasks reveal an unexpected finding that scaling with longer CoTs can indeed impair the reasoning performance of LLMs in certain domains. Moreover, we discover that there exists an optimal scaled length distribution that differs across different domains. Based on these insights, we propose a Thinking-Optimal Scaling strategy. Our method first uses a small set of seed data with varying response length distributions to teach the model to adopt different reasoning efforts for deep thinking. Then, the model selects its shortest correct response under different reasoning efforts on additional problems for self-improvement. Our self-improved models built upon Qwen2.5-32B-Instruct outperform other distillation-based 32B o1-like models across various math benchmarks, and achieve performance on par with QwQ-32B-Preview.</li>
</ul>

<h3>Title: A Fusion Model for Art Style and Author Recognition Based on Convolutional Neural Networks and Transformers</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Wang, Heng Song</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18083">https://arxiv.org/abs/2502.18083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18083">https://arxiv.org/pdf/2502.18083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18083]] A Fusion Model for Art Style and Author Recognition Based on Convolutional Neural Networks and Transformers(https://arxiv.org/abs/2502.18083)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, extraction, transformer</a></li>
<li><strong>Abstract: </strong>The recognition of art styles and authors is crucial in areas like cultural heritage protection, art market analysis, and historical research. With the advancement of deep learning, Convolutional Neural Networks (CNNs) and Transformer models have become key tools for image classification. While CNNs excel in local feature extraction, they struggle with global context, and Transformers are strong in capturing global dependencies but weak in fine-grained local details. To address these challenges, this paper proposes a fusion model combining CNNs and Transformers for art style and author recognition. The model first extracts local features using CNNs, then captures global context with a Transformer, followed by a feature fusion mechanism to enhance classification accuracy. Experiments on Chinese and oil painting datasets show the fusion model outperforms individual CNN and Transformer models, improving classification accuracy by 9.7% and 7.1%, respectively, and increasing F1 scores by 0.06 and 0.05. The results demonstrate the model's effectiveness and potential for future improvements, such as multimodal integration and architecture optimization.</li>
</ul>

<h3>Title: The Built-In Robustness of Decentralized Federated Averaging to Bad Data</h3>
<ul>
<li><strong>Authors: </strong>Samuele Sabella, Chiara Boldrini, Lorenzo Valerio, Andrea Passarella, Marco Conti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18097">https://arxiv.org/abs/2502.18097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18097">https://arxiv.org/pdf/2502.18097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18097]] The Built-In Robustness of Decentralized Federated Averaging to Bad Data(https://arxiv.org/abs/2502.18097)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Decentralized federated learning (DFL) enables devices to collaboratively train models over complex network topologies without relying on a central controller. In this setting, local data remains private, but its quality and quantity can vary significantly across nodes. The extent to which a fully decentralized system is vulnerable to poor-quality or corrupted data remains unclear, but several factors could contribute to potential risks. Without a central authority, there can be no unified mechanism to detect or correct errors, and each node operates with a localized view of the data distribution, making it difficult for the node to assess whether its perspective aligns with the true distribution. Moreover, models trained on low-quality data can propagate through the network, amplifying errors. To explore the impact of low-quality data on DFL, we simulate two scenarios with degraded data quality -- one where the corrupted data is evenly distributed in a subset of nodes and one where it is concentrated on a single node -- using a decentralized implementation of FedAvg. Our results reveal that averaging-based decentralized learning is remarkably robust to localized bad data, even when the corrupted data resides in the most influential nodes of the network. Counterintuitively, this robustness is further enhanced when the corrupted data is concentrated on a single node, regardless of its centrality in the communication network topology. This phenomenon is explained by the averaging process, which ensures that no single node -- however central -- can disproportionately influence the overall learning process.</li>
</ul>

<h3>Title: Stackelberg Game Preference Optimization for Data-Efficient Alignment of Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xu Chu, Zhixin Zhang, Tianyu Jia, Yujie Jin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18099">https://arxiv.org/abs/2502.18099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18099">https://arxiv.org/pdf/2502.18099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18099]] Stackelberg Game Preference Optimization for Data-Efficient Alignment of Language Models(https://arxiv.org/abs/2502.18099)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Aligning language models with human preferences is critical for real-world deployment, but existing methods often require large amounts of high-quality human annotations. Aiming at a data-efficient alignment method, we propose Stackelberg Game Preference Optimization (SGPO), a framework that models alignment as a two-player Stackelberg game, where a policy (leader) optimizes against a worst-case preference distribution (follower) within an $\epsilon$-Wasserstein ball, ensuring robustness to (self-)annotation noise and distribution shifts. SGPO guarantees $O(\epsilon)$-bounded regret, unlike Direct Preference Optimization (DPO), which suffers from linear regret growth in the distribution mismatch. We instantiate SGPO with the Stackelberg Self-Annotated Preference Optimization (SSAPO) algorithm, which iteratively self-annotates preferences and adversarially reweights synthetic annotated preferences. Using only 2K seed preferences, from the UltraFeedback dataset, i.e., 1/30 of human labels in the dataset, our method achieves 35.82% GPT-4 win-rate with Mistral-7B and 40.12% with Llama3-8B-Instruct within three rounds of SSAPO.</li>
</ul>

<h3>Title: Detecting Offensive Memes with Social Biases in Singapore Context Using Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Cao Yuxuan, Wu Jiayang, Alistair Cheong Liang Chuen, Bryan Shan Guanrong, Theodore Lee Chong Jen, Sherman Chann Zhi Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18101">https://arxiv.org/abs/2502.18101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18101">https://arxiv.org/pdf/2502.18101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18101]] Detecting Offensive Memes with Social Biases in Singapore Context Using Multimodal Large Language Models(https://arxiv.org/abs/2502.18101)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Traditional online content moderation systems struggle to classify modern multimodal means of communication, such as memes, a highly nuanced and information-dense medium. This task is especially hard in a culturally diverse society like Singapore, where low-resource languages are used and extensive knowledge on local context is needed to interpret online content. We curate a large collection of 112K memes labeled by GPT-4V for fine-tuning a VLM to classify offensive memes in Singapore context. We show the effectiveness of fine-tuned VLMs on our dataset, and propose a pipeline containing OCR, translation and a 7-billion parameter-class VLM. Our solutions reach 80.62% accuracy and 0.8192 AUROC on a held-out test set, and can greatly aid human in moderating online contents. The dataset, code, and model weights will be open-sourced at this https URL.</li>
</ul>

<h3>Title: PromptMID: Modal Invariant Descriptors Based on Diffusion and Vision Foundation Models for Optical-SAR Image Matching</h3>
<ul>
<li><strong>Authors: </strong>Han Nie, Bin Luo, Jun Liu, Zhitao Fu, Huan Zhou, Shuo Zhang, Weixing Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18104">https://arxiv.org/abs/2502.18104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18104">https://arxiv.org/pdf/2502.18104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18104]] PromptMID: Modal Invariant Descriptors Based on Diffusion and Vision Foundation Models for Optical-SAR Image Matching(https://arxiv.org/abs/2502.18104)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The ideal goal of image matching is to achieve stable and efficient performance in unseen domains. However, many existing learning-based optical-SAR image matching methods, despite their effectiveness in specific scenarios, exhibit limited generalization and struggle to adapt to practical applications. Repeatedly training or fine-tuning matching models to address domain differences is not only not elegant enough but also introduces additional computational overhead and data production costs. In recent years, general foundation models have shown great potential for enhancing generalization. However, the disparity in visual domains between natural and remote sensing images poses challenges for their direct application. Therefore, effectively leveraging foundation models to improve the generalization of optical-SAR image matching remains challenge. To address the above challenges, we propose PromptMID, a novel approach that constructs modality-invariant descriptors using text prompts based on land use classification as priors information for optical and SAR image matching. PromptMID extracts multi-scale modality-invariant features by leveraging pre-trained diffusion models and visual foundation models (VFMs), while specially designed feature aggregation modules effectively fuse features across different granularities. Extensive experiments on optical-SAR image datasets from four diverse regions demonstrate that PromptMID outperforms state-of-the-art matching methods, achieving superior results in both seen and unseen domains and exhibiting strong cross-domain generalization capabilities. The source code will be made publicly available this https URL.</li>
</ul>

<h3>Title: Bayesian Optimization for Controlled Image Editing via LLMs</h3>
<ul>
<li><strong>Authors: </strong>Chengkun Cai, Haoliang Liu, Xu Zhao, Zhongyu Jiang, Tianfang Zhang, Zongkai Wu, Jenq-Neng Hwang, Serge Belongie, Lei Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18116">https://arxiv.org/abs/2502.18116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18116">https://arxiv.org/pdf/2502.18116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18116]] Bayesian Optimization for Controlled Image Editing via LLMs(https://arxiv.org/abs/2502.18116)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the rapidly evolving field of image generation, achieving precise control over generated content and maintaining semantic consistency remain significant limitations, particularly concerning grounding techniques and the necessity for model fine-tuning. To address these challenges, we propose BayesGenie, an off-the-shelf approach that integrates Large Language Models (LLMs) with Bayesian Optimization to facilitate precise and user-friendly image editing. Our method enables users to modify images through natural language descriptions without manual area marking, while preserving the original image's semantic integrity. Unlike existing techniques that require extensive pre-training or fine-tuning, our approach demonstrates remarkable adaptability across various LLMs through its model-agnostic design. BayesGenie employs an adapted Bayesian optimization strategy to automatically refine the inference process parameters, achieving high-precision image editing with minimal user intervention. Through extensive experiments across diverse scenarios, we demonstrate that our framework significantly outperforms existing methods in both editing accuracy and semantic preservation, as validated using different LLMs including Claude3 and GPT-4.</li>
</ul>

<h3>Title: EU-Nets: Enhanced, Explainable and Parsimonious U-Nets</h3>
<ul>
<li><strong>Authors: </strong>B. Sun, P. Liò</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18122">https://arxiv.org/abs/2502.18122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18122">https://arxiv.org/pdf/2502.18122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18122]] EU-Nets: Enhanced, Explainable and Parsimonious U-Nets(https://arxiv.org/abs/2502.18122)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>In this study, we propose MHEX+, a framework adaptable to any U-Net architecture. Built upon MHEX+, we introduce novel U-Net variants, EU-Nets, which enhance explainability and uncertainty estimation, addressing the limitations of traditional U-Net models while improving performance and stability. A key innovation is the Equivalent Convolutional Kernel, which unifies consecutive convolutional layers, boosting interpretability. For uncertainty estimation, we propose the collaboration gradient approach, measuring gradient consistency across decoder layers. Notably, EU-Nets achieve an average accuracy improvement of 1.389\% and a variance reduction of 0.83\% across all networks and datasets in our experiments, requiring fewer than 0.1M parameters.</li>
</ul>

<h3>Title: Personalized Federated Learning for Egocentric Video Gaze Estimation with Comprehensive Parameter Frezzing</h3>
<ul>
<li><strong>Authors: </strong>Yuhu Feng, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18123">https://arxiv.org/abs/2502.18123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18123">https://arxiv.org/pdf/2502.18123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18123]] Personalized Federated Learning for Egocentric Video Gaze Estimation with Comprehensive Parameter Frezzing(https://arxiv.org/abs/2502.18123)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, transformer</a></li>
<li><strong>Abstract: </strong>Egocentric video gaze estimation requires models to capture individual gaze patterns while adapting to diverse user data. Our approach leverages a transformer-based architecture, integrating it into a PFL framework where only the most significant parameters, those exhibiting the highest rate of change during training, are selected and frozen for personalization in client models. Through extensive experimentation on the EGTEA Gaze+ and Ego4D datasets, we demonstrate that FedCPF significantly outperforms previously reported federated learning methods, achieving superior recall, precision, and F1-score. These results confirm the effectiveness of our comprehensive parameters freezing strategy in enhancing model personalization, making FedCPF a promising approach for tasks requiring both adaptability and accuracy in federated learning settings.</li>
</ul>

<h3>Title: LevelRAG: Enhancing Retrieval-Augmented Generation with Multi-hop Logic Planning over Rewriting Augmented Searchers</h3>
<ul>
<li><strong>Authors: </strong>Zhuocheng Zhang, Yang Feng, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18139">https://arxiv.org/abs/2502.18139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18139">https://arxiv.org/pdf/2502.18139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18139]] LevelRAG: Enhancing Retrieval-Augmented Generation with Multi-hop Logic Planning over Rewriting Augmented Searchers(https://arxiv.org/abs/2502.18139)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) is a crucial method for mitigating hallucinations in Large Language Models (LLMs) and integrating external knowledge into their responses. Existing RAG methods typically employ query rewriting to clarify the user intent and manage multi-hop logic, while using hybrid retrieval to expand search scope. However, the tight coupling of query rewriting to the dense retriever limits its compatibility with hybrid retrieval, impeding further RAG performance improvements. To address this challenge, we introduce a high-level searcher that decomposes complex queries into atomic queries, independent of any retriever-specific optimizations. Additionally, to harness the strengths of sparse retrievers for precise keyword retrieval, we have developed a new sparse searcher that employs Lucene syntax to enhance retrieval this http URL web and dense searchers, these components seamlessly collaborate within our proposed method, \textbf{LevelRAG}. In LevelRAG, the high-level searcher orchestrates the retrieval logic, while the low-level searchers (sparse, web, and dense) refine the queries for optimal retrieval. This approach enhances both the completeness and accuracy of the retrieval process, overcoming challenges associated with current query rewriting techniques in hybrid retrieval scenarios. Empirical experiments conducted on five datasets, encompassing both single-hop and multi-hop question answering tasks, demonstrate the superior performance of LevelRAG compared to existing RAG methods. Notably, LevelRAG outperforms the state-of-the-art proprietary model, GPT4o, underscoring its effectiveness and potential impact on the RAG field.</li>
</ul>

<h3>Title: Actively Inferring Optimal Measurement Sequences</h3>
<ul>
<li><strong>Authors: </strong>Catherine F. Higham, Paul Henderson, Roderick Murray-Smith</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18142">https://arxiv.org/abs/2502.18142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18142">https://arxiv.org/pdf/2502.18142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18142]] Actively Inferring Optimal Measurement Sequences(https://arxiv.org/abs/2502.18142)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, generative</a></li>
<li><strong>Abstract: </strong>Measurement of a physical quantity such as light intensity is an integral part of many reconstruction and decision scenarios but can be costly in terms of acquisition time, invasion of or damage to the environment and storage. Data minimisation and compliance with data protection laws is also an important consideration. Where there are a range of measurements that can be made, some may be more informative and compliant with the overall measurement objective than others. We develop an active sequential inference algorithm that uses the low dimensional representational latent space from a variational autoencoder (VAE) to choose which measurement to make next. Our aim is to recover high dimensional data by making as few measurements as possible. We adapt the VAE encoder to map partial data measurements on to the latent space of the complete data. The algorithm draws samples from this latent space and uses the VAE decoder to generate data conditional on the partial measurements. Estimated measurements are made on the generated data and fed back through the partial VAE encoder to the latent space where they can be evaluated prior to making a measurement. Starting from no measurements and a normal prior on the latent space, we consider alternative strategies for choosing the next measurement and updating the predictive posterior prior for the next step. The algorithm is illustrated using the Fashion MNIST dataset and a novel convolutional Hadamard pattern measurement basis. We see that useful patterns are chosen within 10 steps, leading to the convergence of the guiding generative images. Compared with using stochastic variational inference to infer the parameters of the posterior distribution for each generated data point individually, the partial VAE framework can efficiently process batches of generated data and obtains superior results with minimal measurements.</li>
</ul>

<h3>Title: Jacobian Sparse Autoencoders: Sparsify Computations, Not Just Activations</h3>
<ul>
<li><strong>Authors: </strong>Lucy Farnik, Tim Lawson, Conor Houghton, Laurence Aitchison</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18147">https://arxiv.org/abs/2502.18147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18147">https://arxiv.org/pdf/2502.18147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18147]] Jacobian Sparse Autoencoders: Sparsify Computations, Not Just Activations(https://arxiv.org/abs/2502.18147)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) have been successfully used to discover sparse and human-interpretable representations of the latent activations of LLMs. However, we would ultimately like to understand the computations performed by LLMs and not just their representations. The extent to which SAEs can help us understand computations is unclear because they are not designed to "sparsify" computations in any sense, only latent activations. To solve this, we propose Jacobian SAEs (JSAEs), which yield not only sparsity in the input and output activations of a given model component but also sparsity in the computation (formally, the Jacobian) connecting them. With a naïve implementation, the Jacobians in LLMs would be computationally intractable due to their size. One key technical contribution is thus finding an efficient way of computing Jacobians in this setup. We find that JSAEs extract a relatively large degree of computational sparsity while preserving downstream LLM performance approximately as well as traditional SAEs. We also show that Jacobians are a reasonable proxy for computational sparsity because MLPs are approximately linear when rewritten in the JSAE basis. Lastly, we show that JSAEs achieve a greater degree of computational sparsity on pre-trained LLMs than on the equivalent randomized LLM. This shows that the sparsity of the computational graph appears to be a property that LLMs learn through training, and suggests that JSAEs might be more suitable for understanding learned transformer computations than standard SAEs.</li>
</ul>

<h3>Title: NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Farid Adilazuarda, Musa Izzanardi Wijanarko, Lucky Susanto, Khumaisa Nur'aini, Derry Wijaya, Alham Fikri Aji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18148">https://arxiv.org/abs/2502.18148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18148">https://arxiv.org/pdf/2502.18148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18148]] NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts(https://arxiv.org/abs/2502.18148)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Indonesia is rich in languages and scripts. However, most NLP progress has been made using romanized text. In this paper, we present NusaAksara, a novel public benchmark for Indonesian languages that includes their original scripts. Our benchmark covers both text and image modalities and encompasses diverse tasks such as image segmentation, OCR, transliteration, translation, and language identification. Our data is constructed by human experts through rigorous steps. NusaAksara covers 8 scripts across 7 languages, including low-resource languages not commonly seen in NLP benchmarks. Although unsupported by Unicode, the Lampung script is included in this dataset. We benchmark our data across several models, from LLMs and VLMs such as GPT-4o, Llama 3.2, and Aya 23 to task-specific systems such as PP-OCR and LangID, and show that most NLP technologies cannot handle Indonesia's local scripts, with many achieving near-zero performance.</li>
</ul>

<h3>Title: Joint Reconstruction of Spatially-Coherent and Realistic Clothed Humans and Objects from a Single Image</h3>
<ul>
<li><strong>Authors: </strong>Ayushi Dutta, Marco Pesavento, Marco Volino, Adrian Hilton, Armin Mustafa</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18150">https://arxiv.org/abs/2502.18150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18150">https://arxiv.org/pdf/2502.18150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18150]] Joint Reconstruction of Spatially-Coherent and Realistic Clothed Humans and Objects from a Single Image(https://arxiv.org/abs/2502.18150)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in human shape learning have focused on achieving accurate human reconstruction from single-view images. However, in the real world, humans share space with other objects. Reconstructing images with humans and objects is challenging due to the occlusions and lack of 3D spatial awareness, which leads to depth ambiguity in the reconstruction. Existing methods in monocular human-object reconstruction fail to capture intricate details of clothed human bodies and object surfaces due to their template-based nature. In this paper, we jointly reconstruct clothed humans and objects in a spatially coherent manner from single-view images, while addressing human-object occlusions. A novel attention-based neural implicit model is proposed that leverages image pixel alignment to retrieve high-quality details, and incorporates semantic features extracted from the human-object pose to enable 3D spatial awareness. A generative diffusion model is used to handle human-object occlusions. For training and evaluation, we introduce a synthetic dataset with rendered scenes of inter-occluded 3D human scans and diverse objects. Extensive evaluation on both synthetic and real datasets demonstrates the superior quality of proposed human-object reconstructions over competitive methods.</li>
</ul>

<h3>Title: SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation</h3>
<ul>
<li><strong>Authors: </strong>Dahun Shin, Dongyeop Lee, Jinseok Chung, Namhoon Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18153">https://arxiv.org/abs/2502.18153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18153">https://arxiv.org/pdf/2502.18153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18153]] SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation(https://arxiv.org/abs/2502.18153)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust</a></li>
<li><strong>Abstract: </strong>Approximate second-order optimization methods often exhibit poorer generalization compared to first-order approaches. In this work, we look into this issue through the lens of the loss landscape and find that existing second-order methods tend to converge to sharper minima compared to SGD. In response, we propose Sassha, a novel second-order method designed to enhance generalization by explicitly reducing sharpness of the solution, while stabilizing the computation of approximate Hessians along the optimization trajectory. In fact, this sharpness minimization scheme is crafted also to accommodate lazy Hessian updates, so as to secure efficiency besides flatness. To validate its effectiveness, we conduct a wide range of standard deep learning experiments where Sassha demonstrates its outstanding generalization performance that is comparable to, and mostly better than, other methods. We provide a comprehensive set of analyses including convergence, robustness, stability, efficiency, and cost.</li>
</ul>

<h3>Title: Can LLMs Explain Themselves Counterfactually?</h3>
<ul>
<li><strong>Authors: </strong>Zahra Dehghanighobadi, Asja Fischer, Muhammad Bilal Zafar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18156">https://arxiv.org/abs/2502.18156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18156">https://arxiv.org/pdf/2502.18156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18156]] Can LLMs Explain Themselves Counterfactually?(https://arxiv.org/abs/2502.18156)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Explanations are an important tool for gaining insights into the behavior of ML models, calibrating user trust and ensuring regulatory compliance. Past few years have seen a flurry of post-hoc methods for generating model explanations, many of which involve computing model gradients or solving specially designed optimization problems. However, owing to the remarkable reasoning abilities of Large Language Model (LLMs), self-explanation, that is, prompting the model to explain its outputs has recently emerged as a new paradigm. In this work, we study a specific type of self-explanations, self-generated counterfactual explanations (SCEs). We design tests for measuring the efficacy of LLMs in generating SCEs. Analysis over various LLM families, model sizes, temperature settings, and datasets reveals that LLMs sometimes struggle to generate SCEs. Even when they do, their prediction often does not agree with their own counterfactual reasoning.</li>
</ul>

<h3>Title: Monitoring snow avalanches from SAR data with deep learning</h3>
<ul>
<li><strong>Authors: </strong>Filippo Maria Bianchi, Jakob Grahn</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18157">https://arxiv.org/abs/2502.18157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18157">https://arxiv.org/pdf/2502.18157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18157]] Monitoring snow avalanches from SAR data with deep learning(https://arxiv.org/abs/2502.18157)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Snow avalanches present significant risks to human life and infrastructure, particularly in mountainous regions, making effective monitoring crucial. Traditional monitoring methods, such as field observations, are limited by accessibility, weather conditions, and cost. Satellite-borne Synthetic Aperture Radar (SAR) data has become an important tool for large-scale avalanche detection, as it can capture data in all weather conditions and across remote areas. However, traditional processing methods struggle with the complexity and variability of avalanches. This chapter reviews the application of deep learning for detecting and segmenting snow avalanches from SAR data. Early efforts focused on the binary classification of SAR images, while recent advances have enabled pixel-level segmentation, providing greater accuracy and spatial resolution. A case study using Sentinel-1 SAR data demonstrates the effectiveness of deep learning models for avalanche segmentation, achieving superior results over traditional methods. We also present an extension of this work, testing recent state-of-the-art segmentation architectures on an expanded dataset of over 4,500 annotated SAR images. The best-performing model among those tested was applied for large-scale avalanche detection across the whole of Norway, revealing important spatial and temporal patterns over several winter seasons.</li>
</ul>

<h3>Title: SECURA: Sigmoid-Enhanced CUR Decomposition with Uninterrupted Retention and Low-Rank Adaptation in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhang Yuxuan, Li Ruizhe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18168">https://arxiv.org/abs/2502.18168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18168">https://arxiv.org/pdf/2502.18168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18168]] SECURA: Sigmoid-Enhanced CUR Decomposition with Uninterrupted Retention and Low-Rank Adaptation in Large Language Models(https://arxiv.org/abs/2502.18168)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid development of large language models (LLMs), fully fine-tuning (FT) these models has become increasingly impractical due to the high computational demands. Additionally, FT can lead to catastrophic forgetting. As an alternative, Low-Rank Adaptation (LoRA) has been proposed, which fine-tunes only a small subset of parameters, achieving similar performance to FT while significantly reducing resource requirements. However, since LoRA inherits FT's design, the issue of catastrophic forgetting remains. To address these challenges, we propose SECURA: Sigmoid-Enhanced CUR Decomposition LoRA, a novel parameter-efficient fine-tuning (PEFT) variant that mitigates catastrophic forgetting while improving fine-tuning performance. Our method introduces a new normalization technique, SigNorm, to enhance parameter retention and overall performance. SECURA has been evaluated on a variety of tasks, including mathematical problem-solving (GSM8K), challenging question-answering (CNNDM), translation (NewsDE), and complex multiple-choice reasoning (LogiQA). Experimental results show that SECURA achieves an average fine-tuning improvement of 3.59% across four multiple-choice question (MCQ) tasks and a 2.51% improvement across five question-answering (QA) tasks on models such as Gemma2 2b, Qwen2 1.5b, Qwen 2 7b, Llama3 8b, and Llama3.1 8b, compared to DoRA. Moreover, SECURA demonstrates superior knowledge retention capabilities, maintaining more than 70% accuracy on basic LLM knowledge across 16 continual learning tests, outperforming Experience Replay (ER), Sequential Learning (SEQ), EWC, I-LoRA, and CUR-LoRA.</li>
</ul>

<h3>Title: CLIPure: Purification in Latent Space via CLIP for Adversarially Robust Zero-Shot Classification</h3>
<ul>
<li><strong>Authors: </strong>Mingkun Zhang, Keping Bi, Wei Chen, Jiafeng Guo, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18176">https://arxiv.org/abs/2502.18176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18176">https://arxiv.org/pdf/2502.18176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18176]] CLIPure: Purification in Latent Space via CLIP for Adversarially Robust Zero-Shot Classification(https://arxiv.org/abs/2502.18176)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we aim to build an adversarially robust zero-shot image classifier. We ground our work on CLIP, a vision-language pre-trained encoder model that can perform zero-shot classification by matching an image with text prompts ``a photo of a <class-name>.''. Purification is the path we choose since it does not require adversarial training on specific attack types and thus can cope with any foreseen attacks. We then formulate purification risk as the KL divergence between the joint distributions of the purification process of denoising the adversarial samples and the attack process of adding perturbations to benign samples, through bidirectional Stochastic Differential Equations (SDEs). The final derived results inspire us to explore purification in the multi-modal latent space of CLIP. We propose two variants for our CLIPure approach: CLIPure-Diff which models the likelihood of images' latent vectors with the DiffusionPrior module in DaLLE-2 (modeling the generation process of CLIP's latent vectors), and CLIPure-Cos which models the likelihood with the cosine similarity between the embeddings of an image and ``a photo of a.''. As far as we know, CLIPure is the first purification method in multi-modal latent space and CLIPure-Cos is the first purification method that is not based on generative models, which substantially improves defense efficiency. We conducted extensive experiments on CIFAR-10, ImageNet, and 13 datasets that previous CLIP-based defense methods used for evaluating zero-shot classification robustness. Results show that CLIPure boosts the SOTA robustness by a large margin, e.g., from 71.7% to 91.1% on CIFAR10, from 59.6% to 72.6% on ImageNet, and 108% relative improvements of average robustness on the 13 datasets over previous SOTA. The code is available at this https URL.</li>
</ul>

<h3>Title: Problem Solved? Information Extraction Design Space for Layout-Rich Documents using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Gaye Colakoglu, Gürkan Solmaz, Jonathan Fürst</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18179">https://arxiv.org/abs/2502.18179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18179">https://arxiv.org/pdf/2502.18179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18179]] Problem Solved? Information Extraction Design Space for Layout-Rich Documents using LLMs(https://arxiv.org/abs/2502.18179)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This paper defines and explores the design space for information extraction (IE) from layout-rich documents using large language models (LLMs). The three core challenges of layout-aware IE with LLMs are 1) data structuring, 2) model engagement, and 3) output refinement. Our study delves into the sub-problems within these core challenges, such as input representation, chunking, prompting, and selection of LLMs and multimodal models. It examines the outcomes of different design choices through a new layout-aware IE test suite, benchmarking against the state-of-art (SoA) model LayoutLMv3. The results show that the configuration from one-factor-at-a-time (OFAT) trial achieves near-optimal results with 14.1 points F1-score gain from the baseline model, while full factorial exploration yields only a slightly higher 15.1 points gain at around 36x greater token usage. We demonstrate that well-configured general-purpose LLMs can match the performance of specialized models, providing a cost-effective alternative. Our test-suite is freely available at this https URL.</li>
</ul>

<h3>Title: Multi-Perspective Data Augmentation for Few-shot Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Anh-Khoa Nguyen Vu, Quoc-Truong Truong, Vinh-Tiep Nguyen, Thanh Duc Ngo, Thanh-Toan Do, Tam V. Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18195">https://arxiv.org/abs/2502.18195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18195">https://arxiv.org/pdf/2502.18195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18195]] Multi-Perspective Data Augmentation for Few-shot Object Detection(https://arxiv.org/abs/2502.18195)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent few-shot object detection (FSOD) methods have focused on augmenting synthetic samples for novel classes, show promising results to the rise of diffusion models. However, the diversity of such datasets is often limited in representativeness because they lack awareness of typical and hard samples, especially in the context of foreground and background relationships. To tackle this issue, we propose a Multi-Perspective Data Augmentation (MPAD) framework. In terms of foreground-foreground relationships, we propose in-context learning for object synthesis (ICOS) with bounding box adjustments to enhance the detail and spatial information of synthetic samples. Inspired by the large margin principle, support samples play a vital role in defining class boundaries. Therefore, we design a Harmonic Prompt Aggregation Scheduler (HPAS) to mix prompt embeddings at each time step of the generation process in diffusion models, producing hard novel samples. For foreground-background relationships, we introduce a Background Proposal method (BAP) to sample typical and hard backgrounds. Extensive experiments on multiple FSOD benchmarks demonstrate the effectiveness of our approach. Our framework significantly outperforms traditional methods, achieving an average increase of $17.5\%$ in nAP50 over the baseline on PASCAL VOC. Code is available at this https URL.</li>
</ul>

<h3>Title: Training Consistency Models with Variational Noise Coupling</h3>
<ul>
<li><strong>Authors: </strong>Gianluigi Silvestri, Luca Ambrogioni, Chieh-Hsin Lai, Yuhta Takida, Yuki Mitsufuji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18197">https://arxiv.org/abs/2502.18197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18197">https://arxiv.org/pdf/2502.18197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18197]] Training Consistency Models with Variational Noise Coupling(https://arxiv.org/abs/2502.18197)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Consistency Training (CT) has recently emerged as a promising alternative to diffusion models, achieving competitive performance in image generation tasks. However, non-distillation consistency training often suffers from high variance and instability, and analyzing and improving its training dynamics is an active area of research. In this work, we propose a novel CT training approach based on the Flow Matching framework. Our main contribution is a trained noise-coupling scheme inspired by the architecture of Variational Autoencoders (VAE). By training a data-dependent noise emission model implemented as an encoder architecture, our method can indirectly learn the geometry of the noise-to-data mapping, which is instead fixed by the choice of the forward process in classical CT. Empirical results across diverse image datasets show significant generative improvements, with our model outperforming baselines and achieving the state-of-the-art (SoTA) non-distillation CT FID on CIFAR-10, and attaining FID on par with SoTA on ImageNet at $64 \times 64$ resolution in 2-step generation. Our code is available at this https URL .</li>
</ul>

<h3>Title: DenoMAE2.0: Improving Denoising Masked Autoencoders by Classifying Local Patches</h3>
<ul>
<li><strong>Authors: </strong>Atik Faysal, Mohammad Rostami, Taha Boushine, Reihaneh Gh. Roshan, Huaxia Wang, Nikhil Muralidhar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18202">https://arxiv.org/abs/2502.18202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18202">https://arxiv.org/pdf/2502.18202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18202]] DenoMAE2.0: Improving Denoising Masked Autoencoders by Classifying Local Patches(https://arxiv.org/abs/2502.18202)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce DenoMAE2.0, an enhanced denoising masked autoencoder that integrates a local patch classification objective alongside traditional reconstruction loss to improve representation learning and robustness. Unlike conventional Masked Autoencoders (MAE), which focus solely on reconstructing missing inputs, DenoMAE2.0 introduces position-aware classification of unmasked patches, enabling the model to capture fine-grained local features while maintaining global coherence. This dual-objective approach is particularly beneficial in semi-supervised learning for wireless communication, where high noise levels and data scarcity pose significant challenges. We conduct extensive experiments on modulation signal classification across a wide range of signal-to-noise ratios (SNRs), from extremely low to moderately high conditions and in a low data regime. Our results demonstrate that DenoMAE2.0 surpasses its predecessor, Deno-MAE, and other baselines in both denoising quality and downstream classification accuracy. DenoMAE2.0 achieves a 1.1% improvement over DenoMAE on our dataset and 11.83%, 16.55% significant improved accuracy gains on the RadioML benchmark, over DenoMAE, for constellation diagram classification of modulation signals.</li>
</ul>

<h3>Title: Grandes modelos de lenguaje: de la predicción de palabras a la comprensión?</h3>
<ul>
<li><strong>Authors: </strong>Carlos Gómez-Rodríguez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18205">https://arxiv.org/abs/2502.18205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18205">https://arxiv.org/pdf/2502.18205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18205]] Grandes modelos de lenguaje: de la predicción de palabras a la comprensión?(https://arxiv.org/abs/2502.18205)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models, such as the well-known ChatGPT, have brought about an unexpected revolution in the field of artificial intelligence. On the one hand, they have numerous practical applications and enormous potential still to be explored. On the other hand, they are also the subject of debate from scientific, philosophical, and social perspectives: there are doubts about the exact mechanisms of their functioning and their actual capacity for language comprehension, and their applications raise ethical dilemmas. In this chapter, we describe how this technology has been developed and the fundamentals of its operation, allowing us to better understand its capabilities and limitations and to introduce some of the main debates surrounding its development and use. -- Los grandes modelos de lenguaje, como el conocido ChatGPT, han supuesto una inesperada revolución en el ámbito de la inteligencia artificial. Por un lado, cuentan con multitud de aplicaciones prácticas y un enorme potencial todavía por explorar. Por otro lado, son también objeto de debate, tanto desde el punto de vista científico y filosófico como social: hay dudas sobre los mecanismos exactos de su funcionamiento y su capacidad real de comprensión del lenguaje, y sus aplicaciones plantean dilemas éticos. En este capítulo describimos cómo se ha llegado a esta tecnología y los fundamentos de su funcionamiento, permitiéndonos así comprender mejor sus capacidades y limitaciones e introducir algunos de los principales debates que rodean su desarrollo y uso.</li>
</ul>

<h3>Title: LAG: LLM agents for Leaderboard Auto Generation on Demanding</h3>
<ul>
<li><strong>Authors: </strong>Jian Wu, Jiayu Zhang, Dongyuan Li, Linyi Yang, Aoxiao Zhong, Renhe Jiang, Qingsong Wen, Yue Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18209">https://arxiv.org/abs/2502.18209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18209">https://arxiv.org/pdf/2502.18209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18209]] LAG: LLM agents for Leaderboard Auto Generation on Demanding(https://arxiv.org/abs/2502.18209)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, fair, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces Leaderboard Auto Generation (LAG), a novel and well-organized framework for automatic generation of leaderboards on a given research topic in rapidly evolving fields like Artificial Intelligence (AI). Faced with a large number of AI papers updated daily, it becomes difficult for researchers to track every paper's proposed methods, experimental results, and settings, prompting the need for efficient automatic leaderboard construction. While large language models (LLMs) offer promise in automating this process, challenges such as multi-document summarization, leaderboard generation, and experiment fair comparison still remain under exploration. LAG solves these challenges through a systematic approach that involves the paper collection, experiment results extraction and integration, leaderboard generation, and quality evaluation. Our contributions include a comprehensive solution to the leaderboard construction problem, a reliable evaluation method, and experimental results showing the high quality of leaderboards.</li>
</ul>

<h3>Title: Learning Structure-Supporting Dependencies via Keypoint Interactive Transformer for General Mammal Pose Estimation</h3>
<ul>
<li><strong>Authors: </strong>Tianyang Xu, Jiyong Rao, Xiaoning Song, Zhenhua Feng, Xiao-Jun Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18214">https://arxiv.org/abs/2502.18214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18214">https://arxiv.org/pdf/2502.18214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18214]] Learning Structure-Supporting Dependencies via Keypoint Interactive Transformer for General Mammal Pose Estimation(https://arxiv.org/abs/2502.18214)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>General mammal pose estimation is an important and challenging task in computer vision, which is essential for understanding mammal behaviour in real-world applications. However, existing studies are at their preliminary research stage, which focus on addressing the problem for only a few specific mammal species. In principle, from specific to general mammal pose estimation, the biggest issue is how to address the huge appearance and pose variances for different species. We argue that given appearance context, instance-level prior and the structural relation among keypoints can serve as complementary evidence. To this end, we propose a Keypoint Interactive Transformer (KIT) to learn instance-level structure-supporting dependencies for general mammal pose estimation. Specifically, our KITPose consists of two coupled components. The first component is to extract keypoint features and generate body part prompts. The features are supervised by a dedicated generalised heatmap regression loss (GHRL). Instead of introducing external visual/text prompts, we devise keypoints clustering to generate body part biases, aligning them with image context to generate corresponding instance-level prompts. Second, we propose a novel interactive transformer that takes feature slices as input tokens without performing spatial splitting. In addition, to enhance the capability of the KIT model, we design an adaptive weight strategy to address the imbalance issue among different keypoints.</li>
</ul>

<h3>Title: Synthesizing Consistent Novel Views via 3D Epipolar Attention without Re-Training</h3>
<ul>
<li><strong>Authors: </strong>Botao Ye, Sifei Liu, Xueting Li, Marc Pollefeys, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18219">https://arxiv.org/abs/2502.18219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18219">https://arxiv.org/pdf/2502.18219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18219]] Synthesizing Consistent Novel Views via 3D Epipolar Attention without Re-Training(https://arxiv.org/abs/2502.18219)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Large diffusion models demonstrate remarkable zero-shot capabilities in novel view synthesis from a single image. However, these models often face challenges in maintaining consistency across novel and reference views. A crucial factor leading to this issue is the limited utilization of contextual information from reference views. Specifically, when there is an overlap in the viewing frustum between two views, it is essential to ensure that the corresponding regions maintain consistency in both geometry and appearance. This observation leads to a simple yet effective approach, where we propose to use epipolar geometry to locate and retrieve overlapping information from the input view. This information is then incorporated into the generation of target views, eliminating the need for training or fine-tuning, as the process requires no learnable parameters. Furthermore, to enhance the overall consistency of generated views, we extend the utilization of epipolar attention to a multi-view setting, allowing retrieval of overlapping information from the input view and other target views. Qualitative and quantitative experimental results demonstrate the effectiveness of our method in significantly improving the consistency of synthesized views without the need for any fine-tuning. Moreover, This enhancement also boosts the performance of downstream applications such as 3D reconstruction. The code is available at this https URL.</li>
</ul>

<h3>Title: Multi-label out-of-distribution detection via evidential learning</h3>
<ul>
<li><strong>Authors: </strong>Eduardo Aguilar, Bogdan Raducanu, Petia Radeva</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18224">https://arxiv.org/abs/2502.18224</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18224">https://arxiv.org/pdf/2502.18224</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18224]] Multi-label out-of-distribution detection via evidential learning(https://arxiv.org/abs/2502.18224)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A crucial requirement for machine learning algorithms is not only to perform well, but also to show robustness and adaptability when encountering novel scenarios. One way to achieve these characteristics is to endow the deep learning models with the ability to detect out-of-distribution (OOD) data, i.e. data that belong to distributions different from the one used during their training. It is even a more complicated situation, when these data usually are multi-label. In this paper, we propose an approach based on evidential deep learning in order to meet these challenges applied to visual recognition problems. More concretely, we designed a CNN architecture that uses a Beta Evidential Neural Network to compute both the likelihood and the predictive uncertainty of the samples. Based on these results, we propose afterwards two new uncertainty-based scores for OOD data detection: (i) OOD - score Max, based on the maximum evidence; and (ii) OOD score - Sum, which considers the evidence from all outputs. Extensive experiments have been carried out to validate the proposed approach using three widely-used datasets: PASCAL-VOC, MS-COCO and NUS-WIDE, demonstrating its outperformance over several State-of-the-Art methods.</li>
</ul>

<h3>Title: TLDP: An Algorithm of Local Differential Privacy for Tensors</h3>
<ul>
<li><strong>Authors: </strong>Yachao Yuan, Xiao Tang, Yu Huang, Jin Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18227">https://arxiv.org/abs/2502.18227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18227">https://arxiv.org/pdf/2502.18227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18227]] TLDP: An Algorithm of Local Differential Privacy for Tensors(https://arxiv.org/abs/2502.18227)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Tensor-valued data, increasingly common in applications like spatiotemporal modeling and social networks, pose unique challenges for privacy protection due to their multidimensional structure and the risk of losing critical structural information. Traditional local differential privacy (LDP) methods, designed for scalars and matrices, are insufficient for tensors, as they fail to preserve essential relationships among tensor elements. We introduce TLDP, a novel \emph{LDP} algorithm for \emph{T}ensors, which employs a randomized response mechanism to perturb tensor components while maintaining structural integrity. To strike a better balance between utility and privacy, we incorporate a weight matrix that selectively protects sensitive regions. Both theoretical analysis and empirical findings from real-world datasets show that TLDP achieves superior utility while preserving privacy, making it a robust solution for high-dimensional data.</li>
</ul>

<h3>Title: Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent</h3>
<ul>
<li><strong>Authors: </strong>Xiaofeng Wang, Zhixin Zhang, Jinguang Zheng, Yiming Ai, Rui Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18228">https://arxiv.org/abs/2502.18228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18228">https://arxiv.org/pdf/2502.18228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18228]] Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent(https://arxiv.org/abs/2502.18228)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Debt collection negotiations (DCN) are vital for managing non-performing loans (NPLs) and reducing creditor losses. Traditional methods are labor-intensive, while large language models (LLMs) offer promising automation potential. However, prior systems lacked dynamic negotiation and real-time decision-making capabilities. This paper explores LLMs in automating DCN and proposes a novel evaluation framework with 13 metrics across 4 aspects. Our experiments reveal that LLMs tend to over-concede compared to human negotiators. To address this, we propose the Multi-Agent Debt Negotiation (MADeN) framework, incorporating planning and judging modules to improve decision rationality. We also apply post-training techniques, including DPO with rejection sampling, to optimize performance. Our studies provide valuable insights for practitioners and researchers seeking to enhance efficiency and outcomes in this domain.</li>
</ul>

<h3>Title: Beyond the convexity assumption: Realistic tabular data generation under quantifier-free real linear constraints</h3>
<ul>
<li><strong>Authors: </strong>Mihaela Cătălina Stoian, Eleonora Giunchiglia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18237">https://arxiv.org/abs/2502.18237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18237">https://arxiv.org/pdf/2502.18237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18237]] Beyond the convexity assumption: Realistic tabular data generation under quantifier-free real linear constraints(https://arxiv.org/abs/2502.18237)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Synthetic tabular data generation has traditionally been a challenging problem due to the high complexity of the underlying distributions that characterise this type of data. Despite recent advances in deep generative models (DGMs), existing methods often fail to produce realistic datapoints that are well-aligned with available background knowledge. In this paper, we address this limitation by introducing Disjunctive Refinement Layer (DRL), a novel layer designed to enforce the alignment of generated data with the background knowledge specified in user-defined constraints. DRL is the first method able to automatically make deep learning models inherently compliant with constraints as expressive as quantifier-free linear formulas, which can define non-convex and even disconnected spaces. Our experimental analysis shows that DRL not only guarantees constraint satisfaction but also improves efficacy in downstream tasks. Notably, when applied to DGMs that frequently violate constraints, DRL eliminates violations entirely. Further, it improves performance metrics by up to 21.4% in F1-score and 20.9% in Area Under the ROC Curve, thus demonstrating its practical impact on data generation.</li>
</ul>

<h3>Title: Unveiling and Causalizing CoT: A Causal Pespective</h3>
<ul>
<li><strong>Authors: </strong>Jiarun Fu, Lizhong Ding, Hao Li, Pengqi Li, Qiuning Wei, Xu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18239">https://arxiv.org/abs/2502.18239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18239">https://arxiv.org/pdf/2502.18239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18239]] Unveiling and Causalizing CoT: A Causal Pespective(https://arxiv.org/abs/2502.18239)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although Chain-of-Thought (CoT) has achieved remarkable success in enhancing the reasoning ability of large language models (LLMs), the mechanism of CoT remains a ``black box''. Even if the correct answers can frequently be obtained, existing CoTs struggle to make the reasoning understandable to human. In this paper, we unveil and causalize CoT from a causal perspective to ensure both correctness and understandability of all reasoning steps (to the best of our knowledge, the first such). We model causality of CoT via structural causal models (SCM) to unveil the reasoning mechanism of CoT. To measure the causality of CoT, we define the CoT Average Causal Effect (CACE) to test the causal relations between steps. For those steps without causality (wrong or unintelligible steps), we design a role-playing causal query algorithm to causalize these steps, resulting a causalized CoT with all steps correct and understandable. Experimental results on both open-source and closed-source LLMs demonstrate that the causal errors commonly in steps are effectively corrected and the reasoning ability of LLMs is significantly improved.</li>
</ul>

<h3>Title: Causal AI-based Root Cause Identification: Research to Practice at Scale</h3>
<ul>
<li><strong>Authors: </strong>Saurabh Jha, Ameet Rahane, Laura Shwartz, Marc Palaci-Olgun, Frank Bagehorn, Jesus Rios, Dan Stingaciu, Ragu Kattinakere, Debasish Banerjee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18240">https://arxiv.org/abs/2502.18240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18240">https://arxiv.org/pdf/2502.18240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18240]] Causal AI-based Root Cause Identification: Research to Practice at Scale(https://arxiv.org/abs/2502.18240)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern applications are built as large, distributed systems spanning numerous modules, teams, and data centers. Despite robust engineering and recovery strategies, failures and performance issues remain inevitable, risking significant disruptions and affecting end users. Rapid and accurate root cause identification is therefore vital to ensure system reliability and maintain key service metrics. We have developed a novel causality-based Root Cause Identification (RCI) algorithm that emphasizes causation over correlation. This algorithm has been integrated into IBM Instana-bridging research to practice at scale-and is now in production use by enterprise customers. By leveraging "causal AI," Instana stands apart from typical Application Performance Management (APM) tools, pinpointing issues in near real-time. This paper highlights Instana's advanced failure diagnosis capabilities, discussing both the theoretical underpinnings and practical implementations of the RCI algorithm. Real-world examples illustrate how our causality-based approach enhances reliability and performance in today's complex system landscapes.</li>
</ul>

<h3>Title: Beyond In-Distribution Success: Scaling Curves of CoT Granularity for Language Model Generalization</h3>
<ul>
<li><strong>Authors: </strong>Ru Wang, Wei Huang, Selena Song, Haoyu Zhang, Yusuke Iwasawa, Yutaka Matsuo, Jiaxian Guo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18273">https://arxiv.org/abs/2502.18273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18273">https://arxiv.org/pdf/2502.18273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18273]] Beyond In-Distribution Success: Scaling Curves of CoT Granularity for Language Model Generalization(https://arxiv.org/abs/2502.18273)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Generalization to novel compound tasks under distribution shift is important for deploying transformer-based language models (LMs). This work investigates Chain-of-Thought (CoT) reasoning as a means to enhance OOD generalization. Through controlled experiments across several compound tasks, we reveal three key insights: (1) While QA-trained models achieve near-perfect in-distribution accuracy, their OOD performance degrades catastrophically, even with 10000k+ training examples; (2) the granularity of CoT data strongly correlates with generalization performance; finer-grained CoT data leads to better generalization; (3) CoT exhibits remarkable sample efficiency, matching QA performance with much less (even 80%) data. Theoretically, we demonstrate that compound tasks inherently permit shortcuts in Q-A data that misalign with true reasoning principles, while CoT forces internalization of valid dependency structures, and thus can achieve better generalization. Further, we show that transformer positional embeddings can amplify generalization by emphasizing subtask condition recurrence in long CoT sequences. Our combined theoretical and empirical analysis provides compelling evidence for CoT reasoning as a crucial training paradigm for enabling LM generalization under real-world distributional shifts for compound tasks.</li>
</ul>

<h3>Title: Self-Adjust Softmax</h3>
<ul>
<li><strong>Authors: </strong>Chuanyang Zheng, Yihang Gao, Guoxuan Chen, Han Shi, Jing Xiong, Xiaozhe Ren, Chao Huang, Xin Jiang, Zhenguo Li, Yu Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18277">https://arxiv.org/abs/2502.18277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18277">https://arxiv.org/pdf/2502.18277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18277]] Self-Adjust Softmax(https://arxiv.org/abs/2502.18277)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The softmax function is crucial in Transformer attention, which normalizes each row of the attention scores with summation to one, achieving superior performances over other alternative functions. However, the softmax function can face a gradient vanishing issue when some elements of the attention scores approach extreme values, such as probabilities close to one or zero. In this paper, we propose Self-Adjust Softmax (SA-Softmax) to address this issue by modifying $softmax(x)$ to $x \cdot softmax(x)$ and its normalized variant $\frac{(x - min(x_{\min},0))}{max(0,x_{max})-min(x_{min},0)} \cdot softmax(x)$. We theoretically show that SA-Softmax provides enhanced gradient properties compared to the vanilla softmax function. Moreover, SA-Softmax Attention can be seamlessly integrated into existing Transformer models to their attention mechanisms with minor adjustments. We conducted experiments to evaluate the empirical performance of Transformer models using SA-Softmax compared to the vanilla softmax function. These experiments, involving models with up to 2.7 billion parameters, are conducted across diverse datasets, language tasks, and positional encoding methods.</li>
</ul>

<h3>Title: Better Aligned with Survey Respondents or Training Data? Unveiling Political Leanings of LLMs on U.S. Supreme Court Cases</h3>
<ul>
<li><strong>Authors: </strong>Shanshan Xu, T.Y.S.S Santosh, Yanai Elazar, Quirin Vogel, Barbara Plank, Matthias Grabmair</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18282">https://arxiv.org/abs/2502.18282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18282">https://arxiv.org/pdf/2502.18282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18282]] Better Aligned with Survey Respondents or Training Data? Unveiling Political Leanings of LLMs on U.S. Supreme Court Cases(https://arxiv.org/abs/2502.18282)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The increased adoption of Large Language Models (LLMs) and their potential to shape public opinion have sparked interest in assessing these models' political leanings. Building on previous research that compared LLMs and human opinions and observed political bias in system responses, we take a step further to investigate the underlying causes of such biases by empirically examining how the values and biases embedded in training corpora shape model outputs. Specifically, we propose a method to quantitatively evaluate political leanings embedded in the large pretraining corpora. Subsequently we investigate to whom are the LLMs' political leanings more aligned with, their pretrainig corpora or the surveyed human opinions. As a case study, we focus on probing the political leanings of LLMs in 32 U.S. Supreme Court cases, addressing contentious topics such as abortion and voting rights. Our findings reveal that LLMs strongly reflect the political leanings in their training data, and no strong correlation is observed with their alignment to human opinions as expressed in surveys. These results underscore the importance of responsible curation of training data and the need for robust evaluation metrics to ensure LLMs' alignment with human-centered values.</li>
</ul>

<h3>Title: Uncertainty Modeling in Multimodal Speech Analysis Across the Psychosis Spectrum</h3>
<ul>
<li><strong>Authors: </strong>Morteza Rohanian, Roya M. Hüppi, Farhad Nooralahzadeh, Noemi Dannecker, Yves Pauli, Werner Surbeck, Iris Sommer, Wolfram Hinzen, Nicolas Langer, Michael Krauthammer, Philipp Homan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18285">https://arxiv.org/abs/2502.18285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18285">https://arxiv.org/pdf/2502.18285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18285]] Uncertainty Modeling in Multimodal Speech Analysis Across the Psychosis Spectrum(https://arxiv.org/abs/2502.18285)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Capturing subtle speech disruptions across the psychosis spectrum is challenging because of the inherent variability in speech patterns. This variability reflects individual differences and the fluctuating nature of symptoms in both clinical and non-clinical populations. Accounting for uncertainty in speech data is essential for predicting symptom severity and improving diagnostic precision. Speech disruptions characteristic of psychosis appear across the spectrum, including in non-clinical individuals. We develop an uncertainty-aware model integrating acoustic and linguistic features to predict symptom severity and psychosis-related traits. Quantifying uncertainty in specific modalities allows the model to address speech variability, improving prediction accuracy. We analyzed speech data from 114 participants, including 32 individuals with early psychosis and 82 with low or high schizotypy, collected through structured interviews, semi-structured autobiographical tasks, and narrative-driven interactions in German. The model improved prediction accuracy, reducing RMSE and achieving an F1-score of 83% with ECE = 4.5e-2, showing robust performance across different interaction contexts. Uncertainty estimation improved model interpretability by identifying reliability differences in speech markers such as pitch variability, fluency disruptions, and spectral instability. The model dynamically adjusted to task structures, weighting acoustic features more in structured settings and linguistic features in unstructured contexts. This approach strengthens early detection, personalized assessment, and clinical decision-making in psychosis-spectrum research.</li>
</ul>

<h3>Title: Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhaoyi Liu, Huan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18290">https://arxiv.org/abs/2502.18290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18290">https://arxiv.org/pdf/2502.18290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18290]] Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models(https://arxiv.org/abs/2502.18290)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>Self-supervised learning (SSL) vision encoders learn high-quality image representations and thus have become a vital part of developing vision modality of large vision language models (LVLMs). Due to the high cost of training such encoders, pre-trained encoders are widely shared and deployed into many LVLMs, which are security-critical or bear societal significance. Under this practical scenario, we reveal a new backdoor threat that significant visual hallucinations can be induced into these LVLMs by merely compromising vision encoders. Because of the sharing and reuse of these encoders, many downstream LVLMs may inherit backdoor behaviors from encoders, leading to widespread backdoors. In this work, we propose BadVision, the first method to exploit this vulnerability in SSL vision encoders for LVLMs with novel trigger optimization and backdoor learning techniques. We evaluate BadVision on two types of SSL encoders and LVLMs across eight benchmarks. We show that BadVision effectively drives the LVLMs to attacker-chosen hallucination with over 99% attack success rate, causing a 77.6% relative visual understanding error while maintaining the stealthiness. SoTA backdoor detection methods cannot detect our attack effectively.</li>
</ul>

<h3>Title: AMPO: Active Multi-Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Taneesh Gupta, Rahul Madhavan, Xuchao Zhang, Chetan Bansal, Saravan Rajmohan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18293">https://arxiv.org/abs/2502.18293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18293">https://arxiv.org/pdf/2502.18293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18293]] AMPO: Active Multi-Preference Optimization(https://arxiv.org/abs/2502.18293)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multi-preference optimization enriches language-model alignment beyond pairwise preferences by contrasting entire sets of helpful and undesired responses, thereby enabling richer training signals for large language models. During self-play alignment, these models often produce numerous candidate answers per query, rendering it computationally infeasible to include all responses in the training objective. In this work, we propose $\textit{Active Multi-Preference Optimization}$ (AMPO), a novel approach that combines on-policy generation, a multi-preference group-contrastive loss, and active subset selection. Specifically, we score and embed large candidate pools of responses and then select a small, yet informative, subset that covers reward extremes and distinct semantic clusters for preference optimization. Our contrastive training scheme is capable of identifying not only the best and worst answers but also subtle, underexplored modes that are crucial for robust alignment. Theoretically, we provide guarantees for expected reward maximization using our active selection method, and empirically, AMPO achieves state-of-the-art results on $\textit{AlpacaEval}$ using Llama 8B.</li>
</ul>

<h3>Title: DeepCircuitX: A Comprehensive Repository-Level Dataset for RTL Code Understanding, Generation, and PPA Analysis</h3>
<ul>
<li><strong>Authors: </strong>Zeju Li, Changran Xu, Zhengyuan Shi, Zedong Peng, Yi Liu, Yunhao Zhou, Lingfeng Zhou, Chengyu Ma, Jianyuan Zhong, Xi Wang, Jieru Zhao, Zhufei Chu, Xiaoyan Yang, Qiang Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18297">https://arxiv.org/abs/2502.18297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18297">https://arxiv.org/pdf/2502.18297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18297]] DeepCircuitX: A Comprehensive Repository-Level Dataset for RTL Code Understanding, Generation, and PPA Analysis(https://arxiv.org/abs/2502.18297)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces DeepCircuitX, a comprehensive repository-level dataset designed to advance RTL (Register Transfer Level) code understanding, generation, and power-performance-area (PPA) analysis. Unlike existing datasets that are limited to either file-level RTL code or physical layout data, DeepCircuitX provides a holistic, multilevel resource that spans repository, file, module, and block-level RTL code. This structure enables more nuanced training and evaluation of large language models (LLMs) for RTL-specific tasks. DeepCircuitX is enriched with Chain of Thought (CoT) annotations, offering detailed descriptions of functionality and structure at multiple levels. These annotations enhance its utility for a wide range of tasks, including RTL code understanding, generation, and completion. Additionally, the dataset includes synthesized netlists and PPA metrics, facilitating early-stage design exploration and enabling accurate PPA prediction directly from RTL code. We demonstrate the dataset's effectiveness on various LLMs finetuned with our dataset and confirm the quality with human evaluations. Our results highlight DeepCircuitX as a critical resource for advancing RTL-focused machine learning applications in hardware design this http URL data is available at this https URL.</li>
</ul>

<h3>Title: Bayesian Computation in Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenlong Chen, Bolian Li, Ruqi Zhang, Yingzhen Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18300">https://arxiv.org/abs/2502.18300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18300">https://arxiv.org/pdf/2502.18300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18300]] Bayesian Computation in Deep Learning(https://arxiv.org/abs/2502.18300)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This review paper is intended for the 2nd edition of the Handbook of Markov chain Monte this http URL provide an introduction to approximate inference techniques as Bayesian computation methods applied to deep learning models. We organize the chapter by presenting popular computational methods for (1) Bayesian neural networks and (2) deep generative models, explaining their unique challenges in posterior inference as well as the solutions.</li>
</ul>

<h3>Title: LDGen: Enhancing Text-to-Image Synthesis via Large Language Model-Driven Language Representation</h3>
<ul>
<li><strong>Authors: </strong>Pengzhi Li, Pengfei Yu, Zide Liu, Wei He, Xuhao Pan, Xudong Rao, Tao Wei, Wei Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18302">https://arxiv.org/abs/2502.18302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18302">https://arxiv.org/pdf/2502.18302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18302]] LDGen: Enhancing Text-to-Image Synthesis via Large Language Model-Driven Language Representation(https://arxiv.org/abs/2502.18302)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce LDGen, a novel method for integrating large language models (LLMs) into existing text-to-image diffusion models while minimizing computational demands. Traditional text encoders, such as CLIP and T5, exhibit limitations in multilingual processing, hindering image generation across diverse languages. We address these challenges by leveraging the advanced capabilities of LLMs. Our approach employs a language representation strategy that applies hierarchical caption optimization and human instruction techniques to derive precise semantic information,. Subsequently, we incorporate a lightweight adapter and a cross-modal refiner to facilitate efficient feature alignment and interaction between LLMs and image features. LDGen reduces training time and enables zero-shot multilingual image generation. Experimental results indicate that our method surpasses baseline models in both prompt adherence and image aesthetic quality, while seamlessly supporting multiple languages. Project page: this https URL.</li>
</ul>

<h3>Title: Experimental Analysis of Efficiency of the Messaging Layer Security for Multiple Delivery Services</h3>
<ul>
<li><strong>Authors: </strong>David Soler, Carlos Dafonte, Manuel Fernández-Veiga, Ana Fernández Vilas, Francisco J. Nóvoa</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18303">https://arxiv.org/abs/2502.18303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18303">https://arxiv.org/pdf/2502.18303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18303]] Experimental Analysis of Efficiency of the Messaging Layer Security for Multiple Delivery Services(https://arxiv.org/abs/2502.18303)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Messaging Layer security (MLS) and its underlying Continuous Group Key Agreement (CGKA) protocol allows a group of users to share a cryptographic secret in a dynamic manner, such that the secret is modified in member insertions and deletions. One of the most relevant contributions of MLS is its efficiency, as its communication cost scales logarithmically with the number of members. However, this claim has only been analysed in theoretical models and thus it is unclear how efficient MLS is in real-world scenarios. Furthermore, practical decisions such as the chosen Delivery Service and paradigm can also influence the efficiency and evolution of an MLS group. In this work we analyse MLS from an empirical viewpoint: we provide real-world measurements for metrics such as commit generation and processing times and message sizes under different conditions. In order to obtain these results we have developed a highly configurable environment for empirical evaluations of MLS through the simulation of MLS clients. Among other findings, our results show that computation costs scale linearly in practical scenarios even in the best-case scenario.</li>
</ul>

<h3>Title: RefuteBench 2.0 -- Agentic Benchmark for Dynamic Evaluation of LLM Responses to Refutation Instruction</h3>
<ul>
<li><strong>Authors: </strong>Jianhao Yan, Yun Luo, Yue Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18308">https://arxiv.org/abs/2502.18308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18308">https://arxiv.org/pdf/2502.18308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18308]] RefuteBench 2.0 -- Agentic Benchmark for Dynamic Evaluation of LLM Responses to Refutation Instruction(https://arxiv.org/abs/2502.18308)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the multi-turn interaction schema, large language models (LLMs) can leverage user feedback to enhance the quality and relevance of their responses. However, evaluating an LLM's ability to incorporate user refutation feedback is crucial yet challenging. In this study, we introduce RefuteBench 2.0, which significantly extends the original RefuteBench by incorporating LLM agents as refuters and evaluators, which allows for flexible and comprehensive assessment. We design both transient and persistent refutation instructions with different validity periods. Meta-evaluation shows that the LLM-based refuter could generate more human-like refutations and the evaluators could assign scores with high correlation with humans. Experimental results of various LLMs show that current models could effectively satisfy the refutation but fail to memorize the refutation information. Interestingly, we also observe that the performance of the initial task decreases as the refutations increase. Analysis of the attention scores further shows a potential weakness of current LLMs: they struggle to retain and correctly use previous information during long context dialogues. this https URL</li>
</ul>

<h3>Title: Mapping of Subjective Accounts into Interpreted Clusters (MOSAIC): Topic Modelling and LLM applied to Stroboscopic Phenomenology</h3>
<ul>
<li><strong>Authors: </strong>Romy Beauté, David J. Schwartzman, Guillaume Dumas, Jennifer Crook, Fiona Macpherson, Adam B. Barrett, Anil K. Seth</a></li>
<li><strong>Subjects: </strong>cs.CL, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18318">https://arxiv.org/abs/2502.18318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18318">https://arxiv.org/pdf/2502.18318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18318]] Mapping of Subjective Accounts into Interpreted Clusters (MOSAIC): Topic Modelling and LLM applied to Stroboscopic Phenomenology(https://arxiv.org/abs/2502.18318)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Stroboscopic light stimulation (SLS) on closed eyes typically induces simple visual hallucinations (VHs), characterised by vivid, geometric and colourful patterns. A dataset of 862 sentences, extracted from 422 open subjective reports, was recently compiled as part of the Dreamachine programme (Collective Act, 2022), an immersive multisensory experience that combines SLS and spatial sound in a collective setting. Although open reports extend the range of reportable phenomenology, their analysis presents significant challenges, particularly in systematically identifying patterns. To address this challenge, we implemented a data-driven approach leveraging Large Language Models and Topic Modelling to uncover and interpret latent experiential topics directly from the Dreamachine's text-based reports. Our analysis confirmed the presence of simple VHs typically documented in scientific studies of SLS, while also revealing experiences of altered states of consciousness and complex hallucinations. Building on these findings, our computational approach expands the systematic study of subjective experience by enabling data-driven analyses of open-ended phenomenological reports, capturing experiences not readily identified through standard questionnaires. By revealing rich and multifaceted aspects of experiences, our study broadens our understanding of stroboscopically-induced phenomena while highlighting the potential of Natural Language Processing and Large Language Models in the emerging field of computational (neuro)phenomenology. More generally, this approach provides a practically applicable methodology for uncovering subtle hidden patterns of subjective experience across diverse research domains.</li>
</ul>

<h3>Title: Structural Alignment Improves Graph Test-Time Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Hans Hao-Hsun Hsu, Shikun Liu, Han Zhao, Pan Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18334">https://arxiv.org/abs/2502.18334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18334">https://arxiv.org/pdf/2502.18334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18334]] Structural Alignment Improves Graph Test-Time Adaptation(https://arxiv.org/abs/2502.18334)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Graph-based learning has achieved remarkable success in domains ranging from recommendation to fraud detection and particle physics by effectively capturing underlying interaction patterns. However, it often struggles to generalize when distribution shifts occur, particularly those involving changes in network connectivity or interaction patterns. Existing approaches designed to mitigate such shifts typically require retraining with full access to source data, rendering them infeasible under strict computational or privacy constraints. To address this limitation, we propose a test-time structural alignment (TSA) algorithm for Graph Test-Time Adaptation (GTTA), a novel method that aligns graph structures during inference without revisiting the source domain. Built upon a theoretically grounded treatment of graph data distribution shifts, TSA integrates three key strategies: an uncertainty-aware neighborhood weighting that accommodates structure shifts, an adaptive balancing of self-node and neighborhood-aggregated representations driven by node representations' signal-to-noise ratio, and a decision boundary refinement that corrects remaining label and feature shifts. Extensive experiments on synthetic and real-world datasets demonstrate that TSA can consistently outperform both non-graph TTA methods and state-of-the-art GTTA baselines.</li>
</ul>

<h3>Title: BRIDO: Bringing Democratic Order to Abstractive Summarization</h3>
<ul>
<li><strong>Authors: </strong>Junhyun Lee, Harshith Goka, Hyeonmok Ko</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18342">https://arxiv.org/abs/2502.18342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18342">https://arxiv.org/pdf/2502.18342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18342]] BRIDO: Bringing Democratic Order to Abstractive Summarization(https://arxiv.org/abs/2502.18342)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hallucination refers to the inaccurate, irrelevant, and inconsistent text generated from large language models (LLMs). While the LLMs have shown great promise in a variety of tasks, the issue of hallucination still remains a major challenge for many practical uses. In this paper, we tackle the issue of hallucination in abstract text summarization by mitigating exposure bias. Existing models targeted for exposure bias mitigation, namely BRIO, aim for better summarization quality in the ROUGE score. We propose a model that uses a similar exposure bias mitigation strategy but with a goal that is aligned with less hallucination. We conjecture that among a group of candidate outputs, ones with hallucinations will comprise the minority of the whole group. That is, candidates with less similarity with others will have a higher chance of containing hallucinated content. Our method uses this aspect and utilizes contrastive learning, incentivizing candidates with high inter-candidate ROUGE scores. We performed experiments on the XSum and CNN/DM summarization datasets, and our method showed 6.25% and 3.82% improvement, respectively, on the consistency G-Eval score over BRIO.</li>
</ul>

<h3>Title: WebGames: Challenging General-Purpose Web-Browsing AI Agents</h3>
<ul>
<li><strong>Authors: </strong>George Thomas, Alex J. Chan, Jikun Kang, Wenqi Wu, Filippos Christianos, Fraser Greenlee, Andy Toulis, Marvin Purtorab</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18356">https://arxiv.org/abs/2502.18356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18356">https://arxiv.org/pdf/2502.18356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18356]] WebGames: Challenging General-Purpose Web-Browsing AI Agents(https://arxiv.org/abs/2502.18356)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce WebGames, a comprehensive benchmark suite designed to evaluate general-purpose web-browsing AI agents through a collection of 50+ interactive challenges. These challenges are specifically crafted to be straightforward for humans while systematically testing the limitations of current AI systems across fundamental browser interactions, advanced input processing, cognitive tasks, workflow automation, and interactive entertainment. Our framework eliminates external dependencies through a hermetic testing environment, ensuring reproducible evaluation with verifiable ground-truth solutions. We evaluate leading vision-language models including GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, and Qwen2-VL against human performance. Results reveal a substantial capability gap, with the best AI system achieving only 43.1% success rate compared to human performance of 95.7%, highlighting fundamental limitations in current AI systems' ability to handle common web interaction patterns that humans find intuitive. The benchmark is publicly available at this http URL, offering a lightweight, client-side implementation that facilitates rapid evaluation cycles. Through its modular architecture and standardized challenge specifications, WebGames provides a robust foundation for measuring progress in development of more capable web-browsing agents.</li>
</ul>

<h3>Title: ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Yifan Pu, Yiming Zhao, Zhicong Tang, Ruihong Yin, Haoxing Ye, Yuhui Yuan, Dong Chen, Jianmin Bao, Sirui Zhang, Yanbin Wang, Lin Liang, Lijuan Wang, Ji Li, Xiu Li, Zhouhui Lian, Gao Huang, Baining Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18364">https://arxiv.org/abs/2502.18364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18364">https://arxiv.org/pdf/2502.18364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18364]] ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation(https://arxiv.org/abs/2502.18364)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Multi-layer image generation is a fundamental task that enables users to isolate, select, and edit specific image layers, thereby revolutionizing interactions with generative models. In this paper, we introduce the Anonymous Region Transformer (ART), which facilitates the direct generation of variable multi-layer transparent images based on a global text prompt and an anonymous region layout. Inspired by Schema theory suggests that knowledge is organized in frameworks (schemas) that enable people to interpret and learn from new information by linking it to prior knowledge.}, this anonymous region layout allows the generative model to autonomously determine which set of visual tokens should align with which text tokens, which is in contrast to the previously dominant semantic layout for the image generation task. In addition, the layer-wise region crop mechanism, which only selects the visual tokens belonging to each anonymous region, significantly reduces attention computation costs and enables the efficient generation of images with numerous distinct layers (e.g., 50+). When compared to the full attention approach, our method is over 12 times faster and exhibits fewer layer conflicts. Furthermore, we propose a high-quality multi-layer transparent image autoencoder that supports the direct encoding and decoding of the transparency of variable multi-layer images in a joint manner. By enabling precise control and scalable layer generation, ART establishes a new paradigm for interactive content creation.</li>
</ul>

<h3>Title: Near-Shore Mapping for Detection and Tracking of Vessels</h3>
<ul>
<li><strong>Authors: </strong>Nicholas Dalhaug, Annette Stahl, Rudolf Mester, Edmund Førland Brekke</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18368">https://arxiv.org/abs/2502.18368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18368">https://arxiv.org/pdf/2502.18368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18368]] Near-Shore Mapping for Detection and Tracking of Vessels(https://arxiv.org/abs/2502.18368)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>For an autonomous surface vessel (ASV) to dock, it must track other vessels close to the docking area. Kayaks present a particular challenge due to their proximity to the dock and relatively small size. Maritime target tracking has typically employed land masking to filter out land and the dock. However, imprecise land masking makes it difficult to track close-to-dock objects. Our approach uses Light Detection And Ranging (LiDAR) data and maps the docking area offline. The precise 3D measurements allow for precise map creation. However, the mapping could result in static, yet potentially moving, objects being mapped. We detect and filter out potentially moving objects from the LiDAR data by utilizing image data. The visual vessel detection and segmentation method is a neural network that is trained on our labeled data. Close-to-shore tracking improves with an accurate map and is demonstrated on a recently gathered real-world dataset. The dataset contains multiple sequences of a kayak and a day cruiser moving close to the dock, in a collision path with an autonomous ferry prototype.</li>
</ul>

<h3>Title: Mechanistic PDE Networks for Discovery of Governing Equations</h3>
<ul>
<li><strong>Authors: </strong>Adeel Pervez, Efstratios Gavves, Francesco Locatello</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18377">https://arxiv.org/abs/2502.18377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18377">https://arxiv.org/pdf/2502.18377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18377]] Mechanistic PDE Networks for Discovery of Governing Equations(https://arxiv.org/abs/2502.18377)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We present Mechanistic PDE Networks -- a model for discovery of governing partial differential equations from data. Mechanistic PDE Networks represent spatiotemporal data as space-time dependent linear partial differential equations in neural network hidden representations. The represented PDEs are then solved and decoded for specific tasks. The learned PDE representations naturally express the spatiotemporal dynamics in data in neural network hidden space, enabling increased power for dynamical modeling. Solving the PDE representations in a compute and memory-efficient way, however, is a significant challenge. We develop a native, GPU-capable, parallel, sparse, and differentiable multigrid solver specialized for linear partial differential equations that acts as a module in Mechanistic PDE Networks. Leveraging the PDE solver, we propose a discovery architecture that can discover nonlinear PDEs in complex settings while also being robust to noise. We validate PDE discovery on a number of PDEs, including reaction-diffusion and Navier-Stokes equations.</li>
</ul>

<h3>Title: Monte Carlo Temperature: a robust sampling strategy for LLM's uncertainty quantification methods</h3>
<ul>
<li><strong>Authors: </strong>Nicola Cecere, Andrea Bacciu, Ignacio Fernández Tobías, Amin Mantrach</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18389">https://arxiv.org/abs/2502.18389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18389">https://arxiv.org/pdf/2502.18389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18389]] Monte Carlo Temperature: a robust sampling strategy for LLM's uncertainty quantification methods(https://arxiv.org/abs/2502.18389)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Uncertainty quantification (UQ) in Large Language Models (LLMs) is essential for their safe and reliable deployment, particularly in critical applications where incorrect outputs can have serious consequences. Current UQ methods typically rely on querying the model multiple times using non-zero temperature sampling to generate diverse outputs for uncertainty estimation. However, the impact of selecting a given temperature parameter is understudied, and our analysis reveals that temperature plays a fundamental role in the quality of uncertainty estimates. The conventional approach of identifying optimal temperature values requires expensive hyperparameter optimization (HPO) that must be repeated for each new model-dataset combination. We propose Monte Carlo Temperature (MCT), a robust sampling strategy that eliminates the need for temperature calibration. Our analysis reveals that: 1) MCT provides more robust uncertainty estimates across a wide range of temperatures, 2) MCT improves the performance of UQ methods by replacing fixed-temperature strategies that do not rely on HPO, and 3) MCT achieves statistical parity with oracle temperatures, which represent the ideal outcome of a well-tuned but computationally expensive HPO process. These findings demonstrate that effective UQ can be achieved without the computational burden of temperature parameter calibration.</li>
</ul>

<h3>Title: Enhancing DNA Foundation Models to Address Masking Inefficiencies</h3>
<ul>
<li><strong>Authors: </strong>Monireh Safari, Pablo Millan Arias, Scott C. Lowe, Lila Kari, Angel X. Chang, Graham W. Taylor</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18405">https://arxiv.org/abs/2502.18405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18405">https://arxiv.org/pdf/2502.18405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18405]] Enhancing DNA Foundation Models to Address Masking Inefficiencies(https://arxiv.org/abs/2502.18405)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Masked language modelling (MLM) as a pretraining objective has been widely adopted in genomic sequence modelling. While pretrained models can successfully serve as encoders for various downstream tasks, the distribution shift between pretraining and inference detrimentally impacts performance, as the pretraining task is to map [MASK] tokens to predictions, yet the [MASK] is absent during downstream applications. This means the encoder does not prioritize its encodings of non-[MASK] tokens, and expends parameters and compute on work only relevant to the MLM task, despite this being irrelevant at deployment time. In this work, we propose a modified encoder-decoder architecture based on the masked autoencoder framework, designed to address this inefficiency within a BERT-based transformer. We empirically show that the resulting mismatch is particularly detrimental in genomic pipelines where models are often used for feature extraction without fine-tuning. We evaluate our approach on the BIOSCAN-5M dataset, comprising over 2 million unique DNA barcodes. We achieve substantial performance gains in both closed-world and open-world classification tasks when compared against causal models and bidirectional architectures pretrained with MLM tasks.</li>
</ul>

<h3>Title: AgentRM: Enhancing Agent Generalization with Reward Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yu Xia, Jingru Fan, Weize Chen, Siyu Yan, Xin Cong, Zhong Zhang, Yaxi Lu, Yankai Lin, Zhiyuan Liu, Maosong Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18407">https://arxiv.org/abs/2502.18407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18407">https://arxiv.org/pdf/2502.18407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18407]] AgentRM: Enhancing Agent Generalization with Reward Modeling(https://arxiv.org/abs/2502.18407)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Existing LLM-based agents have achieved strong performance on held-in tasks, but their generalizability to unseen tasks remains poor. Hence, some recent work focus on fine-tuning the policy model with more diverse tasks to improve the generalizability. In this work, we find that finetuning a reward model to guide the policy model is more robust than directly finetuning the policy model. Based on this finding, we propose AgentRM, a generalizable reward model, to guide the policy model for effective test-time search. We comprehensively investigate three approaches to construct the reward model, including explicit reward modeling, implicit reward modeling and LLM-as-a-judge. We then use AgentRM to guide the answer generation with Best-of-N sampling and step-level beam search. On four types of nine agent tasks, AgentRM enhances the base policy model by $8.8$ points on average, surpassing the top general agent by $4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding greater improvement of $12.6$ on LLaMA-3-70B policy model. As for the specializability, AgentRM can also boost a finetuned policy model and outperform the top specialized agent by $11.4$ on three held-in tasks. Further analysis verifies its effectiveness in test-time scaling. Codes will be released to facilitate the research in this area.</li>
</ul>

<h3>Title: OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Zhao, Shengyuan Ding, Zicheng Zhang, Haian Huang, Maosong Cao, Weiyun Wang, Jiaqi Wang, Xinyu Fang, Wenhai Wang, Guangtao Zhai, Haodong Duan, Hua Yang, Kai Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18411">https://arxiv.org/abs/2502.18411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18411">https://arxiv.org/pdf/2502.18411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18411]] OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference(https://arxiv.org/abs/2502.18411)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in open-source multi-modal large language models (MLLMs) have primarily focused on enhancing foundational capabilities, leaving a significant gap in human preference alignment. This paper introduces OmniAlign-V, a comprehensive dataset of 200K high-quality training samples featuring diverse images, complex questions, and varied response formats to improve MLLMs' alignment with human preferences. We also present MM-AlignBench, a human-annotated benchmark specifically designed to evaluate MLLMs' alignment with human values. Experimental results show that finetuning MLLMs with OmniAlign-V, using Supervised Fine-Tuning (SFT) or Direct Preference Optimization (DPO), significantly enhances human preference alignment while maintaining or enhancing performance on standard VQA benchmarks, preserving their fundamental capabilities. Our datasets, benchmark, code and checkpoints have been released at this https URL.</li>
</ul>

<h3>Title: Comparative Analysis of MDL-VAE vs. Standard VAE on 202 Years of Gynecological Data</h3>
<ul>
<li><strong>Authors: </strong>Paula Santos</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18412">https://arxiv.org/abs/2502.18412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18412">https://arxiv.org/pdf/2502.18412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18412]] Comparative Analysis of MDL-VAE vs. Standard VAE on 202 Years of Gynecological Data(https://arxiv.org/abs/2502.18412)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study presents a comparative evaluation of a Variational Autoencoder (VAE) enhanced with Minimum Description Length (MDL) regularization against a Standard Autoencoder for reconstructing high-dimensional gynecological data. The MDL-VAE exhibits significantly lower reconstruction errors (MSE, MAE, RMSE) and more structured latent representations, driven by effective KL divergence regularization. Statistical analyses confirm these performance improvements are significant. Furthermore, the MDL-VAE shows consistent training and validation losses and achieves efficient inference times, underscoring its robustness and practical viability. Our findings suggest that incorporating MDL principles into VAE architectures can substantially improve data reconstruction and generalization, making it a promising approach for advanced applications in healthcare data modeling and analysis.</li>
</ul>

<h3>Title: MedKAN: An Advanced Kolmogorov-Arnold Network for Medical Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Zhuoqin Yang, Jiansong Zhang, Xiaoling Luo, Zheng Lu, Linlin Shen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18416">https://arxiv.org/abs/2502.18416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18416">https://arxiv.org/pdf/2502.18416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18416]] MedKAN: An Advanced Kolmogorov-Arnold Network for Medical Image Classification(https://arxiv.org/abs/2502.18416)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Recent advancements in deep learning for image classification predominantly rely on convolutional neural networks (CNNs) or Transformer-based architectures. However, these models face notable challenges in medical imaging, particularly in capturing intricate texture details and contextual features. Kolmogorov-Arnold Networks (KANs) represent a novel class of architectures that enhance nonlinear transformation modeling, offering improved representation of complex features. In this work, we present MedKAN, a medical image classification framework built upon KAN and its convolutional extensions. MedKAN features two core modules: the Local Information KAN (LIK) module for fine-grained feature extraction and the Global Information KAN (GIK) module for global context integration. By combining these modules, MedKAN achieves robust feature modeling and fusion. To address diverse computational needs, we introduce three scalable variants--MedKAN-S, MedKAN-B, and MedKAN-L. Experimental results on nine public medical imaging datasets demonstrate that MedKAN achieves superior performance compared to CNN- and Transformer-based models, highlighting its effectiveness and generalizability in medical image analysis.</li>
</ul>

<h3>Title: GHOST 2.0: generative high-fidelity one shot transfer of heads</h3>
<ul>
<li><strong>Authors: </strong>Alexander Groshev (1), Anastasiia Iashchenko (1), Pavel Paramonov (1), Denis Dimitrov (1 and 2), Andrey Kuznetsov (1 and 2) ((1) SberAI, (2) AIRI)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18417">https://arxiv.org/abs/2502.18417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18417">https://arxiv.org/pdf/2502.18417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18417]] GHOST 2.0: generative high-fidelity one shot transfer of heads(https://arxiv.org/abs/2502.18417)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>While the task of face swapping has recently gained attention in the research community, a related problem of head swapping remains largely unexplored. In addition to skin color transfer, head swap poses extra challenges, such as the need to preserve structural information of the whole head during synthesis and inpaint gaps between swapped head and background. In this paper, we address these concerns with GHOST 2.0, which consists of two problem-specific modules. First, we introduce enhanced Aligner model for head reenactment, which preserves identity information at multiple scales and is robust to extreme pose variations. Secondly, we use a Blender module that seamlessly integrates the reenacted head into the target background by transferring skin color and inpainting mismatched regions. Both modules outperform the baselines on the corresponding tasks, allowing to achieve state of the art results in head swapping. We also tackle complex cases, such as large difference in hair styles of source and target.</li>
</ul>

<h3>Title: TextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Frederikus Hudi, Genta Indra Winata, Ruochen Zhang, Alham Fikri Aji</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18431">https://arxiv.org/abs/2502.18431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18431">https://arxiv.org/pdf/2502.18431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18431]] TextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning(https://arxiv.org/abs/2502.18431)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning is a fundamental capability of large language models (LLMs), enabling them to comprehend, analyze, and solve complex problems. In this paper, we introduce TextGames, an innovative benchmark specifically crafted to assess LLMs through demanding text-based games that require advanced skills in pattern recognition, spatial awareness, arithmetic, and logical reasoning. Our analysis probes LLMs' performance in both single-turn and multi-turn reasoning, and their abilities in leveraging feedback to correct subsequent answers through self-reflection. Our findings reveal that, although LLMs exhibit proficiency in addressing most easy and medium-level problems, they face significant challenges with more difficult tasks. In contrast, humans are capable of solving all tasks when given sufficient time. Moreover, we observe that LLMs show improved performance in multi-turn predictions through self-reflection, yet they still struggle with sequencing, counting, and following complex rules consistently. Additionally, models optimized for reasoning outperform pre-trained LLMs that prioritize instruction following, highlighting the crucial role of reasoning skills in addressing highly complex problems.</li>
</ul>

<h3>Title: Exploring Gender Disparities in Automatic Speech Recognition Technology</h3>
<ul>
<li><strong>Authors: </strong>Hend ElGhazaly, Bahman Mirheidari, Nafise Sadat Moosavi, Heidi Christensen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18434">https://arxiv.org/abs/2502.18434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18434">https://arxiv.org/pdf/2502.18434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18434]] Exploring Gender Disparities in Automatic Speech Recognition Technology(https://arxiv.org/abs/2502.18434)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This study investigates factors influencing Automatic Speech Recognition (ASR) systems' fairness and performance across genders, beyond the conventional examination of demographics. Using the LibriSpeech dataset and the Whisper small model, we analyze how performance varies across different gender representations in training data. Our findings suggest a complex interplay between the gender ratio in training data and ASR performance. Optimal fairness occurs at specific gender distributions rather than a simple 50-50 split. Furthermore, our findings suggest that factors like pitch variability can significantly affect ASR accuracy. This research contributes to a deeper understanding of biases in ASR systems, highlighting the importance of carefully curated training data in mitigating gender bias.</li>
</ul>

<h3>Title: Reversal Blessing: Thinking Backward May Outpace Thinking Forward in Multi-choice Questions</h3>
<ul>
<li><strong>Authors: </strong>Yizhe Zhang, Richard Bai, Zijin Gu, Ruixiang Zhang, Jiatao Gu, Emmanuel Abbe, Samy Bengio, Navdeep Jaitly</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IT, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18435">https://arxiv.org/abs/2502.18435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18435">https://arxiv.org/pdf/2502.18435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18435]] Reversal Blessing: Thinking Backward May Outpace Thinking Forward in Multi-choice Questions(https://arxiv.org/abs/2502.18435)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Language models usually use left-to-right (L2R) autoregressive factorization. However, L2R factorization may not always be the best inductive bias. Therefore, we investigate whether alternative factorizations of the text distribution could be beneficial in some tasks. We investigate right-to-left (R2L) training as a compelling alternative, focusing on multiple-choice questions (MCQs) as a test bed for knowledge extraction and reasoning. Through extensive experiments across various model sizes (2B-8B parameters) and training datasets, we find that R2L models can significantly outperform L2R models on several MCQ benchmarks, including logical reasoning, commonsense understanding, and truthfulness assessment tasks. Our analysis reveals that this performance difference may be fundamentally linked to multiple factors including calibration, computability and directional conditional entropy. We ablate the impact of these factors through controlled simulation studies using arithmetic tasks, where the impacting factors can be better disentangled. Our work demonstrates that exploring alternative factorizations of the text distribution can lead to improvements in LLM capabilities and provides theoretical insights into optimal factorization towards approximating human language distribution, and when each reasoning order might be more advantageous.</li>
</ul>

<h3>Title: FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response</h3>
<ul>
<li><strong>Authors: </strong>Mollie Shichman, Claire Bonial, Austin Blodgett, Taylor Hudson, Francis Ferraro, Rachel Rudinger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18452">https://arxiv.org/abs/2502.18452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18452">https://arxiv.org/pdf/2502.18452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18452]] FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response(https://arxiv.org/abs/2502.18452)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have the potential for substantial common sense reasoning. However, these capabilities are often emergent in larger models. This means smaller models that can be run locally are less helpful and capable with respect to certain reasoning tasks. To meet our problem space requirements, we fine-tune smaller LLMs to disaster domains, as these domains involve complex and low-frequency physical common sense knowledge. We introduce a pipeline to create Field Ready Instruction Decoding Agent (FRIDA) models, where domain experts and linguists combine their knowledge to make high-quality seed data that is used to generate synthetic data for fine-tuning. We create a set of 130 seed instructions for synthetic generation, a synthetic dataset of 25000 instructions, and 119 evaluation instructions relating to both general and earthquake-specific object affordances. We fine-tune several LLaMa and Mistral instruction-tuned models and find that FRIDA models outperform their base models at a variety of sizes. We then run an ablation study to understand which kinds of synthetic data most affect performance and find that training physical state and object function common sense knowledge alone improves over FRIDA models trained on all data. We conclude that the FRIDA pipeline is capable of instilling general common sense, but needs to be augmented with information retrieval for specific domain knowledge.</li>
</ul>

<h3>Title: DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers</h3>
<ul>
<li><strong>Authors: </strong>Xueguang Ma, Xi Victoria Lin, Barlas Oguz, Jimmy Lin, Wen-tau Yih, Xilun Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18460">https://arxiv.org/abs/2502.18460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18460">https://arxiv.org/pdf/2502.18460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18460]] DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers(https://arxiv.org/abs/2502.18460)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated strong effectiveness and robustness while fine-tuned as dense retrievers. However, their large parameter size brings significant inference time computational challenges, including high encoding costs for large-scale corpora and increased query latency, limiting their practical deployment. While smaller retrievers offer better efficiency, they often fail to generalize effectively with limited supervised fine-tuning data. In this work, we introduce DRAMA, a training framework that leverages LLMs to train smaller generalizable dense retrievers. In particular, we adopt pruned LLMs as the backbone and train on diverse LLM-augmented data in a single-stage contrastive learning setup. Experiments show that DRAMA offers better multilingual and long-context capabilities than traditional encoder-based retrievers, and achieves strong performance across multiple tasks and languages. These highlight the potential of connecting the training of smaller retrievers with the growing advancements in LLMs, bridging the gap between efficiency and generalization.</li>
</ul>

<h3>Title: K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs</h3>
<ul>
<li><strong>Authors: </strong>Ziheng Ouyang, Zhen Li, Qibin Hou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18461">https://arxiv.org/abs/2502.18461</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18461">https://arxiv.org/pdf/2502.18461</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18461]] K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs(https://arxiv.org/abs/2502.18461)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent studies have explored combining different LoRAs to jointly generate learned style and content. However, existing methods either fail to effectively preserve both the original subject and style simultaneously or require additional training. In this paper, we argue that the intrinsic properties of LoRA can effectively guide diffusion models in merging learned subject and style. Building on this insight, we propose K-LoRA, a simple yet effective training-free LoRA fusion approach. In each attention layer, K-LoRA compares the Top-K elements in each LoRA to be fused, determining which LoRA to select for optimal fusion. This selection mechanism ensures that the most representative features of both subject and style are retained during the fusion process, effectively balancing their contributions. Experimental results demonstrate that the proposed method effectively integrates the subject and style information learned by the original LoRAs, outperforming state-of-the-art training-based approaches in both qualitative and quantitative results.</li>
</ul>

<h3>Title: Scalable Equilibrium Sampling with Sequential Boltzmann Generators</h3>
<ul>
<li><strong>Authors: </strong>Charlie B. Tan, Avishek Joey Bose, Chen Lin, Leon Klein, Michael M. Bronstein, Alexander Tong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18462">https://arxiv.org/abs/2502.18462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18462">https://arxiv.org/pdf/2502.18462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18462]] Scalable Equilibrium Sampling with Sequential Boltzmann Generators(https://arxiv.org/abs/2502.18462)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann generators tackle this problem by pairing powerful normalizing flows with importance sampling to obtain statistically independent samples under the target distribution. In this paper, we extend the Boltzmann generator framework and introduce Sequential Boltzmann generators (SBG) with two key improvements. The first is a highly efficient non-equivariant Transformer-based normalizing flow operating directly on all-atom Cartesian coordinates. In contrast to equivariant continuous flows of prior methods, we leverage exactly invertible non-equivariant architectures which are highly efficient both during sample generation and likelihood computation. As a result, this unlocks more sophisticated inference strategies beyond standard importance sampling. More precisely, as a second key improvement we perform inference-time scaling of flow samples using annealed Langevin dynamics which transports samples toward the target distribution leading to lower variance (annealed) importance weights which enable higher fidelity resampling with sequential Monte Carlo. SBG achieves state-of-the-art performance w.r.t. all metrics on molecular systems, demonstrating the first equilibrium sampling in Cartesian coordinates of tri, tetra, and hexapeptides that were so far intractable for prior Boltzmann generators.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
