<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h2>privacy</h2>
<h3>Title: Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding. (arXiv:2305.12031v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12031">http://arxiv.org/abs/2305.12031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12031] Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding](http://arxiv.org/abs/2305.12031) #privacy</code></li>
<li>Summary: <p>Large Language Models (LLMs) present immense potential in the medical field,
yet concerns over data privacy, regulatory compliance, and model stability
restrict their widespread adoption. Although the distillation of
high-performing closed-source LLMs has proven effective for general tasks,
their application in healthcare is limited due to reduced domain knowledge and
remnants of alignment behavior hindering clinical tasks. To address these
challenges, we propose Dialogue-Based Knowledge Encoding (DBKE). DBKE enhances
models' implicit knowledge base and primes them for conversational recall,
augmenting their conversational capabilities and enabling a soft alignment for
subsequent use cases. By transforming dense academic source text into synthetic
dialogue, DBKE broadens the model's knowledge base and enables a soft alignment
that guides downstream behaviours. We present Clinical Camel, an open-source,
healthcare-focused conversational model, to showcase the effectiveness of DBKE.
Clinical Camel outperforms GPT-3.5 on the United States Medical Licensing
Examination (USMLE) Step 1 and Step 3 with scores of 53.2 % and 58.2 %,
respectively, compared to GPT-3.5's scores of 36.1 % and 55.7 %. Clinical Camel
adeptly handles multi-stage clinical case problems, provides adaptive
counseling, and generates clinical notes. However, it is prone to
hallucinations, which pose a significant obstacle in safety-critical settings.
The performance of Clinical Camel underscores the importance of continued
research and development of open-source models for the safe and effective
integration of LLMs in healthcare settings.
</p></li>
</ul>

<h3>Title: Privacy in Multimodal Federated Human Activity Recognition. (arXiv:2305.12134v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12134">http://arxiv.org/abs/2305.12134</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12134] Privacy in Multimodal Federated Human Activity Recognition](http://arxiv.org/abs/2305.12134) #privacy</code></li>
<li>Summary: <p>Human Activity Recognition (HAR) training data is often privacy-sensitive or
held by non-cooperative entities. Federated Learning (FL) addresses such
concerns by training ML models on edge clients. This work studies the impact of
privacy in federated HAR at a user, environment, and sensor level. We show that
the performance of FL for HAR depends on the assumed privacy level of the FL
system and primarily upon the colocation of data from different sensors. By
avoiding data sharing and assuming privacy at the human or environment level,
as prior works have done, the accuracy decreases by 5-7%. However, extending
this to the modality level and strictly separating sensor data between multiple
clients may decrease the accuracy by 19-42%. As this form of privacy is
necessary for the ethical utilisation of passive sensing methods in HAR, we
implement a system where clients mutually train both a general FL model and a
group-level one per modality. Our evaluation shows that this method leads to
only a 7-13% decrease in accuracy, making it possible to build HAR systems with
diverse hardware.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: CryptoVampire: Automated Reasoning for the Complete Symbolic Attacker Cryptographic Model. (arXiv:2305.12173v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12173">http://arxiv.org/abs/2305.12173</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12173] CryptoVampire: Automated Reasoning for the Complete Symbolic Attacker Cryptographic Model](http://arxiv.org/abs/2305.12173) #attack</code></li>
<li>Summary: <p>Cryptographic protocols are extremely hard to design and prove correct, as
witnessed by the ever-growing list of attacks even on protocol standards. Using
the symbolic model of cryptography, protocols are proven correct against an
idealized cryptographic model, which abstracts away from the algebraic
properties of cryptographic schemes and thus misses attacks. On the other hand,
existing computational models of cryptography only support interactive proofs
and/or are limited to stateless protocols. A promising approach is given by the
computationally complete symbolic attacker (CCSA) model, formalized in the BC
logic, which aims at bridging and getting the best of the two worlds, obtaining
cryptographic guarantees by symbolic protocol analysis. While machine-checked
security proofs are provided in this domain, such efforts require expert
knowledge both in the cryptographic space as well as on the reasoning side.
</p></li>
</ul>

<p>In this paper, we present the CryptoVampire framework, providing the first
fully automated setting for deriving proofs of trace properties in the BC
logic. CryptoVampire brings a first-order formalization of protocol properties,
by proposing tailored handling of subterm relations. In addition, CryptoVampire
implements specialized reasoning techniques, saturation algorithms, and
heuristics, allowing the direct integration of CryptoVampire within the
landscape of automated theorem proving. Our experimental results showcase the
effectiveness of CryptoVampire, providing also automation support for existing
approaches in the area.
</p>

<h3>Title: Dynamic Gradient Balancing for Enhanced Adversarial Attacks on Multi-Task Models. (arXiv:2305.12066v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12066">http://arxiv.org/abs/2305.12066</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12066] Dynamic Gradient Balancing for Enhanced Adversarial Attacks on Multi-Task Models](http://arxiv.org/abs/2305.12066) #attack</code></li>
<li>Summary: <p>Multi-task learning (MTL) creates a single machine learning model called
multi-task model to simultaneously perform multiple tasks. Although the
security of single task classifiers has been extensively studied, there are
several critical security research questions for multi-task models including 1)
How secure are multi-task models to single task adversarial machine learning
attacks, 2) Can adversarial attacks be designed to attack multiple tasks
simultaneously, and 3) Does task sharing and adversarial training increase
multi-task model robustness to adversarial attacks? In this paper, we answer
these questions through careful analysis and rigorous experimentation. First,
we develop na\"ive adaptation of single-task white-box attacks and analyze
their inherent drawbacks. We then propose a novel attack framework, Dynamic
Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking
a multi-task model as an optimization problem based on averaged relative loss
change, which can be solved by approximating the problem as an integer linear
programming problem. Extensive evaluation on two popular MTL benchmarks, NYUv2
and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to na\"ive
multi-task attack baselines on both clean and adversarially trained multi-task
models. The results also reveal a fundamental trade-off between improving task
accuracy by sharing parameters across tasks and undermining model robustness
due to increased attack transferability from parameter sharing.
</p></li>
</ul>

<h3>Title: Annealing Self-Distillation Rectification Improves Adversarial Training. (arXiv:2305.12118v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12118">http://arxiv.org/abs/2305.12118</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12118] Annealing Self-Distillation Rectification Improves Adversarial Training](http://arxiv.org/abs/2305.12118) #attack</code></li>
<li>Summary: <p>In standard adversarial training, models are optimized to fit one-hot labels
within allowable adversarial perturbation budgets. However, the ignorance of
underlying distribution shifts brought by perturbations causes the problem of
robust overfitting. To address this issue and enhance adversarial robustness,
we analyze the characteristics of robust models and identify that robust models
tend to produce smoother and well-calibrated outputs. Based on the observation,
we propose a simple yet effective method, Annealing Self-Distillation
Rectification (ADR), which generates soft labels as a better guidance mechanism
that accurately reflects the distribution shift under attack during adversarial
training. By utilizing ADR, we can obtain rectified distributions that
significantly improve model robustness without the need for pre-trained models
or extensive extra computation. Moreover, our method facilitates seamless
plug-and-play integration with other adversarial training techniques by
replacing the hard labels in their objectives. We demonstrate the efficacy of
ADR through extensive experiments and strong performances across datasets.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: THRawS: A Novel Dataset for Thermal Hotspots Detection in Raw Sentinel-2 Data. (arXiv:2305.11891v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11891">http://arxiv.org/abs/2305.11891</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11891] THRawS: A Novel Dataset for Thermal Hotspots Detection in Raw Sentinel-2 Data](http://arxiv.org/abs/2305.11891) #robust</code></li>
<li>Summary: <p>Nowadays, most of the datasets leveraging space-borne Earth Observation (EO)
data are based on high-end levels products, which are ortho-rectified,
coregistered, calibrated, and further processed to mitigate the impact of noise
and distortions. Nevertheless, given the growing interest to apply Artificial
Intelligence (AI) onboard satellites for time-critical applications, such as
natural disaster response, providing raw satellite images could be useful to
foster the research on energy-efficient pre-processing algorithms and AI models
for onboard-satellite applications. In this framework, we present THRawS, the
first dataset composed of Sentinel-2 (S-2) raw data containing warm temperature
hotspots (wildfires and volcanic eruptions). To foster the realisation of
robust AI architectures, the dataset gathers data from all over the globe.
Furthermore, we designed a custom methodology to identify events in raw data
starting from the corresponding Level-1C (L1C) products. Indeed, given the
availability of state-of-the-art algorithms for thermal anomalies detection on
the L1C tiles, we detect such events on these latter and we then re-project
them on the corresponding raw images. Additionally, to deal with unprocessed
data, we devise a lightweight coarse coregisteration and georeferencing
strategy. The developed dataset is comprehensive of more than 100 samples
containing wildfires, volcanic eruptions, and event-free volcanic areas to
enable both warm-events detection and general classification applications.
Finally, we compare performances between the proposed coarse spatial
coregistration technique and the SuperGlue Deep Neural Network method to
highlight the different constraints in terms of timing and quality of spatial
registration to minimise the spatial displacement error for a specific scene.
</p></li>
</ul>

<h3>Title: Boosting Crop Classification by Hierarchically Fusing Satellite, Rotational, and Contextual Data. (arXiv:2305.12011v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12011">http://arxiv.org/abs/2305.12011</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12011] Boosting Crop Classification by Hierarchically Fusing Satellite, Rotational, and Contextual Data](http://arxiv.org/abs/2305.12011) #robust</code></li>
<li>Summary: <p>Accurate in-season crop type classification is crucial for the crop
production estimation and monitoring of agricultural parcels. However, the
complexity of the plant growth patterns and their spatio-temporal variability
present significant challenges. While current deep learning-based methods show
promise in crop type classification from single- and multi-modal time series,
most existing methods rely on a single modality, such as satellite optical
remote sensing data or crop rotation patterns. We propose a novel approach to
fuse multimodal information into a model for improved accuracy and robustness
across multiple years and countries. The approach relies on three modalities
used: remote sensing time series from Sentinel-2 and Landsat 8 observations,
parcel crop rotation and local crop distribution. To evaluate our approach, we
release a new annotated dataset of 7.4 million agricultural parcels in France
and Netherlands. We associate each parcel with time-series of surface
reflectance (Red and NIR) and biophysical variables (LAI, FAPAR). Additionally,
we propose a new approach to automatically aggregate crop types into a
hierarchical class structure for meaningful model evaluation and a novel
data-augmentation technique for early-season classification. Performance of the
multimodal approach was assessed at different aggregation level in the semantic
domain spanning from 151 to 8 crop types or groups. It resulted in accuracy
ranging from 91\% to 95\% for NL dataset and from 85\% to 89\% for FR dataset.
Pre-training on a dataset improves domain adaptation between countries,
allowing for cross-domain zero-shot learning, and robustness of the
performances in a few-shot setting from France to Netherlands. Our proposed
approach outperforms comparable methods by enabling learning methods to use the
often overlooked spatio-temporal context of parcels, resulting in increased
preci...
</p></li>
</ul>

<h3>Title: Learning for Open-World Calibration with Graph Neural Networks. (arXiv:2305.12039v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12039">http://arxiv.org/abs/2305.12039</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12039] Learning for Open-World Calibration with Graph Neural Networks](http://arxiv.org/abs/2305.12039) #robust</code></li>
<li>Summary: <p>We tackle the problem of threshold calibration for open-world recognition by
incorporating representation compactness measures into clustering. Unlike the
open-set recognition which focuses on discovering and rejecting the unknown,
open-world recognition learns robust representations that are generalizable to
disjoint unknown classes at test time. Our proposed method is based on two key
observations: (i) representation structures among neighbouring images in high
dimensional visual embedding spaces have strong self-similarity which can be
leveraged to encourage transferability to the open world, (ii) intra-class
embedding structures can be modeled with the marginalized von Mises-Fisher
(vMF) probability, whose correlation with the true positive rate is
dataset-invariant. Motivated by these, we design a unified framework centered
around a graph neural network (GNN) to jointly predict the pseudo-labels and
the vMF concentrations which indicate the representation compactness. These
predictions can be converted into statistical estimations for recognition
accuracy, allowing more robust calibration of the distance threshold to achieve
target utility for the open-world classes. Results on a variety of visual
recognition benchmarks demonstrate the superiority of our method over
traditional posthoc calibration methods for the open world, especially under
distribution shift.
</p></li>
</ul>

<h3>Title: Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?. (arXiv:2305.12096v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12096">http://arxiv.org/abs/2305.12096</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12096] Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?](http://arxiv.org/abs/2305.12096) #robust</code></li>
<li>Summary: <p>Pre-training on large corpora of text enables the language models to acquire
a vast amount of factual and commonsense knowledge which allows them to achieve
remarkable performance on a variety of language understanding tasks. They
typically acquire this knowledge by learning from the pre-training text and
capturing certain patterns from it. However, real-world settings often present
scenarios that do not abide by these patterns i.e. scenarios that break the
common assumptions. Can state-of-the-art NLP models correctly reason over the
contexts of such scenarios?
</p></li>
</ul>

<p>Addressing the above question, in this paper, we investigate the ability of
models to correctly reason over contexts that break the common assumptions. To
this end, we first systematically create evaluation data in which each data
instance consists of (a) a common assumption, (b) a context that follows the
assumption, (c) a context that breaks the assumption, and (d) questions based
on the contexts. Then, through evaluations on multiple models including GPT-3
and Flan T5, we show that while doing fairly well on contexts that follow the
common assumptions, the models struggle to correctly reason over contexts that
break those assumptions. Specifically, the performance gap is as high as 20%
absolute points. Furthermore, we thoroughly analyze these results revealing
several interesting findings. We believe our work and findings will encourage
and facilitate further research in developing more robust models that can also
reliably reason over contexts that break the common assumptions. Data is
available at \url{https://github.com/nrjvarshney/break_the_common_assumptions}.
</p>

<h3>Title: Modeling the Q-Diversity in a Min-max Play Game for Robust Optimization. (arXiv:2305.12123v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12123">http://arxiv.org/abs/2305.12123</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12123] Modeling the Q-Diversity in a Min-max Play Game for Robust Optimization](http://arxiv.org/abs/2305.12123) #robust</code></li>
<li>Summary: <p>Models trained with empirical risk minimization (ERM) are revealed to easily
rely on spurious correlations, resulting in poor generalization. Group
distributionally robust optimization (group DRO) can alleviate this problem by
minimizing the worst-case loss over pre-defined groups. While promising, in
practice factors like expensive annotations and privacy preclude the
availability of group labels. More crucially, when taking a closer look at the
failure modes of out-of-distribution generalization, the typical procedure of
reweighting in group DRO loses efficiency. Hinged on the limitations, in this
work, we reformulate the group DRO framework by proposing Q-Diversity.
Characterized by an interactive training mode, Q-Diversity relaxes the group
identification from annotation into direct parameterization. Furthermore, a
novel mixing strategy across groups is presented to diversify the
under-represented groups. In a series of experiments on both synthetic and
real-world text classification tasks, results demonstrate that Q-Diversity can
consistently improve worst-case accuracy under different distributional shifts,
outperforming state-of-the-art alternatives.
</p></li>
</ul>

<h3>Title: Not All Semantics are Created Equal: Contrastive Self-supervised Learning with Automatic Temperature Individualization. (arXiv:2305.11965v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11965">http://arxiv.org/abs/2305.11965</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11965] Not All Semantics are Created Equal: Contrastive Self-supervised Learning with Automatic Temperature Individualization](http://arxiv.org/abs/2305.11965) #robust</code></li>
<li>Summary: <p>In this paper, we aim to optimize a contrastive loss with individualized
temperatures in a principled and systematic manner for self-supervised
learning. The common practice of using a global temperature parameter $\tau$
ignores the fact that ``not all semantics are created equal", meaning that
different anchor data may have different numbers of samples with similar
semantics, especially when data exhibits long-tails. First, we propose a new
robust contrastive loss inspired by distributionally robust optimization (DRO),
providing us an intuition about the effect of $\tau$ and a mechanism for
automatic temperature individualization. Then, we propose an efficient
stochastic algorithm for optimizing the robust contrastive loss with a provable
convergence guarantee without using large mini-batch sizes. Theoretical and
experimental results show that our algorithm automatically learns a suitable
$\tau$ for each sample. Specifically, samples with frequent semantics use large
temperatures to keep local semantic structures, while samples with rare
semantics use small temperatures to induce more separable features. Our method
not only outperforms prior strong baselines (e.g., SimCLR, CLIP) on unimodal
and bimodal datasets with larger improvements on imbalanced data but also is
less sensitive to hyper-parameters. To our best knowledge, this is the first
methodical approach to optimizing a contrastive loss with individualized
temperatures.
</p></li>
</ul>

<h3>Title: SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models' Safety Filters. (arXiv:2305.12082v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12082">http://arxiv.org/abs/2305.12082</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12082] SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models' Safety Filters](http://arxiv.org/abs/2305.12082) #robust</code></li>
<li>Summary: <p>Text-to-image generative models such as Stable Diffusion and DALL$\cdot$E 2
have attracted much attention since their publication due to their wide
application in the real world. One challenging problem of text-to-image
generative models is the generation of Not-Safe-for-Work (NSFW) content, e.g.,
those related to violence and adult. Therefore, a common practice is to deploy
a so-called safety filter, which blocks NSFW content based on either text or
image features. Prior works have studied the possible bypass of such safety
filters. However, existing works are largely manual and specific to Stable
Diffusion's official safety filter. Moreover, the bypass ratio of Stable
Diffusion's safety filter is as low as 23.51% based on our evaluation.
</p></li>
</ul>

<p>In this paper, we propose the first automated attack framework, called
SneakyPrompt, to evaluate the robustness of real-world safety filters in
state-of-the-art text-to-image generative models. Our key insight is to search
for alternative tokens in a prompt that generates NSFW images so that the
generated prompt (called an adversarial prompt) bypasses existing safety
filters. Specifically, SneakyPrompt utilizes reinforcement learning (RL) to
guide an agent with positive rewards on semantic similarity and bypass success.
</p>
<p>Our evaluation shows that SneakyPrompt successfully generated NSFW content
using an online model DALL$\cdot$E 2 with its default, closed-box safety filter
enabled. At the same time, we also deploy several open-source state-of-the-art
safety filters on a Stable Diffusion model and show that SneakyPrompt not only
successfully generates NSFW content, but also outperforms existing adversarial
attacks in terms of the number of queries and image qualities.
</p>

<h3>Title: Make Transformer Great Again for Time Series Forecasting: Channel Aligned Robust Dual Transformer. (arXiv:2305.12095v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12095">http://arxiv.org/abs/2305.12095</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12095] Make Transformer Great Again for Time Series Forecasting: Channel Aligned Robust Dual Transformer](http://arxiv.org/abs/2305.12095) #robust</code></li>
<li>Summary: <p>Recent studies have demonstrated the great power of deep learning methods,
particularly Transformer and MLP, for time series forecasting. Despite its
success in NLP and CV, many studies found that Transformer is less effective
than MLP for time series forecasting. In this work, we design a special
Transformer, i.e., channel-aligned robust dual Transformer (CARD for short),
that addresses key shortcomings of Transformer in time series forecasting.
First, CARD introduces a dual Transformer structure that allows it to capture
both temporal correlations among signals and dynamical dependence among
multiple variables over time. Second, we introduce a robust loss function for
time series forecasting to alleviate the potential overfitting issue. This new
loss function weights the importance of forecasting over a finite horizon based
on prediction uncertainties. Our evaluation of multiple long-term and
short-term forecasting datasets demonstrates that CARD significantly
outperforms state-of-the-art time series forecasting methods, including both
Transformer and MLP-based models.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Self-Supervised Learning for Point Clouds Data: A Survey. (arXiv:2305.11881v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11881">http://arxiv.org/abs/2305.11881</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11881] Self-Supervised Learning for Point Clouds Data: A Survey](http://arxiv.org/abs/2305.11881) #extraction</code></li>
<li>Summary: <p>The 3D point cloud is a crucial type of data collected by LiDAR sensors and
widely used in transportation-related fields due to its concise description and
accurate localization. To better capture the hierarchical representation of the
point cloud, deep neural networks (DNNs) are employed to process considerable
disorder 3D points and accomplish promising achievements in various computer
vision tasks such as pedestrian detection and vehicle recognition. However,
point cloud labeling is time-consuming and labor-intensive due to the
disordered and sparse attribute of the point cloud. Therefore, self-supervised
learning (SSL), an unsupervised training paradigm that mines effective
information from the data itself without human annotations, is considered an
essential solution for moving away from label dependency via its brilliant
pre-training task design. This paper provides a comprehensive survey of recent
advances in deep neural network-based point cloud SSL. We initially introduce
the definition, motivation, general pipeline as well as background to describe
the concept of SSL and its combination with point cloud in detail. In addition,
we present an innovative taxonomy of point cloud SSL methods, separating
current approaches into four broad categories based on the pretexts'
characteristics. We then summarize and compare the performances of the proposed
SSL methods in literature on multiple downstream tasks quantitatively and
qualitatively on benchmark datasets. Finally, feasible future research
directions are provided to alleviate current limitations of point cloud SSL and
also enhance feature extraction capability and generalizability of pre-training
models.
</p></li>
</ul>

<h3>Title: Eye-SpatialNet: Spatial Information Extraction from Ophthalmology Notes. (arXiv:2305.11948v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11948">http://arxiv.org/abs/2305.11948</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11948] Eye-SpatialNet: Spatial Information Extraction from Ophthalmology Notes](http://arxiv.org/abs/2305.11948) #extraction</code></li>
<li>Summary: <p>We introduce an annotated corpus of 600 ophthalmology notes labeled with
detailed spatial and contextual information of ophthalmic entities. We extend
our previously proposed frame semantics-based spatial representation schema,
Rad-SpatialNet, to represent spatial language in ophthalmology text, resulting
in the Eye-SpatialNet schema. The spatially-grounded entities are findings,
procedures, and drugs. To accurately capture all spatial details, we add some
domain-specific elements in Eye-SpatialNet. The annotated corpus contains 1715
spatial triggers, 7308 findings, 2424 anatomies, and 9914 descriptors. To
automatically extract the spatial information, we employ a two-turn question
answering approach based on the transformer language model BERT. The results
are promising, with F1 scores of 89.31, 74.86, and 88.47 for spatial triggers,
Figure, and Ground frame elements, respectively. This is the first work to
represent and extract a wide variety of clinical information in ophthalmology.
Extracting detailed information can benefit ophthalmology applications and
research targeted toward disease progression and screening.
</p></li>
</ul>

<h3>Title: A Weak Supervision Approach for Few-Shot Aspect Based Sentiment. (arXiv:2305.11979v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11979">http://arxiv.org/abs/2305.11979</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11979] A Weak Supervision Approach for Few-Shot Aspect Based Sentiment](http://arxiv.org/abs/2305.11979) #extraction</code></li>
<li>Summary: <p>We explore how weak supervision on abundant unlabeled data can be leveraged
to improve few-shot performance in aspect-based sentiment analysis (ABSA)
tasks. We propose a pipeline approach to construct a noisy ABSA dataset, and we
use it to adapt a pre-trained sequence-to-sequence model to the ABSA tasks. We
test the resulting model on three widely used ABSA datasets, before and after
fine-tuning. Our proposed method preserves the full fine-tuning performance
while showing significant improvements (15.84% absolute F1) in the few-shot
learning scenario for the harder tasks. In zero-shot (i.e., without
fine-tuning), our method outperforms the previous state of the art on the
aspect extraction sentiment classification (AESC) task and is, additionally,
capable of performing the harder aspect sentiment triplet extraction (ASTE)
task.
</p></li>
</ul>

<h3>Title: ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain. (arXiv:2305.12092v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12092">http://arxiv.org/abs/2305.12092</a></li>
<li>Code URL: <a href="https://github.com/mainlp/escoxlmr">https://github.com/mainlp/escoxlmr</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12092] ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain](http://arxiv.org/abs/2305.12092) #extraction</code></li>
<li>Summary: <p>The increasing number of benchmarks for Natural Language Processing (NLP)
tasks in the computational job market domain highlights the demand for methods
that can handle job-related tasks such as skill extraction, skill
classification, job title classification, and de-identification. While some
approaches have been developed that are specific to the job market domain,
there is a lack of generalized, multilingual models and benchmarks for these
tasks. In this study, we introduce a language model called ESCOXLM-R, based on
XLM-R, which uses domain-adaptive pre-training on the European Skills,
Competences, Qualifications and Occupations (ESCO) taxonomy, covering 27
languages. The pre-training objectives for ESCOXLM-R include dynamic masked
language modeling and a novel additional objective for inducing multilingual
taxonomical ESCO relations. We comprehensively evaluate the performance of
ESCOXLM-R on 6 sequence labeling and 3 classification tasks in 4 languages and
find that it achieves state-of-the-art results on 6 out of 9 datasets. Our
analysis reveals that ESCOXLM-R performs better on short spans and outperforms
XLM-R on entity-level and surface-level span-F1, likely due to ESCO containing
short skill and occupation titles, and encoding information on the
entity-level.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Can Public Large Language Models Help Private Cross-device Federated Learning?. (arXiv:2305.12132v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12132">http://arxiv.org/abs/2305.12132</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12132] Can Public Large Language Models Help Private Cross-device Federated Learning?](http://arxiv.org/abs/2305.12132) #federate</code></li>
<li>Summary: <p>We study (differentially) private federated learning (FL) of language models.
The language models in cross-device FL are relatively small, which can be
trained with meaningful formal user-level differential privacy (DP) guarantees
when massive parallelism in training is enabled by the participation of a
moderate size of users. Recently, public data has been used to improve
privacy-utility trade-offs for both large and small language models. In this
work, we provide a systematic study of using large-scale public data and LLMs
to help differentially private training of on-device FL models, and further
improve the privacy-utility tradeoff by techniques of distillation. Moreover,
we propose a novel distribution matching algorithm with theoretical grounding
to sample public data close to private data distribution, which significantly
improves the sample efficiency of (pre-)training on public data. The proposed
method is efficient and effective for training private model by taking
advantage of public data, especially for customized on-device architectures
that do not have ready-to-use pre-trained models.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Model Debiasing via Gradient-based Explanation on Representation. (arXiv:2305.12178v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12178">http://arxiv.org/abs/2305.12178</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12178] Model Debiasing via Gradient-based Explanation on Representation](http://arxiv.org/abs/2305.12178) #fair</code></li>
<li>Summary: <p>Machine learning systems produce biased results towards certain demographic
groups, known as the fairness problem. Recent approaches to tackle this problem
learn a latent code (i.e., representation) through disentangled representation
learning and then discard the latent code dimensions correlated with sensitive
attributes (e.g., gender). Nevertheless, these approaches may suffer from
incomplete disentanglement and overlook proxy attributes (proxies for sensitive
attributes) when processing real-world data, especially for unstructured data,
causing performance degradation in fairness and loss of useful information for
downstream tasks. In this paper, we propose a novel fairness framework that
performs debiasing with regard to both sensitive attributes and proxy
attributes, which boosts the prediction performance of downstream task models
without complete disentanglement. The main idea is to, first, leverage
gradient-based explanation to find two model focuses, 1) one focus for
predicting sensitive attributes and 2) the other focus for predicting
downstream task labels, and second, use them to perturb the latent code that
guides the training of downstream task models towards fairness and utility
goals. We show empirically that our framework works with both disentangled and
non-disentangled representation learning methods and achieves better
fairness-accuracy trade-off on unstructured and structured datasets than
previous state-of-the-art approaches.
</p></li>
</ul>

<h2>interpretability</h2>
<h2>explainability</h2>
<h3>Title: Machine Learning and VIIRS Satellite Retrievals for Skillful Fuel Moisture Content Monitoring in Wildfire Management. (arXiv:2305.11910v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11910">http://arxiv.org/abs/2305.11910</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11910] Machine Learning and VIIRS Satellite Retrievals for Skillful Fuel Moisture Content Monitoring in Wildfire Management](http://arxiv.org/abs/2305.11910) #explainability</code></li>
<li>Summary: <p>Monitoring the fuel moisture content (FMC) of vegetation is crucial for
managing and mitigating the impact of wildland fires. The combination of in
situ FMC observations with numerical weather prediction (NWP) models and
satellite retrievals has enabled the development of machine learning (ML)
models to estimate dead FMC retrievals over the contiguous US (CONUS). In this
study, ML models were trained using variables from the National Water Model and
the High-Resolution Rapid Refresh (HRRR) NWP models, and static variables
characterizing the surface properties, as well as surface reflectances and land
surface temperature (LST) retrievals from the VIIRS instrument on board the
Suomi-NPP satellite system. Extensive hyper-parameter optimization yielded
skillful FMC models compared to a daily climatography RMSE (+44\%) and to an
hourly climatography RMSE (+24\%). Furthermore, VIIRS retrievals were important
predictors for estimating FMC, contributing significantly as a group due to
their high band-correlation. In contrast, individual predictors in the HRRR
group had relatively high importance according to the explainability techniques
used. When both HRRR and VIIRS retrievals were not used as model inputs, the
performance dropped significantly. If VIIRS retrievals were not used, the RMSE
performance was worse. This highlights the importance of VIIRS retrievals in
modeling FMC, which yielded better models compared to MODIS. Overall, the
importance of the VIIRS group of predictors corroborates the dynamic
relationship between the 10-h fuel and the atmosphere and soil moisture. These
findings emphasize the significance of selecting appropriate data sources for
predicting FMC with ML models, with VIIRS retrievals and selected HRRR
variables being critical components in producing skillful FMC estimates.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: DiffCap: Exploring Continuous Diffusion on Image Captioning. (arXiv:2305.12144v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12144">http://arxiv.org/abs/2305.12144</a></li>
<li>Code URL: <a href="https://github.com/arealgoodname/diffcap">https://github.com/arealgoodname/diffcap</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12144] DiffCap: Exploring Continuous Diffusion on Image Captioning](http://arxiv.org/abs/2305.12144) #diffusion</code></li>
<li>Summary: <p>Current image captioning works usually focus on generating descriptions in an
autoregressive manner. However, there are limited works that focus on
generating descriptions non-autoregressively, which brings more decoding
diversity. Inspired by the success of diffusion models on generating
natural-looking images, we propose a novel method DiffCap to apply continuous
diffusions on image captioning. Unlike image generation where the output is
fixed-size and continuous, image description length varies with discrete
tokens. Our method transforms discrete tokens in a natural way and applies
continuous diffusion on them to successfully fuse extracted image features for
diffusion caption generation. Our experiments on COCO dataset demonstrate that
our method uses a much simpler structure to achieve comparable results to the
previous non-autoregressive works. Apart from quality, an intriguing property
of DiffCap is its high diversity during generation, which is missing from many
autoregressive models. We believe our method on fusing multimodal features in
diffusion language generation will inspire more researches on multimodal
language generation tasks for its simplicity and decoding flexibility.
</p></li>
</ul>

<h3>Title: Deep Learning Hydrodynamic Forecasting for Flooded Region Assessment in Near-Real-Time (DL Hydro-FRAN). (arXiv:2305.12052v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12052">http://arxiv.org/abs/2305.12052</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12052] Deep Learning Hydrodynamic Forecasting for Flooded Region Assessment in Near-Real-Time (DL Hydro-FRAN)](http://arxiv.org/abs/2305.12052) #diffusion</code></li>
<li>Summary: <p>Hydrodynamic flood modeling improves hydrologic and hydraulic prediction of
storm events. However, the computationally intensive numerical solutions
required for high-resolution hydrodynamics have historically prevented their
implementation in near-real-time flood forecasting. This study examines whether
several Deep Neural Network (DNN) architectures are suitable for optimizing
hydrodynamic flood models. Several pluvial flooding events were simulated in a
low-relief high-resolution urban environment using a 2D HEC-RAS hydrodynamic
model. These simulations were assembled into a training set for the DNNs, which
were then used to forecast flooding depths and velocities. The DNNs' forecasts
were compared to the hydrodynamic flood models, and showed good agreement, with
a median RMSE of around 2 mm for cell flooding depths in the study area. The
DNNs also improved forecast computation time significantly, with the DNNs
providing forecasts between 34.2 and 72.4 times faster than conventional
hydrodynamic models. The study area showed little change between HEC-RAS' Full
Momentum Equations and Diffusion Equations, however, important numerical
stability considerations were discovered that impact equation selection and DNN
architecture configuration. Overall, the results from this study show that DNNs
can greatly optimize hydrodynamic flood modeling, and enable near-real-time
hydrodynamic flood forecasting.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: PASTS: Progress-Aware Spatio-Temporal Transformer Speaker For Vision-and-Language Navigation. (arXiv:2305.11918v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11918">http://arxiv.org/abs/2305.11918</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11918] PASTS: Progress-Aware Spatio-Temporal Transformer Speaker For Vision-and-Language Navigation](http://arxiv.org/abs/2305.11918) #transformer</code></li>
<li>Summary: <p>Vision-and-language navigation (VLN) is a crucial but challenging cross-modal
navigation task. One powerful technique to enhance the generalization
performance in VLN is the use of an independent speaker model to provide pseudo
instructions for data augmentation. However, current speaker models based on
Long-Short Term Memory (LSTM) lack the ability to attend to features relevant
at different locations and time steps. To address this, we propose a novel
progress-aware spatio-temporal transformer speaker (PASTS) model that uses the
transformer as the core of the network. PASTS uses a spatio-temporal encoder to
fuse panoramic representations and encode intermediate connections through
steps. Besides, to avoid the misalignment problem that could result in
incorrect supervision, a speaker progress monitor (SPM) is proposed to enable
the model to estimate the progress of instruction generation and facilitate
more fine-grained caption results. Additionally, a multifeature dropout (MFD)
strategy is introduced to alleviate overfitting. The proposed PASTS is flexible
to be combined with existing VLN models. The experimental results demonstrate
that PASTS outperforms all existing speaker models and successfully improves
the performance of previous VLN models, achieving state-of-the-art performance
on the standard Room-to-Room (R2R) dataset.
</p></li>
</ul>

<h3>Title: LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4. (arXiv:2305.12147v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12147">http://arxiv.org/abs/2305.12147</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12147] LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4](http://arxiv.org/abs/2305.12147) #transformer</code></li>
<li>Summary: <p>Generative Pre-trained Transformer 4 (GPT-4) demonstrates impressive
chain-of-thought reasoning ability. Recent work on self-instruction tuning,
such as Alpaca, has focused on enhancing the general proficiency of models.
These instructions enable the model to achieve performance comparable to
GPT-3.5 on general tasks like open-domain text generation and paraphrasing.
However, they fall short of helping the model handle complex reasoning tasks.
To bridge the gap, this paper presents LogiCoT, a new instruction-tuning
dataset for Logical Chain-of-Thought reasoning with GPT-4. We elaborate on the
process of harvesting instructions for prompting GPT-4 to generate
chain-of-thought rationales. LogiCoT serves as an instruction set for teaching
models of logical reasoning and elicits general reasoning skills.
</p></li>
</ul>

<h3>Title: OL-Transformer: A Fast and Universal Surrogate Simulator for Optical Multilayer Thin Film Structures. (arXiv:2305.11984v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11984">http://arxiv.org/abs/2305.11984</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11984] OL-Transformer: A Fast and Universal Surrogate Simulator for Optical Multilayer Thin Film Structures](http://arxiv.org/abs/2305.11984) #transformer</code></li>
<li>Summary: <p>Deep learning-based methods have recently been established as fast and
accurate surrogate simulators for optical multilayer thin film structures.
However, existing methods only work for limited types of structures with
different material arrangements, preventing their applications towards diverse
and universal structures. Here, we propose the Opto-Layer (OL) Transformer to
act as a universal surrogate simulator for enormous types of structures.
Combined with the technique of structure serialization, our model can predict
accurate reflection and transmission spectra for up to $10^{25}$ different
multilayer structures, while still achieving a six-fold time speedup compared
to physical solvers. Further investigation reveals that the general learning
ability comes from the fact that our model first learns the physical embeddings
and then uses the self-attention mechanism to capture the hidden relationship
of light-matter interaction between each layer.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Inventing painting styles through natural inspiration. (arXiv:2305.12015v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12015">http://arxiv.org/abs/2305.12015</a></li>
<li>Code URL: <a href="https://github.com/nilin/art_ab_initio">https://github.com/nilin/art_ab_initio</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12015] Inventing painting styles through natural inspiration](http://arxiv.org/abs/2305.12015) #generative</code></li>
<li>Summary: <p>We propose two procedures to create painting styles using models trained only
on natural images, providing objective proof that the model is not plagiarizing
human art styles. In the first procedure we use the inductive bias from the
artistic medium to achieve creative expression. Abstraction is achieved by
using a reconstruction loss. The second procedure uses an additional natural
image as inspiration to create a new style. These two procedures make it
possible to invent new painting styles with no artistic training data. We
believe that our approach can help pave the way for the ethical employment of
generative AI in art, without infringing upon the originality of human
creators.
</p></li>
</ul>

<h3>Title: Self-QA: Unsupervised Knowledge Guided Language Model Alignment. (arXiv:2305.11952v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11952">http://arxiv.org/abs/2305.11952</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11952] Self-QA: Unsupervised Knowledge Guided Language Model Alignment](http://arxiv.org/abs/2305.11952) #generative</code></li>
<li>Summary: <p>Large-scale language models like ChatGPT and GPT-4 have gained attention for
their impressive conversational and generative capabilities. However, the
creation of supervised paired question-answering data for instruction tuning
presents formidable challenges. This endeavor necessitates substantial human
effort for data annotation and wrestles with issues concerning data quality,
diversity, accuracy, and other related factors. To overcome these obstacles, we
introduce an innovative framework named Self-QA, which replaces the traditional
practice of human-written instruction seeds with a vast amount of unsupervised
knowledge, enabling the model to generate a larger quantity of correct and
domain-specific instruction data. The effectiveness of our proposed method is
demonstrated through experiments conducted on unsupervised corpora from various
domains.
</p></li>
</ul>

<h3>Title: Evaluation of medium-large Language Models at zero-shot closed book generative question answering. (arXiv:2305.11991v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11991">http://arxiv.org/abs/2305.11991</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11991] Evaluation of medium-large Language Models at zero-shot closed book generative question answering](http://arxiv.org/abs/2305.11991) #generative</code></li>
<li>Summary: <p>Large language models (LLMs) have garnered significant attention, but the
definition of "large" lacks clarity. This paper focuses on medium-sized
lan-guage models (MLMs), defined as having at least six billion parameters but
less than 100 billion. The study evaluates MLMs regarding zero-shot genera-tive
question answering, which requires models to provide elaborate answers without
external document retrieval. The paper introduces an own test da-taset and
presents results from human evaluation. Results show that combin-ing the best
answers from different MLMs yielded an overall correct answer rate of 82.7%
which is better than the 60.9% of ChatGPT. The best MLM achieved 46.4% and has
7B parameters, which highlights the importance of using appropriate training
data for fine-tuning rather than solely relying on the number of parameters.
More fine-grained feedback should be used to further improve the quality of
answers.
</p></li>
</ul>

<h3>Title: Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings. (arXiv:2305.12027v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12027">http://arxiv.org/abs/2305.12027</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12027] Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings](http://arxiv.org/abs/2305.12027) #generative</code></li>
<li>Summary: <p>Entity linking methods based on dense retrieval are an efficient and widely
used solution in large-scale applications, but they fall short of the
performance of generative models, as they are sensitive to the structure of the
embedding space. In order to address this issue, this paper introduces DUCK, an
approach to infusing structural information in the space of entity
representations, using prior knowledge of entity types. Inspired by duck typing
in programming languages, we propose to define the type of an entity based on
the relations that it has with other entities in a knowledge graph. Then,
porting the concept of box embeddings to spherical polar coordinates, we
propose to represent relations as boxes on the hypersphere. We optimize the
model to cluster entities of similar type by placing them inside the boxes
corresponding to their relations. Our experiments show that our method sets new
state-of-the-art results on standard entity-disambiguation benchmarks, it
improves the performance of the model by up to 7.9 F1 points, outperforms other
type-aware approaches, and matches the results of generative models with 18
times more parameters.
</p></li>
</ul>

<h3>Title: Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs. (arXiv:2305.12191v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12191">http://arxiv.org/abs/2305.12191</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12191] Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs](http://arxiv.org/abs/2305.12191) #generative</code></li>
<li>Summary: <p>A major concern in using deep learning based generative models for
document-grounded dialogs is the potential generation of responses that are not
\textit{faithful} to the underlying document. Existing automated metrics used
for evaluating the faithfulness of response with respect to the grounding
document measure the degree of similarity between the generated response and
the document's content. However, these automated metrics are far from being
well aligned with human judgments. Therefore, to improve the measurement of
faithfulness, we propose a new metric that utilizes (Conditional) Point-wise
Mutual Information (PMI) between the generated response and the source
document, conditioned on the dialogue. PMI quantifies the extent to which the
document influences the generated response -- with a higher PMI indicating a
more faithful response. We build upon this idea to create a new decoding
technique that incorporates PMI into the response generation process to predict
more faithful responses. Our experiments on the BEGIN benchmark demonstrate an
improved correlation of our metric with human evaluation. We also show that our
decoding technique is effective in generating more faithful responses when
compared to standard decoding techniques on a set of publicly available
document-grounded dialog datasets.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Deep Learning Approaches to Lexical Simplification: A Survey. (arXiv:2305.12000v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12000">http://arxiv.org/abs/2305.12000</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12000] Deep Learning Approaches to Lexical Simplification: A Survey](http://arxiv.org/abs/2305.12000) #large language model</code></li>
<li>Summary: <p>Lexical Simplification (LS) is the task of replacing complex for simpler
words in a sentence whilst preserving the sentence's original meaning. LS is
the lexical component of Text Simplification (TS) with the aim of making texts
more accessible to various target populations. A past survey (Paetzold and
Specia, 2017) has provided a detailed overview of LS. Since this survey,
however, the AI/NLP community has been taken by storm by recent advances in
deep learning, particularly with the introduction of large language models
(LLM) and prompt learning. The high performance of these models sparked renewed
interest in LS. To reflect these recent advances, we present a comprehensive
survey of papers published between 2017 and 2023 on LS and its sub-tasks with a
special focus on deep learning. We also present benchmark datasets for the
future development of LS systems.
</p></li>
</ul>

<h3>Title: OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models. (arXiv:2305.12001v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12001">http://arxiv.org/abs/2305.12001</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12001] OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models](http://arxiv.org/abs/2305.12001) #large language model</code></li>
<li>Summary: <p>In this paper, we conduct a thorough investigation into the reasoning
capabilities of Large Language Models (LLMs), focusing specifically on the Open
Pretrained Transformers (OPT) models as a representative of such models. Our
study entails finetuning three different sizes of OPT on a carefully curated
reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned
without explanations, and OPT-RE, finetuned with explanations. We then evaluate
all models on 57 out-of-domain tasks drawn from the SUPER-NATURALINSTRUCTIONS
benchmark, covering 26 distinct reasoning skills, utilizing three prompting
techniques. Through a comprehensive grid of 27 configurations and 6,156 test
evaluations, we investigate the dimensions of finetuning, prompting, and scale
to understand the role of explanations on different reasoning skills. Our
findings reveal that having explanations in the fewshot exemplar has no
significant impact on the model's performance when the model is finetuned,
while positively affecting the non-finetuned counterpart. Moreover, we observe
a slight yet consistent increase in classification accuracy as we incorporate
explanations during prompting and finetuning, respectively. Finally, we offer
insights on which skills benefit the most from incorporating explanations
during finetuning and prompting, such as Numerical (+20.4%) and Analogical
(+13.9%) reasoning, as well as skills that exhibit negligible or negative
effects.
</p></li>
</ul>

<h3>Title: Re-visiting Automated Topic Model Evaluation with Large Language Models. (arXiv:2305.12152v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12152">http://arxiv.org/abs/2305.12152</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12152] Re-visiting Automated Topic Model Evaluation with Large Language Models](http://arxiv.org/abs/2305.12152) #large language model</code></li>
<li>Summary: <p>Topic models are used to make sense of large text collections. However,
automatically evaluating topic model output and determining the optimal number
of topics both have been longstanding challenges, with no effective automated
solutions to date. This paper proposes using large language models to evaluate
such output. We find that large language models appropriately assess the
resulting topics, correlating more strongly with human judgments than existing
automated metrics. We then investigate whether we can use large language models
to automatically determine the optimal number of topics. We automatically
assign labels to documents and choosing configurations with the most pure
labels returns reasonable values for the optimal number of topics.
</p></li>
</ul>

<h3>Title: Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages. (arXiv:2305.12182v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12182">http://arxiv.org/abs/2305.12182</a></li>
<li>Code URL: <a href="https://github.com/cisnlp/glot500">https://github.com/cisnlp/glot500</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12182] Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages](http://arxiv.org/abs/2305.12182) #large language model</code></li>
<li>Summary: <p>The NLP community has mainly focused on scaling Large Language Models (LLMs)
vertically, i.e., making them better for about 100 languages. We instead scale
LLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM
that covers 511 languages, almost all of them low-resource. An important part
of this effort is to collect and clean Glot500-c, a corpus that covers these
511 languages and allows us to train Glot500-m. We evaluate Glot500-m on five
diverse tasks across these languages. We observe large improvements for both
high-resource and lowresource languages compared to an XLM-R baseline. Our
analysis shows that no single factor explains the quality of multilingual LLM
representations. Rather, a combination of factors determines quality including
corpus size, script, "help" from related languages and the total capacity of
the model. Our work addresses an important goal of NLP research: we should not
limit NLP to a small fraction of the world's languages and instead strive to
support as many languages as possible to bring the benefits of NLP technology
to all languages and cultures. Code, data and models are available at
https://github.com/cisnlp/Glot500.
</p></li>
</ul>

<h3>Title: Experimental results from applying GPT-4 to an unpublished formal language. (arXiv:2305.12196v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12196">http://arxiv.org/abs/2305.12196</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12196] Experimental results from applying GPT-4 to an unpublished formal language](http://arxiv.org/abs/2305.12196) #large language model</code></li>
<li>Summary: <p>Can large language models be used to complete mathematical tasks that are
traditionally performed either manually or with the aid of theorem provers? To
answer this question, a state-of-the-art system, GPT-4, was provided with a
concise natural language specification for a previously unpublished formal
system and asked to complete a number of tasks, from stating function and type
definitions to proving simple theorems and verifying user-supplied proofs. The
system completed all tasks successfully, showed extensive domain knowledge,
invented helpful new syntax and semantics, and exhibited generalization and
inference abilities. So the answer seems to be: yes.
</p></li>
</ul>

<h3>Title: VNHSGE: VietNamese High School Graduation Examination Dataset for Large Language Models. (arXiv:2305.12199v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12199">http://arxiv.org/abs/2305.12199</a></li>
<li>Code URL: <a href="https://github.com/xdao85/vnhsge">https://github.com/xdao85/vnhsge</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12199] VNHSGE: VietNamese High School Graduation Examination Dataset for Large Language Models](http://arxiv.org/abs/2305.12199) #large language model</code></li>
<li>Summary: <p>The VNHSGE (VietNamese High School Graduation Examination) dataset, developed
exclusively for evaluating large language models (LLMs), is introduced in this
article. The dataset, which covers nine subjects, was generated from the
Vietnamese National High School Graduation Examination and comparable tests.
300 literary essays have been included, and there are over 19,000
multiple-choice questions on a range of topics. The dataset assesses LLMs in
multitasking situations such as question answering, text generation, reading
comprehension, visual question answering, and more by including both textual
data and accompanying images. Using ChatGPT and BingChat, we evaluated LLMs on
the VNHSGE dataset and contrasted their performance with that of Vietnamese
students to see how well they performed. The results show that ChatGPT and
BingChat both perform at a human level in a number of areas, including
literature, English, history, geography, and civics education. They still have
space to grow, though, especially in the areas of mathematics, physics,
chemistry, and biology. The VNHSGE dataset seeks to provide an adequate
benchmark for assessing the abilities of LLMs with its wide-ranging coverage
and variety of activities. We intend to promote future developments in the
creation of LLMs by making this dataset available to the scientific community,
especially in resolving LLMs' limits in disciplines involving mathematics and
the natural sciences.
</p></li>
</ul>

<h3>Title: Learning Horn Envelopes via Queries from Large Language Models. (arXiv:2305.12143v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.12143">http://arxiv.org/abs/2305.12143</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.12143] Learning Horn Envelopes via Queries from Large Language Models](http://arxiv.org/abs/2305.12143) #large language model</code></li>
<li>Summary: <p>We investigate an approach for extracting knowledge from trained neural
networks based on Angluin's exact learning model with membership and
equivalence queries to an oracle. In this approach, the oracle is a trained
neural network. We consider Angluin's classical algorithm for learning Horn
theories and study the necessary changes to make it applicable to learn from
neural networks. In particular, we have to consider that trained neural
networks may not behave as Horn oracles, meaning that their underlying target
theory may not be Horn. We propose a new algorithm that aims at extracting the
``tightest Horn approximation'' of the target theory and that is guaranteed to
terminate in exponential time (in the worst case) and in polynomial time if the
target has polynomially many non-Horn examples. To showcase the applicability
of the approach, we perform experiments on pre-trained language models and
extract rules that expose occupation-based gender biases.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Novel deep learning methods for 3D flow field segmentation and classification. (arXiv:2305.11884v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11884">http://arxiv.org/abs/2305.11884</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11884] Novel deep learning methods for 3D flow field segmentation and classification](http://arxiv.org/abs/2305.11884) #segmentation</code></li>
<li>Summary: <p>Flow field segmentation and classification help researchers to understand
vortex structure and thus turbulent flow. Existing deep learning methods mainly
based on global information and focused on 2D circumstance. Based on flow field
theory, we propose novel flow field segmentation and classification deep
learning methods in three-dimensional space. We construct segmentation
criterion based on local velocity information and classification criterion
based on the relationship between local vorticity and vortex wake, to identify
vortex structure in 3D flow field, and further classify the type of vortex
wakes accurately and rapidly. Simulation experiment results showed that,
compared with existing methods, our segmentation method can identify the vortex
area more accurately, while the time consumption is reduced more than 50\%; our
classification method can reduce the time consumption by more than 90\% while
maintaining the same classification accuracy level.
</p></li>
</ul>

<h3>Title: Image2SSM: Reimagining Statistical Shape Models from Images with Radial Basis Functions. (arXiv:2305.11946v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.11946">http://arxiv.org/abs/2305.11946</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.11946] Image2SSM: Reimagining Statistical Shape Models from Images with Radial Basis Functions](http://arxiv.org/abs/2305.11946) #segmentation</code></li>
<li>Summary: <p>Statistical shape modeling (SSM) is an essential tool for analyzing
variations in anatomical morphology. In a typical SSM pipeline, 3D anatomical
images, gone through segmentation and rigid registration, are represented using
lower-dimensional shape features, on which statistical analysis can be
performed. Various methods for constructing compact shape representations have
been proposed, but they involve laborious and costly steps. We propose
Image2SSM, a novel deep-learning-based approach for SSM that leverages
image-segmentation pairs to learn a radial-basis-function (RBF)-based
representation of shapes directly from images. This RBF-based shape
representation offers a rich self-supervised signal for the network to estimate
a continuous, yet compact representation of the underlying surface that can
adapt to complex geometries in a data-driven manner. Image2SSM can characterize
populations of biological structures of interest by constructing statistical
landmark-based shape models of ensembles of anatomical shapes while requiring
minimal parameter tuning and no user assistance. Once trained, Image2SSM can be
used to infer low-dimensional shape representations from new unsegmented
images, paving the way toward scalable approaches for SSM, especially when
dealing with large cohorts. Experiments on synthetic and real datasets show the
efficacy of the proposed method compared to the state-of-art
correspondence-based method for SSM.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
