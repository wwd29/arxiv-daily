<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-11-07</h1>
<h3>Title: Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Pranav Bhandari, Nicolas Fay, Sanjeevan Selvaganapathy, Amitava Datta, Usman Naseem, Mehwish Nasim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03738">https://arxiv.org/abs/2511.03738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03738">https://arxiv.org/pdf/2511.03738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03738]] Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs(https://arxiv.org/abs/2511.03738)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models exhibit implicit personalities in their generation, but reliably controlling or aligning these traits to meet specific needs remains an open challenge. The need for effective mechanisms for behavioural manipulation of the model during generation is a critical gap in the literature that needs to be fulfilled. Personality-aware LLMs hold a promising direction towards this objective. However, the relationship between these psychological constructs and their representations within LLMs remains underexplored and requires further investigation. Moreover, it is intriguing to understand and study the use of these representations to steer the models' behaviour. We propose a novel pipeline that extracts hidden state activations from transformer layers using the Big Five Personality Traits (Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism), which is a comprehensive and empirically validated framework to model human personality applies low-rank subspace discovery methods, and identifies trait-specific optimal layers across different model architectures for robust injection. The resulting personality-aligned directions are then operationalised through a flexible steering framework with dynamic layer selection, enabling precise control of trait expression in LLM outputs. Our findings reveal that personality traits occupy a low-rank shared subspace, and that these latent structures can be transformed into actionable mechanisms for effective steering through careful perturbations without impacting the fluency, variance and general capabilities, helping to bridge the gap between psychological theory and practical model alignment.</li>
</ul>

<h3>Title: TextualVerifier: Verify TextGrad Step-by-Step</h3>
<ul>
<li><strong>Authors: </strong>Eugenius Mario Situmorang, Adila Alfa Krisnadhi, Ari Wibisono</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03739">https://arxiv.org/abs/2511.03739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03739">https://arxiv.org/pdf/2511.03739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03739]] TextualVerifier: Verify TextGrad Step-by-Step(https://arxiv.org/abs/2511.03739)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>TextGrad is a novel approach to text-based automatic differentiation that enables composite AI systems to perform optimization without explicit numerical equations. However, it currently lacks self-verification mechanisms that ensure reasoning validity in text-based decision making. This research introduces TextualVerifier, a verification framework that leverages chain-of-thought reasoning and majority voting with large language models to address this verification gap. TextualVerifier implements a four-stage workflow: chain-of-thought decomposition, variant generation, majority voting, and consensus aggregation. It integrates non-invasively with TextGrad at both the loss function and optimization result verification stages. Experimental evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1) standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically significant improvements (p < 0.001). In phase one, TextualVerifier improves the validity of reasoning steps by 29 percent. In phase two, integration into TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4 percent with a moderate overhead of 5.9 LLM calls on average. Further evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92 percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively. TextualVerifier thus presents the first self-verification framework for TextGrad through LLM-based techniques without requiring numerical gradients, enabling more reliable reasoning and opening new directions for verification in text-based optimization.</li>
</ul>

<h3>Title: Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices</h3>
<ul>
<li><strong>Authors: </strong>Youssef Elmir, Yassine Himeur, Abbes Amira</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03753">https://arxiv.org/abs/2511.03753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03753">https://arxiv.org/pdf/2511.03753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03753]] Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices(https://arxiv.org/abs/2511.03753)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, extraction, federate</a></li>
<li><strong>Abstract: </strong>This study presents a federated learning (FL) framework for privacy-preserving electrocardiogram (ECG) classification in Internet of Things (IoT) healthcare environments. By transforming 1D ECG signals into 2D Gramian Angular Field (GAF) images, the proposed approach enables efficient feature extraction through Convolutional Neural Networks (CNNs) while ensuring that sensitive medical data remain local to each device. This work is among the first to experimentally validate GAF-based federated ECG classification across heterogeneous IoT devices, quantifying both performance and communication efficiency. To evaluate feasibility in realistic IoT settings, we deployed the framework across a server, a laptop, and a resource-constrained Raspberry Pi 4, reflecting edge-cloud integration in IoT ecosystems. Experimental results demonstrate that the FL-GAF model achieves a high classification accuracy of 95.18% in a multi-client setup, significantly outperforming a single-client baseline in both accuracy and training time. Despite the added computational complexity of GAF transformations, the framework maintains efficient resource utilization and communication overhead. These findings highlight the potential of lightweight, privacy-preserving AI for IoT-based healthcare monitoring, supporting scalable and secure edge deployments in smart health systems.</li>
</ul>

<h3>Title: Laugh, Relate, Engage: Stylized Comment Generation for Short Videos</h3>
<ul>
<li><strong>Authors: </strong>Xuan Ouyang, Senan Wang, Bouzhou Wang, Siyuan Xiahou, Jinrong Zhou, Yuekang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03757">https://arxiv.org/abs/2511.03757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03757">https://arxiv.org/pdf/2511.03757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03757]] Laugh, Relate, Engage: Stylized Comment Generation for Short Videos(https://arxiv.org/abs/2511.03757)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Short-video platforms have become a central medium in the modern Internet landscape, where efficient information delivery and strong interactivity are reshaping user engagement and cultural dissemination. Among the various forms of user interaction, comments play a vital role in fostering community participation and enabling content re-creation. However, generating comments that are both compliant with platform guidelines and capable of exhibiting stylistic diversity and contextual awareness remains a significant challenge. We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for controllable short-video comment generation. The system integrates video segmentation, contextual and affective analysis, and style-aware prompt construction. It supports six distinct comment styles: puns (homophones), rhyming, meme application, sarcasm (irony), plain humor, and content extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM directly processes video inputs and achieves fine-grained style control through explicit prompt markers and few-shot examples. To support development and evaluation, we construct a bilingual dataset using official APIs from Douyin (Chinese) and YouTube (English), covering five popular video genres: comedy skits, daily life jokes, funny animal clips, humorous commentary, and talk shows. Evaluation combines automated metrics originality, relevance, and style conformity with a large-scale human preference study involving 40 videos and 105 participants. Results show that LOLGORITHM significantly outperforms baseline models, achieving preference rates of over 90% on Douyin and 87.55% on YouTube. This work presents a scalable and culturally adaptive framework for stylized comment generation on short-video platforms, offering a promising path to enhance user engagement and creative interaction.</li>
</ul>

<h3>Title: Contamination Detection for VLMs using Multi-Modal Semantic Perturbation</h3>
<ul>
<li><strong>Authors: </strong>Jaden Park, Mu Cai, Feng Yao, Jingbo Shang, Soochahn Lee, Yong Jae Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03774">https://arxiv.org/abs/2511.03774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03774">https://arxiv.org/pdf/2511.03774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03774]] Contamination Detection for VLMs using Multi-Modal Semantic Perturbation(https://arxiv.org/abs/2511.03774)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in Vision-Language Models (VLMs) have achieved state-of-the-art performance on numerous benchmark tasks. However, the use of internet-scale, often proprietary, pretraining corpora raises a critical concern for both practitioners and users: inflated performance due to test-set leakage. While prior works have proposed mitigation strategies such as decontamination of pretraining data and benchmark redesign for LLMs, the complementary direction of developing detection methods for contaminated VLMs remains underexplored. To address this gap, we deliberately contaminate open-source VLMs on popular benchmarks and show that existing detection approaches either fail outright or exhibit inconsistent behavior. We then propose a novel simple yet effective detection method based on multi-modal semantic perturbation, demonstrating that contaminated models fail to generalize under controlled perturbations. Finally, we validate our approach across multiple realistic contamination strategies, confirming its robustness and effectiveness. The code and perturbed dataset will be released publicly.</li>
</ul>

<h3>Title: Temporal Analysis Framework for Intrusion Detection Systems: A Novel Taxonomy for Time-Aware Cybersecurity</h3>
<ul>
<li><strong>Authors: </strong>Tatiana S. Parlanti, Carlos A. Catania</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03799">https://arxiv.org/abs/2511.03799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03799">https://arxiv.org/pdf/2511.03799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03799]] Temporal Analysis Framework for Intrusion Detection Systems: A Novel Taxonomy for Time-Aware Cybersecurity(https://arxiv.org/abs/2511.03799)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Most intrusion detection systems still identify attacks only after significant damage has occurred, detecting late-stage tactics rather than early indicators of compromise. This paper introduces a temporal analysis framework and taxonomy for time-aware network intrusion detection. Through a systematic review of over 40 studies published between 2020 and 2025, we classify NIDS methods according to their treatment of time, from static per-flow analysis to multi-window sequential modeling. The proposed taxonomy reveals that inter-flow sequential and temporal window-based methods provide the broadest temporal coverage across MITRE ATT&CK tactics, enabling detection from Reconnaissance through Impact stages. Our analysis further exposes systematic bias in widely used datasets, which emphasize late-stage attacks and thus limit progress toward early detection. This framework provides essential groundwork for developing IDS capable of anticipating rather than merely reacting to cyber threats, advancing the field toward truly proactive defense mechanisms.</li>
</ul>

<h3>Title: FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features</h3>
<ul>
<li><strong>Authors: </strong>Linghui Zeng, Ruixuan Liu, Atiquer Rahman Sarkar, Xiaoqian Jiang, Joyce C. Ho, Li Xiong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03806">https://arxiv.org/abs/2511.03806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03806">https://arxiv.org/pdf/2511.03806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03806]] FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features(https://arxiv.org/abs/2511.03806)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Ensuring the privacy of sensitive training data is crucial in privacy-preserving machine learning. However, in practical scenarios, privacy protection may be required for only a subset of features. For instance, in ICU data, demographic attributes like age and gender pose higher privacy risks due to their re-identification potential, whereas raw lab results are generally less sensitive. Traditional DP-SGD enforces privacy protection on all features in one sample, leading to excessive noise injection and significant utility degradation. We propose FusionDP, a two-step framework that enhances model utility under feature-level differential privacy. First, FusionDP leverages large foundation models to impute sensitive features given non-sensitive features, treating them as external priors that provide high-quality estimates of sensitive attributes without accessing the true values during model training. Second, we introduce a modified DP-SGD algorithm that trains models on both original and imputed features while formally preserving the privacy of the original sensitive features. We evaluate FusionDP on two modalities: a sepsis prediction task on tabular data from PhysioNet and a clinical note classification task from MIMIC-III. By comparing against privacy-preserving baselines, our results show that FusionDP significantly improves model performance while maintaining rigorous feature-level privacy, demonstrating the potential of foundation model-driven imputation to enhance the privacy-utility trade-off for various modalities.</li>
</ul>

<h3>Title: Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations</h3>
<ul>
<li><strong>Authors: </strong>Shivogo John</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03807">https://arxiv.org/abs/2511.03807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03807">https://arxiv.org/pdf/2511.03807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03807]] Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations(https://arxiv.org/abs/2511.03807)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Evolving borrower behaviors, shifting economic conditions, and changing regulatory landscapes continuously reshape the data distributions underlying modern credit-scoring systems. Conventional explainability techniques, such as SHAP, assume static data and fixed background distributions, making their explanations unstable and potentially unfair when concept drift occurs. This study addresses that challenge by developing adaptive explanation frameworks that recalibrate interpretability and fairness in dynamically evolving credit models. Using a multi-year credit dataset, we integrate predictive modeling via XGBoost with three adaptive SHAP variants: (A) per-slice explanation reweighting that adjusts for feature distribution shifts, (B) drift-aware SHAP rebaselining with sliding-window background samples, and (C) online surrogate calibration using incremental Ridge regression. Each method is benchmarked against static SHAP explanations using metrics of predictive performance (AUC, F1), directional and rank stability (cosine, Kendall tau), and fairness (demographic parity and recalibration). Results show that adaptive methods, particularly rebaselined and surrogate-based explanations, substantially improve temporal stability and reduce disparate impact across demographic groups without degrading predictive accuracy. Robustness tests, including counterfactual perturbations, background sensitivity analysis, and proxy-variable detection, confirm the resilience of adaptive explanations under real-world drift conditions. These findings establish adaptive explainability as a practical mechanism for sustaining transparency, accountability, and ethical reliability in data-driven credit systems, and more broadly, in any domain where decision models evolve with population change.</li>
</ul>

<h3>Title: Just in Plain Sight: Unveiling CSAM Distribution Campaigns on the Clear Web</h3>
<ul>
<li><strong>Authors: </strong>Nikolaos Lykousas, Constantinos Patsakis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03816">https://arxiv.org/abs/2511.03816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03816">https://arxiv.org/pdf/2511.03816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03816]] Just in Plain Sight: Unveiling CSAM Distribution Campaigns on the Clear Web(https://arxiv.org/abs/2511.03816)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Child sexual abuse is among the most hideous crimes, yet, after the COVID-19 pandemic, there is a huge surge in the distribution of child sexual abuse material (CSAM). Traditionally, the exchange of such material is performed on the dark web, as it provides many privacy guarantees that facilitate illicit trades. However, the introduction of end-to-end encryption platforms has brought it to the deep web. In this work, we report our findings for a campaign of spreading child sexual abuse material on the clear web. The campaign utilized at least 1,026 web pages for at least 738,286 registered users. Our analysis details the operation of such a campaign, showcasing how social networks are abused and the role of bots, but also the bypasses that are used. Going a step further and exploiting operational faults in the campaign, we gain insight into the demand for such content, as well as the dynamics of the user network that supports it.</li>
</ul>

<h3>Title: PLLuM: A Family of Polish Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jan Kocoń, Maciej Piasecki, Arkadiusz Janz, Teddy Ferdinan, Łukasz Radliński, Bartłomiej Koptyra, Marcin Oleksy, Stanisław Woźniak, Paweł Walkowiak, Konrad Wojtasik, Julia Moska, Tomasz Naskręt, Bartosz Walkowiak, Mateusz Gniewkowski, Kamil Szyc, Dawid Motyka, Dawid Banach, Jonatan Dalasiński, Ewa Rudnicka, Bartłomiej Alberski, Tomasz Walkowiak, Aleksander Szczęsny, Maciej Markiewicz, Tomasz Bernaś, Hubert Mazur, Kamil Żyta, Mateusz Tykierko, Grzegorz Chodak, Tomasz Kajdanowicz, Przemysław Kazienko, Agnieszka Karlińska, Karolina Seweryn, Anna Kołos, Maciej Chrabąszcz, Katarzyna Lorenc, Aleksandra Krasnodębska, Artur Wilczek, Katarzyna Dziewulska, Paula Betscher, Zofia Cieślińska, Katarzyna Kowol, Daria Mikoś, Maciej Trzciński, Dawid Krutul, Marek Kozłowski, Sławomir Dadas, Rafał Poświata, Michał Perełkiewicz, Małgorzata Grębowiec, Maciej Kazuła, Marcin Białas, Roman Roszko, Danuta Roszko, Jurgita Vaičenonienė, Andrius Utka, Paweł Levchuk, Paweł Kowalski, Irena Prawdzic-Jankowska, Maciej Ogrodniczuk, Monika Borys, Anna Bulińska, Wiktoria Gumienna, Witold Kieraś, Dorota Komosińska, Katarzyna Krasnowska-Kieraś, Łukasz Kobyliński, Martyna Lewandowska, Marek Łaziński, Mikołaj Łątkowski, Dawid Mastalerz, Beata Milewicz, Agnieszka Anna Mykowiecka, Angelika Peljak-Łapińska, Sandra Penno, Zuzanna Przybysz, Michał Rudolf, Piotr Rybak, Karolina Saputa, Aleksandra Tomaszewska, Aleksander Wawer, Marcin Woliński, Joanna Wołoszyn, Alina Wróblewska, Bartosz Żuk, Filip Żarnecki, Konrad Kaczyński, Anna Cichosz, Zuzanna Deckert, Monika Garnys, Izabela Grabarczyk, Wojciech Janowski, Sylwia Karasińska, Aleksandra Kujawiak, Piotr Misztela, Maria Szymańska, Karolina Walkusz, Igor Siek, Jakub Kwiatkowski, Piotr Pęzik</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03823">https://arxiv.org/abs/2511.03823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03823">https://arxiv.org/pdf/2511.03823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03823]] PLLuM: A Family of Polish Large Language Models(https://arxiv.org/abs/2511.03823)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) play a central role in modern artificial intelligence, yet their development has been primarily focused on English, resulting in limited support for other languages. We present PLLuM (Polish Large Language Model), the largest open-source family of foundation models tailored specifically for the Polish language. Developed by a consortium of major Polish research institutions, PLLuM addresses the need for high-quality, transparent, and culturally relevant language models beyond the English-centric commercial landscape. We describe the development process, including the construction of a new 140-billion-token Polish text corpus for pre-training, a 77k custom instructions dataset, and a 100k preference optimization dataset. A key component is a Responsible AI framework that incorporates strict data governance and a hybrid module for output correction and safety filtering. We detail the models' architecture, training procedures, and alignment techniques for both base and instruction-tuned variants, and demonstrate their utility in a downstream task within public administration. By releasing these models publicly, PLLuM aims to foster open research and strengthen sovereign AI technologies in Poland.</li>
</ul>

<h3>Title: STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Atif Quamar, Mohammad Areeb, Mikhail Kuznetsov, Muslum Ozgur Ozmen, Z. Berkay Celik</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03827">https://arxiv.org/abs/2511.03827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03827">https://arxiv.org/pdf/2511.03827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03827]] STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models(https://arxiv.org/abs/2511.03827)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models with human values is crucial for their safe deployment; however, existing methods, such as fine-tuning, are computationally expensive and suboptimal. In contrast, inference-time approaches like Best-of-N sampling require practically infeasible computation to achieve optimal alignment. We propose STARS: Segment-level Token Alignment with Rejection Sampling, a decoding-time algorithm that steers model generation by iteratively sampling, scoring, and rejecting/accepting short, fixed-size token segments. This allows for early correction of the generation path, significantly improving computational efficiency and boosting alignment quality. Across a suite of six LLMs, we show that STARS outperforms Supervised Fine-Tuning (SFT) by up to 14.9 percentage points and Direct Preference Optimization (DPO) by up to 4.3 percentage points on win-rates, while remaining highly competitive with strong Best-of-N baselines. Our work establishes granular, reward-guided sampling as a generalizable, robust, and efficient alternative to traditional fine-tuning and full-sequence ranking methods for aligning LLMs.</li>
</ul>

<h3>Title: From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification</h3>
<ul>
<li><strong>Authors: </strong>Lipeng Zu, Hansong Zhou, Xiaonan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03828">https://arxiv.org/abs/2511.03828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03828">https://arxiv.org/pdf/2511.03828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03828]] From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification(https://arxiv.org/abs/2511.03828)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Transitioning from offline to online reinforcement learning (RL) poses critical challenges due to distributional shifts between the fixed behavior policy in the offline dataset and the evolving policy during online learning. Although this issue is widely recognized, few methods attempt to explicitly assess or utilize the distributional structure of the offline data itself, leaving a research gap in adapting learning strategies to different types of samples. To address this challenge, we propose an innovative method, Energy-Guided Diffusion Stratification (StratDiff), which facilitates smoother transitions in offline-to-online RL. StratDiff deploys a diffusion model to learn prior knowledge from the offline dataset. It then refines this knowledge through energy-based functions to improve policy imitation and generate offline-like actions during online fine-tuning. The KL divergence between the generated action and the corresponding sampled action is computed for each sample and used to stratify the training batch into offline-like and online-like subsets. Offline-like samples are updated using offline objectives, while online-like samples follow online learning strategies. We demonstrate the effectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL and IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff significantly outperforms existing methods, achieving enhanced adaptability and more stable performance across diverse RL settings.</li>
</ul>

<h3>Title: Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification</h3>
<ul>
<li><strong>Authors: </strong>Mikołaj Langner, Jan Eliasz, Ewa Rudnicka, Jan Kocoń</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03830">https://arxiv.org/abs/2511.03830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03830">https://arxiv.org/pdf/2511.03830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03830]] Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification(https://arxiv.org/abs/2511.03830)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce a method for efficient multi-label text classification with large language models (LLMs), built on reformulating classification tasks as sequences of dichotomic (yes/no) decisions. Instead of generating all labels in a single structured response, each target dimension is queried independently, which, combined with a prefix caching mechanism, yields substantial efficiency gains for short-text inference without loss of accuracy. To demonstrate the approach, we focus on affective text analysis, covering 24 dimensions including emotions and sentiment. Using LLM-to-SLM distillation, a powerful annotator model (DeepSeek-V3) provides multiple annotations per text, which are aggregated to fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B, Gemma3-1B). The fine-tuned models show significant improvements over zero-shot baselines, particularly on the dimensions seen during training. Our findings suggest that decomposing multi-label classification into dichotomic queries, combined with distillation and cache-aware inference, offers a scalable and effective framework for LLM-based classification. While we validate the method on affective states, the approach is general and applicable across domains.</li>
</ul>

<h3>Title: Security Analysis of Agentic AI Communication Protocols: A Comparative Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Yedidel Louck, Ariel Stulman, Amit Dvir</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03841">https://arxiv.org/abs/2511.03841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03841">https://arxiv.org/pdf/2511.03841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03841]] Security Analysis of Agentic AI Communication Protocols: A Comparative Evaluation(https://arxiv.org/abs/2511.03841)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, robust</a></li>
<li><strong>Abstract: </strong>Multi-agent systems (MAS) powered by artificial intelligence (AI) are increasingly foundational to complex, distributed workflows. Yet, the security of their underlying communication protocols remains critically under-examined. This paper presents the first empirical, comparative security analysis of the official CORAL implementation and a high-fidelity, SDK-based ACP implementation, benchmarked against a literature-based evaluation of A2A. Using a 14 point vulnerability taxonomy, we systematically assess their defenses across authentication, authorization, integrity, confidentiality, and availability. Our results reveal a pronounced security dichotomy: CORAL exhibits a robust architectural design, particularly in its transport-layer message validation and session isolation, but suffers from critical implementation-level vulnerabilities, including authentication and authorization failures at its SSE gateway. Conversely, ACP's architectural flexibility, most notably its optional JWS enforcement, translates into high-impact integrity and confidentiality flaws. We contextualize these findings within current industry trends, highlighting that existing protocols remain insufficiently secure. As a path forward, we recommend a hybrid approach that combines CORAL's integrated architecture with ACP's mandatory per-message integrity guarantees, laying the groundwork for resilient, next-generation agent communications.</li>
</ul>

<h3>Title: Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets</h3>
<ul>
<li><strong>Authors: </strong>Duong Mai, Lawrence Hall</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03855">https://arxiv.org/abs/2511.03855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03855">https://arxiv.org/pdf/2511.03855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03855]] Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets(https://arxiv.org/abs/2511.03855)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learned (DL) models for image recognition have been shown to fail to generalize to data from different devices, populations, etc. COVID-19 detection from Chest X-rays (CXRs), in particular, has been shown to fail to generalize to out-of-distribution (OOD) data from new clinical sources not covered in the training set. This occurs because models learn to exploit shortcuts - source-specific artifacts that do not translate to new distributions - rather than reasonable biomarkers to maximize performance on in-distribution (ID) data. Rendering the models more robust to distribution shifts, our study investigates the use of fundamental noise injection techniques (Gaussian, Speckle, Poisson, and Salt and Pepper) during training. Our empirical results demonstrate that this technique can significantly reduce the performance gap between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results averaged over ten random seeds across key metrics such as AUC, F1, accuracy, recall and specificity. Our source code is publicly available at this https URL</li>
</ul>

<h3>Title: Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures</h3>
<ul>
<li><strong>Authors: </strong>Florence Klitzner, Blanca Inigo, Benjamin D. Killeen, Lalithkumar Seenivasan, Michelle Song, Axel Krieger, Mathias Unberath</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03882">https://arxiv.org/abs/2511.03882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03882">https://arxiv.org/pdf/2511.03882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03882]] Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures(https://arxiv.org/abs/2511.03882)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Imitation learning-based robot control policies are enjoying renewed interest in video-based robotics. However, it remains unclear whether this approach applies to X-ray-guided procedures, such as spine instrumentation. This is because interpretation of multi-view X-rays is complex. We examine opportunities and challenges for imitation policy learning in bi-plane-guided cannula insertion. We develop an in silico sandbox for scalable, automated simulation of X-ray-guided spine procedures with a high degree of realism. We curate a dataset of correct trajectories and corresponding bi-planar X-ray sequences that emulate the stepwise alignment of providers. We then train imitation learning policies for planning and open-loop control that iteratively align a cannula solely based on visual information. This precisely controlled setup offers insights into limitations and capabilities of this method. Our policy succeeded on the first attempt in 68.5% of cases, maintaining safe intra-pedicular trajectories across diverse vertebral levels. The policy generalized to complex anatomy, including fractures, and remained robust to varied initializations. Rollouts on real bi-planar X-rays further suggest that the model can produce plausible trajectories, despite training exclusively in simulation. While these preliminary results are promising, we also identify limitations, especially in entry point precision. Full closed-look control will require additional considerations around how to provide sufficiently frequent feedback. With more robust priors and domain knowledge, such models may provide a foundation for future efforts toward lightweight and CT-free robotic intra-operative spinal navigation.</li>
</ul>

<h3>Title: Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model</h3>
<ul>
<li><strong>Authors: </strong>Abdulmumin Sa'ad, Sulaimon Oyeniyi Adebayo, Abdul Jabbar Siddiqui</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03888">https://arxiv.org/abs/2511.03888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03888">https://arxiv.org/pdf/2511.03888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03888]] Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model(https://arxiv.org/abs/2511.03888)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The global waste crisis is escalating, with solid waste generation expected to increase by 70% by 2050. Traditional waste collection methods, particularly in remote or harsh environments like deserts, are labor-intensive, inefficient, and often hazardous. Recent advances in computer vision and deep learning have opened the door to automated waste detection systems, yet most research focuses on urban environments and recyclable materials, overlooking organic and hazardous waste and underexplored terrains such as deserts. In this work, we propose an enhanced real-time object detection framework based on a pruned, lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT) and specialized data augmentation strategies. Using the DroneTrashNet dataset, we demonstrate significant improvements in precision, recall, and mean average precision (mAP), while achieving low latency and compact model size suitable for deployment on resource-constrained aerial drones. Benchmarking our model against state-of-the-art lightweight YOLO variants further highlights its optimal balance of accuracy and efficiency. Our results validate the effectiveness of combining data-centric and model-centric enhancements for robust, real-time waste detection in desert environments.</li>
</ul>

<h3>Title: Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition</h3>
<ul>
<li><strong>Authors: </strong>Hlali Azzeddine, Majid Ben Yakhlef, Soulaiman El Hazzat</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03891">https://arxiv.org/abs/2511.03891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03891">https://arxiv.org/pdf/2511.03891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03891]] Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition(https://arxiv.org/abs/2511.03891)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Small, imbalanced datasets and poor input image quality can lead to high false predictions rates with deep learning models. This paper introduces Class-Based Image Composition, an approach that allows us to reformulate training inputs through a fusion of multiple images of the same class into combined visual composites, named Composite Input Images (CoImg). That enhances the intra-class variance and improves the valuable information density per training sample and increases the ability of the model to distinguish between subtle disease patterns. Our method was evaluated on the Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et al., 2024), which contains 2,064 high-resolution optical coherence tomography (OCT) scans of the human retina, representing seven distinct diseases with a significant class imbalance. We constructed a perfectly class-balanced version of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout composite image. To assess the effectiveness of this new representation, we conducted a comparative analysis between the original dataset and its variant using a VGG16 model. A fair comparison was ensured by utilizing the identical model architecture and hyperparameters for all experiments. The proposed approach markedly improved diagnostic this http URL enhanced Dataset achieved near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared to a baseline model trained on raw dataset. The false prediction rate was also significantly lower, this demonstrates that the method can producehigh-quality predictions even for weak datasets affected by class imbalance or small sample size.</li>
</ul>

<h3>Title: Secure Code Generation at Scale with Reflexion</h3>
<ul>
<li><strong>Authors: </strong>Arup Datta, Ahmed Aljohani, Hyunsook Do</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CE, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03898">https://arxiv.org/abs/2511.03898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03898">https://arxiv.org/pdf/2511.03898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03898]] Secure Code Generation at Scale with Reflexion(https://arxiv.org/abs/2511.03898)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are now widely used to draft and refactor code, but code that works is not necessarily secure. We evaluate secure code generation using the Instruct Prime, which eliminated compliance-required prompts and cue contamination, and evaluate five instruction-tuned code LLMs using a zero-shot baseline and a three-round reflexion prompting approach. Security is measured using the Insecure Code Detector (ICD), and results are reported by measuring Repair, Regression, and NetGain metrics, considering the programming language and CWE family. Our findings show that insecurity remains common at the first round: roughly 25-33% of programs are insecure at a zero-shot baseline (t0 ). Weak cryptography/config-dependent bugs are the hardest to avoid while templated ones like XSS, code injection, and hard-coded secrets are handled more reliably. Python yields the highest secure rates; C and C# are the lowest, with Java, JS, PHP, and C++ in the middle. Reflexion prompting improves security for all models, improving average accuracy from 70.74% at t0 to 79.43% at t3 , with the largest gains in the first round followed by diminishing returns. The trends with Repair, Regression, and NetGain metrics show that applying one to two rounds produces most of the benefits. A replication package is available at this https URL.</li>
</ul>

<h3>Title: GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Manh Nguyen, Sunil Gupta, Dai Do, Hung Le</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03900">https://arxiv.org/abs/2511.03900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03900">https://arxiv.org/pdf/2511.03900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03900]] GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation(https://arxiv.org/abs/2511.03900)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hallucination mitigation remains a persistent challenge for large language models (LLMs), even as model scales grow. Existing approaches often rely on external knowledge sources, such as structured databases or knowledge graphs, accessed through prompting or retrieval. However, prompt-based grounding is fragile and domain-sensitive, while symbolic knowledge integration incurs heavy retrieval and formatting costs. Motivated by knowledge graphs, we introduce Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds generation in corpus-derived evidence without retraining. GRAD constructs a sparse token transition graph by accumulating next-token logits across a small retrieved corpus in a single forward pass. During decoding, graph-retrieved logits are max-normalized and adaptively fused with model logits to favor high-evidence continuations while preserving fluency. Across three models and a range of question-answering benchmarks spanning intrinsic, extrinsic hallucination, and factuality tasks, GRAD consistently surpasses baselines, achieving up to 9.7$\%$ higher intrinsic accuracy, 8.6$\%$ lower hallucination rates, and 6.9$\%$ greater correctness compared to greedy decoding, while attaining the highest truth--informativeness product score among all methods. GRAD offers a lightweight, plug-and-play alternative to contrastive decoding and knowledge graph augmentation, demonstrating that statistical evidence from corpus-level token transitions can effectively steer generation toward more truthful and verifiable outputs.</li>
</ul>

<h3>Title: DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory Budgets</h3>
<ul>
<li><strong>Authors: </strong>Sanggeon Yun, Hyunwoo Oh, Ryozo Masukawa, Mohsen Imani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03911">https://arxiv.org/abs/2511.03911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03911">https://arxiv.org/pdf/2511.03911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03911]] DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory Budgets(https://arxiv.org/abs/2511.03911)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Decomposition is a proven way to shrink deep networks without changing I/O. We bring this idea to hyperdimensional computing (HDC), where footprint cuts usually shrink the feature axis and erode concentration and robustness. Prior HDC decompositions decode via fixed atomic hypervectors, which are ill-suited for compressing learned class prototypes. We introduce DecoHD, which learns directly in a decomposed HDC parameterization: a small, shared set of per-layer channels with multiplicative binding across layers and bundling at the end, yielding a large representational space from compact factors. DecoHD compresses along the class axis via a lightweight bundling head while preserving native bind-bundle-score; training is end-to-end, and inference remains pure HDC, aligning with in/near-memory accelerators. In evaluation, DecoHD attains extreme memory savings with only minor accuracy degradation under tight deployment budgets. On average it stays within about 0.1-0.15% of a strong non-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip noise, reaches its accuracy plateau with up to ~97% fewer trainable parameters, and -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU (AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x over a baseline HDC ASIC.</li>
</ul>

<h3>Title: I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Nand Kumar Yadav, Rodrigue Rizk, William CW Chen, KC Santosh (AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03912">https://arxiv.org/abs/2511.03912</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03912">https://arxiv.org/pdf/2511.03912</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03912]] I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging(https://arxiv.org/abs/2511.03912)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Unknown anomaly detection in medical imaging remains a fundamental challenge due to the scarcity of labeled anomalies and the high cost of expert supervision. We introduce an unsupervised, oracle-free framework that incrementally expands a trusted set of normal samples without any anomaly labels. Starting from a small, verified seed of normal images, our method alternates between lightweight adapter updates and uncertainty-gated sample admission. A frozen pretrained vision backbone is augmented with tiny convolutional adapters, ensuring rapid domain adaptation with negligible computational overhead. Extracted embeddings are stored in a compact coreset enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during incremental expansion is enforced by dual probabilistic gates, a sample is admitted into the normal memory only if its distance to the existing coreset lies within a calibrated z-score threshold, and its SWAG-based epistemic uncertainty remains below a seed-calibrated bound. This mechanism prevents drift and false inclusions without relying on generative reconstruction or replay buffers. Empirically, our system steadily refines the notion of normality as unlabeled data arrive, producing substantial gains over baselines. On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5, ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These results highlight the effectiveness and efficiency of the proposed framework for real-world, label-scarce medical imaging applications.</li>
</ul>

<h3>Title: The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023</h3>
<ul>
<li><strong>Authors: </strong>Stefano M. Iacus, Devika Jain, Andrea Nasuto, Giuseppe Porro, Marcello Carammia, Andrea Vezzulli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03915">https://arxiv.org/abs/2511.03915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03915">https://arxiv.org/pdf/2511.03915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03915]] The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023(https://arxiv.org/abs/2511.03915)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Quantifying human flourishing, a multidimensional construct including happiness, health, purpose, virtue, relationships, and financial stability, is critical for understanding societal well-being beyond economic indicators. Existing measures often lack fine spatial and temporal resolution. Here we introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned large language models to classify expressions across 48 indicators aligned with Harvard's Global Flourishing Study framework plus attitudes towards migration and perception of corruption. The dataset offers monthly and yearly county- and state-level indicators of flourishing-related discourse, validated to confirm that the measures accurately represent the underlying constructs and show expected correlations with established indicators. This resource enables multidisciplinary analyses of well-being, inequality, and social change at unprecedented resolution, offering insights into the dynamics of human flourishing as reflected in social media discourse across the United States over the past decade.</li>
</ul>

<h3>Title: On Predicting Sociodemographics from Mobility Signals</h3>
<ul>
<li><strong>Authors: </strong>Ekin Uğurel, Cynthia Chen, Brian H. Y. Lee, Filipe Rodrigues</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03924">https://arxiv.org/abs/2511.03924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03924">https://arxiv.org/pdf/2511.03924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03924]] On Predicting Sociodemographics from Mobility Signals(https://arxiv.org/abs/2511.03924)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Inferring sociodemographic attributes from mobility data could help transportation planners better leverage passively collected datasets, but this task remains difficult due to weak and inconsistent relationships between mobility patterns and sociodemographic traits, as well as limited generalization across contexts. We address these challenges from three angles. First, to improve predictive accuracy while retaining interpretability, we introduce a behaviorally grounded set of higher-order mobility descriptors based on directed mobility graphs. These features capture structured patterns in trip sequences, travel modes, and social co-travel, and significantly improve prediction of age, gender, income, and household structure over baselines features. Second, we introduce metrics and visual diagnostic tools that encourage evenness between model confidence and accuracy, enabling planners to quantify uncertainty. Third, to improve generalization and sample efficiency, we develop a multitask learning framework that jointly predicts multiple sociodemographic attributes from a shared representation. This approach outperforms single-task models, particularly when training data are limited or when applying models across different time periods (i.e., when the test set distribution differs from the training set).</li>
</ul>

<h3>Title: SynQuE: Estimating Synthetic Dataset Quality Without Annotations</h3>
<ul>
<li><strong>Authors: </strong>Arthur Chen, Victor Zhong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03928">https://arxiv.org/abs/2511.03928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03928">https://arxiv.org/pdf/2511.03928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03928]] SynQuE: Estimating Synthetic Dataset Quality Without Annotations(https://arxiv.org/abs/2511.03928)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>We introduce and formalize the Synthetic Dataset Quality Estimation (SynQuE) problem: ranking synthetic datasets by their expected real-world task performance using only limited unannotated real data. This addresses a critical and open challenge where data is scarce due to collection costs or privacy constraints. We establish the first comprehensive benchmarks for this problem by introducing and evaluating proxy metrics that choose synthetic data for training to maximize task performance on real data. We introduce the first proxy metrics for SynQuE by adapting distribution and diversity-based distance measures to our context via embedding models. To address the shortcomings of these metrics on complex planning tasks, we propose LENS, a novel proxy that leverages large language model reasoning. Our results show that SynQuE proxies correlate with real task performance across diverse tasks, including sentiment analysis, Text2SQL, web navigation, and image classification, with LENS consistently outperforming others on complex tasks by capturing nuanced characteristics. For instance, on text-to-SQL parsing, training on the top-3 synthetic datasets selected via SynQuE proxies can raise accuracy from 30.4% to 38.4 (+8.1)% on average compared to selecting data indiscriminately. This work establishes SynQuE as a practical framework for synthetic data selection under real-data scarcity and motivates future research on foundation model-based data characterization and fine-grained data selection.</li>
</ul>

<h3>Title: NVIDIA Nemotron Nano V2 VL</h3>
<ul>
<li><strong>Authors: </strong>NVIDIA: Amala Sanjay Deshmukh, Kateryna Chumachenko, Tuomas Rintamaki, Matthieu Le, Tyler Poon, Danial Mohseni Taheri, Ilia Karmanov, Guilin Liu, Jarno Seppanen, Guo Chen, Karan Sapra, Zhiding Yu, Adi Renduchintala, Charles Wang, Peter Jin, Arushi Goel, Mike Ranzinger, Lukas Voegtle, Philipp Fischer, Timo Roman, Wei Ping, Boxin Wang, Zhuolin Yang, Nayeon Lee, Shaokun Zhang, Fuxiao Liu, Zhiqi Li, Di Zhang, Greg Heinrich, Hongxu (Danny)Yin, Song Han, Pavlo Molchanov, Parth Mannan, Yao Xu, Jane Polak Scowcroft, Tom Balough, Subhashree Radhakrishnan, Paris Zhang, Sean Cha, Ratnesh Kumar, Zaid Pervaiz Bhat, Jian Zhang, Darragh Hanley, Pritam Biswas, Jesse Oliver, Kevin Vasques, Roger Waleffe, Duncan Riach, Oluwatobi Olabiyi, Ameya Sunil Mahabaleshwarkar, Bilal Kartal, Pritam Gundecha, Khanh Nguyen, Alexandre Milesi, Eugene Khvedchenia, Ran Zilberstein, Ofri Masad, Natan Bagrov, Nave Assaf, Tomer Asida, Daniel Afrimi, Amit Zuker, Netanel Haber, Zhiyu Cheng, Jingyu (Justin)Xin, Di (Allan)Wu, Nik Spirin, Maryam Moosaei, Roman Ageev, Vanshil Atul Shah, Yuting Wu, Daniel Korzekwa, Unnikrishnan Kizhakkemadam Sreekumar, Wanli Jiang, Padmavathy Subramanian, Alejandra Rico, Sandip Bhaskar, Saeid Motiian, Kedi Wu, Annie Surla, Chia-Chih Chen, Hayden Wolff, Matthew Feinberg, Melissa Corpuz, Marek Wawrzos, Eileen Long, Aastha Jhunjhunwala, Paul Hendricks, Farzan Memarian, Benika Hall, Xin-Yu Wang, David Mosallanezhad, Soumye Singhal, Luis Vega, Katherine Cheung, Krzysztof Pawelec, Michael Evans, Katherine Luna, Jie Lou, Erick Galinkin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03929">https://arxiv.org/abs/2511.03929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03929">https://arxiv.org/pdf/2511.03929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03929]] NVIDIA Nemotron Nano V2 VL(https://arxiv.org/abs/2511.03929)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce Nemotron Nano V2 VL, the latest model of the Nemotron vision-language series designed for strong real-world document understanding, long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers significant improvements over our previous model, Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major enhancements in model architecture, datasets, and training recipes. Nemotron Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and innovative token reduction techniques to achieve higher inference throughput in long document and video scenarios. We are releasing model checkpoints in BF16, FP8, and FP4 formats and sharing large parts of our datasets, recipes and training code.</li>
</ul>

<h3>Title: LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction</h3>
<ul>
<li><strong>Authors: </strong>Sanggeon Yun, Hyunwoo Oh, Ryozo Masukawa, Pietro Mercati, Nathaniel D. Bastian, Mohsen Imani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03938">https://arxiv.org/abs/2511.03938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03938">https://arxiv.org/pdf/2511.03938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03938]] LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction(https://arxiv.org/abs/2511.03938)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hyperdimensional computing (HDC) suits memory, energy, and reliability-constrained systems, yet the standard "one prototype per class" design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior compaction reduces $D$ (feature axis), improving storage/compute but weakening robustness. We introduce LogHD, a logarithmic class-axis reduction that replaces the $C$ per-class prototypes with $n\!\approx\!\lceil\log_k C\rceil$ bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional activation space, cutting memory to $O(D\log_k C)$ while preserving $D$. LogHD uses a capacity-aware codebook and profile-based decoding, and composes with feature-axis sparsification. Across datasets and injected bit flips, LogHD attains competitive accuracy with smaller models and higher resilience at matched memory. Under equal memory, it sustains target accuracy at roughly $2.5$-$3.0\times$ higher bit-flip rates than feature-axis compression; an ASIC instantiation delivers $498\times$ energy efficiency and $62.6\times$ speedup over an AMD Ryzen 9 9950X and $24.3\times$/$6.58\times$ over an NVIDIA RTX 4090, and is $4.06\times$ more energy-efficient and $2.19\times$ faster than a feature-axis HDC ASIC baseline.</li>
</ul>

<h3>Title: RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods</h3>
<ul>
<li><strong>Authors: </strong>Raghav Sharma, Manan Mehta, Sai Tiger Raina</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03939">https://arxiv.org/abs/2511.03939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03939">https://arxiv.org/pdf/2511.03939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03939]] RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods(https://arxiv.org/abs/2511.03939)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) is the standard for aligning Large Language Models (LLMs), yet recent progress has moved beyond canonical text-based methods. This survey synthesizes the new frontier of alignment research by addressing critical gaps in multi-modal alignment, cultural fairness, and low-latency optimization. To systematically explore these domains, we first review foundational algo- rithms, including PPO, DPO, and GRPO, before presenting a detailed analysis of the latest innovations. By providing a comparative synthesis of these techniques and outlining open challenges, this work serves as an essential roadmap for researchers building more robust, efficient, and equitable AI systems.</li>
</ul>

<h3>Title: Direct Semantic Communication Between Large Language Models via Vector Translation</h3>
<ul>
<li><strong>Authors: </strong>Fu-Chun Yang, Jason Eshraghian</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03945">https://arxiv.org/abs/2511.03945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03945">https://arxiv.org/pdf/2511.03945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03945]] Direct Semantic Communication Between Large Language Models via Vector Translation(https://arxiv.org/abs/2511.03945)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In multi-agent settings, such as debate, reflection, or tool-calling, large language models (LLMs) pass messages as plain tokens, discarding most latent semantics. This constrains information transfer and adds unnecessary computational overhead. We form a latent bridge via vector translations, which use learned mappings that enable direct semantic exchange between representation spaces. A dual-encoder translator trained between Llama-2-7B and Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the translated vectors at 30 percent blending strength steers the target model's generation without destabilizing logits. Bidirectional evaluation shows a 2.01:1 transfer asymmetry, indicating that general-purpose models yield more transferable representations than instruction-tuned variants. This conservative injection preserves computational stability while demonstrating that cross-model latent communication is feasible, enabling collaborative AI systems that share meaning rather than tokens.</li>
</ul>

<h3>Title: PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Mingliang Hou, Yinuo Wang, Teng Guo, Zitao Liu, Wenzhou Dou, Jiaqi Zheng, Renqiang Luo, Mi Tian, Weiqi Luo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03966">https://arxiv.org/abs/2511.03966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03966">https://arxiv.org/pdf/2511.03966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03966]] PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis(https://arxiv.org/abs/2511.03966)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>The need to remove specific student data from cognitive diagnosis (CD) models has become a pressing requirement, driven by users' growing assertion of their "right to be forgotten". However, existing CD models are largely designed without privacy considerations and lack effective data unlearning mechanisms. Directly applying general purpose unlearning algorithms is suboptimal, as they struggle to balance unlearning completeness, model utility, and efficiency when confronted with the unique heterogeneous structure of CD models. To address this, our paper presents the first systematic study of the data unlearning problem for CD models, proposing a novel and efficient algorithm: hierarchical importanceguided forgetting (HIF). Our key insight is that parameter importance in CD models exhibits distinct layer wise characteristics. HIF leverages this via an innovative smoothing mechanism that combines individual and layer, level importance, enabling a more precise distinction of parameters associated with the data to be unlearned. Experiments on three real world datasets show that HIF significantly outperforms baselines on key metrics, offering the first effective solution for CD models to respond to user data removal requests and for deploying high-performance, privacy preserving AI systems</li>
</ul>

<h3>Title: Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images</h3>
<ul>
<li><strong>Authors: </strong>Sam Bahrami, Dylan Campbell</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03970">https://arxiv.org/abs/2511.03970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03970">https://arxiv.org/pdf/2511.03970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03970]] Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images(https://arxiv.org/abs/2511.03970)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modern scene reconstruction methods are able to accurately recover 3D surfaces that are visible in one or more images. However, this leads to incomplete reconstructions, missing all occluded surfaces. While much progress has been made on reconstructing entire objects given partial observations using generative models, the structural elements of a scene, like the walls, floors and ceilings, have received less attention. We argue that these scene elements should be relatively easy to predict, since they are typically planar, repetitive and simple, and so less costly approaches may be suitable. In this work, we present a synthetic dataset -- Room Envelopes -- that facilitates progress on this task by providing a set of RGB images and two associated pointmaps for each image: one capturing the visible surface and one capturing the first surface once fittings and fixtures are removed, that is, the structural layout. As we show, this enables direct supervision for feed-forward monocular geometry estimators that predict both the first visible surface and the first layout surface. This confers an understanding of the scene's extent, as well as the shape and location of its objects.</li>
</ul>

<h3>Title: Design and Detection of Covert Man-in-the-Middle Cyberattacks on Water Treatment Plants</h3>
<ul>
<li><strong>Authors: </strong>Victor Mattos, João Henrique Schmidt, Amit Bhaya, Alan Oliveira de Sá, Daniel Sadoc Menasché, Gaurav Srivastava</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03971">https://arxiv.org/abs/2511.03971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03971">https://arxiv.org/pdf/2511.03971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03971]] Design and Detection of Covert Man-in-the-Middle Cyberattacks on Water Treatment Plants(https://arxiv.org/abs/2511.03971)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Cyberattacks targeting critical infrastructures, such as water treatment facilities, represent significant threats to public health, safety, and the environment. This paper introduces a systematic approach for modeling and assessing covert man-in-the-middle (MitM) attacks that leverage system identification techniques to inform the attack design. We focus on the attacker's ability to deploy a covert controller, and we evaluate countermeasures based on the Process-Aware Stealthy Attack Detection (PASAD) anomaly detection method. Using a second-order linear time-invariant with time delay model, representative of water treatment dynamics, we design and simulate stealthy attacks. Our results highlight how factors such as system noise and inaccuracies in the attacker's plant model influence the attack's stealthiness, underscoring the need for more robust detection strategies in industrial control environments.</li>
</ul>

<h3>Title: PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction</h3>
<ul>
<li><strong>Authors: </strong>Xu Zou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03976">https://arxiv.org/abs/2511.03976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03976">https://arxiv.org/pdf/2511.03976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03976]] PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction(https://arxiv.org/abs/2511.03976)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable evolutionary trajectory, characterized by the continual emergence of immune-evasive variants. This poses persistent challenges to public health and vaccine development. While large-scale generative pre-trained transformers (GPTs) have revolutionized the modeling of sequential data, their direct applications to noisy viral genomic sequences are limited. In this paper, we introduce PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based on evolutionary trajectories derived from phylogenetic trees rather than raw RNA sequences. This method effectively mitigates sequencing noise and captures the hierarchical structure of viral evolution. With a weighted training framework to address substantial geographical and temporal imbalances in global sequence data, PETRA excels in predicting future SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide mutations and 17.10\% for spike amino-acid mutations, compared to 0.49% and 6.64% respectively for the best baseline. PETRA also demonstrates its ability to aid in the real-time mutation prediction of major clades like 24F(XEC) and 25A(LP.8.1). The code is open sourced on this https URL</li>
</ul>

<h3>Title: TwIST: Rigging the Lottery in Transformers with Independent Subnetwork Training</h3>
<ul>
<li><strong>Authors: </strong>Michael Menezes, Barbara Su, Xinze Feng, Yehya Farhat, Hamza Shili, Anastasios Kyrillidis</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03983">https://arxiv.org/abs/2511.03983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03983">https://arxiv.org/pdf/2511.03983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03983]] TwIST: Rigging the Lottery in Transformers with Independent Subnetwork Training(https://arxiv.org/abs/2511.03983)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>We introduce TwIST, a distributed training framework for efficient large language model (LLM) sparsification. TwIST trains multiple subnetworks in parallel, periodically aggregates their parameters, and resamples new subnetworks during training. This process identifies high-quality subnetworks ("golden tickets") without requiring post-training procedures such as calibration or Hessian-based recovery. As a result, TwIST enables zero-cost pruning at deployment time while achieving perplexity competitive with state-of-the-art post-training sparsification methods. The benefits are most pronounced under aggressive sparsity (e.g., 50%+), where TwIST significantly outperforms baseline methods; for example, reaching 23.14 PPL compared to 31.64 for the closest prior approach. Unlike unstructured pruning, TwIST produces structured, dense matrices that offer practical inference speedups and memory reductions on commodity hardware (e.g., CPUs) that do not support efficient sparse computation. TwIST provides an efficient training-time path to deployable sparse LLMs without additional fine-tuning or recovery overhead.</li>
</ul>

<h3>Title: CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yuwen Tao, Kanglei Zhou, Xin Tan, Yuan Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03992">https://arxiv.org/abs/2511.03992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03992">https://arxiv.org/pdf/2511.03992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03992]] CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation(https://arxiv.org/abs/2511.03992)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret free-form language expressions and localize the corresponding 3D regions in Gaussian fields. While recent advances have introduced cross-modal alignment between language and 3D geometry, existing pipelines still struggle with cross-view consistency due to their reliance on 2D rendered pseudo supervision and view specific feature learning. In this work, we present Camera Aware Referring Field (CaRF), a fully differentiable framework that operates directly in the 3D Gaussian space and achieves multi view consistency. Specifically, CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates camera geometry into Gaussian text interactions to explicitly model view dependent variations and enhance geometric reasoning. Building on this, In Training Paired View Supervision (ITPVS) is proposed to align per Gaussian logits across calibrated views during training, effectively mitigating single view overfitting and exposing inter view discrepancies for optimization. Extensive experiments on three representative benchmarks demonstrate that CaRF achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively. Moreover, this work promotes more reliable and view consistent 3D scene understanding, with potential benefits for embodied AI, AR/VR interaction, and autonomous perception.</li>
</ul>

<h3>Title: Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible Intelligence in Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Berk Iskar, Michael Taynnan Barros</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03993">https://arxiv.org/abs/2511.03993</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03993">https://arxiv.org/pdf/2511.03993</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03993]] Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible Intelligence in Anomaly Detection(https://arxiv.org/abs/2511.03993)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Network anomaly detection systems encounter several challenges with traditional detectors trained offline. They become susceptible to concept drift and new threats such as zero-day or polymorphic attacks. To address this limitation, we propose a Ca$^{2+}$-modulated learning framework that draws inspiration from astrocytic Ca$^{2+}$ signaling in the brain, where rapid, context-sensitive adaptation enables robust information processing. Our approach couples a multicellular astrocyte dynamics simulator with a deep neural network (DNN). The simulator models astrocytic Ca$^{2+}$ dynamics through three key mechanisms: IP$_3$-mediated Ca$^{2+}$ release, SERCA pump uptake, and conductance-aware diffusion through gap junctions between cells. Evaluation of our proposed network on CTU-13 (Neris) network traffic data demonstrates the effectiveness of our biologically plausible approach. The Ca$^{2+}$-gated model outperforms a matched baseline DNN, achieving up to $\sim$98\% accuracy with reduced false positives and negatives across multiple train/test splits. Importantly, this improved performance comes with negligible runtime overhead once Ca$^{2+}$ trajectories are precomputed. While demonstrated here for cybersecurity applications, this Ca$^{2+}$-modulated learning framework offers a generic solution for streaming detection tasks that require rapid, biologically grounded adaptation to evolving data patterns.</li>
</ul>

<h3>Title: Hybrid Fuzzing with LLM-Guided Input Mutation and Semantic Feedback</h3>
<ul>
<li><strong>Authors: </strong>Shiyin Lin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03995">https://arxiv.org/abs/2511.03995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03995">https://arxiv.org/pdf/2511.03995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03995]] Hybrid Fuzzing with LLM-Guided Input Mutation and Semantic Feedback(https://arxiv.org/abs/2511.03995)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Software fuzzing has become a cornerstone in automated vulnerability discovery, yet existing mutation strategies often lack semantic awareness, leading to redundant test cases and slow exploration of deep program states. In this work, I present a hybrid fuzzing framework that integrates static and dynamic analysis with Large Language Model (LLM)-guided input mutation and semantic feedback. Static analysis extracts control-flow and data-flow information, which is transformed into structured prompts for the LLM to generate syntactically valid and semantically diverse inputs. During execution, I augment traditional coverage-based feedback with semantic feedback signals-derived from program state changes, exception types, and output semantics-allowing the fuzzer to prioritize inputs that trigger novel program behaviors beyond mere code coverage. I implement our approach atop AFL++, combining program instrumentation with embedding-based semantic similarity metrics to guide seed selection. Evaluation on real-world open-source targets, including libpng, tcpdump, and sqlite, demonstrates that our method achieves faster time-to-first-bug, higher semantic diversity, and a competitive number of unique bugs compared to state-of-the-art fuzzers. This work highlights the potential of combining LLM reasoning with semantic-aware feedback to accelerate and deepen vulnerability discovery.</li>
</ul>

<h3>Title: PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection</h3>
<ul>
<li><strong>Authors: </strong>Peiyao Wang, Weining Wang, Qi Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03997">https://arxiv.org/abs/2511.03997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03997">https://arxiv.org/pdf/2511.03997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03997]] PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection(https://arxiv.org/abs/2511.03997)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in text-to-video generation have achieved impressive perceptual quality, yet generated content often violates fundamental principles of physical plausibility - manifesting as implausible object dynamics, incoherent interactions, and unrealistic motion patterns. Such failures hinder the deployment of video generation models in embodied AI, robotics, and simulation-intensive domains. To bridge this gap, we propose PhysCorr, a unified framework for modeling, evaluating, and optimizing physical consistency in video generation. Specifically, we introduce PhysicsRM, the first dual-dimensional reward model that quantifies both intra-object stability and inter-object interactions. On this foundation, we develop PhyDPO, a novel direct preference optimization pipeline that leverages contrastive feedback and physics-aware reweighting to guide generation toward physically coherent outputs. Our approach is model-agnostic and scalable, enabling seamless integration into a wide range of video diffusion and transformer-based backbones. Extensive experiments across multiple benchmarks demonstrate that PhysCorr achieves significant improvements in physical realism while preserving visual fidelity and semantic alignment. This work takes a critical step toward physically grounded and trustworthy video generation.</li>
</ul>

<h3>Title: Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations</h3>
<ul>
<li><strong>Authors: </strong>Kyaw Hpone Myint, Zhe Wu, Alexandre G.R. Day, Giri Iyengar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04000">https://arxiv.org/abs/2511.04000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04000">https://arxiv.org/pdf/2511.04000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04000]] Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations(https://arxiv.org/abs/2511.04000)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Decision trees are widely used in high-stakes fields like finance and healthcare due to their interpretability. This work introduces an efficient, scalable method for generating synthetic pre-training data to enable meta-learning of decision trees. Our approach samples near-optimal decision trees synthetically, creating large-scale, realistic datasets. Using the MetaTree transformer architecture, we demonstrate that this method achieves performance comparable to pre-training on real-world data or with computationally expensive optimal decision trees. This strategy significantly reduces computational costs, enhances data generation flexibility, and paves the way for scalable and efficient meta-learning of interpretable decision tree models.</li>
</ul>

<h3>Title: Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Sung, Vikas Palakonda, Suhwan Im, Sunghwan Moon, Il-Min Kim, Sangseok Yun, Jae-Mo Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04002">https://arxiv.org/abs/2511.04002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04002">https://arxiv.org/pdf/2511.04002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04002]] Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing(https://arxiv.org/abs/2511.04002)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved near-human performance across diverse reasoning tasks, yet their deployment on resource-constrained Internet-of-Things (IoT) devices remains impractical due to massive parameter footprints and memory-intensive autoregressive decoding. While split computing offers a promising solution by partitioning model execution between edge devices and cloud servers, existing approaches fail to address the unique challenges of autoregressive inference, particularly the iterative token generation process and expanding key-value (KV) cache requirements. This work introduces the first autoregressive-aware split computing framework designed explicitly for LLM deployment on edge devices. Our approach makes three key contributions. First, we develop one-point split compression (OPSC), a mixed-precision quantization scheme that prevents out-of-memory failures by strategically partitioning models into front-end and back-end segments with different precision levels. Second, we propose a two-stage intermediate compression pipeline that combines threshold splitting (TS) and token-wise adaptive bit quantization (TAB-Q) to preserve accuracy-critical activations while dramatically reducing communication overhead. Third, we formulate a unified optimization framework that jointly selects optimal split points, quantization settings, and sequence lengths to satisfy strict memory and latency constraints. Extensive evaluations across diverse LLMs and hardware platforms demonstrate superior performance compared to state-of-the-art quantization methods, including SmoothQuant, OmniQuant, and Atom. The framework achieves a 1.49 inference speedup and significant communication overhead reduction while maintaining or improving model accuracy.</li>
</ul>

<h3>Title: GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>Mahmoud Soliman, Omar Abdelaziz, Ahmed Radwan, Anand, Mohamed Shehata</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04008">https://arxiv.org/abs/2511.04008</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04008">https://arxiv.org/pdf/2511.04008</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04008]] GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization(https://arxiv.org/abs/2511.04008)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Domain generalization (DG) seeks robust Vision Transformer (ViT) performance on unseen domains. Efficiently adapting pretrained ViTs for DG is challenging; standard fine-tuning is costly and can impair generalization. We propose GNN-MoE, enhancing Parameter-Efficient Fine-Tuning (PEFT) for DG with a Mixture-of-Experts (MoE) framework using efficient Kronecker adapters. Instead of token-based routing, a novel Graph Neural Network (GNN) router (GCN, GAT, SAGE) operates on inter-patch graphs to dynamically assign patches to specialized experts. This context-aware GNN routing leverages inter-patch relationships for better adaptation to domain shifts. GNN-MoE achieves state-of-the-art or competitive DG benchmark performance with high parameter efficiency, highlighting the utility of graph-based contextual routing for robust, lightweight DG.</li>
</ul>

<h3>Title: MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging</h3>
<ul>
<li><strong>Authors: </strong>Mahmoud Soliman, Islam Osman, Mohamed S. Shehata, Rasika Rajapakshe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04016">https://arxiv.org/abs/2511.04016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04016">https://arxiv.org/pdf/2511.04016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04016]] MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging(https://arxiv.org/abs/2511.04016)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The performance of vision models in medical imaging is often hindered by the prevailing paradigm of fine-tuning backbones pre-trained on out-of-domain natural images. To address this fundamental domain gap, we propose MedDChest, a new foundational Vision Transformer (ViT) model optimized specifically for thoracic imaging. We pre-trained MedDChest from scratch on a massive, curated, multimodal dataset of over 1.2 million images, encompassing different modalities including Chest X-ray and Computed Tomography (CT) compiled from 10 public sources. A core technical contribution of our work is Guided Random Resized Crops, a novel content-aware data augmentation strategy that biases sampling towards anatomically relevant regions, overcoming the inefficiency of standard cropping techniques on medical scans. We validate our model's effectiveness by fine-tuning it on a diverse set of downstream diagnostic tasks. Comprehensive experiments empirically demonstrate that MedDChest significantly outperforms strong, publicly available ImageNet-pretrained models. By establishing the superiority of large-scale, in-domain pre-training combined with domain-specific data augmentation, MedDChest provides a powerful and robust feature extractor that serves as a significantly better starting point for a wide array of thoracic diagnostic tasks. The model weights will be made publicly available to foster future research and applications.</li>
</ul>

<h3>Title: Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises</h3>
<ul>
<li><strong>Authors: </strong>Shiyin Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04020">https://arxiv.org/abs/2511.04020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04020">https://arxiv.org/pdf/2511.04020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04020]] Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises(https://arxiv.org/abs/2511.04020)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) enhanced with retrieval -- commonly referred to as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved evidence is incomplete, leaving gaps in the reasoning process. In such cases, \emph{abductive inference} -- the process of generating plausible missing premises to explain observations -- offers a principled approach to bridge these gaps. In this paper, we propose a framework that integrates abductive inference into retrieval-augmented LLMs. Our method detects insufficient evidence, generates candidate missing premises, and validates them through consistency and plausibility checks. Experimental results on abductive reasoning and multi-hop QA benchmarks show that our approach improves both answer accuracy and reasoning faithfulness. This work highlights abductive inference as a promising direction for enhancing the robustness and explainability of RAG systems.</li>
</ul>

<h3>Title: WST: Weakly Supervised Transducer for Automatic Speech Recognition</h3>
<ul>
<li><strong>Authors: </strong>Dongji Gao, Chenda Liao, Changliang Liu, Matthew Wiesner, Leibny Paola Garcia, Daniel Povey, Sanjeev Khudanpur, Jian Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04035">https://arxiv.org/abs/2511.04035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04035">https://arxiv.org/pdf/2511.04035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04035]] WST: Weakly Supervised Transducer for Automatic Speech Recognition(https://arxiv.org/abs/2511.04035)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The Recurrent Neural Network-Transducer (RNN-T) is widely adopted in end-to-end (E2E) automatic speech recognition (ASR) tasks but depends heavily on large-scale, high-quality annotated data, which are often costly and difficult to obtain. To mitigate this reliance, we propose a Weakly Supervised Transducer (WST), which integrates a flexible training graph designed to robustly handle errors in the transcripts without requiring additional confidence estimation or auxiliary pre-trained models. Empirical evaluations on synthetic and industrial datasets reveal that WST effectively maintains performance even with transcription error rates of up to 70%, consistently outperforming existing Connectionist Temporal Classification (CTC)-based weakly supervised approaches, such as Bypass Temporal Classification (BTC) and Omni-Temporal Classification (OTC). These results demonstrate the practical utility and robustness of WST in realistic ASR settings. The implementation will be publicly available.</li>
</ul>

<h3>Title: A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals</h3>
<ul>
<li><strong>Authors: </strong>Arfina Rahman, Mahesh Banavar</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04037">https://arxiv.org/abs/2511.04037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04037">https://arxiv.org/pdf/2511.04037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04037]] A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals(https://arxiv.org/abs/2511.04037)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, biometric, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Photoplethysmography (PPG) signals, which measure changes in blood volume in the skin using light, have recently gained attention in biometric authentication because of their non-invasive acquisition, inherent liveness detection, and suitability for low-cost wearable devices. However, PPG signal quality is challenged by motion artifacts, illumination changes, and inter-subject physiological variability, making robust feature extraction and classification crucial. This study proposes a lightweight and cost-effective biometric authentication framework based on PPG signals extracted from low-frame-rate fingertip videos. The CFIHSR dataset, comprising PPG recordings from 46 subjects at a sampling rate of 14 Hz, is employed for evaluation. The raw PPG signals undergo a standard preprocessing pipeline involving baseline drift removal, motion artifact suppression using Principal Component Analysis (PCA), bandpass filtering, Fourier-based resampling, and amplitude normalization. To generate robust representations, each one-dimensional PPG segment is converted into a two-dimensional time-frequency scalogram via the Continuous Wavelet Transform (CWT), effectively capturing transient cardiovascular dynamics. We developed a hybrid deep learning model, termed CVT-ConvMixer-LSTM, by combining spatial features from the Convolutional Vision Transformer (CVT) and ConvMixer branches with temporal features from a Long Short-Term Memory network (LSTM). The experimental results on 46 subjects demonstrate an authentication accuracy of 98%, validating the robustness of the model to noise and variability between subjects. Due to its efficiency, scalability, and inherent liveness detection capability, the proposed system is well-suited for real-world mobile and embedded biometric security applications.</li>
</ul>

<h3>Title: DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization</h3>
<ul>
<li><strong>Authors: </strong>Yuantian Shao, Yuanteng Chen, Peisong Wang, Jianlin Yu, Jing Lin, Yiwu Yao, Zhihui Wei, Jian Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04063">https://arxiv.org/abs/2511.04063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04063">https://arxiv.org/pdf/2511.04063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04063]] DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization(https://arxiv.org/abs/2511.04063)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Quantization plays a crucial role in accelerating the inference of large-scale models, and rotational matrices have been shown to effectively improve quantization performance by smoothing outliers. However, end-to-end fine-tuning of rotational optimization algorithms incurs high computational costs and is prone to overfitting. To address this challenge, we propose an efficient distribution-aware rotational calibration method, DartQuant, which reduces the complexity of rotational optimization by constraining the distribution of the activations after rotation. This approach also effectively reduces reliance on task-specific losses, thereby mitigating the risk of overfitting. Additionally, we introduce the QR-Orth optimization scheme, which replaces expensive alternating optimization with a more efficient solution. In a variety of model quantization experiments, DartQuant demonstrates superior performance. Compared to existing methods, it achieves 47$\times$ acceleration and 10$\times$ memory savings for rotational optimization on a 70B model. Furthermore, it is the first to successfully complete rotational calibration for a 70B model on a single 3090 GPU, making quantization of large language models feasible in resource-constrained environments. Code is available at this https URL.</li>
</ul>

<h3>Title: Left Atrial Segmentation with nnU-Net Using MRI</h3>
<ul>
<li><strong>Authors: </strong>Fatemeh Hosseinabadi, Seyedhassan Sharifi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04071">https://arxiv.org/abs/2511.04071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04071">https://arxiv.org/pdf/2511.04071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04071]] Left Atrial Segmentation with nnU-Net Using MRI(https://arxiv.org/abs/2511.04071)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation of the left atrium (LA) from cardiac MRI is critical for guiding atrial fibrillation (AF) ablation and constructing biophysical cardiac models. Manual delineation is time-consuming, observer-dependent, and impractical for large-scale or time-sensitive clinical workflows. Deep learning methods, particularly convolutional architectures, have recently demonstrated superior performance in medical image segmentation tasks. In this study, we applied the nnU-Net framework, an automated, self-configuring deep learning segmentation architecture, to the Left Atrial Segmentation Challenge 2013 dataset. The dataset consists of thirty MRI scans with corresponding expert-annotated masks. The nnU-Net model automatically adapted its preprocessing, network configuration, and training pipeline to the characteristics of the MRI data. Model performance was quantitatively evaluated using the Dice similarity coefficient (DSC), and qualitative results were compared against expert segmentations. The proposed nnU?Net model achieved a mean Dice score of 93.5, demonstrating high overlap with expert annotations and outperforming several traditional segmentation approaches reported in previous studies. The network exhibited robust generalization across variations in left atrial shape, contrast, and image quality, accurately delineating both the atrial body and proximal pulmonary veins.</li>
</ul>

<h3>Title: Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Xinying Qian, Ying Zhang, Yu Zhao, Baohang Zhou, Xuhui Sui, Xiaojie Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04072">https://arxiv.org/abs/2511.04072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04072">https://arxiv.org/pdf/2511.04072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04072]] Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering(https://arxiv.org/abs/2511.04072)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Temporal Knowledge Graph Question Answering (TKGQA) aims to answer time-sensitive questions by leveraging factual information from Temporal Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG embeddings or graph neural networks to inject temporal knowledge, they fail to fully understand the complex semantic information of time constraints. Recently, Large Language Models (LLMs) have shown remarkable progress, benefiting from their strong semantic understanding and reasoning generalization capabilities. However, their temporal reasoning ability remains limited. LLMs frequently suffer from hallucination and a lack of knowledge. To address these limitations, we propose the Plan of Knowledge framework with a contrastive temporal retriever, which is named PoK. Specifically, the proposed Plan of Knowledge module decomposes a complex temporal question into a sequence of sub-objectives from the pre-defined tools, serving as intermediate guidance for reasoning exploration. In parallel, we construct a Temporal Knowledge Store (TKS) with a contrastive retrieval framework, enabling the model to selectively retrieve semantically and temporally aligned facts from TKGs. By combining structured planning with temporal knowledge retrieval, PoK effectively enhances the interpretability and factual consistency of temporal reasoning. Extensive experiments on four benchmark TKGQA datasets demonstrate that PoK significantly improves the retrieval precision and reasoning accuracy of LLMs, surpassing the performance of the state-of-the-art TKGQA methods by 56.0% at most.</li>
</ul>

<h3>Title: The truth is no diaper: Human and AI-generated associations to emotional words</h3>
<ul>
<li><strong>Authors: </strong>Špela Vintar, Jan Jona Javoršek</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04077">https://arxiv.org/abs/2511.04077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04077">https://arxiv.org/pdf/2511.04077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04077]] The truth is no diaper: Human and AI-generated associations to emotional words(https://arxiv.org/abs/2511.04077)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human word associations are a well-known method of gaining insight into the internal mental lexicon, but the responses spontaneously offered by human participants to word cues are not always predictable as they may be influenced by personal experience, emotions or individual cognitive styles. The ability to form associative links between seemingly unrelated concepts can be the driving mechanisms of creativity. We perform a comparison of the associative behaviour of humans compared to large language models. More specifically, we explore associations to emotionally loaded words and try to determine whether large language models generate associations in a similar way to humans. We find that the overlap between humans and LLMs is moderate, but also that the associations of LLMs tend to amplify the underlying emotional load of the stimulus, and that they tend to be more predictable and less creative than human ones.</li>
</ul>

<h3>Title: Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment</h3>
<ul>
<li><strong>Authors: </strong>Zehui Feng, Chenqi Zhang, Mingru Wang, Minuo Wei, Shiwei Cheng, Cuntai Guan, Ting Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04078">https://arxiv.org/abs/2511.04078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04078">https://arxiv.org/pdf/2511.04078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04078]] Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment(https://arxiv.org/abs/2511.04078)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI remains a fundamental challenge due to subject variability and the entangled nature of visual features. Existing approaches primarily align neural activity directly with visual embeddings, but visual-only representations often fail to capture latent semantic dimensions, limiting interpretability and deep robustness. To address these limitations, we propose Bratrix, the first end-to-end framework to achieve multimodal Language-Anchored Vision-Brain alignment. Bratrix decouples visual stimuli into hierarchical visual and linguistic semantic components, and projects both visual and brain representations into a shared latent space, enabling the formation of aligned visual-language and brain-language embeddings. To emulate human-like perceptual reliability and handle noisy neural signals, Bratrix incorporates a novel uncertainty perception module that applies uncertainty-aware weighting during alignment. By leveraging learnable language-anchored semantic matrices to enhance cross-modal correlations and employing a two-stage training strategy of single-modality pretraining followed by multimodal fine-tuning, Bratrix-M improves alignment precision. Extensive experiments on EEG, MEG, and fMRI benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and captioning performance compared to state-of-the-art methods, specifically surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.</li>
</ul>

<h3>Title: Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods</h3>
<ul>
<li><strong>Authors: </strong>Eva Prakash, Maayane Attias, Pierre Chambon, Justin Xu, Steven Truong, Jean-Benoit Delbrouck, Tessa Cook, Curtis Langlotz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04079">https://arxiv.org/abs/2511.04079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04079">https://arxiv.org/pdf/2511.04079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04079]] Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods(https://arxiv.org/abs/2511.04079)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, robust, transformer</a></li>
<li><strong>Abstract: </strong>Objective: To enhance automated de-identification of radiology reports by scaling transformer-based models through extensive training datasets and benchmarking performance against commercial cloud vendor systems for protected health information (PHI) detection. Materials and Methods: In this retrospective study, we built upon a state-of-the-art, transformer-based, PHI de-identification pipeline by fine-tuning on two large annotated radiology corpora from Stanford University, encompassing chest X-ray, chest CT, abdomen/pelvis CT, and brain MR reports and introducing an additional PHI category (AGE) into the architecture. Model performance was evaluated on test sets from Stanford and the University of Pennsylvania (Penn) for token-level PHI detection. We further assessed (1) the stability of synthetic PHI generation using a "hide-in-plain-sight" method and (2) performance against commercial systems. Precision, recall, and F1 scores were computed across all PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining the previous state-of-the-art model performance. Synthetic PHI evaluation showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50 independently de-identified Penn datasets. Our model outperformed all vendor systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754). Discussion: Large-scale, multimodal training improved cross-institutional generalization and robustness. Synthetic PHI generation preserved data utility while ensuring privacy. Conclusion: A transformer-based de-identification model trained on diverse radiology datasets outperforms prior academic and commercial systems in PHI detection and establishes a new benchmark for secure clinical text processing.</li>
</ul>

<h3>Title: Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score</h3>
<ul>
<li><strong>Authors: </strong>Abu Hanif Muhammad Syarubany</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04083">https://arxiv.org/abs/2511.04083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04083">https://arxiv.org/pdf/2511.04083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04083]] Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score(https://arxiv.org/abs/2511.04083)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study CT image denoising in the unpaired and self-supervised regimes by evaluating two strong, training-data-efficient paradigms: a CycleGAN-based residual translator and a Noise2Score (N2S) score-matching denoiser. Under a common evaluation protocol, a configuration sweep identifies a simple standard U-Net backbone within CycleGAN (lambda_cycle = 30, lambda_iden = 2, ngf = ndf = 64) as the most reliable setting; we then train it to convergence with a longer schedule. The selected CycleGAN improves the noisy input from 34.66 dB / 0.9234 SSIM to 38.913 dB / 0.971 SSIM and attains an estimated score of 1.9441 and an unseen-set (Kaggle leaderboard) score of 1.9343. Noise2Score, while slightly behind in absolute PSNR / SSIM, achieves large gains over very noisy inputs, highlighting its utility when clean pairs are unavailable. Overall, CycleGAN offers the strongest final image quality, whereas Noise2Score provides a robust pair-free alternative with competitive performance. Source code is available at this https URL.</li>
</ul>

<h3>Title: When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Nishchal Sapkota, Haoyan Shi, Yejia Zhang, Xianshi Ma, Bofang Zheng, Danny Z. Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04084">https://arxiv.org/abs/2511.04084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04084">https://arxiv.org/pdf/2511.04084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04084]] When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation(https://arxiv.org/abs/2511.04084)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation is critical for accurate diagnostics and treatment planning, but remains challenging due to complex anatomical structures and limited annotated training data. CNN-based segmentation methods excel at local feature extraction, but struggle with modeling long-range dependencies. Transformers, on the other hand, capture global context more effectively, but are inherently data-hungry and computationally expensive. In this work, we introduce UKAST, a U-Net like architecture that integrates rational-function based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By leveraging rational base functions and Group Rational KANs (GR-KANs) from the Kolmogorov-Arnold Transformer (KAT), our architecture addresses the inefficiencies of vanilla spline-based KANs, yielding a more expressive and data-efficient framework with reduced FLOPs and only a very small increase in parameter count compared to SwinUNETR. UKAST achieves state-of-the-art performance on four diverse 2D and 3D medical image segmentation benchmarks, consistently surpassing both CNN- and Transformer-based baselines. Notably, it attains superior accuracy in data-scarce settings, alleviating the data-hungry limitations of standard Vision Transformers. These results show the potential of KAN-enhanced Transformers to advance data-efficient medical image segmentation. Code is available at: this https URL</li>
</ul>

<h3>Title: DeNoise: Learning Robust Graph Representations for Unsupervised Graph-Level Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Qingfeng Chen, Haojin Zeng, Jingyi Jie, Shichao Zhang, Debo Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04086">https://arxiv.org/abs/2511.04086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04086">https://arxiv.org/pdf/2511.04086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04086]] DeNoise: Learning Robust Graph Representations for Unsupervised Graph-Level Anomaly Detection(https://arxiv.org/abs/2511.04086)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With the rapid growth of graph-structured data in critical domains, unsupervised graph-level anomaly detection (UGAD) has become a pivotal task. UGAD seeks to identify entire graphs that deviate from normal behavioral patterns. However, most Graph Neural Network (GNN) approaches implicitly assume that the training set is clean, containing only normal graphs, which is rarely true in practice. Even modest contamination by anomalous graphs can distort learned representations and sharply degrade performance. To address this challenge, we propose DeNoise, a robust UGAD framework explicitly designed for contaminated training data. It jointly optimizes a graph-level encoder, an attribute decoder, and a structure decoder via an adversarial objective to learn noise-resistant embeddings. Further, DeNoise introduces an encoder anchor-alignment denoising mechanism that fuses high-information node embeddings from normal graphs into all graph embeddings, improving representation quality while suppressing anomaly interference. A contrastive learning component then compacts normal graph embeddings and repels anomalous ones in the latent space. Extensive experiments on eight real-world datasets demonstrate that DeNoise consistently learns reliable graph-level representations under varying noise intensities and significantly outperforms state-of-the-art UGAD baselines.</li>
</ul>

<h3>Title: KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea</h3>
<ul>
<li><strong>Authors: </strong>Hyungjong Na, Wonho Song, Seungyong Han, Donghyeon Jo, Sejin Myung, Hyungjoon Kim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04094">https://arxiv.org/abs/2511.04094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04094">https://arxiv.org/pdf/2511.04094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04094]] KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea(https://arxiv.org/abs/2511.04094)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011 and 2024. After excluding financial firms, firms with non-December fiscal year ends, capital impairment, and negative pre-tax income, the final dataset consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed to treat corporate tax avoidance as a predictor variable and link it to multiple domains, including earnings management (accrual- and activity-based), profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE, INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance itself is measured using complementary indicators cash effective tax rate (CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA, TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is its balanced panel structure with standardized variables and its consistency with international literature on the distribution and correlation of core indicators. At the same time, it reflects distinctive institutional features of Korean firms, such as concentrated ownership, high foreign shareholding, and elevated liquidity ratios, providing both international comparability and contextual uniqueness. KoTaP enables applications in benchmarking econometric and deep learning models, external validity checks, and explainable AI analyses. It further supports policy evaluation, audit planning, and investment analysis, making it a critical open resource for accounting, finance, and interdisciplinary research.</li>
</ul>

<h3>Title: Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Wenmo Qiu, Saurabh Srivastava</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04108">https://arxiv.org/abs/2511.04108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04108">https://arxiv.org/pdf/2511.04108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04108]] Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models(https://arxiv.org/abs/2511.04108)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent work has explored batch prompting as a strategy to amortize inference cost in large language models (LLMs). In this paper, we show that batching offers an additional, underappreciated benefit: it regularizes model behavior during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a comprehensive study across 13 diverse benchmarks and observe that batching improves accuracy while substantially reducing reasoning token usage, often by 3x-5x. Through detailed behavioral analysis, we find that batching suppresses overthinking, reduces hedging language (e.g., repetitive self-corrections), and encourages more decisive answers. Surprisingly, we also observe emergent collective effects in batched inference: models often generalize patterns from earlier examples to solve harder ones in the same batch. These findings position batching not just as a throughput optimization, but as a powerful inference-time regularizer for more efficient and reliable LLM reasoning.</li>
</ul>

<h3>Title: Automated and Explainable Denial of Service Analysis for AI-Driven Intrusion Detection Systems</h3>
<ul>
<li><strong>Authors: </strong>Paul Badu Yakubu, Lesther Santana, Mohamed Rahouti, Yufeng Xin, Abdellah Chehri, Mohammed Aledhari</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04114">https://arxiv.org/abs/2511.04114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04114">https://arxiv.org/pdf/2511.04114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04114]] Automated and Explainable Denial of Service Analysis for AI-Driven Intrusion Detection Systems(https://arxiv.org/abs/2511.04114)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, interpretability</a></li>
<li><strong>Abstract: </strong>With the increasing frequency and sophistication of Distributed Denial of Service (DDoS) attacks, it has become critical to develop more efficient and interpretable detection methods. Traditional detection systems often struggle with scalability and transparency, hindering real-time response and understanding of attack vectors. This paper presents an automated framework for detecting and interpreting DDoS attacks using machine learning (ML). The proposed method leverages the Tree-based Pipeline Optimization Tool (TPOT) to automate the selection and optimization of ML models and features, reducing the need for manual experimentation. SHapley Additive exPlanations (SHAP) is incorporated to enhance model interpretability, providing detailed insights into the contribution of individual features to the detection process. By combining TPOT's automated pipeline selection with SHAP interpretability, this approach improves the accuracy and transparency of DDoS detection. Experimental results demonstrate that key features such as mean backward packet length and minimum forward packet header length are critical in detecting DDoS attacks, offering a scalable and explainable cybersecurity solution.</li>
</ul>

<h3>Title: Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration</h3>
<ul>
<li><strong>Authors: </strong>Yunghee Lee, Byeonghyun Pak, Junwha Hong, Hoseong Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04117">https://arxiv.org/abs/2511.04117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04117">https://arxiv.org/pdf/2511.04117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04117]] Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration(https://arxiv.org/abs/2511.04117)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>In this paper, we propose Tortoise and Hare Guidance (THG), a training-free strategy that accelerates diffusion sampling while maintaining high-fidelity generation. We demonstrate that the noise estimate and the additional guidance term exhibit markedly different sensitivity to numerical error by reformulating the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our error-bound analysis shows that the additional guidance branch is more robust to approximation, revealing substantial redundancy that conventional solvers fail to exploit. Building on this insight, THG significantly reduces the computation of the additional guidance: the noise estimate is integrated with the tortoise equation on the original, fine-grained timestep grid, while the additional guidance is integrated with the hare equation only on a coarse grid. We also introduce (i) an error-bound-aware timestep sampler that adaptively selects step sizes and (ii) a guidance-scale scheduler that stabilizes large extrapolation spans. THG reduces the number of function evaluations (NFE) by up to 30% with virtually no loss in generation fidelity ($\Delta$ImageReward $\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free accelerators under identical computation budgets. Our findings highlight the potential of multirate formulations for diffusion solvers, paving the way for real-time high-quality image synthesis without any model retraining. The source code is available at this https URL.</li>
</ul>

<h3>Title: RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Xinyuan Li, Murong Xu, Wenbiao Tao, Hanlun Zhu, Yike Zhao, Jipeng Zhang, Yunshi Lan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04120">https://arxiv.org/abs/2511.04120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04120">https://arxiv.org/pdf/2511.04120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04120]] RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning(https://arxiv.org/abs/2511.04120)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) achieve high performance on mathematical reasoning, but these results can be inflated by training data leakage or superficial pattern matching rather than genuine reasoning. To this end, an adversarial perturbation-based evaluation is needed to measure true mathematical reasoning ability. Current rule-based perturbation methods often generate ill-posed questions and impede the systematic evaluation of question difficulty and the evolution of benchmarks. To bridge this gap, we propose RIDE, a novel adversarial question-rewriting framework that leverages Item Response Theory (IRT) to rigorously measure question difficulty and to generate intrinsically more challenging, well-posed variations of mathematical problems. We employ 35 LLMs to simulate students and build a difficulty ranker from their responses. This ranker provides a reward signal during reinforcement learning and guides a question-rewriting model to reformulate existing questions across difficulty levels. Applying RIDE to competition-level mathematical benchmarks yields perturbed versions that degrade advanced LLM performance, with experiments showing an average 21.73% drop across 26 models, thereby exposing limited robustness in mathematical reasoning and confirming the validity of our evaluation approach.</li>
</ul>

<h3>Title: Text to Sketch Generation with Multi-Styles</h3>
<ul>
<li><strong>Authors: </strong>Tengjie Li, Shikui Tu, Lei Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04123">https://arxiv.org/abs/2511.04123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04123">https://arxiv.org/pdf/2511.04123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04123]] Text to Sketch Generation with Multi-Styles(https://arxiv.org/abs/2511.04123)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in vision-language models have facilitated progress in sketch generation. However, existing specialized methods primarily focus on generic synthesis and lack mechanisms for precise control over sketch styles. In this work, we propose a training-free framework based on diffusion models that enables explicit style guidance via textual prompts and referenced style sketches. Unlike previous style transfer methods that overwrite key and value matrices in self-attention, we incorporate the reference features as auxiliary information with linear smoothing and leverage a style-content guidance mechanism. This design effectively reduces content leakage from reference sketches and enhances synthesis quality, especially in cases with low structural similarity between reference and target sketches. Furthermore, we extend our framework to support controllable multi-style generation by integrating features from multiple reference sketches, coordinated via a joint AdaIN module. Extensive experiments demonstrate that our approach achieves high-quality sketch generation with accurate style alignment and improved flexibility in style control. The official implementation of M3S is available at this https URL.</li>
</ul>

<h3>Title: Decomposable Neuro Symbolic Regression</h3>
<ul>
<li><strong>Authors: </strong>Giorgio Morales, John W. Sheppard</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04124">https://arxiv.org/abs/2511.04124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04124">https://arxiv.org/pdf/2511.04124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04124]] Decomposable Neuro Symbolic Regression(https://arxiv.org/abs/2511.04124)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Symbolic regression (SR) models complex systems by discovering mathematical expressions that capture underlying relationships in observed data. However, most SR methods prioritize minimizing prediction error over identifying the governing equations, often producing overly complex or inaccurate expressions. To address this, we present a decomposable SR method that generates interpretable multivariate expressions leveraging transformer models, genetic algorithms (GAs), and genetic programming (GP). In particular, our explainable SR method distills a trained ``opaque'' regression model into mathematical expressions that serve as explanations of its computed function. Our method employs a Multi-Set Transformer to generate multiple univariate symbolic skeletons that characterize how each variable influences the opaque model's response. We then evaluate the generated skeletons' performance using a GA-based approach to select a subset of high-quality candidates before incrementally merging them via a GP-based cascade procedure that preserves their original skeleton structure. The final multivariate skeletons undergo coefficient optimization via a GA. We evaluated our method on problems with controlled and varying degrees of noise, demonstrating lower or comparable interpolation and extrapolation errors compared to two GP-based methods, three neural SR methods, and a hybrid approach. Unlike them, our approach consistently learned expressions that matched the original mathematical structure.</li>
</ul>

<h3>Title: Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)</h3>
<ul>
<li><strong>Authors: </strong>Venkata Manikanta Desu, Syed Fawaz Ali</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04126">https://arxiv.org/abs/2511.04126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04126">https://arxiv.org/pdf/2511.04126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04126]] Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)(https://arxiv.org/abs/2511.04126)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study presents a complete pipeline for automated tennis match analysis. Our framework integrates multiple deep learning models to detect and track players and the tennis ball in real time, while also identifying court keypoints for spatial reference. Using YOLOv8 for player detection, a custom-trained YOLOv5 model for ball tracking, and a ResNet50-based architecture for court keypoint detection, our system provides detailed analytics including player movement patterns, ball speed, shot accuracy, and player reaction times. The experimental results demonstrate robust performance in varying court conditions and match scenarios. The model outputs an annotated video along with detailed performance metrics, enabling coaches, broadcasters, and players to gain actionable insights into the dynamics of the game.</li>
</ul>

<h3>Title: DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms</h3>
<ul>
<li><strong>Authors: </strong>Shengyu Tang, Zeyuan Lu, Jiazhi Dong, Changdong Yu, Xiaoyu Wang, Yaohui Lyu, Weihao Xia</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04128">https://arxiv.org/abs/2511.04128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04128">https://arxiv.org/pdf/2511.04128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04128]] DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms(https://arxiv.org/abs/2511.04128)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Accurate perception of the marine environment through robust multi-object tracking (MOT) is essential for ensuring safe vessel navigation and effective maritime surveillance. However, the complicated maritime environment often causes camera motion and subsequent visual degradation, posing significant challenges to MOT. To address this challenge, we propose an efficient Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the framework is a parallel tracker with affine compensation, which incorporates an object detection and re-identification (ReID) branch, along with a dedicated branch for dynamic camera motion estimation. Specifically, a Reversible Columnar Detection Network (RCDN) is integrated into the detection module to leverage multi-level visual features for robust object detection. Furthermore, a lightweight Transformer-based appearance extractor (Li-TAE) is designed to capture global contextual information and generate robust appearance features. Another branch decouples platform-induced and target-intrinsic motion by constructing a projective transformation, applying platform-motion compensation within the Kalman filter, and thereby stabilizing true object trajectories. Finally, a clustering-optimized feature fusion module effectively combines motion and appearance cues to ensure identity consistency under noise, occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT attains the fastest runtime among existing ReID-based MOT frameworks while maintaining high identity consistency and robustness to jitter and occlusion. Code is available at: this https URL.</li>
</ul>

<h3>Title: Exploring the Feasibility of End-to-End Large Language Model as a Compiler</h3>
<ul>
<li><strong>Authors: </strong>Hongbin Zhang, Shihao Gao, Yang Liu, Mingjie Xing, Yanjun Wu, Chen Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04132">https://arxiv.org/abs/2511.04132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04132">https://arxiv.org/pdf/2511.04132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04132]] Exploring the Feasibility of End-to-End Large Language Model as a Compiler(https://arxiv.org/abs/2511.04132)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, end-to-end Large Language Model (LLM) technology has shown substantial advantages across various domains. As critical system software and infrastructure, compilers are responsible for transforming source code into target code. While LLMs have been leveraged to assist in compiler development and maintenance, their potential as an end-to-end compiler remains largely unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and its future directions. We designed the CompilerEval dataset and framework specifically to evaluate the capabilities of mainstream LLMs in source code comprehension and assembly code generation. In the evaluation, we analyzed various errors, explored multiple methods to improve LLM-generated code, and evaluated cross-platform compilation capabilities. Experimental results demonstrate that LLMs exhibit basic capabilities as compilers but currently achieve low compilation success rates. By optimizing prompts, scaling up the model, and incorporating reasoning methods, the quality of assembly code generated by LLMs can be significantly enhanced. Based on these findings, we maintain an optimistic outlook for LaaC and propose practical architectural designs and future research directions. We believe that with targeted training, knowledge-rich prompts, and specialized infrastructure, LaaC has the potential to generate high-quality assembly code and drive a paradigm shift in the field of compilation.</li>
</ul>

<h3>Title: Learning from Online Videos at Inference Time for Computer-Use Agents</h3>
<ul>
<li><strong>Authors: </strong>Yujian Liu, Ze Wang, Hao Chen, Ximeng Sun, Xiaodong Yu, Jialian Wu, Jiang Liu, Emad Barsoum, Zicheng Liu, Shiyu Chang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04137">https://arxiv.org/abs/2511.04137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04137">https://arxiv.org/pdf/2511.04137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04137]] Learning from Online Videos at Inference Time for Computer-Use Agents(https://arxiv.org/abs/2511.04137)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Computer-use agents can operate computers and automate laborious tasks, but despite recent rapid progress, they still lag behind human users, especially when tasks require domain-specific procedural knowledge about particular applications, platforms, and multi-step workflows. Humans can bridge this gap by watching video tutorials: we search, skim, and selectively imitate short segments that match our current subgoal. In this paper, we study how to enable computer-use agents to learn from online videos at inference time effectively. We propose a framework that retrieves and filters tutorial videos, converts them into structured demonstration trajectories, and dynamically selects trajectories as in-context guidance during execution. Particularly, using a VLM, we infer UI actions, segment videos into short subsequences of actions, and assign each subsequence a textual objective. At inference time, a two-stage selection mechanism dynamically chooses a single trajectory to add in context at each step, focusing the agent on the most helpful local guidance for its next decision. Experiments on two widely used benchmarks show that our framework consistently outperforms strong base agents and variants that use only textual tutorials or transcripts. Analyses highlight the importance of trajectory segmentation and selection, action filtering, and visual information, suggesting that abundant online videos can be systematically distilled into actionable guidance that improves computer-use agents at inference time. Our code is available at this https URL.</li>
</ul>

<h3>Title: CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese</h3>
<ul>
<li><strong>Authors: </strong>Dazhong Chen, Yi-Cheng Lin, Yuchen Huang, Ziwei Gong, Di Jiang, Zeying Xie, Yi R. (May)Fung</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04139">https://arxiv.org/abs/2511.04139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04139">https://arxiv.org/pdf/2511.04139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04139]] CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese(https://arxiv.org/abs/2511.04139)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Automatic speech recognition (ASR) is critical for language accessibility, yet low-resource Cantonese remains challenging due to limited annotated data, six lexical tones, tone sandhi, and accent variation. Existing ASR models, such as Whisper, often suffer from high word error rates. Large audio-language models (LALMs), in contrast, can leverage broader contextual reasoning but still require explicit tonal and prosodic acoustic cues. We introduce CantoASR, a collaborative ASR-LALM error correction framework that integrates forced alignment for acoustic feature extraction, a LoRA-finetuned Whisper for improved tone discrimination, and an instruction-tuned Qwen-Audio for prosody-aware correction. Evaluations on spontaneous Cantonese data show substantial CER gains over Whisper-Large-V3. These findings suggest that integrating acoustic cues with LALM reasoning provides a scalable strategy for low-resource tonal and dialectal ASR.</li>
</ul>

<h3>Title: BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation</h3>
<ul>
<li><strong>Authors: </strong>Fahim Ahmed, Md Mubtasim Ahasan, Jahir Sadik Monon, Muntasir Wahed, M Ashraful Amin, A K M Mahbubur Rahman, Amin Ahsan Ali</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04153">https://arxiv.org/abs/2511.04153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04153">https://arxiv.org/pdf/2511.04153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04153]] BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation(https://arxiv.org/abs/2511.04153)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Text-to-SQL systems provide a natural language interface that can enable even laymen to access information stored in databases. However, existing Large Language Models (LLM) struggle with SQL generation from natural instructions due to large schema sizes and complex reasoning. Prior work often focuses on complex, somewhat impractical pipelines using flagship models, while smaller, efficient models remain overlooked. In this work, we explore three multi-agent LLM pipelines, with systematic performance benchmarking across a range of small to large open-source models: (1) Multi-agent discussion pipeline, where agents iteratively critique and refine SQL queries, and a judge synthesizes the final answer; (2) Planner-Coder pipeline, where a thinking model planner generates stepwise SQL generation plans and a coder synthesizes queries; and (3) Coder-Aggregator pipeline, where multiple coders independently generate SQL queries, and a reasoning agent selects the best query. Experiments on the Bird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small model performance, with up to 10.6% increase in Execution Accuracy for Qwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines, the LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B and QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest score of 56.4%. Codes are available at this https URL.</li>
</ul>

<h3>Title: Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Olav Finne Praesteng Larsen, Massimiliano Ruocco, Michail Spitieris, Abdulmajid Murad, Martina Ragosta</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04155">https://arxiv.org/abs/2511.04155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04155">https://arxiv.org/pdf/2511.04155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04155]] Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories(https://arxiv.org/abs/2511.04155)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Access to trajectory data is a key requirement for developing and validating Air Traffic Management (ATM) solutions, yet many secondary and regional airports face severe data scarcity. This limits the applicability of machine learning methods and the ability to perform large-scale simulations or "what-if" analyses. In this paper, we investigate whether generative models trained on data-rich airports can be efficiently adapted to data-scarce airports using transfer learning. We adapt state-of-the-art diffusion- and flow-matching-based architectures to the aviation domain and evaluate their transferability between Zurich (source) and Dublin (target) landing trajectory datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying amounts of local data, ranging from 0% to 100%. Results show that diffusion-based models achieve competitive performance with as little as 5% of the Dublin data and reach baseline-level performance around 20%, consistently outperforming models trained from scratch across metrics and visual inspections. Latent flow matching and latent diffusion models also benefit from pretraining, though with more variable gains, while flow matching models show weaker generalization. Despite challenges in capturing rare trajectory patterns, these findings demonstrate the potential of transfer learning to substantially reduce data requirements for trajectory generation in ATM, enabling realistic synthetic data generation even in environments with limited historical records.</li>
</ul>

<h3>Title: Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data</h3>
<ul>
<li><strong>Authors: </strong>Anzhuo Xie, Wei-Chen Chang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04158">https://arxiv.org/abs/2511.04158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04158">https://arxiv.org/pdf/2511.04158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04158]] Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data(https://arxiv.org/abs/2511.04158)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study proposes a Transformer-based longitudinal modeling method to address challenges in clinical risk classification with heterogeneous Electronic Health Record (EHR) data, including irregular temporal patterns, large modality differences, and complex semantic structures. The method takes multi-source medical features as input and employs a feature embedding layer to achieve a unified representation of structured and unstructured data. A learnable temporal encoding mechanism is introduced to capture dynamic evolution under uneven sampling intervals. The core model adopts a multi-head self-attention structure to perform global dependency modeling on longitudinal sequences, enabling the aggregation of long-term trends and short-term fluctuations across different temporal scales. To enhance semantic representation, a semantic-weighted pooling module is designed to assign adaptive importance to key medical events, improving the discriminative ability of risk-related features. Finally, a linear mapping layer generates individual-level risk scores. Experimental results show that the proposed model outperforms traditional machine learning and temporal deep learning models in accuracy, recall, precision, and F1-Score, achieving stable and precise risk identification in multi-source heterogeneous EHR environments and providing an efficient and reliable framework for clinical intelligent decision-making.</li>
</ul>

<h3>Title: Seeing Straight: Document Orientation Detection for Efficient OCR</h3>
<ul>
<li><strong>Authors: </strong>Suranjan Goswami, Abhinav Ravi, Raja Kolla, Ali Faraz, Shaharukh Khan, Akash, Chandra Khatri, Shubham Agarwal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04161">https://arxiv.org/abs/2511.04161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04161">https://arxiv.org/pdf/2511.04161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04161]] Seeing Straight: Document Orientation Detection for Efficient OCR(https://arxiv.org/abs/2511.04161)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite significant advances in document understanding, determining the correct orientation of scanned or photographed documents remains a critical pre-processing step in the real world settings. Accurate rotation correction is essential for enhancing the performance of downstream tasks such as Optical Character Recognition (OCR) where misalignment commonly arises due to user errors, particularly incorrect base orientations of the camera during capture. In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from rotation-transformed structured and free-form English OCR datasets, and (ii) ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource languages. We also present a fast, robust and lightweight rotation classification pipeline built on the vision encoder of Phi-3.5-Vision model with dynamic image cropping, fine-tuned specifically for 4-class rotation task in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy on identifying the rotations respectively on both the datasets. Beyond classification, we demonstrate the critical role of our module in boosting OCR performance: closed-source (up to 14%) and open-weights models (up to 4x) in the simulated real-world setting.</li>
</ul>

<h3>Title: Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Musthafa Rafi, Adarsh Krishnamurthy, Aditya Balu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04184">https://arxiv.org/abs/2511.04184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04184">https://arxiv.org/pdf/2511.04184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04184]] Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains(https://arxiv.org/abs/2511.04184)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The proliferation of AI-generated content has created an absurd communication theater where senders use LLMs to inflate simple ideas into verbose content, recipients use LLMs to compress them back into summaries, and as a consequence neither party engage with authentic content. LAAC (LLM as a Communicator) proposes a paradigm shift - positioning LLMs as intelligent communication intermediaries that capture the sender's intent through structured dialogue and facilitate genuine knowledge exchange with recipients. Rather than perpetuating cycles of AI-generated inflation and compression, LAAC enables authentic communication across diverse contexts including academic papers, proposals, professional emails, and cross-platform content generation. However, deploying LLMs as trusted communication intermediaries raises critical questions about information fidelity, consistency, and reliability. This position paper systematically evaluates the trustworthiness requirements for LAAC's deployment across multiple communication domains. We investigate three fundamental dimensions: (1) Information Capture Fidelity - accuracy of intent extraction during sender interviews across different communication types, (2) Reproducibility - consistency of structured knowledge across multiple interaction instances, and (3) Query Response Integrity - reliability of recipient-facing responses without hallucination, source conflation, or fabrication. Through controlled experiments spanning multiple LAAC use cases, we assess these trust dimensions using LAAC's multi-agent architecture. Preliminary findings reveal measurable trust gaps that must be addressed before LAAC can be reliably deployed in high-stakes communication scenarios.</li>
</ul>

<h3>Title: Computational Turing Test Reveals Systematic Differences Between Human and AI Language</h3>
<ul>
<li><strong>Authors: </strong>Nicolò Pagan, Petter Törnberg, Christopher A. Bail, Anikó Hannák, Christopher Barrie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MA, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04195">https://arxiv.org/abs/2511.04195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04195">https://arxiv.org/pdf/2511.04195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04195]] Computational Turing Test Reveals Systematic Differences Between Human and AI Language(https://arxiv.org/abs/2511.04195)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used in the social sciences to simulate human behavior, based on the assumption that they can generate realistic, human-like text. Yet this assumption remains largely untested. Existing validation efforts rely heavily on human-judgment-based evaluations -- testing whether humans can distinguish AI from human output -- despite evidence that such judgments are blunt and unreliable. As a result, the field lacks robust tools for assessing the realism of LLM-generated text or for calibrating models to real-world data. This paper makes two contributions. First, we introduce a computational Turing test: a validation framework that integrates aggregate metrics (BERT-based detectability and semantic similarity) with interpretable linguistic features (stylistic markers and topical patterns) to assess how closely LLMs approximate human language within a given dataset. Second, we systematically compare nine open-weight LLMs across five calibration strategies -- including fine-tuning, stylistic prompting, and context retrieval -- benchmarking their ability to reproduce user interactions on X (formerly Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the literature. Even after calibration, LLM outputs remain clearly distinguishable from human text, particularly in affective tone and emotional expression. Instruction-tuned models underperform their base counterparts, and scaling up model size does not enhance human-likeness. Crucially, we identify a trade-off: optimizing for human-likeness often comes at the cost of semantic fidelity, and vice versa. These results provide a much-needed scalable framework for validation and calibration in LLM simulations -- and offer a cautionary note about their current limitations in capturing human communication.</li>
</ul>

<h3>Title: LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal</h3>
<ul>
<li><strong>Authors: </strong>Michał Karp, Anna Kubaszewska, Magdalena Król, Robert Król, Aleksander Smywiński-Pohl, Mateusz Szymański, Witold Wydmański</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04205">https://arxiv.org/abs/2511.04205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04205">https://arxiv.org/pdf/2511.04205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04205]] LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal(https://arxiv.org/abs/2511.04205)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This study provides an empirical assessment of whether current large language models (LLMs) can pass the official qualifying examination for membership in Poland's National Appeal Chamber (Krajowa Izba Odwoławcza). The authors examine two related ideas: using LLM as actual exam candidates and applying the 'LLM-as-a-judge' approach, in which model-generated answers are automatically evaluated by other models. The paper describes the structure of the exam, which includes a multiple-choice knowledge test on public procurement law and a written judgment, and presents the hybrid information recovery and extraction pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4 Sonnet and Bielik-11B-v2.6) were tested in closed-book and various Retrieval-Augmented Generation settings. The results show that although the models achieved satisfactory scores in the knowledge test, none met the passing threshold in the practical written part, and the evaluations of the 'LLM-as-a-judge' often diverged from the judgments of the official examining committee. The authors highlight key limitations: susceptibility to hallucinations, incorrect citation of legal provisions, weaknesses in logical argumentation, and the need for close collaboration between legal experts and technical teams. The findings indicate that, despite rapid technological progress, current LLMs cannot yet replace human judges or independent examiners in Polish public procurement adjudication.</li>
</ul>

<h3>Title: Block Rotation is All You Need for MXFP4 Quantization</h3>
<ul>
<li><strong>Authors: </strong>Yuantian Shao, Peisong Wang, Yuanteng Chen, Chang Xu, Zhihui Wei, Jian Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04214">https://arxiv.org/abs/2511.04214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04214">https://arxiv.org/pdf/2511.04214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04214]] Block Rotation is All You Need for MXFP4 Quantization(https://arxiv.org/abs/2511.04214)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable success, but their rapidly growing scale imposes prohibitive costs in memory, computation, and energy. Post-training quantization (PTQ) is a promising solution for efficient deployment, yet achieving accurate W4A4 quantization remains an open challenge. While most existing methods are designed for INT4 formats, the emergence of MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)-- raises questions about the applicability of current techniques. In this work, we establish a comprehensive benchmark of PTQ methods under the MXFP4 format. Through systematic evaluation, we find that methods like GPTQ consistently deliver strong performance, whereas rotation-based approaches, which are almost used by all state-of-the-art approaches, suffer from severe incompatibility with MXFP4. We further provide the first in-depth analysis of this conflict, tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two) block scaling and the redistribution of outlier energy via global rotation. Building on this insight, we propose a simple yet effective block rotation strategy that adapts rotation-based methods to MXFP4, leading to substantial accuracy improvements across diverse LLMs. Our findings not only offer clear guidance for practitioners but also set a foundation for advancing PTQ research under emerging low-precision formats.</li>
</ul>

<h3>Title: Black-Box Guardrail Reverse-engineering Attack</h3>
<ul>
<li><strong>Authors: </strong>Hongwei Yao, Yun Xia, Shuo Shao, Haoran Shi, Tong Qiao, Cong Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04215">https://arxiv.org/abs/2511.04215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04215">https://arxiv.org/pdf/2511.04215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04215]] Black-Box Guardrail Reverse-engineering Attack(https://arxiv.org/abs/2511.04215)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) increasingly employ guardrails to enforce ethical, legal, and application-specific constraints on their outputs. While effective at mitigating harmful responses, these guardrails introduce a new class of vulnerabilities by exposing observable decision patterns. In this work, we present the first study of black-box LLM guardrail reverse-engineering attacks. We propose Guardrail Reverse-engineering Attack (GRA), a reinforcement learning-based framework that leverages genetic algorithm-driven data augmentation to approximate the decision-making policy of victim guardrails. By iteratively collecting input-output pairs, prioritizing divergence cases, and applying targeted mutations and crossovers, our method incrementally converges toward a high-fidelity surrogate of the victim guardrail. We evaluate GRA on three widely deployed commercial systems, namely ChatGPT, DeepSeek, and Qwen3, and demonstrate that it achieves an rule matching rate exceeding 0.92 while requiring less than $85 in API costs. These findings underscore the practical feasibility of guardrail extraction and highlight significant security risks for current LLM safety mechanisms. Our findings expose critical vulnerabilities in current guardrail designs and highlight the urgent need for more robust defense mechanisms in LLM deployment.</li>
</ul>

<h3>Title: The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms</h3>
<ul>
<li><strong>Authors: </strong>Hikari Otsuka, Daiki Chijiwa, Yasuyuki Okoshi, Daichi Fujiki, Susumu Takeuchi, Masato Motomura</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04217">https://arxiv.org/abs/2511.04217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04217">https://arxiv.org/pdf/2511.04217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04217]] The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms(https://arxiv.org/abs/2511.04217)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The strong lottery ticket hypothesis (SLTH) conjectures that high-performing subnetworks, called strong lottery tickets (SLTs), are hidden in randomly initialized neural networks. Although recent theoretical studies have established the SLTH across various neural architectures, the SLTH for transformer architectures still lacks theoretical understanding. In particular, the current theory of the SLTH does not yet account for the multi-head attention (MHA) mechanism, a core component of transformers. To address this gap, we introduce a theoretical analysis of the existence of SLTs within MHAs. We prove that, if a randomly initialized MHA of $H$ heads and input dimension $d$ has the hidden dimension $O(d\log(Hd^{3/2}))$ for the key and value, it contains an SLT that approximates an arbitrary MHA with the same input dimension with high probability. Furthermore, by leveraging this theory for MHAs, we extend the SLTH to transformers without normalization layers. We empirically validate our theoretical findings, demonstrating that the approximation error between the SLT within a source model (MHA and transformer) and an approximate target counterpart decreases exponentially by increasing the hidden dimension of the source model.</li>
</ul>

<h3>Title: REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs</h3>
<ul>
<li><strong>Authors: </strong>Liran Cohen, Yaniv Nemcovesky, Avi Mendelson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04228">https://arxiv.org/abs/2511.04228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04228">https://arxiv.org/pdf/2511.04228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04228]] REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs(https://arxiv.org/abs/2511.04228)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Machine unlearning aims to remove the influence of specific training data from a model without requiring full retraining. This capability is crucial for ensuring privacy, safety, and regulatory compliance. Therefore, verifying whether a model has truly forgotten target data is essential for maintaining reliability and trustworthiness. However, existing evaluation methods often assess forgetting at the level of individual inputs. This approach may overlook residual influence present in semantically similar examples. Such influence can compromise privacy and lead to indirect information leakage. We propose REMIND (Residual Memorization In Neighborhood Dynamics), a novel evaluation method aiming to detect the subtle remaining influence of unlearned data and classify whether the data has been effectively forgotten. REMIND analyzes the model's loss over small input variations and reveals patterns unnoticed by single-point evaluations. We show that unlearned data yield flatter, less steep loss landscapes, while retained or unrelated data exhibit sharper, more volatile patterns. REMIND requires only query-based access, outperforms existing methods under similar constraints, and demonstrates robustness across different models, datasets, and paraphrased inputs, making it practical for real-world deployment. By providing a more sensitive and interpretable measure of unlearning effectiveness, REMIND provides a reliable framework to assess unlearning in language models. As a result, REMIND offers a novel perspective on memorization and unlearning.</li>
</ul>

<h3>Title: Reusing Pre-Training Data at Test Time is a Compute Multiplier</h3>
<ul>
<li><strong>Authors: </strong>Alex Fang, Thomas Voice, Ruoming Pang, Ludwig Schmidt, Tom Gunter</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04234">https://arxiv.org/abs/2511.04234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04234">https://arxiv.org/pdf/2511.04234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04234]] Reusing Pre-Training Data at Test Time is a Compute Multiplier(https://arxiv.org/abs/2511.04234)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models learn from their vast pre-training corpora, gaining the ability to solve an ever increasing variety of tasks; yet although researchers work to improve these datasets, there is little effort to understand how efficient the pre-training apparatus is at extracting ideas and knowledge from the data. In this work, we use retrieval augmented generation along with test-time compute as a way to quantify how much dataset value was left behind by the process of pre-training, and how this changes across scale. We demonstrate that pre-training then retrieving from standard and largely open-sourced datasets results in significant accuracy gains in MMLU, Math-500, and SimpleQA, which persist through decontamination. For MMLU we observe that retrieval acts as a ~5x compute multiplier versus pre-training alone. We show that these results can be further improved by leveraging additional compute at test time to parse the retrieved context, demonstrating a 10 percentage point improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results suggest that today's pre-training methods do not make full use of the information in existing pre-training datasets, leaving significant room for progress.</li>
</ul>

<h3>Title: Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics</h3>
<ul>
<li><strong>Authors: </strong>Irene Ferfoglia, Simone Silvetti, Gaia Saveri, Laura Nenzi, Luca Bortolussi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04244">https://arxiv.org/abs/2511.04244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04244">https://arxiv.org/pdf/2511.04244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04244]] Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics(https://arxiv.org/abs/2511.04244)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Time series classification is a task of paramount importance, as this kind of data often arises in safety-critical applications. However, it is typically tackled with black-box deep learning methods, making it hard for humans to understand the rationale behind their output. To take on this challenge, we propose a novel approach, STELLE (Signal Temporal logic Embedding for Logically-grounded Learning and Explanation), a neuro-symbolic framework that unifies classification and explanation through direct embedding of trajectories into a space of temporal logic concepts. By introducing a novel STL-inspired kernel that maps raw time series to their alignment with predefined STL formulae, our model jointly optimises accuracy and interpretability, as each prediction is accompanied by the most relevant logical concepts that characterise it. This yields (i) local explanations as human-readable STL conditions justifying individual predictions, and (ii) global explanations as class-characterising formulae. Experiments demonstrate that STELLE achieves competitive accuracy while providing logically faithful explanations, validated on diverse real-world benchmarks.</li>
</ul>

<h3>Title: Efficient Topic Extraction via Graph-Based Labeling: A Lightweight Alternative to Deep Models</h3>
<ul>
<li><strong>Authors: </strong>Salma Mekaooui, Hiba Sofyan, Imane Amaaz, Imane Benchrif, Arsalane Zarghili, Ilham Chaker, Nikola S. Nikolov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04248">https://arxiv.org/abs/2511.04248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04248">https://arxiv.org/pdf/2511.04248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04248]] Efficient Topic Extraction via Graph-Based Labeling: A Lightweight Alternative to Deep Models(https://arxiv.org/abs/2511.04248)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Extracting topics from text has become an essential task, especially with the rapid growth of unstructured textual data. Most existing works rely on highly computational methods to address this challenge. In this paper, we argue that probabilistic and statistical approaches, such as topic modeling (TM), can offer effective alternatives that require fewer computational resources. TM is a statistical method that automatically discovers topics in large collections of unlabeled text; however, it produces topics as distributions of representative words, which often lack clear interpretability. Our objective is to perform topic labeling by assigning meaningful labels to these sets of words. To achieve this without relying on computationally expensive models, we propose a graph-based approach that not only enriches topic words with semantically related terms but also explores the relationships among them. By analyzing these connections within the graph, we derive suitable labels that accurately capture each topic's meaning. We present a comparative study between our proposed method and several benchmarks, including ChatGPT-3.5, across two different datasets. Our method achieved consistently better results than traditional benchmarks in terms of BERTScore and cosine similarity and produced results comparable to ChatGPT-3.5, while remaining computationally efficient. Finally, we discuss future directions for topic labeling and highlight potential research avenues for enhancing interpretability and automation.</li>
</ul>

<h3>Title: SSPO: Subsentence-level Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Kun Yang, Zikang chen, Yanmeng Wang, Zhigen Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04256">https://arxiv.org/abs/2511.04256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04256">https://arxiv.org/pdf/2511.04256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04256]] SSPO: Subsentence-level Policy Optimization(https://arxiv.org/abs/2511.04256)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As a significant part of post-training of the Large Language Models (LLMs), Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs' reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative Policy Optimization) and GSPO (Group Sequence Policy Optimization), are observed to suffer from unstable policy updates and low usage of sampling data, respectively. The importance ratio of GRPO is calculated at the token level, which focuses more on optimizing a single token. This will be easily affected by outliers, leading to model training collapse. GSPO proposed the calculation of the response level importance ratio, which solves the problem of high variance and training noise accumulation in the calculation of the GRPO importance ratio. However, since all the response tokens share a common importance ratio, extreme values can easily raise or lower the overall mean, leading to the entire response being mistakenly discarded, resulting in a decrease in the utilization of sampled data. This paper introduces SSPO, which applies sentence-level importance ratio, taking the balance between GRPO and GSPO. SSPO not only avoids training collapse and high variance, but also prevents the whole response tokens from being abandoned by the clipping mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily adjust the clipping bounds, encouraging high-entropy tokens to explore and narrow the clipping range of low-entropy tokens. In particular, SSPO achieves an average score of 46.57 across five datasets, surpassing GRPO (43.01) and GSPO (44.42), and wins state-of-the-art performance on three datasets. These results highlight SSPO's effectiveness in leveraging generated data by taking the essence of GSPO but rejecting its shortcomings.</li>
</ul>

<h3>Title: Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery</h3>
<ul>
<li><strong>Authors: </strong>Claudio Giusti, Luca Guarnera, Sebastiano Battiato</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04260">https://arxiv.org/abs/2511.04260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04260">https://arxiv.org/pdf/2511.04260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04260]] Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery(https://arxiv.org/abs/2511.04260)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>The growing sophistication of synthetic image and deepfake generation models has turned source attribution and authenticity verification into a critical challenge for modern computer vision systems. Recent studies suggest that diffusion pipelines unintentionally imprint persistent statistical traces, known as signal leaks, within their outputs, particularly in latent representations. Building on this observation, we propose Proto-LeakNet, a signal-leak-aware and interpretable attribution framework that integrates closed-set classification with a density-based open-set evaluation on the learned embeddings, enabling analysis of unseen generators without retraining. Operating in the latent domain of diffusion models, our method re-simulates partial forward diffusion to expose residual generator-specific cues. A temporal attention encoder aggregates multi-step latent features, while a feature-weighted prototype head structures the embedding space and enables transparent attribution. Trained solely on closed data and achieving a Macro AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under post-processing, surpassing state-of-the-art methods, and achieves strong separability between known and unseen generators. These results demonstrate that modeling signal-leak bias in latent space enables reliable and interpretable AI-image and deepfake forensics. The code for the whole work will be available upon submission.</li>
</ul>

<h3>Title: A Parallel Region-Adaptive Differential Privacy Framework for Image Pixelization</h3>
<ul>
<li><strong>Authors: </strong>Ming Liu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04261">https://arxiv.org/abs/2511.04261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04261">https://arxiv.org/pdf/2511.04261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04261]] A Parallel Region-Adaptive Differential Privacy Framework for Image Pixelization(https://arxiv.org/abs/2511.04261)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>The widespread deployment of high-resolution visual sensing systems, coupled with the rise of foundation models, has amplified privacy risks in video-based applications. Differentially private pixelization offers mathematically guaranteed protection for visual data through grid-based noise addition, but challenges remain in preserving task-relevant fidelity, achieving scalability, and enabling efficient real-time deployment. To address this, we propose a novel parallel, region-adaptive pixelization framework that combines the theoretical rigor of differential privacy with practical efficiency. Our method adaptively adjusts grid sizes and noise scales based on regional complexity, leveraging GPU parallelism to achieve significant runtime acceleration compared to the classical baseline. A lightweight storage scheme is introduced by retaining only essential noisy statistics, significantly reducing space overhead. Formal privacy analysis is provided under the Laplace mechanism and parallel composition theorem. Extensive experiments on the PETS, Venice-2, and PPM-100 datasets demonstrate favorable privacy-utility trade-offs and significant runtime/storage reductions. A face re-identification attack experiment on CelebA further confirms the method's effectiveness in preventing identity inference. This validates its suitability for real-time privacy-critical applications such as elderly care, smart home monitoring, driver behavior analysis, and crowd behavior monitoring.</li>
</ul>

<h3>Title: DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification</h3>
<ul>
<li><strong>Authors: </strong>Yujie Yang, Shuang Li, Jun Ye, Neng Dong, Fan Li, Huafeng Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04281">https://arxiv.org/abs/2511.04281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04281">https://arxiv.org/pdf/2511.04281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04281]] DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification(https://arxiv.org/abs/2511.04281)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Video-based Visible-Infrared person re-identification (VVI-ReID) aims to retrieve the same pedestrian across visible and infrared modalities from video sequences. Existing methods tend to exploit modality-invariant visual features but largely overlook gait features, which are not only modality-invariant but also rich in temporal dynamics, thus limiting their ability to model the spatiotemporal consistency essential for cross-modal video matching. To address these challenges, we propose a DINOv2-Driven Gait Representation Learning (DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn gait features complementary to appearance cues, facilitating robust sequence-level representations for cross-modal retrieval. Specifically, we introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which generates and enhances silhouette representations with general-purpose semantic priors from DINOv2 and jointly optimizes them with the ReID objective to achieve semantically enriched and task-adaptive gait feature learning. Furthermore, we develop a Progressive Bidirectional Multi-Granularity Enhancement (PBMGE) module, which progressively refines feature representations by enabling bidirectional interactions between gait and appearance streams across multiple spatial granularities, fully leveraging their complementarity to enhance global representations with rich local details and produce highly discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets demonstrate the superiority of our approach, significantly outperforming existing state-of-the-art methods.</li>
</ul>

<h3>Title: Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment</h3>
<ul>
<li><strong>Authors: </strong>Leire Benito-Del-Valle, Artzai Picón, Daniel Mugica, Manuel Ramos, Eva Portillo, Javier Romero, Carlos Javier Jimenez, Ramón Navarra-Mestre</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04288">https://arxiv.org/abs/2511.04288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04288">https://arxiv.org/pdf/2511.04288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04288]] Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment(https://arxiv.org/abs/2511.04288)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Herbicide field trials require accurate identification of plant species and assessment of herbicide-induced damage across diverse environments. While general-purpose vision foundation models have shown promising results in complex visual domains, their performance can be limited in agriculture, where fine-grained distinctions between species and damage types are critical. In this work, we adapt a general-purpose vision foundation model to herbicide trial characterization. Trained using a self-supervised learning approach on a large, curated agricultural dataset, the model learns rich and transferable representations optimized for herbicide trials images. Our domain-specific model significantly outperforms the best general-purpose foundation model in both species identification (F1 score improvement from 0.91 to 0.94) and damage classification (from 0.26 to 0.33). Under unseen conditions (new locations and other time), it achieves even greater gains (species identification from 0.56 to 0.66; damage classification from 0.17 to 0.27). In domain-shift scenarios, such as drone imagery, it maintains strong performance (species classification from 0.49 to 0.60). Additionally, we show that domain-specific pretraining enhances segmentation accuracy, particularly in low-annotation regimes. An annotation-efficiency analysis reveals that, under unseen conditions, the domain-specific model achieves 5.4% higher F1 score than the general-purpose model, while using 80% fewer labeled samples. These results demonstrate the generalization capabilities of domain-specific foundation models and their potential to significantly reduce manual annotation efforts, offering a scalable and automated solution for herbicide trial analysis.</li>
</ul>

<h3>Title: Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data</h3>
<ul>
<li><strong>Authors: </strong>Robin Spanier, Thorsten Hoeser, Claudia Kuenzer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04304">https://arxiv.org/abs/2511.04304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04304">https://arxiv.org/pdf/2511.04304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04304]] Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data(https://arxiv.org/abs/2511.04304)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The recent and ongoing expansion of marine infrastructure, including offshore wind farms, oil and gas platforms, artificial islands, and aquaculture facilities, highlights the need for effective monitoring systems. The development of robust models for offshore infrastructure detection relies on comprehensive, balanced datasets, but falls short when samples are scarce, particularly for underrepresented object classes, shapes, and sizes. By training deep learning-based YOLOv10 object detection models with a combination of synthetic and real Sentinel-1 satellite imagery acquired in the fourth quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of Guinea, and Coast of Brazil), this study investigates the use of synthetic training data to enhance model performance. We evaluated this approach by applying the model to detect offshore platforms in three unseen regions (Gulf of Mexico, North Sea, Persian Gulf) and thereby assess geographic transferability. This region-holdout evaluation demonstrated that the model generalises beyond the training areas. In total, 3,529 offshore platforms were detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and 1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which improved to 0.90 upon incorporating synthetic data. We analysed how synthetic data enhances the representation of unbalanced classes and overall model performance, taking a first step toward globally transferable detection of offshore infrastructure. This study underscores the importance of balanced datasets and highlights synthetic data generation as an effective strategy to address common challenges in remote sensing, demonstrating the potential of deep learning for scalable, global offshore infrastructure monitoring.</li>
</ul>

<h3>Title: RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiangjun Zhang, Litong Gong, Yinglin Zheng, Yansong Liu, Wentao Jiang, Mingyi Xu, Biao Wang, Tiezheng Ge, Ming Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04317">https://arxiv.org/abs/2511.04317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04317">https://arxiv.org/pdf/2511.04317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04317]] RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation(https://arxiv.org/abs/2511.04317)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Most text-to-video(T2V) diffusion models depend on pre-trained text encoders for semantic alignment, yet they often fail to maintain video quality when provided with concise prompts rather than well-designed ones. The primary issue lies in their limited textual semantics understanding. Moreover, these text encoders cannot rephrase prompts online to better align with user intentions, which limits both the scalability and usability of the models, To address these challenges, we introduce RISE-T2V, which uniquely integrates the processes of prompt rephrasing and semantic feature extraction into a single and seamless step instead of two separate steps. RISE-T2V is universal and can be applied to various pre-trained LLMs and video diffusion models(VDMs), significantly enhancing their capabilities for T2V tasks. We propose an innovative module called the Rephrasing Adapter, enabling diffusion models to utilize text hidden states during the next token prediction of the LLM as a condition for video generation. By employing a Rephrasing Adapter, the video generation model can implicitly rephrase basic prompts into more comprehensive representations that better match the user's intent. Furthermore, we leverage the powerful capabilities of LLMs to enable video generation models to accomplish a broader range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a versatile framework applicable to different video diffusion model architectures, significantly enhancing the ability of T2V models to generate high-quality videos that align with user intent. Visual results are available on the webpage at this https URL.</li>
</ul>

<h3>Title: Differentially Private In-Context Learning with Nearest Neighbor Search</h3>
<ul>
<li><strong>Authors: </strong>Antti Koskela, Tejas Kulkarni, Laith Zumot</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04332">https://arxiv.org/abs/2511.04332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04332">https://arxiv.org/pdf/2511.04332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04332]] Differentially Private In-Context Learning with Nearest Neighbor Search(https://arxiv.org/abs/2511.04332)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Differentially private in-context learning (DP-ICL) has recently become an active research topic due to the inherent privacy risks of in-context learning. However, existing approaches overlook a critical component of modern large language model (LLM) pipelines: the similarity search used to retrieve relevant context data. In this work, we introduce a DP framework for in-context learning that integrates nearest neighbor search of relevant examples in a privacy-aware manner. Our method outperforms existing baselines by a substantial margin across all evaluated benchmarks, achieving more favorable privacy-utility trade-offs. To achieve this, we employ nearest neighbor retrieval from a database of context data, combined with a privacy filter that tracks the cumulative privacy cost of selected samples to ensure adherence to a central differential privacy budget. Experimental results on text classification and document question answering show a clear advantage of the proposed method over existing baselines.</li>
</ul>

<h3>Title: LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care</h3>
<ul>
<li><strong>Authors: </strong>Federico Pirola, Fabio Stella, Marco Grzegorczyk</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04333">https://arxiv.org/abs/2511.04333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04333">https://arxiv.org/pdf/2511.04333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04333]] LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care(https://arxiv.org/abs/2511.04333)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Dynamic Bayesian networks (DBNs) are increasingly used in healthcare due to their ability to model complex temporal relationships in patient data while maintaining interpretability, an essential feature for clinical decision-making. However, existing approaches to handling missing data in longitudinal clinical datasets are largely derived from static Bayesian networks literature, failing to properly account for the temporal nature of the data. This gap limits the ability to quantify uncertainty over time, which is particularly critical in settings such as intensive care, where understanding the temporal dynamics is fundamental for model trustworthiness and applicability across diverse patient groups. Despite the potential of DBNs, a full Bayesian framework that integrates missing data handling remains underdeveloped. In this work, we propose a novel Gibbs sampling-based method for learning DBNs from incomplete data. Our method treats each missing value as an unknown parameter following a Gaussian distribution. At each iteration, the unobserved values are sampled from their full conditional distributions, allowing for principled imputation and uncertainty estimation. We evaluate our method on both simulated datasets and real-world intensive care data from critically ill patients. Compared to standard model-agnostic techniques such as MICE, our Bayesian approach demonstrates superior reconstruction accuracy and convergence properties. These results highlight the clinical relevance of incorporating full Bayesian inference in temporal models, providing more reliable imputations and offering deeper insight into model behavior. Our approach supports safer and more informed clinical decision-making, particularly in settings where missing data are frequent and potentially impactful.</li>
</ul>

<h3>Title: Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography</h3>
<ul>
<li><strong>Authors: </strong>Saúl Alonso-Monsalve, Leigh H. Whitehead, Adam Aurisano, Lorena Escudero Sanchez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04334">https://arxiv.org/abs/2511.04334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04334">https://arxiv.org/pdf/2511.04334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04334]] Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography(https://arxiv.org/abs/2511.04334)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The accurate delineation of tumours in radiological images like Computed Tomography is a very specialised and time-consuming task, and currently a bottleneck preventing quantitative analyses to be performed routinely in the clinical setting. For this reason, developing methods for the automated segmentation of tumours in medical imaging is of the utmost importance and has driven significant efforts in recent years. However, challenges regarding the impracticality of 3D scans, given the large amount of voxels to be analysed, usually requires the downsampling of such images or using patches thereof when applying traditional convolutional neural networks. To overcome this problem, in this paper we propose a new methodology that uses, divided into two stages, voxel sparsification and submanifold sparse convolutional networks. This method allows segmentations to be performed with high-resolution inputs and a native 3D model architecture, obtaining state-of-the-art accuracies while significantly reducing the computational resources needed in terms of GPU memory and time. We studied the deployment of this methodology in the context of Computed Tomography images of renal cancer patients from the KiTS23 challenge, and our method achieved results competitive with the challenge winners, with Dice similarity coefficients of 95.8% for kidneys + masses, 85.7% for tumours + cysts, and 80.3% for tumours alone. Crucially, our method also offers significant computational improvements, achieving up to a 60% reduction in inference time and up to a 75\% reduction in VRAM usage compared to an equivalent dense architecture, across both CPU and various GPU cards tested.</li>
</ul>

<h3>Title: Comparative Study of CNN Architectures for Binary Classification of Horses and Motorcycles in the VOC 2008 Dataset</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Annas Shaikh, Hamza Zaman, Arbaz Asif</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04344">https://arxiv.org/abs/2511.04344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04344">https://arxiv.org/pdf/2511.04344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04344]] Comparative Study of CNN Architectures for Binary Classification of Horses and Motorcycles in the VOC 2008 Dataset(https://arxiv.org/abs/2511.04344)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents a comprehensive evaluation of nine convolutional neural network architectures for binary classification of horses and motorcycles in the VOC 2008 dataset. We address the significant class imbalance problem by implementing minority-class augmentation techniques. Our experiments compare modern architectures including ResNet-50, ConvNeXt-Tiny, DenseNet-121, and Vision Transformer across multiple performance metrics. Results demonstrate substantial performance variations, with ConvNeXt-Tiny achieving the highest Average Precision (AP) of 95.53% for horse detection and 89.12% for motorcycle detection. We observe that data augmentation significantly improves minority class detection, particularly benefiting deeper architectures. This study provides insights into architecture selection for imbalanced binary classification tasks and quantifies the impact of data augmentation strategies in mitigating class imbalance issues in object detection.</li>
</ul>

<h3>Title: Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Sanjay Kumar, Tim Brophy, Eoin Martino Grua, Ganesh Sistu, Valentina Donzella, Ciaran Eising</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04347">https://arxiv.org/abs/2511.04347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04347">https://arxiv.org/pdf/2511.04347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04347]] Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection(https://arxiv.org/abs/2511.04347)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate 3D object detection is essential for automated vehicles to navigate safely in complex real-world environments. Bird's Eye View (BEV) representations, which project multi-sensor data into a top-down spatial format, have emerged as a powerful approach for robust perception. Although BEV-based fusion architectures have demonstrated strong performance through multimodal integration, the effects of sensor occlusions, caused by environmental conditions such as fog, haze, or physical obstructions, on 3D detection accuracy remain underexplored. In this work, we investigate the impact of occlusions on both camera and Light Detection and Ranging (LiDAR) outputs using the BEVFusion architecture, evaluated on the nuScenes dataset. Detection performance is measured using mean Average Precision (mAP) and the nuScenes Detection Score (NDS). Our results show that moderate camera occlusions lead to a 41.3% drop in mAP (from 35.6% to 20.9%) when detection is based only on the camera. On the other hand, LiDAR sharply drops in performance only under heavy occlusion, with mAP falling by 47.3% (from 64.7% to 34.1%), with a severe impact on long-range detection. In fused settings, the effect depends on which sensor is occluded: occluding the camera leads to a minor 4.1% drop (from 68.5% to 65.7%), while occluding LiDAR results in a larger 26.8% drop (to 50.1%), revealing the model's stronger reliance on LiDAR for the task of 3D object detection. Our results highlight the need for future research into occlusion-aware evaluation methods and improved sensor fusion techniques that can maintain detection accuracy in the presence of partial sensor failure or degradation due to adverse environmental conditions.</li>
</ul>

<h3>Title: A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications</h3>
<ul>
<li><strong>Authors: </strong>Puneet Mishra, Martijntje Vollebregt, Yizhou Ma, Maria Font-i-Furnols</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04349">https://arxiv.org/abs/2511.04349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04349">https://arxiv.org/pdf/2511.04349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04349]] A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications(https://arxiv.org/abs/2511.04349)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Background In analytical chemistry, spatial information about materials is commonly captured through imaging techniques, such as traditional color cameras or with advanced hyperspectral cameras and microscopes. However, efficiently extracting and analyzing this spatial information for exploratory and predictive purposes remains a challenge, especially when using traditional chemometric methods. Recent advances in deep learning and artificial intelligence have significantly enhanced image processing capabilities, enabling the extraction of multiscale deep features that are otherwise challenging to capture with conventional image processing techniques. Despite the wide availability of open-source deep learning models, adoption in analytical chemistry remains limited because of the absence of structured, step-by-step guidance for implementing these models. Results This tutorial aims to bridge this gap by providing a step-by-step guide for applying deep learning approaches to extract spatial information from imaging data and integrating it with other data sources, such as spectral information. Importantly, the focus of this work is not on training deep learning models for image processing but on using existing open source models to extract deep features from imaging data. Significance The tutorial provides MATLAB code tutorial demonstrations, showcasing the processing of imaging data from various imaging modalities commonly encountered in analytical chemistry. Readers must run the tutorial steps on their own datasets using the codes presented in this tutorial.</li>
</ul>

<h3>Title: Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA</h3>
<ul>
<li><strong>Authors: </strong>Itbaan Safwan, Muhammad Annas Shaikh, Muhammad Haaris, Ramail Khan, Muhammad Atif Tahir</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04384">https://arxiv.org/abs/2511.04384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04384">https://arxiv.org/pdf/2511.04384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04384]] Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA(https://arxiv.org/abs/2511.04384)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We present a multi-task framework for the MediaEval Medico 2025 challenge, leveraging a LoRA-tuned Florence-2 model for simultaneous visual question answering (VQA), explanation generation, and visual grounding. The proposed system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer learning, (2) a synthetically enriched explanation dataset offering structured medical reasoning, and (3) text-to-region pairs linking visual features with segmentation masks. This multi-task setup enables the model to jointly learn visual grounding, reasoning, and interpretation, producing responses that are both accurate and interpretable. Extensive evaluation demonstrates that our approach substantially improves over single-task baselines in both answer accuracy and visual localization, highlighting the effectiveness of grounded multi-task learning for medical VQA applications.</li>
</ul>

<h3>Title: Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness</h3>
<ul>
<li><strong>Authors: </strong>Subeen Park, Joowang Kim, Hakyung Lee, Sunjae Yoo, Kyungwoo Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04401">https://arxiv.org/abs/2511.04401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04401">https://arxiv.org/pdf/2511.04401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04401]] Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness(https://arxiv.org/abs/2511.04401)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning models achieve strong performance across various domains but often rely on spurious correlations, making them vulnerable to distribution shifts. This issue is particularly severe in subpopulation shift scenarios, where models struggle in underrepresented groups. While existing methods have made progress in mitigating this issue, their performance gains are still constrained. They lack a rigorous theoretical framework connecting the embedding space representations with worst-group error. To address this limitation, we propose Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness (SCER), a novel approach that directly regularizes feature representations to suppress spurious cues. We show theoretically that worst-group error is influenced by how strongly the classifier relies on spurious versus core directions, identified from differences in group-wise mean embeddings across domains and classes. By imposing theoretical constraints at the embedding level, SCER encourages models to focus on core features while reducing sensitivity to spurious patterns. Through systematic evaluation on multiple vision and language, we show that SCER outperforms prior state-of-the-art studies in worst-group accuracy. Our code is available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Dynamic Jointly Batch Selection for Data Efficient Machine Translation Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Amin Ghanizadeh, Mohammad Javad Dousti</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04406">https://arxiv.org/abs/2511.04406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04406">https://arxiv.org/pdf/2511.04406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04406]] Dynamic Jointly Batch Selection for Data Efficient Machine Translation Fine-Tuning(https://arxiv.org/abs/2511.04406)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Data quality and its effective selection are fundamental to improving the performance of machine translation models, serving as cornerstones for achieving robust and reliable translation systems. This paper presents a data selection methodology specifically designed for fine-tuning machine translation systems, which leverages the synergy between a learner model and a pre-trained reference model to enhance overall training effectiveness. By defining a learnability score, our approach systematically evaluates the utility of data points for training, ensuring that only the most relevant and impactful examples contribute to the fine-tuning process. Furthermore, our method employs a batch selection strategy which considers interdependencies among data points, optimizing the efficiency of the training process while maintaining a focus on data relevance. Experiments on English to Persian and several other language pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that our method can achieve up to a fivefold improvement in data efficiency compared to an iid baseline. Experimental results indicate that our approach improves computational efficiency by 24 when utilizing cached embeddings, as it requires fewer training data points. Additionally, it enhances generalization, resulting in superior translation performance compared to random selection method.</li>
</ul>

<h3>Title: The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity</h3>
<ul>
<li><strong>Authors: </strong>Tim Tomov, Dominik Fuchsgruber, Tom Wollschläger, Stephan Günnemann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04418">https://arxiv.org/abs/2511.04418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04418">https://arxiv.org/pdf/2511.04418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04418]] The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity(https://arxiv.org/abs/2511.04418)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is critical for trustworthy deployment. While real-world language is inherently ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically benchmarked against tasks with no ambiguity. In this work, we demonstrate that while current uncertainty estimators perform well under the restrictive assumption of no ambiguity, they degrade to close-to-random performance on ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first ambiguous question-answering (QA) datasets equipped with ground-truth answer distributions estimated from factual co-occurrence. We find this performance deterioration to be consistent across different estimation paradigms: using the predictive distribution itself, internal representations throughout the model, and an ensemble of models. We show that this phenomenon can be theoretically explained, revealing that predictive-distribution and ensemble-based estimators are fundamentally limited under ambiguity. Overall, our study reveals a key shortcoming of current UQ methods for LLMs and motivates a rethinking of current modeling paradigms.</li>
</ul>

<h3>Title: HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats</h3>
<ul>
<li><strong>Authors: </strong>Alan de Aguiar, Michaella Pereira Andrade, Charles Morphy D. Santos, João Paulo Gois</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04426">https://arxiv.org/abs/2511.04426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04426">https://arxiv.org/pdf/2511.04426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04426]] HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats(https://arxiv.org/abs/2511.04426)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Analyzing octopuses in their natural habitats is challenging due to their camouflage capability, rapid changes in skin texture and color, non-rigid body deformations, and frequent occlusions, all of which are compounded by variable underwater lighting and turbidity. Addressing the lack of large-scale annotated datasets, this paper introduces HideAndSeg, a novel, minimally supervised AI-based tool for segmenting videos of octopuses. It establishes a quantitative baseline for this task. HideAndSeg integrates SAM2 with a custom-trained YOLOv11 object detector. First, the user provides point coordinates to generate the initial segmentation masks with SAM2. These masks serve as training data for the YOLO model. After that, our approach fully automates the pipeline by providing a bounding box prompt to SAM2, eliminating the need for further manual intervention. We introduce two unsupervised metrics - temporal consistency $DICE_t$ and new component count $NC_t$ - to quantitatively evaluate segmentation quality and guide mask refinement in the absence of ground-truth data, i.e., real-world information that serves to train, validate, and test AI models. Results show that HideAndSeg achieves satisfactory performance, reducing segmentation noise compared to the manually prompted approach. Our method can re-identify and segment the octopus even after periods of complete occlusion in natural environments, a scenario in which the manually prompted model fails. By reducing the need for manual analysis in real-world scenarios, this work provides a practical tool that paves the way for more efficient behavioral studies of wild cephalopods.</li>
</ul>

<h3>Title: Adversarially Robust and Interpretable Magecart Malware Detection</h3>
<ul>
<li><strong>Authors: </strong>Pedro Pereira, José Gouveia, João Vitorino, Eva Maia, Isabel Praça</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04440">https://arxiv.org/abs/2511.04440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04440">https://arxiv.org/pdf/2511.04440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04440]] Adversarially Robust and Interpretable Magecart Malware Detection(https://arxiv.org/abs/2511.04440)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Magecart skimming attacks have emerged as a significant threat to client-side security and user trust in online payment systems. This paper addresses the challenge of achieving robust and explainable detection of Magecart attacks through a comparative study of various Machine Learning (ML) models with a real-world dataset. Tree-based, linear, and kernel-based models were applied, further enhanced through hyperparameter tuning and feature selection, to distinguish between benign and malicious scripts. Such models are supported by a Behavior Deterministic Finite Automaton (DFA) which captures structural behavior patterns in scripts, helping to analyze and classify client-side script execution logs. To ensure robustness against adversarial evasion attacks, the ML models were adversarially trained and evaluated using attacks from the Adversarial Robustness Toolbox and the Adaptative Perturbation Pattern Method. In addition, concise explanations of ML model decisions are provided, supporting transparency and user trust. Experimental validation demonstrated high detection performance and interpretable reasoning, demonstrating that traditional ML models can be effective in real-world web security contexts.</li>
</ul>

<h3>Title: ForecastGAN: A Decomposition-Based Adversarial Framework for Multi-Horizon Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Syeda Sitara Wishal Fatima, Afshin Rahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04445">https://arxiv.org/abs/2511.04445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04445">https://arxiv.org/pdf/2511.04445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04445]] ForecastGAN: A Decomposition-Based Adversarial Framework for Multi-Horizon Time Series Forecasting(https://arxiv.org/abs/2511.04445)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>Time series forecasting is essential across domains from finance to supply chain management. This paper introduces ForecastGAN, a novel decomposition based adversarial framework addressing limitations in existing approaches for multi-horizon predictions. Although transformer models excel in long-term forecasting, they often underperform in short-term scenarios and typically ignore categorical features. ForecastGAN operates through three integrated modules: a Decomposition Module that extracts seasonality and trend components; a Model Selection Module that identifies optimal neural network configurations based on forecasting horizon; and an Adversarial Training Module that enhances prediction robustness through Conditional Generative Adversarial Network training. Unlike conventional approaches, ForecastGAN effectively integrates both numerical and categorical features. We validate our framework on eleven benchmark multivariate time series datasets that span various forecasting horizons. The results show that ForecastGAN consistently outperforms state-of-the-art transformer models for short-term forecasting while remaining competitive for long-term horizons. This research establishes a more generalizable approach to time series forecasting that adapts to specific contexts while maintaining strong performance across diverse data characteristics without extensive hyperparameter tuning.</li>
</ul>

<h3>Title: Federated Stochastic Minimax Optimization under Heavy-Tailed Noises</h3>
<ul>
<li><strong>Authors: </strong>Xinwen Zhang, Hongchang Gao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04456">https://arxiv.org/abs/2511.04456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04456">https://arxiv.org/pdf/2511.04456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04456]] Federated Stochastic Minimax Optimization under Heavy-Tailed Noises(https://arxiv.org/abs/2511.04456)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Heavy-tailed noise has attracted growing attention in nonconvex stochastic optimization, as numerous empirical studies suggest it offers a more realistic assumption than standard bounded variance assumption. In this work, we investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which integrates normalized gradients, and FedMuon-DA, which leverages the Muon optimizer for local updates. Both algorithms are designed to effectively address heavy-tailed noise in federated minimax optimization, under a milder condition. We theoretically establish that both algorithms achieve a convergence rate of $O({1}/{(TNp)^{\frac{s-1}{2s}}})$. To the best of our knowledge, these are the first federated minimax optimization algorithms with rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments further validate their effectiveness.</li>
</ul>

<h3>Title: Towards Causal Market Simulators</h3>
<ul>
<li><strong>Authors: </strong>Dennis Thumm, Luis Ontaneda Mijares</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.CP, stat.OT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04469">https://arxiv.org/abs/2511.04469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04469">https://arxiv.org/pdf/2511.04469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04469]] Towards Causal Market Simulators(https://arxiv.org/abs/2511.04469)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Market generators using deep generative models have shown promise for synthetic financial data generation, but existing approaches lack causal reasoning capabilities essential for counterfactual analysis and risk assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that combines variational autoencoders with structural causal models to generate counterfactual financial time series while preserving both temporal dependencies and causal relationships. Our approach enforces causal constraints through directed acyclic graphs in the decoder architecture and employs the causal Wasserstein distance for training. We validate our method on synthetic autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating superior performance in counterfactual probability estimation with L1 distances as low as 0.03-0.10 compared to ground truth. The model enables financial stress testing, scenario analysis, and enhanced backtesting by generating plausible counterfactual market trajectories that respect underlying causal mechanisms.</li>
</ul>

<h3>Title: Exploiting Data Structures for Bypassing and Crashing Anti-Malware Solutions via Telemetry Complexity Attacks</h3>
<ul>
<li><strong>Authors: </strong>Evgenios Gkritsis, Constantinos Patsakis, George Stergiopoulos</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04472">https://arxiv.org/abs/2511.04472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04472">https://arxiv.org/pdf/2511.04472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04472]] Exploiting Data Structures for Bypassing and Crashing Anti-Malware Solutions via Telemetry Complexity Attacks(https://arxiv.org/abs/2511.04472)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Anti-malware systems rely on sandboxes, hooks, and telemetry pipelines, including collection agents, serializers, and database backends, to monitor program and system behavior. We show that these data-handling components constitute an exploitable attack surface that can lead to denial-of-analysis (DoA) states without disabling sensors or requiring elevated privileges. As a result, we present \textit{Telemetry Complexity Attacks} (TCAs), a new class of vulnerabilities that exploit fundamental mismatches between unbounded collection mechanisms and bounded processing capabilities. Our method recursively spawns child processes to generate specially crafted, deeply nested, and oversized telemetry that stresses serialization and storage boundaries, as well as visualization layers, for example, JSON/BSON depth and size limits. Depending on the product, this leads to truncated or missing behavioral reports, rejected database inserts, serializer recursion and size errors, and unresponsive dashboards. In all of these cases, malicious activity is normally executed; however, depending on the examined solution, it is not recorded and/or not presented to the analysts. Therefore, instead of evading sensors, we break the pipeline that stores the data captured by the sensors. We evaluate our technique against twelve commercial and open-source malware analysis platforms and endpoint detection and response (EDR) solutions. Seven products fail in different stages of the telemetry pipeline; two vendors assigned CVE identifiers (CVE-2025-61301 and CVE-2025-61303), and others issued patches or configuration changes. We discuss root causes and propose mitigation strategies to prevent DoA attacks triggered by adversarial telemetry.</li>
</ul>

<h3>Title: Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability</h3>
<ul>
<li><strong>Authors: </strong>Wenwen Li, Sizhe Wang, Hyunho Lee, Chenyan Lu, Sujit Roy, Rahul Ramachandran, Chia-Yu Hsu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04474">https://arxiv.org/abs/2511.04474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04474">https://arxiv.org/pdf/2511.04474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04474]] Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability(https://arxiv.org/abs/2511.04474)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Landslides cause severe damage to lives, infrastructure, and the environment, making accurate and timely mapping essential for disaster preparedness and response. However, conventional deep learning models often struggle when applied across different sensors, regions, or under conditions of limited training data. To address these challenges, we present a three-axis analytical framework of sensor, label, and domain for adapting geospatial foundation models (GeoFMs), focusing on Prithvi-EO-2.0 for landslide mapping. Through a series of experiments, we show that it consistently outperforms task-specific CNNs (U-Net, U-Net++), vision transformers (Segformer, SwinV2-B), and other GeoFMs (TerraMind, SatMAE). The model, built on global pretraining, self-supervision, and adaptable fine-tuning, proved resilient to spectral variation, maintained accuracy under label scarcity, and generalized more reliably across diverse datasets and geographic settings. Alongside these strengths, we also highlight remaining challenges such as computational cost and the limited availability of reusable AI-ready training data for landslide research. Overall, our study positions GeoFMs as a step toward more robust and scalable approaches for landslide risk reduction and environmental monitoring.</li>
</ul>

<h3>Title: Probabilistic Textual Time Series Depression Detection</h3>
<ul>
<li><strong>Authors: </strong>Fabian Schmidt, Seyedehmoniba Ravan, Vladimir Vlassov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04476">https://arxiv.org/abs/2511.04476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04476">https://arxiv.org/pdf/2511.04476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04476]] Probabilistic Textual Time Series Depression Detection(https://arxiv.org/abs/2511.04476)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Accurate and interpretable predictions of depression severity are essential for clinical decision support, yet existing models often lack uncertainty estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time Series Depression Detection framework that predicts PHQ-8 scores from utterance-level clinical interviews while modeling uncertainty over time. PTTSD includes sequence-to-sequence and sequence-to-one variants, both combining bidirectional LSTMs, self-attention, and residual connections with Gaussian or Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated prediction intervals. Ablations confirm the value of attention and probabilistic modeling, while comparisons with MentalBERT establish generality. A three-part calibration analysis and qualitative case studies further highlight the interpretability and clinical relevance of uncertainty-aware forecasting.</li>
</ul>

<h3>Title: ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai</h3>
<ul>
<li><strong>Authors: </strong>Surapon Nonesung, Teetouch Jaknamon, Sirinya Chaiophat, Natapong Nitarach, Chanakan Wittayasakpan, Warit Sirichotedumrong, Adisai Na-Thalang, Kunat Pipatanakul</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04479">https://arxiv.org/abs/2511.04479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04479">https://arxiv.org/pdf/2511.04479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04479]] ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai(https://arxiv.org/abs/2511.04479)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We present ThaiOCRBench, the first comprehensive benchmark for evaluating vision-language models (VLMs) on Thai text-rich visual understanding tasks. Despite recent progress in multimodal modeling, existing benchmarks predominantly focus on high-resource languages, leaving Thai underrepresented, especially in tasks requiring document structure understanding. ThaiOCRBench addresses this gap by offering a diverse, human-annotated dataset comprising 2,808 samples across 13 task categories. We evaluate a wide range of state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and open-source systems. Results show a significant performance gap, with proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source counterparts. Notably, fine-grained text recognition and handwritten content extraction exhibit the steepest performance drops among open-source models. Through detailed error analysis, we identify key challenges such as language bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a standardized framework for assessing VLMs in low-resource, script-complex settings, and provides actionable insights for improving Thai-language document understanding.</li>
</ul>

<h3>Title: Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training</h3>
<ul>
<li><strong>Authors: </strong>Ipsita Ghosh, Ethan Nguyen, Christian Kümmerle</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04485">https://arxiv.org/abs/2511.04485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04485">https://arxiv.org/pdf/2511.04485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04485]] Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training(https://arxiv.org/abs/2511.04485)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Parameter-efficient training, based on low-rank optimization, has become a highly successful tool for fine-tuning large deep-learning models. However, these methods fail at low-rank pre-training tasks where maintaining the low-rank structure and the objective remains a challenging task. We propose the Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel low-rank inducing training strategy inspired by the iteratively reweighted least squares (IRLS) framework. Q3R is based on a quadratic regularizer term which majorizes a smoothed log determinant serving as rank surrogate objective. Unlike other low-rank training techniques, Q3R is able to train weight matrices with prescribed, low target ranks of models that achieve comparable predictive performance as dense models, with small computational overhead, while remaining fully compatible with existing architectures. For example, we demonstrated one experiment where we are able to truncate $60\%$ and $80\%$ of the parameters of a ViT-Tiny model with $~1.3\%$ and $~4\%$ accuracy drop in CIFAR-10 performance respectively. The efficacy of Q3R is confirmed on Transformers across both image and language tasks, including for low-rank fine-tuning.</li>
</ul>

<h3>Title: RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables</h3>
<ul>
<li><strong>Authors: </strong>Nikhil Abhyankar, Purvi Chaurasia, Sanchit Kabra, Ananya Srivastava, Vivek Gupta, Chandan K. Reddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04491">https://arxiv.org/abs/2511.04491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04491">https://arxiv.org/pdf/2511.04491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04491]] RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables(https://arxiv.org/abs/2511.04491)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing tabular reasoning benchmarks mostly test models on small, uniform tables, underrepresenting the complexity of real-world data and giving an incomplete view of Large Language Models' (LLMs) reasoning abilities. Real tables are long, heterogeneous, and domain-specific, mixing structured fields with free text and requiring multi-hop reasoning across thousands of tokens. To address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from 2031 real-world tables spanning two domains: i) RB-Science (NSF grant records) and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates LLMs jointly across scale, heterogeneity, domain specificity, and reasoning complexity. Experiments with open-source and proprietary models show that LLMs struggle with heterogeneous schemas and complex multi-hop inference, revealing persistent weaknesses in current architectures and prompting strategies. RUST-BENCH establishes a challenging new testbed for advancing tabular reasoning research.</li>
</ul>

<h3>Title: Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering</h3>
<ul>
<li><strong>Authors: </strong>Christos-Nikolaos Zacharopoulos, Revekka Kyriakoglou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04499">https://arxiv.org/abs/2511.04499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04499">https://arxiv.org/pdf/2511.04499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04499]] Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering(https://arxiv.org/abs/2511.04499)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) become integral to human-centered applications, understanding their personality-like behaviors is increasingly important for responsible development and deployment. This paper systematically evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to assess trait expressions under varying sampling temperatures. We find significant differences across four of the five personality dimensions, with Neuroticism and Extraversion susceptible to temperature adjustments. Further, hierarchical clustering reveals distinct model clusters, suggesting that architectural features may predispose certain models toward stable trait profiles. Taken together, these results offer new insights into the emergence of personality-like patterns in LLMs and provide a new perspective on model tuning, selection, and the ethical governance of AI systems. We share the data and code for this analysis here: this https URL</li>
</ul>

<h3>Title: RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG</h3>
<ul>
<li><strong>Authors: </strong>Joshua Gao, Quoc Huy Pham, Subin Varghese, Silwal Saurav, Vedhus Hoskere</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04502">https://arxiv.org/abs/2511.04502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04502">https://arxiv.org/pdf/2511.04502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04502]] RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG(https://arxiv.org/abs/2511.04502)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) is a critical technique for grounding Large Language Models (LLMs) in factual evidence, yet evaluating RAG systems in specialized, safety-critical domains remains a significant challenge. Existing evaluation frameworks often rely on heuristic-based metrics that fail to capture domain-specific nuances and other works utilize LLM-as-a-Judge approaches that lack validated alignment with human judgment. This paper introduces RAGalyst, an automated, human-aligned agentic framework designed for the rigorous evaluation of domain-specific RAG systems. RAGalyst features an agentic pipeline that generates high-quality, synthetic question-answering (QA) datasets from source documents, incorporating an agentic filtering step to ensure data fidelity. The framework refines two key LLM-as-a-Judge metrics-Answer Correctness and Answerability-using prompt optimization to achieve a strong correlation with human annotations. Applying this framework to evaluate various RAG components across three distinct domains (military operations, cybersecurity, and bridge engineering), we find that performance is highly context-dependent. No single embedding model, LLM, or hyperparameter configuration proves universally optimal. Additionally, we provide an analysis on the most common low Answer Correctness reasons in RAG. These findings highlight the necessity of a systematic evaluation framework like RAGalyst, which empowers practitioners to uncover domain-specific trade-offs and make informed design choices for building reliable and effective RAG systems. RAGalyst is available on our Github.</li>
</ul>

<h3>Title: Alternative Fairness and Accuracy Optimization in Criminal Justice</h3>
<ul>
<li><strong>Authors: </strong>Shaolong Wu, James Blume, Geshi Yeung</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04505">https://arxiv.org/abs/2511.04505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04505">https://arxiv.org/pdf/2511.04505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04505]] Alternative Fairness and Accuracy Optimization in Criminal Justice(https://arxiv.org/abs/2511.04505)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Algorithmic fairness has grown rapidly as a research area, yet key concepts remain unsettled, especially in criminal justice. We review group, individual, and process fairness and map the conditions under which they conflict. We then develop a simple modification to standard group fairness. Rather than exact parity across protected groups, we minimize a weighted error loss while keeping differences in false negative rates within a small tolerance. This makes solutions easier to find, can raise predictive accuracy, and surfaces the ethical choice of error costs. We situate this proposal within three classes of critique: biased and incomplete data, latent affirmative action, and the explosion of subgroup constraints. Finally, we offer a practical framework for deployment in public decision systems built on three pillars: need-based decisions, Transparency and accountability, and narrowly tailored definitions and solutions. Together, these elements link technical design to legitimacy and provide actionable guidance for agencies that use risk assessment and related tools.</li>
</ul>

<h3>Title: Large Language Models for Cyber Security</h3>
<ul>
<li><strong>Authors: </strong>Raunak Somani, Aswani Kumar Cherukuri</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04508">https://arxiv.org/abs/2511.04508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04508">https://arxiv.org/pdf/2511.04508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04508]] Large Language Models for Cyber Security(https://arxiv.org/abs/2511.04508)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>This paper studies the integration off Large Language Models into cybersecurity tools and protocols. The main issue discussed in this paper is how traditional rule-based and signature based security systems are not enough to deal with modern AI powered cyber threats. Cybersecurity industry is changing as threats are becoming more dangerous and adaptive in nature by levering the features provided by AI tools. By integrating LLMs into these tools and protocols, make the systems scalable, context-aware and intelligent. Thus helping it to mitigate these evolving cyber threats. The paper studies the architecture and functioning of LLMs, its integration into Encrypted prompts to prevent prompt injection attacks. It also studies the integration of LLMs into cybersecurity tools using a four layered architecture. At last, the paper has tried to explain various ways of integration LLMs into traditional Intrusion Detection System and enhancing its original abilities in various dimensions. The key findings of this paper has been (i)Encrypted Prompt with LLM is an effective way to mitigate prompt injection attacks, (ii) LLM enhanced cyber security tools are more accurate, scalable and adaptable to new threats as compared to traditional models, (iii) The decoupled model approach for LLM integration into IDS is the best way as it is the most accurate way.</li>
</ul>

<h3>Title: Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom Parity</h3>
<ul>
<li><strong>Authors: </strong>Obed Amo, Samit Ghosh, Markus Lange-Hegermann, Bogdan Raiţă, Michael Pokojovy</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04518">https://arxiv.org/abs/2511.04518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04518">https://arxiv.org/pdf/2511.04518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04518]] Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom Parity(https://arxiv.org/abs/2511.04518)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We present a new benchmarking study comparing a boundary-constrained Ehrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical finite element method combined with Crank--Nicolson time stepping (CN-FEM) for solving the two-dimensional wave equation with homogeneous Dirichlet boundary conditions. The B-EPGP construction leverages exponential-polynomial bases derived from the characteristic variety to enforce the PDE and boundary conditions exactly and employs penalized least squares to estimate the coefficients. To ensure fairness across paradigms, we introduce a degrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP consistently attains lower space-time $L^2$-error and maximum-in-time $L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of magnitude.</li>
</ul>

<h3>Title: THEval. Evaluation Framework for Talking Head Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Nabyl Quignon, Baptiste Chopin, Yaohui Wang, Antitza Dantcheva</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04520">https://arxiv.org/abs/2511.04520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04520">https://arxiv.org/pdf/2511.04520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04520]] THEval. Evaluation Framework for Talking Head Video Generation(https://arxiv.org/abs/2511.04520)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Video generation has achieved remarkable progress, with generated videos increasingly resembling real ones. However, the rapid advance in generation has outpaced the development of adequate evaluation metrics. Currently, the assessment of talking head generation primarily relies on limited metrics, evaluating general video quality, lip synchronization, and on conducting user studies. Motivated by this, we propose a new evaluation framework comprising 8 metrics related to three dimensions (i) quality, (ii) naturalness, and (iii) synchronization. In selecting the metrics, we place emphasis on efficiency, as well as alignment with human preferences. Based on this considerations, we streamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as well as face quality. Our extensive experiments on 85,000 videos generated by 17 state-of-the-art models suggest that while many algorithms excel in lip synchronization, they face challenges with generating expressiveness and artifact-free details. These videos were generated based on a novel real dataset, that we have curated, in order to mitigate bias of training data. Our proposed benchmark framework is aimed at evaluating the improvement of generative methods. Original code, dataset and leaderboards will be publicly released and regularly updated with new methods, in order to reflect progress in the field.</li>
</ul>

<h3>Title: IntelliProof: An Argumentation Network-based Conversational Helper for Organized Reflection</h3>
<ul>
<li><strong>Authors: </strong>Kaveh Eskandari Miandoab, Katharine Kowalyshyn, Kabir Pamnani, Anesu Gavhera, Vasanth Sarathy, Matthias Scheutz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04528">https://arxiv.org/abs/2511.04528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04528">https://arxiv.org/pdf/2511.04528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04528]] IntelliProof: An Argumentation Network-based Conversational Helper for Organized Reflection(https://arxiv.org/abs/2511.04528)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>We present IntelliProof, an interactive system for analyzing argumentative essays through LLMs. IntelliProof structures an essay as an argumentation graph, where claims are represented as nodes, supporting evidence is attached as node properties, and edges encode supporting or attacking relations. Unlike existing automated essay scoring systems, IntelliProof emphasizes the user experience: each relation is initially classified and scored by an LLM, then visualized for enhanced understanding. The system provides justifications for classifications and produces quantitative measures for essay coherence. It enables rapid exploration of argumentative quality while retaining human oversight. In addition, IntelliProof provides a set of tools for a better understanding of an argumentative essay and its corresponding graph in natural language, bridging the gap between the structural semantics of argumentative essays and the user's understanding of a given text. A live demo and the system are available here to try: \textbf{this https URL}</li>
</ul>

<h3>Title: Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics</h3>
<ul>
<li><strong>Authors: </strong>Jonas E. Katona, Emily K. de Jong, Nipun Gunawardena</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04534">https://arxiv.org/abs/2511.04534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04534">https://arxiv.org/pdf/2511.04534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04534]] Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics(https://arxiv.org/abs/2511.04534)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reduced-order models (ROMs) can efficiently simulate high-dimensional physical systems, but lack robust uncertainty quantification methods. Existing approaches are frequently architecture- or training-specific, which limits flexibility and generalization. We introduce a post hoc, model-agnostic framework for predictive uncertainty quantification in latent space ROMs that requires no modification to the underlying architecture or training procedure. Using conformal prediction, our approach estimates statistical prediction intervals for multiple components of the ROM pipeline: latent dynamics, reconstruction, and end-to-end predictions. We demonstrate the method on a latent space dynamical model for cloud microphysics, where it accurately predicts the evolution of droplet-size distributions and quantifies uncertainty across the ROM pipeline.</li>
</ul>

<h3>Title: From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting</h3>
<ul>
<li><strong>Authors: </strong>Cyril Vallez, Alexander Sternfeld, Andrei Kucharavy, Ljiljana Dolamic</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04538">https://arxiv.org/abs/2511.04538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04538">https://arxiv.org/pdf/2511.04538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04538]] From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting(https://arxiv.org/abs/2511.04538)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>As the role of Large Language Models (LLM)-based coding assistants in software development becomes more critical, so does the role of the bugs they generate in the overall cybersecurity landscape. While a number of LLM code security benchmarks have been proposed alongside approaches to improve the security of generated code, it remains unclear to what extent they have impacted widely used coding LLMs. Here, we show that even the latest open-weight models are vulnerable in the earliest reported vulnerability scenarios in a realistic use setting, suggesting that the safety-functionality trade-off has until now prevented effective patching of vulnerabilities. To help address this issue, we introduce a new severity metric that reflects the risk posed by an LLM-generated vulnerability, accounting for vulnerability severity, generation chance, and the formulation of the prompt that induces vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation of the most serious and prevalent vulnerabilities, we use PE to define the Model Exposure (ME) score, which indicates the severity and prevalence of vulnerabilities a model generates.</li>
</ul>

<h3>Title: Confidential Computing for Cloud Security: Exploring Hardware based Encryption Using Trusted Execution Environments</h3>
<ul>
<li><strong>Authors: </strong>Dhruv Deepak Agarwal, Aswani Kumar Cherukuri</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04550">https://arxiv.org/abs/2511.04550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04550">https://arxiv.org/pdf/2511.04550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04550]] Confidential Computing for Cloud Security: Exploring Hardware based Encryption Using Trusted Execution Environments(https://arxiv.org/abs/2511.04550)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect</a></li>
<li><strong>Abstract: </strong>The growth of cloud computing has revolutionized data processing and storage capacities to another levels of scalability and flexibility. But in the process, it has created a huge challenge of security, especially in terms of safeguarding sensitive data. Classical security practices, including encryption at rest and during transit, fail to protect data in use and expose it to various possible breaches. In response to this problem , Confidential Computing has been a tool ,seeking to secure data in processing by usage of hardware-based Trusted Execution Environments (TEEs). TEEs, including Intel's Software Guard Extensions (SGX) and ARM's TrustZone, offers protected contexts within the processor, where data is kept confidential ,intact and secure , even with malicious software or compromised operating systems. In this research, we have explored the architecture and security features of TEEs like Intel SGX and ARM TrustZone, and their effectiveness in improving cloud data security. From a thorough literature survey ,we have analyzed the deployment strategies, performance indicators, and practical uses of these TEEs for the same purpose. In addition, we have discussed the issues regarding deployment, possible weaknesses, scalability issues, and integration issues. Our results focuses on the central position of TEEs in strengthening and advancing cloud security infrastructures, pointing towards their ability to create a secure foundation for Confidential Computing.</li>
</ul>

<h3>Title: Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Divyansha Lachi, Mahmoud Mohammadi, Joe Meyer, Vinam Arora, Tom Palczewski, Eva L. Dyer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04557">https://arxiv.org/abs/2511.04557</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04557">https://arxiv.org/pdf/2511.04557</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04557]] Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning(https://arxiv.org/abs/2511.04557)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In domains such as healthcare, finance, and e-commerce, the temporal dynamics of relational data emerge from complex interactions-such as those between patients and providers, or users and products across diverse categories. To be broadly useful, models operating on these data must integrate long-range spatial and temporal dependencies across diverse types of entities, while also supporting multiple predictive tasks. However, existing graph models for relational data primarily focus on spatial structure, treating temporal information merely as a filtering constraint to exclude future events rather than a modeling signal, and are typically designed for single-task prediction. To address these gaps, we introduce a temporal subgraph sampler that enhances global context by retrieving nodes beyond the immediate neighborhood to capture temporally relevant relationships. In addition, we propose the Relational Graph Perceiver (RGP), a graph transformer architecture for relational deep learning that leverages a cross-attention-based latent bottleneck to efficiently integrate information from both structural and temporal contexts. This latent bottleneck integrates signals from different node and edge types into a common latent space, enabling the model to build global context across the entire relational system. RGP also incorporates a flexible cross-attention decoder that supports joint learning across tasks with disjoint label spaces within a single model. Experiments on RelBench, SALT, and CTU show that RGP delivers state-of-the-art performance, offering a general and scalable solution for relational deep learning with support for diverse predictive tasks.</li>
</ul>

<h3>Title: BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented Generation Strategies for Bangla Biomedical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Sadia Sultana, Saiyma Sittul Muna, Mosammat Zannatul Samarukh, Ajwad Abrar, Tareque Mohmud Chowdhury</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04560">https://arxiv.org/abs/2511.04560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04560">https://arxiv.org/pdf/2511.04560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04560]] BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented Generation Strategies for Bangla Biomedical Question Answering(https://arxiv.org/abs/2511.04560)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Developing accurate biomedical Question Answering (QA) systems in low-resource languages remains a major challenge, limiting equitable access to reliable medical knowledge. This paper introduces BanglaMedQA and BanglaMMedBench, the first large-scale Bangla biomedical Multiple Choice Question (MCQ) datasets designed to evaluate reasoning and retrieval in medical artificial intelligence (AI). The study applies and benchmarks several Retrieval-Augmented Generation (RAG) strategies, including Traditional, Zero-Shot Fallback, Agentic, Iterative Feedback, and Aggregate RAG, combining textbook-based and web retrieval with generative reasoning to improve factual accuracy. A key novelty lies in integrating a Bangla medical textbook corpus through Optical Character Recognition (OCR) and implementing an Agentic RAG pipeline that dynamically selects between retrieval and reasoning strategies. Experimental results show that the Agentic RAG achieved the highest accuracy 89.54% with openai/gpt-oss-120b, outperforming other configurations and demonstrating superior rationale quality. These findings highlight the potential of RAG-based methods to enhance the reliability and accessibility of Bangla medical QA, establishing a foundation for future research in multilingual medical artificial intelligence.</li>
</ul>

<h3>Title: Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm</h3>
<ul>
<li><strong>Authors: </strong>Jingqi Tong, Yurong Mou, Hangcheng Li, Mingzhe Li, Yongzhuo Yang, Ming Zhang, Qiguang Chen, Tianyi Liang, Xiaomeng Hu, Yining Zheng, Xinchi Chen, Jun Zhao, Xuanjing Huang, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04570">https://arxiv.org/abs/2511.04570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04570">https://arxiv.org/pdf/2511.04570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04570]] Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm(https://arxiv.org/abs/2511.04570)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>"Thinking with Text" and "Thinking with Images" paradigm significantly improve the reasoning ability of large language models (LLMs) and Vision Language Models (VLMs). However, these paradigms have inherent limitations. (1) Images capture only single moments and fail to represent dynamic processes or continuous changes, and (2) The separation of text and vision as distinct modalities, hindering unified multimodal understanding and generation. To overcome these limitations, we introduce "Thinking with Video", a new paradigm that leverages video generation models, such as Sora-2, to bridge visual and textual reasoning in a unified temporal framework. To support this exploration, we developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench encompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing Puzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our evaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks, Sora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even surpasses VLMs on several tasks, such as Eyeballing Games. On text-centric tasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU. Furthermore, we systematically analyse the source of these abilities. We also find that self-consistency and in-context learning can improve Sora-2's performance. In summary, our findings demonstrate that the video generation model is the potential unified multimodal understanding and generation model, positions "thinking with video" as a unified multimodal reasoning paradigm.</li>
</ul>

<h3>Title: ARETE: an R package for Automated REtrieval from TExt with large language models</h3>
<ul>
<li><strong>Authors: </strong>Vasco V. Branco, Jandó Benedek, Lidia Pivovarova, Luís Correia, Pedro Cardoso</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04573">https://arxiv.org/abs/2511.04573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04573">https://arxiv.org/pdf/2511.04573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04573]] ARETE: an R package for Automated REtrieval from TExt with large language models(https://arxiv.org/abs/2511.04573)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>1. A hard stop for the implementation of rigorous conservation initiatives is our lack of key species data, especially occurrence data. Furthermore, researchers have to contend with an accelerated speed at which new information must be collected and processed due to anthropogenic activity. Publications ranging from scientific papers to gray literature contain this crucial information but their data are often not machine-readable, requiring extensive human work to be retrieved. 2. We present the ARETE R package, an open-source software aiming to automate data extraction of species occurrences powered by large language models, namely using the chatGPT Application Programming Interface. This R package integrates all steps of the data extraction and validation process, from Optical Character Recognition to detection of outliers and output in tabular format. Furthermore, we validate ARETE through systematic comparison between what is modelled and the work of human annotators. 3. We demonstrate the usefulness of the approach by comparing range maps produced using GBIF data and with those automatically extracted for 100 species of spiders. Newly extracted data allowed to expand the known Extent of Occurrence by a mean three orders of magnitude, revealing new areas where the species were found in the past, which mayhave important implications for spatial conservation planning and extinction risk assessments. 4. ARETE allows faster access to hitherto untapped occurrence data, a potential game changer in projects requiring such data. Researchers will be able to better prioritize resources, manually verifying selected species while maintaining automated extraction for the majority. This workflow also allows predicting available bibliographic data during project planning.</li>
</ul>

<h3>Title: UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Chen Shi, Shaoshuai Shi, Xiaoyang Lyu, Chunyang Liu, Kehua Sheng, Bo Zhang, Li Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04595">https://arxiv.org/abs/2511.04595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04595">https://arxiv.org/pdf/2511.04595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04595]] UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction(https://arxiv.org/abs/2511.04595)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Feed-forward 3D reconstruction for autonomous driving has advanced rapidly, yet existing methods struggle with the joint challenges of sparse, non-overlapping camera views and complex scene dynamics. We present UniSplat, a general feed-forward framework that learns robust dynamic scene reconstruction through unified latent spatio-temporal fusion. UniSplat constructs a 3D latent scaffold, a structured representation that captures geometric and semantic scene context by leveraging pretrained foundation models. To effectively integrate information across spatial views and temporal frames, we introduce an efficient fusion mechanism that operates directly within the 3D scaffold, enabling consistent spatio-temporal alignment. To ensure complete and detailed reconstructions, we design a dual-branch decoder that generates dynamic-aware Gaussians from the fused scaffold by combining point-anchored refinement with voxel-based generation, and maintain a persistent memory of static Gaussians to enable streaming scene completion beyond current camera coverage. Extensive experiments on real-world datasets demonstrate that UniSplat achieves state-of-the-art performance in novel view synthesis, while providing robust and high-quality renderings even for viewpoints outside the original camera coverage.</li>
</ul>

<h3>Title: PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning</h3>
<ul>
<li><strong>Authors: </strong>Yicheng Xiao, Yu Chen, Haoxuan Ma, Jiale Hong, Caorui Li, Lingxiang Wu, Haiyun Guo, Jinqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04601">https://arxiv.org/abs/2511.04601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04601">https://arxiv.org/pdf/2511.04601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04601]] PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning(https://arxiv.org/abs/2511.04601)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While the Contrastive Language-Image Pretraining(CLIP) model has achieved remarkable success in a variety of downstream vison language understanding tasks, enhancing its capability for fine-grained image-text alignment remains an active research focus. To this end, most existing works adopt the strategy of explicitly increasing the granularity of visual information processing, e.g., incorporating visual prompts to guide the model focus on specific local regions within the image. Meanwhile, researches on Multimodal Large Language Models(MLLMs) have demonstrated that training with long and detailed textual descriptions can effectively improve the model's fine-grained vision-language alignment. However, the inherent token length limitation of CLIP's text encoder fundamentally limits CLIP to process more granular textual information embedded in long text sequences. To synergistically leverage the advantages of enhancing both visual and textual content processing granularity, we propose PixCLIP, a novel framework designed to concurrently accommodate visual prompt inputs and process lengthy textual descriptions. Specifically, we first establish an automated annotation pipeline capable of generating pixel-level localized, long-form textual descriptions for images. Utilizing this pipeline, we construct LongGRIT, a high-quality dataset comprising nearly 1.5 million samples. Secondly, we replace CLIP's original text encoder with the LLM and propose a three-branch pixel-text alignment learning framework, facilitating fine-grained alignment between image regions and corresponding textual descriptions at arbitrary granularity. Experiments demonstrate that PixCLIP showcases breakthroughs in pixel-level interaction and handling long-form texts, achieving state-of-the-art performance.</li>
</ul>

<h3>Title: Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality</h3>
<ul>
<li><strong>Authors: </strong>Tushar Kataria, Shikha Dubey, Mary Bronner, Jolanta Jedrzkiewicz, Ben J. Brintz, Shireen Y. Elhabian, Beatrice S. Knudsen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04615">https://arxiv.org/abs/2511.04615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04615">https://arxiv.org/pdf/2511.04615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04615]] Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality(https://arxiv.org/abs/2511.04615)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Deep learning models can generate virtual immunohistochemistry (IHC) stains from hematoxylin and eosin (H&E) images, offering a scalable and low-cost alternative to laboratory IHC. However, reliable evaluation of image quality remains a challenge as current texture- and distribution-based metrics quantify image fidelity rather than the accuracy of IHC staining. Here, we introduce an automated and accuracy grounded framework to determine image quality across sixteen paired or unpaired image translation models. Using color deconvolution, we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by each virtual IHC model. We use the segmented masks of real and virtual IHC to compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly quantify correct pixel - level labeling without needing expert manual annotations. Our results demonstrate that conventional image fidelity metrics, including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR), and structural similarity (SSIM), correlate poorly with stain accuracy and pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based models are less reliable in providing accurate IHC positive pixel labels. Moreover, whole-slide images (WSI) reveal performance declines that are invisible in patch-based evaluations, emphasizing the need for WSI-level benchmarks. Together, this framework defines a reproducible approach for assessing the quality of virtual IHC models, a critical step to accelerate translation towards routine use by pathologists.</li>
</ul>

<h3>Title: Addressing divergent representations from causal interventions on neural networks</h3>
<ul>
<li><strong>Authors: </strong>Satchel Grant, Simon Jerome Han, Alexa Tartaglini, Christopher Potts</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04638">https://arxiv.org/abs/2511.04638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04638">https://arxiv.org/pdf/2511.04638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04638]] Addressing divergent representations from causal interventions on neural networks(https://arxiv.org/abs/2511.04638)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>A common approach to mechanistic interpretability is to causally manipulate model representations via targeted interventions in order to understand what those representations encode. Here we ask whether such interventions create out-of-distribution (divergent) representations, and whether this raises concerns about how faithful their resulting explanations are to the target model in its natural state. First, we demonstrate empirically that common causal intervention techniques often do shift internal representations away from the natural distribution of the target model. Then, we provide a theoretical analysis of two classes of such divergences: `harmless' divergences that occur in the null-space of the weights and from covariance within behavioral decision boundaries, and `pernicious' divergences that activate hidden network pathways and cause dormant behavioral changes. Finally, in an effort to mitigate the pernicious cases, we modify the Counterfactual Latent (CL) loss from Grant (2025) that regularizes interventions to remain closer to the natural distributions, reducing the likelihood of harmful divergences while preserving the interpretive power of interventions. Together, these results highlight a path towards more reliable interpretability methods.</li>
</ul>

<h3>Title: Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems</h3>
<ul>
<li><strong>Authors: </strong>Hans Harder, Abhijeet Vishwasrao, Luca Guastoni, Ricardo Vinuesa, Sebastian Peitz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04641">https://arxiv.org/abs/2511.04641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04641">https://arxiv.org/pdf/2511.04641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04641]] Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems(https://arxiv.org/abs/2511.04641)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper is concerned with probabilistic techniques for forecasting dynamical systems described by partial differential equations (such as, for example, the Navier-Stokes equations). In particular, it is investigating and comparing various extensions to the flow matching paradigm that reduce the number of sampling steps. In this regard, it compares direct distillation, progressive distillation, adversarial diffusion distillation, Wasserstein GANs and rectified flows. Moreover, experiments are conducted on a set of challenging systems. In particular, we also address the challenge of directly predicting 2D slices of large-scale 3D simulations, paving the way for efficient inflow generation for solvers.</li>
</ul>

<h3>Title: When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection</h3>
<ul>
<li><strong>Authors: </strong>Alamgir Munir Qazi, John P. McCrae, Jamal Abdul Nasir</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04643">https://arxiv.org/abs/2511.04643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04643">https://arxiv.org/pdf/2511.04643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04643]] When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection(https://arxiv.org/abs/2511.04643)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust, large language model</a></li>
<li><strong>Abstract: </strong>The proliferation of misinformation necessitates robust yet computationally efficient fact verification systems. While current state-of-the-art approaches leverage Large Language Models (LLMs) for generating explanatory rationales, these methods face significant computational barriers and hallucination risks in real-world deployments. We present DeReC (Dense Retrieval Classification), a lightweight framework that demonstrates how general-purpose text embeddings can effectively replace autoregressive LLM-based approaches in fact verification tasks. By combining dense retrieval with specialized classification, our system achieves better accuracy while being significantly more efficient. DeReC outperforms explanation-generating LLMs in efficiency, reducing runtime by 95% on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92% on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds), showcasing its effectiveness across varying dataset sizes. On the RAWFC dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art method L-Defense (61.20%). Our results demonstrate that carefully engineered retrieval-based systems can match or exceed LLM performance in specialized tasks while being significantly more practical for real-world deployment.</li>
</ul>

<h3>Title: Optimal Inference Schedules for Masked Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Sitan Chen, Kevin Cong, Jerry Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04647">https://arxiv.org/abs/2511.04647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04647">https://arxiv.org/pdf/2511.04647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04647]] Optimal Inference Schedules for Masked Diffusion Models(https://arxiv.org/abs/2511.04647)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>A major bottleneck of standard auto-regressive large language models is that their inference process is inherently sequential, resulting in very long and costly inference times. To circumvent this, practitioners proposed a class of language models called diffusion language models, of which the masked diffusion model (MDM) is the most successful. The MDM is able to sample tokens out-of-order and, ostensibly, many tokens at once and in parallel. However, there is very limited rigorous understanding of how much parallel sampling these models can perform without noticeable degradation in their sampling performance. Prior work of Li and Cai obtained some preliminary bounds, but these are not tight for many natural classes of distributions. In this work, we give a new, exact characterization of the expected divergence between the true distribution and the sampled distribution, for any distribution and any unmasking schedule for the sampler, showing an elegant connection to the theory of univariate function approximation. By leveraging this connection, we then attain a number of novel lower and upper bounds for this problem. While the connection to function approximation in principle gives the optimal unmasking schedule for any distribution, we show that it is in general impossible to compete with it without strong a priori knowledge of the distribution, even in seemingly benign settings. However, we also demonstrate new upper bounds and new sampling schedules in terms of well-studied information-theoretic properties of the base distribution, namely, its total correlation and dual total correlation, which show that in some natural settings, one can sample in $O(log n)$ steps without any visible loss in performance, where $n$ is the total sequence length.</li>
</ul>

<h3>Title: Polarization-resolved imaging improves eye tracking</h3>
<ul>
<li><strong>Authors: </strong>Mantas Žurauskas, Tom Bu, Sanaz Alali, Beyza Kalkanli, Derek Shi, Fernando Alamos, Gauresh Pandit, Christopher Mei, Ali Behrooz, Ramin Mirjalili, Dave Stronks, Alexander Fix, Dmitri Model</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.optics</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04652">https://arxiv.org/abs/2511.04652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04652">https://arxiv.org/pdf/2511.04652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04652]] Polarization-resolved imaging improves eye tracking(https://arxiv.org/abs/2511.04652)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Polarization-resolved near-infrared imaging adds a useful optical contrast mechanism to eye tracking by measuring the polarization state of light reflected by ocular tissues in addition to its intensity. In this paper we demonstrate how this contrast can be used to enable eye tracking. Specifically, we demonstrate that a polarization-enabled eye tracking (PET) system composed of a polarization--filter--array camera paired with a linearly polarized near-infrared illuminator can reveal trackable features across the sclera and gaze-informative patterns on the cornea, largely absent in intensity-only images. Across a cohort of 346 participants, convolutional neural network based machine learning models trained on data from PET reduced the median 95th-percentile absolute gaze error by 10--16\% relative to capacity-matched intensity baselines under nominal conditions and in the presence of eyelid occlusions, eye-relief changes, and pupil-size variation. These results link light--tissue polarization effects to practical gains in human--computer interaction and position PET as a simple, robust sensing modality for future wearable devices.</li>
</ul>

<h3>Title: TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Xinlu Zhang, Yansha Deng, Toktam Mahmoodi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04653">https://arxiv.org/abs/2511.04653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04653">https://arxiv.org/pdf/2511.04653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04653]] TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning(https://arxiv.org/abs/2511.04653)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) offers new opportunities in machine learning, particularly in addressing data privacy concerns. In contrast to conventional event-based federated learning, time-triggered federated learning (TT-Fed), as a general form of both asynchronous and synchronous FL, clusters users into different tiers based on fixed time intervals. However, the FL network consists of a growing number of user devices with limited wireless bandwidth, consequently magnifying issues such as stragglers and communication overhead. In this paper, we introduce adaptive model pruning to wireless TT-Fed systems and study the problem of jointly optimizing the pruning ratio and bandwidth allocation to minimize the training loss while ensuring minimal learning latency. To answer this question, we perform convergence analysis on the gradient l_2 norm of the TT-Fed model based on model pruning. Based on the obtained convergence upper bound, a joint optimization problem of pruning ratio and wireless bandwidth is formulated to minimize the model training loss under a given delay threshold. Then, we derive closed-form solutions for wireless bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The simulation results show that model pruning could reduce the communication cost by 40% while maintaining the model performance at the same level.</li>
</ul>

<h3>Title: Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Atif Quamar, Mohammad Areeb</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04654">https://arxiv.org/abs/2511.04654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04654">https://arxiv.org/pdf/2511.04654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04654]] Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning(https://arxiv.org/abs/2511.04654)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-Thought (CoT) prompting is a key technique for enabling complex reasoning in large language models. However, generating full, fixed-length rationales is computationally wasteful, inflating both token usage and latency. We introduce LEASH: Logit-Entropy Adaptive Stopping Heuristic, a training-free decoding algorithm that adaptively halts rationale generation. LEASH monitors two intrinsic signals: the slope of token-level entropy and the improvement in the top-logit margin. It terminates the generation once both signals plateau, indicating the model has reached a stable reasoning state. Across four instruction-tuned models on the GSM8K and AQuA-RAT benchmarks, LEASH reduces average token generation by 30--35% and latency by 27%, while incurring a 10 p.p. accuracy drop relative to CoT. LEASH is model-agnostic and requires no additional training or supervision, offering a simple and efficient alternative to CoT decoding.</li>
</ul>

<h3>Title: Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts</h3>
<ul>
<li><strong>Authors: </strong>Ellis Brown, Jihan Yang, Shusheng Yang, Rob Fergus, Saining Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04655">https://arxiv.org/abs/2511.04655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04655">https://arxiv.org/pdf/2511.04655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04655]] Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts(https://arxiv.org/abs/2511.04655)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Robust benchmarks are crucial for evaluating Multimodal Large Language Models (MLLMs). Yet we find that models can ace many multimodal benchmarks without strong visual understanding, instead exploiting biases, linguistic priors, and superficial patterns. This is especially problematic for vision-centric benchmarks that are meant to require visual inputs. We adopt a diagnostic principle for benchmark design: if a benchmark can be gamed, it will be. Designers should therefore try to ``game'' their own benchmarks first, using diagnostic and debiasing procedures to systematically identify and mitigate non-visual biases. Effective diagnosis requires directly ``training on the test set'' -- probing the released test set for its intrinsic, exploitable patterns. We operationalize this standard with two components. First, we diagnose benchmark susceptibility using a ``Test-set Stress-Test'' (TsT) methodology. Our primary diagnostic tool involves fine-tuning a powerful Large Language Model via $k$-fold cross-validation on exclusively the non-visual, textual inputs of the test set to reveal shortcut performance and assign each sample a bias score $s(x)$. We complement this with a lightweight Random Forest-based diagnostic operating on hand-crafted features for fast, interpretable auditing. Second, we debias benchmarks by filtering high-bias samples using an ``Iterative Bias Pruning'' (IBP) procedure. Applying this framework to four benchmarks -- VSI-Bench, CV-Bench, MMMU, and VideoMME -- we uncover pervasive non-visual biases. As a case study, we apply our full framework to create VSI-Bench-Debiased, demonstrating reduced non-visual solvability and a wider vision-blind performance gap than the original.</li>
</ul>

<h3>Title: Nowcast3D: Reliable precipitation nowcasting via gray-box learning</h3>
<ul>
<li><strong>Authors: </strong>Huaguan Chen, Wei Han, Haofei Sun, Ning Lin, Xingtao Song, Yunfan Yang, Jie Tian, Yang Liu, Ji-Rong Wen, Xiaoye Zhang, Xueshun Shen, Hao Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04659">https://arxiv.org/abs/2511.04659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04659">https://arxiv.org/pdf/2511.04659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04659]] Nowcast3D: Reliable precipitation nowcasting via gray-box learning(https://arxiv.org/abs/2511.04659)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Extreme precipitation nowcasting demands high spatiotemporal fidelity and extended lead times, yet existing approaches remain limited. Numerical Weather Prediction (NWP) and its deep-learning emulations are too slow and coarse for rapidly evolving convection, while extrapolation and purely data-driven models suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based methods discard crucial vertical information, preventing accurate reconstruction of height-dependent dynamics. We introduce a gray-box, fully three-dimensional nowcasting framework that directly processes volumetric radar reflectivity and couples physically constrained neural operators with datadriven learning. The model learns vertically varying 3D advection fields under a conservative advection operator, parameterizes spatially varying diffusion, and introduces a Brownian-motion--inspired stochastic term to represent unresolved motions. A residual branch captures small-scale convective initiation and microphysical variability, while a diffusion-based stochastic module estimates uncertainty. The framework achieves more accurate forecasts up to three-hour lead time across precipitation regimes and ranked first in 57\% of cases in a blind evaluation by 160 meteorologists. By restoring full 3D dynamics with physical consistency, it offers a scalable and robust pathway for skillful and reliable nowcasting of extreme precipitation.</li>
</ul>

<h3>Title: Forgetting is Everywhere</h3>
<ul>
<li><strong>Authors: </strong>Ben Sanati, Thomas L. Lee, Trevor McInroe, Aidan Scannell, Nikolay Malkin, David Abel, Amos Storkey</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04666">https://arxiv.org/abs/2511.04666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04666">https://arxiv.org/pdf/2511.04666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04666]] Forgetting is Everywhere(https://arxiv.org/abs/2511.04666)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>A fundamental challenge in developing general learning algorithms is their tendency to forget past knowledge when adapting to new data. Addressing this problem requires a principled understanding of forgetting; yet, despite decades of study, no unified definition has emerged that provides insights into the underlying dynamics of learning. We propose an algorithm- and task-agnostic theory that characterises forgetting as a lack of self-consistency in a learner's predictive distribution over future experiences, manifesting as a loss of predictive information. Our theory naturally yields a general measure of an algorithm's propensity to forget. To validate the theory, we design a comprehensive set of experiments that span classification, regression, generative modelling, and reinforcement learning. We empirically demonstrate how forgetting is present across all learning settings and plays a significant role in determining learning efficiency. Together, these results establish a principled understanding of forgetting and lay the foundation for analysing and improving the information retention capabilities of general learning algorithms.</li>
</ul>

<h3>Title: Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches</h3>
<ul>
<li><strong>Authors: </strong>Julian D. Allagan, Dasia A. Singleton, Shanae N. Perry, Gabrielle C. Morgan, Essence A. Morgan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04667">https://arxiv.org/abs/2511.04667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04667">https://arxiv.org/pdf/2511.04667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04667]] Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches(https://arxiv.org/abs/2511.04667)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study evaluates a 40-item mathematics placement examination administered to 198 students using a multi-method framework combining Classical Test Theory, machine learning, and unsupervised clustering. Classical Test Theory analysis reveals that 55\% of items achieve excellent discrimination ($D \geq 0.40$) while 30\% demonstrate poor discrimination ($D < 0.20$) requiring replacement. Question 6 (Graph Interpretation) emerges as the examination's most powerful discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA F-statistic ($F = 4609.1$), and maximum Random Forest feature importance (0.206), accounting for 20.6\% of predictive power. Machine learning algorithms demonstrate exceptional performance, with Random Forest and Gradient Boosting achieving 97.5\% and 96.0\% cross-validation accuracy. K-means clustering identifies a natural binary competency structure with a boundary at 42.5\%, diverging from the institutional threshold of 55\% and suggesting potential overclassification into remedial categories. The two-cluster solution exhibits exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster purity. Convergent evidence across methods supports specific refinements: replace poorly discriminating items, implement a two-stage assessment, and integrate Random Forest predictions with transparency mechanisms. These findings demonstrate that multi-method integration provides a robust empirical foundation for evidence-based mathematics placement optimization.</li>
</ul>

<h3>Title: SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Ellis Brown, Arijit Ray, Ranjay Krishna, Ross Girshick, Rob Fergus, Saining Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04668">https://arxiv.org/abs/2511.04668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04668">https://arxiv.org/pdf/2511.04668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04668]] SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding(https://arxiv.org/abs/2511.04668)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite impressive high-level video comprehension, multimodal language models struggle with spatial reasoning across time and space. While current spatial training approaches rely on real-world video data, obtaining diverse footage with precise spatial annotations remains a bottleneck. To alleviate this bottleneck, we present SIMS-V -- a systematic data-generation framework that leverages the privileged information of 3D simulators to create spatially-rich video training data for multimodal language models. Using this framework, we investigate which properties of simulated data drive effective real-world transfer through systematic ablations of question types, mixes, and scales. We identify a minimal set of three question categories (metric measurement, perspective-dependent reasoning, and temporal tracking) that prove most effective for developing transferable spatial intelligence, outperforming comprehensive coverage despite using fewer question types. These insights enable highly efficient training: our 7B-parameter video LLM fine-tuned on just 25K simulated examples outperforms the larger 72B baseline and achieves competitive performance with proprietary models on rigorous real-world spatial reasoning benchmarks. Our approach demonstrates robust generalization, maintaining performance on general video understanding while showing substantial improvements on embodied and real-world spatial tasks.</li>
</ul>

<h3>Title: Cambrian-S: Towards Spatial Supersensing in Video</h3>
<ul>
<li><strong>Authors: </strong>Shusheng Yang, Jihan Yang, Pinzhi Huang, Ellis Brown, Zihao Yang, Yue Yu, Shengbang Tong, Zihan Zheng, Yifan Xu, Muhan Wang, Daohan Lu, Rob Fergus, Yann LeCun, Li Fei-Fei, Saining Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04670">https://arxiv.org/abs/2511.04670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04670">https://arxiv.org/pdf/2511.04670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04670]] Cambrian-S: Towards Spatial Supersensing in Video(https://arxiv.org/abs/2511.04670)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We argue that progress in true multimodal intelligence calls for a shift from reactive, task-driven systems and brute-force long context towards a broader paradigm of supersensing. We frame spatial supersensing as four stages beyond linguistic-only understanding: semantic perception (naming what is seen), streaming event cognition (maintaining memory across continuous experiences), implicit 3D spatial cognition (inferring the world behind pixels), and predictive world modeling (creating internal models that filter and organize information). Current benchmarks largely test only the early stages, offering narrow coverage of spatial cognition and rarely challenging models in ways that require true world modeling. To drive progress in spatial supersensing, we present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial recall) and VSC (continual visual spatial counting). These tasks require arbitrarily long video inputs yet are resistant to brute-force context expansion. We then test data scaling limits by curating VSI-590K and training Cambrian-S, achieving +30% absolute improvement on VSI-Bench without sacrificing general capabilities. Yet performance on VSI-SUPER remains limited, indicating that scale alone is insufficient for spatial supersensing. We propose predictive sensing as a path forward, presenting a proof-of-concept in which a self-supervised next-latent-frame predictor leverages surprise (prediction error) to drive memory and event segmentation. On VSI-SUPER, this approach substantially outperforms leading proprietary baselines, showing that spatial supersensing requires models that not only see but also anticipate, select, and organize experience.</li>
</ul>

<h3>Title: InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation</h3>
<ul>
<li><strong>Authors: </strong>Jinlai Liu, Jian Han, Bin Yan, Hui Wu, Fengda Zhu, Xing Wang, Yi Jiang, Bingyue Peng, Zehuan Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.04675">https://arxiv.org/abs/2511.04675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.04675">https://arxiv.org/pdf/2511.04675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.04675]] InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation(https://arxiv.org/abs/2511.04675)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce InfinityStar, a unified spacetime autoregressive framework for high-resolution image and dynamic video synthesis. Building on the recent success of autoregressive modeling in both vision and language, our purely discrete approach jointly captures spatial and temporal dependencies within a single architecture. This unified design naturally supports a variety of generation tasks such as text-to-image, text-to-video, image-to-video, and long interactive video synthesis via straightforward temporal autoregression. Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench, outperforming all autoregressive models by large margins, even surpassing some diffusion competitors like HunyuanVideo. Without extra optimizations, our model generates a 5s, 720p video approximately 10x faster than leading diffusion-based methods. To our knowledge, InfinityStar is the first discrete autoregressive video generator capable of producing industrial level 720p videos. We release all code and models to foster further research in efficient, high-quality video generation.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
