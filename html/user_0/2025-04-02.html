<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-04-02</h1>
<h3>Title: LayerCraft: Enhancing Text-to-Image Generation with CoT Reasoning and Layered Object Integration</h3>
<ul>
<li><strong>Authors: </strong>Yuyao Zhang, Jinghao Li, Yu-Wing Tai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GR, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00010">https://arxiv.org/abs/2504.00010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00010">https://arxiv.org/pdf/2504.00010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00010]] LayerCraft: Enhancing Text-to-Image Generation with CoT Reasoning and Layered Object Integration(https://arxiv.org/abs/2504.00010)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Text-to-image generation (T2I) has become a key area of research with broad applications. However, existing methods often struggle with complex spatial relationships and fine-grained control over multiple concepts. Many existing approaches require significant architectural modifications, extensive training, or expert-level prompt engineering. To address these challenges, we introduce \textbf{LayerCraft}, an automated framework that leverages large language models (LLMs) as autonomous agents for structured procedural generation. LayerCraft enables users to customize objects within an image and supports narrative-driven creation with minimal effort. At its core, the system includes a coordinator agent that directs the process, along with two specialized agents: \textbf{ChainArchitect}, which employs chain-of-thought (CoT) reasoning to generate a dependency-aware 3D layout for precise instance-level control, and the \textbf{Object-Integration Network (OIN)}, which utilizes LoRA fine-tuning on pre-trained T2I models to seamlessly blend objects into specified regions of an image based on textual prompts without requiring architectural changes. Extensive evaluations demonstrate LayerCraft's versatility in applications ranging from multi-concept customization to storytelling. By providing non-experts with intuitive, precise control over T2I generation, our framework democratizes creative image creation. Our code will be released upon acceptance at this http URL</li>
</ul>

<h3>Title: I'm Sorry Dave: How the old world of personnel security can inform the new world of AI insider risk</h3>
<ul>
<li><strong>Authors: </strong>Paul Martin, Sarah Mercer</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00012">https://arxiv.org/abs/2504.00012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00012">https://arxiv.org/pdf/2504.00012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00012]] I'm Sorry Dave: How the old world of personnel security can inform the new world of AI insider risk(https://arxiv.org/abs/2504.00012)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Organisations are rapidly adopting artificial intelligence (AI) tools to perform tasks previously undertaken by people. The potential benefits are enormous. Separately, some organisations deploy personnel security measures to mitigate the security risks arising from trusted human insiders. Unfortunately, there is no meaningful interplay between the rapidly evolving domain of AI and the traditional world of personnel security. This is a problem. The complex risks from human insiders are hard enough to understand and manage, despite many decades of effort. The emerging security risks from AI insiders are even more opaque. Both sides need all the help they can get. Some of the concepts and approaches that have proved useful in dealing with human insiders are also applicable to the emerging risks from AI insiders. Furthermore, AI can be used defensively to protect against both human and AI insiders.</li>
</ul>

<h3>Title: Medical Reasoning in LLMs: An In-Depth Analysis of DeepSeek R1</h3>
<ul>
<li><strong>Authors: </strong>Birger Moell, Fredrik Sand Aronsson, Sanian Akbar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00016">https://arxiv.org/abs/2504.00016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00016">https://arxiv.org/pdf/2504.00016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00016]] Medical Reasoning in LLMs: An In-Depth Analysis of DeepSeek R1(https://arxiv.org/abs/2504.00016)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Integrating large language models (LLMs) like DeepSeek R1 into healthcare requires rigorous evaluation of their reasoning alignment with clinical expertise. This study assesses DeepSeek R1's medical reasoning against expert patterns using 100 MedQA clinical cases. The model achieved 93% diagnostic accuracy, demonstrating systematic clinical judgment through differential diagnosis, guideline-based treatment selection, and integration of patient-specific factors. However, error analysis of seven incorrect cases revealed persistent limitations: anchoring bias, challenges reconciling conflicting data, insufficient exploration of alternatives, overthinking, knowledge gaps, and premature prioritization of definitive treatment over intermediate care. Crucially, reasoning length correlated with accuracy - shorter responses (<5,000 characters) were more reliable, suggesting extended explanations may signal uncertainty or rationalization of errors. While DeepSeek R1 exhibits foundational clinical reasoning capabilities, recurring flaws highlight critical areas for refinement, including bias mitigation, knowledge updates, and structured reasoning frameworks. These findings underscore LLMs' potential to augment medical decision-making through artificial reasoning but emphasize the need for domain-specific validation, interpretability safeguards, and confidence metrics (e.g., response length thresholds) to ensure reliability in real-world applications.</li>
</ul>

<h3>Title: SandboxEval: Towards Securing Test Environment for Untrusted Code</h3>
<ul>
<li><strong>Authors: </strong>Rafiqul Rabin, Jesse Hostetler, Sean McGregor, Brett Weir, Nick Judd</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00018">https://arxiv.org/abs/2504.00018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00018">https://arxiv.org/pdf/2504.00018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00018]] SandboxEval: Towards Securing Test Environment for Untrusted Code(https://arxiv.org/abs/2504.00018)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) are powerful assistants in programming tasks, they may also produce malicious code. Testing LLM-generated code therefore poses significant risks to assessment infrastructure tasked with executing untrusted code. To address these risks, this work focuses on evaluating the security and confidentiality properties of test environments, reducing the risk that LLM-generated code may compromise the assessment infrastructure. We introduce SandboxEval, a test suite featuring manually crafted test cases that simulate real-world safety scenarios for LLM assessment environments in the context of untrusted code execution. The suite evaluates vulnerabilities to sensitive information exposure, filesystem manipulation, external communication, and other potentially dangerous operations in the course of assessment activity. We demonstrate the utility of SandboxEval by deploying it on an open-source implementation of Dyff, an established AI assessment framework used to evaluate the safety of LLMs at scale. We show, first, that the test suite accurately describes limitations placed on an LLM operating under instructions to generate malicious code. Second, we show that the test results provide valuable insights for developers seeking to harden assessment infrastructure and identify risks associated with LLM execution activities.</li>
</ul>

<h3>Title: FUSE : A Ridge and Random Forest-Based Metric for Evaluating MT in Indigenous Languages</h3>
<ul>
<li><strong>Authors: </strong>Rahul Raja, Arpita Vats</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00021">https://arxiv.org/abs/2504.00021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00021">https://arxiv.org/pdf/2504.00021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00021]] FUSE : A Ridge and Random Forest-Based Metric for Evaluating MT in Indigenous Languages(https://arxiv.org/abs/2504.00021)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents the winning submission of the RaaVa team to the AmericasNLP 2025 Shared Task 3 on Automatic Evaluation Metrics for Machine Translation (MT) into Indigenous Languages of America, where our system ranked first overall based on average Pearson correlation with the human annotations. We introduce Feature-Union Scorer (FUSE) for Evaluation, FUSE integrates Ridge regression and Gradient Boosting to model translation quality. In addition to FUSE, we explore five alternative approaches leveraging different combinations of linguistic similarity features and learning paradigms. FUSE Score highlights the effectiveness of combining lexical, phonetic, semantic, and fuzzy token similarity with learning-based modeling to improve MT evaluation for morphologically rich and low-resource languages. MT into Indigenous languages poses unique challenges due to polysynthesis, complex morphology, and non-standardized orthography. Conventional automatic metrics such as BLEU, TER, and ChrF often fail to capture deeper aspects like semantic adequacy and fluency. Our proposed framework, formerly referred to as FUSE, incorporates multilingual sentence embeddings and phonological encodings to better align with human evaluation. We train supervised models on human-annotated development sets and evaluate held-out test data. Results show that FUSE consistently achieves higher Pearson and Spearman correlations with human judgments, offering a robust and linguistically informed solution for MT evaluation in low-resource settings.</li>
</ul>

<h3>Title: A Novel Distance-Based Metric for Quality Assessment in Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Niklas Rottmayer, Claudia Redenbach</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00023">https://arxiv.org/abs/2504.00023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00023">https://arxiv.org/pdf/2504.00023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00023]] A Novel Distance-Based Metric for Quality Assessment in Image Segmentation(https://arxiv.org/abs/2504.00023)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The assessment of segmentation quality plays a fundamental role in the development, optimization, and comparison of segmentation methods which are used in a wide range of applications. With few exceptions, quality assessment is performed using traditional metrics, which are based on counting the number of erroneous pixels but do not capture the spatial distribution of errors. Established distance-based metrics such as the average Hausdorff distance are difficult to interpret and compare for different methods and datasets. In this paper, we introduce the Surface Consistency Coefficient (SCC), a novel distance-based quality metric that quantifies the spatial distribution of errors based on their proximity to the surface of the structure. Through a rigorous analysis using synthetic data and real segmentation results, we demonstrate the robustness and effectiveness of SCC in distinguishing errors near the surface from those further away. At the same time, SCC is easy to interpret and comparable across different structural contexts.</li>
</ul>

<h3>Title: Generalization Bias in Large Language Model Summarization of Scientific Research</h3>
<ul>
<li><strong>Authors: </strong>Uwe Peters, Benjamin Chin-Yee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00025">https://arxiv.org/abs/2504.00025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00025">https://arxiv.org/pdf/2504.00025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00025]] Generalization Bias in Large Language Model Summarization of Scientific Research(https://arxiv.org/abs/2504.00025)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Artificial intelligence chatbots driven by large language models (LLMs) have the potential to increase public science literacy and support scientific research, as they can quickly summarize complex scientific information in accessible terms. However, when summarizing scientific texts, LLMs may omit details that limit the scope of research conclusions, leading to generalizations of results broader than warranted by the original study. We tested 10 prominent LLMs, including ChatGPT-4o, ChatGPT-4.5, DeepSeek, LLaMA 3.3 70B, and Claude 3.7 Sonnet, comparing 4900 LLM-generated summaries to their original scientific texts. Even when explicitly prompted for accuracy, most LLMs produced broader generalizations of scientific results than those in the original texts, with DeepSeek, ChatGPT-4o, and LLaMA 3.3 70B overgeneralizing in 26 to 73% of cases. In a direct comparison of LLM-generated and human-authored science summaries, LLM summaries were nearly five times more likely to contain broad generalizations (OR = 4.85, 95% CI [3.06, 7.70]). Notably, newer models tended to perform worse in generalization accuracy than earlier ones. Our results indicate a strong bias in many widely used LLMs towards overgeneralizing scientific conclusions, posing a significant risk of large-scale misinterpretations of research findings. We highlight potential mitigation strategies, including lowering LLM temperature settings and benchmarking LLMs for generalization accuracy.</li>
</ul>

<h3>Title: Opioid Named Entity Recognition (ONER-2025) from Reddit</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ahmad, Humaira Farid, Iqra Ameer, Muhammad Muzamil, Ameer Hamza Muhammad Jalal, Ildar Batyrshin, Grigori Sidorov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00027">https://arxiv.org/abs/2504.00027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00027">https://arxiv.org/pdf/2504.00027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00027]] Opioid Named Entity Recognition (ONER-2025) from Reddit(https://arxiv.org/abs/2504.00027)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The opioid overdose epidemic remains a critical public health crisis, particularly in the United States, leading to significant mortality and societal costs. Social media platforms like Reddit provide vast amounts of unstructured data that offer insights into public perceptions, discussions, and experiences related to opioid use. This study leverages Natural Language Processing (NLP), specifically Opioid Named Entity Recognition (ONER-2025), to extract actionable information from these platforms. Our research makes four key contributions. First, we created a unique, manually annotated dataset sourced from Reddit, where users share self-reported experiences of opioid use via different administration routes. This dataset contains 331,285 tokens and includes eight major opioid entity categories. Second, we detail our annotation process and guidelines while discussing the challenges of labeling the ONER-2025 dataset. Third, we analyze key linguistic challenges, including slang, ambiguity, fragmented sentences, and emotionally charged language, in opioid discussions. Fourth, we propose a real-time monitoring system to process streaming data from social media, healthcare records, and emergency services to identify overdose events. Using 5-fold cross-validation in 11 experiments, our system integrates machine learning, deep learning, and transformer-based language models with advanced contextual embeddings to enhance understanding. Our transformer-based models (bert-base-NER and roberta-base) achieved 97% accuracy and F1-score, outperforming baselines by 10.23% (RF=0.88).</li>
</ul>

<h3>Title: Token-Driven GammaTune: Adaptive Calibration for Enchanced Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Aayush Gautam, Susav Shrestha, Narasimha Annapareddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00030">https://arxiv.org/abs/2504.00030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00030">https://arxiv.org/pdf/2504.00030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00030]] Token-Driven GammaTune: Adaptive Calibration for Enchanced Speculative Decoding(https://arxiv.org/abs/2504.00030)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding accelerates large language model (LLM) inference by using a smaller draft model to propose tokens, which are then verified by a larger target model. However, selecting an optimal speculation length is critical for maximizing speedup while minimizing wasted computation. We introduce \textit{GammaTune} and \textit{GammaTune+}, training-free adaptive algorithms that dynamically adjust speculation length based on token acceptance rates using a heuristic-based switching mechanism. Evaluated on SpecBench across multiple tasks and model pairs, our method outperforms other heuristic-based approaches and fixed-length speculative decoding, achieving an average speedup of 15\% ($\pm$5\%) with \textit{GammaTune} and 16\% ($\pm$3\%) with \textit{GammaTune+}, while reducing performance variance. This makes \textit{GammaTune} a robust and efficient solution for real-world deployment.</li>
</ul>

<h3>Title: Leaking LoRa: An Evaluation of Password Leaks and Knowledge Storage in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ryan Marinelli, Magnus Eckhoff</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00031">https://arxiv.org/abs/2504.00031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00031">https://arxiv.org/pdf/2504.00031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00031]] Leaking LoRa: An Evaluation of Password Leaks and Knowledge Storage in Large Language Models(https://arxiv.org/abs/2504.00031)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To effectively deploy Large Language Models (LLMs) in application-specific settings, fine-tuning techniques are applied to enhance performance on specialized tasks. This process often involves fine-tuning on user data data, which may contain sensitive information. Although not recommended, it is not uncommon for users to send passwords in messages, and fine-tuning models on this could result in passwords being leaked. In this study, a Large Language Model is fine-tuned with customer support data and passwords from the RockYou password wordlist using Low-Rank Adaptation (LoRA). Out of the first 200 passwords from the list, 37 were successfully recovered. Further, causal tracing is used to identify that password information is largely located in a few layers. Lastly, Rank One Model Editing (ROME) is used to remove the password information from the model, resulting in the number of passwords recovered going from 37 to 0.</li>
</ul>

<h3>Title: MiZero: The Shadowy Defender Against Text Style Infringements</h3>
<ul>
<li><strong>Authors: </strong>Ziwei Zhang, Juan Wen, Wanli Peng, Zhengxian Wu, Yinghan Zhou, Yiming Xue</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00035">https://arxiv.org/abs/2504.00035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00035">https://arxiv.org/pdf/2504.00035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00035]] MiZero: The Shadowy Defender Against Text Style Infringements(https://arxiv.org/abs/2504.00035)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, watermark, large language model</a></li>
<li><strong>Abstract: </strong>In-Context Learning (ICL) and efficient fine-tuning methods significantly enhanced the efficiency of applying Large Language Models (LLMs) to downstream tasks. However, they also raise concerns about the imitation and infringement of personal creative data. Current methods for data copyright protection primarily focuses on content security but lacks effectiveness in protecting the copyrights of text styles. In this paper, we introduce a novel implicit zero-watermarking scheme, namely MiZero. This scheme establishes a precise watermark domain to protect the copyrighted style, surpassing traditional watermarking methods that distort the style characteristics. Specifically, we employ LLMs to extract condensed-lists utilizing the designed instance delimitation mechanism. These lists guide MiZero in generating the watermark. Extensive experiments demonstrate that MiZero effectively verifies text style copyright ownership against AI imitation.</li>
</ul>

<h3>Title: ViT-Linearizer: Distilling Quadratic Knowledge into Linear-Time Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Guoyizhe Wei, Rama Chellappa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00037">https://arxiv.org/abs/2504.00037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00037">https://arxiv.org/pdf/2504.00037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00037]] ViT-Linearizer: Distilling Quadratic Knowledge into Linear-Time Vision Models(https://arxiv.org/abs/2504.00037)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformers (ViTs) have delivered remarkable progress through global self-attention, yet their quadratic complexity can become prohibitive for high-resolution inputs. In this work, we present ViT-Linearizer, a cross-architecture distillation framework that transfers rich ViT representations into a linear-time, recurrent-style model. Our approach leverages 1) activation matching, an intermediate constraint that encourages student to align its token-wise dependencies with those produced by the teacher, and 2) masked prediction, a contextual reconstruction objective that requires the student to predict the teacher's representations for unseen (masked) tokens, to effectively distill the quadratic self-attention knowledge into the student while maintaining efficient complexity. Empirically, our method provides notable speedups particularly for high-resolution tasks, significantly addressing the hardware challenges in inference. Additionally, it also elevates Mamba-based architectures' performance on standard vision benchmarks, achieving a competitive 84.3% top-1 accuracy on ImageNet with a base-sized model. Our results underscore the good potential of RNN-based solutions for large-scale visual tasks, bridging the gap between theoretical efficiency and real-world practice.</li>
</ul>

<h3>Title: Revisiting the Relationship between Adversarial and Clean Training: Why Clean Training Can Make Adversarial Training Better</h3>
<ul>
<li><strong>Authors: </strong>MingWei Zhou, Xiaobing Pei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00038">https://arxiv.org/abs/2504.00038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00038">https://arxiv.org/pdf/2504.00038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00038]] Revisiting the Relationship between Adversarial and Clean Training: Why Clean Training Can Make Adversarial Training Better(https://arxiv.org/abs/2504.00038)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Adversarial training (AT) is an effective technique for enhancing adversarial robustness, but it usually comes at the cost of a decline in generalization ability. Recent studies have attempted to use clean training to assist adversarial training, yet there are contradictions among the conclusions. We comprehensively summarize the representative strategies and, with a focus on the multi - view hypothesis, provide a unified explanation for the contradictory phenomena among different studies. In addition, we conduct an in - depth analysis of the knowledge combinations transferred from clean - trained models to adversarially - trained models in previous studies, and find that they can be divided into two categories: reducing the learning difficulty and providing correct guidance. Based on this finding, we propose a new idea of leveraging clean training to further improve the performance of advanced AT this http URL reveal that the problem of generalization degradation faced by AT partly stems from the difficulty of adversarial training in learning certain sample features, and this problem can be alleviated by making full use of clean training.</li>
</ul>

<h3>Title: Imbalanced malware classification: an approach based on dynamic classifier selection</h3>
<ul>
<li><strong>Authors: </strong>J. V. S. Souza, C. B. Vieira, G. D. C. Cunha, R. M. O. Cruz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00041">https://arxiv.org/abs/2504.00041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00041">https://arxiv.org/pdf/2504.00041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00041]] Imbalanced malware classification: an approach based on dynamic classifier selection(https://arxiv.org/abs/2504.00041)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>In recent years, the rise of cyber threats has emphasized the need for robust malware detection systems, especially on mobile devices. Malware, which targets vulnerabilities in devices and user data, represents a substantial security risk. A significant challenge in malware detection is the imbalance in datasets, where most applications are benign, with only a small fraction posing a threat. This study addresses the often-overlooked issue of class imbalance in malware detection by evaluating various machine learning strategies for detecting malware in Android applications. We assess monolithic classifiers and ensemble methods, focusing on dynamic selection algorithms, which have shown superior performance compared to traditional approaches. In contrast to balancing strategies performed on the whole dataset, we propose a balancing procedure that works individually for each classifier in the pool. Our empirical analysis demonstrates that the KNOP algorithm obtained the best results using a pool of Random Forest. Additionally, an instance hardness assessment revealed that balancing reduces the difficulty of the minority class and enhances the detection of the minority class (malware). The code used for the experiments is available at this https URL.</li>
</ul>

<h3>Title: Beyond the Reported Cutoff: Where Large Language Models Fall Short on Financial Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Agam Shah, Liqin Ye, Sebastian Jaskowski, Wei Xu, Sudheer Chava</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00042">https://arxiv.org/abs/2504.00042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00042">https://arxiv.org/pdf/2504.00042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00042]] Beyond the Reported Cutoff: Where Large Language Models Fall Short on Financial Knowledge(https://arxiv.org/abs/2504.00042)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are frequently utilized as sources of knowledge for question-answering. While it is known that LLMs may lack access to real-time data or newer data produced after the model's cutoff date, it is less clear how their knowledge spans across historical information. In this study, we assess the breadth of LLMs' knowledge using financial data of U.S. publicly traded companies by evaluating more than 197k questions and comparing model responses to factual data. We further explore the impact of company characteristics, such as size, retail investment, institutional attention, and readability of financial filings, on the accuracy of knowledge represented in LLMs. Our results reveal that LLMs are less informed about past financial performance, but they display a stronger awareness of larger companies and more recent information. Interestingly, at the same time, our analysis also reveals that LLMs are more likely to hallucinate for larger companies, especially for data from more recent years. We will make the code, prompts, and model outputs public upon the publication of the work.</li>
</ul>

<h3>Title: CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation</h3>
<ul>
<li><strong>Authors: </strong>Jixuan Leng, Chengsong Huang, Langlin Huang, Bill Yuchen Lin, William W. Cohen, Haohan Wang, Jiaxin Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00043">https://arxiv.org/abs/2504.00043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00043">https://arxiv.org/pdf/2504.00043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00043]] CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation(https://arxiv.org/abs/2504.00043)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing reasoning evaluation frameworks for Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) predominantly either assess text-based reasoning or vision-language understanding capabilities, with limited dynamic interplay between textual and visual constraints. To address this limitation, we introduce CrossWordBench, a benchmark designed to evaluate the reasoning capabilities of both LLMs and LVLMs through the medium of crossword puzzles-a task requiring multimodal adherence to semantic constraints from text-based clues and intersectional constraints from visual grid structures. CrossWordBench leverages a controllable puzzle generation framework that produces puzzles in multiple formats (text and image) and offers different evaluation strategies ranging from direct puzzle solving to interactive modes. Our extensive evaluation of over 20 models reveals that reasoning LLMs outperform non-reasoning models substantially by effectively leveraging crossing-letter constraints. We further demonstrate that LVLMs struggle with the task, showing a strong correlation between their puzzle-solving performance and grid-parsing accuracy. Our findings offer insights into the limitations of the reasoning capabilities of current LLMs and LVLMs, and provide an effective approach for creating multimodal constrained tasks for future evaluations.</li>
</ul>

<h3>Title: Measuring Online Hate on 4chan using Pre-trained Deep Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Adrian Bermudez-Villalva, Maryam Mehrnezhad, Ehsan Toreini</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00045">https://arxiv.org/abs/2504.00045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00045">https://arxiv.org/pdf/2504.00045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00045]] Measuring Online Hate on 4chan using Pre-trained Deep Learning Models(https://arxiv.org/abs/2504.00045)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>Online hate speech can harmfully impact individuals and groups, specifically on non-moderated platforms such as 4chan where users can post anonymous content. This work focuses on analysing and measuring the prevalence of online hate on 4chan's politically incorrect board (/pol/) using state-of-the-art Natural Language Processing (NLP) models, specifically transformer-based models such as RoBERTa and Detoxify. By leveraging these advanced models, we provide an in-depth analysis of hate speech dynamics and quantify the extent of online hate non-moderated platforms. The study advances understanding through multi-class classification of hate speech (racism, sexism, religion, etc.), while also incorporating the classification of toxic content (e.g., identity attacks and threats) and a further topic modelling analysis. The results show that 11.20% of this dataset is identified as containing hate in different categories. These evaluations show that online hate is manifested in various forms, confirming the complicated and volatile nature of detection in the wild.</li>
</ul>

<h3>Title: Multi-Stakeholder Disaster Insights from Social Media Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Loris Belcastro, Cristian Cosentino, Fabrizio Marozzo, Merve Gündüz-Cüre, Şule Öztürk-Birim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.ET, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00046">https://arxiv.org/abs/2504.00046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00046">https://arxiv.org/pdf/2504.00046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00046]] Multi-Stakeholder Disaster Insights from Social Media Using Large Language Models(https://arxiv.org/abs/2504.00046)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In recent years, social media has emerged as a primary channel for users to promptly share feedback and issues during disasters and emergencies, playing a key role in crisis management. While significant progress has been made in collecting and analyzing social media content, there remains a pressing need to enhance the automation, aggregation, and customization of this data to deliver actionable insights tailored to diverse stakeholders, including the press, police, EMS, and firefighters. This effort is essential for improving the coordination of activities such as relief efforts, resource distribution, and media communication. This paper presents a methodology that leverages the capabilities of LLMs to enhance disaster response and management. Our approach combines classification techniques with generative AI to bridge the gap between raw user feedback and stakeholder-specific reports. Social media posts shared during catastrophic events are analyzed with a focus on user-reported issues, service interruptions, and encountered challenges. We employ full-spectrum LLMs, using analytical models like BERT for precise, multi-dimensional classification of content type, sentiment, emotion, geolocation, and topic. Generative models such as ChatGPT are then used to produce human-readable, informative reports tailored to distinct audiences, synthesizing insights derived from detailed classifications. We compare standard approaches, which analyze posts directly using prompts in ChatGPT, to our advanced method, which incorporates multi-dimensional classification, sub-event selection, and tailored report generation. Our methodology demonstrates superior performance in both quantitative metrics, such as text coherence scores and latent representations, and qualitative assessments by automated tools and field experts, delivering precise insights for diverse disaster response stakeholders.</li>
</ul>

<h3>Title: Distill-C: Enhanced NL2SQL via Distilled Customization with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Cong Duy Vu Hoang, Gioacchino Tangari, Clemence Lanfranchi, Dalu Guo, Paul Cayet, Steve Siu, Don Dharmasiri, Yuan-Fang Li, Long Duong, Damien Hilloulin, Rhicheek Patra, Sungpack Hong, Hassan Chafi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00048">https://arxiv.org/abs/2504.00048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00048">https://arxiv.org/pdf/2504.00048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00048]] Distill-C: Enhanced NL2SQL via Distilled Customization with LLMs(https://arxiv.org/abs/2504.00048)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The growing adoption of large language models (LLMs) in business applications has amplified interest in Natural Language to SQL (NL2SQL) solutions, in which there is competing demand for high performance and efficiency. Domain- and customer-specific requirements further complicate the problem. To address this conundrum, we introduce Distill-C, a distilled customization framework tailored for NL2SQL tasks. Distill-C utilizes large teacher LLMs to produce high-quality synthetic data through a robust and scalable pipeline. Finetuning smaller and open-source LLMs on this synthesized data enables them to rival or outperform teacher models an order of magnitude larger. Evaluated on multiple challenging benchmarks, Distill-C achieves an average improvement of 36% in execution accuracy compared to the base models from three distinct LLM families. Additionally, on three internal customer benchmarks, Distill-C demonstrates a 22.6% performance improvement over the base models. Our results demonstrate that Distill-C is an effective, high-performing and generalizable approach for deploying lightweight yet powerful NL2SQL models, delivering exceptional accuracies while maintaining low computational cost.</li>
</ul>

<h3>Title: JudgeLRM: Large Reasoning Models as a Judge</h3>
<ul>
<li><strong>Authors: </strong>Nuo Chen, Zhiyuan Hu, Qingyun Zou, Jiaying Wu, Qian Wang, Bryan Hooi, Bingsheng He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00050">https://arxiv.org/abs/2504.00050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00050">https://arxiv.org/pdf/2504.00050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00050]] JudgeLRM: Large Reasoning Models as a Judge(https://arxiv.org/abs/2504.00050)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rise of Large Language Models (LLMs) as evaluators offers a scalable alternative to human annotation, yet existing Supervised Fine-Tuning (SFT) for judges approaches often fall short in domains requiring complex reasoning. In this work, we investigate whether LLM judges truly benefit from enhanced reasoning capabilities. Through a detailed analysis of reasoning requirements across evaluation tasks, we reveal a negative correlation between SFT performance gains and the proportion of reasoning-demanding samples - highlighting the limitations of SFT in such scenarios. To address this, we introduce JudgeLRM, a family of judgment-oriented LLMs trained using reinforcement learning (RL) with judge-wise, outcome-driven rewards. JudgeLRM models consistently outperform both SFT-tuned and state-of-the-art reasoning models. Notably, JudgeLRM-3B surpasses GPT-4, and JudgeLRM-7B outperforms DeepSeek-R1 by 2.79% in F1 score, particularly excelling in judge tasks requiring deep reasoning.</li>
</ul>

<h3>Title: The Cursive Transformer</h3>
<ul>
<li><strong>Authors: </strong>Sam Greydanus, Zachary Wimpee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00051">https://arxiv.org/abs/2504.00051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00051">https://arxiv.org/pdf/2504.00051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00051]] The Cursive Transformer(https://arxiv.org/abs/2504.00051)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers trained on tokenized text, audio, and images can generate high-quality autoregressive samples. But handwriting data, represented as sequences of pen coordinates, remains underexplored. We introduce a novel tokenization scheme that converts pen stroke offsets to polar coordinates, discretizes them into bins, and then turns them into sequences of tokens with which to train a standard GPT model. This allows us to capture complex stroke distributions without using any specialized architectures (eg. the mixture density network or the self-advancing ASCII attention head from Graves 2014). With just 3,500 handwritten words and a few simple data augmentations, we are able to train a model that can generate realistic cursive handwriting. Our approach is simpler and more performant than previous RNN-based methods.</li>
</ul>

<h3>Title: Integrating Large Language Models with Human Expertise for Disease Detection in Electronic Health Records</h3>
<ul>
<li><strong>Authors: </strong>Jie Pan, Seungwon Lee, Cheligeer Cheligeer, Elliot A. Martin, Kiarash Riazi, Hude Quan, Na Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00053">https://arxiv.org/abs/2504.00053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00053">https://arxiv.org/pdf/2504.00053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00053]] Integrating Large Language Models with Human Expertise for Disease Detection in Electronic Health Records(https://arxiv.org/abs/2504.00053)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Objective: Electronic health records (EHR) are widely available to complement administrative data-based disease surveillance and healthcare performance evaluation. Defining conditions from EHR is labour-intensive and requires extensive manual labelling of disease outcomes. This study developed an efficient strategy based on advanced large language models to identify multiple conditions from EHR clinical notes. Methods: We linked a cardiac registry cohort in 2015 with an EHR system in Alberta, Canada. We developed a pipeline that leveraged a generative large language model (LLM) to analyze, understand, and interpret EHR notes by prompts based on specific diagnosis, treatment management, and clinical guidelines. The pipeline was applied to detect acute myocardial infarction (AMI), diabetes, and hypertension. The performance was compared against clinician-validated diagnoses as the reference standard and widely adopted International Classification of Diseases (ICD) codes-based methods. Results: The study cohort accounted for 3,088 patients and 551,095 clinical notes. The prevalence was 55.4%, 27.7%, 65.9% and for AMI, diabetes, and hypertension, respectively. The performance of the LLM-based pipeline for detecting conditions varied: AMI had 88% sensitivity, 63% specificity, and 77% positive predictive value (PPV); diabetes had 91% sensitivity, 86% specificity, and 71% PPV; and hypertension had 94% sensitivity, 32% specificity, and 72% PPV. Compared with ICD codes, the LLM-based method demonstrated improved sensitivity and negative predictive value across all conditions. The monthly percentage trends from the detected cases by LLM and reference standard showed consistent patterns.</li>
</ul>

<h3>Title: ModelRadar: Aspect-based Forecast Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Vitor Cerqueira, Luis Roque, Carlos Soares</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00059">https://arxiv.org/abs/2504.00059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00059">https://arxiv.org/pdf/2504.00059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00059]] ModelRadar: Aspect-based Forecast Evaluation(https://arxiv.org/abs/2504.00059)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate evaluation of forecasting models is essential for ensuring reliable predictions. Current practices for evaluating and comparing forecasting models focus on summarising performance into a single score, using metrics such as SMAPE. While convenient, averaging performance over all samples dilutes relevant information about model behavior under varying conditions. This limitation is especially problematic for time series forecasting, where multiple layers of averaging--across time steps, horizons, and multiple time series in a dataset--can mask relevant performance variations. We address this limitation by proposing ModelRadar, a framework for evaluating univariate time series forecasting models across multiple aspects, such as stationarity, presence of anomalies, or forecasting horizons. We demonstrate the advantages of this framework by comparing 24 forecasting methods, including classical approaches and different machine learning algorithms. NHITS, a state-of-the-art neural network architecture, performs best overall but its superiority varies with forecasting conditions. For instance, concerning the forecasting horizon, we found that NHITS (and also other neural networks) only outperforms classical approaches for multi-step ahead forecasting. Another relevant insight is that classical approaches such as ETS or Theta are notably more robust in the presence of anomalies. These and other findings highlight the importance of aspect-based model evaluation for both practitioners and researchers. ModelRadar is available as a Python package.</li>
</ul>

<h3>Title: CF-CAM: Gradient Perturbation Mitigation and Feature Stabilization for Reliable Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Hongjie He, Xu Pan, Yudong Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00060">https://arxiv.org/abs/2504.00060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00060">https://arxiv.org/pdf/2504.00060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00060]] CF-CAM: Gradient Perturbation Mitigation and Feature Stabilization for Reliable Interpretability(https://arxiv.org/abs/2504.00060)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>As deep learning continues to advance, the opacity of neural network decision-making remains a critical challenge, limiting trust and applicability in high-stakes domains. Class Activation Mapping (CAM) techniques have emerged as a key approach to visualizing model decisions, yet existing methods face inherent trade-offs. Gradient-based CAM variants suffer from sensitivity to gradient perturbations, leading to unstable and unreliable explanations. Conversely, gradient-free approaches mitigate gradient instability but incur significant computational overhead and inference latency. To address these limitations, we propose Cluster Filter Class Activation Map (CF-CAM), a novel framework that reintroduces gradient-based weighting while enhancing robustness against gradient noise. CF-CAM employs a hierarchical importance weighting strategy to balance discriminative feature preservation and noise elimination. A density-aware channel clustering via Density-Based Spatial Clustering of Applications with Noise (DBSCAN) groups semantically relevant feature channels and discard noise-prone activations. Additionally, cluster-conditioned gradient filtering leverages bilateral filters to refine gradient signals, preserving edge-aware localization while suppressing noise impact. Experiment results demonstrate that CF-CAM achieves superior interpretability performance while maintaining resilience to gradient perturbations, outperforming state-of-the-art CAM methods in faithfulness and robustness. By effectively mitigating gradient instability without excessive computational cost, CF-CAM provides a reliable solution for enhancing the interpretability of deep neural networks in critical applications such as medical diagnosis and autonomous driving.</li>
</ul>

<h3>Title: Evaluating the Feasibility and Accuracy of Large Language Models for Medical History-Taking in Obstetrics and Gynecology</h3>
<ul>
<li><strong>Authors: </strong>Dou Liu, Ying Long, Sophia Zuoqiu, Tian Tang, Rong Yin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00061">https://arxiv.org/abs/2504.00061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00061">https://arxiv.org/pdf/2504.00061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00061]] Evaluating the Feasibility and Accuracy of Large Language Models for Medical History-Taking in Obstetrics and Gynecology(https://arxiv.org/abs/2504.00061)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Effective physician-patient communications in pre-diagnostic environments, and most specifically in complex and sensitive medical areas such as infertility, are critical but consume a lot of time and, therefore, cause clinic workflows to become inefficient. Recent advancements in Large Language Models (LLMs) offer a potential solution for automating conversational medical history-taking and improving diagnostic accuracy. This study evaluates the feasibility and performance of LLMs in those tasks for infertility cases. An AI-driven conversational system was developed to simulate physician-patient interactions with ChatGPT-4o and ChatGPT-4o-mini. A total of 70 real-world infertility cases were processed, generating 420 diagnostic histories. Model performance was assessed using F1 score, Differential Diagnosis (DDs) Accuracy, and Accuracy of Infertility Type Judgment (ITJ). ChatGPT-4o-mini outperformed ChatGPT-4o in information extraction accuracy (F1 score: 0.9258 vs. 0.9029, p = 0.045, d = 0.244) and demonstrated higher completeness in medical history-taking (97.58% vs. 77.11%), suggesting that ChatGPT-4o-mini is more effective in extracting detailed patient information, which is critical for improving diagnostic accuracy. In contrast, ChatGPT-4o performed slightly better in differential diagnosis accuracy (2.0524 vs. 2.0048, p > 0.05). ITJ accuracy was higher in ChatGPT-4o-mini (0.6476 vs. 0.5905) but with lower consistency (Cronbach's $\alpha$ = 0.562), suggesting variability in classification reliability. Both models demonstrated strong feasibility in automating infertility history-taking, with ChatGPT-4o-mini excelling in completeness and extraction accuracy. In future studies, expert validation for accuracy and dependability in a clinical setting, AI model fine-tuning, and larger datasets with a mix of cases of infertility have to be prioritized.</li>
</ul>

<h3>Title: Integrating Quantum-Classical Attention in Patch Transformers for Enhanced Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Sanjay Chakraborty, Fredrik Heintz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00068">https://arxiv.org/abs/2504.00068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00068">https://arxiv.org/pdf/2504.00068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00068]] Integrating Quantum-Classical Attention in Patch Transformers for Enhanced Time Series Forecasting(https://arxiv.org/abs/2504.00068)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>QCAAPatchTF is a quantum attention network integrated with an advanced patch-based transformer, designed for multivariate time series forecasting, classification, and anomaly detection. Leveraging quantum superpositions, entanglement, and variational quantum eigensolver principles, the model introduces a quantum-classical hybrid self-attention mechanism to capture multivariate correlations across time points. For multivariate long-term time series, the quantum self-attention mechanism can reduce computational complexity while maintaining temporal relationships. It then applies the quantum-classical hybrid self-attention mechanism alongside a feed-forward network in the encoder stage of the advanced patch-based transformer. While the feed-forward network learns nonlinear representations for each variable frame, the quantum self-attention mechanism processes individual series to enhance multivariate relationships. The advanced patch-based transformer computes the optimized patch length by dividing the sequence length into a fixed number of patches instead of using an arbitrary set of values. The stride is then set to half of the patch length to ensure efficient overlapping representations while maintaining temporal continuity. QCAAPatchTF achieves state-of-the-art performance in both long-term and short-term forecasting, classification, and anomaly detection tasks, demonstrating state-of-the-art accuracy and efficiency on complex real-world datasets.</li>
</ul>

<h3>Title: Enhancing Time Series Forecasting with Fuzzy Attention-Integrated Transformers</h3>
<ul>
<li><strong>Authors: </strong>Sanjay Chakraborty, Fredrik Heintz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00070">https://arxiv.org/abs/2504.00070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00070">https://arxiv.org/pdf/2504.00070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00070]] Enhancing Time Series Forecasting with Fuzzy Attention-Integrated Transformers(https://arxiv.org/abs/2504.00070)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces FANTF (Fuzzy Attention Network-Based Transformers), a novel approach that integrates fuzzy logic with existing transformer architectures to advance time series forecasting, classification, and anomaly detection tasks. FANTF leverages a proposed fuzzy attention mechanism incorporating fuzzy membership functions to handle uncertainty and imprecision in noisy and ambiguous time series data. The FANTF approach enhances its ability to capture complex temporal dependencies and multivariate relationships by embedding fuzzy logic principles into the self-attention module of the existing transformer's architecture. The framework combines fuzzy-enhanced attention with a set of benchmark existing transformer-based architectures to provide efficient predictions, classification and anomaly detection. Specifically, FANTF generates learnable fuzziness attention scores that highlight the relative importance of temporal features and data points, offering insights into its decision-making process. Experimental evaluatios on some real-world datasets reveal that FANTF significantly enhances the performance of forecasting, classification, and anomaly detection tasks over traditional transformer-based models.</li>
</ul>

<h3>Title: Chapter-Llama: Efficient Chaptering in Hour-Long Videos with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Lucas Ventura, Antoine Yang, Cordelia Schmid, Gül Varol</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00072">https://arxiv.org/abs/2504.00072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00072">https://arxiv.org/pdf/2504.00072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00072]] Chapter-Llama: Efficient Chaptering in Hour-Long Videos with LLMs(https://arxiv.org/abs/2504.00072)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We address the task of video chaptering, i.e., partitioning a long video timeline into semantic units and generating corresponding chapter titles. While relatively underexplored, automatic chaptering has the potential to enable efficient navigation and content retrieval in long-form videos. In this paper, we achieve strong chaptering performance on hour-long videos by efficiently addressing the problem in the text domain with our 'Chapter-Llama' framework. Specifically, we leverage a pretrained large language model (LLM) with large context window, and feed as input (i) speech transcripts and (ii) captions describing video frames, along with their respective timestamps. Given the inefficiency of exhaustively captioning all frames, we propose a lightweight speech-guided frame selection strategy based on speech transcript content, and experimentally demonstrate remarkable advantages. We train the LLM to output timestamps for the chapter boundaries, as well as free-form chapter titles. This simple yet powerful approach scales to processing one-hour long videos in a single forward pass. Our results demonstrate substantial improvements (e.g., 45.3 vs 26.7 F1 score) over the state of the art on the recent VidChapters-7M benchmark. To promote further research, we release our code and models at our project page.</li>
</ul>

<h3>Title: EMForecaster: A Deep Learning Framework for Time Series Forecasting in Wireless Networks with Distribution-Free Uncertainty Quantification</h3>
<ul>
<li><strong>Authors: </strong>Xavier Mootoo, Hina Tabassum, Luca Chiaraviglio</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00120">https://arxiv.org/abs/2504.00120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00120">https://arxiv.org/pdf/2504.00120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00120]] EMForecaster: A Deep Learning Framework for Time Series Forecasting in Wireless Networks with Distribution-Free Uncertainty Quantification(https://arxiv.org/abs/2504.00120)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>With the recent advancements in wireless technologies, forecasting electromagnetic field (EMF) exposure has become critical to enable proactive network spectrum and power allocation, as well as network deployment planning. In this paper, we develop a deep learning (DL) time series forecasting framework referred to as \textit{EMForecaster}. The proposed DL architecture employs patching to process temporal patterns at multiple scales, complemented by reversible instance normalization and mixing operations along both temporal and patch dimensions for efficient feature extraction. We augment {EMForecaster} with a conformal prediction mechanism, which is independent of the data distribution, to enhance the trustworthiness of model predictions via uncertainty quantification of forecasts. This conformal prediction mechanism ensures that the ground truth lies within a prediction interval with target error rate $\alpha$, where $1-\alpha$ is referred to as coverage. However, a trade-off exists, as increasing coverage often results in wider prediction intervals. To address this challenge, we propose a new metric called the \textit{Trade-off Score}, that balances trustworthiness of the forecast (i.e., coverage) and the width of prediction interval. Our experiments demonstrate that EMForecaster achieves superior performance across diverse EMF datasets, spanning both short-term and long-term prediction horizons. In point forecasting tasks, EMForecaster substantially outperforms current state-of-the-art DL approaches, showing improvements of 53.97\% over the Transformer architecture and 38.44\% over the average of all baseline models. EMForecaster also exhibits an excellent balance between prediction interval width and coverage in conformal forecasting, measured by the tradeoff score, showing marked improvements of 24.73\% over the average baseline and 49.17\% over the Transformer architecture.</li>
</ul>

<h3>Title: Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B</h3>
<ul>
<li><strong>Authors: </strong>Aleksandra Bakalova, Yana Veitsman, Xinting Huang, Michael Hahn</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00132">https://arxiv.org/abs/2504.00132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00132">https://arxiv.org/pdf/2504.00132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00132]] Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B(https://arxiv.org/abs/2504.00132)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-Context Learning (ICL) is an intriguing ability of large language models (LLMs). Despite a substantial amount of work on its behavioral aspects and how it emerges in miniature setups, it remains unclear which mechanism assembles task information from the individual examples in a fewshot prompt. We use causal interventions to identify information flow in Gemma-2 2B for five naturalistic ICL tasks. We find that the model infers task information using a two-step strategy we call contextualize-then-aggregate: In the lower layers, the model builds up representations of individual fewshot examples, which are contextualized by preceding examples through connections between fewshot input and output tokens across the sequence. In the higher layers, these representations are aggregated to identify the task and prepare prediction of the next output. The importance of the contextualization step differs between tasks, and it may become more important in the presence of ambiguous examples. Overall, by providing rigorous causal analysis, our results shed light on the mechanisms through which ICL happens in language models.</li>
</ul>

<h3>Title: SuperEvent: Cross-Modal Learning of Event-based Keypoint Detection</h3>
<ul>
<li><strong>Authors: </strong>Yannick Burkhardt, Simon Schaefer, Stefan Leutenegger</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00139">https://arxiv.org/abs/2504.00139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00139">https://arxiv.org/pdf/2504.00139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00139]] SuperEvent: Cross-Modal Learning of Event-based Keypoint Detection(https://arxiv.org/abs/2504.00139)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Event-based keypoint detection and matching holds significant potential, enabling the integration of event sensors into highly optimized Visual SLAM systems developed for frame cameras over decades of research. Unfortunately, existing approaches struggle with the motion-dependent appearance of keypoints and the complex noise prevalent in event streams, resulting in severely limited feature matching capabilities and poor performance on downstream tasks. To mitigate this problem, we propose SuperEvent, a data-driven approach to predict stable keypoints with expressive descriptors. Due to the absence of event datasets with ground truth keypoint labels, we leverage existing frame-based keypoint detectors on readily available event-aligned and synchronized gray-scale frames for self-supervision: we generate temporally sparse keypoint pseudo-labels considering that events are a product of both scene appearance and camera motion. Combined with our novel, information-rich event representation, we enable SuperEvent to effectively learn robust keypoint detection and description in event streams. Finally, we demonstrate the usefulness of SuperEvent by its integration into a modern sparse keypoint and descriptor-based SLAM framework originally developed for traditional cameras, surpassing the state-of-the-art in event-based SLAM by a wide margin. Source code and multimedia material are available at this http URL.</li>
</ul>

<h3>Title: Lorentzian Graph Isomorphic Network</h3>
<ul>
<li><strong>Authors: </strong>Srinitish Srinivasan, Omkumar CU</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00142">https://arxiv.org/abs/2504.00142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00142">https://arxiv.org/pdf/2504.00142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00142]] Lorentzian Graph Isomorphic Network(https://arxiv.org/abs/2504.00142)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce the Lorentzian Graph Isomorphic Network (LGIN), a novel graph neural network (GNN) designed to operate in hyperbolic spaces, leveraging the Lorentzian model to enhance graph representation learning. Existing GNNs primarily operate in Euclidean spaces, which can limit their ability to capture hierarchical and multi-relational structures inherent to complex graphs. LGIN addresses this by incorporating curvature-aware aggregation functions that preserve the Lorentzian metric tensor, ensuring embeddings remain constrained within the hyperbolic space by proposing a new update rule that effectively captures both local neighborhood interactions and global structural properties, enabling LGIN to distinguish non-isomorphic graphs with expressiveness at least as powerful as the Weisfeiler-Lehman test. Through extensive evaluation across nine benchmark datasets, including molecular and protein structures, LGIN consistently outperforms or matches state-of-the-art GNNs, demonstrating its robustness and efficacy in modeling complex graph structures. To the best of our knowledge, this is the first study to extend the concept of a powerful graph neural network to Riemannian manifolds, paving the way for future advancements in hyperbolic graph learning. The code for our paper can be found at this https URL.</li>
</ul>

<h3>Title: Why risk matters for protein binder design</h3>
<ul>
<li><strong>Authors: </strong>Tudor Cotet, Igor Krawczuk</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00146">https://arxiv.org/abs/2504.00146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00146">https://arxiv.org/pdf/2504.00146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00146]] Why risk matters for protein binder design(https://arxiv.org/abs/2504.00146)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Bayesian optimization (BO) has recently become more prevalent in protein engineering applications and hence has become a fruitful target of benchmarks. However, current BO comparisons often overlook real-world considerations like risk and cost constraints. In this work, we compare 72 model combinations of encodings, surrogate models, and acquisition functions on 11 protein binder fitness landscapes, specifically from this perspective. Drawing from the portfolio optimization literature, we adopt metrics to quantify the cold-start performance relative to a random baseline, to assess the risk of an optimization campaign, and to calculate the overall budget required to reach a fitness threshold. Our results suggest the existence of Pareto-optimal models on the risk-performance axis, the shift of this preference depending on the landscape explored, and the robust correlation between landscape properties such as epistasis with the average and worst-case model performance. They also highlight that rigorous model selection requires substantial computational and statistical efforts.</li>
</ul>

<h3>Title: Universal Zero-shot Embedding Inversion</h3>
<ul>
<li><strong>Authors: </strong>Collin Zhang, John X. Morris, Vitaly Shmatikov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00147">https://arxiv.org/abs/2504.00147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00147">https://arxiv.org/pdf/2504.00147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00147]] Universal Zero-shot Embedding Inversion(https://arxiv.org/abs/2504.00147)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Embedding inversion, i.e., reconstructing text given its embedding and black-box access to the embedding encoder, is a fundamental problem in both NLP and security. From the NLP perspective, it helps determine how much semantic information about the input is retained in the embedding. From the security perspective, it measures how much information is leaked by vector databases and embedding-based retrieval systems. State-of-the-art methods for embedding inversion, such as vec2text, have high accuracy but require (a) training a separate model for each embedding, and (b) a large number of queries to the corresponding encoder. We design, implement, and evaluate ZSInvert, a zero-shot inversion method based on the recently proposed adversarial decoding technique. ZSInvert is fast, query-efficient, and can be used for any text embedding without training an embedding-specific inversion model. We measure the effectiveness of ZSInvert on several embeddings and demonstrate that it recovers key semantic information about the corresponding texts.</li>
</ul>

<h3>Title: Few-Shot Generation of Brain Tumors for Secure and Fair Data Sharing</h3>
<ul>
<li><strong>Authors: </strong>Yongyi Shi, Ge Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00150">https://arxiv.org/abs/2504.00150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00150">https://arxiv.org/pdf/2504.00150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00150]] Few-Shot Generation of Brain Tumors for Secure and Fair Data Sharing(https://arxiv.org/abs/2504.00150)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, federate, fair, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Leveraging multi-center data for medical analytics presents challenges due to privacy concerns and data heterogeneity. While distributed approaches such as federated learning has gained traction, they remain vulnerable to privacy breaches, particularly in sensitive domains like medical imaging. Generative models, such as diffusion models, enhance privacy by synthesizing realistic data. However, they are prone to memorization, especially when trained on small datasets. This study proposes a decentralized few-shot generative model (DFGM) to synthesize brain tumor images while fully preserving privacy. DFGM harmonizes private tumor data with publicly shareable healthy images from multiple medical centers, constructing a new dataset by blending tumor foregrounds with healthy backgrounds. This approach ensures stringent privacy protection and enables controllable, high-quality synthesis by preserving both the healthy backgrounds and tumor foregrounds. We assess DFGM's effectiveness in brain tumor segmentation using a UNet, achieving Dice score improvements of 3.9% for data augmentation and 4.6% for fairness on a separate dataset.</li>
</ul>

<h3>Title: Does "Reasoning" with Large Language Models Improve Recognizing, Generating, and Reframing Unhelpful Thoughts?</h3>
<ul>
<li><strong>Authors: </strong>Yilin Qi, Dong Won Lee, Cynthia Breazeal, Hae Won Park</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00163">https://arxiv.org/abs/2504.00163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00163">https://arxiv.org/pdf/2504.00163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00163]] Does "Reasoning" with Large Language Models Improve Recognizing, Generating, and Reframing Unhelpful Thoughts?(https://arxiv.org/abs/2504.00163)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Cognitive Reframing, a core element of Cognitive Behavioral Therapy (CBT), helps individuals reinterpret negative experiences by finding positive meaning. Recent advances in Large Language Models (LLMs) have demonstrated improved performance through reasoning-based strategies. This inspires a promising direction of leveraging the reasoning capabilities of LLMs to improve CBT and mental reframing by simulating the process of critical thinking, potentially enabling more effective recognition, generation, and reframing of cognitive distortions. In this work, we investigate the role of various reasoning methods, including pre-trained reasoning LLMs and augmented reasoning strategies such as CoT and self-consistency in enhancing LLMs' ability to perform cognitive reframing tasks. We find that augmented reasoning methods, even when applied to "outdated" LLMs like GPT-3.5, consistently outperform state-of-the-art pretrained reasoning models on recognizing, generating and reframing unhelpful thoughts.</li>
</ul>

<h3>Title: Backdoor Detection through Replicated Execution of Outsourced Training</h3>
<ul>
<li><strong>Authors: </strong>Hengrui Jia, Sierra Wyllie, Akram Bin Sediq, Ahmed Ibrahim, Nicolas Papernot</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00170">https://arxiv.org/abs/2504.00170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00170">https://arxiv.org/pdf/2504.00170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00170]] Backdoor Detection through Replicated Execution of Outsourced Training(https://arxiv.org/abs/2504.00170)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>It is common practice to outsource the training of machine learning models to cloud providers. Clients who do so gain from the cloud's economies of scale, but implicitly assume trust: the server should not deviate from the client's training procedure. A malicious server may, for instance, seek to insert backdoors in the model. Detecting a backdoored model without prior knowledge of both the backdoor attack and its accompanying trigger remains a challenging problem. In this paper, we show that a client with access to multiple cloud providers can replicate a subset of training steps across multiple servers to detect deviation from the training procedure in a similar manner to differential testing. Assuming some cloud-provided servers are benign, we identify malicious servers by the substantial difference between model updates required for backdooring and those resulting from clean training. Perhaps the strongest advantage of our approach is its suitability to clients that have limited-to-no local compute capability to perform training; we leverage the existence of multiple cloud providers to identify malicious updates without expensive human labeling or heavy computation. We demonstrate the capabilities of our approach on an outsourced supervised learning task where $50\%$ of the cloud providers insert their own backdoor; our approach is able to correctly identify $99.6\%$ of them. In essence, our approach is successful because it replaces the signature-based paradigm taken by existing approaches with an anomaly-based detection paradigm. Furthermore, our approach is robust to several attacks from adaptive adversaries utilizing knowledge of our detection scheme.</li>
</ul>

<h3>Title: MetaCLBench: Meta Continual Learning Benchmark on Resource-Constrained Edge Devices</h3>
<ul>
<li><strong>Authors: </strong>Sijia Li, Young D. Kwon, Lik-Hang Lee, Pan Hui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00174">https://arxiv.org/abs/2504.00174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00174">https://arxiv.org/pdf/2504.00174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00174]] MetaCLBench: Meta Continual Learning Benchmark on Resource-Constrained Edge Devices(https://arxiv.org/abs/2504.00174)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Meta-Continual Learning (Meta-CL) has emerged as a promising approach to minimize manual labeling efforts and system resource requirements by enabling Continual Learning (CL) with limited labeled samples. However, while existing methods have shown success in image-based tasks, their effectiveness remains unexplored for sequential time-series data from sensor systems, particularly audio inputs. To address this gap, we conduct a comprehensive benchmark study evaluating six representative Meta-CL approaches using three network architectures on five datasets from both image and audio modalities. We develop MetaCLBench, an end-to-end Meta-CL benchmark framework for edge devices to evaluate system overheads and investigate trade-offs among performance, computational costs, and memory requirements across various Meta-CL methods. Our results reveal that while many Meta-CL methods enable to learn new classes for both image and audio modalities, they impose significant computational and memory costs on edge devices. Also, we find that pre-training and meta-training procedures based on source data before deployment improve Meta-CL performance. Finally, to facilitate further research, we provide practical guidelines for researchers and machine learning practitioners implementing Meta-CL on resource-constrained environments and make our benchmark framework and tools publicly available, enabling fair evaluation across both accuracy and system-level metrics.</li>
</ul>

<h3>Title: Contradiction Detection in RAG Systems: Evaluating LLMs as Context Validators for Improved Information Consistency</h3>
<ul>
<li><strong>Authors: </strong>Vignesh Gokul, Srikanth Tenneti, Alwarappan Nakkiran</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00180">https://arxiv.org/abs/2504.00180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00180">https://arxiv.org/pdf/2504.00180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00180]] Contradiction Detection in RAG Systems: Evaluating LLMs as Context Validators for Improved Information Consistency(https://arxiv.org/abs/2504.00180)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) systems have emerged as a powerful method for enhancing large language models (LLMs) with up-to-date information. However, the retrieval step in RAG can sometimes surface documents containing contradictory information, particularly in rapidly evolving domains such as news. These contradictions can significantly impact the performance of LLMs, leading to inconsistent or erroneous outputs. This study addresses this critical challenge in two ways. First, we present a novel data generation framework to simulate different types of contradictions that may occur in the retrieval stage of a RAG system. Second, we evaluate the robustness of different LLMs in performing as context validators, assessing their ability to detect contradictory information within retrieved document sets. Our experimental results reveal that context validation remains a challenging task even for state-of-the-art LLMs, with performance varying significantly across different types of contradictions. While larger models generally perform better at contradiction detection, the effectiveness of different prompting strategies varies across tasks and model architectures. We find that chain-of-thought prompting shows notable improvements for some models but may hinder performance in others, highlighting the complexity of the task and the need for more robust approaches to context validation in RAG systems.</li>
</ul>

<h3>Title: Are Domain Generalization Benchmarks with Accuracy on the Line Misspecified?</h3>
<ul>
<li><strong>Authors: </strong>Olawale Salaudeen, Nicole Chiou, Shiny Weng, Sanmi Koyejo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00186">https://arxiv.org/abs/2504.00186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00186">https://arxiv.org/pdf/2504.00186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00186]] Are Domain Generalization Benchmarks with Accuracy on the Line Misspecified?(https://arxiv.org/abs/2504.00186)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spurious correlations are unstable statistical associations that hinder robust decision-making. Conventional wisdom suggests that models relying on such correlations will fail to generalize out-of-distribution (OOD), especially under strong distribution shifts. However, empirical evidence challenges this view as naive in-distribution empirical risk minimizers often achieve the best OOD accuracy across popular OOD generalization benchmarks. In light of these results, we propose a different perspective: many widely used benchmarks for evaluating robustness to spurious correlations are misspecified. Specifically, they fail to include shifts in spurious correlations that meaningfully impact OOD generalization, making them unsuitable for evaluating the benefit of removing such correlations. We establish conditions under which a distribution shift can reliably assess a model's reliance on spurious correlations. Crucially, under these conditions, we should not observe a strong positive correlation between in-distribution and OOD accuracy, often called "accuracy on the line." Yet, most state-of-the-art benchmarks exhibit this pattern, suggesting they do not effectively assess robustness. Our findings expose a key limitation in current benchmarks used to evaluate domain generalization algorithms, that is, models designed to avoid spurious correlations. We highlight the need to rethink how robustness to spurious correlations is assessed, identify well-specified benchmarks the field should prioritize, and enumerate strategies for designing future benchmarks that meaningfully reflect robustness under distribution shift.</li>
</ul>

<h3>Title: Insight-RAG: Enhancing LLMs with Insight-Driven Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Pouya Pezeshkpour, Estevam Hruschka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00187">https://arxiv.org/abs/2504.00187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00187">https://arxiv.org/pdf/2504.00187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00187]] Insight-RAG: Enhancing LLMs with Insight-Driven Augmentation(https://arxiv.org/abs/2504.00187)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) frameworks have shown significant promise in leveraging external knowledge to enhance the performance of large language models (LLMs). However, conventional RAG methods often retrieve documents based solely on surface-level relevance, leading to many issues: they may overlook deeply buried information within individual documents, miss relevant insights spanning multiple sources, and are not well-suited for tasks beyond traditional question answering. In this paper, we propose Insight-RAG, a novel framework designed to address these issues. In the initial stage of Insight-RAG, instead of using traditional retrieval methods, we employ an LLM to analyze the input query and task, extracting the underlying informational requirements. In the subsequent stage, a specialized LLM -- trained on the document database -- is queried to mine content that directly addresses these identified insights. Finally, by integrating the original query with the retrieved insights, similar to conventional RAG approaches, we employ a final LLM to generate a contextually enriched and accurate response. Using two scientific paper datasets, we created evaluation benchmarks targeting each of the mentioned issues and assessed Insight-RAG against traditional RAG pipeline. Our results demonstrate that the Insight-RAG pipeline successfully addresses these challenges, outperforming existing methods by a significant margin in most cases. These findings suggest that integrating insight-driven retrieval within the RAG framework not only enhances performance but also broadens the applicability of RAG to tasks beyond conventional question answering.</li>
</ul>

<h3>Title: Leveraging Diffusion Model and Image Foundation Model for Improved Correspondence Matching in Coronary Angiography</h3>
<ul>
<li><strong>Authors: </strong>Lin Zhao, Xin Yu, Yikang Liu, Xiao Chen, Eric Z. Chen, Terrence Chen, Shanhui Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00191">https://arxiv.org/abs/2504.00191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00191">https://arxiv.org/pdf/2504.00191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00191]] Leveraging Diffusion Model and Image Foundation Model for Improved Correspondence Matching in Coronary Angiography(https://arxiv.org/abs/2504.00191)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Accurate correspondence matching in coronary angiography images is crucial for reconstructing 3D coronary artery structures, which is essential for precise diagnosis and treatment planning of coronary artery disease (CAD). Traditional matching methods for natural images often fail to generalize to X-ray images due to inherent differences such as lack of texture, lower contrast, and overlapping structures, compounded by insufficient training data. To address these challenges, we propose a novel pipeline that generates realistic paired coronary angiography images using a diffusion model conditioned on 2D projections of 3D reconstructed meshes from Coronary Computed Tomography Angiography (CCTA), providing high-quality synthetic data for training. Additionally, we employ large-scale image foundation models to guide feature aggregation, enhancing correspondence matching accuracy by focusing on semantically relevant regions and keypoints. Our approach demonstrates superior matching performance on synthetic datasets and effectively generalizes to real-world datasets, offering a practical solution for this task. Furthermore, our work investigates the efficacy of different foundation models in correspondence matching, providing novel insights into leveraging advanced image foundation models for medical imaging applications.</li>
</ul>

<h3>Title: Identifying Sparsely Active Circuits Through Local Loss Landscape Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Brianna Chrisman, Lucius Bushnaq, Lee Sharkey</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00194">https://arxiv.org/abs/2504.00194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00194">https://arxiv.org/pdf/2504.00194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00194]] Identifying Sparsely Active Circuits Through Local Loss Landscape Decomposition(https://arxiv.org/abs/2504.00194)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Much of mechanistic interpretability has focused on understanding the activation spaces of large neural networks. However, activation space-based approaches reveal little about the underlying circuitry used to compute features. To better understand the circuits employed by models, we introduce a new decomposition method called Local Loss Landscape Decomposition (L3D). L3D identifies a set of low-rank subnetworks: directions in parameter space of which a subset can reconstruct the gradient of the loss between any sample's output and a reference output vector. We design a series of progressively more challenging toy models with well-defined subnetworks and show that L3D can nearly perfectly recover the associated subnetworks. Additionally, we investigate the extent to which perturbing the model in the direction of a given subnetwork affects only the relevant subset of samples. Finally, we apply L3D to a real-world transformer model and a convolutional neural network, demonstrating its potential to identify interpretable and relevant circuits in parameter space.</li>
</ul>

<h3>Title: SmartScan: An AI-based Interactive Framework for Automated Region Extraction from Satellite Images</h3>
<ul>
<li><strong>Authors: </strong>Savinay Nagendra, Kashif Rashid</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00200">https://arxiv.org/abs/2504.00200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00200">https://arxiv.org/pdf/2504.00200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00200]] SmartScan: An AI-based Interactive Framework for Automated Region Extraction from Satellite Images(https://arxiv.org/abs/2504.00200)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The deployment of a continuous methane monitoring system requires determining the optimal number and placement of fixed sensors. However, planning is labor-intensive, requiring extensive site setup and iteration to meet client restrictions. This challenge is amplified when evaluating multiple sites, limiting scalability. To address this, we introduce SmartScan, an AI framework that automates data extraction for optimal sensor placement. SmartScan identifies subspaces of interest from satellite images using an interactive tool to create facility-specific constraint sets efficiently. SmartScan leverages the Segment Anything Model (SAM), a prompt-based transformer for zero-shot segmentation, enabling subspace extraction without explicit training. It operates in two modes: (1) Data Curation Mode, where satellite images are processed to extract high-quality subspaces using an interactive prompting system for SAM, and (2) Autonomous Mode, where user-curated prompts train a deep learning network to replace manual prompting, fully automating subspace extraction. The interactive tool also serves for quality control, allowing users to refine AI-generated outputs and generate additional constraint sets as needed. With its AI-driven prompting mechanism, SmartScan delivers high-throughput, high-quality subspace extraction with minimal human intervention, enhancing scalability and efficiency. Notably, its adaptable design makes it suitable for extracting regions of interest from ultra-high-resolution satellite imagery across various domains.</li>
</ul>

<h3>Title: LITA-GS: Illumination-Agnostic Novel View Synthesis via Reference-Free 3D Gaussian Splatting and Physical Priors</h3>
<ul>
<li><strong>Authors: </strong>Han Zhou, Wei Dong, Jun Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00219">https://arxiv.org/abs/2504.00219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00219">https://arxiv.org/pdf/2504.00219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00219]] LITA-GS: Illumination-Agnostic Novel View Synthesis via Reference-Free 3D Gaussian Splatting and Physical Priors(https://arxiv.org/abs/2504.00219)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Directly employing 3D Gaussian Splatting (3DGS) on images with adverse illumination conditions exhibits considerable difficulty in achieving high-quality, normally-exposed representations due to: (1) The limited Structure from Motion (SfM) points estimated in adverse illumination scenarios fail to capture sufficient scene details; (2) Without ground-truth references, the intensive information loss, significant noise, and color distortion pose substantial challenges for 3DGS to produce high-quality results; (3) Combining existing exposure correction methods with 3DGS does not achieve satisfactory performance due to their individual enhancement processes, which lead to the illumination inconsistency between enhanced images from different viewpoints. To address these issues, we propose LITA-GS, a novel illumination-agnostic novel view synthesis method via reference-free 3DGS and physical priors. Firstly, we introduce an illumination-invariant physical prior extraction pipeline. Secondly, based on the extracted robust spatial structure prior, we develop the lighting-agnostic structure rendering strategy, which facilitates the optimization of the scene structure and object appearance. Moreover, a progressive denoising module is introduced to effectively mitigate the noise within the light-invariant representation. We adopt the unsupervised strategy for the training of LITA-GS and extensive experiments demonstrate that LITA-GS surpasses the state-of-the-art (SOTA) NeRF-based method while enjoying faster inference speed and costing reduced training time. The code is released at this https URL.</li>
</ul>

<h3>Title: Can Diffusion Models Disentangle? A Theoretical Perspective</h3>
<ul>
<li><strong>Authors: </strong>Liming Wang, Muhammad Jehanzeb Mirza, Yishu Gong, Yuan Gong, Jiaqi Zhang, Brian H. Tracey, Katerina Placek, Marco Vilela, James R. Glass</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00220">https://arxiv.org/abs/2504.00220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00220">https://arxiv.org/pdf/2504.00220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00220]] Can Diffusion Models Disentangle? A Theoretical Perspective(https://arxiv.org/abs/2504.00220)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper presents a novel theoretical framework for understanding how diffusion models can learn disentangled representations. Within this framework, we establish identifiability conditions for general disentangled latent variable models, analyze training dynamics, and derive sample complexity bounds for disentangled latent subspace models. To validate our theory, we conduct disentanglement experiments across diverse tasks and modalities, including subspace recovery in latent subspace Gaussian mixture models, image colorization, image denoising, and voice conversion for speech classification. Additionally, our experiments show that training strategies inspired by our theory, such as style guidance regularization, consistently enhance disentanglement performance.</li>
</ul>

<h3>Title: Synthesizing Public Opinions with LLMs: Role Creation, Impacts, and the Future to eDemorcacy</h3>
<ul>
<li><strong>Authors: </strong>Rabimba Karanjai, Boris Shor, Amanda Austin, Ryan Kennedy, Yang Lu, Lei Xu, Weidong Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00241">https://arxiv.org/abs/2504.00241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00241">https://arxiv.org/pdf/2504.00241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00241]] Synthesizing Public Opinions with LLMs: Role Creation, Impacts, and the Future to eDemorcacy(https://arxiv.org/abs/2504.00241)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the use of Large Language Models (LLMs) to synthesize public opinion data, addressing challenges in traditional survey methods like declining response rates and non-response bias. We introduce a novel technique: role creation based on knowledge injection, a form of in-context learning that leverages RAG and specified personality profiles from the HEXACO model and demographic information, and uses that for dynamically generated prompts. This method allows LLMs to simulate diverse opinions more accurately than existing prompt engineering approaches. We compare our results with pre-trained models with standard few-shot prompts. Experiments using questions from the Cooperative Election Study (CES) demonstrate that our role-creation approach significantly improves the alignment of LLM-generated opinions with real-world human survey responses, increasing answer adherence. In addition, we discuss challenges, limitations and future research directions.</li>
</ul>

<h3>Title: SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers</h3>
<ul>
<li><strong>Authors: </strong>Yanzheng Xiang, Hanqi Yan, Shuyin Ouyang, Lin Gui, Yulan He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00255">https://arxiv.org/abs/2504.00255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00255">https://arxiv.org/pdf/2504.00255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00255]] SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers(https://arxiv.org/abs/2504.00255)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study evaluates large language models (LLMs) in generating code from algorithm descriptions from recent NLP papers. The task requires two key competencies: (1) algorithm comprehension: synthesizing information from papers and academic literature to understand implementation logic, and (2) coding expertise: identifying dependencies and correctly implementing necessary APIs. To facilitate rigorous evaluation, we introduce SciReplicate-Bench, a benchmark of 100 tasks from 36 NLP papers published in 2024, featuring detailed annotations and comprehensive test cases. Building on SciReplicate-Bench, we propose Sci-Reproducer, a multi-agent framework consisting of a Paper Agent that interprets algorithmic concepts from literature and a Code Agent that retrieves dependencies from repositories and implement solutions. To assess algorithm understanding, we introduce reasoning graph accuracy, which quantifies similarity between generated and reference reasoning graphs derived from code comments and structure. For evaluating implementation quality, we employ execution accuracy, CodeBLEU, and repository dependency/API recall metrics. In our experiments, we evaluate various powerful Non-Reasoning LLMs and Reasoning LLMs as foundational models. The best-performing LLM using Sci-Reproducer achieves only 39% execution accuracy, highlighting the benchmark's this http URL analysis identifies missing or inconsistent algorithm descriptions as key barriers to successful reproduction. We will open-source our benchmark, and code at this https URL.</li>
</ul>

<h3>Title: Multilingual Sentiment Analysis of Summarized Texts: A Cross-Language Study of Text Shortening Effects</h3>
<ul>
<li><strong>Authors: </strong>Mikhail Krasitskii, Grigori Sidorov, Olga Kolesnikova, Liliana Chanona Hernandez, Alexander Gelbukh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00265">https://arxiv.org/abs/2504.00265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00265">https://arxiv.org/pdf/2504.00265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00265]] Multilingual Sentiment Analysis of Summarized Texts: A Cross-Language Study of Text Shortening Effects(https://arxiv.org/abs/2504.00265)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Summarization significantly impacts sentiment analysis across languages with diverse morphologies. This study examines extractive and abstractive summarization effects on sentiment classification in English, German, French, Spanish, Italian, Finnish, Hungarian, and Arabic. We assess sentiment shifts post-summarization using multilingual transformers (mBERT, XLM-RoBERTa, T5, and BART) and language-specific models (FinBERT, AraBERT). Results show extractive summarization better preserves sentiment, especially in morphologically complex languages, while abstractive summarization improves readability but introduces sentiment distortion, affecting sentiment accuracy. Languages with rich inflectional morphology, such as Finnish, Hungarian, and Arabic, experience greater accuracy drops than English or German. Findings emphasize the need for language-specific adaptations in sentiment analysis and propose a hybrid summarization approach balancing readability and sentiment preservation. These insights benefit multilingual sentiment applications, including social media monitoring, market analysis, and cross-lingual opinion mining.</li>
</ul>

<h3>Title: Text Chunking for Document Classification for Urban System Management using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Joshua Rodriguez (1), Om Sanan (2), Guillermo Vizarreta-Luna (1), Steven A. Conrad (1) ((1) Department of Systems Engineering, Colorado State University, Fort Collins, CO, USA, (2) Scarsdale High School, Scardsale, NY, USA)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00274">https://arxiv.org/abs/2504.00274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00274">https://arxiv.org/pdf/2504.00274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00274]] Text Chunking for Document Classification for Urban System Management using Large Language Models(https://arxiv.org/abs/2504.00274)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Urban systems are managed using complex textual documentation that need coding and analysis to set requirements and evaluate built environment performance. This paper contributes to the study of applying large-language models (LLM) to qualitative coding activities to reduce resource requirements while maintaining comparable reliability to humans. Qualitative coding and assessment face challenges like resource limitations and bias, accuracy, and consistency between human evaluators. Here we report the application of LLMs to deductively code 10 case documents on the presence of 17 digital twin characteristics for the management of urban systems. We utilize two prompting methods to compare the semantic processing of LLMs with human coding efforts: whole text analysis and text chunk analysis using OpenAI's GPT-4o, GPT-4o-mini, and o1-mini models. We found similar trends of internal variability between methods and results indicate that LLMs may perform on par with human coders when initialized with specific deductive coding contexts. GPT-4o, o1-mini and GPT-4o-mini showed significant agreement with human raters when employed using a chunking method. The application of both GPT-4o and GPT-4o-mini as an additional rater with three manual raters showed statistically significant agreement across all raters, indicating that the analysis of textual documents is benefited by LLMs. Our findings reveal nuanced sub-themes of LLM application suggesting LLMs follow human memory coding processes where whole-text analysis may introduce multiple meanings. The novel contributions of this paper lie in assessing the performance of OpenAI GPT models and introduces the chunk-based prompting approach, which addresses context aggregation biases by preserving localized context.</li>
</ul>

<h3>Title: Federated Learning for Cross-Domain Data Privacy: A Distributed Approach to Secure Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Yiwei Zhang, Jie Liu, Jiawei Wang, Lu Dai, Fan Guo, Guohui Cai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00282">https://arxiv.org/abs/2504.00282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00282">https://arxiv.org/pdf/2504.00282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00282]] Federated Learning for Cross-Domain Data Privacy: A Distributed Approach to Secure Collaboration(https://arxiv.org/abs/2504.00282)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>This paper proposes a data privacy protection framework based on federated learning, which aims to realize effective cross-domain data collaboration under the premise of ensuring data privacy through distributed learning. Federated learning greatly reduces the risk of privacy breaches by training the model locally on each client and sharing only model parameters rather than raw data. The experiment verifies the high efficiency and privacy protection ability of federated learning under different data sources through the simulation of medical, financial, and user data. The results show that federated learning can not only maintain high model performance in a multi-domain data environment but also ensure effective protection of data privacy. The research in this paper provides a new technical path for cross-domain data collaboration and promotes the application of large-scale data analysis and machine learning while protecting privacy.</li>
</ul>

<h3>Title: Do Large Language Models Exhibit Spontaneous Rational Deception?</h3>
<ul>
<li><strong>Authors: </strong>Samuel M. Taylor, Benjamin K. Bergen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00285">https://arxiv.org/abs/2504.00285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00285">https://arxiv.org/pdf/2504.00285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00285]] Do Large Language Models Exhibit Spontaneous Rational Deception?(https://arxiv.org/abs/2504.00285)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are effective at deceiving, when prompted to do so. But under what conditions do they deceive spontaneously? Models that demonstrate better performance on reasoning tasks are also better at prompted deception. Do they also increasingly deceive spontaneously in situations where it could be considered rational to do so? This study evaluates spontaneous deception produced by LLMs in a preregistered experimental protocol using tools from signaling theory. A range of proprietary closed-source and open-source LLMs are evaluated using modified 2x2 games (in the style of Prisoner's Dilemma) augmented with a phase in which they can freely communicate to the other agent using unconstrained language. This setup creates an opportunity to deceive, in conditions that vary in how useful deception might be to an agent's rational self-interest. The results indicate that 1) all tested LLMs spontaneously misrepresent their actions in at least some conditions, 2) they are generally more likely to do so in situations in which deception would benefit them, and 3) models exhibiting better reasoning capacity overall tend to deceive at higher rates. Taken together, these results suggest a tradeoff between LLM reasoning capability and honesty. They also provide evidence of reasoning-like behavior in LLMs from a novel experimental configuration. Finally, they reveal certain contextual factors that affect whether LLMs will deceive or not. We discuss consequences for autonomous, human-facing systems driven by LLMs both now and as their reasoning capabilities continue to improve.</li>
</ul>

<h3>Title: A Deep Learning Approach to Anomaly Detection in High-Frequency Trading Data</h3>
<ul>
<li><strong>Authors: </strong>Qiuliuyang Bao, Jiawei Wang, Hao Gong, Yiwei Zhang, Xiaojun Guo, Hanrui Feng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00287">https://arxiv.org/abs/2504.00287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00287">https://arxiv.org/pdf/2504.00287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00287]] A Deep Learning Approach to Anomaly Detection in High-Frequency Trading Data(https://arxiv.org/abs/2504.00287)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper proposes an algorithm based on a staged sliding window Transformer architecture to detect abnormal behaviors in the microstructure of the foreign exchange market, focusing on high-frequency EUR/USD trading data. The method captures multi-scale temporal features through a staged sliding window, extracts global and local dependencies by combining the self-attention mechanism and weighted attention mechanism of the Transformer, and uses a classifier to identify abnormal events. Experimental results on a real high-frequency dataset containing order book depth, spread, and trading volume show that the proposed method significantly outperforms traditional machine learning (such as decision trees and random forests) and deep learning methods (such as MLP, CNN, RNN, LSTM) in terms of accuracy (0.93), F1-Score (0.91), and AUC-ROC (0.95). Ablation experiments verify the contribution of each component, and the visualization of order book depth and anomaly detection further reveals the effectiveness of the model under complex market dynamics. Despite the false positive problem, the model still provides important support for market supervision. In the future, noise processing can be optimized and extended to other markets to improve generalization and real-time performance.</li>
</ul>

<h3>Title: Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead</h3>
<ul>
<li><strong>Authors: </strong>Vidhisha Balachandran, Jingya Chen, Lingjiao Chen, Shivam Garg, Neel Joshi, Yash Lara, John Langford, Besmira Nushi, Vibhav Vineet, Yue Wu, Safoora Yousefi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00294">https://arxiv.org/abs/2504.00294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00294">https://arxiv.org/pdf/2504.00294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00294]] Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead(https://arxiv.org/abs/2504.00294)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inference-time scaling can enhance the reasoning capabilities of large language models (LLMs) on complex problems that benefit from step-by-step problem solving. Although lengthening generated scratchpads has proven effective for mathematical tasks, the broader impact of this approach on other tasks remains less clear. In this work, we investigate the benefits and limitations of scaling methods across nine state-of-the-art models and eight challenging tasks, including math and STEM reasoning, calendar planning, NP-hard problems, navigation, and spatial reasoning. We compare conventional models (e.g., GPT-4o) with models fine-tuned for inference-time scaling (e.g., o1) through evaluation protocols that involve repeated model calls, either independently or sequentially with feedback. These evaluations approximate lower and upper performance bounds and potential for future performance improvements for each model, whether through enhanced training or multi-model inference systems. Our extensive empirical analysis reveals that the advantages of inference-time scaling vary across tasks and diminish as problem complexity increases. In addition, simply using more tokens does not necessarily translate to higher accuracy in these challenging regimes. Results from multiple independent runs with conventional models using perfect verifiers show that, for some tasks, these models can achieve performance close to the average performance of today's most advanced reasoning models. However, for other tasks, a significant performance gap remains, even in very high scaling regimes. Encouragingly, all models demonstrate significant gains when inference is further scaled with perfect verifiers or strong feedback, suggesting ample potential for future improvements.</li>
</ul>

<h3>Title: Diffusion models for probabilistic precipitation generation from atmospheric variables</h3>
<ul>
<li><strong>Authors: </strong>Michael Aich, Sebastian Bathiany, Philipp Hess, Yu Huang, Niklas Boers</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00307">https://arxiv.org/abs/2504.00307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00307">https://arxiv.org/pdf/2504.00307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00307]] Diffusion models for probabilistic precipitation generation from atmospheric variables(https://arxiv.org/abs/2504.00307)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Improving the representation of precipitation in Earth system models (ESMs) is critical for assessing the impacts of climate change and especially of extreme events like floods and droughts. In existing ESMs, precipitation is not resolved explicitly, but represented by parameterizations. These typically rely on resolving approximated but computationally expensive column-based physics, not accounting for interactions between locations. They struggle to capture fine-scale precipitation processes and introduce significant biases. We present a novel approach, based on generative machine learning, which integrates a conditional diffusion model with a UNet architecture to generate accurate, high-resolution (0.25°) global daily precipitation fields from a small set of prognostic atmospheric variables. Unlike traditional parameterizations, our framework efficiently produces ensemble predictions, capturing uncertainties in precipitation, and does not require fine-tuning by hand. We train our model on the ERA5 reanalysis and present a method that allows us to apply it to arbitrary ESM data, enabling fast generation of probabilistic forecasts and climate scenarios. By leveraging interactions between global prognostic variables, our approach provides an alternative parameterization scheme that mitigates biases present in the ESM precipitation while maintaining consistency with its large-scale (annual) trends. This work demonstrates that complex precipitation patterns can be learned directly from large-scale atmospheric variables, offering a computationally efficient alternative to conventional schemes.</li>
</ul>

<h3>Title: FedPaI: Achieving Extreme Sparsity in Federated Learning via Pruning at Initialization</h3>
<ul>
<li><strong>Authors: </strong>Haonan Wang, Zeli Liu, Kajimusugura Hoshino, Tuo Zhang, John Paul Walters, Stephen Crago</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00308">https://arxiv.org/abs/2504.00308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00308">https://arxiv.org/pdf/2504.00308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00308]] FedPaI: Achieving Extreme Sparsity in Federated Learning via Pruning at Initialization(https://arxiv.org/abs/2504.00308)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables distributed training on edge devices but faces significant challenges due to resource constraints in edge environments, impacting both communication and computational efficiency. Existing iterative pruning techniques improve communication efficiency but are limited by their centralized design, which struggles with FL's decentralized and data-imbalanced nature, resulting in suboptimal sparsity levels. To address these issues, we propose FedPaI, a novel efficient FL framework that leverages Pruning at Initialization (PaI) to achieve extreme sparsity. FedPaI identifies optimal sparse connections at an early stage, maximizing model capacity and significantly reducing communication and computation overhead by fixing sparsity patterns at the start of training. To adapt to diverse hardware and software environments, FedPaI supports both structured and unstructured pruning. Additionally, we introduce personalized client-side pruning mechanisms for improved learning capacity and sparsity-aware server-side aggregation for enhanced efficiency. Experimental results demonstrate that FedPaI consistently outperforms existing efficient FL that applies conventional iterative pruning with significant leading in efficiency and model accuracy. For the first time, our proposed FedPaI achieves an extreme sparsity level of up to 98% without compromising the model accuracy compared to unpruned baselines, even under challenging non-IID settings. By employing our FedPaI with joint optimization of model learning capacity and sparsity, FL applications can benefit from faster convergence and accelerate the training by 6.4 to 7.9 times.</li>
</ul>

<h3>Title: Detecting and Mitigating Bias in LLMs through Knowledge Graph-Augmented Training</h3>
<ul>
<li><strong>Authors: </strong>Rajeev Kumar, Harishankar Kumar, Kumari Shalini</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00310">https://arxiv.org/abs/2504.00310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00310">https://arxiv.org/pdf/2504.00310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00310]] Detecting and Mitigating Bias in LLMs through Knowledge Graph-Augmented Training(https://arxiv.org/abs/2504.00310)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have revolutionized natural language processing with their surprising capability to understand and generate human-like text. However, many of these models inherit and further amplify the biases present in their training data, raising ethical and fairness concerns. The detection and mitigation of such biases are vital to ensuring that LLMs act responsibly and equitably across diverse domains. This work investigates Knowledge Graph-Augmented Training (KGAT) as a novel method to mitigate bias in LLM. Using structured domain-specific knowledge from real-world knowledge graphs, we improve the understanding of the model and reduce biased output. Public datasets for bias assessment include Gender Shades, Bias in Bios, and FairFace, while metrics such as demographic parity and equal opportunity facilitate rigorous detection. We also performed targeted mitigation strategies to correct biased associations, leading to a significant drop in biased output and improved bias metrics. Equipped with real-world datasets and knowledge graphs, our framework is both scalable and effective, paving the way toward responsible deployment in sensitive and high-stakes applications.</li>
</ul>

<h3>Title: SHIFT SNARE: Uncovering Secret Keys in FALCON via Single-Trace Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jinyi Qiu, Aydin Aysu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00320">https://arxiv.org/abs/2504.00320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00320">https://arxiv.org/pdf/2504.00320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00320]] SHIFT SNARE: Uncovering Secret Keys in FALCON via Single-Trace Analysis(https://arxiv.org/abs/2504.00320)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>This paper presents a novel single-trace side-channel attack on FALCON -- a lattice-based post-quantum digital signature protocol recently approved for standardization by NIST. We target the discrete Gaussian sampling operation within the FALCON key generation scheme and use a single power measurement trace to succeed. Notably, negating the `shift right 63-bit' operation (for 64-bit values) leaks critical information about the `-1' vs. `0' assignments to intermediate coefficients. These leaks enable full recovery of the generated secret keys. The proposed attack is implemented on an ARM Cortex-M4 microcontroller running both reference and optimized software implementations from FALCON's NIST Round 3 package. Statistical analysis with 500k tests reveals a per coefficient success rate of 99.9999999478% and a full key recovery success rate of 99.99994654% for FALCON-512. This work highlights the vulnerability of current software solutions to single-trace attacks and underscores the urgent need to develop single-trace resilient software for embedded systems.</li>
</ul>

<h3>Title: Simple yet Effective Node Property Prediction on Edge Streams under Distribution Shifts</h3>
<ul>
<li><strong>Authors: </strong>Jongha Lee, Taehyung Kwon, Heechan Moon, Kijung Shin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00328">https://arxiv.org/abs/2504.00328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00328">https://arxiv.org/pdf/2504.00328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00328]] Simple yet Effective Node Property Prediction on Edge Streams under Distribution Shifts(https://arxiv.org/abs/2504.00328)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The problem of predicting node properties (e.g., node classes) in graphs has received significant attention due to its broad range of applications. Graphs from real-world datasets often evolve over time, with newly emerging edges and dynamically changing node properties, posing a significant challenge for this problem. In response, temporal graph neural networks (TGNNs) have been developed to predict dynamic node properties from a stream of emerging edges. However, our analysis reveals that most TGNN-based methods are (a) far less effective without proper node features and, due to their complex model architectures, (b) vulnerable to distribution shifts. In this paper, we propose SPLASH, a simple yet powerful method for predicting node properties on edge streams under distribution shifts. Our key contributions are as follows: (1) we propose feature augmentation methods and an automatic feature selection method for edge streams, which improve the effectiveness of TGNNs, (2) we propose a lightweight MLP-based TGNN architecture that is highly efficient and robust under distribution shifts, and (3) we conduct extensive experiments to evaluate the accuracy, efficiency, generalization, and qualitative performance of the proposed method and its competitors on dynamic node classification, dynamic anomaly detection, and node affinity prediction tasks across seven real-world datasets.</li>
</ul>

<h3>Title: SeizureTransformer: Scaling U-Net with Transformer for Simultaneous Time-Step Level Seizure Detection from Long EEG Recordings</h3>
<ul>
<li><strong>Authors: </strong>Kerui Wu, Ziyue Zhao, Bülent Yener</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00336">https://arxiv.org/abs/2504.00336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00336">https://arxiv.org/pdf/2504.00336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00336]] SeizureTransformer: Scaling U-Net with Transformer for Simultaneous Time-Step Level Seizure Detection from Long EEG Recordings(https://arxiv.org/abs/2504.00336)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Epilepsy is a common neurological disorder that affects around 65 million people worldwide. Detecting seizures quickly and accurately is vital, given the prevalence and severity of the associated complications. Recently, deep learning-based automated seizure detection methods have emerged as solutions; however, most existing methods require extensive post-processing and do not effectively handle the crucial long-range patterns in EEG data. In this work, we propose SeizureTransformer, a simple model comprised of (i) a deep encoder comprising 1D convolutions (ii) a residual CNN stack and a transformer encoder to embed previous output into high-level representation with contextual information, and (iii) streamlined decoder which converts these features into a sequence of probabilities, directly indicating the presence or absence of seizures at every time step. Extensive experiments on public and private EEG seizure detection datasets demonstrate that our model significantly outperforms existing approaches (ranked in the first place in the 2025 "seizure detection challenge" organized in the International Conference on Artificial Intelligence in Epilepsy and Other Neurological Disorders), underscoring its potential for real-time, precise seizure detection.</li>
</ul>

<h3>Title: Agentic Multimodal AI for Hyperpersonalized B2B and B2C Advertising in Competitive Markets: An AI-Driven Competitive Advertising Framework</h3>
<ul>
<li><strong>Authors: </strong>Sakhinana Sagar Srinivas, Akash Das, Shivam Gupta, Venkataramana Runkana</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00338">https://arxiv.org/abs/2504.00338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00338">https://arxiv.org/pdf/2504.00338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00338]] Agentic Multimodal AI for Hyperpersonalized B2B and B2C Advertising in Competitive Markets: An AI-Driven Competitive Advertising Framework(https://arxiv.org/abs/2504.00338)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The growing use of foundation models (FMs) in real-world applications demands adaptive, reliable, and efficient strategies for dynamic markets. In the chemical industry, AI-discovered materials drive innovation, but commercial success hinges on market adoption, requiring FM-driven advertising frameworks that operate in-the-wild. We present a multilingual, multimodal AI framework for autonomous, hyper-personalized advertising in B2B and B2C markets. By integrating retrieval-augmented generation (RAG), multimodal reasoning, and adaptive persona-based targeting, our system generates culturally relevant, market-aware ads tailored to shifting consumer behaviors and competition. Validation combines real-world product experiments with a Simulated Humanistic Colony of Agents to model consumer personas, optimize strategies at scale, and ensure privacy compliance. Synthetic experiments mirror real-world scenarios, enabling cost-effective testing of ad strategies without risky A/B tests. Combining structured retrieval-augmented reasoning with in-context learning (ICL), the framework boosts engagement, prevents market cannibalization, and maximizes ROAS. This work bridges AI-driven innovation and market adoption, advancing multimodal FM deployment for high-stakes decision-making in commercial marketing.</li>
</ul>

<h3>Title: VNJPTranslate: A comprehensive pipeline for Vietnamese-Japanese translation</h3>
<ul>
<li><strong>Authors: </strong>Hoang Hai Phan, Nguyen Duc Minh Vu, Nam Dang Phuong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00339">https://arxiv.org/abs/2504.00339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00339">https://arxiv.org/pdf/2504.00339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00339]] VNJPTranslate: A comprehensive pipeline for Vietnamese-Japanese translation(https://arxiv.org/abs/2504.00339)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Neural Machine Translation (NMT) driven by Transformer architectures has advanced significantly, yet faces challenges with low-resource language pairs like Vietnamese-Japanese (Vi-Ja). Issues include sparse parallel data and handling linguistic/cultural nuances. Recent progress in Large Language Models (LLMs) with strong reasoning, often refined via Reinforcement Learning (RL), enables high-quality synthetic data generation. We introduce VNJPTranslate, a pipeline designed to systematically address the Vi-Ja translation task. It features a targeted data augmentation strategy using advanced LLMs with Chain-of-Thought prompting for challenging segments identified via corpus analysis. Subsequently, we employ efficient fine-tuning techniques (Unsloth with QLoRA) on a capable, low-parameter autoregressive model (specifically, a fine-tuned version of the 1.8B parameter Sailor model, which is based on the Qwen architecture) to create a practical and high-performing translation system. This integrated approach aims to improve Vi-Ja translation quality significantly over existing baselines.</li>
</ul>

<h3>Title: Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments</h3>
<ul>
<li><strong>Authors: </strong>Joshua Moore, Aly Sabri Abdalla, Prabesh Khanal, Vuk Marojevic</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00341">https://arxiv.org/abs/2504.00341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00341">https://arxiv.org/pdf/2504.00341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00341]] Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments(https://arxiv.org/abs/2504.00341)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, large language model</a></li>
<li><strong>Abstract: </strong>The Open Radio Access Network (O-RAN) architecture is reshaping telecommunications by promoting openness, flexibility, and intelligent closed-loop optimization. By decoupling hardware and software and enabling multi-vendor deployments, O-RAN reduces costs, enhances performance, and allows rapid adaptation to new technologies. A key innovation is intelligent network slicing, which partitions networks into isolated slices tailored for specific use cases or quality of service requirements. The RAN Intelligent Controller further optimizes resource allocation, ensuring efficient utilization and improved service quality for user equipment (UEs). However, the modular and dynamic nature of O-RAN expands the threat surface, necessitating advanced security measures to maintain network integrity, confidentiality, and availability. Intrusion detection systems have become essential for identifying and mitigating attacks. This research explores using large language models (LLMs) to generate security recommendations based on the temporal traffic patterns of connected UEs. The paper introduces an LLM-driven intrusion detection framework and demonstrates its efficacy through experimental deployments, comparing non fine-tuned and fine-tuned models for task-specific accuracy.</li>
</ul>

<h3>Title: Leveraging Large Language Models for Automated Definition Extraction with TaxoMatic A Case Study on Media Bias</h3>
<ul>
<li><strong>Authors: </strong>Timo Spinde, Luyang Lin, Smi Hinterreiter, Isao Echizen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00343">https://arxiv.org/abs/2504.00343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00343">https://arxiv.org/pdf/2504.00343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00343]] Leveraging Large Language Models for Automated Definition Extraction with TaxoMatic A Case Study on Media Bias(https://arxiv.org/abs/2504.00343)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces TaxoMatic, a framework that leverages large language models to automate definition extraction from academic literature. Focusing on the media bias domain, the framework encompasses data collection, LLM-based relevance classification, and extraction of conceptual definitions. Evaluated on a dataset of 2,398 manually rated articles, the study demonstrates the frameworks effectiveness, with Claude-3-sonnet achieving the best results in both relevance classification and definition extraction. Future directions include expanding datasets and applying TaxoMatic to additional domains.</li>
</ul>

<h3>Title: Reducing Smoothness with Expressive Memory Enhanced Hierarchical Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Thomas Bailie, Yun Sing Koh, S. Karthik Mukkavilli, Varvara Vetrova</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00349">https://arxiv.org/abs/2504.00349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00349">https://arxiv.org/pdf/2504.00349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00349]] Reducing Smoothness with Expressive Memory Enhanced Hierarchical Graph Neural Networks(https://arxiv.org/abs/2504.00349)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graphical forecasting models learn the structure of time series data via projecting onto a graph, with recent techniques capturing spatial-temporal associations between variables via edge weights. Hierarchical variants offer a distinct advantage by analysing the time series across multiple resolutions, making them particularly effective in tasks like global weather forecasting, where low-resolution variable interactions are significant. A critical challenge in hierarchical models is information loss during forward or backward passes through the hierarchy. We propose the Hierarchical Graph Flow (HiGFlow) network, which introduces a memory buffer variable of dynamic size to store previously seen information across variable resolutions. We theoretically show two key results: HiGFlow reduces smoothness when mapping onto new feature spaces in the hierarchy and non-strictly enhances the utility of message-passing by improving Weisfeiler-Lehman (WL) expressivity. Empirical results demonstrate that HiGFlow outperforms state-of-the-art baselines, including transformer models, by at least an average of 6.1% in MAE and 6.2% in RMSE. Code is available at this https URL this http URL.</li>
</ul>

<h3>Title: Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ting Liu, Siyuan Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00356">https://arxiv.org/abs/2504.00356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00356">https://arxiv.org/pdf/2504.00356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00356]] Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation(https://arxiv.org/abs/2504.00356)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in zero-shot referring image segmentation (RIS), driven by models such as the Segment Anything Model (SAM) and CLIP, have made substantial progress in aligning visual and textual information. Despite these successes, the extraction of precise and high-quality mask region representations remains a critical challenge, limiting the full potential of RIS tasks. In this paper, we introduce a training-free, hybrid global-local feature extraction approach that integrates detailed mask-specific features with contextual information from the surrounding area, enhancing mask region representation. To further strengthen alignment between mask regions and referring expressions, we propose a spatial guidance augmentation strategy that improves spatial coherence, which is essential for accurately localizing described areas. By incorporating multiple spatial cues, this approach facilitates more robust and precise referring segmentation. Extensive experiments on standard RIS benchmarks demonstrate that our method significantly outperforms existing zero-shot RIS models, achieving substantial performance gains. We believe our approach advances RIS tasks and establishes a versatile framework for region-text alignment, offering broader implications for cross-modal understanding and interaction. Code is available at this https URL .</li>
</ul>

<h3>Title: Spatiotemporal Attention Learning Framework for Event-Driven Object Recognition</h3>
<ul>
<li><strong>Authors: </strong>Tiantian Xie, Pengpai Wang, Rosa H. M. Chan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00370">https://arxiv.org/abs/2504.00370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00370">https://arxiv.org/pdf/2504.00370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00370]] Spatiotemporal Attention Learning Framework for Event-Driven Object Recognition(https://arxiv.org/abs/2504.00370)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Event-based vision sensors, inspired by biological neural systems, asynchronously capture local pixel-level intensity changes as a sparse event stream containing position, polarity, and timestamp information. These neuromorphic sensors offer significant advantages in dynamic range, latency, and power efficiency. Their working principle inherently addresses traditional camera limitations such as motion blur and redundant background information, making them particularly suitable for dynamic vision tasks. While recent works have proposed increasingly complex event-based architectures, the computational overhead and parameter complexity of these approaches limit their practical deployment. This paper presents a novel spatiotemporal learning framework for event-based object recognition, utilizing a VGG network enhanced with Convolutional Block Attention Module (CBAM). Our approach achieves comparable performance to state-of-the-art ResNet-based methods while reducing parameter count by 2.3% compared to the original VGG model. Specifically, it outperforms ResNet-based methods like MVF-Net, achieving the highest Top-1 accuracy of 76.4% (pretrained) and 71.3% (not pretrained) on CIFAR10-DVS, and 72.4% (not pretrained) on N-Caltech101. These results highlight the robustness of our method when pretrained weights are not used, making it suitable for scenarios where transfer learning is unavailable. Moreover, our approach reduces reliance on data augmentation. Experimental results on standard event-based datasets demonstrate the framework's efficiency and effectiveness for real-world applications.</li>
</ul>

<h3>Title: When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)</h3>
<ul>
<li><strong>Authors: </strong>Mahak Agarwal, Divyam Khanna</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00374">https://arxiv.org/abs/2504.00374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00374">https://arxiv.org/pdf/2504.00374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00374]] When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)(https://arxiv.org/abs/2504.00374)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In many real-world scenarios, a single Large Language Model (LLM) may encounter contradictory claims-some accurate, others forcefully incorrect-and must judge which is true. We investigate this risk in a single-turn, multi-agent debate framework: one LLM-based agent provides a factual answer from TruthfulQA, another vigorously defends a falsehood, and the same LLM architecture serves as judge. We introduce the Confidence-Weighted Persuasion Override Rate (CW-POR), which captures not only how often the judge is deceived but also how strongly it believes the incorrect choice. Our experiments on five open-source LLMs (3B-14B parameters), where we systematically vary agent verbosity (30-300 words), reveal that even smaller models can craft persuasive arguments that override truthful answers-often with high confidence. These findings underscore the importance of robust calibration and adversarial testing to prevent LLMs from confidently endorsing misinformation.</li>
</ul>

<h3>Title: CamoSAM2: Motion-Appearance Induced Auto-Refining Prompts for Video Camouflaged Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Xin Zhang, Keren Fu, Qijun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00375">https://arxiv.org/abs/2504.00375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00375">https://arxiv.org/pdf/2504.00375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00375]] CamoSAM2: Motion-Appearance Induced Auto-Refining Prompts for Video Camouflaged Object Detection(https://arxiv.org/abs/2504.00375)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model 2 (SAM2), a prompt-guided video foundation model, has remarkably performed in video object segmentation, drawing significant attention in the community. Due to the high similarity between camouflaged objects and their surroundings, which makes them difficult to distinguish even by the human eye, the application of SAM2 for automated segmentation in real-world scenarios faces challenges in camouflage perception and reliable prompts generation. To address these issues, we propose CamoSAM2, a motion-appearance prompt inducer (MAPI) and refinement framework to automatically generate and refine prompts for SAM2, enabling high-quality automatic detection and segmentation in VCOD task. Initially, we introduce a prompt inducer that simultaneously integrates motion and appearance cues to detect camouflaged objects, delivering more accurate initial predictions than existing methods. Subsequently, we propose a video-based adaptive multi-prompts refinement (AMPR) strategy tailored for SAM2, aimed at mitigating prompt error in initial coarse masks and further producing good prompts. Specifically, we introduce a novel three-step process to generate reliable prompts by camouflaged object determination, pivotal prompting frame selection, and multi-prompts formation. Extensive experiments conducted on two benchmark datasets demonstrate that our proposed model, CamoSAM2, significantly outperforms existing state-of-the-art methods, achieving increases of 8.0% and 10.1% in mIoU metric. Additionally, our method achieves the fastest inference speed compared to current VCOD models.</li>
</ul>

<h3>Title: Hierarchical Flow Diffusion for Efficient Frame Interpolation</h3>
<ul>
<li><strong>Authors: </strong>Yang Hai, Guo Wang, Tan Su, Wenjie Jiang, Yinlin Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00380">https://arxiv.org/abs/2504.00380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00380">https://arxiv.org/pdf/2504.00380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00380]] Hierarchical Flow Diffusion for Efficient Frame Interpolation(https://arxiv.org/abs/2504.00380)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Most recent diffusion-based methods still show a large gap compared to non-diffusion methods for video frame interpolation, in both accuracy and efficiency. Most of them formulate the problem as a denoising procedure in latent space directly, which is less effective caused by the large latent space. We propose to model bilateral optical flow explicitly by hierarchical diffusion models, which has much smaller search space in the denoising procedure. Based on the flow diffusion model, we then use a flow-guided images synthesizer to produce the final result. We train the flow diffusion model and the image synthesizer end to end. Our method achieves state of the art in accuracy, and 10+ times faster than other diffusion-based methods. The project page is at: this https URL.</li>
</ul>

<h3>Title: Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single Panoramic Image for Your Immerse Exploration</h3>
<ul>
<li><strong>Authors: </strong>Zilong Huang, Jun He, Junyan Ye, Lihan Jiang, Weijia Li, Yiping Chen, Ting Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00387">https://arxiv.org/abs/2504.00387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00387">https://arxiv.org/pdf/2504.00387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00387]] Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single Panoramic Image for Your Immerse Exploration(https://arxiv.org/abs/2504.00387)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>The reconstruction of immersive and realistic 3D scenes holds significant practical importance in various fields of computer vision and computer graphics. Typically, immersive and realistic scenes should be free from obstructions by dynamic objects, maintain global texture consistency, and allow for unrestricted exploration. The current mainstream methods for image-driven scene construction involves iteratively refining the initial image using a moving virtual camera to generate the scene. However, previous methods struggle with visual discontinuities due to global texture inconsistencies under varying camera poses, and they frequently exhibit scene voids caused by foreground-background occlusions. To this end, we propose a novel layered 3D scene reconstruction framework from panoramic image, named Scene4U. Specifically, Scene4U integrates an open-vocabulary segmentation model with a large language model to decompose a real panorama into multiple layers. Then, we employs a layered repair module based on diffusion model to restore occluded regions using visual cues and depth information, generating a hierarchical representation of the scene. The multi-layer panorama is then initialized as a 3D Gaussian Splatting representation, followed by layered optimization, which ultimately produces an immersive 3D scene with semantic and structural consistency that supports free exploration. Scene4U outperforms state-of-the-art method, improving by 24.24% in LPIPS and 24.40% in BRISQUE, while also achieving the fastest training speed. Additionally, to demonstrate the robustness of Scene4U and allow users to experience immersive scenes from various landmarks, we build WorldVista3D dataset for 3D scene reconstruction, which contains panoramic images of globally renowned sites. The implementation code and dataset will be released at this https URL .</li>
</ul>

<h3>Title: Beyond Wide-Angle Images: Unsupervised Video Portrait Correction via Spatiotemporal Diffusion Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Wenbo Nie, Lang Nie, Chunyu Lin, Jingwen Chen, Ke Xing, Jiyuan Wang, Yao Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00401">https://arxiv.org/abs/2504.00401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00401">https://arxiv.org/pdf/2504.00401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00401]] Beyond Wide-Angle Images: Unsupervised Video Portrait Correction via Spatiotemporal Diffusion Adaptation(https://arxiv.org/abs/2504.00401)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Wide-angle cameras, despite their popularity for content creation, suffer from distortion-induced facial stretching-especially at the edge of the lens-which degrades visual appeal. To address this issue, we propose an image portrait correction framework using diffusion models named ImagePD. It integrates the long-range awareness of transformer and multi-step denoising of diffusion models into a unified framework, achieving global structural robustness and local detail refinement. Besides, considering the high cost of obtaining video labels, we then repurpose ImagePD for unlabeled wide-angle videos (termed VideoPD), by spatiotemporal diffusion adaption with spatial consistency and temporal smoothness constraints. For the former, we encourage the denoised image to approximate pseudo labels following the wide-angle distortion distribution pattern, while for the latter, we derive rectification trajectories with backward optical flows and smooth them. Compared with ImagePD, VideoPD maintains high-quality facial corrections in space and mitigates the potential temporal shakes sequentially. Finally, to establish an evaluation benchmark and train the framework, we establish a video portrait dataset with a large diversity in people number, lighting conditions, and background. Experiments demonstrate that the proposed methods outperform existing solutions quantitatively and qualitatively, contributing to high-fidelity wide-angle videos with stable and natural portraits. The codes and dataset will be available.</li>
</ul>

<h3>Title: VerifiAgent: a Unified Verification Agent in Language Model Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jiuzhou Han, Wray Buntine, Ehsan Shareghi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00406">https://arxiv.org/abs/2504.00406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00406">https://arxiv.org/pdf/2504.00406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00406]] VerifiAgent: a Unified Verification Agent in Language Model Reasoning(https://arxiv.org/abs/2504.00406)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models demonstrate remarkable reasoning capabilities but often produce unreliable or incorrect responses. Existing verification methods are typically model-specific or domain-restricted, requiring significant computational resources and lacking scalability across diverse reasoning tasks. To address these limitations, we propose VerifiAgent, a unified verification agent that integrates two levels of verification: meta-verification, which assesses completeness and consistency in model responses, and tool-based adaptive verification, where VerifiAgent autonomously selects appropriate verification tools based on the reasoning type, including mathematical, logical, or commonsense reasoning. This adaptive approach ensures both efficiency and robustness across different verification scenarios. Experimental results show that VerifiAgent outperforms baseline verification methods (e.g., deductive verifier, backward verifier) among all reasoning tasks. Additionally, it can further enhance reasoning accuracy by leveraging feedback from verification results. VerifiAgent can also be effectively applied to inference scaling, achieving better results with fewer generated samples and costs compared to existing process reward models in the mathematical reasoning domain. Code is available at this https URL</li>
</ul>

<h3>Title: Semantic Mastery: Enhancing LLMs with Advanced Natural Language Understanding</h3>
<ul>
<li><strong>Authors: </strong>Mohanakrishnan Hariharan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00409">https://arxiv.org/abs/2504.00409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00409">https://arxiv.org/pdf/2504.00409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00409]] Semantic Mastery: Enhancing LLMs with Advanced Natural Language Understanding(https://arxiv.org/abs/2504.00409)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have greatly improved their capability in performing NLP tasks. However, deeper semantic understanding, contextual coherence, and more subtle reasoning are still difficult to obtain. The paper discusses state-of-the-art methodologies that advance LLMs with more advanced NLU techniques, such as semantic parsing, knowledge integration, and contextual reinforcement learning. We analyze the use of structured knowledge graphs, retrieval-augmented generation (RAG), and fine-tuning strategies that match models with human-level understanding. Furthermore, we address the incorporation of transformer-based architectures, contrastive learning, and hybrid symbolic-neural methods that address problems like hallucinations, ambiguity, and inconsistency in the factual perspectives involved in performing complex NLP tasks, such as question-answering text summarization and dialogue generation. Our findings show the importance of semantic precision for enhancing AI-driven language systems and suggest future research directions to bridge the gap between statistical language models and true natural language understanding.</li>
</ul>

<h3>Title: Forward Learning with Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Mingqian Feng, Zeliang Zhang, Jinyang Jiang, Yijie Peng, Chenliang Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00411">https://arxiv.org/abs/2504.00411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00411">https://arxiv.org/pdf/2504.00411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00411]] Forward Learning with Differential Privacy(https://arxiv.org/abs/2504.00411)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Differential privacy (DP) in deep learning is a critical concern as it ensures the confidentiality of training data while maintaining model utility. Existing DP training algorithms provide privacy guarantees by clipping and then injecting external noise into sample gradients computed by the backpropagation algorithm. Different from backpropagation, forward-learning algorithms based on perturbation inherently add noise during the forward pass and utilize randomness to estimate the gradients. Although these algorithms are non-privatized, the introduction of noise during the forward pass indirectly provides internal randomness protection to the model parameters and their gradients, suggesting the potential for naturally providing differential privacy. In this paper, we propose a \blue{privatized} forward-learning algorithm, Differential Private Unified Likelihood Ratio (DP-ULR), and demonstrate its differential privacy guarantees. DP-ULR features a novel batch sampling operation with rejection, of which we provide theoretical analysis in conjunction with classic differential privacy mechanisms. DP-ULR is also underpinned by a theoretically guided privacy controller that dynamically adjusts noise levels to manage privacy costs in each training step. Our experiments indicate that DP-ULR achieves competitive performance compared to traditional differential privacy training algorithms based on backpropagation, maintaining nearly the same privacy loss limits.</li>
</ul>

<h3>Title: Multimodal LLMs for OCR, OCR Post-Correction, and Named Entity Recognition in Historical Documents</h3>
<ul>
<li><strong>Authors: </strong>Gavin Greif, Niclas Griesshaber, Robin Greif</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00414">https://arxiv.org/abs/2504.00414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00414">https://arxiv.org/pdf/2504.00414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00414]] Multimodal LLMs for OCR, OCR Post-Correction, and Named Entity Recognition in Historical Documents(https://arxiv.org/abs/2504.00414)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We explore how multimodal Large Language Models (mLLMs) can help researchers transcribe historical documents, extract relevant historical information, and construct datasets from historical sources. Specifically, we investigate the capabilities of mLLMs in performing (1) Optical Character Recognition (OCR), (2) OCR Post-Correction, and (3) Named Entity Recognition (NER) tasks on a set of city directories published in German between 1754 and 1870. First, we benchmark the off-the-shelf transcription accuracy of both mLLMs and conventional OCR models. We find that the best-performing mLLM model significantly outperforms conventional state-of-the-art OCR models and other frontier mLLMs. Second, we are the first to introduce multimodal post-correction of OCR output using mLLMs. We find that this novel approach leads to a drastic improvement in transcription accuracy and consistently produces highly accurate transcriptions (<1% CER), without any image pre-processing or model fine-tuning. Third, we demonstrate that mLLMs can efficiently recognize entities in transcriptions of historical documents and parse them into structured dataset formats. Our findings provide early evidence for the long-term potential of mLLMs to introduce a paradigm shift in the approaches to historical data collection and document transcription.</li>
</ul>

<h3>Title: Can LLMs Assist Computer Education? an Empirical Case Study of DeepSeek</h3>
<ul>
<li><strong>Authors: </strong>Dongfu Xiao, Chen Gao, Zhengquan Luo, Chi Liu, Sheng Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00421">https://arxiv.org/abs/2504.00421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00421">https://arxiv.org/pdf/2504.00421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00421]] Can LLMs Assist Computer Education? an Empirical Case Study of DeepSeek(https://arxiv.org/abs/2504.00421)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>This study presents an empirical case study to assess the efficacy and reliability of DeepSeek-V3, an emerging large language model, within the context of computer education. The evaluation employs both CCNA simulation questions and real-world inquiries concerning computer network security posed by Chinese network engineers. To ensure a thorough evaluation, diverse dimensions are considered, encompassing role dependency, cross-linguistic proficiency, and answer reproducibility, accompanied by statistical analysis. The findings demonstrate that the model performs consistently, regardless of whether prompts include a role definition or not. In addition, its adaptability across languages is confirmed by maintaining stable accuracy in both original and translated datasets. A distinct contrast emerges between its performance on lower-order factual recall tasks and higher-order reasoning exercises, which underscores its strengths in retrieving information and its limitations in complex analytical tasks. Although DeepSeek-V3 offers considerable practical value for network security education, challenges remain in its capability to process multimodal data and address highly intricate topics. These results provide valuable insights for future refinement of large language models in specialized professional environments.</li>
</ul>

<h3>Title: LLM-Assisted Proactive Threat Intelligence for Automated Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Shuva Paul, Farhad Alemi, Richard Macwan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00428">https://arxiv.org/abs/2504.00428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00428">https://arxiv.org/pdf/2504.00428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00428]] LLM-Assisted Proactive Threat Intelligence for Automated Reasoning(https://arxiv.org/abs/2504.00428)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, robust, large language model</a></li>
<li><strong>Abstract: </strong>Successful defense against dynamically evolving cyber threats requires advanced and sophisticated techniques. This research presents a novel approach to enhance real-time cybersecurity threat detection and response by integrating large language models (LLMs) and Retrieval-Augmented Generation (RAG) systems with continuous threat intelligence feeds. Leveraging recent advancements in LLMs, specifically GPT-4o, and the innovative application of RAG techniques, our approach addresses the limitations of traditional static threat analysis by incorporating dynamic, real-time data sources. We leveraged RAG to get the latest information in real-time for threat intelligence, which is not possible in the existing GPT-4o model. We employ the Patrowl framework to automate the retrieval of diverse cybersecurity threat intelligence feeds, including Common Vulnerabilities and Exposures (CVE), Common Weakness Enumeration (CWE), Exploit Prediction Scoring System (EPSS), and Known Exploited Vulnerabilities (KEV) databases, and integrate these with the all-mpnet-base-v2 model for high-dimensional vector embeddings, stored and queried in Milvus. We demonstrate our system's efficacy through a series of case studies, revealing significant improvements in addressing recently disclosed vulnerabilities, KEVs, and high-EPSS-score CVEs compared to the baseline GPT-4o. This work not only advances the role of LLMs in cybersecurity but also establishes a robust foundation for the development of automated intelligent cyberthreat information management systems, addressing crucial gaps in current cybersecurity practices.</li>
</ul>

<h3>Title: Unleashing the Power of Pre-trained Encoders for Universal Adversarial Attack Detection</h3>
<ul>
<li><strong>Authors: </strong>Yinghe Zhang, Chi Liu, Shuai Zhou, Sheng Shen, Peng Gui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00429">https://arxiv.org/abs/2504.00429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00429">https://arxiv.org/pdf/2504.00429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00429]] Unleashing the Power of Pre-trained Encoders for Universal Adversarial Attack Detection(https://arxiv.org/abs/2504.00429)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial attacks pose a critical security threat to real-world AI systems by injecting human-imperceptible perturbations into benign samples to induce misclassification in deep learning models. While existing detection methods, such as Bayesian uncertainty estimation and activation pattern analysis, have achieved progress through feature engineering, their reliance on handcrafted feature design and prior knowledge of attack patterns limits generalization capabilities and incurs high engineering costs. To address these limitations, this paper proposes a lightweight adversarial detection framework based on the large-scale pre-trained vision-language model CLIP. Departing from conventional adversarial feature characterization paradigms, we innovatively adopt an anomaly detection perspective. By jointly fine-tuning CLIP's dual visual-text encoders with trainable adapter networks and learnable prompts, we construct a compact representation space tailored for natural images. Notably, our detection architecture achieves substantial improvements in generalization capability across both known and unknown attack patterns compared to traditional methods, while significantly reducing training overhead. This study provides a novel technical pathway for establishing a parameter-efficient and attack-agnostic defense paradigm, markedly enhancing the robustness of vision systems against evolving adversarial threats.</li>
</ul>

<h3>Title: Data Synthesis with Diverse Styles for Face Recognition via 3DMM-Guided Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yuxi Mi, Zhizhou Zhong, Yuge Huang, Qiuyang Yuan, Xuan Zhao, Jianqing Xu, Shouhong Ding, ShaoMing Wang, Rizen Guo, Shuigeng Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00430">https://arxiv.org/abs/2504.00430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00430">https://arxiv.org/pdf/2504.00430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00430]] Data Synthesis with Diverse Styles for Face Recognition via 3DMM-Guided Diffusion(https://arxiv.org/abs/2504.00430)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Identity-preserving face synthesis aims to generate synthetic face images of virtual subjects that can substitute real-world data for training face recognition models. While prior arts strive to create images with consistent identities and diverse styles, they face a trade-off between them. Identifying their limitation of treating style variation as subject-agnostic and observing that real-world persons actually have distinct, subject-specific styles, this paper introduces MorphFace, a diffusion-based face generator. The generator learns fine-grained facial styles, e.g., shape, pose and expression, from the renderings of a 3D morphable model (3DMM). It also learns identities from an off-the-shelf recognition model. To create virtual faces, the generator is conditioned on novel identities of unlabeled synthetic faces, and novel styles that are statistically sampled from a real-world prior distribution. The sampling especially accounts for both intra-subject variation and subject distinctiveness. A context blending strategy is employed to enhance the generator's responsiveness to identity and style conditions. Extensive experiments show that MorphFace outperforms the best prior arts in face recognition efficacy.</li>
</ul>

<h3>Title: Enhancing Fundus Image-based Glaucoma Screening via Dynamic Global-Local Feature Integration</h3>
<ul>
<li><strong>Authors: </strong>Yuzhuo Zhou, Chi Liu, Sheng Shen, Siyu Le, Liwen Yu, Sihan Ouyang, Zongyuan Ge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00431">https://arxiv.org/abs/2504.00431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00431">https://arxiv.org/pdf/2504.00431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00431]] Enhancing Fundus Image-based Glaucoma Screening via Dynamic Global-Local Feature Integration(https://arxiv.org/abs/2504.00431)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>With the advancements in medical artificial intelligence (AI), fundus image classifiers are increasingly being applied to assist in ophthalmic diagnosis. While existing classification models have achieved high accuracy on specific fundus datasets, they struggle to address real-world challenges such as variations in image quality across different imaging devices, discrepancies between training and testing images across different racial groups, and the uncertain boundaries due to the characteristics of glaucomatous cases. In this study, we aim to address the above challenges posed by image variations by highlighting the importance of incorporating comprehensive fundus image information, including the optic cup (OC) and optic disc (OD) regions, and other key image patches. Specifically, we propose a self-adaptive attention window that autonomously determines optimal boundaries for enhanced feature extraction. Additionally, we introduce a multi-head attention mechanism to effectively fuse global and local features via feature linear readout, improving the model's discriminative capability. Experimental results demonstrate that our method achieves superior accuracy and robustness in glaucoma classification.</li>
</ul>

<h3>Title: HERA: Hybrid Edge-cloud Resource Allocation for Cost-Efficient AI Agents</h3>
<ul>
<li><strong>Authors: </strong>Shiyi Liu, Haiying Shen, Shuai Che, Mahdi Ghandi, Mingqin Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00434">https://arxiv.org/abs/2504.00434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00434">https://arxiv.org/pdf/2504.00434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00434]] HERA: Hybrid Edge-cloud Resource Allocation for Cost-Efficient AI Agents(https://arxiv.org/abs/2504.00434)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the realm of AI, large language models (LLMs) like GPT-4, central to the operation of AI agents, predominantly operate in the cloud, incurring high operational costs. With local-based small language models (SLMs) becoming more accurate, the necessity of cloud-exclusive processing is being reconsidered. An AI agent's response to a user's request comprises a series of subtasks or iterations. Existing approaches only allocate a single request between SLM and LLM to ensure their outputs are similar, but adopting this approach in the AI agent scenario for assigning each subtask is not effective since SLM will output a different subsequent subtask, which affects the accuracy of the final output. In this paper, we first conduct experimental analysis to understand the features of AI agent operations. Leveraging our findings, we propose the Adaptive Iteration-level Model Selector (AIMS), a lightweight scheduler to automatically partition AI agent's subtasks between local-based SLM and cloud-based LLM. AIMS considers the varying subtask features and strategically decides the location for each subtask in order to use SLM as much as possible while attaining the accuracy level. Our experimental results demonstrate that AIMS increases accuracy by up to 9.1% and SLM usage by up to 10.8% compared to HybridLLM. It offloads 45.67% of subtasks to a local SLM while attaining similar accuracy on average compared with the cloud-only LLM approach.</li>
</ul>

<h3>Title: FingerSlid: Towards Finger-Sliding Continuous Authentication on Smart Devices Via Vibration</h3>
<ul>
<li><strong>Authors: </strong>Yadong Xie, Fan Li, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00436">https://arxiv.org/abs/2504.00436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00436">https://arxiv.org/pdf/2504.00436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00436]] FingerSlid: Towards Finger-Sliding Continuous Authentication on Smart Devices Via Vibration(https://arxiv.org/abs/2504.00436)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, attack, biometric</a></li>
<li><strong>Abstract: </strong>Nowadays, mobile smart devices are widely used in daily life. It is increasingly important to prevent malicious users from accessing private data, thus a secure and convenient authentication method is urgently needed. Compared with common one-off authentication (e.g., password, face recognition, and fingerprint), continuous authentication can provide constant privacy protection. However, most studies are based on behavioral features and vulnerable to spoofing attacks. To solve this problem, we study the unique influence of sliding fingers on active vibration signals, and further propose an authentication system, FingerSlid, which uses vibration motors and accelerometers in mobile devices to sense biometric features of sliding fingers to achieve behavior-independent continuous authentication. First, we design two kinds of active vibration signals and propose a novel signal generation mechanism to improve the anti-attack ability of FingerSlid. Then, we extract different biometric features from the received two kinds of signals, and eliminate the influence of behavioral features in biometric features using a carefully designed Triplet network. Last, user authentication is performed by using the generated behavior-independent biometric features. FingerSlid is evaluated through a large number of experiments under different scenarios, and it achieves an average accuracy of 95.4% and can resist 99.5% of attacks.</li>
</ul>

<h3>Title: Suite-IN++: A FlexiWear BodyNet Integrating Global and Local Motion Features from Apple Suite for Robust Inertial Navigation</h3>
<ul>
<li><strong>Authors: </strong>Lan Sun, Songpengcheng Xia, Jiarui Yang, Ling Pei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00438">https://arxiv.org/abs/2504.00438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00438">https://arxiv.org/pdf/2504.00438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00438]] Suite-IN++: A FlexiWear BodyNet Integrating Global and Local Motion Features from Apple Suite for Robust Inertial Navigation(https://arxiv.org/abs/2504.00438)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The proliferation of wearable technology has established multi-device ecosystems comprising smartphones, smartwatches, and headphones as critical enablers for ubiquitous pedestrian localization. However, traditional pedestrian dead reckoning (PDR) struggles with diverse motion modes, while data-driven methods, despite improving accuracy, often lack robustness due to their reliance on a single-device setup. Therefore, a promising solution is to fully leverage existing wearable devices to form a flexiwear bodynet for robust and accurate pedestrian localization. This paper presents Suite-IN++, a deep learning framework for flexiwear bodynet-based pedestrian localization. Suite-IN++ integrates motion data from wearable devices on different body parts, using contrastive learning to separate global and local motion features. It fuses global features based on the data reliability of each device to capture overall motion trends and employs an attention mechanism to uncover cross-device correlations in local features, extracting motion details helpful for accurate localization. To evaluate our method, we construct a real-life flexiwear bodynet dataset, incorporating Apple Suite (iPhone, Apple Watch, and AirPods) across diverse walking modes and device configurations. Experimental results demonstrate that Suite-IN++ achieves superior localization accuracy and robustness, significantly outperforming state-of-the-art models in real-life pedestrian tracking scenarios.</li>
</ul>

<h3>Title: No Free Lunch with Guardrails</h3>
<ul>
<li><strong>Authors: </strong>Divyanshu Kumar, Nitin Aravind Birur, Tanay Baswa, Sahil Agarwal, Prashanth Harshangi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00441">https://arxiv.org/abs/2504.00441</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00441">https://arxiv.org/pdf/2504.00441</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00441]] No Free Lunch with Guardrails(https://arxiv.org/abs/2504.00441)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, generative, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) and generative AI become widely adopted, guardrails have emerged as a key tool to ensure their safe use. However, adding guardrails isn't without tradeoffs; stronger security measures can reduce usability, while more flexible systems may leave gaps for adversarial attacks. In this work, we explore whether current guardrails effectively prevent misuse while maintaining practical utility. We introduce a framework to evaluate these tradeoffs, measuring how different guardrails balance risk, security, and usability, and build an efficient guardrail. Our findings confirm that there is no free lunch with guardrails; strengthening security often comes at the cost of usability. To address this, we propose a blueprint for designing better guardrails that minimize risk while maintaining usability. We evaluate various industry guardrails, including Azure Content Safety, Bedrock Guardrails, OpenAI's Moderation API, Guardrails AI, Nemo Guardrails, and our own custom-built guardrails. Additionally, we assess how LLMs like GPT-4o, Gemini 2.0-Flash, Claude 3.5-Sonnet, and Mistral Large-Latest respond under different system prompts, including simple prompts, detailed prompts, and detailed prompts with chain-of-thought (CoT) reasoning. Our study provides a clear comparison of how different guardrails perform, highlighting the challenges in balancing security and usability.</li>
</ul>

<h3>Title: Exposing the Ghost in the Transformer: Abnormal Detection for Large Language Models via Hidden State Forensics</h3>
<ul>
<li><strong>Authors: </strong>Shide Zhou, Kailong Wang, Ling Shi, Haoyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00446">https://arxiv.org/abs/2504.00446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00446">https://arxiv.org/pdf/2504.00446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00446]] Exposing the Ghost in the Transformer: Abnormal Detection for Large Language Models via Hidden State Forensics(https://arxiv.org/abs/2504.00446)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>The widespread adoption of Large Language Models (LLMs) in critical applications has introduced severe reliability and security risks, as LLMs remain vulnerable to notorious threats such as hallucinations, jailbreak attacks, and backdoor exploits. These vulnerabilities have been weaponized by malicious actors, leading to unauthorized access, widespread misinformation, and compromised LLM-embedded system integrity. In this work, we introduce a novel approach to detecting abnormal behaviors in LLMs via hidden state forensics. By systematically inspecting layer-specific activation patterns, we develop a unified framework that can efficiently identify a range of security threats in real-time without imposing prohibitive computational costs. Extensive experiments indicate detection accuracies exceeding 95% and consistently robust performance across multiple models in most scenarios, while preserving the ability to detect novel attacks effectively. Furthermore, the computational overhead remains minimal, with merely fractions of a second. The significance of this work lies in proposing a promising strategy to reinforce the security of LLM-integrated systems, paving the way for safer and more reliable deployment in high-stakes domains. By enabling real-time detection that can also support the mitigation of abnormal behaviors, it represents a meaningful step toward ensuring the trustworthiness of AI systems amid rising security challenges.</li>
</ul>

<h3>Title: FA^{3}-CLIP: Frequency-Aware Cues Fusion and Attack-Agnostic Prompt Learning for Unified Face Attack Detection</h3>
<ul>
<li><strong>Authors: </strong>Yongze Li, Ning Li, Ajian Liu, Hui Ma, Liying Yang, Xihong Chen, Zhiyao Liang, Yanyan Liang, Jun Wan, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00454">https://arxiv.org/abs/2504.00454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00454">https://arxiv.org/pdf/2504.00454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00454]] FA^{3}-CLIP: Frequency-Aware Cues Fusion and Attack-Agnostic Prompt Learning for Unified Face Attack Detection(https://arxiv.org/abs/2504.00454)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Facial recognition systems are vulnerable to physical (e.g., printed photos) and digital (e.g., DeepFake) face attacks. Existing methods struggle to simultaneously detect physical and digital attacks due to: 1) significant intra-class variations between these attack types, and 2) the inadequacy of spatial information alone to comprehensively capture live and fake cues. To address these issues, we propose a unified attack detection model termed Frequency-Aware and Attack-Agnostic CLIP (FA\textsuperscript{3}-CLIP), which introduces attack-agnostic prompt learning to express generic live and fake cues derived from the fusion of spatial and frequency features, enabling unified detection of live faces and all categories of attacks. Specifically, the attack-agnostic prompt module generates generic live and fake prompts within the language branch to extract corresponding generic representations from both live and fake faces, guiding the model to learn a unified feature space for unified attack detection. Meanwhile, the module adaptively generates the live/fake conditional bias from the original spatial and frequency information to optimize the generic prompts accordingly, reducing the impact of intra-class variations. We further propose a dual-stream cues fusion framework in the vision branch, which leverages frequency information to complement subtle cues that are difficult to capture in the spatial domain. In addition, a frequency compression block is utilized in the frequency stream, which reduces redundancy in frequency features while preserving the diversity of crucial cues. We also establish new challenging protocols to facilitate unified face attack detection effectiveness. Experimental results demonstrate that the proposed method significantly improves performance in detecting physical and digital face attacks, achieving state-of-the-art results.</li>
</ul>

<h3>Title: Distilling Multi-view Diffusion Models into 3D Generators</h3>
<ul>
<li><strong>Authors: </strong>Hao Qin, Luyuan Chen, Ming Kong, Mengxu Lu, Qiang Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00457">https://arxiv.org/abs/2504.00457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00457">https://arxiv.org/pdf/2504.00457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00457]] Distilling Multi-view Diffusion Models into 3D Generators(https://arxiv.org/abs/2504.00457)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>We introduce DD3G, a formulation that Distills a multi-view Diffusion model (MV-DM) into a 3D Generator using gaussian splatting. DD3G compresses and integrates extensive visual and spatial geometric knowledge from the MV-DM by simulating its ordinary differential equation (ODE) trajectory, ensuring the distilled generator generalizes better than those trained solely on 3D data. Unlike previous amortized optimization approaches, we align the MV-DM and 3D generator representation spaces to transfer the teacher's probabilistic flow to the student, thus avoiding inconsistencies in optimization objectives caused by probabilistic sampling. The introduction of probabilistic flow and the coupling of various attributes in 3D Gaussians introduce challenges in the generation process. To tackle this, we propose PEPD, a generator consisting of Pattern Extraction and Progressive Decoding phases, which enables efficient fusion of probabilistic flow and converts a single image into 3D Gaussians within 0.06 seconds. Furthermore, to reduce knowledge loss and overcome sparse-view supervision, we design a joint optimization objective that ensures the quality of generated samples through explicit supervision and implicit verification. Leveraging existing 2D generation models, we compile 120k high-quality RGBA images for distillation. Experiments on synthetic and public datasets demonstrate the effectiveness of our method. Our project is available at: this https URL</li>
</ul>

<h3>Title: Mixture-of-Attack-Experts with Class Regularization for Unified Physical-Digital Face Attack Detection</h3>
<ul>
<li><strong>Authors: </strong>Shunxin Chen, Ajian Liu, Junze Zheng, Jun Wan, Kailai Peng, Sergio Escalera, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00458">https://arxiv.org/abs/2504.00458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00458">https://arxiv.org/pdf/2504.00458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00458]] Mixture-of-Attack-Experts with Class Regularization for Unified Physical-Digital Face Attack Detection(https://arxiv.org/abs/2504.00458)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Facial recognition systems in real-world scenarios are susceptible to both digital and physical attacks. Previous methods have attempted to achieve classification by learning a comprehensive feature space. However, these methods have not adequately accounted for the inherent characteristics of physical and digital attack data, particularly the large intra class variation in attacks and the small inter-class variation between live and fake faces. To address these limitations, we propose the Fine-Grained MoE with Class-Aware Regularization CLIP framework (FG-MoE-CLIP-CAR), incorporating key improvements at both the feature and loss levels. At the feature level, we employ a Soft Mixture of Experts (Soft MoE) architecture to leverage different experts for specialized feature processing. Additionally, we refine the Soft MoE to capture more subtle differences among various types of fake faces. At the loss level, we introduce two constraint modules: the Disentanglement Module (DM) and the Cluster Distillation Module (CDM). The DM enhances class separability by increasing the distance between the centers of live and fake face classes. However, center-to-center constraints alone are insufficient to ensure distinctive representations for individual features. Thus, we propose the CDM to further cluster features around their respective class centers while maintaining separation from other classes. Moreover, specific attacks that significantly deviate from common attack patterns are often overlooked. To address this issue, our distance calculation prioritizes more distant features. Experimental results on two unified physical-digital attack datasets demonstrate that the proposed method achieves state-of-the-art (SOTA) performance.</li>
</ul>

<h3>Title: Exploring the Collaborative Advantage of Low-level Information on Generalizable AI-Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Ziyin Zhou, Ke Sun, Zhongxi Chen, Xianming Lin, Yunpeng Luo, Ke Yan, Shouhong Ding, Xiaoshuai Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00463">https://arxiv.org/abs/2504.00463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00463">https://arxiv.org/pdf/2504.00463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00463]] Exploring the Collaborative Advantage of Low-level Information on Generalizable AI-Generated Image Detection(https://arxiv.org/abs/2504.00463)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Existing state-of-the-art AI-Generated image detection methods mostly consider extracting low-level information from RGB images to help improve the generalization of AI-Generated image detection, such as noise patterns. However, these methods often consider only a single type of low-level information, which may lead to suboptimal generalization. Through empirical analysis, we have discovered a key insight: different low-level information often exhibits generalization capabilities for different types of forgeries. Furthermore, we found that simple fusion strategies are insufficient to leverage the detection advantages of each low-level and high-level information for various forgery types. Therefore, we propose the Adaptive Low-level Experts Injection (ALEI) framework. Our approach introduces Lora Experts, enabling the backbone network, which is trained with high-level semantic RGB images, to accept and learn knowledge from different low-level information. We utilize a cross-attention method to adaptively fuse these features at intermediate layers. To prevent the backbone network from losing the modeling capabilities of different low-level features during the later stages of modeling, we developed a Low-level Information Adapter that interacts with the features extracted by the backbone network. Finally, we propose Dynamic Feature Selection, which dynamically selects the most suitable features for detecting the current image to maximize generalization detection capability. Extensive experiments demonstrate that our method, finetuned on only four categories of mainstream ProGAN data, performs excellently and achieves state-of-the-art results on multiple datasets containing unseen GAN and Diffusion methods.</li>
</ul>

<h3>Title: Informed Greedy Algorithm for Scalable Bayesian Network Fusion via Minimum Cut Analysis</h3>
<ul>
<li><strong>Authors: </strong>Pablo Torrijos, José M. Puerta, José A. Gámez, Juan A. Aledo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00467">https://arxiv.org/abs/2504.00467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00467">https://arxiv.org/pdf/2504.00467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00467]] Informed Greedy Algorithm for Scalable Bayesian Network Fusion via Minimum Cut Analysis(https://arxiv.org/abs/2504.00467)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>This paper presents the Greedy Min-Cut Bayesian Consensus (GMCBC) algorithm for the structural fusion of Bayesian Networks (BNs). The method is designed to preserve essential dependencies while controlling network complexity. It addresses the limitations of traditional fusion approaches, which often lead to excessively complex models that are impractical for inference, reasoning, or real-world applications. As the number and size of input networks increase, this issue becomes even more pronounced. GMCBC integrates principles from flow network theory into BN fusion, adapting the Backward Equivalence Search (BES) phase of the Greedy Equivalence Search (GES) algorithm and applying the Ford-Fulkerson algorithm for minimum cut analysis. This approach removes non-essential edges, ensuring that the fused network retains key dependencies while minimizing unnecessary complexity. Experimental results on synthetic Bayesian Networks demonstrate that GMCBC achieves near-optimal network structures. In federated learning simulations, GMCBC produces a consensus network that improves structural accuracy and dependency preservation compared to the average of the input networks, resulting in a structure that better captures the real underlying (in)dependence relationships. This consensus network also maintains a similar size to the original networks, unlike unrestricted fusion methods, where network size grows exponentially.</li>
</ul>

<h3>Title: Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ruoxi Xu, Yunjie Ji, Boxi Cao, Yaojie Lu, Hongyu Lin, Xianpei Han, Ben He, Yingfei Sun, Xiangang Li, Le Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00472">https://arxiv.org/abs/2504.00472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00472">https://arxiv.org/pdf/2504.00472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00472]] Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning(https://arxiv.org/abs/2504.00472)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although large language models (LLMs) excel in knowledge recall and reasoning, their static nature leads to outdated information as the real world evolves or when adapting to domain-specific knowledge, highlighting the need for effective knowledge injection. However, current research on knowledge injection remains superficial, mainly focusing on knowledge memorization and retrieval. This paper proposes a four-tier knowledge injection framework that systematically defines the levels of knowledge injection: memorization, retrieval, reasoning, and association. Based on this framework, we introduce DeepKnowledge, a synthetic experimental testbed designed for fine-grained evaluation of the depth of knowledge injection across three knowledge types (novel, incremental, and updated). We then explore various knowledge injection scenarios and evaluate the depth of knowledge injection for each scenario on the benchmark. Experimental results reveal key factors to reach each level of knowledge injection for LLMs and establish a mapping between the levels of knowledge injection and the corresponding suitable injection methods, aiming to provide a comprehensive approach for efficient knowledge injection across various levels.</li>
</ul>

<h3>Title: Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences</h3>
<ul>
<li><strong>Authors: </strong>Xiangyang Liu, Junliang He, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00473">https://arxiv.org/abs/2504.00473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00473">https://arxiv.org/pdf/2504.00473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00473]] Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences(https://arxiv.org/abs/2504.00473)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can perform complex reasoning by generating intermediate thoughts under zero-shot or few-shot settings. However, zero-shot prompting always encounters low performance, and the superior performance of few-shot prompting hinges on the manual-crafted demonstrations. In this paper, we present RoSE (Reasoning with Orchestrated Streaming Experiences), a general framework for solving reasoning tasks that can self-improve without complex external efforts. To enable RoSE, we describe an architecture that extends an LLM to store all answered questions and their thoughts in a streaming experience pool then orchestrates helpful questions from the pool to assist in answering new questions. To set up a question-aware orchestration mechanism, RoSE first calculates the similarity of each question in the pool with a new test question. Since the solution to each answered question is not always correct, RoSE will sort the questions according to their similarity with the new question, and then uniformly divide them into multiple buckets. It finally extracts one question from each bucket to make these extracted questions more diverse. To make these extracted questions help RoSE answer new questions as much as possible, we introduce two other attributes of uncertainty and complexity for each question. RoSE will preferentially select the questions with low uncertainty and high complexity from each bucket. We evaluate the versatility of RoSE in various reasoning tasks, LLMs, and CoT methods.</li>
</ul>

<h3>Title: 4th PVUW MeViS 3rd Place Report: Sa2VA</h3>
<ul>
<li><strong>Authors: </strong>Haobo Yuan, Tao Zhang, Xiangtai Li, Lu Qi, Zilong Huang, Shilin Xu, Jiashi Feng, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00476">https://arxiv.org/abs/2504.00476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00476">https://arxiv.org/pdf/2504.00476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00476]] 4th PVUW MeViS 3rd Place Report: Sa2VA(https://arxiv.org/abs/2504.00476)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Referring video object segmentation (RVOS) is a challenging task that requires the model to segment the object in a video given the language description. MeViS is a recently proposed dataset that contains motion expressions of the target objects, leading to a challenging benchmark, compared with existing RVOS benchmarks. On the other hand, for referring expression tasks, a new trend is to adopt multi-modal large language model (MLLM) to achieve better image and text alignment. In this report, we show that with a simple modification to the test time inference method on stronger MLLMs, we can lead to stronger results on MeVIS. In particular, we adopt the recent method Sa2VA, a unified model for dense grounded understanding of both images and videos. By enlarging the scope of key frames, without any further training, we can achieve the 3rd place in the 4th PVUW workshop.</li>
</ul>

<h3>Title: FSSUWNet: Mitigating the Fragility of Pre-trained Models with Feature Enhancement for Few-Shot Semantic Segmentation in Underwater Images</h3>
<ul>
<li><strong>Authors: </strong>Zhuohao Li, Zhicheng Huang, Wenchao Liu, Zhuxing Zhang, Jianming Miao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00478">https://arxiv.org/abs/2504.00478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00478">https://arxiv.org/pdf/2504.00478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00478]] FSSUWNet: Mitigating the Fragility of Pre-trained Models with Feature Enhancement for Few-Shot Semantic Segmentation in Underwater Images(https://arxiv.org/abs/2504.00478)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Few-Shot Semantic Segmentation (FSS), which focuses on segmenting new classes in images using only a limited number of annotated examples, has recently progressed in data-scarce domains. However, in this work, we show that the existing FSS methods often struggle to generalize to underwater environments. Specifically, the prior features extracted by pre-trained models used as feature extractors are fragile due to the unique challenges of underwater images. To address this, we propose FSSUWNet, a tailored FSS framework for underwater images with feature enhancement. FSSUWNet exploits the integration of complementary features, emphasizing both low-level and high-level image characteristics. In addition to employing a pre-trained model as the primary encoder, we propose an auxiliary encoder called Feature Enhanced Encoder which extracts complementary features to better adapt to underwater scene characteristics. Furthermore, a simple and effective Feature Alignment Module aims to provide global prior knowledge and align low-level features with high-level features in dimensions. Given the scarcity of underwater images, we introduce a cross-validation dataset version based on the Segmentation of Underwater Imagery dataset. Extensive experiments on public underwater segmentation datasets demonstrate that our approach achieves state-of-the-art performance. For example, our method outperforms the previous best method by 2.8% and 2.6% in terms of the mean Intersection over Union metric for 1-shot and 5-shot scenarios in the datasets, respectively. Our implementation is available at this https URL.</li>
</ul>

<h3>Title: Hierarchical Attention Networks for Lossless Point Cloud Attribute Compression</h3>
<ul>
<li><strong>Authors: </strong>Yueru Chen, Wei Zhang, Dingquan Li, Jing Wang, Ge Li</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00481">https://arxiv.org/abs/2504.00481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00481">https://arxiv.org/pdf/2504.00481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00481]] Hierarchical Attention Networks for Lossless Point Cloud Attribute Compression(https://arxiv.org/abs/2504.00481)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a deep hierarchical attention context model for lossless attribute compression of point clouds, leveraging a multi-resolution spatial structure and residual learning. A simple and effective Level of Detail (LoD) structure is introduced to yield a coarse-to-fine representation. To enhance efficiency, points within the same refinement level are encoded in parallel, sharing a common context point group. By hierarchically aggregating information from neighboring points, our attention model learns contextual dependencies across varying scales and densities, enabling comprehensive feature extraction. We also adopt normalization for position coordinates and attributes to achieve scale-invariant compression. Additionally, we segment the point cloud into multiple slices to facilitate parallel processing, further optimizing time complexity. Experimental results demonstrate that the proposed method offers better coding performance than the latest G-PCC for color and reflectance attributes while maintaining more efficient encoding and decoding runtimes.</li>
</ul>

<h3>Title: Enhancing stroke disease classification through machine learning models via a novel voting system by feature selection techniques</h3>
<ul>
<li><strong>Authors: </strong>Mahade Hasan, Farhana Yasmin, Md. Mehedi Hassan, Xue Yu, Soniya Yeasmin, Herat Joshi, Sheikh Mohammed Shariful Islam</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00485">https://arxiv.org/abs/2504.00485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00485">https://arxiv.org/pdf/2504.00485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00485]] Enhancing stroke disease classification through machine learning models via a novel voting system by feature selection techniques(https://arxiv.org/abs/2504.00485)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Heart disease remains a leading cause of mortality and morbidity worldwide, necessitating the development of accurate and reliable predictive models to facilitate early detection and intervention. While state of the art work has focused on various machine learning approaches for predicting heart disease, but they could not able to achieve remarkable accuracy. In response to this need, we applied nine machine learning algorithms XGBoost, logistic regression, decision tree, random forest, k-nearest neighbors (KNN), support vector machine (SVM), gaussian naïve bayes (NB gaussian), adaptive boosting, and linear regression to predict heart disease based on a range of physiological indicators. Our approach involved feature selection techniques to identify the most relevant predictors, aimed at refining the models to enhance both performance and interpretability. The models were trained, incorporating processes such as grid search hyperparameter tuning, and cross-validation to minimize overfitting. Additionally, we have developed a novel voting system with feature selection techniques to advance heart disease classification. Furthermore, we have evaluated the models using key performance metrics including accuracy, precision, recall, F1-score, and the area under the receiver operating characteristic curve (ROC AUC). Among the models, XGBoost demonstrated exceptional performance, achieving 99% accuracy, precision, F1-Score, 98% recall, and 100% ROC AUC. This study offers a promising approach to early heart disease diagnosis and preventive healthcare.</li>
</ul>

<h3>Title: SCFANet: Style Distribution Constraint Feature Alignment Network For Pathological Staining Translation</h3>
<ul>
<li><strong>Authors: </strong>Zetong Chen, Yuzhuo Chen, Hai Zhong, Xu Qiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00490">https://arxiv.org/abs/2504.00490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00490">https://arxiv.org/pdf/2504.00490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00490]] SCFANet: Style Distribution Constraint Feature Alignment Network For Pathological Staining Translation(https://arxiv.org/abs/2504.00490)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Immunohistochemical (IHC) staining serves as a valuable technique for detecting specific antigens or proteins through antibody-mediated visualization. However, the IHC staining process is both time-consuming and costly. To address these limitations, the application of deep learning models for direct translation of cost-effective Hematoxylin and Eosin (H&E) stained images into IHC stained images has emerged as an efficient solution. Nevertheless, the conversion from H&E to IHC images presents significant challenges, primarily due to alignment discrepancies between image pairs and the inherent diversity in IHC staining style patterns. To overcome these challenges, we propose the Style Distribution Constraint Feature Alignment Network (SCFANet), which incorporates two innovative modules: the Style Distribution Constrainer (SDC) and Feature Alignment Learning (FAL). The SDC ensures consistency between the generated and target images' style distributions while integrating cycle consistency loss to maintain structural consistency. To mitigate the complexity of direct image-to-image translation, the FAL module decomposes the end-to-end translation task into two subtasks: image reconstruction and feature alignment. Furthermore, we ensure pathological consistency between generated and target images by maintaining pathological pattern consistency and Optical Density (OD) uniformity. Extensive experiments conducted on the Breast Cancer Immunohistochemical (BCI) dataset demonstrate that our SCFANet model outperforms existing methods, achieving precise transformation of H&E-stained images into their IHC-stained counterparts. The proposed approach not only addresses the technical challenges in H&E to IHC image translation but also provides a robust framework for accurate and efficient stain conversion in pathological analysis.</li>
</ul>

<h3>Title: ParallelFlow: Parallelizing Linear Transformers via Flow Discretization</h3>
<ul>
<li><strong>Authors: </strong>Nicola Muca Cirone, Cristopher Salvi</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00492">https://arxiv.org/abs/2504.00492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00492">https://arxiv.org/pdf/2504.00492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00492]] ParallelFlow: Parallelizing Linear Transformers via Flow Discretization(https://arxiv.org/abs/2504.00492)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a theoretical framework for analyzing linear attention models through matrix-valued state space models (SSMs). Our approach, Parallel Flows, provides a perspective that systematically decouples temporal dynamics from implementation constraints, enabling independent analysis of critical algorithmic components: chunking, parallelization, and information aggregation. Central to this framework is the reinterpretation of chunking procedures as computations of the flows governing system dynamics. This connection establishes a bridge to mathematical tools from rough path theory, opening the door to new insights into sequence modeling architectures. As a concrete application, we analyze DeltaNet in a generalized low-rank setting motivated by recent theoretical advances. Our methods allow us to design simple, streamlined generalizations of hardware-efficient algorithms present in the literature, and to provide completely different ones, inspired by rough paths techniques, with provably lower complexity. This dual contribution demonstrates how principled theoretical analysis can both explain existing practical methods and inspire fundamentally new computational approaches.</li>
</ul>

<h3>Title: Visually Image Encryption and Compression Using a CNN-Based Auto Encoder</h3>
<ul>
<li><strong>Authors: </strong>Mahdi Madani, El-Bay Bourennane</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00497">https://arxiv.org/abs/2504.00497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00497">https://arxiv.org/pdf/2504.00497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00497]] Visually Image Encryption and Compression Using a CNN-Based Auto Encoder(https://arxiv.org/abs/2504.00497)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>This paper proposes a visual encryption method to ensure the confidentiality of digital images. The model used is based on an autoencoder using aConvolutional Neural Network (CNN) to ensure the protection of the user data on both the sender side (encryption process) and the receiver side(decryption process)in a symmetric mode. To train and test the model, we used the MNIST and CIFAR-10 datasets. Our focus lies in generating an encrypted dataset by combining the original dataset with a random mask. Then, a convolutional autoencoder in the masked dataset will be designed and trained to learn essential image features in a reduced-dimensional latent space and reconstruct the image from this space. The used mask can be considered as a secret key known in standard cryptographic algorithms which allows the receiver of the masked data to recover the plain data. The implementation of this proposed encryption model demonstrates efficacy in preserving data confidentiality and integrity while reducing the dimensionality (for example we pass from 3072 Bytes to 1024 Bytes for CIFAR-10 images). Experimental results show that the used CNN exhibits a proficient encryption and decryption process on the MNIST dataset, and a proficient encryption and acceptable decryption process on the CIFAR-10 dataset.</li>
</ul>

<h3>Title: ShortV: Efficient Multimodal Large Language Models by Freezing Visual Tokens in Ineffective Layers</h3>
<ul>
<li><strong>Authors: </strong>Qianhao Yuan, Qingyu Zhang, Yanjiang Liu, Jiawei Chen, Yaojie Lu, Hongyu Lin, Jia Zheng, Xianpei Han, Le Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00502">https://arxiv.org/abs/2504.00502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00502">https://arxiv.org/pdf/2504.00502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00502]] ShortV: Efficient Multimodal Large Language Models by Freezing Visual Tokens in Ineffective Layers(https://arxiv.org/abs/2504.00502)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) suffer from high computational costs due to their massive size and the large number of visual tokens. In this paper, we investigate layer-wise redundancy in MLLMs by introducing a novel metric, Layer Contribution (LC), which quantifies the impact of a layer's transformations on visual and text tokens, respectively. The calculation of LC involves measuring the divergence in model output that results from removing the layer's transformations on the specified tokens. Our pilot experiment reveals that many layers of MLLMs exhibit minimal contribution during the processing of visual tokens. Motivated by this observation, we propose ShortV, a training-free method that leverages LC to identify ineffective layers, and freezes visual token updates in these layers. Experiments show that ShortV can freeze visual token in approximately 60\% of the MLLM layers, thereby dramatically reducing computational costs related to updating visual tokens. For example, it achieves a 50\% reduction in FLOPs on LLaVA-NeXT-13B while maintaining superior performance. The code will be publicly available at this https URL</li>
</ul>

<h3>Title: Training Frozen Feature Pyramid DINOv2 for Eyelid Measurements with Infinite Encoding and Orthogonal Regularization</h3>
<ul>
<li><strong>Authors: </strong>Chun-Hung Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00515">https://arxiv.org/abs/2504.00515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00515">https://arxiv.org/pdf/2504.00515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00515]] Training Frozen Feature Pyramid DINOv2 for Eyelid Measurements with Infinite Encoding and Orthogonal Regularization(https://arxiv.org/abs/2504.00515)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Accurate measurement of eyelid parameters such as Margin Reflex Distances (MRD1, MRD2) and Levator Function (LF) is critical in oculoplastic diagnostics but remains limited by manual, inconsistent methods. This study evaluates deep learning models: SE-ResNet, EfficientNet, and the vision transformer-based DINOv2 for automating these measurements using smartphone-acquired images. We assess performance across frozen and fine-tuned settings, using MSE, MAE, and R2 metrics. DINOv2, pretrained through self-supervised learning, demonstrates superior scalability and robustness, especially under frozen conditions ideal for mobile deployment. Lightweight regressors such as MLP and Deep Ensemble offer high precision with minimal computational overhead. To address class imbalance and improve generalization, we integrate focal loss, orthogonal regularization, and binary encoding strategies. Our results show that DINOv2 combined with these enhancements delivers consistent, accurate predictions across all tasks, making it a strong candidate for real-world, mobile-friendly clinical applications. This work highlights the potential of foundation models in advancing AI-powered ophthalmic care.</li>
</ul>

<h3>Title: High-Quality Pseudo-Label Generation Based on Visual Prompt Assisted Cloud Model Update</h3>
<ul>
<li><strong>Authors: </strong>Xinrun Xu, Qiuhong Zhang, Jianwen Yang, Zhanbiao Lian, Jin Yan, Zhiming Ding, Shan Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00526">https://arxiv.org/abs/2504.00526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00526">https://arxiv.org/pdf/2504.00526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00526]] High-Quality Pseudo-Label Generation Based on Visual Prompt Assisted Cloud Model Update(https://arxiv.org/abs/2504.00526)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Generating high-quality pseudo-labels on the cloud is crucial for cloud-edge object detection, especially in dynamic traffic monitoring where data distributions evolve. Existing methods often assume reliable cloud models, neglecting potential errors or struggling with complex distribution shifts. This paper proposes Cloud-Adaptive High-Quality Pseudo-label generation (CA-HQP), addressing these limitations by incorporating a learnable Visual Prompt Generator (VPG) and dual feature alignment into cloud model updates. The VPG enables parameter-efficient adaptation by injecting visual prompts, enhancing flexibility without extensive fine-tuning. CA-HQP mitigates domain discrepancies via two feature alignment techniques: global Domain Query Feature Alignment (DQFA) capturing scene-level shifts, and fine-grained Temporal Instance-Aware Feature Embedding Alignment (TIAFA) addressing instance variations. Experiments on the Bellevue traffic dataset demonstrate that CA-HQP significantly improves pseudo-label quality compared to existing methods, leading to notable performance gains for the edge model and showcasing CA-HQP's adaptation effectiveness. Ablation studies validate each component (DQFA, TIAFA, VPG) and the synergistic effect of combined alignment strategies, highlighting the importance of adaptive cloud updates and domain adaptation for robust object detection in evolving scenarios. CA-HQP provides a promising solution for enhancing cloud-edge object detection systems in real-world applications.</li>
</ul>

<h3>Title: Adversarial Curriculum Graph-Free Knowledge Distillation for Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Yuang Jia, Xiaojuan Shan, Jun Xia, Guancheng Wan, Yuchen Zhang, Wenke Huang, Mang Ye, Stan Z. Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00540">https://arxiv.org/abs/2504.00540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00540">https://arxiv.org/pdf/2504.00540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00540]] Adversarial Curriculum Graph-Free Knowledge Distillation for Graph Neural Networks(https://arxiv.org/abs/2504.00540)</code><input type="text"></li>
<li><strong>Keywords: </strong>data-free</a></li>
<li><strong>Abstract: </strong>Data-free Knowledge Distillation (DFKD) is a method that constructs pseudo-samples using a generator without real data, and transfers knowledge from a teacher model to a student by enforcing the student to overcome dimensional differences and learn to mimic the teacher's outputs on these pseudo-samples. In recent years, various studies in the vision domain have made notable advancements in this area. However, the varying topological structures and non-grid nature of graph data render the methods from the vision domain ineffective. Building upon prior research into differentiable methods for graph neural networks, we propose a fast and high-quality data-free knowledge distillation approach in this paper. Without compromising distillation quality, the proposed graph-free KD method (ACGKD) significantly reduces the spatial complexity of pseudo-graphs by leveraging the Binary Concrete distribution to model the graph structure and introducing a spatial complexity tuning parameter. This approach enables efficient gradient computation for the graph structure, thereby accelerating the overall distillation process. Additionally, ACGKD eliminates the dimensional ambiguity between the student and teacher models by increasing the student's dimensions and reusing the teacher's classifier. Moreover, it equips graph knowledge distillation with a CL-based strategy to ensure the student learns graph structures progressively. Extensive experiments demonstrate that ACGKD achieves state-of-the-art performance in distilling knowledge from GNNs without training data.</li>
</ul>

<h3>Title: Generalization-aware Remote Sensing Change Detection via Domain-agnostic Learning</h3>
<ul>
<li><strong>Authors: </strong>Qi Zang, Shuang Wang, Dong Zhao, Dou Quan, Yang Hu, Licheng Jiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00543">https://arxiv.org/abs/2504.00543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00543">https://arxiv.org/pdf/2504.00543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00543]] Generalization-aware Remote Sensing Change Detection via Domain-agnostic Learning(https://arxiv.org/abs/2504.00543)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Change detection has essential significance for the region's development, in which pseudo-changes between bitemporal images induced by imaging environmental factors are key challenges. Existing transformation-based methods regard pseudo-changes as a kind of style shift and alleviate it by transforming bitemporal images into the same style using generative adversarial networks (GANs). However, their efforts are limited by two drawbacks: 1) Transformed images suffer from distortion that reduces feature discrimination. 2) Alignment hampers the model from learning domain-agnostic representations that degrades performance on scenes with domain shifts from the training data. Therefore, oriented from pseudo-changes caused by style differences, we present a generalizable domain-agnostic difference learning network (DonaNet). For the drawback 1), we argue for local-level statistics as style proxies to assist against domain shifts. For the drawback 2), DonaNet learns domain-agnostic representations by removing domain-specific style of encoded features and highlighting the class characteristics of objects. In the removal, we propose a domain difference removal module to reduce feature variance while preserving discriminative properties and propose its enhanced version to provide possibilities for eliminating more style by decorrelating the correlation between features. In the highlighting, we propose a cross-temporal generalization learning strategy to imitate latent domain shifts, thus enabling the model to extract feature representations more robust to shifts actively. Extensive experiments conducted on three public datasets demonstrate that DonaNet outperforms existing state-of-the-art methods with a smaller model size and is more robust to domain shift.</li>
</ul>

<h3>Title: Adaptive Federated Learning with Functional Encryption: A Comparison of Classical and Quantum-safe Options</h3>
<ul>
<li><strong>Authors: </strong>Enrico Sorbera, Federica Zanetti, Giacomo Brandi, Alessandro Tomasi, Roberto Doriguzzi-Corin, Silvio Ranise</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00563">https://arxiv.org/abs/2504.00563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00563">https://arxiv.org/pdf/2504.00563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00563]] Adaptive Federated Learning with Functional Encryption: A Comparison of Classical and Quantum-safe Options(https://arxiv.org/abs/2504.00563)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a collaborative method for training machine learning models while preserving the confidentiality of the participants' training data. Nevertheless, FL is vulnerable to reconstruction attacks that exploit shared parameters to reveal private training data. In this paper, we address this issue in the cybersecurity domain by applying Multi-Input Functional Encryption (MIFE) to a recent FL implementation for training ML-based network intrusion detection systems. We assess both classical and post-quantum solutions in terms of memory cost and computational overhead in the FL process, highlighting their impact on convergence time.</li>
</ul>

<h3>Title: Geometric Median Matching for Robust k-Subset Selection from Noisy Data</h3>
<ul>
<li><strong>Authors: </strong>Anish Acharya, Sujay Sanghavi, Alexandros G Dimakis, Inderjit S Dhillon</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00564">https://arxiv.org/abs/2504.00564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00564">https://arxiv.org/pdf/2504.00564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00564]] Geometric Median Matching for Robust k-Subset Selection from Noisy Data(https://arxiv.org/abs/2504.00564)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Data pruning -- the combinatorial task of selecting a small and representative subset from a large dataset, is crucial for mitigating the enormous computational costs associated with training data-hungry modern deep learning models at scale. Since large scale data collections are invariably noisy, developing data pruning strategies that remain robust even in the presence of corruption is critical in practice. However, existing data pruning methods often fail under high corruption rates due to their reliance on empirical mean estimation, which is highly sensitive to outliers. In response, we propose Geometric Median (GM) Matching, a novel k-subset selection strategy that leverages Geometric Median -- a robust estimator with an optimal breakdown point of 1/2; to enhance resilience against noisy data. Our method iteratively selects a k-subset such that the mean of the subset approximates the GM of the (potentially) noisy dataset, ensuring robustness even under arbitrary corruption. We provide theoretical guarantees, showing that GM Matching enjoys an improved O(1/k) convergence rate -- a quadratic improvement over random sampling, even under arbitrary corruption. Extensive experiments across image classification and image generation tasks demonstrate that GM Matching consistently outperforms existing pruning approaches, particularly in high-corruption settings and at high pruning rates; making it a strong baseline for robust data pruning.</li>
</ul>

<h3>Title: Enhancing Negation Awareness in Universal Text Embeddings: A Data-efficient and Computational-efficient Approach</h3>
<ul>
<li><strong>Authors: </strong>Hongliu Cao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00584">https://arxiv.org/abs/2504.00584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00584">https://arxiv.org/pdf/2504.00584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00584]] Enhancing Negation Awareness in Universal Text Embeddings: A Data-efficient and Computational-efficient Approach(https://arxiv.org/abs/2504.00584)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Negation plays an important role in various natural language processing tasks such as Natural Language Inference and Sentiment Analysis tasks. Numerous prior studies have found that contextual text embedding models such as BERT, ELMO, RoBERTa or XLNet face challenges in accurately understanding negation. Recent advancements in universal text embeddings have demonstrated superior performance over contextual text embeddings in various tasks. However, due to the bias in popular evaluation benchmarks, the negation awareness capacity of these models remains unclear. To bridge the gap in existing literature, an in-depth analysis is initiated in this work to study the negation awareness of cutting-edge universal text embedding models. Our findings reveal a significant lack of negation awareness in these models, often interpreting negated text pairs as semantically similar. To efficiently deal with the conflict that different tasks need different trade-offs between topic and negation information among other semantic information, a data-efficient and computational-efficient embedding re-weighting method is proposed without modifying the parameters of text embedding models. The proposed solution is able to improve text embedding models' negation awareness significantly on both simple negation understanding task and complex negation understanding task. Furthermore, the proposed solution can also significantly improve the negation awareness of Large Language Model based task-specific high dimensional universal text embeddings.</li>
</ul>

<h3>Title: Efficient Annotator Reliablity Assessment with EffiARA</h3>
<ul>
<li><strong>Authors: </strong>Owen Cook, Jake Vasilakes, Ian Roberts, Xingyi Song</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00589">https://arxiv.org/abs/2504.00589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00589">https://arxiv.org/pdf/2504.00589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00589]] Efficient Annotator Reliablity Assessment with EffiARA(https://arxiv.org/abs/2504.00589)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Data annotation is an essential component of the machine learning pipeline; it is also a costly and time-consuming process. With the introduction of transformer-based models, annotation at the document level is increasingly popular; however, there is no standard framework for structuring such tasks. The EffiARA annotation framework is, to our knowledge, the first project to support the whole annotation pipeline, from understanding the resources required for an annotation task to compiling the annotated dataset and gaining insights into the reliability of individual annotators as well as the dataset as a whole. The framework's efficacy is supported by two previous studies: one improving classification performance through annotator-reliability-based soft label aggregation and sample weighting, and the other increasing the overall agreement among annotators through removing identifying and replacing an unreliable annotator. This work introduces the EffiARA Python package and its accompanying webtool, which provides an accessible graphical user interface for the system. We open-source the EffiARA Python package at this https URL and the webtool is publicly accessible at this https URL.</li>
</ul>

<h3>Title: Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal LLMs on Academic Resources</h3>
<ul>
<li><strong>Authors: </strong>Weizhi Wang, Yu Tian, Linjie Yang, Heng Wang, Xifeng Yan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00595">https://arxiv.org/abs/2504.00595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00595">https://arxiv.org/pdf/2504.00595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00595]] Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal LLMs on Academic Resources(https://arxiv.org/abs/2504.00595)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The reproduction of state-of-the-art multimodal LLM pre-training faces barriers at every stage of the pipeline, including high-quality data filtering, multimodal data mixture strategies, sequence packing techniques, and training frameworks. We introduce Open-Qwen2VL, a fully open-source 2B-parameter Multimodal Large Language Model pre-trained efficiently on 29M image-text pairs using only 442 A100-40G GPU hours. Our approach employs low-to-high dynamic image resolution and multimodal sequence packing to significantly enhance pre-training efficiency. The training dataset was carefully curated using both MLLM-based filtering techniques (e.g., MLM-Filter) and conventional CLIP-based filtering methods, substantially improving data quality and training efficiency. The Open-Qwen2VL pre-training is conducted on academic level 8xA100-40G GPUs at UCSB on 5B packed multimodal tokens, which is 0.36\% of 1.4T multimodal pre-training tokens of Qwen2-VL. The final instruction-tuned Open-Qwen2VL outperforms partially-open state-of-the-art MLLM Qwen2-VL-2B on various multimodal benchmarks of MMBench, SEEDBench, MMstar, and MathVista, indicating the remarkable training efficiency of Open-Qwen2VL. We open-source all aspects of our work, including compute-efficient and data-efficient training details, data filtering methods, sequence packing scripts, pre-training data in WebDataset format, FSDP-based training codebase, and both base and instruction-tuned model checkpoints. We redefine "fully open" for multimodal LLMs as the complete release of: 1) the training codebase, 2) detailed data filtering techniques, and 3) all pre-training and supervised fine-tuning data used to develop the model.</li>
</ul>

<h3>Title: On the Consistency of Multilingual Context Utilization in Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Jirui Qi, Raquel Fernández, Arianna Bisazza</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00597">https://arxiv.org/abs/2504.00597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00597">https://arxiv.org/pdf/2504.00597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00597]] On the Consistency of Multilingual Context Utilization in Retrieval-Augmented Generation(https://arxiv.org/abs/2504.00597)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) with large language models (LLMs) has demonstrated strong performance in multilingual question-answering (QA) tasks by leveraging relevant passages retrieved from corpora. In multilingual RAG (mRAG), the retrieved passages can be written in languages other than that of the query entered by the user, making it challenging for LLMs to effectively utilize the provided information. Recent research suggests that retrieving passages from multilingual corpora can improve RAG performance, particularly for low-resource languages. However, the extent to which LLMs can leverage different kinds of multilingual contexts to generate accurate answers, *independently from retrieval quality*, remains understudied. In this paper, we conduct an extensive assessment of LLMs' ability to (i) make consistent use of a relevant passage regardless of its language, (ii) respond in the expected language, and (iii) focus on the relevant passage even when multiple `distracting' passages in different languages are provided in the context. Our experiments with four LLMs across three QA datasets covering a total of 48 languages reveal a surprising ability of LLMs to extract the relevant information from out-language passages, but a much weaker ability to formulate a full answer in the correct language. Our analysis, based on both accuracy and feature attribution techniques, further shows that distracting passages negatively impact answer quality regardless of their language. However, distractors in the query language exert a slightly stronger influence. Taken together, our findings deepen the understanding of how LLMs utilize context in mRAG systems, providing directions for future improvements.</li>
</ul>

<h3>Title: Data Cleansing for GANs</h3>
<ul>
<li><strong>Authors: </strong>Naoyuki Terashita, Hiroki Ohashi, Satoshi Hara</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00603">https://arxiv.org/abs/2504.00603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00603">https://arxiv.org/pdf/2504.00603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00603]] Data Cleansing for GANs(https://arxiv.org/abs/2504.00603)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>As the application of generative adversarial networks (GANs) expands, it becomes increasingly critical to develop a unified approach that improves performance across various generative tasks. One effective strategy that applies to any machine learning task is identifying harmful instances, whose removal improves the performance. While previous studies have successfully estimated these harmful training instances in supervised settings, their approaches are not easily applicable to GANs. The challenge lies in two requirements of the previous approaches that do not apply to GANs. First, previous approaches require that the absence of a training instance directly affects the parameters. However, in the training for GANs, the instances do not directly affect the generator's parameters since they are only fed into the discriminator. Second, previous approaches assume that the change in loss directly quantifies the harmfulness of the instance to a model's performance, while common types of GAN losses do not always reflect the generative performance. To overcome the first challenge, we propose influence estimation methods that use the Jacobian of the generator's gradient with respect to the discriminator's parameters (and vice versa). Such a Jacobian represents the indirect effect between two models: how removing an instance from the discriminator's training changes the generator's parameters. Second, we propose an instance evaluation scheme that measures the harmfulness of each training instance based on how a GAN evaluation metric (e.g., Inception score) is expected to change by the instance's removal. Furthermore, we demonstrate that removing the identified harmful instances significantly improves the generative performance on various GAN evaluation metrics.</li>
</ul>

<h3>Title: Bi-Grid Reconstruction for Image Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Huichuan Huang, Zhiqing Zhong, Guangyu Wei, Yonghao Wan, Wenlong Sun, Aimin Feng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00609">https://arxiv.org/abs/2504.00609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00609">https://arxiv.org/pdf/2504.00609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00609]] Bi-Grid Reconstruction for Image Anomaly Detection(https://arxiv.org/abs/2504.00609)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In image anomaly detection, significant advancements have been made using un- and self-supervised methods with datasets containing only normal samples. However, these approaches often struggle with fine-grained anomalies. This paper introduces \textbf{GRAD}: Bi-\textbf{G}rid \textbf{R}econstruction for Image \textbf{A}nomaly \textbf{D}etection, which employs two continuous grids to enhance anomaly detection from both normal and abnormal perspectives. In this work: 1) Grids as feature repositories that improve generalization and mitigate the Identical Shortcut (IS) issue; 2) An abnormal feature grid that refines normal feature boundaries, boosting detection of fine-grained defects; 3) The Feature Block Paste (FBP) module, which synthesizes various anomalies at the feature level for quick abnormal grid deployment. GRAD's robust representation capabilities also allow it to handle multiple classes with a single model. Evaluations on datasets like MVTecAD, VisA, and GoodsAD show significant performance improvements in fine-grained anomaly detection. GRAD excels in overall accuracy and in discerning subtle differences, demonstrating its superiority over existing methods.</li>
</ul>

<h3>Title: Efficient Construction of Model Family through Progressive Training Using Model Expansion</h3>
<ul>
<li><strong>Authors: </strong>Kazuki Yano, Sho Takase, Sosuke Kobayashi, Shun Kiyono, Jun Suzuki</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00623">https://arxiv.org/abs/2504.00623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00623">https://arxiv.org/pdf/2504.00623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00623]] Efficient Construction of Model Family through Progressive Training Using Model Expansion(https://arxiv.org/abs/2504.00623)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) gain widespread practical application, providing the model family of different parameter sizes has become standard practice to address diverse computational requirements. Conventionally, each model in a family is trained independently, resulting in computational costs that scale additively with the number of models. We propose an efficient method for constructing the model family through progressive training, where smaller models are incrementally expanded to larger sizes to create a complete model family. Through extensive experiments with a model family ranging from 1B to 8B parameters, we demonstrate that our method reduces computational costs by approximately 25% while maintaining comparable performance to independently trained models. Furthermore, by strategically adjusting maximum learning rates based on model size, our method outperforms the independent training across various metrics. Beyond performance gains, our approach offers an additional advantage: models in our family tend to yield more consistent behavior across different model sizes.</li>
</ul>

<h3>Title: Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models</h3>
<ul>
<li><strong>Authors: </strong>Alireza Aghabagherloo, Aydin Abadi, Sumanta Sarkar, Vishnu Asutosh Dasu, Bart Preneel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00638">https://arxiv.org/abs/2504.00638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00638">https://arxiv.org/pdf/2504.00638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00638]] Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models(https://arxiv.org/abs/2504.00638)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>The accuracy and robustness of machine learning models against adversarial attacks are significantly influenced by factors such as training data quality, model architecture, the training process, and the deployment environment. In recent years, duplicated data in training sets, especially in language models, has attracted considerable attention. It has been shown that deduplication enhances both training performance and model accuracy in language models. While the importance of data quality in training image classifier Deep Neural Networks (DNNs) is widely recognized, the impact of duplicated images in the training set on model generalization and performance has received little attention. In this paper, we address this gap and provide a comprehensive study on the effect of duplicates in image classification. Our analysis indicates that the presence of duplicated images in the training set not only negatively affects the efficiency of model training but also may result in lower accuracy of the image classifier. This negative impact of duplication on accuracy is particularly evident when duplicated data is non-uniform across classes or when duplication, whether uniform or non-uniform, occurs in the training set of an adversarially trained model. Even when duplicated samples are selected in a uniform way, increasing the amount of duplication does not lead to a significant improvement in accuracy.</li>
</ul>

<h3>Title: Coca-Splat: Collaborative Optimization for Camera Parameters and 3D Gaussians</h3>
<ul>
<li><strong>Authors: </strong>Jiamin Wu, Hongyang Li, Xiaoke Jiang, Yuan Yao, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00639">https://arxiv.org/abs/2504.00639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00639">https://arxiv.org/pdf/2504.00639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00639]] Coca-Splat: Collaborative Optimization for Camera Parameters and 3D Gaussians(https://arxiv.org/abs/2504.00639)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this work, we introduce Coca-Splat, a novel approach to addressing the challenges of sparse view pose-free scene reconstruction and novel view synthesis (NVS) by jointly optimizing camera parameters with 3D Gaussians. Inspired by deformable DEtection TRansformer, we design separate queries for 3D Gaussians and camera parameters and update them layer by layer through deformable Transformer layers, enabling joint optimization in a single network. This design demonstrates better performance because to accurately render views that closely approximate ground-truth images relies on precise estimation of both 3D Gaussians and camera parameters. In such a design, the centers of 3D Gaussians are projected onto each view by camera parameters to get projected points, which are regarded as 2D reference points in deformable cross-attention. With camera-aware multi-view deformable cross-attention (CaMDFA), 3D Gaussians and camera parameters are intrinsically connected by sharing the 2D reference points. Additionally, 2D reference point determined rays (RayRef) defined from camera centers to the reference points assist in modeling relationship between 3D Gaussians and camera parameters through RQ-decomposition on an overdetermined system of equations derived from the rays, enhancing the relationship between 3D Gaussians and camera parameters. Extensive evaluation shows that our approach outperforms previous methods, both pose-required and pose-free, on RealEstate10K and ACID within the same pose-free setting.</li>
</ul>

<h3>Title: POPEN: Preference-Based Optimization and Ensemble for LVLM-Based Reasoning Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Lanyun Zhu, Tianrun Chen, Qianxiong Xu, Xuanyi Liu, Deyi Ji, Haiyang Wu, De Wen Soh, Jun Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00640">https://arxiv.org/abs/2504.00640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00640">https://arxiv.org/pdf/2504.00640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00640]] POPEN: Preference-Based Optimization and Ensemble for LVLM-Based Reasoning Segmentation(https://arxiv.org/abs/2504.00640)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Existing LVLM-based reasoning segmentation methods often suffer from imprecise segmentation results and hallucinations in their text responses. This paper introduces POPEN, a novel framework designed to address these issues and achieve improved results. POPEN includes a preference-based optimization method to finetune the LVLM, aligning it more closely with human preferences and thereby generating better text responses and segmentation results. Additionally, POPEN introduces a preference-based ensemble method for inference, which integrates multiple outputs from the LVLM using a preference-score-based attention mechanism for refinement. To better adapt to the segmentation task, we incorporate several task-specific designs in our POPEN framework, including a new approach for collecting segmentation preference data with a curriculum learning mechanism, and a novel preference optimization loss to refine the segmentation capability of the LVLM. Experiments demonstrate that our method achieves state-of-the-art performance in reasoning segmentation, exhibiting minimal hallucination in text responses and the highest segmentation accuracy compared to previous advanced methods like LISA and PixelLM. Project page is this https URL</li>
</ul>

<h3>Title: QG-VTC: Question-Guided Visual Token Compression in MLLMs for Efficient VQA</h3>
<ul>
<li><strong>Authors: </strong>Shuai Li, Jian Xu, Xiao-Hui Li, Chao Deng, Lin-Lin Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00654">https://arxiv.org/abs/2504.00654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00654">https://arxiv.org/pdf/2504.00654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00654]] QG-VTC: Question-Guided Visual Token Compression in MLLMs for Efficient VQA(https://arxiv.org/abs/2504.00654)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Multi-modal Large Language Models (MLLMs) have shown significant progress in open-world Visual Question Answering (VQA). However, integrating visual information increases the number of processed tokens, leading to higher GPU memory usage and computational overhead. Images often contain more redundant information than text, and not all visual details are pertinent to specific questions. To address these challenges, we propose QG-VTC, a novel question-guided visual token compression method for MLLM-based VQA tasks. QG-VTC employs a pretrained text encoder and a learnable feed-forward layer to embed user questions into the vision encoder's feature space then computes correlation scores between the question embeddings and visual tokens. By selecting the most relevant tokens and softly compressing others, QG-VTC ensures fine-tuned relevance to user needs. Additionally, a progressive strategy applies this compression across different vision encoder layers, gradually reducing token numbers. This approach maximizes retention of question-relevant information while discarding irrelevant details. Experimental results show that our method achieves performance on par with uncompressed models using just 1/8 of the visual tokens. The code and model will be publicly available on GitHub.</li>
</ul>

<h3>Title: DynMoLE: Boosting Mixture of LoRA Experts Fine-Tuning with a Hybrid Routing Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Dengchun Li, Naizheng Wang, Zihao Zhang, Haoyang Yin, Lei Duan, Meng Xiao, Mingjie Tang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00661">https://arxiv.org/abs/2504.00661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00661">https://arxiv.org/pdf/2504.00661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00661]] DynMoLE: Boosting Mixture of LoRA Experts Fine-Tuning with a Hybrid Routing Mechanism(https://arxiv.org/abs/2504.00661)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Instruction-based fine-tuning of large language models (LLMs) has achieved remarkable success in various natural language processing (NLP) tasks. Parameter-efficient fine-tuning (PEFT) methods, such as Mixture of LoRA Experts (MoLE), combine the efficiency of Low-Rank Adaptation (LoRA) with the versatility of Mixture of Experts (MoE) models, demonstrating significant potential for handling multiple downstream tasks. However, the existing routing mechanisms for MoLE often involve a trade-off between computational efficiency and predictive accuracy, and they fail to fully address the diverse expert selection demands across different transformer layers. In this work, we propose DynMoLE, a hybrid routing strategy that dynamically adjusts expert selection based on the Tsallis entropy of the router's probability distribution. This approach mitigates router uncertainty, enhances stability, and promotes more equitable expert participation, leading to faster convergence and improved model performance. Additionally, we introduce an auxiliary loss based on Tsallis entropy to further guide the model toward convergence with reduced uncertainty, thereby improving training stability and performance. Our extensive experiments on commonsense reasoning benchmarks demonstrate that DynMoLE achieves substantial performance improvements, outperforming LoRA by 9.6% and surpassing the state-of-the-art MoLE method, MoLA, by 2.3%. We also conduct a comprehensive ablation study to evaluate the contributions of DynMoLE's key components.</li>
</ul>

<h3>Title: Do LLMs Surpass Encoders for Biomedical NER?</h3>
<ul>
<li><strong>Authors: </strong>Motasem S Obeidat, Md Sultan Al Nahian, Ramakanth Kavuluru</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00664">https://arxiv.org/abs/2504.00664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00664">https://arxiv.org/pdf/2504.00664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00664]] Do LLMs Surpass Encoders for Biomedical NER?(https://arxiv.org/abs/2504.00664)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Recognizing spans of biomedical concepts and their types (e.g., drug or gene) in free text, often called biomedical named entity recognition (NER), is a basic component of information extraction (IE) pipelines. Without a strong NER component, other applications, such as knowledge discovery and information retrieval, are not practical. State-of-the-art in NER shifted from traditional ML models to deep neural networks with transformer-based encoder models (e.g., BERT) emerging as the current standard. However, decoder models (also called large language models or LLMs) are gaining traction in IE. But LLM-driven NER often ignores positional information due to the generative nature of decoder models. Furthermore, they are computationally very expensive (both in inference time and hardware needs). Hence, it is worth exploring if they actually excel at biomedical NER and assess any associated trade-offs (performance vs efficiency). This is exactly what we do in this effort employing the same BIO entity tagging scheme (that retains positional information) using five different datasets with varying proportions of longer entities. Our results show that the LLMs chosen (Mistral and Llama: 8B range) often outperform best encoder models (BERT-(un)cased, BiomedBERT, and DeBERTav3: 300M range) by 2-8% in F-scores except for one dataset, where they equal encoder performance. This gain is more prominent among longer entities of length >= 3 tokens. However, LLMs are one to two orders of magnitude more expensive at inference time and may need cost prohibitive hardware. Thus, when performance differences are small or real time user feedback is needed, encoder models might still be more suitable than LLMs.</li>
</ul>

<h3>Title: GLiNER-biomed: A Suite of Efficient Models for Open Biomedical Named Entity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Anthony Yazdani, Ihor Stepanov, Douglas Teodoro</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00676">https://arxiv.org/abs/2504.00676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00676">https://arxiv.org/pdf/2504.00676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00676]] GLiNER-biomed: A Suite of Efficient Models for Open Biomedical Named Entity Recognition(https://arxiv.org/abs/2504.00676)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Biomedical named entity recognition (NER) presents unique challenges due to specialized vocabularies, the sheer volume of entities, and the continuous emergence of novel entities. Traditional NER models, constrained by fixed taxonomies and human annotations, struggle to generalize beyond predefined entity types or efficiently adapt to emerging concepts. To address these issues, we introduce GLiNER-biomed, a domain-adapted suite of Generalist and Lightweight Model for NER (GLiNER) models specifically tailored for biomedical NER. In contrast to conventional approaches, GLiNER uses natural language descriptions to infer arbitrary entity types, enabling zero-shot recognition. Our approach first distills the annotation capabilities of large language models (LLMs) into a smaller, more efficient model, enabling the generation of high-coverage synthetic biomedical NER data. We subsequently train two GLiNER architectures, uni- and bi-encoder, at multiple scales to balance computational efficiency and recognition performance. Evaluations on several biomedical datasets demonstrate that GLiNER-biomed outperforms state-of-the-art GLiNER models in both zero- and few-shot scenarios, achieving 5.96% improvement in F1-score over the strongest baseline. Ablation studies highlight the effectiveness of our synthetic data generation strategy and emphasize the complementary benefits of synthetic biomedical pre-training combined with fine-tuning on high-quality general-domain annotations. All datasets, models, and training pipelines are publicly available at this https URL.</li>
</ul>

<h3>Title: On Benchmarking Code LLMs for Android Malware Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yiling He, Hongyu She, Xingzhi Qian, Xinran Zheng, Zhuo Chen, Zhan Qin, Lorenzo Cavallaro</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00694">https://arxiv.org/abs/2504.00694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00694">https://arxiv.org/pdf/2504.00694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00694]] On Benchmarking Code LLMs for Android Malware Analysis(https://arxiv.org/abs/2504.00694)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated strong capabilities in various code intelligence tasks. However, their effectiveness for Android malware analysis remains underexplored. Decompiled Android code poses unique challenges for analysis, primarily due to its large volume of functions and the frequent absence of meaningful function names. This paper presents Cama, a benchmarking framework designed to systematically evaluate the effectiveness of Code LLMs in Android malware analysis tasks. Cama specifies structured model outputs (comprising function summaries, refined function names, and maliciousness scores) to support key malware analysis tasks, including malicious function identification and malware purpose summarization. Built on these, it integrates three domain-specific evaluation metrics, consistency, fidelity, and semantic relevance, enabling rigorous stability and effectiveness assessment and cross-model comparison. We construct a benchmark dataset consisting of 118 Android malware samples, encompassing over 7.5 million distinct functions, and use Cama to evaluate four popular open-source models. Our experiments provide insights into how Code LLMs interpret decompiled code and quantify the sensitivity to function renaming, highlighting both the potential and current limitations of Code LLMs in malware analysis tasks.</li>
</ul>

<h3>Title: ToReMi: Topic-Aware Data Reweighting for Dynamic Pre-Training Data Selection</h3>
<ul>
<li><strong>Authors: </strong>Xiaoxuan Zhu, Zhouhong Gu, Suhang Zheng, Tao Wang, Tianyu Li, Hongwei Feng, Yanghua Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00695">https://arxiv.org/abs/2504.00695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00695">https://arxiv.org/pdf/2504.00695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00695]] ToReMi: Topic-Aware Data Reweighting for Dynamic Pre-Training Data Selection(https://arxiv.org/abs/2504.00695)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pre-training large language models (LLMs) necessitates enormous diverse textual corpora, making effective data selection a key challenge for balancing computational resources and model performance. Current methodologies primarily emphasize data quality metrics and mixing proportions, yet they fail to adequately capture the underlying semantic connections between training samples and quality disparities within individual domains. We introduce ToReMi (Topic-based Reweighting for Model improvement), a novel two-stage framework that dynamically adjusts training sample weights according to their topical associations and observed learning patterns. Our comprehensive experiments reveal that ToReMi variants consistently achieve superior performance over conventional pre-training approaches, demonstrating accelerated perplexity reduction across multiple domains and enhanced capabilities on downstream evaluation tasks. Code is available at this https URL.</li>
</ul>

<h3>Title: Command A: An Enterprise-Ready Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Team Cohere, Aakanksha, Arash Ahmadian, Marwan Ahmed, Jay Alammar, Yazeed Alnumay, Sophia Althammer, Arkady Arkhangorodsky, Viraat Aryabumi, Dennis Aumiller, Raphaël Avalos, Zahara Aviv, Sammie Bae, Saurabh Baji, Alexandre Barbet, Max Bartolo, Björn Bebensee, Neeral Beladia, Walter Beller-Morales, Alexandre Bérard, Andrew Berneshawi, Anna Bialas, Phil Blunsom, Matt Bobkin, Adi Bongale, Sam Braun, Maxime Brunet, Samuel Cahyawijaya, David Cairuz, Jon Ander Campos, Cassie Cao, Kris Cao, Roman Castagné, Julián Cendrero, Leila Chan Currie, Yash Chandak, Diane Chang, Giannis Chatziveroglou, Hongyu Chen, Claire Cheng, Alexis Chevalier, Justin T. Chiu, Eugene Cho, Eugene Choi, Eujeong Choi, Tim Chung, Volkan Cirik, Ana Cismaru, Pierre Clavier, Henry Conklin, Lucas Crawhall-Stein, Devon Crouse, Andres Felipe Cruz-Salinas, Ben Cyrus, Daniel D'souza, Hugo Dalla-Torre, John Dang, William Darling, Omar Darwiche Domingues, Saurabh Dash, Antoine Debugne, Théo Dehaze, Shaan Desai, Joan Devassy, Rishit Dholakia, Kyle Duffy, Ali Edalati, Ace Eldeib, Abdullah Elkady, Sarah Elsharkawy, Irem Ergün, Beyza Ermis, Marzieh Fadaee, Boyu Fan, Lucas Fayoux, Yannis Flet-Berliac, Nick Frosst, Matthias Gallé, Wojciech Galuba, Utsav Garg, Matthieu Geist, Mohammad Gheshlaghi Azar, Seraphina Goldfarb-Tarrant, Tomas Goldsack, Aidan Gomez, Victor Machado Gonzaga, Nithya Govindarajan, Manoj Govindassamy, Nathan Grinsztajn, Nikolas Gritsch, Patrick Gu, Shangmin Guo, Kilian Haefeli, Rod Hajjar, Tim Hawes, Jingyi He, Sebastian Hofstätter, Sungjin Hong, Sara Hooker, Tom Hosking</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00698">https://arxiv.org/abs/2504.00698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00698">https://arxiv.org/pdf/2504.00698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00698]] Command A: An Enterprise-Ready Large Language Model(https://arxiv.org/abs/2504.00698)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this report we describe the development of Command A, a powerful large language model purpose-built to excel at real-world enterprise use cases. Command A is an agent-optimised and multilingual-capable model, with support for 23 languages of global business, and a novel hybrid architecture balancing efficiency with top of the range performance. It offers best-in-class Retrieval Augmented Generation (RAG) capabilities with grounding and tool use to automate sophisticated business processes. These abilities are achieved through a decentralised training approach, including self-refinement algorithms and model merging techniques. We also include results for Command R7B which shares capability and architectural similarities to Command A. Weights for both models have been released for research purposes. This technical report details our original training pipeline and presents an extensive evaluation of our models across a suite of enterprise-relevant tasks and public benchmarks, demonstrating excellent performance and efficiency.</li>
</ul>

<h3>Title: GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments</h3>
<ul>
<li><strong>Authors: </strong>Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00711">https://arxiv.org/abs/2504.00711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00711">https://arxiv.org/pdf/2504.00711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00711]] GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments(https://arxiv.org/abs/2504.00711)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The era of foundation models has revolutionized AI research, yet Graph Foundation Models (GFMs) remain constrained by the scarcity of large-scale graph corpora. Traditional graph data synthesis techniques primarily focus on simplistic structural operations, lacking the capacity to generate semantically rich nodes with meaningful textual attributes: a critical limitation for real-world applications. While large language models (LLMs) demonstrate exceptional text generation capabilities, their direct application to graph synthesis is impeded by context window limitations, hallucination phenomena, and structural consistency challenges. To address these issues, we introduce GraphMaster, the first multi-agent framework specifically designed for graph data synthesis in data-limited environments. GraphMaster orchestrates four specialized LLM agents (Manager, Perception, Enhancement, and Evaluation) that collaboratively optimize the synthesis process through iterative refinement, ensuring both semantic coherence and structural integrity. To rigorously evaluate our approach, we create new data-limited "Sub" variants of six standard graph benchmarks, specifically designed to test synthesis capabilities under realistic constraints. Additionally, we develop a novel interpretability assessment framework that combines human evaluation with a principled Grassmannian manifold-based analysis, providing both qualitative and quantitative measures of semantic coherence. Experimental results demonstrate that GraphMaster significantly outperforms traditional synthesis methods across multiple datasets, establishing a strong foundation for advancing GFMs in data-scarce environments.</li>
</ul>

<h3>Title: Spectral Normalization and Voigt-Reuss net: A universal approach to microstructure-property forecasting with physical guarantees</h3>
<ul>
<li><strong>Authors: </strong>Sanath Keshav, Julius Herb, Felix Fritzen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00712">https://arxiv.org/abs/2504.00712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00712">https://arxiv.org/pdf/2504.00712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00712]] Spectral Normalization and Voigt-Reuss net: A universal approach to microstructure-property forecasting with physical guarantees(https://arxiv.org/abs/2504.00712)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Heterogeneous materials are crucial to producing lightweight components, functional components, and structures composed of them. A crucial step in the design process is the rapid evaluation of their effective mechanical, thermal, or, in general, constitutive properties. The established procedure is to use forward models that accept microstructure geometry and local constitutive properties as inputs. The classical simulation-based approach, which uses, e.g., finite elements and FFT-based solvers, can require substantial computational resources. At the same time, simulation-based models struggle to provide gradients with respect to the microstructure and the constitutive parameters. Such gradients are, however, of paramount importance for microstructure design and for inverting the microstructure-property mapping. Machine learning surrogates can excel in these situations. However, they can lead to unphysical predictions that violate essential bounds on the constitutive response, such as the upper (Voigt-like) or the lower (Reuss-like) bound in linear elasticity. Therefore, we propose a novel spectral normalization scheme that a priori enforces these bounds. The approach is fully agnostic with respect to the chosen microstructural features and the utilized surrogate model. All of these will automatically and strictly predict outputs that obey the upper and lower bounds by construction. The technique can be used for any constitutive tensor that is symmetric and where upper and lower bounds (in the Löwner sense) exist, i.e., for permeability, thermal conductivity, linear elasticity, and many more. We demonstrate the use of spectral normalization in the Voigt-Reuss net using a simple neural network. Numerical examples on truly extensive datasets illustrate the improved accuracy, robustness, and independence of the type of input features in comparison to much-used neural networks.</li>
</ul>

<h3>Title: Alleviating Performance Disparity in Adversarial Spatiotemporal Graph Learning Under Zero-Inflated Distribution</h3>
<ul>
<li><strong>Authors: </strong>Songran Bai, Yuheng Ji, Yue Liu, Xingwei Zhang, Xiaolong Zheng, Daniel Dajun Zeng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00721">https://arxiv.org/abs/2504.00721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00721">https://arxiv.org/pdf/2504.00721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00721]] Alleviating Performance Disparity in Adversarial Spatiotemporal Graph Learning Under Zero-Inflated Distribution(https://arxiv.org/abs/2504.00721)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Spatiotemporal Graph Learning (SGL) under Zero-Inflated Distribution (ZID) is crucial for urban risk management tasks, including crime prediction and traffic accident profiling. However, SGL models are vulnerable to adversarial attacks, compromising their practical utility. While adversarial training (AT) has been widely used to bolster model robustness, our study finds that traditional AT exacerbates performance disparities between majority and minority classes under ZID, potentially leading to irreparable losses due to underreporting critical risk events. In this paper, we first demonstrate the smaller top-k gradients and lower separability of minority class are key factors contributing to this disparity. To address these issues, we propose MinGRE, a framework for Minority Class Gradients and Representations Enhancement. MinGRE employs a multi-dimensional attention mechanism to reweight spatiotemporal gradients, minimizing the gradient distribution discrepancies across classes. Additionally, we introduce an uncertainty-guided contrastive loss to improve the inter-class separability and intra-class compactness of minority representations with higher uncertainty. Extensive experiments demonstrate that the MinGRE framework not only significantly reduces the performance disparity across classes but also achieves enhanced robustness compared to existing baselines. These findings underscore the potential of our method in fostering the development of more equitable and robust models.</li>
</ul>

<h3>Title: Aplicação de Large Language Models na Análise e Síntese de Documentos Jurídicos: Uma Revisão de Literatura</h3>
<ul>
<li><strong>Authors: </strong>Matheus Belarmino, Rackel Coelho, Roberto Lotudo, Jayr Pereira</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00725">https://arxiv.org/abs/2504.00725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00725">https://arxiv.org/pdf/2504.00725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00725]] Aplicação de Large Language Models na Análise e Síntese de Documentos Jurídicos: Uma Revisão de Literatura(https://arxiv.org/abs/2504.00725)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have been increasingly used to optimize the analysis and synthesis of legal documents, enabling the automation of tasks such as summarization, classification, and retrieval of legal information. This study aims to conduct a systematic literature review to identify the state of the art in prompt engineering applied to LLMs in the legal context. The results indicate that models such as GPT-4, BERT, Llama 2, and Legal-Pegasus are widely employed in the legal field, and techniques such as Few-shot Learning, Zero-shot Learning, and Chain-of-Thought prompting have proven effective in improving the interpretation of legal texts. However, challenges such as biases in models and hallucinations still hinder their large-scale implementation. It is concluded that, despite the great potential of LLMs for the legal field, there is a need to improve prompt engineering strategies to ensure greater accuracy and reliability in the generated results.</li>
</ul>

<h3>Title: EMO: Edge Model Overlays to Scale Model Size in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Di Wu, Weibo He, Wanglei Feng, Zhenyu Wen, Bin Qian, Blesson Varghese</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00726">https://arxiv.org/abs/2504.00726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00726">https://arxiv.org/pdf/2504.00726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00726]] EMO: Edge Model Overlays to Scale Model Size in Federated Learning(https://arxiv.org/abs/2504.00726)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) trains machine learning models on edge devices with distributed data. However, the computational and memory limitations of these devices restrict the training of large models using FL. Split Federated Learning (SFL) addresses this challenge by distributing the model across the device and server, but it introduces a tightly coupled data flow, leading to computational bottlenecks and high communication costs. We propose EMO as a solution to enable the training of large models in FL while mitigating the challenges of SFL. EMO introduces Edge Model Overlay(s) between the device and server, enabling the creation of a larger ensemble model without modifying the FL workflow. The key innovation in EMO is Augmented Federated Learning (AFL), which builds an ensemble model by connecting the original (smaller) FL model with model(s) trained in the overlay(s) to facilitate horizontal or vertical scaling. This is accomplished through three key modules: a hierarchical activation replay cache to decouple AFL from FL, a convergence-aware communication controller to optimize communication overhead, and an ensemble inference module. Evaluations on a real-world prototype show that EMO improves accuracy by up to 17.77% compared to FL, and reduces communication costs by up to 7.17x and decreases training time by up to 6.9x compared to SFL.</li>
</ul>

<h3>Title: IHC-LLMiner: Automated extraction of tumour immunohistochemical profiles from PubMed abstracts using large language models</h3>
<ul>
<li><strong>Authors: </strong>Yunsoo Kim, Michal W. S. Ong, Daniel W. Rogalsky, Manuel Rodriguez-Justo, Honghan Wu, Adam P. Levine</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00748">https://arxiv.org/abs/2504.00748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00748">https://arxiv.org/pdf/2504.00748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00748]] IHC-LLMiner: Automated extraction of tumour immunohistochemical profiles from PubMed abstracts using large language models(https://arxiv.org/abs/2504.00748)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Immunohistochemistry (IHC) is essential in diagnostic pathology and biomedical research, offering critical insights into protein expression and tumour biology. This study presents an automated pipeline, IHC-LLMiner, for extracting IHC-tumour profiles from PubMed abstracts, leveraging advanced biomedical text mining. There are two subtasks: abstract classification (include/exclude as relevant) and IHC-tumour profile extraction on relevant included abstracts. The best-performing model, "Gemma-2 finetuned", achieved 91.5% accuracy and an F1 score of 91.4, outperforming GPT4-O by 9.5% accuracy with 5.9 times faster inference time. From an initial dataset of 107,759 abstracts identified for 50 immunohistochemical markers, the classification task identified 30,481 relevant abstracts (Include) using the Gemma-2 finetuned model. For IHC-tumour profile extraction, the Gemma-2 finetuned model achieved the best performance with 63.3% Correct outputs. Extracted IHC-tumour profiles (tumour types and markers) were normalised to Unified Medical Language System (UMLS) concepts to ensure consistency and facilitate IHC-tumour profile landscape analysis. The extracted IHC-tumour profiles demonstrated excellent concordance with available online summary data and provided considerable added value in terms of both missing IHC-tumour profiles and quantitative assessments. Our proposed LLM based pipeline provides a practical solution for large-scale IHC-tumour profile data mining, enhancing the accessibility and utility of such data for research and clinical applications as well as enabling the generation of quantitative and structured data to support cancer-specific knowledge base development. Models and training datasets are available at this https URL.</li>
</ul>

<h3>Title: LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sameer Sadruddin, Jennifer D'Souza, Eleni Poupaki, Alex Watkins, Hamed Babaei Giglou, Anisa Rula, Bora Karasulu, Sören Auer, Adrie Mackus, Erwin Kessels</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00752">https://arxiv.org/abs/2504.00752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00752">https://arxiv.org/pdf/2504.00752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00752]] LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models(https://arxiv.org/abs/2504.00752)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Extracting structured information from unstructured text is crucial for modeling real-world processes, but traditional schema mining relies on semi-structured data, limiting scalability. This paper introduces schema-miner, a novel tool that combines large language models with human feedback to automate and refine schema extraction. Through an iterative workflow, it organizes properties from text, incorporates expert input, and integrates domain-specific ontologies for semantic depth. Applied to materials science--specifically atomic layer deposition--schema-miner demonstrates that expert-guided LLMs generate semantically rich schemas suitable for diverse real-world applications.</li>
</ul>

<h3>Title: CAPE: Connectivity-Aware Path Enforcement Loss for Curvilinear Structure Delineation</h3>
<ul>
<li><strong>Authors: </strong>Elyar Esmaeilzadeh, Ehsan Garaaghaji, Farzad Hallaji Azad, Doruk Oner</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00753">https://arxiv.org/abs/2504.00753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00753">https://arxiv.org/pdf/2504.00753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00753]] CAPE: Connectivity-Aware Path Enforcement Loss for Curvilinear Structure Delineation(https://arxiv.org/abs/2504.00753)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Promoting the connectivity of curvilinear structures, such as neuronal processes in biomedical scans and blood vessels in CT images, remains a key challenge in semantic segmentation. Traditional pixel-wise loss functions, including cross-entropy and Dice losses, often fail to capture high-level topological connectivity, resulting in topological mistakes in graphs obtained from prediction maps. In this paper, we propose CAPE (Connectivity-Aware Path Enforcement), a novel loss function designed to enforce connectivity in graphs obtained from segmentation maps by optimizing a graph connectivity metric. CAPE uses the graph representation of the ground truth to select node pairs and determine their corresponding paths within the predicted segmentation through a shortest-path algorithm. Using this, we penalize both disconnections and false positive connections, effectively promoting the model to preserve topological correctness. Experiments on 2D and 3D datasets, including neuron and blood vessel tracing demonstrate that CAPE significantly improves topology-aware metrics and outperforms state-of-the-art methods.</li>
</ul>

<h3>Title: Automated Feature Labeling with Token-Space Gradient Descent</h3>
<ul>
<li><strong>Authors: </strong>Julian Schulz, Seamus Fallows</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00754">https://arxiv.org/abs/2504.00754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00754">https://arxiv.org/pdf/2504.00754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00754]] Automated Feature Labeling with Token-Space Gradient Descent(https://arxiv.org/abs/2504.00754)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We present a novel approach to feature labeling using gradient descent in token-space. While existing methods typically use language models to generate hypotheses about feature meanings, our method directly optimizes label representations by using a language model as a discriminator to predict feature activations. We formulate this as a multi-objective optimization problem in token-space, balancing prediction accuracy, entropy minimization, and linguistic naturalness. Our proof-of-concept experiments demonstrate successful convergence to interpretable single-token labels across diverse domains, including features for detecting animals, mammals, Chinese text, and numbers. Although our current implementation is constrained to single-token labels and relatively simple features, the results suggest that token-space gradient descent could become a valuable addition to the interpretability researcher's toolkit.</li>
</ul>

<h3>Title: RECKON: Large-scale Reference-based Efficient Knowledge Evaluation for Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Lin Zhang, Zhouhong Gu, Xiaoran Shi, Hongwei Feng, Yanghua Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00756">https://arxiv.org/abs/2504.00756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00756">https://arxiv.org/pdf/2504.00756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00756]] RECKON: Large-scale Reference-based Efficient Knowledge Evaluation for Large Language Model(https://arxiv.org/abs/2504.00756)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) advance, efficient knowledge evaluation becomes crucial to verifying their capabilities. Traditional methods, relying on benchmarks, face limitations such as high resource costs and information loss. We propose the Large-scale Reference-based Efficient Knowledge Evaluation for Large Language Model (RECKON), which directly uses reference data to evaluate models. RECKON organizes unstructured data into manageable units and generates targeted questions for each cluster, improving evaluation accuracy and efficiency. Experimental results show that RECKON reduces resource consumption by 56.5% compared to traditional methods while achieving over 97% accuracy across various domains, including world knowledge, code, legal, and biomedical datasets. Code is available at this https URL</li>
</ul>

<h3>Title: Integrating Fourier Neural Operators with Diffusion Models to improve Spectral Representation of Synthetic Earthquake Ground Motion Response</h3>
<ul>
<li><strong>Authors: </strong>Niccolò Perrone, Fanny Lehmann, Hugo Gabrielidis, Stefania Fresca, Filippo Gatti</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00757">https://arxiv.org/abs/2504.00757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00757">https://arxiv.org/pdf/2504.00757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00757]] Integrating Fourier Neural Operators with Diffusion Models to improve Spectral Representation of Synthetic Earthquake Ground Motion Response(https://arxiv.org/abs/2504.00757)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Nuclear reactor buildings must be designed to withstand the dynamic load induced by strong ground motion earthquakes. For this reason, their structural behavior must be assessed in multiple realistic ground shaking scenarios (e.g., the Maximum Credible Earthquake). However, earthquake catalogs and recorded seismograms may not always be available in the region of interest. Therefore, synthetic earthquake ground motion is progressively being employed, although with some due precautions: earthquake physics is sometimes not well enough understood to be accurately reproduced with numerical tools, and the underlying epistemic uncertainties lead to prohibitive computational costs related to model calibration. In this study, we propose an AI physics-based approach to generate synthetic ground motion, based on the combination of a neural operator that approximates the elastodynamics Green's operator in arbitrary source-geology setups, enhanced by a denoising diffusion probabilistic model. The diffusion model is trained to correct the ground motion time series generated by the neural operator. Our results show that such an approach promisingly enhances the realism of the generated synthetic seismograms, with frequency biases and Goodness-Of-Fit (GOF) scores being improved by the diffusion model. This indicates that the latter is capable to mitigate the mid-frequency spectral falloff observed in the time series generated by the neural operator. Our method showcases fast and cheap inference in different site and source conditions.</li>
</ul>

<h3>Title: TAMIS: Tailored Membership Inference Attacks on Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Paul Andrey, Batiste Le Bars, Marc Tommasi</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00758">https://arxiv.org/abs/2504.00758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00758">https://arxiv.org/pdf/2504.00758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00758]] TAMIS: Tailored Membership Inference Attacks on Synthetic Data(https://arxiv.org/abs/2504.00758)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Membership Inference Attacks (MIA) enable to empirically assess the privacy of a machine learning algorithm. In this paper, we propose TAMIS, a novel MIA against differentially-private synthetic data generation methods that rely on graphical models. This attack builds upon MAMA-MIA, a recently-published state-of-the-art method. It lowers its computational cost and requires less attacker knowledge. Our attack is the product of a two-fold improvement. First, we recover the graphical model having generated a synthetic dataset by using solely that dataset, rather than shadow-modeling over an auxiliary one. This proves less costly and more performant. Second, we introduce a more mathematically-grounded attack score, that provides a natural threshold for binary predictions. In our experiments, TAMIS achieves better or similar performance as MAMA-MIA on replicas of the SNAKE challenge.</li>
</ul>

<h3>Title: MSSFC-Net:Enhancing Building Interpretation with Multi-Scale Spatial-Spectral Feature Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Dehua Huo, Weida Zhan, Jinxin Guo, Depeng Zhu, Yu Chen, YiChun Jiang, Yueyi Han, Deng Han, Jin Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00759">https://arxiv.org/abs/2504.00759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00759">https://arxiv.org/pdf/2504.00759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00759]] MSSFC-Net:Enhancing Building Interpretation with Multi-Scale Spatial-Spectral Feature Collaboration(https://arxiv.org/abs/2504.00759)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Building interpretation from remote sensing imagery primarily involves two fundamental tasks: building extraction and change detection. However, most existing methods address these tasks independently, overlooking their inherent correlation and failing to exploit shared feature representations for mutual enhancement. Furthermore, the diverse spectral,spatial, and scale characteristics of buildings pose additional challenges in jointly modeling spatial-spectral multi-scale features and effectively balancing precision and recall. The limited synergy between spatial and spectral representations often results in reduced detection accuracy and incomplete change this http URL address these challenges, we propose a Multi-Scale Spatial-Spectral Feature Cooperative Dual-Task Network (MSSFC-Net) for joint building extraction and change detection in remote sensing images. The framework integrates both tasks within a unified architecture, leveraging their complementary nature to simultaneously extract building and change features. Specifically,a Dual-branch Multi-scale Feature Extraction module (DMFE) with Spatial-Spectral Feature Collaboration (SSFC) is designed to enhance multi-scale representation learning, effectively capturing shallow texture details and deep semantic information, thus improving building extraction performance. For temporal feature aggregation, we introduce a Multi-scale Differential Fusion Module (MDFM) that explicitly models the interaction between differential and dual-temporal features. This module refines the network's capability to detect large-area changes and subtle structural variations in buildings. Extensive experiments conducted on three benchmark datasets demonstrate that MSSFC-Net achieves superior performance in both building extraction and change detection tasks, effectively improving detection accuracy while maintaining completeness.</li>
</ul>

<h3>Title: Automated Explanation of Machine Learning Models of Footballing Actions in Words</h3>
<ul>
<li><strong>Authors: </strong>Pegah Rahimian, Jernej Flisar, David Sumpter</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00767">https://arxiv.org/abs/2504.00767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00767">https://arxiv.org/pdf/2504.00767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00767]] Automated Explanation of Machine Learning Models of Footballing Actions in Words(https://arxiv.org/abs/2504.00767)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While football analytics has changed the way teams and analysts assess performance, there remains a communication gap between machine learning practice and how coaching staff talk about football. Coaches and practitioners require actionable insights, which are not always provided by models. To bridge this gap, we show how to build wordalizations (a novel approach that leverages large language models) for shots in football. Specifically, we first build an expected goals model using logistic regression. We then use the co-efficients of this regression model to write sentences describing how factors (such as distance, angle and defensive pressure) contribute to the model's prediction. Finally, we use large language models to give an entertaining description of the shot. We describe our approach in a model card and provide an interactive open-source application describing shots in recent tournaments. We discuss how shot wordalisations might aid communication in coaching and football commentary, and give a further example of how the same approach can be applied to other actions in football.</li>
</ul>

<h3>Title: DropGaussian: Structural Regularization for Sparse-view Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Hyunwoo Park, Gun Ryu, Wonjun Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00773">https://arxiv.org/abs/2504.00773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00773">https://arxiv.org/pdf/2504.00773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00773]] DropGaussian: Structural Regularization for Sparse-view Gaussian Splatting(https://arxiv.org/abs/2504.00773)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recently, 3D Gaussian splatting (3DGS) has gained considerable attentions in the field of novel view synthesis due to its fast performance while yielding the excellent image quality. However, 3DGS in sparse-view settings (e.g., three-view inputs) often faces with the problem of overfitting to training views, which significantly drops the visual quality of novel view images. Many existing approaches have tackled this issue by using strong priors, such as 2D generative contextual information and external depth signals. In contrast, this paper introduces a prior-free method, so-called DropGaussian, with simple changes in 3D Gaussian splatting. Specifically, we randomly remove Gaussians during the training process in a similar way of dropout, which allows non-excluded Gaussians to have larger gradients while improving their visibility. This makes the remaining Gaussians to contribute more to the optimization process for rendering with sparse input views. Such simple operation effectively alleviates the overfitting problem and enhances the quality of novel view synthesis. By simply applying DropGaussian to the original 3DGS framework, we can achieve the competitive performance with existing prior-based 3DGS methods in sparse-view settings of benchmark datasets without any additional complexity. The code and model are publicly available at: this https URL release.</li>
</ul>

<h3>Title: Digitally Supported Analysis of Spontaneous Speech (DigiSpon): Benchmarking NLP-Supported Language Sample Analysis of Swiss Children's Speech</h3>
<ul>
<li><strong>Authors: </strong>Anja Ryser, Yingqiang Gao, Sarah Ebling</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00780">https://arxiv.org/abs/2504.00780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00780">https://arxiv.org/pdf/2504.00780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00780]] Digitally Supported Analysis of Spontaneous Speech (DigiSpon): Benchmarking NLP-Supported Language Sample Analysis of Swiss Children's Speech(https://arxiv.org/abs/2504.00780)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Language sample analysis (LSA) is a process that complements standardized psychometric tests for diagnosing, for example, developmental language disorder (DLD) in children. However, its labor-intensive nature has limited its use in speech-language pathology practice. We introduce an approach that leverages natural language processing (NLP) methods not based on commercial large language models (LLMs) applied to transcribed speech data from 119 children in the German speaking part of Switzerland with typical and atypical language development. The study aims to identify optimal practices that support speech-language pathologists in diagnosing DLD more efficiently within a human-in-the-loop framework, without relying on potentially unethical implementations that leverage commercial LLMs. Preliminary findings underscore the potential of integrating locally deployed NLP methods into the process of semi-automatic LSA.</li>
</ul>

<h3>Title: CellVTA: Enhancing Vision Foundation Models for Accurate Cell Segmentation and Classification</h3>
<ul>
<li><strong>Authors: </strong>Yang Yang, Xijie Xu, Yixun Zhou, Jie Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00784">https://arxiv.org/abs/2504.00784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00784">https://arxiv.org/pdf/2504.00784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00784]] CellVTA: Enhancing Vision Foundation Models for Accurate Cell Segmentation and Classification(https://arxiv.org/abs/2504.00784)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Cell instance segmentation is a fundamental task in digital pathology with broad clinical applications. Recently, vision foundation models, which are predominantly based on Vision Transformers (ViTs), have achieved remarkable success in pathology image analysis. However, their improvements in cell instance segmentation remain limited. A key challenge arises from the tokenization process in ViTs, which substantially reduces the spatial resolution of input images, leading to suboptimal segmentation quality, especially for small and densely packed cells. To address this problem, we propose CellVTA (Cell Vision Transformer with Adapter), a novel method that improves the performance of vision foundation models for cell instance segmentation by incorporating a CNN-based adapter module. This adapter extracts high-resolution spatial information from input images and injects it into the ViT through a cross-attention mechanism. Our method preserves the core architecture of ViT, ensuring seamless integration with pretrained foundation models. Extensive experiments show that CellVTA achieves 0.538 mPQ on the CoNIC dataset and 0.506 mPQ on the PanNuke dataset, which significantly outperforms the state-of-the-art cell segmentation methods. Ablation studies confirm the superiority of our approach over other fine-tuning strategies, including decoder-only fine-tuning and full fine-tuning. Our code and models are publicly available at this https URL.</li>
</ul>

<h3>Title: Conditional Temporal Neural Processes with Covariance Loss</h3>
<ul>
<li><strong>Authors: </strong>Boseon Yoo, Jiwoo Lee, Janghoon Ju, Seijun Chung, Soyeon Kim, Jaesik Choi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00794">https://arxiv.org/abs/2504.00794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00794">https://arxiv.org/pdf/2504.00794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00794]] Conditional Temporal Neural Processes with Covariance Loss(https://arxiv.org/abs/2504.00794)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce a novel loss function, Covariance Loss, which is conceptually equivalent to conditional neural processes and has a form of regularization so that is applicable to many kinds of neural networks. With the proposed loss, mappings from input variables to target variables are highly affected by dependencies of target variables as well as mean activation and mean dependencies of input and target variables. This nature enables the resulting neural networks to become more robust to noisy observations and recapture missing dependencies from prior information. In order to show the validity of the proposed loss, we conduct extensive sets of experiments on real-world datasets with state-of-the-art models and discuss the benefits and drawbacks of the proposed Covariance Loss.</li>
</ul>

<h3>Title: Z1: Efficient Test-time Scaling with Code</h3>
<ul>
<li><strong>Authors: </strong>Zhaojian Yu, Yinghao Wu, Yilun Zhao, Arman Cohan, Xiao-Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00810">https://arxiv.org/abs/2504.00810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00810">https://arxiv.org/pdf/2504.00810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00810]] Z1: Efficient Test-time Scaling with Code(https://arxiv.org/abs/2504.00810)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) can achieve enhanced complex problem-solving through test-time computing scaling, yet this often entails longer contexts and numerous reasoning token costs. In this paper, we propose an efficient test-time scaling method that trains LLMs on code-related reasoning trajectories, facilitating their reduction of excess thinking tokens while maintaining performance. First, we create Z1-Code-Reasoning-107K, a curated dataset of simple and complex coding problems paired with their short and long solution trajectories. Second, we present a novel Shifted Thinking Window to mitigate overthinking overhead by removing context-delimiting tags (e.g., <think>. . . </think>) and capping reasoning tokens. Trained with long and short trajectory data and equipped with Shifted Thinking Window, our model, Z1-7B, demonstrates the ability to adjust its reasoning level as the complexity of problems and exhibits efficient test-time scaling across different reasoning tasks that matches R1-Distill-Qwen-7B performance with about 30% of its average thinking tokens. Notably, fine-tuned with only code trajectories, Z1-7B demonstrates generalization to broader reasoning tasks (47.5% on GPQA Diamond). Our analysis of efficient reasoning elicitation also provides valuable insights for future research.</li>
</ul>

<h3>Title: Scaling Prompt Instructed Zero Shot Composed Image Retrieval with Image-Only Data</h3>
<ul>
<li><strong>Authors: </strong>Yiqun Duan, Sameera Ramasinghe, Stephen Gould, Ajanthan Thalaiyasingam</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00812">https://arxiv.org/abs/2504.00812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00812">https://arxiv.org/pdf/2504.00812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00812]] Scaling Prompt Instructed Zero Shot Composed Image Retrieval with Image-Only Data(https://arxiv.org/abs/2504.00812)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Composed Image Retrieval (CIR) is the task of retrieving images matching a reference image augmented with a text, where the text describes changes to the reference image in natural language. Traditionally, models designed for CIR have relied on triplet data containing a reference image, reformulation text, and a target image. However, curating such triplet data often necessitates human intervention, leading to prohibitive costs. This challenge has hindered the scalability of CIR model training even with the availability of abundant unlabeled data. With the recent advances in foundational models, we advocate a shift in the CIR training paradigm where human annotations can be efficiently replaced by large language models (LLMs). Specifically, we demonstrate the capability of large captioning and language models in efficiently generating data for CIR only relying on unannotated image collections. Additionally, we introduce an embedding reformulation architecture that effectively combines image and text modalities. Our model, named InstructCIR, outperforms state-of-the-art methods in zero-shot composed image retrieval on CIRR and FashionIQ datasets. Furthermore, we demonstrate that by increasing the amount of generated data, our zero-shot model gets closer to the performance of supervised baselines.</li>
</ul>

<h3>Title: The study of non-complete-ring positron emission tomography (PET) detection method</h3>
<ul>
<li><strong>Authors: </strong>Yeqi Fang, Rong Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00816">https://arxiv.org/abs/2504.00816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00816">https://arxiv.org/pdf/2504.00816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00816]] The study of non-complete-ring positron emission tomography (PET) detection method(https://arxiv.org/abs/2504.00816)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Positron Emission Tomography (PET) is a vital molecular imaging tool widely used in medical diagnosis and treatment evaluation. Traditional PET systems typically rely on complete detector rings to achieve full angular coverage for uniform and statistically robust sampling of coincidence events. However, incomplete-ring PET scanners have emerged in various scenarios due to hardware failures, cost constraints, or specific clinical needs. In such cases, conventional reconstruction algorithms often suffer from performance degradation due to reduced data completeness and geometric inconsistencies. This thesis proposes a coarse-to-fine reconstruction framework for incomplete-ring PET scanners. The framework first employs an Attention U-Net model to recover complete sinograms from incomplete ones, then uses the OSEM algorithm for preliminary reconstruction, and finally applies a two-stage architecture comprising a Coarse Prediction Module (CPM) and an Iterative Refinement Module (IRM) for fine reconstruction. Our approach utilizes neighboring axial slices and spectral transform features as auxiliary guidance at the input level to ensure spatial and frequency domain consistency, and integrates a contrastive diffusion strategy at the output level to improve correspondence between low-quality PET inputs and refined PET outputs. Experimental results on public and in-house brain PET datasets demonstrate that the proposed method significantly outperforms existing approaches in metrics such as PSNR (35.6421 dB) and SSIM (0.9588), successfully preserving key anatomical structures and tracer distribution features, thus providing an effective solution for incomplete-ring PET imaging.</li>
</ul>

<h3>Title: Deep Generative Models: Complexity, Dimensionality, and Approximation</h3>
<ul>
<li><strong>Authors: </strong>Kevin Wang, Hongqian Niu, Yixin Wang, Didong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00820">https://arxiv.org/abs/2504.00820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00820">https://arxiv.org/pdf/2504.00820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00820]] Deep Generative Models: Complexity, Dimensionality, and Approximation(https://arxiv.org/abs/2504.00820)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative networks have shown remarkable success in learning complex data distributions, particularly in generating high-dimensional data from lower-dimensional inputs. While this capability is well-documented empirically, its theoretical underpinning remains unclear. One common theoretical explanation appeals to the widely accepted manifold hypothesis, which suggests that many real-world datasets, such as images and signals, often possess intrinsic low-dimensional geometric structures. Under this manifold hypothesis, it is widely believed that to approximate a distribution on a $d$-dimensional Riemannian manifold, the latent dimension needs to be at least $d$ or $d+1$. In this work, we show that this requirement on the latent dimension is not necessary by demonstrating that generative networks can approximate distributions on $d$-dimensional Riemannian manifolds from inputs of any arbitrary dimension, even lower than $d$, taking inspiration from the concept of space-filling curves. This approach, in turn, leads to a super-exponential complexity bound of the deep neural networks through expanded neurons. Our findings thus challenge the conventional belief on the relationship between input dimensionality and the ability of generative networks to model data distributions. This novel insight not only corroborates the practical effectiveness of generative networks in handling complex data structures, but also underscores a critical trade-off between approximation error, dimensionality, and model complexity.</li>
</ul>

<h3>Title: ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations</h3>
<ul>
<li><strong>Authors: </strong>Yubo Wang, Xueguang Ma, Ping Nie, Huaye Zeng, Zhiheng Lyu, Yuxuan Zhang, Benjamin Schneider, Yi Lu, Xiang Yue, Wenhu Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00824">https://arxiv.org/abs/2504.00824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00824">https://arxiv.org/pdf/2504.00824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00824]] ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations(https://arxiv.org/abs/2504.00824)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Academic writing requires both coherent text generation and precise citation of relevant literature. Although recent Retrieval-Augmented Generation (RAG) systems have significantly improved factual accuracy in general-purpose text generation, their capacity to adequately support professional academic writing remains limited. In this work, we introduce ScholarCopilot, a unified framework designed to enhance existing large language models for generating professional academic articles with accurate and contextually relevant citations. ScholarCopilot dynamically determines when to retrieve scholarly references by generating a retrieval token [RET], and then utilizes its representation to look up relevant citations from a database. The retrieved references are fed into the model to augment the generation process. We jointly optimize both the generation and citation tasks within a single framework to increase efficiency. Trained on 500K papers from arXiv, our model achieves a top-1 retrieval accuracy of 40.1% on our evaluation dataset, outperforming baselines such as E5-Mistral-7B-Instruct (15.0%) and BM25 (9.8%). On a dataset of 1,000 academic writing samples, ScholarCopilot scores 16.2/25 in generation quality (measured across relevance, coherence, academic rigor, completeness, and innovation), surpassing models with 10x more parameters such as Qwen-2.5-72B-Instruct (15.8/25). Human studies also confirm ScholarCopilot's superior performance in citation recall, writing efficiency, and overall user experience, confirming the effectiveness of our approach.</li>
</ul>

<h3>Title: How Difficulty-Aware Staged Reinforcement Learning Enhances LLMs' Reasoning Capabilities: A Preliminary Experimental Study</h3>
<ul>
<li><strong>Authors: </strong>Yunjie Ji, Sitong Zhao, Xiaoyu Tian, Haotian Wang, Shuaiting Chen, Yiping Peng, Han Zhao, Xiangang Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00829">https://arxiv.org/abs/2504.00829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00829">https://arxiv.org/pdf/2504.00829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00829]] How Difficulty-Aware Staged Reinforcement Learning Enhances LLMs' Reasoning Capabilities: A Preliminary Experimental Study(https://arxiv.org/abs/2504.00829)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Enhancing the reasoning capabilities of Large Language Models (LLMs) with efficiency and scalability remains a fundamental challenge in artificial intelligence research. This paper presents a rigorous experimental investigation into how difficulty-aware staged reinforcement learning (RL) strategies can substantially improve LLM reasoning performance. Through systematic analysis, we demonstrate that strategically selecting training data according to well-defined difficulty levels markedly enhances RL optimization. Moreover, we introduce a staged training methodology, progressively exposing models to increasingly challenging tasks, further amplifying reasoning capabilities. Our findings reveal significant cross-domain benefits when simultaneously training models on mathematical reasoning and code generation tasks. Notably, our proposed approach enables a 1.5B parameter model to achieve an accuracy of 42.3\% on the AIME-2024 benchmark, 89.5\% on the MATH-500 benchmark. These results underscore the efficacy of our method in advancing the reasoning proficiency of LLMs. We will open-source our datasets on GitHub and Hugging Face.</li>
</ul>

<h3>Title: Zero-Shot 4D Lidar Panoptic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yushan Zhang, Aljoša Ošep, Laura Leal-Taixé, Tim Meinhardt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00848">https://arxiv.org/abs/2504.00848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00848">https://arxiv.org/pdf/2504.00848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00848]] Zero-Shot 4D Lidar Panoptic Segmentation(https://arxiv.org/abs/2504.00848)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Zero-shot 4D segmentation and recognition of arbitrary objects in Lidar is crucial for embodied navigation, with applications ranging from streaming perception to semantic mapping and localization. However, the primary challenge in advancing research and developing generalized, versatile methods for spatio-temporal scene understanding in Lidar lies in the scarcity of datasets that provide the necessary diversity and scale of this http URL overcome these challenges, we propose SAL-4D (Segment Anything in Lidar--4D), a method that utilizes multi-modal robotic sensor setups as a bridge to distill recent developments in Video Object Segmentation (VOS) in conjunction with off-the-shelf Vision-Language foundation models to Lidar. We utilize VOS models to pseudo-label tracklets in short video sequences, annotate these tracklets with sequence-level CLIP tokens, and lift them to the 4D Lidar space using calibrated multi-modal sensory setups to distill them to our SAL-4D model. Due to temporal consistent predictions, we outperform prior art in 3D Zero-Shot Lidar Panoptic Segmentation (LPS) over $5$ PQ, and unlock Zero-Shot 4D-LPS.</li>
</ul>

<h3>Title: Global Intervention and Distillation for Federated Out-of-Distribution Generalization</h3>
<ul>
<li><strong>Authors: </strong>Zhuang Qi, Runhui Zhang, Lei Meng, Wei Wu, Yachong Zhang, Xiangxu Meng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00850">https://arxiv.org/abs/2504.00850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00850">https://arxiv.org/pdf/2504.00850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00850]] Global Intervention and Distillation for Federated Out-of-Distribution Generalization(https://arxiv.org/abs/2504.00850)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Attribute skew in federated learning leads local models to focus on learning non-causal associations, guiding them towards inconsistent optimization directions, which inevitably results in performance degradation and unstable convergence. Existing methods typically leverage data augmentation to enhance sample diversity or employ knowledge distillation to learn invariant representations. However, the instability in the quality of generated data and the lack of domain information limit their performance on unseen samples. To address these issues, this paper presents a global intervention and distillation method, termed FedGID, which utilizes diverse attribute features for backdoor adjustment to break the spurious association between background and label. It includes two main modules, where the global intervention module adaptively decouples objects and backgrounds in images, injects background information into random samples to intervene in the sample distribution, which links backgrounds to all categories to prevent the model from treating background-label associations as causal. The global distillation module leverages a unified knowledge base to guide the representation learning of client models, preventing local models from overfitting to client-specific attributes. Experimental results on three datasets demonstrate that FedGID enhances the model's ability to focus on the main subjects in unseen data and outperforms existing methods in collaborative modeling.</li>
</ul>

<h3>Title: Exploring Personalized Federated Learning Architectures for Violence Detection in Surveillance Videos</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Kassir, Siba Haidar, Antoun Yaacoub</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00857">https://arxiv.org/abs/2504.00857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00857">https://arxiv.org/pdf/2504.00857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00857]] Exploring Personalized Federated Learning Architectures for Violence Detection in Surveillance Videos(https://arxiv.org/abs/2504.00857)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>The challenge of detecting violent incidents in urban surveillance systems is compounded by the voluminous and diverse nature of video data. This paper presents a targeted approach using Personalized Federated Learning (PFL) to address these issues, specifically employing the Federated Learning with Personalization Layers method within the Flower framework. Our methodology adapts learning models to the unique data characteristics of each surveillance node, effectively managing the heterogeneous and non-IID nature of surveillance video data. Through rigorous experiments conducted on balanced and imbalanced datasets, our PFL models demonstrated enhanced accuracy and efficiency, achieving up to 99.3% accuracy. This study underscores the potential of PFL to significantly improve the scalability and effectiveness of surveillance systems, offering a robust, privacy-preserving solution for violence detection in complex urban environments.</li>
</ul>

<h3>Title: Whispering Under the Eaves: Protecting User Privacy Against Commercial and LLM-powered Automatic Speech Recognition Systems</h3>
<ul>
<li><strong>Authors: </strong>Weifei Jin, Yuxin Cao, Junjie Su, Derui Wang, Yedi Zhang, Minhui Xue, Jie Hao, Jin Song Dong, Yixian Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00858">https://arxiv.org/abs/2504.00858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00858">https://arxiv.org/pdf/2504.00858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00858]] Whispering Under the Eaves: Protecting User Privacy Against Commercial and LLM-powered Automatic Speech Recognition Systems(https://arxiv.org/abs/2504.00858)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>The widespread application of automatic speech recognition (ASR) supports large-scale voice surveillance, raising concerns about privacy among users. In this paper, we concentrate on using adversarial examples to mitigate unauthorized disclosure of speech privacy thwarted by potential eavesdroppers in speech communications. While audio adversarial examples have demonstrated the capability to mislead ASR models or evade ASR surveillance, they are typically constructed through time-intensive offline optimization, restricting their practicality in real-time voice communication. Recent work overcame this limitation by generating universal adversarial perturbations (UAPs) and enhancing their transferability for black-box scenarios. However, they introduced excessive noise that significantly degrades audio quality and affects human perception, thereby limiting their effectiveness in practical scenarios. To address this limitation and protect live users' speech against ASR systems, we propose a novel framework, AudioShield. Central to this framework is the concept of Transferable Universal Adversarial Perturbations in the Latent Space (LS-TUAP). By transferring the perturbations to the latent space, the audio quality is preserved to a large extent. Additionally, we propose target feature adaptation to enhance the transferability of UAPs by embedding target text features into the perturbations. Comprehensive evaluation on four commercial ASR APIs (Google, Amazon, iFlytek, and Alibaba), three voice assistants, two LLM-powered ASR and one NN-based ASR demonstrates the protection superiority of AudioShield over existing competitors, and both objective and subjective evaluations indicate that AudioShield significantly improves the audio quality. Moreover, AudioShield also shows high effectiveness in real-time end-to-end scenarios, and demonstrates strong resilience against adaptive countermeasures.</li>
</ul>

<h3>Title: NeuRadar: Neural Radiance Fields for Automotive Radar Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Mahan Rafidashti, Ji Lan, Maryam Fatemi, Junsheng Fu, Lars Hammarstrand, Lennart Svensson</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00859">https://arxiv.org/abs/2504.00859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00859">https://arxiv.org/pdf/2504.00859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00859]] NeuRadar: Neural Radiance Fields for Automotive Radar Point Clouds(https://arxiv.org/abs/2504.00859)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Radar is an important sensor for autonomous driving (AD) systems due to its robustness to adverse weather and different lighting conditions. Novel view synthesis using neural radiance fields (NeRFs) has recently received considerable attention in AD due to its potential to enable efficient testing and validation but remains unexplored for radar point clouds. In this paper, we present NeuRadar, a NeRF-based model that jointly generates radar point clouds, camera images, and lidar point clouds. We explore set-based object detection methods such as DETR, and propose an encoder-based solution grounded in the NeRF geometry for improved generalizability. We propose both a deterministic and a probabilistic point cloud representation to accurately model the radar behavior, with the latter being able to capture radar's stochastic behavior. We achieve realistic reconstruction results for two automotive datasets, establishing a baseline for NeRF-based radar point cloud simulation models. In addition, we release radar data for ZOD's Sequences and Drives to enable further research in this field. To encourage further development of radar NeRFs, we release the source code for NeuRadar.</li>
</ul>

<h3>Title: Investigating the Capabilities and Limitations of Machine Learning for Identifying Bias in English Language Data with Information and Heritage Professionals</h3>
<ul>
<li><strong>Authors: </strong>Lucy Havens, Benjamin Bach, Melissa Terras, Beatrice Alex</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00860">https://arxiv.org/abs/2504.00860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00860">https://arxiv.org/pdf/2504.00860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00860]] Investigating the Capabilities and Limitations of Machine Learning for Identifying Bias in English Language Data with Information and Heritage Professionals(https://arxiv.org/abs/2504.00860)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Despite numerous efforts to mitigate their biases, ML systems continue to harm already-marginalized people. While predominant ML approaches assume bias can be removed and fair models can be created, we show that these are not always possible, nor desirable, goals. We reframe the problem of ML bias by creating models to identify biased language, drawing attention to a dataset's biases rather than trying to remove them. Then, through a workshop, we evaluated the models for a specific use case: workflows of information and heritage professionals. Our findings demonstrate the limitations of ML for identifying bias due to its contextual nature, the way in which approaches to mitigating it can simultaneously privilege and oppress different communities, and its inevitability. We demonstrate the need to expand ML approaches to bias and fairness, providing a mixed-methods approach to investigating the feasibility of removing bias or achieving fairness in a given ML use case.</li>
</ul>

<h3>Title: Balancing Multi-Target Semi-Supervised Medical Image Segmentation with Collaborative Generalist and Specialists</h3>
<ul>
<li><strong>Authors: </strong>You Wang, Zekun Li, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00862">https://arxiv.org/abs/2504.00862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00862">https://arxiv.org/pdf/2504.00862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00862]] Balancing Multi-Target Semi-Supervised Medical Image Segmentation with Collaborative Generalist and Specialists(https://arxiv.org/abs/2504.00862)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Despite the promising performance achieved by current semi-supervised models in segmenting individual medical targets, many of these models suffer a notable decrease in performance when tasked with the simultaneous segmentation of multiple targets. A vital factor could be attributed to the imbalanced scales among different targets: during simultaneously segmenting multiple targets, large targets dominate the loss, leading to small targets being misclassified as larger ones. To this end, we propose a novel method, which consists of a Collaborative Generalist and several Specialists, termed CGS. It is centered around the idea of employing a specialist for each target class, thus avoiding the dominance of larger targets. The generalist performs conventional multi-target segmentation, while each specialist is dedicated to distinguishing a specific target class from the remaining target classes and the background. Based on a theoretical insight, we demonstrate that CGS can achieve a more balanced training. Moreover, we develop cross-consistency losses to foster collaborative learning between the generalist and the specialists. Lastly, regarding their intrinsic relation that the target class of any specialized head should belong to the remaining classes of the other heads, we introduce an inter-head error detection module to further enhance the quality of pseudo-labels. Experimental results on three popular benchmarks showcase its superior performance compared to state-of-the-art methods.</li>
</ul>

<h3>Title: m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaoke Huang, Juncheng Wu, Hui Liu, Xianfeng Tang, Yuyin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00869">https://arxiv.org/abs/2504.00869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00869">https://arxiv.org/pdf/2504.00869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00869]] m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models(https://arxiv.org/abs/2504.00869)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from mathematical tasks in terms of knowledge representation and decision-making processes. In this paper, we provide the first comprehensive investigation of test-time scaling for medical reasoning and present m1, a simple yet effective approach that increases a model's medical reasoning capability at inference. Our evaluation across diverse medical tasks demonstrates that test-time scaling consistently enhances medical reasoning, enabling lightweight fine-tuned models under 10B parameters to establish new state-of-the-art performance, while our 32B model rivals previous 70B-scale medical LLMs. However, we identify an optimal reasoning token budget of approximately 4K, beyond which performance may degrade due to overthinking. Budget forcing, which extends test-time computation through iterative prompts, helps models double-check answers but does not necessarily improve the overall medical QA performance and, in some cases, even introduces errors into previously correct responses. Our case-by-case analysis identifies insufficient medical knowledge as a key bottleneck that prevents further performance gains through test-time scaling. We find that increasing data scale, improving data quality, and expanding model capacity consistently enhance medical knowledge grounding, enabling continued performance improvements, particularly on challenging medical benchmarks where smaller models reach saturation. These findings underscore fundamental differences between medical and mathematical reasoning in LLMs, highlighting that enriched medical knowledge, other than increased reasoning depth alone, is essential for realizing the benefits of test-time scaling.</li>
</ul>

<h3>Title: Data-free Knowledge Distillation with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaohua Qi, Renda Li, Long Peng, Qiang Ling, Jun Yu, Ziyi Chen, Peng Chang, Mei Han, Jing Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00870">https://arxiv.org/abs/2504.00870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00870">https://arxiv.org/pdf/2504.00870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00870]] Data-free Knowledge Distillation with Diffusion Models(https://arxiv.org/abs/2504.00870)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, data-free</a></li>
<li><strong>Abstract: </strong>Recently Data-Free Knowledge Distillation (DFKD) has garnered attention and can transfer knowledge from a teacher neural network to a student neural network without requiring any access to training data. Although diffusion models are adept at synthesizing high-fidelity photorealistic images across various domains, existing methods cannot be easiliy implemented to DFKD. To bridge that gap, this paper proposes a novel approach based on diffusion models, DiffDFKD. Specifically, DiffDFKD involves targeted optimizations in two key areas. Firstly, DiffDFKD utilizes valuable information from teacher models to guide the pre-trained diffusion models' data synthesis, generating datasets that mirror the training data distribution and effectively bridge domain gaps. Secondly, to reduce computational burdens, DiffDFKD introduces Latent CutMix Augmentation, an efficient technique, to enhance the diversity of diffusion model-generated images for DFKD while preserving key attributes for effective knowledge transfer. Extensive experiments validate the efficacy of DiffDFKD, yielding state-of-the-art results exceeding existing DFKD approaches. We release our code at this https URL.</li>
</ul>

<h3>Title: P2NIA: Privacy-Preserving Non-Iterative Auditing</h3>
<ul>
<li><strong>Authors: </strong>Jade Garcia Bourrée, Hadrien Lautraite, Sébastien Gambs, Gilles Tredan, Erwan Le Merrer, Benoît Rottembourg</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00874">https://arxiv.org/abs/2504.00874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00874">https://arxiv.org/pdf/2504.00874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00874]] P2NIA: Privacy-Preserving Non-Iterative Auditing(https://arxiv.org/abs/2504.00874)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>The emergence of AI legislation has increased the need to assess the ethical compliance of high-risk AI systems. Traditional auditing methods rely on platforms' application programming interfaces (APIs), where responses to queries are examined through the lens of fairness requirements. However, such approaches put a significant burden on platforms, as they are forced to maintain APIs while ensuring privacy, facing the possibility of data leaks. This lack of proper collaboration between the two parties, in turn, causes a significant challenge to the auditor, who is subject to estimation bias as they are unaware of the data distribution of the platform. To address these two issues, we present P2NIA, a novel auditing scheme that proposes a mutually beneficial collaboration for both the auditor and the platform. Extensive experiments demonstrate P2NIA's effectiveness in addressing both issues. In summary, our work introduces a privacy-preserving and non-iterative audit scheme that enhances fairness assessments using synthetic or local data, avoiding the challenges associated with traditional API-based audits.</li>
</ul>

<h3>Title: WISE-TTT:Worldwide Information Segmentation Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Fenglei Hao, Yuliang Yang, Ruiyuan Su, Zhengran Zhao, Yukun Qiao, Mengyu Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00879">https://arxiv.org/abs/2504.00879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00879">https://arxiv.org/pdf/2504.00879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00879]] WISE-TTT:Worldwide Information Segmentation Enhancement(https://arxiv.org/abs/2504.00879)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Video multi-target segmentation remains a major challenge in long sequences, mainly due to the inherent limitations of existing architectures in capturing global temporal dependencies. We introduce WISE-TTT, a synergistic architecture integrating Test-Time Training (TTT) mechanisms with the Transformer architecture through co-design. The TTT layer systematically compresses historical temporal data to generate hidden states containing worldwide information(Lossless memory to maintain long contextual integrity), while achieving multi-stage contextual aggregation through splicing. Crucially, our framework provides the first empirical validation that implementing worldwide information across multiple network layers is essential for optimal dependency this http URL studies show TTT modules at high-level features boost global modeling. This translates to 3.1% accuracy improvement(J&F metric) on Davis2017 long-term benchmarks -- the first proof of hierarchical context superiority in video segmentation. We provide the first systematic evidence that worldwide information critically impacts segmentation performance.</li>
</ul>

<h3>Title: Detection of Anomalous Vehicular Traffic and Sensor Failures Using Data Clustering Techniques</h3>
<ul>
<li><strong>Authors: </strong>Davide Moretti, Elia Onofri, Emiliano Cristiani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00881">https://arxiv.org/abs/2504.00881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00881">https://arxiv.org/pdf/2504.00881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00881]] Detection of Anomalous Vehicular Traffic and Sensor Failures Using Data Clustering Techniques(https://arxiv.org/abs/2504.00881)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The increasing availability of traffic data from sensor networks has created new opportunities for understanding vehicular dynamics and identifying anomalies. In this study, we employ clustering techniques to analyse traffic flow data with the dual objective of uncovering meaningful traffic patterns and detecting anomalies, including sensor failures and irregular congestion events. We explore multiple clustering approaches, i.e partitioning and hierarchical methods, combined with various time-series representations and similarity measures. Our methodology is applied to real-world data from highway sensors, enabling us to assess the impact of different clustering frameworks on traffic pattern recognition. We also introduce a clustering-driven anomaly detection methodology that identifies deviations from expected traffic behaviour based on distance-based anomaly scores. Results indicate that hierarchical clustering with symbolic representations provides robust segmentation of traffic patterns, while partitioning methods such as k-means and fuzzy c-means yield meaningful results when paired with Dynamic Time Warping. The proposed anomaly detection strategy successfully identifies sensor malfunctions and abnormal traffic conditions with minimal false positives, demonstrating its practical utility for real-time monitoring. Real-world vehicular traffic data are provided by Autostrade Alto Adriatico S.p.A.</li>
</ul>

<h3>Title: Improved Visual-Spatial Reasoning via R1-Zero-Like Training</h3>
<ul>
<li><strong>Authors: </strong>Zhenyi Liao, Qingsong Xie, Yanhao Zhang, Zijian Kong, Haonan Lu, Zhenyu Yang, Zhijie Deng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00883">https://arxiv.org/abs/2504.00883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00883">https://arxiv.org/pdf/2504.00883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00883]] Improved Visual-Spatial Reasoning via R1-Zero-Like Training(https://arxiv.org/abs/2504.00883)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Increasing attention has been placed on improving the reasoning capacities of multi-modal large language models (MLLMs). As the cornerstone for AI agents that function in the physical realm, video-based visual-spatial intelligence (VSI) emerges as one of the most pivotal reasoning capabilities of MLLMs. This work conducts a first, in-depth study on improving the visual-spatial reasoning of MLLMs via R1-Zero-like training. Technically, we first identify that the visual-spatial reasoning capacities of small- to medium-sized Qwen2-VL models cannot be activated via Chain of Thought (CoT) prompts. We then incorporate GRPO training for improved visual-spatial reasoning, using the carefully curated VSI-100k dataset, following DeepSeek-R1-Zero. During the investigation, we identify the necessity to keep the KL penalty (even with a small value) in GRPO. With just 120 GPU hours, our vsGRPO-2B model, fine-tuned from Qwen2-VL-2B, can outperform the base model by 12.1% and surpass GPT-4o. Moreover, our vsGRPO-7B model, fine-tuned from Qwen2-VL-7B, achieves performance comparable to that of the best open-source model LLaVA-NeXT-Video-72B. Additionally, we compare vsGRPO to supervised fine-tuning and direct preference optimization baselines and observe strong performance superiority. The code and dataset will be available soon.</li>
</ul>

<h3>Title: GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jian Zhao, Runze Liu, Kaiyan Zhang, Zhimu Zhou, Junqi Gao, Dong Li, Jiafei Lyu, Zhouyi Qian, Biqing Qi, Xiu Li, Bowen Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00891">https://arxiv.org/abs/2504.00891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00891">https://arxiv.org/pdf/2504.00891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00891]] GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning(https://arxiv.org/abs/2504.00891)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have shown that it is promising to utilize Process Reward Models (PRMs) as verifiers to enhance the performance of LLMs. However, current PRMs face three key challenges: (1) limited process supervision and generalization capabilities, (2) dependence on scalar value prediction without leveraging the generative abilities of LLMs, and (3) inability to scale the test-time compute of PRMs. In this work, we introduce GenPRM, a generative process reward model that performs explicit Chain-of-Thought (CoT) reasoning with code verification before providing judgment for each reasoning step. To obtain high-quality process supervision labels and rationale data, we propose Relative Progress Estimation (RPE) and a rationale synthesis framework that incorporates code verification. Experimental results on ProcessBench and several mathematical reasoning tasks show that GenPRM significantly outperforms prior PRMs with only 23K training data from MATH dataset. Through test-time scaling, a 1.5B GenPRM outperforms GPT-4o, and a 7B GenPRM surpasses Qwen2.5-Math-PRM-72B on ProcessBench. Additionally, GenPRM demonstrates strong abilities to serve as a critic model for policy model refinement. This work establishes a new paradigm for process supervision that bridges the gap between PRMs and critic models in LLMs. Our code, model, and data will be available in this https URL.</li>
</ul>

<h3>Title: A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities</h3>
<ul>
<li><strong>Authors: </strong>Enzhe Sun, Yongchuan Cui, Peng Liu, Jining Yan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00901">https://arxiv.org/abs/2504.00901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00901">https://arxiv.org/pdf/2504.00901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00901]] A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities(https://arxiv.org/abs/2504.00901)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Hardware limitations and satellite launch costs make direct acquisition of high temporal-spatial resolution remote sensing imagery challenging. Remote sensing spatiotemporal fusion (STF) technology addresses this problem by merging high temporal but low spatial resolution imagery with high spatial but low temporal resolution imagery to efficiently generate high spatiotemporal resolution satellite images. STF provides unprecedented observational capabilities for land surface change monitoring, agricultural management, and environmental research. Deep learning (DL) methods have revolutionized the remote sensing spatiotemporal fusion field over the past decade through powerful automatic feature extraction and nonlinear modeling capabilities, significantly outperforming traditional methods in handling complex spatiotemporal data. Despite the rapid development of DL-based remote sensing STF, the community lacks a systematic review of this quickly evolving field. This paper comprehensively reviews DL developments in remote sensing STF over the last decade, analyzing key research trends, method classifications, commonly used datasets, and evaluation metrics. It discusses major challenges in existing research and identifies promising future research directions as references for researchers in this field to inspire new ideas. The specific models, datasets, and other information mentioned in this article have been collected in: this https URL.</li>
</ul>

<h3>Title: DBF-UNet: A Two-Stage Framework for Carotid Artery Segmentation with Pseudo-Label Generation</h3>
<ul>
<li><strong>Authors: </strong>Haoxuan Li, Wei Song, Aofan Liu, Peiwu Qin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00908">https://arxiv.org/abs/2504.00908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00908">https://arxiv.org/pdf/2504.00908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00908]] DBF-UNet: A Two-Stage Framework for Carotid Artery Segmentation with Pseudo-Label Generation(https://arxiv.org/abs/2504.00908)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Medical image analysis faces significant challenges due to limited annotation data, particularly in three-dimensional carotid artery segmentation tasks, where existing datasets exhibit spatially discontinuous slice annotations with only a small portion of expert-labeled slices in complete 3D volumetric data. To address this challenge, we propose a two-stage segmentation framework. First, we construct continuous vessel centerlines by interpolating between annotated slice centroids and propagate labels along these centerlines to generate interpolated annotations for unlabeled slices. The slices with expert annotations are used for fine-tuning SAM-Med2D, while the interpolated labels on unlabeled slices serve as prompts to guide segmentation during inference. In the second stage, we propose a novel Dense Bidirectional Feature Fusion UNet (DBF-UNet). This lightweight architecture achieves precise segmentation of complete 3D vascular structures. The network incorporates bidirectional feature fusion in the encoder and integrates multi-scale feature aggregation with dense connectivity for effective feature reuse. Experimental validation on public datasets demonstrates that our proposed method effectively addresses the sparse annotation challenge in carotid artery segmentation while achieving superior performance compared to existing approaches. The source code is available at this https URL.</li>
</ul>

<h3>Title: On the Robustness of Agentic Function Calling</h3>
<ul>
<li><strong>Authors: </strong>Ella Rabinovich, Ateret Anaby-Tavor</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00914">https://arxiv.org/abs/2504.00914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00914">https://arxiv.org/pdf/2504.00914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00914]] On the Robustness of Agentic Function Calling(https://arxiv.org/abs/2504.00914)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly acting as autonomous agents, with function calling (FC) capabilities enabling them to invoke specific tools for tasks. While prior research has primarily focused on improving FC accuracy, little attention has been given to the robustness of these agents to perturbations in their input. We introduce a benchmark assessing FC robustness in two key areas: resilience to naturalistic query variations, and stability in function calling when the toolkit expands with semantically related tools. Evaluating best-performing FC models on a carefully expanded subset of the Berkeley function calling leaderboard (BFCL), we identify critical weaknesses in existing evaluation methodologies, and highlight areas for improvement in real-world agentic deployments.</li>
</ul>

<h3>Title: Benchmarking Federated Machine Unlearning methods for Tabular Data</h3>
<ul>
<li><strong>Authors: </strong>Chenguang Xiao, Abhirup Ghosh, Han Wu, Shuo Wang, Diederick van Thiel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00921">https://arxiv.org/abs/2504.00921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00921">https://arxiv.org/pdf/2504.00921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00921]] Benchmarking Federated Machine Unlearning methods for Tabular Data(https://arxiv.org/abs/2504.00921)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Machine unlearning, which enables a model to forget specific data upon request, is increasingly relevant in the era of privacy-centric machine learning, particularly within federated learning (FL) environments. This paper presents a pioneering study on benchmarking machine unlearning methods within a federated setting for tabular data, addressing the unique challenges posed by cross-silo FL where data privacy and communication efficiency are paramount. We explore unlearning at the feature and instance levels, employing both machine learning, random forest and logistic regression models. Our methodology benchmarks various unlearning algorithms, including fine-tuning and gradient-based approaches, across multiple datasets, with metrics focused on fidelity, certifiability, and computational efficiency. Experiments demonstrate that while fidelity remains high across methods, tree-based models excel in certifiability, ensuring exact unlearning, whereas gradient-based methods show improved computational efficiency. This study provides critical insights into the design and selection of unlearning algorithms tailored to the FL environment, offering a foundation for further research in privacy-preserving machine learning.</li>
</ul>

<h3>Title: S3C2 Summit 2024-08: Government Secure Supply Chain Summit</h3>
<ul>
<li><strong>Authors: </strong>Courtney Miller, William Enck, Yasemin Acar, Michel Cukier, Alexandros Kapravelos, Christian Kastner, Dominik Wermke, Laurie Williams</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00924">https://arxiv.org/abs/2504.00924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00924">https://arxiv.org/pdf/2504.00924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00924]] S3C2 Summit 2024-08: Government Secure Supply Chain Summit(https://arxiv.org/abs/2504.00924)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust</a></li>
<li><strong>Abstract: </strong>Supply chain security has become a very important vector to consider when defending against adversary attacks. Due to this, more and more developers are keen on improving their supply chains to make them more robust against future threats. On August 29, 2024 researchers from the Secure Software Supply Chain Center (S3C2) gathered 14 practitioners from 10 government agencies to discuss the state of supply chain security. The goal of the summit is to share insights between companies and developers alike to foster new collaborations and ideas moving forward. Through this meeting, participants were questions on best practices and thoughts how to improve things for the future. In this paper we summarize the responses and discussions of the summit.</li>
</ul>

<h3>Title: Multi-Token Attention</h3>
<ul>
<li><strong>Authors: </strong>Olga Golovneva, Tianlu Wang, Jason Weston, Sainbayar Sukhbaatar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00927">https://arxiv.org/abs/2504.00927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00927">https://arxiv.org/pdf/2504.00927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00927]] Multi-Token Attention(https://arxiv.org/abs/2504.00927)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Soft attention is a critical mechanism powering LLMs to locate relevant parts within a given context. However, individual attention weights are determined by the similarity of only a single query and key token vector. This "single token attention" bottlenecks the amount of information used in distinguishing a relevant part from the rest of the context. To address this issue, we propose a new attention method, Multi-Token Attention (MTA), which allows LLMs to condition their attention weights on multiple query and key vectors simultaneously. This is achieved by applying convolution operations over queries, keys and heads, allowing nearby queries and keys to affect each other's attention weights for more precise attention. As a result, our method can locate relevant context using richer, more nuanced information that can exceed a single vector's capacity. Through extensive evaluations, we demonstrate that MTA achieves enhanced performance on a range of popular benchmarks. Notably, it outperforms Transformer baseline models on standard language modeling tasks, and on tasks that require searching for information within long contexts, where our method's ability to leverage richer information proves particularly beneficial.</li>
</ul>

<h3>Title: Taxonomizing Representational Harms using Speech Act Theory</h3>
<ul>
<li><strong>Authors: </strong>Emily Corvi, Hannah Washington, Stefanie Reed, Chad Atalla, Alexandra Chouldechova, P. Alex Dow, Jean Garcia-Gathright, Nicholas Pangakis, Emily Sheng, Dan Vann, Matthew Vogel, Hanna Wallach</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00928">https://arxiv.org/abs/2504.00928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00928">https://arxiv.org/pdf/2504.00928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00928]] Taxonomizing Representational Harms using Speech Act Theory(https://arxiv.org/abs/2504.00928)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>Representational harms are widely recognized among fairness-related harms caused by generative language systems. However, their definitions are commonly under-specified. We present a framework, grounded in speech act theory (Austin, 1962), that conceptualizes representational harms caused by generative language systems as the perlocutionary effects (i.e., real-world impacts) of particular types of illocutionary acts (i.e., system behaviors). Building on this argument and drawing on relevant literature from linguistic anthropology and sociolinguistics, we provide new definitions stereotyping, demeaning, and erasure. We then use our framework to develop a granular taxonomy of illocutionary acts that cause representational harms, going beyond the high-level taxonomies presented in previous work. We also discuss the ways that our framework and taxonomy can support the development of valid measurement instruments. Finally, we demonstrate the utility of our framework and taxonomy via a case study that engages with recent conceptual debates about what constitutes a representational harm and how such harms should be measured.</li>
</ul>

<h3>Title: CFIRE: A General Method for Combining Local Explanations</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Müller, Vanessa Toborek, Tamás Horváth, Christian Bauckhage</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00930">https://arxiv.org/abs/2504.00930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00930">https://arxiv.org/pdf/2504.00930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00930]] CFIRE: A General Method for Combining Local Explanations(https://arxiv.org/abs/2504.00930)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>We propose a novel eXplainable AI algorithm to compute faithful, easy-to-understand, and complete global decision rules from local explanations for tabular data by combining XAI methods with closed frequent itemset mining. Our method can be used with any local explainer that indicates which dimensions are important for a given sample for a given black-box decision. This property allows our algorithm to choose among different local explainers, addressing the disagreement problem, \ie the observation that no single explanation method consistently outperforms others across models and datasets. Unlike usual experimental methodology, our evaluation also accounts for the Rashomon effect in model explainability. To this end, we demonstrate the robustness of our approach in finding suitable rules for nearly all of the 700 black-box models we considered across 14 benchmark datasets. The results also show that our method exhibits improved runtime, high precision and F1-score while generating compact and complete rules.</li>
</ul>

<h3>Title: InformGen: An AI Copilot for Accurate and Compliant Clinical Research Consent Document Generation</h3>
<ul>
<li><strong>Authors: </strong>Zifeng Wang, Junyi Gao, Benjamin Danek, Brandon Theodorou, Ruba Shaik, Shivashankar Thati, Seunghyun Won, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00934">https://arxiv.org/abs/2504.00934</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00934">https://arxiv.org/pdf/2504.00934</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00934]] InformGen: An AI Copilot for Accurate and Compliant Clinical Research Consent Document Generation(https://arxiv.org/abs/2504.00934)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Leveraging large language models (LLMs) to generate high-stakes documents, such as informed consent forms (ICFs), remains a significant challenge due to the extreme need for regulatory compliance and factual accuracy. Here, we present InformGen, an LLM-driven copilot for accurate and compliant ICF drafting by optimized knowledge document parsing and content generation, with humans in the loop. We further construct a benchmark dataset comprising protocols and ICFs from 900 clinical trials. Experimental results demonstrate that InformGen achieves near 100% compliance with 18 core regulatory rules derived from FDA guidelines, outperforming a vanilla GPT-4o model by up to 30%. Additionally, a user study with five annotators shows that InformGen, when integrated with manual intervention, attains over 90% factual accuracy, significantly surpassing the vanilla GPT-4o model's 57%-82%. Crucially, InformGen ensures traceability by providing inline citations to source protocols, enabling easy verification and maintaining the highest standards of factual integrity.</li>
</ul>

<h3>Title: GKAN: Explainable Diagnosis of Alzheimer's Disease Using Graph Neural Network with Kolmogorov-Arnold Networks</h3>
<ul>
<li><strong>Authors: </strong>Tianqi Ding, Dawei Xiang, Keith E Schubert, Liang Dong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00946">https://arxiv.org/abs/2504.00946</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00946">https://arxiv.org/pdf/2504.00946</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00946]] GKAN: Explainable Diagnosis of Alzheimer's Disease Using Graph Neural Network with Kolmogorov-Arnold Networks(https://arxiv.org/abs/2504.00946)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, generative</a></li>
<li><strong>Abstract: </strong>Alzheimer's Disease (AD) is a progressive neurodegenerative disorder that poses significant diagnostic challenges due to its complex etiology. Graph Convolutional Networks (GCNs) have shown promise in modeling brain connectivity for AD diagnosis, yet their reliance on linear transformations limits their ability to capture intricate nonlinear patterns in neuroimaging data. To address this, we propose GCN-KAN, a novel single-modal framework that integrates Kolmogorov-Arnold Networks (KAN) into GCNs to enhance both diagnostic accuracy and interpretability. Leveraging structural MRI data, our model employs learnable spline-based transformations to better represent brain region interactions. Evaluated on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, GCN-KAN outperforms traditional GCNs by 4-8% in classification accuracy while providing interpretable insights into key brain regions associated with AD. This approach offers a robust and explainable tool for early AD diagnosis.</li>
</ul>

<h3>Title: Personalized Federated Training of Diffusion Models with Privacy Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Kumar Kshitij Patel, Weitong Zhang, Lingxiao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00952">https://arxiv.org/abs/2504.00952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00952">https://arxiv.org/pdf/2504.00952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00952]] Personalized Federated Training of Diffusion Models with Privacy Guarantees(https://arxiv.org/abs/2504.00952)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate, fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The scarcity of accessible, compliant, and ethically sourced data presents a considerable challenge to the adoption of artificial intelligence (AI) in sensitive fields like healthcare, finance, and biomedical research. Furthermore, access to unrestricted public datasets is increasingly constrained due to rising concerns over privacy, copyright, and competition. Synthetic data has emerged as a promising alternative, and diffusion models -- a cutting-edge generative AI technology -- provide an effective solution for generating high-quality and diverse synthetic data. In this paper, we introduce a novel federated learning framework for training diffusion models on decentralized private datasets. Our framework leverages personalization and the inherent noise in the forward diffusion process to produce high-quality samples while ensuring robust differential privacy guarantees. Our experiments show that our framework outperforms non-collaborative training methods, particularly in settings with high data heterogeneity, and effectively reduces biases and imbalances in synthetic data, resulting in fairer downstream models.</li>
</ul>

<h3>Title: IDMR: Towards Instance-Driven Precise Visual Correspondence in Multimodal Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Bangwei Liu, Yicheng Bao, Shaohui Lin, Xuhong Wang, Xin Tan, Yingchun Wang, Yuan Xie, Chaochao Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00954">https://arxiv.org/abs/2504.00954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00954">https://arxiv.org/pdf/2504.00954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00954]] IDMR: Towards Instance-Driven Precise Visual Correspondence in Multimodal Retrieval(https://arxiv.org/abs/2504.00954)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal retrieval systems are becoming increasingly vital for cutting-edge AI technologies, such as embodied AI and AI-driven digital content industries. However, current multimodal retrieval tasks lack sufficient complexity and demonstrate limited practical application value. It spires us to design Instance-Driven Multimodal Image Retrieval (IDMR), a novel task that requires models to retrieve images containing the same instance as a query image while matching a text-described scenario. Unlike existing retrieval tasks focused on global image similarity or category-level matching, IDMR demands fine-grained instance-level consistency across diverse contexts. To benchmark this capability, we develop IDMR-bench using real-world object tracking and first-person video data. Addressing the scarcity of training data, we propose a cross-domain synthesis method that creates 557K training samples by cropping objects from standard detection datasets. Our Multimodal Large Language Model (MLLM) based retrieval model, trained on 1.2M samples, outperforms state-of-the-art approaches on both traditional benchmarks and our zero-shot IDMR-bench. Experimental results demonstrate previous models' limitations in instance-aware retrieval and highlight the potential of MLLM for advanced retrieval applications. The whole training dataset, codes and models, with wide ranges of sizes, are available at this https URL.</li>
</ul>

<h3>Title: SentenceKV: Efficient LLM Inference via Sentence-Level Semantic KV Caching</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Zhu, Ali Falahati, David H. Yang, Mohammad Mohammadi Amiri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00970">https://arxiv.org/abs/2504.00970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00970">https://arxiv.org/pdf/2504.00970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00970]] SentenceKV: Efficient LLM Inference via Sentence-Level Semantic KV Caching(https://arxiv.org/abs/2504.00970)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models face significant computational and memory challenges when processing long contexts. During inference, efficient management of the key-value (KV) cache, which stores intermediate activations for autoregressive generation, is critical to reducing memory overhead and improving computational efficiency. Traditional token-level efficient KV caching methods overlook semantic information, treating tokens independently without considering their semantic relationships. Meanwhile, existing semantic-preserving KV cache management approaches often suffer from substantial memory usage and high time-to-first-token. To address these limitations, we propose SentenceKV, a novel sentence-level semantic KV caching approach designed to enhance inference efficiency while preserving semantic coherence. During prefilling, SentenceKV groups tokens based on sentence-level semantic similarity, compressing sentence representations into concise semantic vectors stored directly on the GPU, while individual KV pairs are offloaded to CPU. During decoding, SentenceKV generates tokens by selectively retrieving semantically relevant sentence-level KV entries, leveraging the semantic similarity between the prefilling-stage semantic vectors and decoding-stage queries. This ensures efficient and contextually accurate predictions, minimizing the loading of redundant or irrelevant data into GPU memory and significantly reducing memory overhead while maintaining stable inference latency, even for extremely long contexts. Extensive evaluations on benchmarks including PG-19, LongBench, and Needle-In-A-Haystack demonstrate that SentenceKV significantly outperforms state-of-the-art methods in both efficiency and memory usage, without compromising model accuracy.</li>
</ul>

<h3>Title: Chinese Grammatical Error Correction: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Mengyang Qiu, Qingyu Gao, Linxuan Yang, Yang Gu, Tran Minh Nguyen, Zihao Huang, Jungyeul Park</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00977">https://arxiv.org/abs/2504.00977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00977">https://arxiv.org/pdf/2504.00977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00977]] Chinese Grammatical Error Correction: A Survey(https://arxiv.org/abs/2504.00977)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Chinese Grammatical Error Correction (CGEC) is a critical task in Natural Language Processing, addressing the growing demand for automated writing assistance in both second-language (L2) and native (L1) Chinese writing. While L2 learners struggle with mastering complex grammatical structures, L1 users also benefit from CGEC in academic, professional, and formal contexts where writing precision is essential. This survey provides a comprehensive review of CGEC research, covering datasets, annotation schemes, evaluation methodologies, and system advancements. We examine widely used CGEC datasets, highlighting their characteristics, limitations, and the need for improved standardization. We also analyze error annotation frameworks, discussing challenges such as word segmentation ambiguity and the classification of Chinese-specific error types. Furthermore, we review evaluation metrics, focusing on their adaptation from English GEC to Chinese, including character-level scoring and the use of multiple references. In terms of system development, we trace the evolution from rule-based and statistical approaches to neural architectures, including Transformer-based models and the integration of large pre-trained language models. By consolidating existing research and identifying key challenges, this survey provides insights into the current state of CGEC and outlines future directions, including refining annotation standards to address segmentation challenges, and leveraging multilingual approaches to enhance CGEC.</li>
</ul>

<h3>Title: Safety and Security Risk Mitigation in Satellite Missions via Attack-Fault-Defense Trees</h3>
<ul>
<li><strong>Authors: </strong>Reza Soltani, Pablo Diale, Milan Lopuhaä-Zwakenberg, Mariëlle Stoelinga</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00988">https://arxiv.org/abs/2504.00988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00988">https://arxiv.org/pdf/2504.00988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00988]] Safety and Security Risk Mitigation in Satellite Missions via Attack-Fault-Defense Trees(https://arxiv.org/abs/2504.00988)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Cyber-physical systems, such as self-driving cars or digitized electrical grids, often involve complex interactions between security, safety, and defense. Proper risk management strategies must account for these three critical domains and their interaction because the failure to address one domain can exacerbate risks in the others, leading to cascading effects that compromise the overall system resilience. This work presents a case study from Ascentio Technologies, a mission-critical system company in Argentina specializing in aerospace, where the interplay between safety, security, and defenses is critical for ensuring the resilience and reliability of their systems. The main focus will be on the Ground Segment for the satellite project currently developed by the company. Analyzing safety, security, and defense mechanisms together in the Ground Segment of a satellite project is crucial because these domains are deeply interconnected--for instance, a security breach could disable critical safety functions, or a safety failure could create opportunities for attackers to exploit vulnerabilities, amplifying the risks to the entire system. This paper showcases the application of the Attack-Fault-Defense Tree (AFDT) framework, which integrates attack trees, fault trees, and defense mechanisms into a unified model. AFDT provides an intuitive visual language that facilitates interdisciplinary collaboration, enabling experts from various fields to better assess system vulnerabilities and defenses. By applying AFDT to the Ground Segment of the satellite project, we demonstrate how qualitative analyses can be performed to identify weaknesses and enhance the overall system's security and safety. This case highlights the importance of jointly analyzing attacks, faults, and defenses to improve resilience in complex cyber-physical environments.</li>
</ul>

<h3>Title: SuperDec: 3D Scene Decomposition with Superquadric Primitives</h3>
<ul>
<li><strong>Authors: </strong>Elisabetta Fedele, Boyang Sun, Leonidas Guibas, Marc Pollefeys, Francis Engelmann</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00992">https://arxiv.org/abs/2504.00992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00992">https://arxiv.org/pdf/2504.00992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00992]] SuperDec: 3D Scene Decomposition with Superquadric Primitives(https://arxiv.org/abs/2504.00992)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We present SuperDec, an approach for creating compact 3D scene representations via decomposition into superquadric primitives. While most recent works leverage geometric primitives to obtain photorealistic 3D scene representations, we propose to leverage them to obtain a compact yet expressive representation. We propose to solve the problem locally on individual objects and leverage the capabilities of instance segmentation methods to scale our solution to full 3D scenes. In doing that, we design a new architecture which efficiently decompose point clouds of arbitrary objects in a compact set of superquadrics. We train our architecture on ShapeNet and we prove its generalization capabilities on object instances extracted from the ScanNet++ dataset as well as on full Replica scenes. Finally, we show how a compact representation based on superquadrics can be useful for a diverse range of downstream applications, including robotic tasks and controllable visual content generation and editing.</li>
</ul>

<h3>Title: MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Juncheng Wu, Wenlong Deng, Xingxuan Li, Sheng Liu, Taomian Mi, Yifan Peng, Ziyang Xu, Yi Liu, Hyunjin Cho, Chang-In Choi, Yihan Cao, Hui Ren, Xiang Li, Xiaoxiao Li, Yuyin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00993">https://arxiv.org/abs/2504.00993</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00993">https://arxiv.org/pdf/2504.00993</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00993]] MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs(https://arxiv.org/abs/2504.00993)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Medical tasks such as diagnosis and treatment planning require precise and complex reasoning, particularly in life-critical domains. Unlike mathematical reasoning, medical reasoning demands meticulous, verifiable thought processes to ensure reliability and accuracy. However, there is a notable lack of datasets that provide transparent, step-by-step reasoning to validate and enhance the medical reasoning ability of AI models. To bridge this gap, we introduce MedReason, a large-scale high-quality medical reasoning dataset designed to enable faithful and explainable medical problem-solving in large language models (LLMs). We utilize a structured medical knowledge graph (KG) to convert clinical QA pairs into logical chains of reasoning, or ``thinking paths'', which trace connections from question elements to answers via relevant KG entities. Each path is validated for consistency with clinical logic and evidence-based medicine. Our pipeline generates detailed reasoning for various medical questions from 7 medical datasets, resulting in a dataset of 32,682 question-answer pairs, each with detailed, step-by-step explanations. Experiments demonstrate that fine-tuning with our dataset consistently boosts medical problem-solving capabilities, achieving significant gains of up to 7.7% for DeepSeek-Ditill-8B. Our top-performing model, MedReason-8B, outperforms the Huatuo-o1-8B, a state-of-the-art medical reasoning model, by up to 4.2% on the clinical benchmark MedBullets. We also engage medical professionals from diverse specialties to assess our dataset's quality, ensuring MedReason offers accurate and coherent medical reasoning. Our data, models, and code will be publicly available.</li>
</ul>

<h3>Title: TurboFill: Adapting Few-step Text-to-image Model for Fast Image Inpainting</h3>
<ul>
<li><strong>Authors: </strong>Liangbin Xie, Daniil Pakhomov, Zhonghao Wang, Zongze Wu, Ziyan Chen, Yuqian Zhou, Haitian Zheng, Zhifei Zhang, Zhe Lin, Jiantao Zhou, Chao Dong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00996">https://arxiv.org/abs/2504.00996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00996">https://arxiv.org/pdf/2504.00996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00996]] TurboFill: Adapting Few-step Text-to-image Model for Fast Image Inpainting(https://arxiv.org/abs/2504.00996)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper introduces TurboFill, a fast image inpainting model that enhances a few-step text-to-image diffusion model with an inpainting adapter for high-quality and efficient inpainting. While standard diffusion models generate high-quality results, they incur high computational costs. We overcome this by training an inpainting adapter on a few-step distilled text-to-image model, DMD2, using a novel 3-step adversarial training scheme to ensure realistic, structurally consistent, and visually harmonious inpainted regions. To evaluate TurboFill, we propose two benchmarks: DilationBench, which tests performance across mask sizes, and HumanBench, based on human feedback for complex prompts. Experiments show that TurboFill outperforms both multi-step BrushNet and few-step inpainting methods, setting a new benchmark for high-performance inpainting tasks. Our project page: this https URL</li>
</ul>

<h3>Title: MergeVQ: A Unified Framework for Visual Generation and Representation with Disentangled Token Merging and Quantization</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Li, Luyuan Zhang, Zedong Wang, Juanxi Tian, Cheng Tan, Zicheng Liu, Chang Yu, Qingsong Xie, Haonan Lu, Haoqian Wang, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.00999">https://arxiv.org/abs/2504.00999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.00999">https://arxiv.org/pdf/2504.00999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.00999]] MergeVQ: A Unified Framework for Visual Generation and Representation with Disentangled Token Merging and Quantization(https://arxiv.org/abs/2504.00999)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Masked Image Modeling (MIM) with Vector Quantization (VQ) has achieved great success in both self-supervised pre-training and image generation. However, most existing methods struggle to address the trade-off in shared latent space for generation quality vs. representation learning and efficiency. To push the limits of this paradigm, we propose MergeVQ, which incorporates token merging techniques into VQ-based generative models to bridge the gap between image generation and visual representation learning in a unified architecture. During pre-training, MergeVQ decouples top-k semantics from latent space with the token merge module after self-attention blocks in the encoder for subsequent Look-up Free Quantization (LFQ) and global alignment and recovers their fine-grained details through cross-attention in the decoder for reconstruction. As for the second-stage generation, we introduce MergeAR, which performs KV Cache compression for efficient raster-order prediction. Extensive experiments on ImageNet verify that MergeVQ as an AR generative model achieves competitive performance in both visual representation learning and image generation tasks while maintaining favorable token efficiency and inference speed. The code and model will be available at this https URL.</li>
</ul>

<h3>Title: Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models</h3>
<ul>
<li><strong>Authors: </strong>José Pombal, Nuno M. Guerreiro, Ricardo Rei, André F. T. Martins</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.01001">https://arxiv.org/abs/2504.01001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.01001">https://arxiv.org/pdf/2504.01001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.01001]] Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models(https://arxiv.org/abs/2504.01001)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As language models improve and become capable of performing more complex tasks across modalities, evaluating them automatically becomes increasingly challenging. Developing strong and robust task-specific automatic metrics gets harder, and human-annotated test sets -- which are expensive to create -- saturate more quickly. A compelling alternative is to design reliable strategies to automate the creation of test data and evaluation, but previous attempts either rely on pre-existing data, or focus solely on individual tasks. We present Zero-shot Benchmarking (ZSB), a framework for creating high-quality benchmarks for any task by leveraging language models for both synthetic test data creation and evaluation. ZSB is simple and flexible: it requires only the creation of a prompt for data generation and one for evaluation; it is scalable to tasks and languages where collecting real-world data is costly or impractical; it is model-agnostic, allowing the creation of increasingly challenging benchmarks as models improve. To assess the effectiveness of our framework, we create benchmarks for five text-only tasks and a multi-modal one: general capabilities in four languages (English, Chinese, French, and Korean), translation, and general vision-language capabilities in English. We then rank a broad range of open and closed systems on our benchmarks. ZSB rankings consistently correlate strongly with human rankings, outperforming widely-adopted standard benchmarks. Through ablations, we find that strong benchmarks can be created with open models, and that judge model size and dataset variety are crucial drivers of performance. We release all our benchmarks, and code to reproduce our experiments and to produce new benchmarks.</li>
</ul>

<h3>Title: Token embeddings violate the manifold hypothesis</h3>
<ul>
<li><strong>Authors: </strong>Michael Robinson, Sourya Dey, Tony Chiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.01002">https://arxiv.org/abs/2504.01002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.01002">https://arxiv.org/pdf/2504.01002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.01002]] Token embeddings violate the manifold hypothesis(https://arxiv.org/abs/2504.01002)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To fully understand the behavior of a large language model (LLM) requires our understanding of its input space. If this input space differs from our assumption, our understanding of and conclusions about the LLM is likely flawed, regardless of its architecture. Here, we elucidate the structure of the token embeddings, the input domain for LLMs, both empirically and theoretically. We present a generalized and statistically testable model where the neighborhood of each token splits into well-defined signal and noise dimensions. This model is based on a generalization of a manifold called a fiber bundle, so we denote our hypothesis test as the ``fiber bundle null.'' Failing to reject the null is uninformative, but rejecting it at a specific token indicates that token has a statistically significant local structure, and so is of interest to us. By running our test over several open-source LLMs, each with unique token embeddings, we find that the null is frequently rejected, and so the token subspace is provably not a fiber bundle and hence also not a manifold. As a consequence of our findings, when an LLM is presented with two semantically equivalent prompts, and if one prompt contains a token implicated by our test, that prompt will likely exhibit more output variability proportional to the local signal dimension of the token.</li>
</ul>

<h3>Title: Enhancing 3T BOLD fMRI SNR using Unpaired 7T Data with Schrödinger Bridge Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yujian Xiong, Xuanzhao Dong, Sebastian Waz, Wenhui Zhu, Negar Mallak, Zhong-lin Lu, Yalin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.01004">https://arxiv.org/abs/2504.01004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.01004">https://arxiv.org/pdf/2504.01004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.01004]] Enhancing 3T BOLD fMRI SNR using Unpaired 7T Data with Schrödinger Bridge Diffusion(https://arxiv.org/abs/2504.01004)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>High spatial and temporal resolution, coupled with a strong signal-to-noise ratio (SNR), has made BOLD 7 Tesla fMRI an invaluable tool for understanding how the brain processes visual stimuli. However, the limited availability of 7T MRI systems means that most research relies on 3T MRI systems, which offer lower spatial and temporal resolution and SNR. This naturally raises the question: Can we enhance the spatiotemporal resolution and SNR of 3T BOLD fMRI data to approximate 7T quality? In this study, we propose a novel framework that aligns 7T and 3T fMRI data from different subjects and datasets in a shared parametric domain. We then apply an unpaired Brain Disk Schrödinger Bridge diffusion model to enhance the spatiotemporal resolution and SNR of the 3T data. Our approach addresses the challenge of limited 7T data by improving the 3T scan quality. We demonstrate its effectiveness by testing it on two distinct fMRI retinotopy datasets (one 7T and one 3T), as well as synthetic data. The results show that our method significantly improves the SNR and goodness-of-fit of the population receptive field (pRF) model in the enhanced 3T data, making it comparable to 7T quality. The codes will be available at Github.</li>
</ul>

<h3>Title: When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Nishad Singhi, Hritik Bansal, Arian Hosseini, Aditya Grover, Kai-Wei Chang, Marcus Rohrbach, Anna Rohrbach</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.01005">https://arxiv.org/abs/2504.01005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.01005">https://arxiv.org/pdf/2504.01005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.01005]] When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning(https://arxiv.org/abs/2504.01005)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Scaling test-time compute has emerged as a key strategy for enhancing the reasoning capabilities of large language models (LLMs), particularly in tasks like mathematical problem-solving. A traditional approach, Self-Consistency (SC), generates multiple solutions to a problem and selects the most common answer via majority voting. Another common method involves scoring each solution with a reward model (verifier) and choosing the best one. Recent advancements in Generative Reward Models (GenRM) reframe verification as a next-token prediction task, enabling inference-time scaling along a new axis. Specifically, GenRM generates multiple verification chains-of-thought to score each solution. Under a limited inference budget, this introduces a fundamental trade-off: should you spend the budget on scaling solutions via SC or generate fewer solutions and allocate compute to verification via GenRM? To address this, we evaluate GenRM against SC under a fixed inference budget. Interestingly, we find that SC is more compute-efficient than GenRM for most practical inference budgets across diverse models and datasets. For instance, GenRM first matches SC after consuming up to 8x the inference compute and requires significantly more compute to outperform it. Furthermore, we derive inference scaling laws for the GenRM paradigm, revealing that compute-optimal inference favors scaling solution generation more aggressively than scaling the number of verifications. Our work provides practical guidance on optimizing test-time scaling by balancing solution generation and verification. The code is available at this https URL.</li>
</ul>

<h3>Title: GECKO: Gigapixel Vision-Concept Contrastive Pretraining in Histopathology</h3>
<ul>
<li><strong>Authors: </strong>Saarthak Kapse, Pushpak Pati, Srikar Yellapragada, Srijan Das, Rajarsi R. Gupta, Joel Saltz, Dimitris Samaras, Prateek Prasanna</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.01009">https://arxiv.org/abs/2504.01009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.01009">https://arxiv.org/pdf/2504.01009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.01009]] GECKO: Gigapixel Vision-Concept Contrastive Pretraining in Histopathology(https://arxiv.org/abs/2504.01009)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Pretraining a Multiple Instance Learning (MIL) aggregator enables the derivation of Whole Slide Image (WSI)-level embeddings from patch-level representations without supervision. While recent multimodal MIL pretraining approaches leveraging auxiliary modalities have demonstrated performance gains over unimodal WSI pretraining, the acquisition of these additional modalities necessitates extensive clinical profiling. This requirement increases costs and limits scalability in existing WSI datasets lacking such paired modalities. To address this, we propose Gigapixel Vision-Concept Knowledge Contrastive pretraining (GECKO), which aligns WSIs with a Concept Prior derived from the available WSIs. First, we derive an inherently interpretable concept prior by computing the similarity between each WSI patch and textual descriptions of predefined pathology concepts. GECKO then employs a dual-branch MIL network: one branch aggregates patch embeddings into a WSI-level deep embedding, while the other aggregates the concept prior into a corresponding WSI-level concept embedding. Both aggregated embeddings are aligned using a contrastive objective, thereby pretraining the entire dual-branch MIL model. Moreover, when auxiliary modalities such as transcriptomics data are available, GECKO seamlessly integrates them. Across five diverse tasks, GECKO consistently outperforms prior unimodal and multimodal pretraining approaches while also delivering clinically meaningful interpretability that bridges the gap between computational models and pathology expertise. Code is made available at this https URL</li>
</ul>

<h3>Title: AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction</h3>
<ul>
<li><strong>Authors: </strong>Junhao Cheng, Yuying Ge, Yixiao Ge, Jing Liao, Ying Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.01014">https://arxiv.org/abs/2504.01014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.01014">https://arxiv.org/pdf/2504.01014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.01014]] AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction(https://arxiv.org/abs/2504.01014)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in image and video synthesis have opened up new promise in generative games. One particularly intriguing application is transforming characters from anime films into interactive, playable entities. This allows players to immerse themselves in the dynamic anime world as their favorite characters for life simulation through language instructions. Such games are defined as infinite game since they eliminate predetermined boundaries and fixed gameplay rules, where players can interact with the game world through open-ended language and experience ever-evolving storylines and environments. Recently, a pioneering approach for infinite anime life simulation employs large language models (LLMs) to translate multi-turn text dialogues into language instructions for image generation. However, it neglects historical visual context, leading to inconsistent gameplay. Furthermore, it only generates static images, failing to incorporate the dynamics necessary for an engaging gaming experience. In this work, we propose AnimeGamer, which is built upon Multimodal Large Language Models (MLLMs) to generate each game state, including dynamic animation shots that depict character movements and updates to character states, as illustrated in Figure 1. We introduce novel action-aware multimodal representations to represent animation shots, which can be decoded into high-quality video clips using a video diffusion model. By taking historical animation shot representations as context and predicting subsequent representations, AnimeGamer can generate games with contextual consistency and satisfactory dynamics. Extensive evaluations using both automated metrics and human evaluations demonstrate that AnimeGamer outperforms existing methods in various aspects of the gaming experience. Codes and checkpoints are available at this https URL.</li>
</ul>

<h3>Title: Self-Routing RAG: Binding Selective Retrieval with Knowledge Verbalization</h3>
<ul>
<li><strong>Authors: </strong>Di Wu, Jia-Chen Gu, Kai-Wei Chang, Nanyun Peng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.01018">https://arxiv.org/abs/2504.01018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.01018">https://arxiv.org/pdf/2504.01018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.01018]] Self-Routing RAG: Binding Selective Retrieval with Knowledge Verbalization(https://arxiv.org/abs/2504.01018)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Selective retrieval improves retrieval-augmented generation (RAG) by reducing distractions from low-quality retrievals and improving efficiency. However, existing approaches under-utilize the inherent knowledge of large language models (LLMs), leading to suboptimal retrieval decisions and degraded generation performance. To bridge this gap, we propose Self-Routing RAG (SR-RAG), a novel framework that binds selective retrieval with knowledge verbalization. SR-RAG enables an LLM to dynamically decide between external retrieval and verbalizing its own parametric knowledge. To this end, we design a multi-task objective that jointly optimizes an LLM on knowledge source selection, knowledge verbalization, and response generation. We further introduce dynamic knowledge source inference via nearest neighbor search to improve the accuracy of knowledge source decision under domain shifts. Fine-tuning three LLMs with SR-RAG significantly improves both their response accuracy and inference latency. Compared to the strongest selective retrieval baseline, SR-RAG reduces retrievals by 29% while improving the performance by 5.1%.</li>
</ul>

<h3>Title: MixerMDM: Learnable Composition of Human Motion Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Pablo Ruiz-Ponce, German Barquero, Cristina Palmero, Sergio Escalera, José García-Rodríguez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.01019">https://arxiv.org/abs/2504.01019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.01019">https://arxiv.org/pdf/2504.01019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.01019]] MixerMDM: Learnable Composition of Human Motion Diffusion Models(https://arxiv.org/abs/2504.01019)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generating human motion guided by conditions such as textual descriptions is challenging due to the need for datasets with pairs of high-quality motion and their corresponding conditions. The difficulty increases when aiming for finer control in the generation. To that end, prior works have proposed to combine several motion diffusion models pre-trained on datasets with different types of conditions, thus allowing control with multiple conditions. However, the proposed merging strategies overlook that the optimal way to combine the generation processes might depend on the particularities of each pre-trained generative model and also the specific textual descriptions. In this context, we introduce MixerMDM, the first learnable model composition technique for combining pre-trained text-conditioned human motion diffusion models. Unlike previous approaches, MixerMDM provides a dynamic mixing strategy that is trained in an adversarial fashion to learn to combine the denoising process of each model depending on the set of conditions driving the generation. By using MixerMDM to combine single- and multi-person motion diffusion models, we achieve fine-grained control on the dynamics of every person individually, and also on the overall interaction. Furthermore, we propose a new evaluation technique that, for the first time in this task, measures the interaction and individual quality by computing the alignment between the mixed generated motions and their conditions as well as the capabilities of MixerMDM to adapt the mixing throughout the denoising process depending on the motions to mix.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
