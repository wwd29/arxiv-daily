<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-09-01</h1>
<h3>Title: Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering</h3>
<ul>
<li><strong>Authors: </strong>Thanasis Schoinas, Benjamin Guinard, Diba Esbati, Richard Chalk</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21081">https://arxiv.org/abs/2508.21081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21081">https://arxiv.org/pdf/2508.21081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21081]] Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering(https://arxiv.org/abs/2508.21081)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Short text clustering is a known use case in the text analytics community. When the structure and content falls in the natural language domain e.g. Twitter posts or instant messages, then natural language techniques can be used, provided texts are of sufficient length to allow for use of (pre)trained models to extract meaningful information, such as part-of-speech or topic annotations. However, natural language models are not suitable for clustering transaction counterparties, as they are found in bank payment messaging systems, such as SWIFT. The manually typed tags are typically physical or legal entity details, which lack sentence structure, while containing all the variations and noise that manual entry introduces. This leaves a gap in an investigator or counter-fraud professional's toolset when looking to augment their knowledge of payment flow originator and beneficiary entities and trace funds and assets. A gap that vendors traditionally try to close with fuzzy matching tools. With these considerations in mind, we are proposing a hybrid string similarity, topic modelling, hierarchical clustering and rule-based pipeline to facilitate clustering of transaction counterparties, also catering for unknown number of expected clusters. We are also devising metrics to supplement the evaluation of the approach, based on the well-known measures of precision and recall. Testing on a real-life labelled dataset demonstrates significantly improved performance over a baseline rule-based ('keyword') approach. The approach retains most of the interpretability found in rule-based systems, as the former adds an additional level of cluster refinement to the latter. The resulting workflow reduces the need for manual review. When only a subset of the population needs to be investigated, such as in sanctions investigations, the approach allows for better control of the risks of missing entity variations.</li>
</ul>

<h3>Title: CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples</h3>
<ul>
<li><strong>Authors: </strong>Kyohoon Jin, Juhwan Choi, Jungmin Yun, Junho Lee, Soojin Jang, Youngbin Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21083">https://arxiv.org/abs/2508.21083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21083">https://arxiv.org/pdf/2508.21083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21083]] CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples(https://arxiv.org/abs/2508.21083)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning models often learn and exploit spurious correlations in training data, using these non-target features to inform their predictions. Such reliance leads to performance degradation and poor generalization on unseen data. To address these limitations, we introduce a more general form of counterfactual data augmentation, termed counterbias data augmentation, which simultaneously tackles multiple biases (e.g., gender bias, simplicity bias) and enhances out-of-distribution robustness. We present CoBA: CounterBias Augmentation, a unified framework that operates at the semantic triple level: first decomposing text into subject-predicate-object triples, then selectively modifying these triples to disrupt spurious correlations. By reconstructing the text from these adjusted triples, CoBA generates counterbias data that mitigates spurious patterns. Through extensive experiments, we demonstrate that CoBA not only improves downstream task performance, but also effectively reduces biases and strengthens out-of-distribution resilience, offering a versatile and robust solution to the challenges posed by spurious correlations.</li>
</ul>

<h3>Title: Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images</h3>
<ul>
<li><strong>Authors: </strong>Alireza Golkarieh, Kiana Kiashemshaki, Sajjad Rezvani Boroujeni</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21088">https://arxiv.org/abs/2508.21088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21088">https://arxiv.org/pdf/2508.21088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21088]] Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images(https://arxiv.org/abs/2508.21088)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This study investigates deep learning methods for automated classification of dental conditions in panoramic X-ray images. A dataset of 1,512 radiographs with 11,137 expert-verified annotations across four conditions fillings, cavities, implants, and impacted teeth was used. After preprocessing and class balancing, three approaches were evaluated: a custom convolutional neural network (CNN), hybrid models combining CNN feature extraction with traditional classifiers, and fine-tuned pre-trained architectures. Experiments employed 5 fold cross validation with accuracy, precision, recall, and F1 score as evaluation metrics. The hybrid CNN Random Forest model achieved the highest performance with 85.4% accuracy, surpassing the custom CNN baseline of 74.3%. Among pre-trained models, VGG16 performed best at 82.3% accuracy, followed by Xception and ResNet50. Results show that hybrid models improve discrimination of morphologically similar conditions and provide efficient, reliable performance. These findings suggest that combining CNN-based feature extraction with ensemble classifiers offers a practical path toward automated dental diagnostic support, while also highlighting the need for larger datasets and further clinical validation.</li>
</ul>

<h3>Title: ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Xurui Peng, Hong Liu, Chenqian Yan, Rui Ma, Fangmin Chen, Xing Wang, Zhihua Wu, Songwei Liu, Mingbao Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21091">https://arxiv.org/abs/2508.21091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21091">https://arxiv.org/pdf/2508.21091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21091]] ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion(https://arxiv.org/abs/2508.21091)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models suffer from substantial computational overhead due to their inherently iterative inference process. While feature caching offers a promising acceleration strategy by reusing intermediate outputs across timesteps, naive reuse often incurs noticeable quality degradation. In this work, we formally analyze the cumulative error introduced by caching and decompose it into two principal components: feature shift error, caused by inaccuracies in cached outputs, and step amplification error, which arises from error propagation under fixed timestep schedules. To address these issues, we propose ERTACache, a principled caching framework that jointly rectifies both error types. Our method employs an offline residual profiling stage to identify reusable steps, dynamically adjusts integration intervals via a trajectory-aware correction coefficient, and analytically approximates cache-induced errors through a closed-form residual linearization model. Together, these components enable accurate and efficient sampling under aggressive cache reuse. Extensive experiments across standard image and video generation benchmarks show that ERTACache achieves up to 2x inference speedup while consistently preserving or even improving visual quality. Notably, on the state-of-the-art Wan2.1 video diffusion model, ERTACache delivers 2x acceleration with minimal VBench degradation, effectively maintaining baseline fidelity while significantly improving efficiency. The code is available at this https URL.</li>
</ul>

<h3>Title: Video-LLMs with Temporal Visual Screening</h3>
<ul>
<li><strong>Authors: </strong>Zheyu Fan, Jiateng Liu, Yuji Zhang, Zihan Wang, Yi R. (May)Fung, Manling Li, Heng Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21094">https://arxiv.org/abs/2508.21094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21094">https://arxiv.org/pdf/2508.21094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21094]] Video-LLMs with Temporal Visual Screening(https://arxiv.org/abs/2508.21094)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Humans naturally perform temporal screening by dragging the progress bar and focusing on salient temporal segments, but current Video Large Language Models (Video-LLMs) struggle to capture fine-grained temporal semantics due to sparse frame sampling and insufficient inter-frame reasoning supervision during their training. To address this, Inspired by well-established cognitive science principles, we propose Temporal Visual Screening (TVS), a new task that universally pre-processes video question answering and instruction tuning data by: (1) retaining focus-critical video segments, (2) synchronously reconstructing queries to their most direct form while preserving answer consistency, and (3) keeping the invariance and consistency for any possible answer. TVS is formulated as a modular front-end adapter task that can be seamlessly integrated into both Video Instruction Tuning (training) and Video Question Answering (inference) pipelines. TVS optimizes distribution of reasoning burden and cognitive load; during training, it aligns queries with focus-critical visual information; at inference, it enables query-aware segment focus and streamlined query representations. In particular, we curate the first benchmark for TVS and propose ReSimplifyIt, a baseline outperforming prior approaches on seemingly similar tasks by 0.47 in F-1 score on video trimming while achieving competitive query rewriting performance. Experiments demonstrate that incorporating TVS yields relative gains of 7.33% (training) and 34.6% (inference), demonstrating the effectiveness of temporal information screening for improving video-language understanding.</li>
</ul>

<h3>Title: ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments</h3>
<ul>
<li><strong>Authors: </strong>Zhe Han, Charlie Budd, Gongyu Zhang, Huanyu Tian, Christos Bergeles, Tom Vercauteren</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21096">https://arxiv.org/abs/2508.21096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21096">https://arxiv.org/pdf/2508.21096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21096]] ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments(https://arxiv.org/abs/2508.21096)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Localisation of surgical tools constitutes a foundational building block for computer-assisted interventional technologies. Works in this field typically focus on training deep learning models to perform segmentation tasks. Performance of learning-based approaches is limited by the availability of diverse annotated data. We argue that skeletal pose annotations are a more efficient annotation approach for surgical tools, striking a balance between richness of semantic information and ease of annotation, thus allowing for accelerated growth of available annotated data. To encourage adoption of this annotation style, we present, ROBUST-MIPS, a combined tool pose and tool instance segmentation dataset derived from the existing ROBUST-MIS dataset. Our enriched dataset facilitates the joint study of these two annotation styles and allow head-to-head comparison on various downstream tasks. To demonstrate the adequacy of pose annotations for surgical tool localisation, we set up a simple benchmark using popular pose estimation methods and observe high-quality results. To ease adoption, together with the dataset, we release our benchmark models and custom tool pose annotation software.</li>
</ul>

<h3>Title: TrInk: Ink Generation with Transformer Network</h3>
<ul>
<li><strong>Authors: </strong>Zezhong Jin, Shubhang Desai, Xu Chen, Biyi Fang, Zhuoyi Huang, Zhe Li, Chong-Xin Gan, Xiao Tu, Man-Wai Mak, Yan Lu, Shujie Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21098">https://arxiv.org/abs/2508.21098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21098">https://arxiv.org/pdf/2508.21098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21098]] TrInk: Ink Generation with Transformer Network(https://arxiv.org/abs/2508.21098)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we propose TrInk, a Transformer-based model for ink generation, which effectively captures global dependencies. To better facilitate the alignment between the input text and generated stroke points, we introduce scaled positional embeddings and a Gaussian memory mask in the cross-attention module. Additionally, we design both subjective and objective evaluation pipelines to comprehensively assess the legibility and style consistency of the generated handwriting. Experiments demonstrate that our Transformer-based model achieves a 35.56\% reduction in character error rate (CER) and an 29.66% reduction in word error rate (WER) on the IAM-OnDB dataset compared to previous methods. We provide an demo page with handwriting samples from TrInk and baseline models at: this https URL</li>
</ul>

<h3>Title: Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models</h3>
<ul>
<li><strong>Authors: </strong>Xiangtao Meng, Yingkai Dong, Ning Yu, Li Wang, Zheng Li, Shanqing Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21099">https://arxiv.org/abs/2508.21099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21099">https://arxiv.org/pdf/2508.21099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21099]] Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models(https://arxiv.org/abs/2508.21099)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, generative</a></li>
<li><strong>Abstract: </strong>Despite the advancements in Text-to-Image (T2I) generation models, their potential for misuse or even abuse raises serious safety concerns. Model developers have made tremendous efforts to introduce safety mechanisms that can address these concerns in T2I models. However, the existing safety mechanisms, whether external or internal, either remain susceptible to evasion under distribution shifts or require extensive model-specific adjustments. To address these limitations, we introduce Safe-Control, an innovative plug-and-play safety patch designed to mitigate unsafe content generation in T2I models. Using data-driven strategies and safety-aware conditions, Safe-Control injects safety control signals into the locked T2I model, acting as an update in a patch-like manner. Model developers can also construct various safety patches to meet the evolving safety requirements, which can be flexibly merged into a single, unified patch. Its plug-and-play design further ensures adaptability, making it compatible with other T2I models of similar denoising architecture. We conduct extensive evaluations on six diverse and public T2I models. Empirical results highlight that Safe-Control is effective in reducing unsafe content generation across six diverse T2I models with similar generative architectures, yet it successfully maintains the quality and text alignment of benign images. Compared to seven state-of-the-art safety mechanisms, including both external and internal defenses, Safe-Control significantly outperforms all baselines in reducing unsafe content generation. For example, it reduces the probability of unsafe content generation to 7%, compared to approximately 20% for most baseline methods, under both unsafe prompts and the latest adversarial attacks.</li>
</ul>

<h3>Title: Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI</h3>
<ul>
<li><strong>Authors: </strong>Dilruk Perera, Gousia Habib, Qianyi Xu, Daniel J. Tan, Kai He, Erik Cambria, Mengling Feng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21101">https://arxiv.org/abs/2508.21101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21101">https://arxiv.org/pdf/2508.21101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21101]] Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI(https://arxiv.org/abs/2508.21101)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) marks a fundamental shift in how artificial intelligence is applied in healthcare. Instead of merely predicting outcomes, RL actively decides interventions with long term goals. Unlike traditional models that operate on fixed associations, RL systems learn through trial, feedback, and long-term reward optimization, introducing transformative possibilities and new risks. From an information fusion lens, healthcare RL typically integrates multi-source signals such as vitals, labs clinical notes, imaging and device telemetry using temporal and decision-level mechanisms. These systems can operate within centralized, federated, or edge architectures to meet real-time clinical constraints, and naturally span data, features and decision fusion levels. This survey explore RL's rise in healthcare as more than a set of tools, rather a shift toward agentive intelligence in clinical environments. We first structure the landscape of RL techniques including model-based and model-free methods, offline and batch-constrained approaches, and emerging strategies for reward specification and uncertainty calibration through the lens of healthcare constraints. We then comprehensively analyze RL applications spanning critical care, chronic disease, mental health, diagnostics, and robotic assistance, identifying their trends, gaps, and translational bottlenecks. In contrast to prior reviews, we critically analyze RL's ethical, deployment, and reward design challenges, and synthesize lessons for safe, human-aligned policy learning. This paper serves as both a a technical roadmap and a critical reflection of RL's emerging transformative role in healthcare AI not as prediction machinery, but as agentive clinical intelligence.</li>
</ul>

<h3>Title: GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions</h3>
<ul>
<li><strong>Authors: </strong>Kei Katsumata, Yui Iioka, Naoki Hosomi, Teruhisa Misu, Kentaro Yamada, Komei Sugiura</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21102">https://arxiv.org/abs/2508.21102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21102">https://arxiv.org/pdf/2508.21102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21102]] GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions(https://arxiv.org/abs/2508.21102)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>We focus on the task of identifying the location of target regions from a natural language instruction and a front camera image captured by a mobility. This task is challenging because it requires both existence prediction and segmentation, particularly for stuff-type target regions with ambiguous boundaries. Existing methods often underperform in handling stuff-type target regions, in addition to absent or multiple targets. To overcome these limitations, we propose GENNAV, which predicts target existence and generates segmentation masks for multiple stuff-type target regions. To evaluate GENNAV, we constructed a novel benchmark called GRiN-Drive, which includes three distinct types of samples: no-target, single-target, and multi-target. GENNAV achieved superior performance over baseline methods on standard evaluation metrics. Furthermore, we conducted real-world experiments with four automobiles operated in five geographically distinct urban areas to validate its zero-shot transfer performance. In these experiments, GENNAV outperformed baseline methods and demonstrated its robustness across diverse real-world environments. The project page is available at this https URL.</li>
</ul>

<h3>Title: Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Abdul Rehman, Ilona Heldal, Jerry Chun-Wei Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21103">https://arxiv.org/abs/2508.21103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21103">https://arxiv.org/pdf/2508.21103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21103]] Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning(https://arxiv.org/abs/2508.21103)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in EEG-based emotion recognition have shown promising outcomes using both deep learning and classical machine learning approaches; however, most existing studies focus narrowly on binary valence prediction or subject-specific classification, which limits generalizability and deployment in real-world affective computing systems. To address this gap, this paper presents a unified, multigranularity EEG emotion classification framework built on the GAMEEMO dataset, which consists of 14-channel EEG recordings and continuous self-reported emotion ratings (boring, horrible, calm, and funny) from 28 subjects across four emotion-inducing gameplay scenarios. Our pipeline employs a structured preprocessing strategy that comprises temporal window segmentation, hybrid statistical and frequency-domain feature extraction, and z-score normalization to convert raw EEG signals into robust, discriminative input vectors. Emotion labels are derived and encoded across three complementary axes: (i) binary valence classification based on the averaged polarity of positive and negative emotion ratings, and (ii) Multi-class emotion classification, where the presence of the most affective state is predicted. (iii) Fine-grained multi-label representation via binning each emotion into 10 ordinal classes. We evaluate a broad spectrum of models, including Random Forest, XGBoost, and SVM, alongside deep neural architectures such as LSTM, LSTM-GRU, and CNN-LSTM. Among these, the LSTM-GRU model consistently outperforms the others, achieving an F1-score of 0.932 in the binary valence task and 94.5% and 90.6% in both multi-class and Multi-Label emotion classification.</li>
</ul>

<h3>Title: PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Wenfeng Feng, Penghong Zhao, Guochao Jiang, Chuzhan Hao, Yuewei Zhang, Hao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21104">https://arxiv.org/abs/2508.21104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21104">https://arxiv.org/pdf/2508.21104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21104]] PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning(https://arxiv.org/abs/2508.21104)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Critic-free reinforcement learning methods, particularly group policies, have attracted considerable attention for their efficiency in complex tasks. However, these methods rely heavily on multiple sampling and comparisons within the policy to estimate advantage, which may cause the policy to fall into local optimum and increase computational cost. To address these issues, we propose PVPO, an efficient reinforcement learning method enhanced by an advantage reference anchor and data pre-sampling. Specifically, we use the reference model to rollout in advance and employ the calculated reward score as a reference anchor. Our approach effectively corrects the cumulative bias introduced by intra-group comparisons and significantly reduces reliance on the number of rollouts. Meanwhile, the reference model can assess sample difficulty during data pre-sampling, enabling effective selection of high-gain data to improve training efficiency. Experiments conducted on nine datasets across two domains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our approach not only demonstrates robust generalization across multiple tasks, but also exhibits scalable performance across models of varying scales.</li>
</ul>

<h3>Title: An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity</h3>
<ul>
<li><strong>Authors: </strong>Georgios Vamvouras, Konstantinos Braimakis, Christos Tzivanidis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21109">https://arxiv.org/abs/2508.21109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21109">https://arxiv.org/pdf/2508.21109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21109]] An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity(https://arxiv.org/abs/2508.21109)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>This paper presents a Deep Learning (DL) framework for 48-hour forecasting of temperature, solar irradiance, and relative humidity to support Model Predictive Control (MPC) in smart HVAC systems. The approach employs a stacked Bidirectional Long Short-Term Memory (BiLSTM) network with attention, capturing temporal and cross-feature dependencies by jointly predicting all three variables. Historical meteorological data (2019-2022) with encoded cyclical time features were used for training, while 2023 data evaluated generalization. The model achieved Mean Absolute Errors of 1.3 degrees Celsius (temperature), 31 W/m2 (irradiance), and 6.7 percentage points (humidity), outperforming state-of-the-art numerical weather prediction and machine learning benchmarks. Integrated Gradients quantified feature contributions, and attention weights revealed temporal patterns, enhancing interpretability. By combining multivariate forecasting, attention-based DL, and explainability, this work advances data-driven weather prediction. The demonstrated accuracy and transparency highlight the framework's potential for energy-efficient building control through reliable short-term meteorological forecasting.</li>
</ul>

<h3>Title: Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI</h3>
<ul>
<li><strong>Authors: </strong>Evan J. Chou (1 and 2), Lisa S. Locke (3), Harvey M. Soldan (3) ((1) University of California San Diego, (2) Pasadena City College, (3) Jet Propulsion Laboratory California Institute of Technology)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21111">https://arxiv.org/abs/2508.21111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21111">https://arxiv.org/pdf/2508.21111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21111]] Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI(https://arxiv.org/abs/2508.21111)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>The Deep Space Network (DSN) is NASA's largest network of antenna facilities that generate a large volume of multivariate time-series data. These facilities contain DSN antennas and transmitters that undergo degradation over long periods of time, which may cause costly disruptions to the data flow and threaten the earth-connection of dozens of spacecraft that rely on the Deep Space Network for their lifeline. The purpose of this study was to experiment with different methods that would be able to assist JPL engineers with directly pinpointing anomalies and equipment degradation through collected data, and continue conducting maintenance and operations of the DSN for future space missions around our universe. As such, we have researched various machine learning techniques that can fully reconstruct data through predictive analysis, and determine anomalous data entries within real-time datasets through statistical computations and thresholds. On top of the fully trained and tested machine learning models, we have also integrated the use of a reinforcement learning subsystem that classifies identified anomalies based on severity level and a Large Language Model that labels an explanation for each anomalous data entry, all of which can be improved and fine-tuned over time through human feedback/input. Specifically, for the DSN transmitters, we have also implemented a full data pipeline system that connects the data extraction, parsing, and processing workflow all together as there was no coherent program or script for performing these tasks before. Using this data pipeline system, we were able to then also connect the models trained from DSN antenna data, completing the data workflow for DSN anomaly detection. This was all wrapped around and further connected by an agentic AI system, where complex reasoning was utilized to determine the classifications and predictions of anomalous data.</li>
</ul>

<h3>Title: R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning</h3>
<ul>
<li><strong>Authors: </strong>Jie Jiang, Qi Yang, Bolin Ni, Shiming Xiang, Han Hu, Houwen Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21113">https://arxiv.org/abs/2508.21113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21113">https://arxiv.org/pdf/2508.21113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21113]] R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning(https://arxiv.org/abs/2508.21113)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) equipped with step-by-step thinking capabilities have demonstrated remarkable performance on complex reasoning problems. However, this thinking process is redundant for simple problems solvable without complex reasoning. To address this inefficiency, we propose R-4B, an auto-thinking MLLM, which can adaptively decide when to think based on problem complexity. The central idea of R-4B is to empower the model with both thinking and non-thinking capabilities using bi-mode annealing, and apply Bi-mode Policy Optimization~(BPO) to improve the model's accuracy in determining whether to activate the thinking process. Specifically, we first train the model on a carefully curated dataset spanning various topics, which contains samples from both thinking and non-thinking modes. Then it undergoes a second phase of training under an improved GRPO framework, where the policy model is forced to generate responses from both modes for each input query. Experimental results show that R-4B achieves state-of-the-art performance across 25 challenging benchmarks. It outperforms Qwen2.5-VL-7B in most tasks and achieves performance comparable to larger models such as Kimi-VL-A3B-Thinking-2506 (16B) on reasoning-intensive benchmarks with lower computational cost.</li>
</ul>

<h3>Title: HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Harris Song, Tuan-Anh Vu, Sanjith Menon, Sriram Narasimhan, M. Khalid Jawed</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21135">https://arxiv.org/abs/2508.21135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21135">https://arxiv.org/pdf/2508.21135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21135]] HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection(https://arxiv.org/abs/2508.21135)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Detecting hidden or partially concealed objects remains a fundamental challenge in multimodal environments, where factors like occlusion, camouflage, and lighting variations significantly hinder performance. Traditional RGB-based detection methods often fail under such adverse conditions, motivating the need for more robust, modality-agnostic approaches. In this work, we present HiddenObject, a fusion framework that integrates RGB, thermal, and depth data using a Mamba-based fusion mechanism. Our method captures complementary signals across modalities, enabling enhanced detection of obscured or camouflaged targets. Specifically, the proposed approach identifies modality-specific features and fuses them in a unified representation that generalizes well across challenging scenarios. We validate HiddenObject across multiple benchmark datasets, demonstrating state-of-the-art or competitive performance compared to existing methods. These results highlight the efficacy of our fusion design and expose key limitations in current unimodal and naïve fusion strategies. More broadly, our findings suggest that Mamba-based fusion architectures can significantly advance the field of multimodal object detection, especially under visually degraded or complex conditions.</li>
</ul>

<h3>Title: How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations</h3>
<ul>
<li><strong>Authors: </strong>Yoshiki Takenami, Yin Jou Huang, Yugo Murawaki, Chenhui Chu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21137">https://arxiv.org/abs/2508.21137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21137">https://arxiv.org/pdf/2508.21137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21137]] How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations(https://arxiv.org/abs/2508.21137)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Cognitive biases, well-studied in humans, can also be observed in LLMs, affecting their reliability in real-world applications. This paper investigates the anchoring effect in LLM-driven price negotiations. To this end, we instructed seller LLM agents to apply the anchoring effect and evaluated negotiations using not only an objective metric but also a subjective metric. Experimental results show that LLMs are influenced by the anchoring effect like humans. Additionally, we investigated the relationship between the anchoring effect and factors such as reasoning and personality. It was shown that reasoning models are less prone to the anchoring effect, suggesting that the long chain of thought mitigates the effect. However, we found no significant correlation between personality traits and susceptibility to the anchoring effect. These findings contribute to a deeper understanding of cognitive biases in LLMs and to the realization of safe and responsible application of LLMs in society.</li>
</ul>

<h3>Title: Adaptive LLM Routing under Budget Constraints</h3>
<ul>
<li><strong>Authors: </strong>Pranoy Panda, Raghav Magazine, Chaitanya Devaguptapu, Sho Takemori, Vishal Sharma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21141">https://arxiv.org/abs/2508.21141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21141">https://arxiv.org/pdf/2508.21141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21141]] Adaptive LLM Routing under Budget Constraints(https://arxiv.org/abs/2508.21141)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have revolutionized natural language processing, but their varying capabilities and costs pose challenges in practical applications. LLM routing addresses this by dynamically selecting the most suitable LLM for each query/task. Previous approaches treat this as a supervised learning problem, assuming complete knowledge of optimal query-LLM pairings. However, real-world scenarios lack such comprehensive mappings and face evolving user queries. We thus propose to study LLM routing as a contextual bandit problem, enabling adaptive decision-making using bandit feedback without requiring exhaustive inference across all LLMs for all queries (in contrast to supervised routing). To address this problem, we develop a shared embedding space for queries and LLMs, where query and LLM embeddings are aligned to reflect their affinity. This space is initially learned from offline human preference data and refined through online bandit feedback. We instantiate this idea through Preference-prior Informed Linucb fOr adaptive rouTing (PILOT), a novel extension of LinUCB. To handle diverse user budgets for model routing, we introduce an online cost policy modeled as a multi-choice knapsack problem, ensuring resource-efficient routing.</li>
</ul>

<h3>Title: Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?</h3>
<ul>
<li><strong>Authors: </strong>Samrajnee Ghosh, Naman Agarwal, Hemanshu Garg, Chinmay Mittal, Mausam, Parag Singla</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21143">https://arxiv.org/abs/2508.21143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21143">https://arxiv.org/pdf/2508.21143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21143]] Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?(https://arxiv.org/abs/2508.21143)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The reasoning abilities of Multimodal Large Language Models (MLLMs) have garnered a lot of attention in recent times, with advances made in frontiers like coding, mathematics, and science. However, very limited experiments have been done to assess their performance in simple perception tasks performed over uncontaminated, generated images containing basic shapes and structures. To address this issue, the paper introduces a dataset, Percept-V, containing a total of 7200 program-generated images equally divided into 30 categories, each testing a combination of visual perception skills. Unlike previously proposed datasets, Percept-V comprises very basic tasks of varying complexity that test the perception abilities of MLLMs. This dataset is then tested on state-of-the-art MLLMs like GPT-4o, Gemini, and Claude as well as Large Reasoning Models (LRMs) like OpenAI o4-mini and DeepSeek R1 to gauge their performance. Contrary to the evidence that MLLMs excel in many complex tasks, our experiments show a significant drop in the models' performance with increasing problem complexity across all categories. An analysis of the performances also reveals that the tested MLLMs exhibit a similar trend in accuracy across categories, testing a particular cognitive skill and find some skills to be more difficult than others.</li>
</ul>

<h3>Title: Privacy Auditing Synthetic Data Release through Local Likelihood Attacks</h3>
<ul>
<li><strong>Authors: </strong>Joshua Ward, Chi-Hua Wang, Guang Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21146">https://arxiv.org/abs/2508.21146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21146">https://arxiv.org/pdf/2508.21146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21146]] Privacy Auditing Synthetic Data Release through Local Likelihood Attacks(https://arxiv.org/abs/2508.21146)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer, generative</a></li>
<li><strong>Abstract: </strong>Auditing the privacy leakage of synthetic data is an important but unresolved problem. Most existing privacy auditing frameworks for synthetic data rely on heuristics and unreasonable assumptions to attack the failure modes of generative models, exhibiting limited capability to describe and detect the privacy exposure of training data through synthetic data release. In this paper, we study designing Membership Inference Attacks (MIAs) that specifically exploit the observation that tabular generative models tend to significantly overfit to certain regions of the training distribution. Here, we propose Generative Likelihood Ratio Attack (Gen-LRA), a novel, computationally efficient No-Box MIA that, with no assumption of model knowledge or access, formulates its attack by evaluating the influence a test observation has in a surrogate model's estimation of a local likelihood ratio over the synthetic data. Assessed over a comprehensive benchmark spanning diverse datasets, model architectures, and attack parameters, we find that Gen-LRA consistently dominates other MIAs for generative models across multiple performance metrics. These results underscore Gen-LRA's effectiveness as a privacy auditing tool for the release of synthetic data, highlighting the significant privacy risks posed by generative model overfitting in real-world applications.</li>
</ul>

<h3>Title: A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers</h3>
<ul>
<li><strong>Authors: </strong>Ming Hu, Chenglong Ma, Wei Li, Wanghan Xu, Jiamin Wu, Jucheng Hu, Tianbin Li, Guohang Zhuang, Jiaqi Liu, Yingzhou Lu, Ying Chen, Chaoyang Zhang, Cheng Tan, Jie Ying, Guocheng Wu, Shujian Gao, Pengcheng Chen, Jiashi Lin, Haitao Wu, Lulu Chen, Fengxiang Wang, Yuanyuan Zhang, Xiangyu Zhao, Feilong Tang, Encheng Su, Junzhi Ning, Xinyao Liu, Ye Du, Changkai Ji, Cheng Tang, Huihui Xu, Ziyang Chen, Ziyan Huang, Jiyao Liu, Pengfei Jiang, Yizhou Wang, Chen Tang, Jianyu Wu, Yuchen Ren, Siyuan Yan, Zhonghua Wang, Zhongxing Xu, Shiyan Su, Shangquan Sun, Runkai Zhao, Zhisheng Zhang, Yu Liu, Fudi Wang, Yuanfeng Ji, Yanzhou Su, Hongming Shan, Chunmei Feng, Jiahao Xu, Jiangtao Yan, Wenhao Tang, Diping Song, Lihao Liu, Yanyan Huang, Lequan Yu, Bin Fu, Shujun Wang, Xiaomeng Li, Xiaowei Hu, Yun Gu, Ben Fei, Zhongying Deng, Benyou Wang, Yuewen Cao, Minjie Shen, Haodong Duan, Jie Xu, Yirong Chen, Fang Yan, Hongxia Hao, Jielan Li, Jiajun Du, Yanbo Wang, Imran Razzak, Chi Zhang, Lijun Wu, Conghui He, Zhaohui Lu, Jinhai Huang, Yihao Liu, Fenghua Ling, Yuqiang Li, Aoran Wang, Qihao Zheng, Nanqing Dong, Tianfan Fu, Dongzhan Zhou, Yan Lu, Wenlong Zhang, Jin Ye, Jianfei Cai, Wanli Ouyang, Yu Qiao, Zongyuan Ge, Shixiang Tang, Junjun He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21148">https://arxiv.org/abs/2508.21148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21148">https://arxiv.org/pdf/2508.21148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21148]] A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers(https://arxiv.org/abs/2508.21148)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate. We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets. We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning. On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols. These data-centric analyses highlight persistent issues in scientific data development and discuss emerging solutions involving semi-automated annotation pipelines and expert validation. Finally, we outline a paradigm shift toward closed-loop systems where autonomous agents based on Sci-LLMs actively experiment, validate, and contribute to a living, evolving knowledge base. Collectively, this work provides a roadmap for building trustworthy, continually evolving artificial intelligence (AI) systems that function as a true partner in accelerating scientific discovery.</li>
</ul>

<h3>Title: Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations</h3>
<ul>
<li><strong>Authors: </strong>Muskan Saraf, Sajjad Rezvani Boroujeni, Justin Beaudry, Hossein Abedi, Tom Bush</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21164">https://arxiv.org/abs/2508.21164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21164">https://arxiv.org/pdf/2508.21164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21164]] Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations(https://arxiv.org/abs/2508.21164)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used to evaluate outputs, yet their judgments may be influenced. This study examines bias in self- and cross-model evaluations by ChatGPT, Gemini, and Claude under four conditions: no labels, true labels, and two false-label scenarios. Blog posts authored by each model were evaluated by all three using both overall preference voting and quality ratings for Coherence, Informativeness, and Conciseness, with all scores expressed as percentages for direct comparison. Results reveal striking asymmetries: the "Claude" label consistently boosts scores, while the "Gemini" label consistently depresses them, regardless of actual content. False labels frequently reversed rankings, producing shifts of up to 50 percentage points in preference votes and up to 12 percentage points in converted quality ratings. Gemini's self-scores collapsed under true labels, while Claude's self-preference intensified. These findings show that perceived model identity can heavily distort high-level judgments and subtly influence detailed quality ratings, underscoring the need for blind or multimodel evaluation protocols to ensure fairness in LLM benchmarking.</li>
</ul>

<h3>Title: SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4</h3>
<ul>
<li><strong>Authors: </strong>Kevin Mayer, Alex Vesel, Xinyi Zhao, Martin Fischer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21169">https://arxiv.org/abs/2508.21169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21169">https://arxiv.org/pdf/2508.21169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21169]] SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4(https://arxiv.org/abs/2508.21169)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>3D building models are critical for applications in architecture, energy simulation, and navigation. Yet, generating accurate and semantically rich 3D buildings automatically remains a major challenge due to the lack of large-scale annotated datasets in the public domain. Inspired by the success of synthetic data in computer vision, we introduce SYNBUILD-3D, a large, diverse, and multi-modal dataset of over 6.2 million synthetic 3D residential buildings at Level of Detail (LoD) 4. In the dataset, each building is represented through three distinct modalities: a semantically enriched 3D wireframe graph at LoD 4 (Modality I), the corresponding floor plan images (Modality II), and a LiDAR-like roof point cloud (Modality III). The semantic annotations for each building wireframe are derived from the corresponding floor plan images and include information on rooms, doors, and windows. Through its tri-modal nature, future work can use SYNBUILD-3D to develop novel generative AI algorithms that automate the creation of 3D building models at LoD 4, subject to predefined floor plan layouts and roof geometries, while enforcing semantic-geometric consistency. Dataset and code samples are publicly available at this https URL.</li>
</ul>

<h3>Title: FUTURE: Flexible Unlearning for Tree Ensemble</h3>
<ul>
<li><strong>Authors: </strong>Ziheng Chen, Jin Huang, Jiali Cheng, Yuchan Guo, Mengjie Wang, Lalitesh Morishetti, Kaushiki Nag, Hadi Amiri</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21181">https://arxiv.org/abs/2508.21181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21181">https://arxiv.org/pdf/2508.21181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21181]] FUTURE: Flexible Unlearning for Tree Ensemble(https://arxiv.org/abs/2508.21181)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Tree ensembles are widely recognized for their effectiveness in classification tasks, achieving state-of-the-art performance across diverse domains, including bioinformatics, finance, and medical diagnosis. With increasing emphasis on data privacy and the \textit{right to be forgotten}, several unlearning algorithms have been proposed to enable tree ensembles to forget sensitive information. However, existing methods are often tailored to a particular model or rely on the discrete tree structure, making them difficult to generalize to complex ensembles and inefficient for large-scale datasets. To address these limitations, we propose FUTURE, a novel unlearning algorithm for tree ensembles. Specifically, we formulate the problem of forgetting samples as a gradient-based optimization task. In order to accommodate non-differentiability of tree ensembles, we adopt the probabilistic model approximations within the optimization framework. This enables end-to-end unlearning in an effective and efficient manner. Extensive experiments on real-world datasets show that FUTURE yields significant and successful unlearning performance.</li>
</ul>

<h3>Title: BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design</h3>
<ul>
<li><strong>Authors: </strong>Deepro Choudhury, Sinead Williamson, Adam Goliński, Ning Miao, Freddie Bickford Smith, Michael Kirchhof, Yizhe Zhang, Tom Rainforth</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21184">https://arxiv.org/abs/2508.21184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21184">https://arxiv.org/pdf/2508.21184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21184]] BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design(https://arxiv.org/abs/2508.21184)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose a general-purpose approach for improving the ability of Large Language Models (LLMs) to intelligently and adaptively gather information from a user or other external source using the framework of sequential Bayesian experimental design (BED). This enables LLMs to act as effective multi-turn conversational agents and interactively interface with external environments. Our approach, which we call BED-LLM (Bayesian Experimental Design with Large Language Models), is based on iteratively choosing questions or queries that maximize the expected information gain (EIG) about the task of interest given the responses gathered previously. We show how this EIG can be formulated in a principled way using a probabilistic model derived from the LLM's belief distribution and provide detailed insights into key decisions in its construction. Further key to the success of BED-LLM are a number of specific innovations, such as a carefully designed estimator for the EIG, not solely relying on in-context updates for conditioning on previous responses, and a targeted strategy for proposing candidate queries. We find that BED-LLM achieves substantial gains in performance across a wide range of tests based on the 20-questions game and using the LLM to actively infer user preferences, compared to direct prompting of the LLM and other adaptive design strategies.</li>
</ul>

<h3>Title: Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium</h3>
<ul>
<li><strong>Authors: </strong>Christopher R. Lee-Jenkins</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21186">https://arxiv.org/abs/2508.21186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21186">https://arxiv.org/pdf/2508.21186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21186]] Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium(https://arxiv.org/abs/2508.21186)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Decoding in large language models is often described as scoring tokens and normalizing with softmax. We give a minimal, self-contained account of this step as a constrained variational principle on the probability simplex. The discrete, normalization-respecting ascent is the classical multiplicative-weights (entropic mirror) update; its continuous-time limit is the replicator flow. From these ingredients we prove that, for a fixed context and temperature, the next-token distribution follows a smooth trajectory inside the simplex and converges to the softmax equilibrium. This formalizes the common ``manifold traversal'' intuition at the output-distribution level. The analysis yields precise, practice-facing consequences: temperature acts as an exact rescaling of time along the same trajectory, while top-k and nucleus sampling restrict the flow to a face with identical guarantees. We also outline a controlled account of path-dependent score adjustments and their connection to loop-like, hallucination-style behavior. We make no claims about training dynamics or internal representations; those are deferred to future work.</li>
</ul>

<h3>Title: Model-Task Alignment Drives Distinct RL Outcomes</h3>
<ul>
<li><strong>Authors: </strong>Haoze Wu, Cheng Wang, Wenshuo Zhao, Junxian He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21188">https://arxiv.org/abs/2508.21188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21188">https://arxiv.org/pdf/2508.21188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21188]] Model-Task Alignment Drives Distinct RL Outcomes(https://arxiv.org/abs/2508.21188)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in applying reinforcement learning (RL) to large language models (LLMs) have led to substantial progress. In particular, a series of remarkable yet often counterintuitive phenomena have been reported in LLMs, exhibiting patterns not typically observed in traditional RL settings. For example, notable claims include that a single training example can match the performance achieved with an entire dataset, that the reward signal does not need to be very accurate, and that training solely with negative samples can match or even surpass sophisticated reward-based methods. However, the precise conditions under which these observations hold - and, critically, when they fail - remain unclear. In this work, we identify a key factor that differentiates RL observations: whether the pretrained model already exhibits strong Model-Task Alignment, as measured by pass@k accuracy on the evaluated task. Through a systematic and comprehensive examination of a series of counterintuitive claims, supported by rigorous experimental validation across different model architectures and task domains, our findings show that while standard RL training remains consistently robust across settings, many of these counterintuitive results arise only when the model and task already exhibit strong model-task alignment. In contrast, these techniques fail to drive substantial learning in more challenging regimes, where standard RL methods remain effective.</li>
</ul>

<h3>Title: GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Zhenghao He, Sanchit Sinha, Guangzhi Xiong, Aidong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21197">https://arxiv.org/abs/2508.21197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21197">https://arxiv.org/pdf/2508.21197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21197]] GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability(https://arxiv.org/abs/2508.21197)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Concept Activation Vectors (CAVs) provide a powerful approach for interpreting deep neural networks by quantifying their sensitivity to human-defined concepts. However, when computed independently at different layers, CAVs often exhibit inconsistencies, making cross-layer comparisons unreliable. To address this issue, we propose the Global Concept Activation Vector (GCAV), a novel framework that unifies CAVs into a single, semantically consistent representation. Our method leverages contrastive learning to align concept representations across layers and employs an attention-based fusion mechanism to construct a globally integrated CAV. By doing so, our method significantly reduces the variance in TCAV scores while preserving concept relevance, ensuring more stable and reliable concept attributions. To evaluate the effectiveness of GCAV, we introduce Testing with Global Concept Activation Vectors (TGCAV) as a method to apply TCAV to GCAV-based representations. We conduct extensive experiments on multiple deep neural networks, demonstrating that our method effectively mitigates concept inconsistency across layers, enhances concept localization, and improves robustness against adversarial perturbations. By integrating cross-layer information into a coherent framework, our method offers a more comprehensive and interpretable understanding of how deep learning models encode human-defined concepts. Code and models are available at this https URL.</li>
</ul>

<h3>Title: Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Arash Ahmadi, Sarah Sharif, Yaser Banad</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21201">https://arxiv.org/abs/2508.21201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21201">https://arxiv.org/pdf/2508.21201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21201]] Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization(https://arxiv.org/abs/2508.21201)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Analyzing the human factors behind aviation accidents is crucial for preventing future incidents, yet traditional methods using the Human Factors Analysis and Classification System (HFACS) are limited by scalability and consistency. To address this, we introduce an automated HFACS classification framework for aviation safety analysis that utilizes Reinforcement Learning with Group Relative Policy Optimization (GRPO) to fine-tune a Llama-3.1 8B language model. Our approach incorporates a multi-component reward system tailored for aviation safety analysis and integrates synthetic data generation to overcome class imbalance in accident datasets. The resulting GRPO-optimized model achieved noticeable performance gains, including a 350% increase in exact match accuracy (from 0.0400 to 0.1800) and an improved partial match accuracy of 0.8800. Significantly, our specialized model outperforms state-of-the-art LLMs (Large Language Models), including GPT-5-mini and Gemini-2.5-fiash, on key metrics. This research also proposes exact match accuracy in multi-label HFACS classification problem as a new benchmarking methodology to evaluate the advanced reasoning capabilities of language models. Ultimately, our work validates that smaller, domain-optimized models can provide a computationally efficient and better solution for critical safety analysis. This approach makes powerful, low-latency deployment on resource-constrained edge devices feasible.</li>
</ul>

<h3>Title: Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach</h3>
<ul>
<li><strong>Authors: </strong>Han Yang, Jian Lan, Yihong Liu, Hinrich Schütze, Thomas Seidl</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21206">https://arxiv.org/abs/2508.21206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21206">https://arxiv.org/pdf/2508.21206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21206]] Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach(https://arxiv.org/abs/2508.21206)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Autoregressive language models are vulnerable to orthographic attacks, where input text is perturbed with characters from multilingual alphabets, leading to substantial performance degradation. This vulnerability primarily stems from the out-of-vocabulary issue inherent in subword tokenizers and their embeddings. To address this limitation, we propose a pixel-based generative language model that replaces the text-based embeddings with pixel-based representations by rendering words as individual images. This design provides stronger robustness to noisy inputs, while an extension of compatibility to multilingual text across diverse writing systems. We evaluate the proposed method on the multilingual LAMBADA dataset, WMT24 dataset and the SST-2 benchmark, demonstrating both its resilience to orthographic noise and its effectiveness in multilingual settings.</li>
</ul>

<h3>Title: The WASM Cloak: Evaluating Browser Fingerprinting Defenses Under WebAssembly based Obfuscation</h3>
<ul>
<li><strong>Authors: </strong>A H M Nazmus Sakib, Mahsin Bin Akram, Joseph Spracklen, Sahan Kalutarage, Raveen Wijewickrama, Igor Bilogrevic, Murtuza Jadliwala</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21219">https://arxiv.org/abs/2508.21219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21219">https://arxiv.org/pdf/2508.21219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21219]] The WASM Cloak: Evaluating Browser Fingerprinting Defenses Under WebAssembly based Obfuscation(https://arxiv.org/abs/2508.21219)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Browser fingerprinting defenses have historically focused on detecting JavaScript(JS)-based tracking techniques. However, the widespread adoption of WebAssembly (WASM) introduces a potential blind spot, as adversaries can convert JS to WASM's low-level binary format to obfuscate malicious logic. This paper presents the first systematic evaluation of how such WASM-based obfuscation impacts the robustness of modern fingerprinting defenses. We develop an automated pipeline that translates real-world JS fingerprinting scripts into functional WASM-obfuscated variants and test them against two classes of defenses: state-of-the-art detectors in research literature and commercial, in-browser tools. Our findings reveal a notable divergence: detectors proposed in the research literature that rely on feature-based analysis of source code show moderate vulnerability, stemming from outdated datasets or a lack of WASM compatibility. In contrast, defenses such as browser extensions and native browser features remained completely effective, as their API-level interception is agnostic to the script's underlying implementation. These results highlight a gap between academic and practical defense strategies and offer insights into strengthening detection approaches against WASM-based obfuscation, while also revealing opportunities for more evasive techniques in future attacks.</li>
</ul>

<h3>Title: Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg</h3>
<ul>
<li><strong>Authors: </strong>Keshav Jha, William Sharp, Dominic LaBella</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21227">https://arxiv.org/abs/2508.21227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21227">https://arxiv.org/pdf/2508.21227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21227]] Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg(https://arxiv.org/abs/2508.21227)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate delineation of pancreatic tumors is critical for diagnosis, treatment planning, and outcome assessment, yet automated segmentation remains challenging due to anatomical variability and limited dataset availability. In this study, SegResNet models, as part of the Auto3DSeg architecture, were trained and evaluated on two MRI-based pancreatic tumor segmentation tasks as part of the 2025 PANTHER Challenge. Algorithm methodology included 5-fold cross-validation with STAPLE ensembling after focusing on an anatomically relevant region-of-interest. The Pancreatic Tumor Segmentation on Diagnostic MRI task 1 training set included 91 T1-weighted arterial contrast-enhanced MRI with expert annotated pancreas and tumor labels. The Pancreatic Tumor Segmentation on MR-Linac task 2 training set used 50 T2-weighted MR-Linac cases with expert annotated pancreas and tumor labels. Algorithm-automated segmentation performance of pancreatic tumor was assessed using Dice Similarity Coefficient (DSC), 5 mm DSC, 95th percentile Hausdorff Distance (HD95), Mean Average Surface Distance (MASD), and Root Mean Square Error (RMSE). For Task 1, the algorithm achieved a DSC of 0.56, 5 mm DSC of 0.73, HD95 of 41.1 mm, MASD of 26.0 mm, and RMSE of 5164 mm. For Task 2, performance decreased, with a DSC of 0.33, 5 mm DSC of 0.50, HD95 of 20.1 mm, MASD of 7.2 mm, and RMSE of 17,203 mm. These findings illustrate the challenges of MRI-based pancreatic tumor segmentation with small datasets, highlighting variability introduced by different MRI sequences. Despite modest performance, the results demonstrate potential for automated delineation and emphasize the need for larger, standardized MRI datasets to improve model robustness and clinical utility.</li>
</ul>

<h3>Title: Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection</h3>
<ul>
<li><strong>Authors: </strong>Weizhi Gao, Xiaorui Liu, Feiyi Wang, Dan Lu, Junqi Yin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21228">https://arxiv.org/abs/2508.21228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21228">https://arxiv.org/pdf/2508.21228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21228]] Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection(https://arxiv.org/abs/2508.21228)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated impressive performance in both research and real-world applications, but they still struggle with hallucination. Existing hallucination detection methods often perform poorly on sentence-level generation or rely heavily on domain-specific knowledge. While self-consistency approaches help address these limitations, they incur high computational costs due to repeated generation. In this paper, we conduct the first study on identifying redundancy in self-consistency methods, manifested as shared prefix tokens across generations, and observe that non-exact-answer tokens contribute minimally to the semantic content. Based on these insights, we propose a novel Decoding Memory Pipeline (DMP) that accelerates generation through selective inference and annealed decoding. Being orthogonal to the model, dataset, decoding strategy, and self-consistency baseline, our DMP consistently improves the efficiency of multi-response generation and holds promise for extension to alignment and reasoning tasks. Extensive experiments show that our method achieves up to a 3x speedup without sacrificing AUROC performance.</li>
</ul>

<h3>Title: Class Incremental Continual Learning with Self-Organizing Maps and Variational Autoencoders Using Synthetic Replay</h3>
<ul>
<li><strong>Authors: </strong>Pujan Thapa, Alexander Ororbia, Travis Desell</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21240">https://arxiv.org/abs/2508.21240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21240">https://arxiv.org/pdf/2508.21240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21240]] Class Incremental Continual Learning with Self-Organizing Maps and Variational Autoencoders Using Synthetic Replay(https://arxiv.org/abs/2508.21240)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This work introduces a novel generative continual learning framework based on self-organizing maps (SOMs) and variational autoencoders (VAEs) to enable memory-efficient replay, eliminating the need to store raw data samples or task labels. For high-dimensional input spaces, such as of CIFAR-10 and CIFAR-100, we design a scheme where the SOM operates over the latent space learned by a VAE, whereas, for lower-dimensional inputs, such as those found in MNIST and FashionMNIST, the SOM operates in a standalone fashion. Our method stores a running mean, variance, and covariance for each SOM unit, from which synthetic samples are then generated during future learning iterations. For the VAE-based method, generated samples are then fed through the decoder to then be used in subsequent replay. Experimental results on standard class-incremental benchmarks show that our approach performs competitively with state-of-the-art memory-based methods and outperforms memory-free methods, notably improving over best state-of-the-art single class incremental performance on CIFAR-10 and CIFAR-100 by nearly $10$\% and $7$\%, respectively. Our methodology further facilitates easy visualization of the learning process and can also be utilized as a generative model post-training. Results show our method's capability as a scalable, task-label-free, and memory-efficient solution for continual learning.</li>
</ul>

<h3>Title: A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Amin Nabian, Sanjay Choudhry</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21249">https://arxiv.org/abs/2508.21249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21249">https://arxiv.org/pdf/2508.21249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21249]] A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics(https://arxiv.org/abs/2508.21249)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The computational cost associated with high-fidelity CFD simulations remains a significant bottleneck in the automotive design and optimization cycle. While ML-based surrogate models have emerged as a promising alternative to accelerate aerodynamic predictions, the field is characterized by a diverse and rapidly evolving landscape of specialized neural network architectures, with no single model demonstrating universal superiority. This paper introduces a novel meta-learning framework that leverages this architectural diversity as a strength. We propose a Mixture of Experts (MoE) model that employs a dedicated gating network to dynamically and optimally combine the predictions from three heterogeneous, state-of-the-art surrogate models: DoMINO, a decomposable multi-scale neural operator; X-MeshGraphNet, a scalable multi-scale graph neural network; and FigConvNet, a factorized implicit global convolution network. The gating network learns a spatially-variant weighting strategy, assigning credibility to each expert based on its localized performance in predicting surface pressure and wall shear stress fields. To prevent model collapse and encourage balanced expert contributions, we integrate an entropy regularization term into the training loss function. The entire system is trained and validated on the DrivAerML dataset, a large-scale, public benchmark of high-fidelity CFD simulations for automotive aerodynamics. Quantitative results demonstrate that the MoE model achieves a significant reduction in L-2 prediction error, outperforming not only the ensemble average but also the most accurate individual expert model across all evaluated physical quantities. This work establishes the MoE framework as a powerful and effective strategy for creating more robust and accurate composite surrogate models by synergistically combining the complementary strengths of specialized architectures.</li>
</ul>

<h3>Title: Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yidong Zhao, Peter Kellman, Hui Xue, Tongyun Yang, Yi Zhang, Yuchi Han, Orlando Simonetti, Qian Tao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21254">https://arxiv.org/abs/2508.21254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21254">https://arxiv.org/pdf/2508.21254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21254]] Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation(https://arxiv.org/abs/2508.21254)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Pretrained segmentation models for cardiac magnetic resonance imaging (MRI) struggle to generalize across different imaging sequences due to significant variations in image contrast. These variations arise from changes in imaging protocols, yet the same fundamental spin properties, including proton density, T1, and T2 values, govern all acquired images. With this core principle, we introduce Reverse Imaging, a novel physics-driven method for cardiac MRI data augmentation and domain adaptation to fundamentally solve the generalization problem. Our method reversely infers the underlying spin properties from observed cardiac MRI images, by solving ill-posed nonlinear inverse problems regularized by the prior distribution of spin properties. We acquire this "spin prior" by learning a generative diffusion model from the multiparametric SAturation-recovery single-SHot acquisition sequence (mSASHA) dataset, which offers joint cardiac T1 and T2 maps. Our method enables approximate but meaningful spin-property estimates from MR images, which provide an interpretable "latent variable" that lead to highly flexible image synthesis of arbitrary novel sequences. We show that Reverse Imaging enables highly accurate segmentation across vastly different image contrasts and imaging protocols, realizing wide-spectrum generalization of cardiac MRI segmentation.</li>
</ul>

<h3>Title: PHD: Personalized 3D Human Body Fitting with Point Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Hsuan-I Ho, Chen Guo, Po-Chen Wu, Ivan Shugurov, Chengcheng Tang, Abhay Mittal, Sizhe An, Manuel Kaufmann, Linguang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21257">https://arxiv.org/abs/2508.21257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21257">https://arxiv.org/pdf/2508.21257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21257]] PHD: Personalized 3D Human Body Fitting with Point Diffusion(https://arxiv.org/abs/2508.21257)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We introduce PHD, a novel approach for personalized 3D human mesh recovery (HMR) and body fitting that leverages user-specific shape information to improve pose estimation accuracy from videos. Traditional HMR methods are designed to be user-agnostic and optimized for generalization. While these methods often refine poses using constraints derived from the 2D image to improve alignment, this process compromises 3D accuracy by failing to jointly account for person-specific body shapes and the plausibility of 3D poses. In contrast, our pipeline decouples this process by first calibrating the user's body shape and then employing a personalized pose fitting process conditioned on that shape. To achieve this, we develop a body shape-conditioned 3D pose prior, implemented as a Point Diffusion Transformer, which iteratively guides the pose fitting via a Point Distillation Sampling loss. This learned 3D pose prior effectively mitigates errors arising from an over-reliance on 2D constraints. Consequently, our approach improves not only pelvis-aligned pose accuracy but also absolute pose accuracy -- an important metric often overlooked by prior work. Furthermore, our method is highly data-efficient, requiring only synthetic data for training, and serves as a versatile plug-and-play module that can be seamlessly integrated with existing 3D pose estimators to enhance their performance. Project page: this https URL</li>
</ul>

<h3>Title: RelP: Faithful and Efficient Circuit Discovery via Relevance Patching</h3>
<ul>
<li><strong>Authors: </strong>Farnoush Rezaei Jafari, Oliver Eberle, Ashkan Khakzar, Neel Nanda</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21258">https://arxiv.org/abs/2508.21258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21258">https://arxiv.org/pdf/2508.21258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21258]] RelP: Faithful and Efficient Circuit Discovery via Relevance Patching(https://arxiv.org/abs/2508.21258)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Activation patching is a standard method in mechanistic interpretability for localizing the components of a model responsible for specific behaviors, but it is computationally expensive to apply at scale. Attribution patching offers a faster, gradient-based approximation, yet suffers from noise and reduced reliability in deep, highly non-linear networks. In this work, we introduce Relevance Patching (RelP), which replaces the local gradients in attribution patching with propagation coefficients derived from Layer-wise Relevance Propagation (LRP). LRP propagates the network's output backward through the layers, redistributing relevance to lower-level components according to local propagation rules that ensure properties such as relevance conservation or improved signal-to-noise ratio. Like attribution patching, RelP requires only two forward passes and one backward pass, maintaining computational efficiency while improving faithfulness. We validate RelP across a range of models and tasks, showing that it more accurately approximates activation patching than standard attribution patching, particularly when analyzing residual stream and MLP outputs in the Indirect Object Identification (IOI) task. For instance, for MLP outputs in GPT-2 Large, attribution patching achieves a Pearson correlation of 0.006, whereas RelP reaches 0.956, highlighting the improvement offered by RelP. Additionally, we compare the faithfulness of sparse feature circuits identified by RelP and Integrated Gradients (IG), showing that RelP achieves comparable faithfulness without the extra computational cost associated with IG.</li>
</ul>

<h3>Title: Owen Sampling Accelerates Contribution Estimation in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Hossein KhademSohi, Hadi Hemmati, Jiayu Zhou, Steve Drew</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21261">https://arxiv.org/abs/2508.21261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21261">https://arxiv.org/pdf/2508.21261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21261]] Owen Sampling Accelerates Contribution Estimation in Federated Learning(https://arxiv.org/abs/2508.21261)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, fair</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) aggregates information from multiple clients to train a shared global model without exposing raw data. Accurately estimating each client's contribution is essential not just for fair rewards, but for selecting the most useful clients so the global model converges faster. The Shapley value is a principled choice, yet exact computation scales exponentially with the number of clients, making it infeasible for large federations. We propose FedOwen, an efficient framework that uses Owen sampling to approximate Shapley values under the same total evaluation budget as existing methods while keeping the approximation error small. In addition, FedOwen uses an adaptive client selection strategy that balances exploiting high-value clients with exploring under-sampled ones, reducing bias and uncovering rare but informative data. Under a fixed valuation cost, FedOwen achieves up to 23 percent higher final accuracy within the same number of communication rounds compared to state-of-the-art baselines on non-IID benchmarks.</li>
</ul>

<h3>Title: Guess-and-Learn (G&L): Measuring the Cumulative Error Cost of Cold-Start Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Roland Arnold</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21270">https://arxiv.org/abs/2508.21270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21270">https://arxiv.org/pdf/2508.21270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21270]] Guess-and-Learn (G&L): Measuring the Cumulative Error Cost of Cold-Start Adaptation(https://arxiv.org/abs/2508.21270)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Evaluation of machine learning models typically emphasizes final accuracy, overlooking the cost of adaptation: the cumulative errors incurred while learning from scratch. Guess-and- Learn (G&L) v1.0 addresses this gap by measuring cold-start adaptability - the total mistakes a model makes while sequentially labeling an unlabeled dataset. At each step, the learner selects an instance, predicts its label, receives the ground truth, and updates parameters under either online (per-sample) or batch (delayed) mode. The resulting error trajectory exposes adaptation speed, selection quality, and bias - dynamics invisible to endpoint metrics. G&L defines four tracks (Scratch/Pretrained $\times$ Online/Batch) to disentangle the effects of initialization and update frequency. We formalize the protocol, relate it to classical mistake-bound theory, and estimate a heuristic "oracle reference band" for MNIST as a plausibility reference. Baseline experiments on MNIST and AG News, spanning classical methods (Perceptron, k-NN), convolutional architectures (CNN, ResNet-50), and pretrained transformers (ViT-B/16, BERT-base), reveal systematic differences in early-phase efficiency: smaller models can adapt with fewer initial errors, while pretraining benefits vary by domain. Across settings, current models remain well above the oracle band, highlighting an adaptability gap. By quantifying the mistake cost of early learning, G&L complements conventional benchmarks and provides a reproducible framework for developing learners that are not only accurate in the limit but also reliable from the first examples.</li>
</ul>

<h3>Title: CALM: A Framework for Continuous, Adaptive, and LLM-Mediated Anomaly Detection in Time-Series Streams</h3>
<ul>
<li><strong>Authors: </strong>Ashok Devireddy, Shunping Huang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21273">https://arxiv.org/abs/2508.21273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21273">https://arxiv.org/pdf/2508.21273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21273]] CALM: A Framework for Continuous, Adaptive, and LLM-Mediated Anomaly Detection in Time-Series Streams(https://arxiv.org/abs/2508.21273)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The detection of anomalies in non-stationary time-series streams is a critical but challenging task across numerous industrial and scientific domains. Traditional models, trained offline, suffer significant performance degradation when faced with concept drift, where the underlying statistical properties of the data change over time. This paper introduces CALM (Continuous, Adaptive, and LLM-Mediated), a novel, end-to-end framework for real-time anomaly detection designed to address this challenge. CALM is built on the Apache Beam distributed processing framework and leverages the TimesFm foundation model for forecasting-based anomaly detection. The framework's novelty lies in two core contributions. First, it implements a closed-loop, continuous fine-tuning mechanism that allows the anomaly detection model to adapt to evolving data patterns in near real-time. Second, it introduces an LLM-as-a-Judge component, a Large Language Model that provides semantic, context-aware judgments on detected anomalies to curate a high-quality training dataset, deciding whether an anomaly represents transient noise or a meaningful pattern shift. We evaluate CALM on the comprehensive TSB-UAD benchmark. Our results demonstrate that the continuously fine-tuned model improves the ROC AUC score in most datasets compared to the static, pre-trained base model, validating the efficacy of our adaptive, LLM-guided approach to maintaining high-performance anomaly detection in dynamic streaming environments.</li>
</ul>

<h3>Title: Detecting Domain Shifts in Myoelectric Activations: Challenges and Opportunities in Stream Learning</h3>
<ul>
<li><strong>Authors: </strong>Yibin Sun, Nick Lim, Guilherme Weigert Cassales, Heitor Murilo Gomes, Bernhard Pfahringer, Albert Bifet, Anany Dwivedi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21278">https://arxiv.org/abs/2508.21278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21278">https://arxiv.org/pdf/2508.21278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21278]] Detecting Domain Shifts in Myoelectric Activations: Challenges and Opportunities in Stream Learning(https://arxiv.org/abs/2508.21278)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Detecting domain shifts in myoelectric activations poses a significant challenge due to the inherent non-stationarity of electromyography (EMG) signals. This paper explores the detection of domain shifts using data stream (DS) learning techniques, focusing on the DB6 dataset from the Ninapro database. We define domains as distinct time-series segments based on different subjects and recording sessions, applying Kernel Principal Component Analysis (KPCA) with a cosine kernel to pre-process and highlight these shifts. By evaluating multiple drift detection methods such as CUSUM, Page-Hinckley, and ADWIN, we reveal the limitations of current techniques in achieving high performance for real-time domain shift detection in EMG signals. Our results underscore the potential of streaming-based approaches for maintaining stable EMG decoding models, while highlighting areas for further research to enhance robustness and accuracy in real-world scenarios.</li>
</ul>

<h3>Title: BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning</h3>
<ul>
<li><strong>Authors: </strong>João Guilherme Alves Santos, Giovana Kerche Bonás, Thales Sales Almeida</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21294">https://arxiv.org/abs/2508.21294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21294">https://arxiv.org/pdf/2508.21294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21294]] BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning(https://arxiv.org/abs/2508.21294)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>With the growing capabilities of Large Language Models (LLMs), there is an increasing need for robust evaluation methods, especially in multilingual and non-English contexts. We present an updated version of the BLUEX dataset, now including 2024-2025 exams and automatically generated image captions using state-of-the-art models, enhancing its relevance for data contamination studies in LLM pretraining. Captioning strategies increase accessibility to text-only models by more than 40%, producing 1,422 usable questions, more than doubling the number in the original BLUEX. We evaluated commercial and open-source LLMs and their ability to leverage visual context through captions.</li>
</ul>

<h3>Title: MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems</h3>
<ul>
<li><strong>Authors: </strong>Shihao Ji, Zihui Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21296">https://arxiv.org/abs/2508.21296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21296">https://arxiv.org/pdf/2508.21296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21296]] MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems(https://arxiv.org/abs/2508.21296)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, generative</a></li>
<li><strong>Abstract: </strong>Continual or Lifelong Learning aims to develop models capable of acquiring new knowledge from a sequence of tasks without catastrophically forgetting what has been learned before. Existing approaches often rely on storing samples from previous tasks (experience replay) or employing complex regularization terms to protect learned weights. However, these methods face challenges related to data privacy, storage limitations, and performance degradation when tasks are dissimilar. To address these challenges, we introduce MyGO (Memory Yielding Generative Offline-consolidation), a novel lifelong learning framework inspired by the biological wake-sleep cycle. During the "wake" phase, the system rapidly learns a new task and trains a compact generative model (Generative Memory, G-mem) to capture its data distribution. During the "sleep" phase, the system enters an offline state, using all learned G-mem models to generate pseudo-data ("dreams") and consolidate new and old knowledge into a core feature extractor via knowledge distillation. This approach obviates the need to store any raw data, retaining only compact generative models, which offers significant advantages in privacy and storage efficiency. We evaluate MyGO on computer vision (Split-MNIST) and natural language processing (Split-AG News) benchmarks, comparing it against a sequential fine-tuning baseline. The results demonstrate that MyGO significantly mitigates catastrophic forgetting and maintains high average accuracy across tasks, proving the framework's effectiveness and domain-generality.</li>
</ul>

<h3>Title: LLM-driven Provenance Forensics for Threat Investigation and Detection</h3>
<ul>
<li><strong>Authors: </strong>Kunal Mukherjee, Murat Kantarcioglu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21323">https://arxiv.org/abs/2508.21323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21323">https://arxiv.org/pdf/2508.21323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21323]] LLM-driven Provenance Forensics for Threat Investigation and Detection(https://arxiv.org/abs/2508.21323)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction</a></li>
<li><strong>Abstract: </strong>We introduce PROVSEEK, an LLM-powered agentic framework for automated provenance-driven forensic analysis and threat intelligence extraction. PROVSEEK employs specialized toolchains to dynamically retrieve relevant context by generating precise, context-aware queries that fuse a vectorized threat report knowledge base with data from system provenance databases. The framework resolves provenance queries, orchestrates multiple role-specific agents to mitigate hallucinations, and synthesizes structured, ground-truth verifiable forensic summaries. By combining agent orchestration with Retrieval-Augmented Generation (RAG) and chain-of-thought (CoT) reasoning, PROVSEEK enables adaptive multi-step analysis that iteratively refines hypotheses, verifies supporting evidence, and produces scalable, interpretable forensic explanations of attack behaviors. By combining provenance data with agentic reasoning, PROVSEEK establishes a new paradigm for grounded agentic forecics to investigate APTs. We conduct a comprehensive evaluation on publicly available DARPA datasets, demonstrating that PROVSEEK outperforms retrieval-based methods for intelligence extraction task, achieving a 34% improvement in contextual precision/recall; and for threat detection task, PROVSEEK achieves 22%/29% higher precision/recall compared to both a baseline agentic AI approach and State-Of-The-Art (SOTA) Provenance-based Intrusion Detection System (PIDS).</li>
</ul>

<h3>Title: Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Xuan Hou, Shuhan Liu, Zhaohui Peng, Yaohui Chu, Yue Zhang, Yining Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21330">https://arxiv.org/abs/2508.21330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21330">https://arxiv.org/pdf/2508.21330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21330]] Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models(https://arxiv.org/abs/2508.21330)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models have been successfully used in the field of time series generation. However, when dealing with long-term time series, which span over extended periods and exhibit more complex long-term temporal patterns, the task of generation becomes significantly more challenging. Long-term time series exhibit long-range temporal dependencies, but their data distribution also undergoes gradual changes over time. Finding a balance between these long-term dependencies and the drift in data distribution is a key challenge. On the other hand, long-term time series contain more complex interrelationships between different feature sequences, making the task of effectively capturing both intra-sequence and inter-sequence dependencies another important challenge. To address these issues, we propose Stage-Diff, a staged generative model for long-term time series based on diffusion models. First, through stage-wise sequence generation and inter-stage information transfer, the model preserves long-term sequence dependencies while enabling the modeling of data distribution shifts. Second, within each stage, progressive sequence decomposition is applied to perform channel-independent modeling at different time scales, while inter-stage information transfer utilizes multi-channel fusion modeling. This approach combines the robustness of channel-independent modeling with the information fusion advantages of multi-channel modeling, effectively balancing the intra-sequence and inter-sequence dependencies of long-term time series. Extensive experiments on multiple real-world datasets validate the effectiveness of Stage-Diff in long-term time series generation tasks.</li>
</ul>

<h3>Title: DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Xuan Hou, Shuhan Liu, Zhaohui Peng, Yaohui Chu, Yue Zhang, Yining Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21340">https://arxiv.org/abs/2508.21340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21340">https://arxiv.org/pdf/2508.21340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21340]] DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks(https://arxiv.org/abs/2508.21340)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, extraction, generative</a></li>
<li><strong>Abstract: </strong>Time series synthesis is an effective approach to ensuring the secure circulation of time series data. Existing time series synthesis methods typically perform temporal modeling based on random sequences to generate target sequences, which often struggle to ensure the temporal dependencies in the generated time series. Additionally, directly modeling temporal features on random sequences makes it challenging to accurately capture the feature information of the original time series. To address the above issues, we propose a simple but effective generative model \textbf{D}ual-\textbf{L}ayer \textbf{G}enerative \textbf{A}dversarial \textbf{N}etworks, named \textbf{DLGAN}. The model decomposes the time series generation process into two stages: sequence feature extraction and sequence reconstruction. First, these two stages form a complete time series autoencoder, enabling supervised learning on the original time series to ensure that the reconstruction process can restore the temporal dependencies of the sequence. Second, a Generative Adversarial Network (GAN) is used to generate synthetic feature vectors that align with the real-time sequence feature vectors, ensuring that the generator can capture the temporal features from real time series. Extensive experiments on four public datasets demonstrate the superiority of this model across various evaluation metrics.</li>
</ul>

<h3>Title: Adaptive Heavy-Tailed Stochastic Gradient Descent</h3>
<ul>
<li><strong>Authors: </strong>Bodu Gong, Gustavo Enrique Batista, Pierre Lafaye de Micheaux</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21353">https://arxiv.org/abs/2508.21353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21353">https://arxiv.org/pdf/2508.21353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21353]] Adaptive Heavy-Tailed Stochastic Gradient Descent(https://arxiv.org/abs/2508.21353)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the era of large-scale neural network models, optimization algorithms often struggle with generalization due to an overreliance on training loss. One key insight widely accepted in the machine learning community is the idea that wide basins (regions around a local minimum where the loss increases gradually) promote better generalization by offering greater stability to small changes in input data or model parameters. In contrast, sharp minima are typically more sensitive and less stable. Motivated by two key empirical observations - the inherent heavy-tailed distribution of gradient noise in stochastic gradient descent and the Edge of Stability phenomenon during neural network training, in which curvature grows before settling at a plateau, we introduce Adaptive Heavy Tailed Stochastic Gradient Descent (AHTSGD). The algorithm injects heavier-tailed noise into the optimizer during the early stages of training to enhance exploration and gradually transitions to lighter-tailed noise as sharpness stabilizes. By dynamically adapting to the sharpness of the loss landscape throughout training, AHTSGD promotes accelerated convergence to wide basins. AHTSGD is the first algorithm to adjust the nature of injected noise into an optimizer based on the Edge of Stability phenomenon. AHTSGD consistently outperforms SGD and other noise-based methods on benchmarks like MNIST and CIFAR-10, with marked gains on noisy datasets such as SVHN. It ultimately accelerates early training from poor initializations and improves generalization across clean and noisy settings, remaining robust to learning rate choices.</li>
</ul>

<h3>Title: Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning</h3>
<ul>
<li><strong>Authors: </strong>Yuquan Bi, Hongsong Wang, Xinli Shi, Zhipeng Gui, Jie Gui, Yuan Yan Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21363">https://arxiv.org/abs/2508.21363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21363">https://arxiv.org/pdf/2508.21363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21363]] Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning(https://arxiv.org/abs/2508.21363)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated strong capabilities in generating high-fidelity 3D human poses, yet their iterative nature and multi-hypothesis requirements incur substantial computational cost. In this paper, we propose an Efficient Diffusion-Based 3D Human Pose Estimation framework with a Hierarchical Temporal Pruning (HTP) strategy, which dynamically prunes redundant pose tokens across both frame and semantic levels while preserving critical motion dynamics. HTP operates in a staged, top-down manner: (1) Temporal Correlation-Enhanced Pruning (TCEP) identifies essential frames by analyzing inter-frame motion correlations through adaptive temporal graph construction; (2) Sparse-Focused Temporal MHSA (SFT MHSA) leverages the resulting frame-level sparsity to reduce attention computation, focusing on motion-relevant tokens; and (3) Mask-Guided Pose Token Pruner (MGPTP) performs fine-grained semantic pruning via clustering, retaining only the most informative pose tokens. Experiments on Human3.6M and MPI-INF-3DHP show that HTP reduces training MACs by 38.5\%, inference MACs by 56.8\%, and improves inference speed by an average of 81.1\% compared to prior diffusion-based methods, while achieving state-of-the-art performance.</li>
</ul>

<h3>Title: Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image</h3>
<ul>
<li><strong>Authors: </strong>Qingran Miao, Haixia Wang, Haohao Sun, Yilong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21371">https://arxiv.org/abs/2508.21371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21371">https://arxiv.org/pdf/2508.21371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21371]] Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image(https://arxiv.org/abs/2508.21371)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric</a></li>
<li><strong>Abstract: </strong>Optical Coherence Tomography (OCT) enables the acquisition of high-resolution, three-dimensional fingerprint data, capturing rich subsurface structures for robust biometric recognition. However, the high cost and time-consuming nature of OCT data acquisition have led to a scarcity of large-scale public datasets, significantly hindering the development of advanced algorithms, particularly data-hungry deep learning models. To address this critical bottleneck, this paper introduces Print2Volume, a novel framework for generating realistic, synthetic OCT-based 3D fingerprints from 2D fingerprint image. Our framework operates in three sequential stages: (1) a 2D style transfer module that converts a binary fingerprint into a grayscale images mimicking the style of a Z-direction mean-projected OCT scan; (2) a 3D Structure Expansion Network that extrapolates the 2D im-age into a plausible 3D anatomical volume; and (3) an OCT Realism Refiner, based on a 3D GAN, that renders the structural volume with authentic textures, speckle noise, and other imaging characteristics. Using Print2Volume, we generated a large-scale synthetic dataset of 420,000 samples. Quantitative experiments demonstrate the high quality of our synthetic data and its significant impact on recognition performance. By pre-training a recognition model on our synthetic data and fine-tuning it on a small real-world dataset, we achieved a remarkable reduction in the Equal Error Rate (EER) from 15.62% to 2.50% on the ZJUT-EIFD benchmark, proving the effectiveness of our approach in overcoming data scarcity.</li>
</ul>

<h3>Title: Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models</h3>
<ul>
<li><strong>Authors: </strong>Shubham Sharma, Sneha Tuli, Narendra Badam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21377">https://arxiv.org/abs/2508.21377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21377">https://arxiv.org/pdf/2508.21377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21377]] Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models(https://arxiv.org/abs/2508.21377)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are transforming AI across industries, but their development and deployment remain complex. This survey reviews 16 key challenges in building and using LLMs and examines how these challenges are addressed by two state-of-the-art models with unique approaches: OpenAI's closed source GPT-4o (May 2024 update) and DeepSeek-V3-0324 (March 2025), a large open source Mixture-of-Experts model. Through this comparison, we showcase the trade-offs between closed source models (robust safety, fine-tuned reliability) and open source models (efficiency, adaptability). We also explore LLM applications across different domains (from chatbots and coding tools to healthcare and education), highlighting which model attributes are best suited for each use case. This article aims to guide AI researchers, developers, and decision-makers in understanding current LLM capabilities, limitations, and best practices.</li>
</ul>

<h3>Title: Normality and the Turing Test</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Kabbach</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21382">https://arxiv.org/abs/2508.21382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21382">https://arxiv.org/pdf/2508.21382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21382]] Normality and the Turing Test(https://arxiv.org/abs/2508.21382)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper proposes to revisit the Turing test through the concept of normality. Its core argument is that the statistical interpretation of the normal--understood as the average both in the normative and mathematical sense of the term--proves useful for understanding the Turing test in at least two ways. First, in the sense that the Turing test targets normal/average rather than exceptional human intelligence, so that successfully passing the test requires building machines that "make mistakes" and display imperfect behavior just like normal/average humans. Second, in the sense that the Turing test is a statistical test where judgments of intelligence are never carried out by a single "average" judge (understood as non-expert) but always by a full jury. As such, the notion of "average human interrogator" that Turing talks about in his original paper should be understood primarily as referring to a mathematical abstraction made of the normalized aggregate of individual judgments of multiple judges. In short, this paper argues that the Turing test is a test of normal intelligence as assessed by a normal judge characterizing the average judgment of a pool of human interrogators. Its conclusions are twofold. First, it argues that large language models such as ChatGPT are unlikely to pass the Turing test as those models precisely target exceptional rather than normal/average human intelligence. As such, they constitute models of what it proposes to call artificial smartness rather than artificial intelligence per se. Second, it argues that the core question of whether the Turing test can contribute anything to the understanding of human cognition is that of whether the human mind is really reducible to the normal/average mind--a question which largely extends beyond the Turing test itself and questions the conceptual underpinnings of the normalist paradigm it belongs to.</li>
</ul>

<h3>Title: Risks and Compliance with the EU's Core Cyber Security Legislation</h3>
<ul>
<li><strong>Authors: </strong>Jukka Ruohonen, Jesper Løffler Nielsen, Jakub Skórczynski</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21386">https://arxiv.org/abs/2508.21386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21386">https://arxiv.org/pdf/2508.21386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21386]] Risks and Compliance with the EU's Core Cyber Security Legislation(https://arxiv.org/abs/2508.21386)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The European Union (EU) has long favored a risk-based approach to regulation. Such an approach is also used in recent cyber security legislation enacted in the EU. Risks are also inherently related to compliance with the new legislation. Objective: The paper investigates how risks are framed in the EU's five core cyber security legislative acts, whether the framings indicate convergence or divergence between the acts and their risk concepts, and what qualifying words and terms are used when describing the legal notions of risks. Method : The paper's methodology is based on qualitative legal interpretation and taxonomy-building. Results: The five acts have an encompassing coverage of different cyber security risks, including but not limited to risks related to technical, organizational, and human security as well as those not originating from man-made actions. Both technical aspects and assets are used to frame the legal risk notions in many of the legislative acts. A threat-centric viewpoint is also present in one of the acts. Notable gaps are related to acceptable risks, non-probabilistic risks, and residual risks. Conclusion: The EU's new cyber security legislation has significantly extended the risk-based approach to regulations. At the same time, complexity and compliance burden have increased. With this point in mind, the paper concludes with a few practical takeaways about means to deal with compliance and research it.</li>
</ul>

<h3>Title: AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume</h3>
<ul>
<li><strong>Authors: </strong>Tanguy Herserant, Vincent Guigue</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21389">https://arxiv.org/abs/2508.21389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21389">https://arxiv.org/pdf/2508.21389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21389]] AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume(https://arxiv.org/abs/2508.21389)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>This paper investigates reproducibility challenges in automatic text summarization evaluation. Based on experiments conducted across six representative metrics ranging from classical approaches like ROUGE to recent LLM-based methods (G-Eval, SEval-Ex), we highlight significant discrepancies between reported performances in the literature and those observed in our experimental setting. We introduce a unified, open-source framework, applied to the SummEval dataset and designed to support fair and transparent comparison of evaluation metrics. Our results reveal a structural trade-off: metrics with the highest alignment with human judgments tend to be computationally intensive and less stable across runs. Beyond comparative analysis, this study highlights key concerns about relying on LLMs for evaluation, stressing their randomness, technical dependencies, and limited reproducibility. We advocate for more robust evaluation protocols including exhaustive documentation and methodological standardization to ensure greater reliability in automatic summarization assessment.</li>
</ul>

<h3>Title: zkLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs</h3>
<ul>
<li><strong>Authors: </strong>Guofu Liao, Taotao Wang, Shengli Zhang, Jiqun Zhang, Shi Long, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21393">https://arxiv.org/abs/2508.21393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21393">https://arxiv.org/pdf/2508.21393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21393]] zkLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs(https://arxiv.org/abs/2508.21393)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) is crucial for adapting them to specific tasks, yet it remains computationally demanding and raises concerns about correctness and privacy, particularly in untrusted environments. Although parameter-efficient methods like Low-Rank Adaptation (LoRA) significantly reduce resource requirements, ensuring the security and verifiability of fine-tuning under zero-knowledge constraints remains an unresolved challenge. To address this, we introduce zkLoRA, the first framework to integrate LoRA fine-tuning with zero-knowledge proofs (ZKPs), achieving provable security and correctness. zkLoRA employs advanced cryptographic techniques -- such as lookup arguments, sumcheck protocols, and polynomial commitments -- to verify both arithmetic and non-arithmetic operations in Transformer-based architectures. The framework provides end-to-end verifiability for forward propagation, backward propagation, and parameter updates during LoRA fine-tuning, while safeguarding the privacy of model parameters and training data. Leveraging GPU-based implementations, zkLoRA demonstrates practicality and efficiency through experimental validation on open-source LLMs like LLaMA, scaling up to 13 billion parameters. By combining parameter-efficient fine-tuning with ZKPs, zkLoRA bridges a critical gap, enabling secure and trustworthy deployment of LLMs in sensitive or untrusted environments.</li>
</ul>

<h3>Title: Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Sabrina Kletz, Klaus Schoeffmann, Jenny Benois-Pineau, Heinrich Husslein</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21399">https://arxiv.org/abs/2508.21399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21399">https://arxiv.org/pdf/2508.21399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21399]] Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation(https://arxiv.org/abs/2508.21399)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recorded videos from surgeries have become an increasingly important information source for the field of medical endoscopy, since the recorded footage shows every single detail of the surgery. However, while video recording is straightforward these days, automatic content indexing - the basis for content-based search in a medical video archive - is still a great challenge due to the very special video content. In this work, we investigate segmentation and recognition of surgical instruments in videos recorded from laparoscopic gynecology. More precisely, we evaluate the achievable performance of segmenting surgical instruments from their background by using a region-based fully convolutional network for instance-aware (1) instrument segmentation as well as (2) instrument recognition. While the first part addresses only binary segmentation of instances (i.e., distinguishing between instrument or background) we also investigate multi-class instrument recognition (i.e., identifying the type of instrument). Our evaluation results show that even with a moderately low number of training examples, we are able to localize and segment instrument regions with a pretty high accuracy. However, the results also reveal that determining the particular instrument is still very challenging, due to the inherently high similarity of surgical instruments.</li>
</ul>

<h3>Title: An Empirical Study of Vulnerable Package Dependencies in LLM Repositories</h3>
<ul>
<li><strong>Authors: </strong>Shuhan Liu, Xing Hu, Xin Xia, David Lo, Xiaohu Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21417">https://arxiv.org/abs/2508.21417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21417">https://arxiv.org/pdf/2508.21417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21417]] An Empirical Study of Vulnerable Package Dependencies in LLM Repositories(https://arxiv.org/abs/2508.21417)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have developed rapidly in recent years, revolutionizing various fields. Despite their widespread success, LLMs heavily rely on external code dependencies from package management systems, creating a complex and interconnected LLM dependency supply chain. Vulnerabilities in dependencies can expose LLMs to security risks. While existing research predominantly focuses on model-level security threats, vulnerabilities within the LLM dependency supply chain have been overlooked. To fill this gap, we conducted an empirical analysis of 52 open-source LLMs, examining their third-party dependencies and associated vulnerabilities. We then explored activities within the LLM repositories to understand how maintainers manage third-party vulnerabilities in practice. Finally, we compared third-party dependency vulnerabilities in the LLM ecosystem to those in the Python ecosystem. Our results show that half of the vulnerabilities in the LLM ecosystem remain undisclosed for more than 56.2 months, significantly longer than those in the Python ecosystem. Additionally, 75.8% of LLMs include vulnerable dependencies in their configuration files. This study advances the understanding of LLM supply chain risks, provides insights for practitioners, and highlights potential directions for improving the security of the LLM supply chain.</li>
</ul>

<h3>Title: Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework</h3>
<ul>
<li><strong>Authors: </strong>Nils Dycke, Iryna Gurevych</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21422">https://arxiv.org/abs/2508.21422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21422">https://arxiv.org/pdf/2508.21422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21422]] Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework(https://arxiv.org/abs/2508.21422)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have great potential to accelerate and support scholarly peer review and are increasingly used as fully automatic review generators (ARGs). However, potential biases and systematic errors may pose significant risks to scientific integrity; understanding the specific capabilities and limitations of state-of-the-art ARGs is essential. We focus on a core reviewing skill that underpins high-quality peer review: detecting faulty research logic. This involves evaluating the internal consistency between a paper's results, interpretations, and claims. We present a fully automated counterfactual evaluation framework that isolates and tests this skill under controlled conditions. Testing a range of ARG approaches, we find that, contrary to expectation, flaws in research logic have no significant effect on their output reviews. Based on our findings, we derive three actionable recommendations for future work and release our counterfactual dataset and evaluation framework publicly.</li>
</ul>

<h3>Title: Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Meidan Ding, Jipeng Zhang, Wenxuan Wang, Cheng-Yi Li, Wei-Chieh Fang, Hsin-Yu Wu, Haiqin Zhong, Wenting Chen, Linlin Shen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21430">https://arxiv.org/abs/2508.21430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21430">https://arxiv.org/pdf/2508.21430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21430]] Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models(https://arxiv.org/abs/2508.21430)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) hold significant potential in medical applications, including disease diagnosis and clinical decision-making. However, these tasks require highly accurate, context-sensitive, and professionally aligned responses, making reliable reward models and judges critical. Despite their importance, medical reward models (MRMs) and judges remain underexplored, with no dedicated benchmarks addressing clinical requirements. Existing benchmarks focus on general MLLM capabilities or evaluate models as solvers, neglecting essential evaluation dimensions like diagnostic accuracy and clinical relevance. To address this, we introduce Med-RewardBench, the first benchmark specifically designed to evaluate MRMs and judges in medical scenarios. Med-RewardBench features a multimodal dataset spanning 13 organ systems and 8 clinical departments, with 1,026 expert-annotated cases. A rigorous three-step process ensures high-quality evaluation data across six clinically critical dimensions. We evaluate 32 state-of-the-art MLLMs, including open-source, proprietary, and medical-specific models, revealing substantial challenges in aligning outputs with expert judgment. Additionally, we develop baseline models that demonstrate substantial performance improvements through fine-tuning.</li>
</ul>

<h3>Title: RepoMark: A Code Usage Auditing Framework for Code Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wenjie Qu, Yuguang Zhou, Bo Wang, Wengrui Zheng, Yuexin Li, Jinyuan Jia, Jiaheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21432">https://arxiv.org/abs/2508.21432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21432">https://arxiv.org/pdf/2508.21432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21432]] RepoMark: A Code Usage Auditing Framework for Code Large Language Models(https://arxiv.org/abs/2508.21432)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of Large Language Models (LLMs) for code generation has transformed software development by automating coding tasks with unprecedented efficiency. However, the training of these models on open-source code repositories (e.g., from GitHub) raises critical ethical and legal concerns, particularly regarding data authorization and open-source license compliance. Developers are increasingly questioning whether model trainers have obtained proper authorization before using repositories for training, especially given the lack of transparency in data collection. To address these concerns, we propose a novel data marking framework RepoMark to audit the data usage of code LLMs. Our method enables repository owners to verify whether their code has been used in training, while ensuring semantic preservation, imperceptibility, and theoretical false detection rate (FDR) guarantees. By generating multiple semantically equivalent code variants, RepoMark introduces data marks into the code files, and during detection, RepoMark leverages a novel ranking-based hypothesis test to detect memorization within the model. Compared to prior data auditing approaches, RepoMark significantly enhances sample efficiency, allowing effective auditing even when the user's repository possesses only a small number of code files. Experiments demonstrate that RepoMark achieves a detection success rate over 90\% on small code repositories under a strict FDR guarantee of 5\%. This represents a significant advancement over existing data marking techniques, all of which only achieve accuracy below 55\% under identical settings. This further validates RepoMark as a robust, theoretically sound, and promising solution for enhancing transparency in code LLM training, which can safeguard the rights of repository owners.</li>
</ul>

<h3>Title: MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Francisco Caetano, Christiaan Viviers, Peter H.H. de With, Fons van der Sommen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21435">https://arxiv.org/abs/2508.21435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21435">https://arxiv.org/pdf/2508.21435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21435]] MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation(https://arxiv.org/abs/2508.21435)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Synthetic medical data offers a scalable solution for training robust models, but significant domain gaps limit its generalizability to real-world clinical settings. This paper addresses the challenge of cross-domain translation between synthetic and real X-ray images of the head, focusing on bridging discrepancies in attenuation behavior, noise characteristics, and soft tissue representation. We propose MedShift, a unified class-conditional generative model based on Flow Matching and Schrodinger Bridges, which enables high-fidelity, unpaired image translation across multiple domains. Unlike prior approaches that require domain-specific training or rely on paired data, MedShift learns a shared domain-agnostic latent space and supports seamless translation between any pair of domains seen during training. We introduce X-DigiSkull, a new dataset comprising aligned synthetic and real skull X-rays under varying radiation doses, to benchmark domain translation models. Experimental results demonstrate that, despite its smaller model size compared to diffusion-based approaches, MedShift offers strong performance and remains flexible at inference time, as it can be tuned to prioritize either perceptual fidelity or structural consistency, making it a scalable and generalizable solution for domain adaptation in medical imaging. The code and dataset are available at this https URL</li>
</ul>

<h3>Title: Discovering Semantic Subdimensions through Disentangled Conceptual Representations</h3>
<ul>
<li><strong>Authors: </strong>Yunhao Zhang, Shaonan Wang, Nan Lin, Xinyi Dong, Chong Li, Chengqing Zong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21436">https://arxiv.org/abs/2508.21436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21436">https://arxiv.org/pdf/2508.21436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21436]] Discovering Semantic Subdimensions through Disentangled Conceptual Representations(https://arxiv.org/abs/2508.21436)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding the core dimensions of conceptual semantics is fundamental to uncovering how meaning is organized in language and the brain. Existing approaches often rely on predefined semantic dimensions that offer only broad representations, overlooking finer conceptual distinctions. This paper proposes a novel framework to investigate the subdimensions underlying coarse-grained semantic dimensions. Specifically, we introduce a Disentangled Continuous Semantic Representation Model (DCSRM) that decomposes word embeddings from large language models into multiple sub-embeddings, each encoding specific semantic information. Using these sub-embeddings, we identify a set of interpretable semantic subdimensions. To assess their neural plausibility, we apply voxel-wise encoding models to map these subdimensions to brain activation. Our work offers more fine-grained interpretable semantic subdimensions of conceptual meaning. Further analyses reveal that semantic dimensions are structured according to distinct principles, with polarity emerging as a key factor driving their decomposition into subdimensions. The neural correlates of the identified subdimensions support their cognitive and neuroscientific plausibility.</li>
</ul>

<h3>Title: Trees as Gaussians: Large-Scale Individual Tree Mapping</h3>
<ul>
<li><strong>Authors: </strong>Dimitri Gominski, Martin Brandt, Xiaoye Tong, Siyu Liu, Maurice Mugabowindekwe, Sizhuo Li, Florian Reiner, Andrew Davies, Rasmus Fensholt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21437">https://arxiv.org/abs/2508.21437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21437">https://arxiv.org/pdf/2508.21437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21437]] Trees as Gaussians: Large-Scale Individual Tree Mapping(https://arxiv.org/abs/2508.21437)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Trees are key components of the terrestrial biosphere, playing vital roles in ecosystem function, climate regulation, and the bioeconomy. However, large-scale monitoring of individual trees remains limited by inadequate modelling. Available global products have focused on binary tree cover or canopy height, which do not explicitely identify trees at individual level. In this study, we present a deep learning approach for detecting large individual trees in 3-m resolution PlanetScope imagery at a global scale. We simulate tree crowns with Gaussian kernels of scalable size, allowing the extraction of crown centers and the generation of binary tree cover maps. Training is based on billions of points automatically extracted from airborne lidar data, enabling the model to successfully identify trees both inside and outside forests. We compare against existing tree cover maps and airborne lidar with state-of-the-art performance (fractional cover R$^2 = 0.81$ against aerial lidar), report balanced detection metrics across biomes, and demonstrate how detection can be further improved through fine-tuning with manual labels. Our method offers a scalable framework for global, high-resolution tree monitoring, and is adaptable to future satellite missions offering improved imagery.</li>
</ul>

<h3>Title: Quantum enhanced ensemble GANs for anomaly detection in continuous biomanufacturing</h3>
<ul>
<li><strong>Authors: </strong>Rajiv Kailasanathan, William R. Clements, Mohammad Reza Boskabadi, Shawn M. Gibford, Emmanouil Papadakis, Christopher J. Savoie, Seyed Soheil Mansouri</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.OT, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21438">https://arxiv.org/abs/2508.21438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21438">https://arxiv.org/pdf/2508.21438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21438]] Quantum enhanced ensemble GANs for anomaly detection in continuous biomanufacturing(https://arxiv.org/abs/2508.21438)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The development of continuous biomanufacturing processes requires robust and early anomaly detection, since even minor deviations can compromise yield and stability, leading to disruptions in scheduling, reduced weekly production, and diminished economic performance. These processes are inherently complex and exhibit non-linear dynamics with intricate relationships between process variables, thus making advanced methods for anomaly detection essential for efficient operation. In this work, we present a novel framework for unsupervised anomaly detection in continuous biomanufacturing based on an ensemble of generative adversarial networks (GANs). We first establish a benchmark dataset simulating both normal and anomalous operation regimes in a continuous process for the production of a small molecule. We then demonstrate the effectiveness of our GAN-based framework in detecting anomalies caused by sudden feedstock variability. Finally, we evaluate the impact of using a hybrid quantum/classical GAN approach with both a simulated quantum circuit and a real photonic quantum processor on anomaly detection performance. We find that the hybrid approach yields improved anomaly detection rates. Our work shows the potential of hybrid quantum/classical approaches for solving real-world problems in complex continuous biomanufacturing processes.</li>
</ul>

<h3>Title: Time Tells All: Deanonymization of Blockchain RPC Users with Zero Transaction Fee (Extended Version)</h3>
<ul>
<li><strong>Authors: </strong>Shan Wang, Ming Yang, Yu Liu, Yue Zhang, Shuaiqing Zhang, Zhen Ling, Jiannong Cao, Xinwen Fu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21440">https://arxiv.org/abs/2508.21440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21440">https://arxiv.org/pdf/2508.21440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21440]] Time Tells All: Deanonymization of Blockchain RPC Users with Zero Transaction Fee (Extended Version)(https://arxiv.org/abs/2508.21440)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>Remote Procedure Call (RPC) services have become a primary gateway for users to access public blockchains. While they offer significant convenience, RPC services also introduce critical privacy challenges that remain insufficiently examined. Existing deanonymization attacks either do not apply to blockchain RPC users or incur costs like transaction fees assuming an active network eavesdropper. In this paper, we propose a novel deanonymization attack that can link an IP address of a RPC user to this user's blockchain pseudonym. Our analysis reveals a temporal correlation between the timestamps of transaction confirmations recorded on the public ledger and those of TCP packets sent by the victim when querying transaction status. We assume a strong passive adversary with access to network infrastructure, capable of monitoring traffic at network border routers or Internet exchange points. By monitoring network traffic and analyzing public ledgers, the attacker can link the IP address of the TCP packet to the pseudonym of the transaction initiator by exploiting the temporal correlation. This deanonymization attack incurs zero transaction fee. We mathematically model and analyze the attack method, perform large-scale measurements of blockchain ledgers, and conduct real-world attacks to validate the attack. Our attack achieves a high success rate of over 95% against normal RPC users on various blockchain networks, including Ethereum, Bitcoin and Solana.</li>
</ul>

<h3>Title: Beyond the Surface: Probing the Ideological Depth of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shariar Kabir, Kevin Esterling, Yue Dong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21448">https://arxiv.org/abs/2508.21448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21448">https://arxiv.org/pdf/2508.21448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21448]] Beyond the Surface: Probing the Ideological Depth of Large Language Models(https://arxiv.org/abs/2508.21448)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated pronounced ideological leanings, yet the stability and depth of these positions remain poorly understood. Surface-level responses can often be manipulated through simple prompt engineering, calling into question whether they reflect a coherent underlying ideology. This paper investigates the concept of "ideological depth" in LLMs, defined as the robustness and complexity of their internal political representations. We employ a dual approach: first, we measure the "steerability" of two well-known open-source LLMs using instruction prompting and activation steering. We find that while some models can easily switch between liberal and conservative viewpoints, others exhibit resistance or an increased rate of refusal, suggesting a more entrenched ideological structure. Second, we probe the internal mechanisms of these models using Sparse Autoencoders (SAEs). Preliminary analysis reveals that models with lower steerability possess more distinct and abstract ideological features. Our evaluations reveal that one model can contain 7.3x more political features than another model of similar size. This allows targeted ablation of a core political feature in an ideologically "deep" model, leading to consistent, logical shifts in its reasoning across related topics, whereas the same intervention in a "shallow" model results in an increase in refusal outputs. Our findings suggest that ideological depth is a quantifiable property of LLMs and that steerability serves as a valuable window into their latent political architecture.</li>
</ul>

<h3>Title: One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist</h3>
<ul>
<li><strong>Authors: </strong>Junha Song, Yongsik Jo, So Yeon Min, Quanting Xie, Taehwan Kim, Yonatan Bisk, Jaegul Choo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21451">https://arxiv.org/abs/2508.21451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21451">https://arxiv.org/pdf/2508.21451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21451]] One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist(https://arxiv.org/abs/2508.21451)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Image captioning is fundamental for applications like video instruction systems and exploration robots, yet deploying such models on local devices is challenging due to the high computational demands of multimodal large language models (MLLMs). To address this, we first explore lightweight captioning by implementing a specialist based on a 125M-parameter language model, 56 times smaller than LLaMA-7B, and evaluating its performance on both single-sentence and detailed captioning tasks. Surprisingly, we find that our model can achieve performance comparable to large multimodal generalists, suggesting its potential to serve as a strong visual specialist for on-device applications. While promising, our model also exhibits a limitation: like other MLLMs, it suffers from visual blindness, occasionally resulting in semantic captioning errors. We carry out toy experiments and investigate the underlying causes, where we observe that the problems arise from ineffective attention mechanisms and limited visual representations. To alleviate them, we develop a novel captioning framework, Sharp-Eyed Refinement, which enhances caption quality through improved visual grounding. At its core, our DeepLens extracts detailed visual representations by concentrating on informative regions identified during the initial glance. Our experiments confirm both the advantages of our specialist over prior small captioning models and large generalists and the effectiveness of our framework.</li>
</ul>

<h3>Title: SoK: Large Language Model-Generated Textual Phishing Campaigns End-to-End Analysis of Generation, Characteristics, and Detection</h3>
<ul>
<li><strong>Authors: </strong>Fengchao Chen, Tingmin Wu, Van Nguyen, Carsten Rudolph</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21457">https://arxiv.org/abs/2508.21457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21457">https://arxiv.org/pdf/2508.21457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21457]] SoK: Large Language Model-Generated Textual Phishing Campaigns End-to-End Analysis of Generation, Characteristics, and Detection(https://arxiv.org/abs/2508.21457)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Phishing is a pervasive form of social engineering in which attackers impersonate trusted entities to steal information or induce harmful actions. Text-based phishing dominates for its low cost, scalability, and concealability, advantages recently amplified by large language models (LLMs) that enable ``Phishing-as-a-Service'' attacks at scale within minutes. Despite the growing research into LLM-facilitated phishing attacks, consolidated systematic research on the phishing attack life cycle remains scarce. In this work, we present the first systematization of knowledge (SoK) on LLM-generated phishing, offering an end-to-end analysis that spans generation techniques, attack features, and mitigation strategies. We introduce Generation-Characterization-Defense (GenCharDef), which systematizes the ways in which LLM-generated phishing differs from traditional phishing across methodologies, security perspectives, data dependencies, and evaluation practices. This framework highlights unique challenges of LLM-driven phishing, providing a coherent foundation for understanding the evolving threat landscape and guiding the design of more resilient defenses.</li>
</ul>

<h3>Title: Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification</h3>
<ul>
<li><strong>Authors: </strong>Kaouther Mouheb, Marawan Elbatel, Janne Papma, Geert Jan Biessels, Jurgen Claassen, Huub Middelkoop, Barbara van Munster, Wiesje van der Flier, Inez Ramakers, Stefan Klein, Esther E. Bron</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21458">https://arxiv.org/abs/2508.21458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21458">https://arxiv.org/pdf/2508.21458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21458]] Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification(https://arxiv.org/abs/2508.21458)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>While foundation models (FMs) offer strong potential for AI-based dementia diagnosis, their integration into federated learning (FL) systems remains underexplored. In this benchmarking study, we systematically evaluate the impact of key design choices: classification head architecture, fine-tuning strategy, and aggregation method, on the performance and efficiency of federated FM tuning using brain MRI data. Using a large multi-cohort dataset, we find that the architecture of the classification head substantially influences performance, freezing the FM encoder achieves comparable results to full fine-tuning, and advanced aggregation methods outperform standard federated averaging. Our results offer practical insights for deploying FMs in decentralized clinical settings and highlight trade-offs that should guide future method development.</li>
</ul>

<h3>Title: Multi-Method Ensemble for Out-of-Distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Lucas Rakotoarivony</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21463">https://arxiv.org/abs/2508.21463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21463">https://arxiv.org/pdf/2508.21463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21463]] Multi-Method Ensemble for Out-of-Distribution Detection(https://arxiv.org/abs/2508.21463)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Detecting out-of-distribution (OOD) samples is essential for neural networks operating in open-world settings, particularly in safety-critical applications. Existing methods have improved OOD detection by leveraging two main techniques: feature truncation, which increases the separation between in-distribution (ID) and OOD samples, and scoring functions, which assign scores to distinguish between ID and OOD data. However, most approaches either focus on a single family of techniques or evaluate their effectiveness on a specific type of OOD dataset, overlooking the potential of combining multiple existing solutions. Motivated by this observation, we theoretically and empirically demonstrate that state-of-the-art feature truncation and scoring functions can be effectively combined. Moreover, we show that aggregating multiple scoring functions enhances robustness against various types of OOD samples. Based on these insights, we propose the Multi-Method Ensemble (MME) score, which unifies state-of-the-art OOD detectors into a single, more effective scoring function. Extensive experiments on both large-scale and small-scale benchmarks, covering near-OOD and far-OOD scenarios, show that MME significantly outperforms recent state-of-the-art methods across all benchmarks. Notably, using the BiT model, our method achieves an average FPR95 of 27.57% on the challenging ImageNet-1K benchmark, improving performance by 6% over the best existing baseline.</li>
</ul>

<h3>Title: Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration</h3>
<ul>
<li><strong>Authors: </strong>Seungyeon Choi, Hwanhee Kim, Chihyun Park, Dahyeon Lee, Seungyong Lee, Yoonju Kim, Hyoungjoon Park, Sein Kwon, Youngwan Jo, Sanghyun Park</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21468">https://arxiv.org/abs/2508.21468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21468">https://arxiv.org/pdf/2508.21468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21468]] Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration(https://arxiv.org/abs/2508.21468)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in Structure-based Drug Design (SBDD) have leveraged generative models for 3D molecular generation, predominantly evaluating model performance by binding affinity to target proteins. However, practical drug discovery necessitates high binding affinity along with synthetic feasibility and selectivity, critical properties that were largely neglected in previous evaluations. To address this gap, we identify fundamental limitations of conventional diffusion-based generative models in effectively guiding molecule generation toward these diverse pharmacological properties. We propose CByG, a novel framework extending Bayesian Flow Network into a gradient-based conditional generative model that robustly integrates property-specific guidance. Additionally, we introduce a comprehensive evaluation scheme incorporating practical benchmarks for binding affinity, synthetic feasibility, and selectivity, overcoming the limitations of conventional evaluation methods. Extensive experiments demonstrate that our proposed CByG framework significantly outperforms baseline models across multiple essential evaluation criteria, highlighting its effectiveness and practicality for real-world drug discovery applications.</li>
</ul>

<h3>Title: Adversarial Patch Attack for Ship Detection via Localized Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Chun Liu, Panpan Ding, Zheng Zheng, Hailong Wang, Bingqian Zhu, Tao Xu, Zhigang Han, Jiayao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21472">https://arxiv.org/abs/2508.21472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21472">https://arxiv.org/pdf/2508.21472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21472]] Adversarial Patch Attack for Ship Detection via Localized Augmentation(https://arxiv.org/abs/2508.21472)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Current ship detection techniques based on remote sensing imagery primarily rely on the object detection capabilities of deep neural networks (DNNs). However, DNNs are vulnerable to adversarial patch attacks, which can lead to misclassification by the detection model or complete evasion of the targets. Numerous studies have demonstrated that data transformation-based methods can improve the transferability of adversarial examples. However, excessive augmentation of image backgrounds or irrelevant regions may introduce unnecessary interference, resulting in false detections of the object detection model. These errors are not caused by the adversarial patches themselves but rather by the over-augmentation of background and non-target areas. This paper proposes a localized augmentation method that applies augmentation only to the target regions, avoiding any influence on non-target areas. By reducing background interference, this approach enables the loss function to focus more directly on the impact of the adversarial patch on the detection model, thereby improving the attack success rate. Experiments conducted on the HRSC2016 dataset demonstrate that the proposed method effectively increases the success rate of adversarial patch attacks and enhances their transferability.</li>
</ul>

<h3>Title: Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards</h3>
<ul>
<li><strong>Authors: </strong>Xiaolong Wei, Bo Lu, Xingyu Zhang, Zhejun Zhao, Dongdong Shen, Long Xia, Dawei Yin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21476">https://arxiv.org/abs/2508.21476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21476">https://arxiv.org/pdf/2508.21476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21476]] Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards(https://arxiv.org/abs/2508.21476)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable creative writing capabilities, yet their substantial computational demands hinder widespread use. Enhancing Small Language Models (SLMs) offers a promising alternative, but current methods like Supervised Fine-Tuning (SFT) struggle with novelty, and Reinforcement Learning from Human Feedback (RLHF) is costly. This paper explores two distinct AI-driven reward strategies within a Reinforcement Learning from AI Feedback (RLAIF) framework to ignite the creative writing of a 7B-parameter SLM, specifically for generating Chinese greetings. The first strategy employs a RM trained on high-quality preference data curated by a novel multi-agent rejection sampling framework designed for creative tasks. The second, more novel strategy utilizes a principle-guided LLM-as-a-Judge, whose reward function is optimized via an adversarial training scheme with a reflection mechanism, to directly provide reward signals. Comprehensive experiments reveal that while both approaches significantly enhance creative output over baselines, the principle-guided LLM-as-a-Judge demonstrably yields superior generation quality. Furthermore, it offers notable advantages in training efficiency and reduced dependency on human-annotated data, presenting a more scalable and effective path towards creative SLMs. Our automated evaluation methods also exhibit strong alignment with human judgments. Our code and data are publicly available at this https URL.</li>
</ul>

<h3>Title: Towards a Decentralized IoT Onboarding for Smart Homes Using Consortium Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Narges Dadkhah, Khan Reaz, Gerhard Wunder</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21480">https://arxiv.org/abs/2508.21480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21480">https://arxiv.org/pdf/2508.21480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21480]] Towards a Decentralized IoT Onboarding for Smart Homes Using Consortium Blockchain(https://arxiv.org/abs/2508.21480)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The increasing adoption of smart home devices and IoT-based security systems presents significant opportunities to enhance convenience, safety, and risk management for homeowners and service providers. However, secure onboarding-provisioning credentials and establishing trust with cloud platforms-remains a considerable challenge. Traditional onboarding methods often rely on centralized Public Key Infrastructure (PKI) models and manufacturer-controlled keys, which introduce security risks and limit the user's digital sovereignty. These limitations hinder the widespread deployment of scalable IoT solutions. This paper presents a novel onboarding framework that builds upon existing network-layer onboarding techniques and extends them to the application layer to address these challenges. By integrating consortium blockchain technology, we propose a decentralized onboarding mechanism that enhances transparency, security, and monitoring for smart home architectures. The architecture supports device registration, key revocation, access control management, and risk detection through event-driven alerts across dedicated blockchain channels and smart contracts. To evaluate the framework, we formally model the protocol using the Tamarin Prover under the Dolev-Yao adversary model. The analysis focuses on authentication, token integrity, key confidentiality, and resilience over public channels. A prototype implementation demonstrates the system's viability in smart home settings, with verification completing in 0.34 seconds, highlighting its scalability and suitability for constrained devices and diverse stakeholders. Additionally, performance evaluation shows that the blockchain-based approach effectively handles varying workloads, maintains high throughput and low latency, and supports near real-time IoT data processing.</li>
</ul>

<h3>Title: HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble</h3>
<ul>
<li><strong>Authors: </strong>Sara B. Coutinho, Rafael M.O. Cruz, Francimaria R. S. Nascimento, George D. C. Cavalcanti</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21482">https://arxiv.org/abs/2508.21482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21482">https://arxiv.org/pdf/2508.21482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21482]] HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble(https://arxiv.org/abs/2508.21482)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Psychological biases, such as confirmation bias, make individuals particularly vulnerable to believing and spreading fake news on social media, leading to significant consequences in domains such as public health and politics. Machine learning-based fact-checking systems have been widely studied to mitigate this problem. Among them, ensemble methods are particularly effective in combining multiple classifiers to improve robustness. However, their performance heavily depends on the diversity of the constituent classifiers-selecting genuinely diverse models remains a key challenge, especially when models tend to learn redundant patterns. In this work, we propose a novel automatic classifier selection approach that prioritizes diversity, also extended by performance. The method first computes pairwise diversity between classifiers and applies hierarchical clustering to organize them into groups at different levels of granularity. A HierarchySelect then explores these hierarchical levels to select one pool of classifiers per level, each representing a distinct intra-pool diversity. The most diverse pool is identified and selected for ensemble construction from these. The selection process incorporates an evaluation metric reflecting each classifiers's performance to ensure the ensemble also generalises well. We conduct experiments with 40 heterogeneous classifiers across six datasets from different application domains and with varying numbers of classes. Our method is compared against the Elbow heuristic and state-of-the-art baselines. Results show that our approach achieves the highest accuracy on two of six datasets. The implementation details are available on the project's repository: this https URL .</li>
</ul>

<h3>Title: Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning</h3>
<ul>
<li><strong>Authors: </strong>Pascal R. van der Vaart, Neil Yorke-Smith, Matthijs T.J. Spaan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21488">https://arxiv.org/abs/2508.21488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21488">https://arxiv.org/pdf/2508.21488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21488]] Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning(https://arxiv.org/abs/2508.21488)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Uncertainty quantification in reinforcement learning can greatly improve exploration and robustness. Approximate Bayesian approaches have recently been popularized to quantify uncertainty in model-free algorithms. However, so far the focus has been on improving the accuracy of the posterior approximation, instead of studying the accuracy of the prior and likelihood assumptions underlying the posterior. In this work, we demonstrate that there is a cold posterior effect in Bayesian deep Q-learning, where contrary to theory, performance increases when reducing the temperature of the posterior. To identify and overcome likely causes, we challenge common assumptions made on the likelihood and priors in Bayesian model-free algorithms. We empirically study prior distributions and show through statistical tests that the common Gaussian likelihood assumption is frequently violated. We argue that developing more suitable likelihoods and priors should be a key focus in future Bayesian reinforcement learning research and we offer simple, implementable solutions for better priors in deep Q-learning that lead to more performant Bayesian algorithms.</li>
</ul>

<h3>Title: ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Hao Lu, Jiahao Wang, Yaolun Zhang, Ruohui Wang, Xuanyu Zheng, Yepeng Tang, Dahua Lin, Lewei Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21496">https://arxiv.org/abs/2508.21496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21496">https://arxiv.org/pdf/2508.21496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21496]] ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding(https://arxiv.org/abs/2508.21496)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Video multimodal large language models (Video-MLLMs) have achieved remarkable progress in video understanding. However, they remain vulnerable to hallucination-producing content inconsistent with or unrelated to video inputs. Previous video hallucination benchmarks primarily focus on short-videos. They attribute hallucinations to factors such as strong language priors, missing frames, or vision-language biases introduced by the visual encoder. While these causes indeed account for most hallucinations in short videos, they still oversimplify the cause of hallucinations. Sometimes, models generate incorrect outputs but with correct frame-level semantics. We refer to this type of hallucination as Semantic Aggregation Hallucination (SAH), which arises during the process of aggregating frame-level semantics into event-level semantic groups. Given that SAH becomes particularly critical in long videos due to increased semantic complexity across multiple events, it is essential to separate and thoroughly investigate the causes of this type of hallucination. To address the above issues, we introduce ELV-Halluc, the first benchmark dedicated to long-video hallucination, enabling a systematic investigation of SAH. Our experiments confirm the existence of SAH and show that it increases with semantic complexity. Additionally, we find that models are more prone to SAH on rapidly changing semantics. Moreover, we discuss potential approaches to mitigate SAH. We demonstrate that positional encoding strategy contributes to alleviating SAH, and further adopt DPO strategy to enhance the model's ability to distinguish semantics within and across events. To support this, we curate a dataset of 8K adversarial data pairs and achieve improvements on both ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.</li>
</ul>

<h3>Title: Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control</h3>
<ul>
<li><strong>Authors: </strong>Vishal Pandey, Debasmita Biswas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21505">https://arxiv.org/abs/2508.21505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21505">https://arxiv.org/pdf/2508.21505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21505]] Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control(https://arxiv.org/abs/2508.21505)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Reinforcement learning agents based on Transformer architectures have achieved impressive performance on sequential decision-making tasks, but their reliance on dense matrix operations makes them ill-suited for energy-constrained, edge-oriented platforms. Spiking neural networks promise ultra-low-power, event-driven inference, yet no prior work has seamlessly merged spiking dynamics with return-conditioned sequence modeling. We present the Spiking Decision Transformer (SNN-DT), which embeds Leaky Integrate-and-Fire neurons into each self-attention block, trains end-to-end via surrogate gradients, and incorporates biologically inspired three-factor plasticity, phase-shifted spike-based positional encodings, and a lightweight dendritic routing module. Our implementation matches or exceeds standard Decision Transformer performance on classic control benchmarks (CartPole-v1, MountainCar-v0, Acrobot-v1, Pendulum-v1) while emitting fewer than ten spikes per decision, an energy proxy suggesting over four orders-of-magnitude reduction in per inference energy. By marrying sequence modeling with neuromorphic efficiency, SNN-DT opens a pathway toward real-time, low-power control on embedded and wearable devices.</li>
</ul>

<h3>Title: Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches</h3>
<ul>
<li><strong>Authors: </strong>Israel Abebe Azime, Deborah D. Kanubala, Tejumade Afonja, Mario Fritz, Isabel Valera, Dietrich Klakow, Philipp Slusallek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21512">https://arxiv.org/abs/2508.21512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21512">https://arxiv.org/pdf/2508.21512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21512]] Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches(https://arxiv.org/abs/2508.21512)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly employed in high-stakes decision-making tasks, such as loan approvals. While their applications expand across domains, LLMs struggle to process tabular data, ensuring fairness and delivering reliable predictions. In this work, we assess the performance and fairness of LLMs on serialized loan approval datasets from three geographically distinct regions: Ghana, Germany, and the United States. Our evaluation focuses on the model's zero-shot and in-context learning (ICL) capabilities. Our results reveal that the choice of serialization (Serialization refers to the process of converting tabular data into text formats suitable for processing by LLMs.) format significantly affects both performance and fairness in LLMs, with certain formats such as GReat and LIFT yielding higher F1 scores but exacerbating fairness disparities. Notably, while ICL improved model performance by 4.9-59.6% relative to zero-shot baselines, its effect on fairness varied considerably across datasets. Our work underscores the importance of effective tabular data representation methods and fairness-aware models to improve the reliability of LLMs in financial decision-making.</li>
</ul>

<h3>Title: Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ronan Docherty, Antonis Vamvakeros, Samuel J. Cooper</a></li>
<li><strong>Subjects: </strong>cs.CV, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21529">https://arxiv.org/abs/2508.21529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21529">https://arxiv.org/pdf/2508.21529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21529]] Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation(https://arxiv.org/abs/2508.21529)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Feature foundation models - usually vision transformers - offer rich semantic descriptors of images, useful for downstream tasks such as (interactive) segmentation and object detection. For computational efficiency these descriptors are often patch-based, and so struggle to represent the fine features often present in micrographs; they also struggle with the large image sizes present in materials and biological image analysis. In this work, we train a convolutional neural network to upsample low-resolution (i.e, large patch size) foundation model features with reference to the input image. We apply this upsampler network (without any further training) to efficiently featurise and then segment a variety of microscopy images, including plant cells, a lithium-ion battery cathode and organic crystals. The richness of these upsampled features admits separation of hard to segment phases, like hairline cracks. We demonstrate that interactive segmentation with these deep features produces high-quality segmentations far faster and with far fewer labels than training or finetuning a more traditional convolutional network.</li>
</ul>

<h3>Title: HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones</h3>
<ul>
<li><strong>Authors: </strong>Hao Ruan, Jinliang Lin, Yingxin Lai, Zhiming Luo, Shaozi Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21539">https://arxiv.org/abs/2508.21539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21539">https://arxiv.org/pdf/2508.21539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21539]] HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones(https://arxiv.org/abs/2508.21539)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Natural Language-Guided Drones (NLGD) provide a novel paradigm for tasks such as target matching and navigation. However, the wide field of view and complex compositional semantics in drone scenarios pose challenges for vision-language understanding. Mainstream Vision-Language Models (VLMs) emphasize global alignment while lacking fine-grained semantics, and existing hierarchical methods depend on precise entity partitioning and strict containment, limiting effectiveness in dynamic environments. To address this, we propose the Hierarchical Cross-Granularity Contrastive and Matching learning (HCCM) framework with two components: (1) Region-Global Image-Text Contrastive Learning (RG-ITC), which avoids precise scene partitioning and captures hierarchical local-to-global semantics by contrasting local visual regions with global text and vice versa; (2) Region-Global Image-Text Matching (RG-ITM), which dispenses with rigid constraints and instead evaluates local semantic consistency within global cross-modal representations, enhancing compositional reasoning. Moreover, drone text descriptions are often incomplete or ambiguous, destabilizing alignment. HCCM introduces a Momentum Contrast and Distillation (MCD) mechanism to improve robustness. Experiments on GeoText-1652 show HCCM achieves state-of-the-art Recall@1 of 28.8% (image retrieval) and 14.7% (text retrieval). On the unseen ERA dataset, HCCM demonstrates strong zero-shot generalization with 39.93% mean recall (mR), outperforming fine-tuned baselines.</li>
</ul>

<h3>Title: Complete Gaussian Splats from a Single Image with Denoising Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Ziwei Liao, Mohamed Sayed, Steven L. Waslander, Sara Vicente, Daniyar Turmukhambetov, Michael Firman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21542">https://arxiv.org/abs/2508.21542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21542">https://arxiv.org/pdf/2508.21542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21542]] Complete Gaussian Splats from a Single Image with Denoising Diffusion Models(https://arxiv.org/abs/2508.21542)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Gaussian splatting typically requires dense observations of the scene and can fail to reconstruct occluded and unobserved areas. We propose a latent diffusion model to reconstruct a complete 3D scene with Gaussian splats, including the occluded parts, from only a single image during inference. Completing the unobserved surfaces of a scene is challenging due to the ambiguity of the plausible surfaces. Conventional methods use a regression-based formulation to predict a single "mode" for occluded and out-of-frustum surfaces, leading to blurriness, implausibility, and failure to capture multiple possible explanations. Thus, they often address this problem partially, focusing either on objects isolated from the background, reconstructing only visible surfaces, or failing to extrapolate far from the input views. In contrast, we propose a generative formulation to learn a distribution of 3D representations of Gaussian splats conditioned on a single input image. To address the lack of ground-truth training data, we propose a Variational AutoReconstructor to learn a latent space only from 2D images in a self-supervised manner, over which a diffusion model is trained. Our method generates faithful reconstructions and diverse samples with the ability to complete the occluded surfaces for high-quality 360-degree renderings.</li>
</ul>

<h3>Title: Comprehensive Signal Quality Evaluation of a Wearable Textile ECG Garment: A Sex-Balanced Study</h3>
<ul>
<li><strong>Authors: </strong>Maximilian P. Oppelt, Tobias S. Zech, Sarah H. Lorenz, Laurenz Ottmann, Jan Steffan, Bjoern M. Eskofier, Nadine R. Lang-Richter, Norman Pfeiffer</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21554">https://arxiv.org/abs/2508.21554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21554">https://arxiv.org/pdf/2508.21554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21554]] Comprehensive Signal Quality Evaluation of a Wearable Textile ECG Garment: A Sex-Balanced Study(https://arxiv.org/abs/2508.21554)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce a novel wearable textile-garment featuring an innovative electrode placement aimed at minimizing noise and motion artifacts, thereby enhancing signal fidelity in Electrocardiography (ECG) recordings. We present a comprehensive, sex-balanced evaluation involving 15 healthy males and 15 healthy female participants to ensure the device's suitability across anatomical and physiological variations. The assessment framework encompasses distinct evaluation approaches: quantitative signal quality indices to objectively benchmark device performance; rhythm-based analyzes of physiological parameters such as heart rate and heart rate variability; machine learning classification tasks to assess application-relevant predictive utility; morphological analysis of ECG features including amplitude and interval parameters; and investigations of the effects of electrode projection angle given by the textile / body shape, with all analyzes stratified by sex to elucidate sex-specific influences. Evaluations were conducted across various activity phases representing real-world conditions. The results demonstrate that the textile system achieves signal quality highly concordant with reference devices in both rhythm and morphological analyses, exhibits robust classification performance, and enables identification of key sex-specific determinants affecting signal acquisition. These findings underscore the practical viability of textile-based ECG garments for physiological monitoring as well as psychophysiological state detection. Moreover, we identify the importance of incorporating sex-specific design considerations to ensure equitable and reliable cardiac diagnostics in wearable health technologies.</li>
</ul>

<h3>Title: ECHO: Ego-Centric modeling of Human-Object interactions</h3>
<ul>
<li><strong>Authors: </strong>Ilya A. Petrov, Vladimir Guzov, Riccardo Marin, Emre Aksan, Xu Chen, Daniel Cremers, Thabo Beeler, Gerard Pons-Moll</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21556">https://arxiv.org/abs/2508.21556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21556">https://arxiv.org/pdf/2508.21556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21556]] ECHO: Ego-Centric modeling of Human-Object interactions(https://arxiv.org/abs/2508.21556)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Modeling human-object interactions (HOI) from an egocentric perspective is a largely unexplored yet important problem due to the increasing adoption of wearable devices, such as smart glasses and watches. We investigate how much information about interaction can be recovered from only head and wrists tracking. Our answer is ECHO (Ego-Centric modeling of Human-Object interactions), which, for the first time, proposes a unified framework to recover three modalities: human pose, object motion, and contact from such minimal observation. ECHO employs a Diffusion Transformer architecture and a unique three-variate diffusion process, which jointly models human motion, object trajectory, and contact sequence, allowing for flexible input configurations. Our method operates in a head-centric canonical space, enhancing robustness to global orientation. We propose a conveyor-based inference, which progressively increases the diffusion timestamp with the frame position, allowing us to process sequences of any length. Through extensive evaluation, we demonstrate that ECHO outperforms existing methods that do not offer the same flexibility, setting a state-of-the-art in egocentric HOI reconstruction.</li>
</ul>

<h3>Title: Generalized Encrypted Traffic Classification Using Inter-Flow Signals</h3>
<ul>
<li><strong>Authors: </strong>Federica Bianchi, Edoardo Di Paolo, Angelo Spognardi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21558">https://arxiv.org/abs/2508.21558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21558">https://arxiv.org/pdf/2508.21558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21558]] Generalized Encrypted Traffic Classification Using Inter-Flow Signals(https://arxiv.org/abs/2508.21558)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present a novel encrypted traffic classification model that operates directly on raw PCAP data without requiring prior assumptions about traffic type. Unlike existing methods, it is generalizable across multiple classification tasks and leverages inter-flow signals - an innovative representation that captures temporal correlations and packet volume distributions across flows. Experimental results show that our model outperforms well-established methods in nearly every classification task and across most datasets, achieving up to 99% accuracy in some cases, demonstrating its robustness and adaptability.</li>
</ul>

<h3>Title: Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification</h3>
<ul>
<li><strong>Authors: </strong>Yifei Yuan, Jiatong Li, Weijia Zhang, Mohammad Aliannejadi, Evangelos Kanoulas, Renjun Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21561">https://arxiv.org/abs/2508.21561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21561">https://arxiv.org/pdf/2508.21561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21561]] Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification(https://arxiv.org/abs/2508.21561)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent studies show the promise of large language models (LLMs) for few-shot tabular classification but highlight challenges due to the variability in structured data. To address this, we propose distilling data into actionable insights to enable robust and effective classification by LLMs. Drawing inspiration from human learning processes, we introduce InsightTab, an insight distillation framework guided by principles of divide-and-conquer, easy-first, and reflective learning. Our approach integrates rule summarization, strategic exemplification, and insight reflection through deep collaboration between LLMs and data modeling techniques. The obtained insights enable LLMs to better align their general knowledge and capabilities with the particular requirements of specific tabular tasks. We extensively evaluate InsightTab on nine datasets. The results demonstrate consistent improvement over state-of-the-art methods. Ablation studies further validate the principle-guided distillation process, while analyses emphasize InsightTab's effectiveness in leveraging labeled data and managing bias.</li>
</ul>

<h3>Title: How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images</h3>
<ul>
<li><strong>Authors: </strong>Juneyoung Ro, Namwoo Kim, Yoonjin Yoon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21565">https://arxiv.org/abs/2508.21565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21565">https://arxiv.org/pdf/2508.21565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21565]] How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images(https://arxiv.org/abs/2508.21565)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Effectively understanding urban scenes requires fine-grained spatial reasoning about objects, layouts, and depth cues. However, how well current vision-language models (VLMs), pretrained on general scenes, transfer these abilities to urban domain remains underexplored. To address this gap, we conduct a comparative study of three off-the-shelf VLMs-BLIP-2, InstructBLIP, and LLaVA-1.5-evaluating both zero-shot performance and the effects of fine-tuning with a synthetic VQA dataset specific to urban scenes. We construct such dataset from segmentation, depth, and object detection predictions of street-view images, pairing each question with LLM-generated Chain-of-Thought (CoT) answers for step-by-step reasoning supervision. Results show that while VLMs perform reasonably well in zero-shot settings, fine-tuning with our synthetic CoT-supervised dataset substantially boosts performance, especially for challenging question types such as negation and counterfactuals. This study introduces urban spatial reasoning as a new challenge for VLMs and demonstrates synthetic dataset construction as a practical path for adapting general-purpose models to specialized domains.</li>
</ul>

<h3>Title: OASIS: Harnessing Diffusion Adversarial Network for Ocean Salinity Imputation using Sparse Drifter Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Bo Li, Yingqi Feng, Ming Jin, Xin Zheng, Yufei Tang, Laurent Cherubin, Alan Wee-Chung Liew, Can Wang, Qinghua Lu, Jingwei Yao, Shirui Pan, Hong Zhang, Xingquan Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21570">https://arxiv.org/abs/2508.21570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21570">https://arxiv.org/pdf/2508.21570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21570]] OASIS: Harnessing Diffusion Adversarial Network for Ocean Salinity Imputation using Sparse Drifter Trajectories(https://arxiv.org/abs/2508.21570)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Ocean salinity plays a vital role in circulation, climate, and marine ecosystems, yet its measurement is often sparse, irregular, and noisy, especially in drifter-based datasets. Traditional approaches, such as remote sensing and optimal interpolation, rely on linearity and stationarity, and are limited by cloud cover, sensor drift, and low satellite revisit rates. While machine learning models offer flexibility, they often fail under severe sparsity and lack principled ways to incorporate physical covariates without specialized sensors. In this paper, we introduce the OceAn Salinity Imputation System (OASIS), a novel diffusion adversarial framework designed to address these challenges.</li>
</ul>

<h3>Title: Agentic Discovery and Validation of Android App Vulnerabilities</h3>
<ul>
<li><strong>Authors: </strong>Ziyue Wang, Liyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21579">https://arxiv.org/abs/2508.21579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21579">https://arxiv.org/pdf/2508.21579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21579]] Agentic Discovery and Validation of Android App Vulnerabilities(https://arxiv.org/abs/2508.21579)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Existing Android vulnerability detection tools overwhelm teams with thousands of low-signal warnings yet uncover few true positives. Analysts spend days triaging these results, creating a bottleneck in the security pipeline. Meanwhile, genuinely exploitable vulnerabilities often slip through, leaving opportunities open to malicious counterparts. We introduce A2, a system that mirrors how security experts analyze and validate Android vulnerabilities through two complementary phases: (i) Agentic Vulnerability Discovery, which reasons about application security by combining semantic understanding with traditional security tools; and (ii) Agentic Vulnerability Validation, which systematically validates vulnerabilities across Android's multi-modal attack surface-UI interactions, inter-component communication, file system operations, and cryptographic computations. On the Ghera benchmark (n=60), A2 achieves 78.3% coverage, surpassing state-of-the-art analyzers (e.g., APKHunt 30.0%). Rather than overwhelming analysts with thousands of warnings, A2 distills results into 82 speculative vulnerability findings, including 47 Ghera cases and 28 additional true positives. Crucially, A2 then generates working Proof-of-Concepts (PoCs) for 51 of these speculative findings, transforming them into validated vulnerability findings that provide direct, self-confirming evidence of exploitability. In real-world evaluation on 169 production APKs, A2 uncovers 104 true-positive zero-day vulnerabilities. Among these, 57 (54.8%) are self-validated with automatically generated PoCs, including a medium-severity vulnerability in a widely used application with over 10 million installs.</li>
</ul>

<h3>Title: Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Nico Albert Disch, Yannick Kirchhoff, Robin Peretzke, Maximilian Rokuss, Saikat Roy, Constantin Ulrich, David Zimmerer, Klaus Maier-Hein</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21580">https://arxiv.org/abs/2508.21580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21580">https://arxiv.org/pdf/2508.21580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21580]] Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging(https://arxiv.org/abs/2508.21580)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Understanding temporal dynamics in medical imaging is crucial for applications such as disease progression modeling, treatment planning and anatomical development tracking. However, most deep learning methods either consider only single temporal contexts, or focus on tasks like classification or regression, limiting their ability for fine-grained spatial predictions. While some approaches have been explored, they are often limited to single timepoints, specific diseases or have other technical restrictions. To address this fundamental gap, we introduce Temporal Flow Matching (TFM), a unified generative trajectory method that (i) aims to learn the underlying temporal distribution, (ii) by design can fall back to a nearest image predictor, i.e. predicting the last context image (LCI), as a special case, and (iii) supports $3D$ volumes, multiple prior scans, and irregular sampling. Extensive benchmarks on three public longitudinal datasets show that TFM consistently surpasses spatio-temporal methods from natural imaging, establishing a new state-of-the-art and robust baseline for $4D$ medical image prediction.</li>
</ul>

<h3>Title: A Survey on Current Trends and Recent Advances in Text Anonymization</h3>
<ul>
<li><strong>Authors: </strong>Tobias Deußer, Lorenz Sparrenberg, Armin Berger, Max Hahnbück, Christian Bauckhage, Rafet Sifa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21587">https://arxiv.org/abs/2508.21587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21587">https://arxiv.org/pdf/2508.21587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21587]] A Survey on Current Trends and Recent Advances in Text Anonymization(https://arxiv.org/abs/2508.21587)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, large language model</a></li>
<li><strong>Abstract: </strong>The proliferation of textual data containing sensitive personal information across various domains requires robust anonymization techniques to protect privacy and comply with regulations, while preserving data usability for diverse and crucial downstream tasks. This survey provides a comprehensive overview of current trends and recent advances in text anonymization techniques. We begin by discussing foundational approaches, primarily centered on Named Entity Recognition, before examining the transformative impact of Large Language Models, detailing their dual role as sophisticated anonymizers and potent de-anonymization threats. The survey further explores domain-specific challenges and tailored solutions in critical sectors such as healthcare, law, finance, and education. We investigate advanced methodologies incorporating formal privacy models and risk-aware frameworks, and address the specialized subfield of authorship anonymization. Additionally, we review evaluation frameworks, comprehensive metrics, benchmarks, and practical toolkits for real-world deployment of anonymization solutions. This review consolidates current knowledge, identifies emerging trends and persistent challenges, including the evolving privacy-utility trade-off, the need to address quasi-identifiers, and the implications of LLM capabilities, and aims to guide future research directions for both academics and practitioners in this field.</li>
</ul>

<h3>Title: Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning</h3>
<ul>
<li><strong>Authors: </strong>Zinan Tang, Xin Gao, Qizhi Pei, Zhuoshi Pan, Mengzhang Cai, Jiang Wu, Conghui He, Lijun Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21589">https://arxiv.org/abs/2508.21589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21589">https://arxiv.org/pdf/2508.21589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21589]] Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning(https://arxiv.org/abs/2508.21589)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Supervised Fine-Tuning (SFT) Large Language Models (LLM) fundamentally rely on high-quality training data. While data selection and data synthesis are two common strategies to improve data quality, existing approaches often face limitations in static dataset curation that fail to adapt to evolving model capabilities. In this paper, we introduce Middo, a self-evolving Model-informed dynamic data optimization framework that uses model-aware data selection and context-preserving data refinement. Unlike conventional one-off filtering/synthesis methods, our framework establishes a closed-loop optimization system: (1) A self-referential diagnostic module proactively identifies suboptimal samples through tri-axial model signals - loss patterns (complexity), embedding cluster dynamics (diversity), and self-alignment scores (quality); (2) An adaptive optimization engine then transforms suboptimal samples into pedagogically valuable training points while preserving semantic integrity; (3) This optimization process continuously evolves with model capability through dynamic learning principles. Experiments on multiple benchmarks demonstrate that our \method consistently enhances the quality of seed data and boosts LLM's performance with improving accuracy by 7.15% on average while maintaining the original dataset scale. This work establishes a new paradigm for sustainable LLM training through dynamic human-AI co-evolution of data and models. Our datasets, models, and code are coming soon.</li>
</ul>

<h3>Title: Condense to Conduct and Conduct to Condense</h3>
<ul>
<li><strong>Authors: </strong>Tomasz Kazana</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21602">https://arxiv.org/abs/2508.21602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21602">https://arxiv.org/pdf/2508.21602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21602]] Condense to Conduct and Conduct to Condense(https://arxiv.org/abs/2508.21602)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this paper we give the first examples of low-conductance permutations. The notion of conductance of permutations was introduced in the paper "Indifferentiability of Confusion-Diffusion Networks" by Dodis et al., where the search for low-conductance permutations was initiated and motivated. In this paper we not only give the desired examples, but also make a general characterization of the problem -- i.e. we show that low-conductance permutations are equivalent to permutations that have the information-theoretic properties of the so-called Multi-Source-Somewhere-Condensers.</li>
</ul>

<h3>Title: Hybrid Cryptographic Monitoring System for Side-Channel Attack Detection on PYNQ SoCs</h3>
<ul>
<li><strong>Authors: </strong>Nishant Chinnasami, Rasha Karakchi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21606">https://arxiv.org/abs/2508.21606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21606">https://arxiv.org/pdf/2508.21606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21606]] Hybrid Cryptographic Monitoring System for Side-Channel Attack Detection on PYNQ SoCs(https://arxiv.org/abs/2508.21606)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>AES-128 encryption is theoretically secure but vulnerable in practical deployments due to timing and fault injection attacks on embedded systems. This work presents a lightweight dual-detection framework combining statistical thresholding and machine learning (ML) for real-time anomaly detection. By simulating anomalies via delays and ciphertext corruption, we collect timing and data features to evaluate two strategies: (1) a statistical threshold method based on execution time and (2) a Random Forest classifier trained on block-level anomalies. Implemented on CPU and FPGA (PYNQ-Z1), our results show that the ML approach outperforms static thresholds in accuracy, while maintaining real-time feasibility on embedded platforms. The framework operates without modifying AES internals or relying on hardware performance counters. This makes it especially suitable for low-power, resource-constrained systems where detection accuracy and computational efficiency must be balanced.</li>
</ul>

<h3>Title: Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks</h3>
<ul>
<li><strong>Authors: </strong>Sarfaroz Yunusov, Kaige Chen, Kazi Nishat Anwar, Ali Emami</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21628">https://arxiv.org/abs/2508.21628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21628">https://arxiv.org/pdf/2508.21628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21628]] Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks(https://arxiv.org/abs/2508.21628)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) increasingly integrate into everyday workflows, where users shape outcomes through multi-turn collaboration, a critical question emerges: do users with different personality traits systematically prefer certain LLMs over others? We conducted a study with 32 participants evenly distributed across four Keirsey personality types, evaluating their interactions with GPT-4 and Claude 3.5 across four collaborative tasks: data analysis, creative writing, information retrieval, and writing assistance. Results revealed significant personality-driven preferences: Rationals strongly preferred GPT-4, particularly for goal-oriented tasks, while idealists favored Claude 3.5, especially for creative and analytical tasks. Other personality types showed task-dependent preferences. Sentiment analysis of qualitative feedback confirmed these patterns. Notably, aggregate helpfulness ratings were similar across models, showing how personality-based analysis reveals LLM differences that traditional evaluations miss.</li>
</ul>

<h3>Title: QZhou-Embedding Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Peng Yu, En Xu, Bin Chen, Haibiao Chen, Yinfei Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21632">https://arxiv.org/abs/2508.21632</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21632">https://arxiv.org/pdf/2508.21632</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21632]] QZhou-Embedding Technical Report(https://arxiv.org/abs/2508.21632)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>We present QZhou-Embedding, a general-purpose contextual text embedding model with exceptional text representation capabilities. Built upon the Qwen2.5-7B-Instruct foundation model, we designed a unified multi-task framework comprising specialized data transformation and training strategies. The data transformation scheme enables the incorporation of more diverse textual training datasets, while the task-specific training strategies enhance model learning efficiency. We developed a data synthesis pipeline leveraging LLM API, incorporating techniques such as paraphrasing, augmentation, and hard negative example generation to improve the semantic richness and sample difficulty of the training set. Additionally, we employ a two-stage training strategy, comprising initial retrieval-focused pretraining followed by full-task fine-tuning, enabling the embedding model to extend its capabilities based on robust retrieval performance. Our model achieves state-of-the-art results on the MTEB and CMTEB benchmarks, ranking first on both leaderboards (August 27 2025), and simultaneously achieves state-of-the-art performance on tasks including reranking, clustering, etc. Our findings demonstrate that higher-quality, more diverse data is crucial for advancing retrieval model performance, and that leveraging LLMs generative capabilities can further optimize data quality for embedding model breakthroughs. Our model weights are released on HuggingFace under Apache 2.0 license. For reproducibility, we provide evaluation code and instructions on GitHub.</li>
</ul>

<h3>Title: Detecting Stealthy Data Poisoning Attacks in AI Code Generators</h3>
<ul>
<li><strong>Authors: </strong>Cristina Improta</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21636">https://arxiv.org/abs/2508.21636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21636">https://arxiv.org/pdf/2508.21636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21636]] Detecting Stealthy Data Poisoning Attacks in AI Code Generators(https://arxiv.org/abs/2508.21636)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, defense, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Deep learning (DL) models for natural language-to-code generation have become integral to modern software development pipelines. However, their heavy reliance on large amounts of data, often collected from unsanitized online sources, exposes them to data poisoning attacks, where adversaries inject malicious samples to subtly bias model behavior. Recent targeted attacks silently replace secure code with semantically equivalent but vulnerable implementations without relying on explicit triggers to launch the attack, making it especially hard for detection methods to distinguish clean from poisoned samples. We present a systematic study on the effectiveness of existing poisoning detection methods under this stealthy threat model. Specifically, we perform targeted poisoning on three DL models (CodeBERT, CodeT5+, AST-T5), and evaluate spectral signatures analysis, activation clustering, and static analysis as defenses. Our results show that all methods struggle to detect triggerless poisoning, with representation-based approaches failing to isolate poisoned samples and static analysis suffering false positives and false negatives, highlighting the need for more robust, trigger-independent defenses for AI-assisted code generation.</li>
</ul>

<h3>Title: I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks</h3>
<ul>
<li><strong>Authors: </strong>Daryna Oliynyk, Rudolf Mayer, Kathrin Grosse, Andreas Rauber</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21654">https://arxiv.org/abs/2508.21654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21654">https://arxiv.org/pdf/2508.21654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21654]] I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks(https://arxiv.org/abs/2508.21654)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Model stealing attacks endanger the confidentiality of machine learning models offered as a service. Although these models are kept secret, a malicious party can query a model to label data samples and train their own substitute model, violating intellectual property. While novel attacks in the field are continually being published, their design and evaluations are not standardised, making it challenging to compare prior works and assess progress in the field. This paper is the first to address this gap by providing recommendations for designing and evaluating model stealing attacks. To this end, we study the largest group of attacks that rely on training a substitute model -- those attacking image classification models. We propose the first comprehensive threat model and develop a framework for attack comparison. Further, we analyse attack setups from related works to understand which tasks and models have been studied the most. Based on our findings, we present best practices for attack development before, during, and beyond experiments and derive an extensive list of open research questions regarding the evaluation of model stealing attacks. Our findings and recommendations also transfer to other problem domains, hence establishing the first generic evaluation methodology for model stealing attacks.</li>
</ul>

<h3>Title: Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation</h3>
<ul>
<li><strong>Authors: </strong>Haomiao Zhang, Zhangyuan Li, Yanling Piao, Zhi Li, Xiaodong Wang, Miao Cao, Xiongfei Su, Qiang Song, Xin Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21657">https://arxiv.org/abs/2508.21657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21657">https://arxiv.org/pdf/2508.21657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21657]] Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation(https://arxiv.org/abs/2508.21657)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Computer-generated holography (CGH) has gained wide attention with deep learning-based algorithms. However, due to its nonlinear and ill-posed nature, challenges remain in achieving accurate and stable reconstruction. Specifically, ($i$) the widely used end-to-end networks treat the reconstruction model as a black box, ignoring underlying physical relationships, which reduces interpretability and flexibility. ($ii$) CNN-based CGH algorithms have limited receptive fields, hindering their ability to capture long-range dependencies and global context. ($iii$) Angular spectrum method (ASM)-based models are constrained to finite this http URL this paper, we propose a Deep Unfolding Network (DUN) that decomposes gradient descent into two modules: an adaptive bandwidth-preserving model (ABPM) and a phase-domain complex-valued denoiser (PCD), providing more flexibility. ABPM allows for wider working distances compared to ASM-based methods. At the same time, PCD leverages its complex-valued deformable self-attention module to capture global features and enhance performance, achieving a PSNR over 35 dB. Experiments on simulated and real data show state-of-the-art results.</li>
</ul>

<h3>Title: Cybersecurity AI: Hacking the AI Hackers via Prompt Injection</h3>
<ul>
<li><strong>Authors: </strong>Víctor Mayoral-Vilches, Per Mannermaa Rynning</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21669">https://arxiv.org/abs/2508.21669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21669">https://arxiv.org/pdf/2508.21669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21669]] Cybersecurity AI: Hacking the AI Hackers via Prompt Injection(https://arxiv.org/abs/2508.21669)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>We demonstrate how AI-powered cybersecurity tools can be turned against themselves through prompt injection attacks. Prompt injection is reminiscent of cross-site scripting (XSS): malicious text is hidden within seemingly trusted content, and when the system processes it, that text is transformed into unintended instructions. When AI agents designed to find and exploit vulnerabilities interact with malicious web servers, carefully crafted reponses can hijack their execution flow, potentially granting attackers system access. We present proof-of-concept exploits against the Cybersecurity AI (CAI) framework and its CLI tool, and detail our mitigations against such attacks in a multi-layered defense implementation. Our findings indicate that prompt injection is a recurring and systemic issue in LLM-based architectures, one that will require dedicated work to address, much as the security community has had to do with XSS in traditional web applications.</li>
</ul>

<h3>Title: Is this chart lying to me? Automating the detection of misleading visualizations</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Tonglet, Jan Zimny, Tinne Tuytelaars, Iryna Gurevych</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21675">https://arxiv.org/abs/2508.21675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21675">https://arxiv.org/pdf/2508.21675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21675]] Is this chart lying to me? Automating the detection of misleading visualizations(https://arxiv.org/abs/2508.21675)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Misleading visualizations are a potent driver of misinformation on social media and the web. By violating chart design principles, they distort data and lead readers to draw inaccurate conclusions. Prior work has shown that both humans and multimodal large language models (MLLMs) are frequently deceived by such visualizations. Automatically detecting misleading visualizations and identifying the specific design rules they violate could help protect readers and reduce the spread of misinformation. However, the training and evaluation of AI models has been limited by the absence of large, diverse, and openly available datasets. In this work, we introduce Misviz, a benchmark of 2,604 real-world visualizations annotated with 12 types of misleaders. To support model training, we also release Misviz-synth, a synthetic dataset of 81,814 visualizations generated using Matplotlib and based on real-world data tables. We perform a comprehensive evaluation on both datasets using state-of-the-art MLLMs, rule-based systems, and fine-tuned classifiers. Our results reveal that the task remains highly challenging. We release Misviz, Misviz-synth, and the accompanying code.</li>
</ul>

<h3>Title: Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Rokuss, Yannick Kirchhoff, Fabian Isensee, Klaus H. Maier-Hein</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21680">https://arxiv.org/abs/2508.21680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21680">https://arxiv.org/pdf/2508.21680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21680]] Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models(https://arxiv.org/abs/2508.21680)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Whole-body PET/CT is a cornerstone of oncological imaging, yet accurate lesion segmentation remains challenging due to tracer heterogeneity, physiological uptake, and multi-center variability. While fully automated methods have advanced substantially, clinical practice benefits from approaches that keep humans in the loop to efficiently refine predicted masks. The autoPET/CT IV challenge addresses this need by introducing interactive segmentation tasks based on simulated user prompts. In this work, we present our submission to Task 1. Building on the winning autoPET III nnU-Net pipeline, we extend the framework with promptable capabilities by encoding user-provided foreground and background clicks as additional input channels. We systematically investigate representations for spatial prompts and demonstrate that Euclidean Distance Transform (EDT) encodings consistently outperform Gaussian kernels. Furthermore, we propose online simulation of user interactions and a custom point sampling strategy to improve robustness under realistic prompting conditions. Our ensemble of EDT-based models, trained with and without external data, achieves the strongest cross-validation performance, reducing both false positives and false negatives compared to baseline models. These results highlight the potential of promptable models to enable efficient, user-guided segmentation workflows in multi-tracer, multi-center PET/CT. Code is publicly available at this https URL</li>
</ul>

<h3>Title: Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR</h3>
<ul>
<li><strong>Authors: </strong>Shashank Vempati, Nishit Anand, Gaurav Talebailkar, Arpan Garai, Chetan Arora</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21693">https://arxiv.org/abs/2508.21693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21693">https://arxiv.org/pdf/2508.21693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21693]] Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR(https://arxiv.org/abs/2508.21693)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Conventional optical character recognition (OCR) techniques segmented each character and then recognized. This made them prone to error in character segmentation, and devoid of context to exploit language models. Advances in sequence to sequence translation in last decade led to modern techniques first detecting words and then inputting one word at a time to a model to directly output full words as sequence of characters. This allowed better utilization of language models and bypass error-prone character segmentation step. We observe that the above transition in style has moved the bottleneck in accuracy to word segmentation. Hence, in this paper, we propose a natural and logical progression from word level OCR to line-level OCR. The proposal allows to bypass errors in word detection, and provides larger sentence context for better utilization of language models. We show that the proposed technique not only improves the accuracy but also efficiency of OCR. Despite our thorough literature survey, we did not find any public dataset to train and benchmark such shift from word to line-level OCR. Hence, we also contribute a meticulously curated dataset of 251 English page images with line-level annotations. Our experimentation revealed a notable end-to-end accuracy improvement of 5.4%, underscoring the potential benefits of transitioning towards line-level OCR, especially for document images. We also report a 4 times improvement in efficiency compared to word-based pipelines. With continuous improvements in large language models, our methodology also holds potential to exploit such advances. Project Website: this https URL</li>
</ul>

<h3>Title: FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA</h3>
<ul>
<li><strong>Authors: </strong>Alvaro Patricio, Atabak Dehban, Rodrigo Ventura</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21712">https://arxiv.org/abs/2508.21712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21712">https://arxiv.org/pdf/2508.21712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21712]] FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA(https://arxiv.org/abs/2508.21712)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion-based generative models have demonstrated significant potential in augmenting scarce datasets for object detection tasks. Nevertheless, most recent models rely on resource-intensive full fine-tuning of large-scale diffusion models, requiring enterprise-grade GPUs (e.g., NVIDIA V100) and thousands of synthetic images. To address these limitations, we propose Flux LoRA Augmentation (FLORA), a lightweight synthetic data generation pipeline. Our approach uses the Flux 1.1 Dev diffusion model, fine-tuned exclusively through Low-Rank Adaptation (LoRA). This dramatically reduces computational requirements, enabling synthetic dataset generation with a consumer-grade GPU (e.g., NVIDIA RTX 4090). We empirically evaluate our approach on seven diverse object detection datasets. Our results demonstrate that training object detectors with just 500 synthetic images generated by our approach yields superior detection performance compared to models trained on 5000 synthetic images from the ODGEN baseline, achieving improvements of up to 21.3% in mAP@.50:.95. This work demonstrates that it is possible to surpass state-of-the-art performance with far greater efficiency, as FLORA achieves superior results using only 10% of the data and a fraction of the computational cost. This work demonstrates that a quality and efficiency-focused approach is more effective than brute-force generation, making advanced synthetic data creation more practical and accessible for real-world scenarios.</li>
</ul>

<h3>Title: OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization</h3>
<ul>
<li><strong>Authors: </strong>Jiazheng Xing, Hai Ci, Hongbin Xu, Hangjie Yuan, Yong Liu, Mike Zheng Shou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21727">https://arxiv.org/abs/2508.21727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21727">https://arxiv.org/pdf/2508.21727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21727]] OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization(https://arxiv.org/abs/2508.21727)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, watermark, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Watermarking diffusion-generated images is crucial for copyright protection and user tracking. However, current diffusion watermarking methods face significant limitations: zero-bit watermarking systems lack the capacity for large-scale user tracking, while multi-bit methods are highly sensitive to certain image transformations or generative attacks, resulting in a lack of comprehensive robustness. In this paper, we propose OptMark, an optimization-based approach that embeds a robust multi-bit watermark into the intermediate latents of the diffusion denoising process. OptMark strategically inserts a structural watermark early to resist generative attacks and a detail watermark late to withstand image transformations, with tailored regularization terms to preserve image quality and ensure imperceptibility. To address the challenge of memory consumption growing linearly with the number of denoising steps during optimization, OptMark incorporates adjoint gradient methods, reducing memory usage from O(N) to O(1). Experimental results demonstrate that OptMark achieves invisible multi-bit watermarking while ensuring robust resilience against valuemetric transformations, geometric transformations, editing, and regeneration attacks.</li>
</ul>

<h3>Title: CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>João Valente, Atabak Dehban, Rodrigo Ventura</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21732">https://arxiv.org/abs/2508.21732</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21732">https://arxiv.org/pdf/2508.21732</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21732]] CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models(https://arxiv.org/abs/2508.21732)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities across various multimodal tasks. They continue, however, to struggle with trivial scenarios such as reading values from Digital Measurement Devices (DMDs), particularly in real-world conditions involving clutter, occlusions, extreme viewpoints, and motion blur; common in head-mounted cameras and Augmented Reality (AR) applications. Motivated by these limitations, this work introduces CAD2DMD-SET, a synthetic data generation tool designed to support visual question answering (VQA) tasks involving DMDs. By leveraging 3D CAD models, advanced rendering, and high-fidelity image composition, our tool produces diverse, VQA-labelled synthetic DMD datasets suitable for fine-tuning LVLMs. Additionally, we present DMDBench, a curated validation set of 1,000 annotated real-world images designed to evaluate model performance under practical constraints. Benchmarking three state-of-the-art LVLMs using Average Normalised Levenshtein Similarity (ANLS) and further fine-tuning LoRA's of these models with CAD2DMD-SET's generated dataset yielded substantial improvements, with InternVL showcasing a score increase of 200% without degrading on other tasks. This demonstrates that the CAD2DMD-SET training dataset substantially improves the robustness and performance of LVLMs when operating under the previously stated challenging conditions. The CAD2DMD-SET tool is expected to be released as open-source once the final version of this manuscript is prepared, allowing the community to add different measurement devices and generate their own datasets.</li>
</ul>

<h3>Title: Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance</h3>
<ul>
<li><strong>Authors: </strong>Yao Wang, Di Liang, Minlong Peng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21741">https://arxiv.org/abs/2508.21741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21741">https://arxiv.org/pdf/2508.21741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21741]] Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance(https://arxiv.org/abs/2508.21741)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Supervised fine-tuning (SFT) is a pivotal approach to adapting large language models (LLMs) for downstream tasks; however, performance often suffers from the ``seesaw phenomenon'', where indiscriminate parameter updates yield progress on certain tasks at the expense of others. To address this challenge, we propose a novel \emph{Core Parameter Isolation Fine-Tuning} (CPI-FT) framework. Specifically, we first independently fine-tune the LLM on each task to identify its core parameter regions by quantifying parameter update magnitudes. Tasks with similar core regions are then grouped based on region overlap, forming clusters for joint modeling. We further introduce a parameter fusion technique: for each task, core parameters from its individually fine-tuned model are directly transplanted into a unified backbone, while non-core parameters from different tasks are smoothly integrated via Spherical Linear Interpolation (SLERP), mitigating destructive interference. A lightweight, pipelined SFT training phase using mixed-task data is subsequently employed, while freezing core regions from prior tasks to prevent catastrophic forgetting. Extensive experiments on multiple public benchmarks demonstrate that our approach significantly alleviates task interference and forgetting, consistently outperforming vanilla multi-task and multi-stage fine-tuning baselines.</li>
</ul>

<h3>Title: Learning from Silence and Noise for Visual Sound Source Localization</h3>
<ul>
<li><strong>Authors: </strong>Xavier Juanola, Giovana Morais, Magdalena Fuentes, Gloria Haro</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21761">https://arxiv.org/abs/2508.21761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21761">https://arxiv.org/pdf/2508.21761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21761]] Learning from Silence and Noise for Visual Sound Source Localization(https://arxiv.org/abs/2508.21761)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual sound source localization is a fundamental perception task that aims to detect the location of sounding sources in a video given its audio. Despite recent progress, we identify two shortcomings in current methods: 1) most approaches perform poorly in cases with low audio-visual semantic correspondence such as silence, noise, and offscreen sounds, i.e. in the presence of negative audio; and 2) most prior evaluations are limited to positive cases, where both datasets and metrics convey scenarios with a single visible sound source in the scene. To address this, we introduce three key contributions. First, we propose a new training strategy that incorporates silence and noise, which improves performance in positive cases, while being more robust against negative sounds. Our resulting self-supervised model, SSL-SaN, achieves state-of-the-art performance compared to other self-supervised models, both in sound localization and cross-modal retrieval. Second, we propose a new metric that quantifies the trade-off between alignment and separability of auditory and visual features across positive and negative audio-visual pairs. Third, we present IS3+, an extended and improved version of the IS3 synthetic dataset with negative audio. Our data, metrics and code are available on the this https URL.</li>
</ul>

<h3>Title: Reasoning-Intensive Regression</h3>
<ul>
<li><strong>Authors: </strong>Diane Tchuindjo, Omar Khattab</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21762">https://arxiv.org/abs/2508.21762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21762">https://arxiv.org/pdf/2508.21762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21762]] Reasoning-Intensive Regression(https://arxiv.org/abs/2508.21762)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>AI researchers and practitioners increasingly apply large language models (LLMs) to what we call reasoning-intensive regression (RiR), i.e. deducing subtle numerical properties from text. Unlike standard language regression tasks, e.g. for sentiment or similarity, RiR often appears instead in ad-hoc problems like rubric-based scoring or domain-specific retrieval, where much deeper analysis of text is required while only limited task-specific training data and computation are available. We cast three realistic problems as RiR tasks to establish an initial benchmark, and use that to test our hypothesis that prompting frozen LLMs and finetuning Transformer encoders via gradient descent will both often struggle in RiR. We then propose MENTAT, a simple and lightweight method that combines batch-reflective prompt optimization with neural ensemble learning. MENTAT achieves up to 65% improvement over both baselines, though substantial room remains for future advances in RiR.</li>
</ul>

<h3>Title: Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering</h3>
<ul>
<li><strong>Authors: </strong>Nattapong Kurpukdee, Adrian G. Bors</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21773">https://arxiv.org/abs/2508.21773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21773">https://arxiv.org/pdf/2508.21773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21773]] Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering(https://arxiv.org/abs/2508.21773)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We propose a realistic scenario for the unsupervised video learning where neither task boundaries nor labels are provided when learning a succession of tasks. We also provide a non-parametric learning solution for the under-explored problem of unsupervised video continual learning. Videos represent a complex and rich spatio-temporal media information, widely used in many applications, but which have not been sufficiently explored in unsupervised continual learning. Prior studies have only focused on supervised continual learning, relying on the knowledge of labels and task boundaries, while having labeled data is costly and not practical. To address this gap, we study the unsupervised video continual learning (uVCL). uVCL raises more challenges due to the additional computational and memory requirements of processing videos when compared to images. We introduce a general benchmark experimental protocol for uVCL by considering the learning of unstructured video data categories during each task. We propose to use the Kernel Density Estimation (KDE) of deep embedded video features extracted by unsupervised video transformer networks as a non-parametric probabilistic representation of the data. We introduce a novelty detection criterion for the incoming new task data, dynamically enabling the expansion of memory clusters, aiming to capture new knowledge when learning a succession of tasks. We leverage the use of transfer learning from the previous tasks as an initial state for the knowledge transfer to the current learning task. We found that the proposed methodology substantially enhances the performance of the model when successively learning many tasks. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, without using any labels or class boundaries.</li>
</ul>

<h3>Title: A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI</h3>
<ul>
<li><strong>Authors: </strong>Omer Faruk Durugol, Maximilian Rokuss, Yannick Kirchhoff, Klaus H. Maier-Hein</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21775">https://arxiv.org/abs/2508.21775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21775">https://arxiv.org/pdf/2508.21775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21775]] A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI(https://arxiv.org/abs/2508.21775)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Automated segmentation of Pancreatic Ductal Adenocarcinoma (PDAC) from MRI is critical for clinical workflows but is hindered by poor tumor-tissue contrast and a scarcity of annotated data. This paper details our submission to the PANTHER challenge, addressing both diagnostic T1-weighted (Task 1) and therapeutic T2-weighted (Task 2) segmentation. Our approach is built upon the nnU-Net framework and leverages a deep, multi-stage cascaded pre-training strategy, starting from a general anatomical foundation model and sequentially fine-tuning on CT pancreatic lesion datasets and the target MRI modalities. Through extensive five-fold cross-validation, we systematically evaluated data augmentation schemes and training schedules. Our analysis revealed a critical trade-off, where aggressive data augmentation produced the highest volumetric accuracy, while default augmentations yielded superior boundary precision (achieving a state-of-the-art MASD of 5.46 mm and HD95 of 17.33 mm for Task 1). For our final submission, we exploited this finding by constructing custom, heterogeneous ensembles of specialist models, essentially creating a mix of experts. This metric-aware ensembling strategy proved highly effective, achieving a top cross-validation Tumor Dice score of 0.661 for Task 1 and 0.523 for Task 2. Our work presents a robust methodology for developing specialized, high-performance models in the context of limited data and complex medical imaging tasks (Team MIC-DKFZ).</li>
</ul>

<h3>Title: Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight</h3>
<ul>
<li><strong>Authors: </strong>Ugur Dinc, Jibak Sarkar, Philipp Schubert, Sabine Semrau, Thomas Weissmann, Andre Karius, Johann Brand, Bernd-Niklas Axer, Ahmed Gomaa, Pluvio Stephan, Ishita Sheth, Sogand Beirami, Annette Schwarz, Udo Gaipl, Benjamin Frey, Christoph Bert, Stefanie Corradini, Rainer Fietkau, Florian Putz</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21777">https://arxiv.org/abs/2508.21777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21777">https://arxiv.org/pdf/2508.21777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21777]] Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight(https://arxiv.org/abs/2508.21777)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Introduction: Large language models (LLM) have shown great potential in clinical decision support. GPT-5 is a novel LLM system that has been specifically marketed towards oncology use. Methods: Performance was assessed using two complementary benchmarks: (i) the ACR Radiation Oncology In-Training Examination (TXIT, 2021), comprising 300 multiple-choice items, and (ii) a curated set of 60 authentic radiation oncologic vignettes representing diverse disease sites and treatment indications. For the vignette evaluation, GPT-5 was instructed to generate concise therapeutic plans. Four board-certified radiation oncologists rated correctness, comprehensiveness, and hallucinations. Inter-rater reliability was quantified using Fleiss' \k{appa}. Results: On the TXIT benchmark, GPT-5 achieved a mean accuracy of 92.8%, outperforming GPT-4 (78.8%) and GPT-3.5 (62.1%). Domain-specific gains were most pronounced in Dose and Diagnosis. In the vignette evaluation, GPT-5's treatment recommendations were rated highly for correctness (mean 3.24/4, 95% CI: 3.11-3.38) and comprehensiveness (3.59/4, 95% CI: 3.49-3.69). Hallucinations were rare with no case reaching majority consensus for their presence. Inter-rater agreement was low (Fleiss' \k{appa} 0.083 for correctness), reflecting inherent variability in clinical judgment. Errors clustered in complex scenarios requiring precise trial knowledge or detailed clinical adaptation. Discussion: GPT-5 clearly outperformed prior model variants on the radiation oncology multiple-choice benchmark. Although GPT-5 exhibited favorable performance in generating real-world radiation oncology treatment recommendations, correctness ratings indicate room for further improvement. While hallucinations were infrequent, the presence of substantive errors underscores that GPT-5-generated recommendations require rigorous expert oversight before clinical implementation.</li>
</ul>

<h3>Title: Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling</h3>
<ul>
<li><strong>Authors: </strong>Peng Yang, Zhengdong Huang, Zicheng Xie, Wentao Tian, Jingyu Liu, Lunhong Dong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21785">https://arxiv.org/abs/2508.21785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21785">https://arxiv.org/pdf/2508.21785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21785]] Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling(https://arxiv.org/abs/2508.21785)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Heart rate prediction is vital for personalized health monitoring and fitness, while it frequently faces a critical challenge when deploying in real-world: data heterogeneity. We classify it in two key dimensions: source heterogeneity from fragmented device markets with varying feature sets, and user heterogeneity reflecting distinct physiological patterns across individuals and activities. Existing methods either discard device-specific information, or fail to model user-specific differences, limiting their real-world performance. To address this, we propose a framework that learns latent representations agnostic to both heterogeneity, enabling downstream predictors to work consistently under heterogeneous data patterns. Specifically, we introduce a random feature dropout strategy to handle source heterogeneity, making the model robust to various feature sets. To manage user heterogeneity, we employ a time-aware attention module to capture long-term physiological traits and use a contrastive learning objective to build a discriminative representation space. To reflect the heterogeneous nature of real-world data, we created and publicly released a new benchmark dataset, ParroTao. Evaluations on both ParroTao and the public FitRec dataset show that our model significantly outperforms existing baselines by 17% and 15%, respectively. Furthermore, analysis of the learned representations demonstrates their strong discriminative power, and one downstream application task confirm the practical value of our model.</li>
</ul>

<h3>Title: PiCSAR: Probabilistic Confidence Selection And Ranking</h3>
<ul>
<li><strong>Authors: </strong>Joshua Ong Jun Leang, Zheng Zhao, Aryo Pradipta Gema, Sohee Yang, Wai-Chung Kwan, Xuanli He, Wenda Li, Pasquale Minervini, Eleonora Giunchiglia, Shay B. Cohen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21787">https://arxiv.org/abs/2508.21787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21787">https://arxiv.org/pdf/2508.21787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21787]] PiCSAR: Probabilistic Confidence Selection And Ranking(https://arxiv.org/abs/2508.21787)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Best-of-n sampling improves the accuracy of large language models (LLMs) and large reasoning models (LRMs) by generating multiple candidate solutions and selecting the one with the highest reward. The key challenge for reasoning tasks is designing a scoring function that can identify correct reasoning chains without access to ground-truth answers. We propose Probabilistic Confidence Selection And Ranking (PiCSAR): a simple, training-free method that scores each candidate generation using the joint log-likelihood of the reasoning and final answer. The joint log-likelihood of the reasoning and final answer naturally decomposes into reasoning confidence and answer confidence. PiCSAR achieves substantial gains across diverse benchmarks (+10.18 on MATH500, +9.81 on AIME2025), outperforming baselines with at least 2x fewer samples in 16 out of 20 comparisons. Our analysis reveals that correct reasoning chains exhibit significantly higher reasoning and answer confidence, justifying the effectiveness of PiCSAR.</li>
</ul>

<h3>Title: Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Inés Altemir Marinas, Anastasiia Kucherenko, Andrei Kucharavy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21788">https://arxiv.org/abs/2508.21788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21788">https://arxiv.org/pdf/2508.21788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21788]] Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval(https://arxiv.org/abs/2508.21788)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) rely heavily on web-scale datasets like Common Crawl, which provides over 80\% of training data for some modern models. However, the indiscriminate nature of web crawling raises challenges in data quality, safety, and ethics. Despite the critical importance of training data quality, prior research on harmful content has been limited to small samples due to computational constraints. This project presents a framework for indexing and analyzing LLM training datasets using an ElasticSearch-based pipeline. We apply it to SwissAI's FineWeb-2 corpus (1.5TB, four languages), achieving fast query performance--most searches in milliseconds, all under 2 seconds. Our work demonstrates real-time dataset analysis, offering practical tools for safer, more accountable AI systems.</li>
</ul>

<h3>Title: MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyang Wang, Christopher C. Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21793">https://arxiv.org/abs/2508.21793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21793">https://arxiv.org/pdf/2508.21793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21793]] MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction(https://arxiv.org/abs/2508.21793)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Healthcare systems generate diverse multimodal data, including Electronic Health Records (EHR), clinical notes, and medical images. Effectively leveraging this data for clinical prediction is challenging, particularly as real-world samples often present with varied or incomplete modalities. Existing approaches typically require complete modality data or rely on manual selection strategies, limiting their applicability in real-world clinical settings where data availability varies across patients and institutions. To address these limitations, we propose MoE-Health, a novel Mixture of Experts framework designed for robust multimodal fusion in healthcare prediction. MoE-Health architecture is specifically developed to handle samples with differing modalities and improve performance on critical clinical tasks. By leveraging specialized expert networks and a dynamic gating mechanism, our approach dynamically selects and combines relevant experts based on available data modalities, enabling flexible adaptation to varying data availability scenarios. We evaluate MoE-Health on the MIMIC-IV dataset across three critical clinical prediction tasks: in-hospital mortality prediction, long length of stay, and hospital readmission prediction. Experimental results demonstrate that MoE-Health achieves superior performance compared to existing multimodal fusion methods while maintaining robustness across different modality availability patterns. The framework effectively integrates multimodal information, offering improved predictive performance and robustness in handling heterogeneous and incomplete healthcare data, making it particularly suitable for deployment in diverse healthcare environments with heterogeneous data availability.</li>
</ul>

<h3>Title: VoCap: Video Object Captioning and Segmentation from Any Prompt</h3>
<ul>
<li><strong>Authors: </strong>Jasper Uijlings, Xingyi Zhou, Xiuye Gu, Arsha Nagrani, Anurag Arnab, Alireza Fathi, David Ross, Cordelia Schmid</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21809">https://arxiv.org/abs/2508.21809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21809">https://arxiv.org/pdf/2508.21809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21809]] VoCap: Video Object Captioning and Segmentation from Any Prompt(https://arxiv.org/abs/2508.21809)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Understanding objects in videos in terms of fine-grained localization masks and detailed semantic properties is a fundamental task in video understanding. In this paper, we propose VoCap, a flexible video model that consumes a video and a prompt of various modalities (text, box or mask), and produces a spatio-temporal masklet with a corresponding object-centric caption. As such our model addresses simultaneously the tasks of promptable video object segmentation, referring expression segmentation, and object captioning. Since obtaining data for this task is tedious and expensive, we propose to annotate an existing large-scale segmentation dataset (SAV) with pseudo object captions. We do so by preprocessing videos with their ground-truth masks to highlight the object of interest and feed this to a large Vision Language Model (VLM). For an unbiased evaluation, we collect manual annotations on the validation set. We call the resulting dataset SAV-Caption. We train our VoCap model at scale on a SAV-Caption together with a mix of other image and video datasets. Our model yields state-of-the-art results on referring expression video object segmentation, is competitive on semi-supervised video object segmentation, and establishes a benchmark for video object captioning. Our dataset will be made available at this https URL.</li>
</ul>

<h3>Title: QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jessica Liang, Anirudh Bharadwaj</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21810">https://arxiv.org/abs/2508.21810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21810">https://arxiv.org/pdf/2508.21810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21810]] QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models(https://arxiv.org/abs/2508.21810)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing scale of Large Language Models (LLMs) has necessitated the development of parameter-efficient fine-tuning techniques. Low-Rank Adaptation (LoRA) has emerged as a promising approach, reducing the number of trainable parameters by applying low-rank updates to pretrained weights. While standard LoRA learns both update factors directly, several recent variants first initialize those matrices via an SVD of the pretrained weights -- an operation that can be expensive on large models and yields singular vectors that are not always easy to interpret. In this work, we extract an orthonormal basis from the pretrained weight matrix using QR decomposition with column pivoting, and then express the LoRA update as a linear combination of these basis vectors -- training only the scalar coefficients, which imposes clear structure on adaptation and drastically reduces parameter count. Experiments across GLUE tasks show that QR-LoRA matches or exceeds the performance of full fine-tuning, standard LoRA, and SVD-LoRA (LoRA with update matrices initialized via singular value decomposition) with as few as 601 parameters -- a reduction of over 1000x compared to full fine-tuning and 77x fewer than typical LoRA setups.</li>
</ul>

<h3>Title: Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy for Fair and Private Data Generation</h3>
<ul>
<li><strong>Authors: </strong>Tobias Hyrup, Emmanouil Panagiotou, Arjun Roy, Arthur Zimek, Eirini Ntoutsi, Peter Schneider-Kamp</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21815">https://arxiv.org/abs/2508.21815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21815">https://arxiv.org/pdf/2508.21815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21815]] Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy for Fair and Private Data Generation(https://arxiv.org/abs/2508.21815)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, fair, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>As privacy regulations such as the GDPR and HIPAA and responsibility frameworks for artificial intelligence such as the AI Act gain traction, the ethical and responsible use of real-world data faces increasing constraints. Synthetic data generation has emerged as a promising solution to risk-aware data sharing and model development, particularly for tabular datasets that are foundational to sensitive domains such as healthcare. To address both privacy and fairness concerns in this setting, we propose FLIP (Fair Latent Intervention under Privacy guarantees), a transformer-based variational autoencoder augmented with latent diffusion to generate heterogeneous tabular data. Unlike the typical setup in fairness-aware data generation, we assume a task-agnostic setup, not reliant on a fixed, defined downstream task, thus offering broader applicability. To ensure privacy, FLIP employs Rényi differential privacy (RDP) constraints during training and addresses fairness in the input space with RDP-compatible balanced sampling that accounts for group-specific noise levels across multiple sampling rates. In the latent space, we promote fairness by aligning neuron activation patterns across protected groups using Centered Kernel Alignment (CKA), a similarity measure extending the Hilbert-Schmidt Independence Criterion (HSIC). This alignment encourages statistical independence between latent representations and the protected feature. Empirical results demonstrate that FLIP effectively provides significant fairness improvements for task-agnostic fairness and across diverse downstream tasks under differential privacy constraints.</li>
</ul>

<h3>Title: The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning</h3>
<ul>
<li><strong>Authors: </strong>Yiming Lin, Yuchen Niu, Shang Wang, Kaizhu Huang, Qiufeng Wang, Xiao-Bo Jin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21816">https://arxiv.org/abs/2508.21816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21816">https://arxiv.org/pdf/2508.21816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21816]] The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning(https://arxiv.org/abs/2508.21816)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Context recognition (SR) is a fundamental task in computer vision that aims to extract structured semantic summaries from images by identifying key events and their associated entities. Specifically, given an input image, the model must first classify the main visual events (verb classification), then identify the participating entities and their semantic roles (semantic role labeling), and finally localize these entities in the image (semantic role localization). Existing methods treat verb classification as a single-label problem, but we show through a comprehensive analysis that this formulation fails to address the inherent ambiguity in visual event recognition, as multiple verb categories may reasonably describe the same image. This paper makes three key contributions: First, we reveal through empirical analysis that verb classification is inherently a multi-label problem due to the ubiquitous semantic overlap between verb categories. Second, given the impracticality of fully annotating large-scale datasets with multiple labels, we propose to reformulate verb classification as a single positive multi-label learning (SPMLL) problem - a novel perspective in SR research. Third, we design a comprehensive multi-label evaluation benchmark for SR that is carefully designed to fairly evaluate model performance in a multi-label setting. To address the challenges of SPMLL, we futher develop the Graph Enhanced Verb Multilayer Perceptron (GE-VerbMLP), which combines graph neural networks to capture label correlations and adversarial training to optimize decision boundaries. Extensive experiments on real-world datasets show that our approach achieves more than 3\% MAP improvement while remaining competitive on traditional top-1 and top-5 accuracy metrics.</li>
</ul>

<h3>Title: DriveQA: Passing the Driving Knowledge Test</h3>
<ul>
<li><strong>Authors: </strong>Maolin Wei, Wanzhou Liu, Eshed Ohn-Bar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.21824">https://arxiv.org/abs/2508.21824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.21824">https://arxiv.org/pdf/2508.21824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.21824]] DriveQA: Passing the Driving Knowledge Test(https://arxiv.org/abs/2508.21824)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>If a Large Language Model (LLM) were to take a driving knowledge test today, would it pass? Beyond standard spatial and visual question-answering (QA) tasks on current autonomous driving benchmarks, driving knowledge tests require a complete understanding of all traffic rules, signage, and right-of-way principles. To pass this test, human drivers must discern various edge cases that rarely appear in real-world datasets. In this work, we present DriveQA, an extensive open-source text and vision-based benchmark that exhaustively covers traffic regulations and scenarios. Through our experiments using DriveQA, we show that (1) state-of-the-art LLMs and Multimodal LLMs (MLLMs) perform well on basic traffic rules but exhibit significant weaknesses in numerical reasoning and complex right-of-way scenarios, traffic sign variations, and spatial layouts, (2) fine-tuning on DriveQA improves accuracy across multiple categories, particularly in regulatory sign recognition and intersection decision-making, (3) controlled variations in DriveQA-V provide insights into model sensitivity to environmental factors such as lighting, perspective, distance, and weather conditions, and (4) pretraining on DriveQA enhances downstream driving task performance, leading to improved results on real-world datasets such as nuScenes and BDD, while also demonstrating that models can internalize text and synthetic traffic knowledge to generalize effectively across downstream QA tasks.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
