<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Reflections on trusting distributed trust. (arXiv:2210.08127v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08127">http://arxiv.org/abs/2210.08127</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08127] Reflections on trusting distributed trust](http://arxiv.org/abs/2210.08127)</code></li>
<li>Summary: <p>Many systems today distribute trust across multiple parties such that the
system provides certain security properties if a subset of the parties are
honest. In the past few years, we have seen an explosion of academic and
industrial cryptographic systems built on distributed trust, including secure
multi-party computation applications (e.g., private analytics, secure learning,
and private key recovery) and blockchains. These systems have great potential
for improving security and privacy, but face a significant hurdle on the path
to deployment. We initiate study of the following problem: a single
organization is, by definition, a single party, and so how can a single
organization build a distributed-trust system where corruptions are
independent? We instead consider an alternative formulation of the problem:
rather than ensuring that a distributed-trust system is set up correctly by
design, what if instead, users can audit a distributed-trust deployment? We
propose a framework that enables a developer to efficiently and cheaply set up
any distributed-trust system in a publicly auditable way. To do this, we
identify two application-independent building blocks that we can use to
bootstrap arbitrary distributed-trust applications: secure hardware and an
append-only log. We show how to leverage existing implementations of these
building blocks to deploy distributed-trust systems, and we give
recommendations for infrastructure changes that would make it easier to deploy
distributed-trust systems in the future.
</p></li>
</ul>

<h3>Title: A Secure Federated Data-Driven Evolutionary Multi-objective Optimization Algorithm. (arXiv:2210.08295v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08295">http://arxiv.org/abs/2210.08295</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08295] A Secure Federated Data-Driven Evolutionary Multi-objective Optimization Algorithm](http://arxiv.org/abs/2210.08295)</code></li>
<li>Summary: <p>Data-driven evolutionary algorithms usually aim to exploit the information
behind a limited amount of data to perform optimization, which have proved to
be successful in solving many complex real-world optimization problems.
However, most data-driven evolutionary algorithms are centralized, causing
privacy and security concerns. Existing federated Bayesian algorithms and
data-driven evolutionary algorithms mainly protect the raw data on each client.
To address this issue, this paper proposes a secure federated data-driven
evolutionary multi-objective optimization algorithm to protect both the raw
data and the newly infilled solutions obtained by optimizing the acquisition
function conducted on the server. We select the query points on a randomly
selected client at each round of surrogate update by calculating the
acquisition function values of the unobserved points on this client, thereby
reducing the risk of leaking the information about the solution to be sampled.
In addition, since the predicted objective values of each client may contain
sensitive information, we mask the objective values with Diffie-Hellmann-based
noise, and then send only the masked objective values of other clients to the
selected client via the server. Since the calculation of the acquisition
function also requires both the predicted objective value and the uncertainty
of the prediction, the predicted mean objective and uncertainty are normalized
to reduce the influence of noise. Experimental results on a set of widely used
multi-objective optimization benchmarks show that the proposed algorithm can
protect privacy and enhance security with only negligible sacrifice in the
performance of federated data-driven evolutionary optimization.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Assessing the Solid Protocol in Relation to Security &amp; Privacy Obligations. (arXiv:2210.08270v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08270">http://arxiv.org/abs/2210.08270</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08270] Assessing the Solid Protocol in Relation to Security &amp; Privacy Obligations](http://arxiv.org/abs/2210.08270)</code></li>
<li>Summary: <p>The Solid specification aims to empower data subjects by giving them direct
access control over their data across multiple applications. As governments are
manifesting their interest in this framework for citizen empowerment and
e-government services, security and privacy represent pivotal issues to be
addressed. By analyzing the relevant legislation, notably GDPR, and
international standards, namely ISO/IEC 27001:2011 and 15408, we formulate the
primary security and privacy requirements for such a framework. Furthermore, we
survey the current Solid protocol specifications regarding how they cover the
highlighted requirements, and draw attention to potential gaps between the
specifications and requirements. We also point out the contribution of recent
academic work presenting novel approaches to increase the security and privacy
degree provided by the Solid project. This paper has a twofold contribution to
improve user awareness of how Solid can help protect their data and to present
possible future research lines on Solid security and privacy enhancements.
</p></li>
</ul>

<h3>Title: Man-in-the-OBD: A modular, protocol agnostic firewall for automotive dongles to enhance privacy and security. (arXiv:2210.08281v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08281">http://arxiv.org/abs/2210.08281</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08281] Man-in-the-OBD: A modular, protocol agnostic firewall for automotive dongles to enhance privacy and security](http://arxiv.org/abs/2210.08281)</code></li>
<li>Summary: <p>Third-party dongles for cars, e.g. from insurance companies, can extract
sensitive data and even send commands to the car via the standardized OBD-II
interface. Due to the lack of message authentication mechanisms, this leads to
major security vulnerabilities for example regarding the connection with
malicious devices. Therefore, we apply a modular, protocol-independent firewall
approach by placing a man-in-the-middle between the third-party dongle and the
car's OBD-II interface. With this privileged network position, we demonstrate
how the data flow accessible through the OBD-II interface can be modified or
restricted. We can modify the messages contents or delay the arrival of
messages by using our fine-granular configurable rewriting rules, specifically
designed to work protocol agnostic. We have implemented our modular approach
for a configurable firewall at the OBD-II interface and successfully tested it
against third-party dongles available on the market. Thus, our approach enables
a security layer to enhance automotive privacy and security of dongle users,
which is of high relevance due to missing message authentications on the level
of the electronic control units.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Hand Gestures Recognition in Videos Taken with Lensless Camera. (arXiv:2210.08233v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08233">http://arxiv.org/abs/2210.08233</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08233] Hand Gestures Recognition in Videos Taken with Lensless Camera](http://arxiv.org/abs/2210.08233)</code></li>
<li>Summary: <p>A lensless camera is an imaging system that uses a mask in place of a lens,
making it thinner, lighter, and less expensive than a lensed camera. However,
additional complex computation and time are required for image reconstruction.
This work proposes a deep learning model named Raw3dNet that recognizes hand
gestures directly on raw videos captured by a lensless camera without the need
for image restoration. In addition to conserving computational resources, the
reconstruction-free method provides privacy protection. Raw3dNet is a novel
end-to-end deep neural network model for the recognition of hand gestures in
lensless imaging systems. It is created specifically for raw video captured by
a lensless camera and has the ability to properly extract and combine temporal
and spatial features. The network is composed of two stages: 1. spatial feature
extractor (SFE), which enhances the spatial features of each frame prior to
temporal convolution; 2. 3D-ResNet, which implements spatial and temporal
convolution of video streams. The proposed model achieves 98.59% accuracy on
the Cambridge Hand Gesture dataset in the lensless optical experiment, which is
comparable to the lensed-camera result. Additionally, the feasibility of
physical object recognition is assessed. Furtherly, we show that the
recognition can be achieved with respectable accuracy using only a tiny portion
of the original raw data, indicating the potential for reducing data traffic in
cloud computing scenarios.
</p></li>
</ul>

<h3>Title: No Video Left Behind: A Utility-Preserving Obfuscation Approach for YouTube Recommendations. (arXiv:2210.08136v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08136">http://arxiv.org/abs/2210.08136</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08136] No Video Left Behind: A Utility-Preserving Obfuscation Approach for YouTube Recommendations](http://arxiv.org/abs/2210.08136)</code></li>
<li>Summary: <p>Online content platforms optimize engagement by providing personalized
recommendations to their users. These recommendation systems track and profile
users to predict relevant content a user is likely interested in. While the
personalized recommendations provide utility to users, the tracking and
profiling that enables them poses a privacy issue because the platform might
infer potentially sensitive user interests. There is increasing interest in
building privacy-enhancing obfuscation approaches that do not rely on
cooperation from online content platforms. However, existing obfuscation
approaches primarily focus on enhancing privacy but at the same time they
degrade the utility because obfuscation introduces unrelated recommendations.
We design and implement De-Harpo, an obfuscation approach for YouTube's
recommendation system that not only obfuscates a user's video watch history to
protect privacy but then also denoises the video recommendations by YouTube to
preserve their utility. In contrast to prior obfuscation approaches, De-Harpo
adds a denoiser that makes use of a "secret" input (i.e., a user's actual watch
history) as well as information that is also available to the adversarial
recommendation system (i.e., obfuscated watch history and corresponding "noisy"
recommendations). Our large-scale evaluation of De-Harpo shows that it
outperforms the state-of-the-art by a factor of 2x in terms of preserving
utility for the same level of privacy, while maintaining stealthiness and
robustness to de-obfuscation.
</p></li>
</ul>

<h3>Title: Deep Regression Unlearning. (arXiv:2210.08196v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08196">http://arxiv.org/abs/2210.08196</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08196] Deep Regression Unlearning](http://arxiv.org/abs/2210.08196)</code></li>
<li>Summary: <p>With the introduction of data protection and privacy regulations, it has
become crucial to remove the lineage of data on demand in a machine learning
system. In past few years, there has been notable development in machine
unlearning to remove the information of certain training data points
efficiently and effectively from the model. In this work, we explore unlearning
in a regression problem, particularly in deep learning models. Unlearning in
classification and simple linear regression has been investigated considerably.
However, unlearning in deep regression models largely remain an untouched
problem till now. In this work, we introduce deep regression unlearning methods
that are well generalized and robust to privacy attacks. We propose the
Blindspot unlearning method which uses a novel weight optimization process. A
randomly initialized model, partially exposed to the retain samples and a copy
of original model are used together to selectively imprint knowledge about the
data that we wish to keep and scrub the information of the data we wish to
forget. We also propose a Gaussian distribution based fine tuning method for
regression unlearning. The existing evaluation metrics for unlearning in a
classification task are not directly applicable for regression unlearning.
Therefore, we adapt these metrics for regression task. We devise a membership
inference attack to check the privacy leaks in the unlearned regression model.
We conduct the experiments on regression tasks for computer vision, natural
language processing and forecasting applications. Our deep regression
unlearning methods show excellent performance across all of these datasets and
metrics.
</p></li>
</ul>

<h3>Title: A Closer Look at the Calibration of Differentially Private Learners. (arXiv:2210.08248v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08248">http://arxiv.org/abs/2210.08248</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08248] A Closer Look at the Calibration of Differentially Private Learners](http://arxiv.org/abs/2210.08248)</code></li>
<li>Summary: <p>We systematically study the calibration of classifiers trained with
differentially private stochastic gradient descent (DP-SGD) and observe
miscalibration across a wide range of vision and language tasks. Our analysis
identifies per-example gradient clipping in DP-SGD as a major cause of
miscalibration, and we show that existing approaches for improving calibration
with differential privacy only provide marginal improvements in calibration
error while occasionally causing large degradations in accuracy. As a solution,
we show that differentially private variants of post-processing calibration
methods such as temperature scaling and Platt scaling are surprisingly
effective and have negligible utility cost to the overall model. Across 7
tasks, temperature scaling and Platt scaling with DP-SGD result in an average
3.1-fold reduction in the in-domain expected calibration error and only incur
at most a minor percent drop in accuracy.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Dynamics-aware Adversarial Attack of Adaptive Neural Networks. (arXiv:2210.08159v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08159">http://arxiv.org/abs/2210.08159</a></li>
<li>Code URL: <a href="https://github.com/AnTao97/LGM">https://github.com/AnTao97/LGM</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08159] Dynamics-aware Adversarial Attack of Adaptive Neural Networks](http://arxiv.org/abs/2210.08159)</code></li>
<li>Summary: <p>In this paper, we investigate the dynamics-aware adversarial attack problem
of adaptive neural networks. Most existing adversarial attack algorithms are
designed under a basic assumption -- the network architecture is fixed
throughout the attack process. However, this assumption does not hold for many
recently proposed adaptive neural networks, which adaptively deactivate
unnecessary execution units based on inputs to improve computational
efficiency. It results in a serious issue of lagged gradient, making the
learned attack at the current step ineffective due to the architecture change
afterward. To address this issue, we propose a Leaded Gradient Method (LGM) and
show the significant effects of the lagged gradient. More specifically, we
reformulate the gradients to be aware of the potential dynamic changes of
network architectures, so that the learned attack better "leads" the next step
than the dynamics-unaware methods when network architecture changes
dynamically. Extensive experiments on representative types of adaptive neural
networks for both 2D images and 3D point clouds show that our LGM achieves
impressive adversarial attack performance compared with the dynamic-unaware
attack methods.
</p></li>
</ul>

<h3>Title: Is Face Recognition Safe from Realizable Attacks?. (arXiv:2210.08178v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08178">http://arxiv.org/abs/2210.08178</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08178] Is Face Recognition Safe from Realizable Attacks?](http://arxiv.org/abs/2210.08178)</code></li>
<li>Summary: <p>Face recognition is a popular form of biometric authentication and due to its
widespread use, attacks have become more common as well. Recent studies show
that Face Recognition Systems are vulnerable to attacks and can lead to
erroneous identification of faces. Interestingly, most of these attacks are
white-box, or they are manipulating facial images in ways that are not
physically realizable. In this paper, we propose an attack scheme where the
attacker can generate realistic synthesized face images with subtle
perturbations and physically realize that onto his face to attack black-box
face recognition systems. Comprehensive experiments and analyses show that
subtle perturbations realized on attackers face can create successful attacks
on state-of-the-art face recognition systems in black-box settings. Our study
exposes the underlying vulnerability posed by the Face Recognition Systems
against realizable black-box attacks.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Neural Attentive Circuits. (arXiv:2210.08031v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08031">http://arxiv.org/abs/2210.08031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08031] Neural Attentive Circuits](http://arxiv.org/abs/2210.08031)</code></li>
<li>Summary: <p>Recent work has seen the development of general purpose neural architectures
that can be trained to perform tasks across diverse data modalities. General
purpose models typically make few assumptions about the underlying
data-structure and are known to perform well in the large-data regime. At the
same time, there has been growing interest in modular neural architectures that
represent the data using sparsely interacting modules. These models can be more
robust out-of-distribution, computationally efficient, and capable of
sample-efficient adaptation to new data. However, they tend to make
domain-specific assumptions about the data, and present challenges in how
module behavior (i.e., parameterization) and connectivity (i.e., their layout)
can be jointly learned. In this work, we introduce a general purpose, yet
modular neural architecture called Neural Attentive Circuits (NACs) that
jointly learns the parameterization and a sparse connectivity of neural modules
without using domain knowledge. NACs are best understood as the combination of
two systems that are jointly trained end-to-end: one that determines the module
configuration and the other that executes it on an input. We demonstrate
qualitatively that NACs learn diverse and meaningful module configurations on
the NLVR2 dataset without additional supervision. Quantitatively, we show that
by incorporating modularity in this way, NACs improve upon a strong non-modular
baseline in terms of low-shot adaptation on CIFAR and CUBs dataset by about
10%, and OOD robustness on Tiny ImageNet-R by about 2.5%. Further, we find that
NACs can achieve an 8x speedup at inference time while losing less than 3%
performance. Finally, we find NACs to yield competitive results on diverse data
modalities spanning point-cloud classification, symbolic processing and
text-classification from ASCII bytes, thereby confirming its general purpose
nature.
</p></li>
</ul>

<h3>Title: Attention Regularized Laplace Graph for Domain Adaptation. (arXiv:2210.08170v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08170">http://arxiv.org/abs/2210.08170</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08170] Attention Regularized Laplace Graph for Domain Adaptation](http://arxiv.org/abs/2210.08170)</code></li>
<li>Summary: <p>In leveraging manifold learning in domain adaptation (DA), graph
embedding-based DA methods have shown their effectiveness in preserving data
manifold through the Laplace graph. However, current graph embedding DA methods
suffer from two issues: 1). they are only concerned with preservation of the
underlying data structures in the embedding and ignore sub-domain adaptation,
which requires taking into account intra-class similarity and inter-class
dissimilarity, thereby leading to negative transfer; 2). manifold learning is
proposed across different feature/label spaces separately, thereby hindering
unified comprehensive manifold learning. In this paper, starting from our
previous DGA-DA, we propose a novel DA method, namely Attention Regularized
Laplace Graph-based Domain Adaptation (ARG-DA), to remedy the aforementioned
issues. Specifically, by weighting the importance across different sub-domain
adaptation tasks, we propose the Attention Regularized Laplace Graph for
class-aware DA, thereby generating the attention regularized DA. Furthermore,
using a specifically designed FEEL strategy, our approach dynamically unifies
alignment of the manifold structures across different feature/label spaces,
thus leading to comprehensive manifold learning. Comprehensive experiments are
carried out to verify the effectiveness of the proposed DA method, which
consistently outperforms the state-of-the-art DA methods on 7 standard DA
benchmarks, i.e., 37 cross-domain image classification tasks including object,
face, and digit images. An in-depth analysis of the proposed DA method is also
discussed, including sensitivity, convergence, and robustness.
</p></li>
</ul>

<h3>Title: Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers. (arXiv:2210.08198v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08198">http://arxiv.org/abs/2210.08198</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08198] Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers](http://arxiv.org/abs/2210.08198)</code></li>
<li>Summary: <p>We develop a Distributionally Robust Optimization (DRO) formulation for
Multiclass Logistic Regression (MLR), which could tolerate data contaminated by
outliers. The DRO framework uses a probabilistic ambiguity set defined as a
ball of distributions that are close to the empirical distribution of the
training set in the sense of the Wasserstein metric. We relax the DRO
formulation into a regularized learning problem whose regularizer is a norm of
the coefficient matrix. We establish out-of-sample performance guarantees for
the solutions to our model, offering insights on the role of the regularizer in
controlling the prediction error. We apply the proposed method in rendering
deep Vision Transformer (ViT)-based image classifiers robust to random and
adversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we
demonstrate reductions in test error rate by up to 83.5% and loss by up to
91.3% compared with baseline methods, by adopting a novel random training
method.
</p></li>
</ul>

<h3>Title: Bidirectional Semi-supervised Dual-branch CNN for Robust 3D Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel Supervisions. (arXiv:2210.08291v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08291">http://arxiv.org/abs/2210.08291</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08291] Bidirectional Semi-supervised Dual-branch CNN for Robust 3D Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel Supervisions](http://arxiv.org/abs/2210.08291)</code></li>
<li>Summary: <p>Semi-supervised learning via teacher-student network can train a model
effectively on a few labeled samples. It enables a student model to distill
knowledge from the teacher's predictions of extra unlabeled data. However, such
knowledge flow is typically unidirectional, having the performance vulnerable
to the quality of teacher model. In this paper, we seek to robust 3D
reconstruction of stereo endoscopic images by proposing a novel fashion of
bidirectional learning between two learners, each of which can play both roles
of teacher and student concurrently. Specifically, we introduce two
self-supervisions, i.e., Adaptive Cross Supervision (ACS) and Adaptive Parallel
Supervision (APS), to learn a dual-branch convolutional neural network. The two
branches predict two different disparity probability distributions for the same
position, and output their expectations as disparity values. The learned
knowledge flows across branches along two directions: a cross direction
(disparity guides distribution in ACS) and a parallel direction (disparity
guides disparity in APS). Moreover, each branch also learns confidences to
dynamically refine its provided supervisions. In ACS, the predicted disparity
is softened into a unimodal distribution, and the lower the confidence, the
smoother the distribution. In APS, the incorrect predictions are suppressed by
lowering the weights of those with low confidence. With the adaptive
bidirectional learning, the two branches enjoy well-tuned supervisions from
each other, and eventually converge on a consistent and more accurate disparity
estimation. The experimental results on three public datasets demonstrate our
superior performance over other state-of-the-arts with a decrease of averaged
disparity error by at least 9.76%.
</p></li>
</ul>

<h3>Title: Classification of Web Phishing Kits for early detection by platform providers. (arXiv:2210.08273v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08273">http://arxiv.org/abs/2210.08273</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08273] Classification of Web Phishing Kits for early detection by platform providers](http://arxiv.org/abs/2210.08273)</code></li>
<li>Summary: <p>Phishing kits are tools that dark side experts provide to the community of
criminal phishers to facilitate the construction of malicious Web sites. As
these kits evolve in sophistication, providers of Web-based services need to
keep pace with continuous complexity. We present an original classification of
a corpus of over 2000 recent phishing kits according to their adopted evasion
and obfuscation functions. We carry out an initial deterministic analysis of
the source code of the kits to extract the most discriminant features and
information about their principal authors. We then integrate this initial
classification through supervised machine learning models. Thanks to the
ground-truth achieved in the first step, we can demonstrate whether and which
machine learning models are able to suitably classify even the kits adopting
novel evasion and obfuscation techniques that were unseen during the training
phase. We compare different algorithms and evaluate their robustness in the
realistic case in which only a small number of phishing kits are available for
training. This paper represents an initial but important step to support Web
service providers and analysts in improving early detection mechanisms and
intelligence operations for the phishing kits that might be installed on their
platforms.
</p></li>
</ul>

<h3>Title: Hierarchical Decentralized Deep Reinforcement Learning Architecture for a Simulated Four-Legged Agent. (arXiv:2210.08003v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08003">http://arxiv.org/abs/2210.08003</a></li>
<li>Code URL: <a href="https://github.com/wzaielamri/hddrl">https://github.com/wzaielamri/hddrl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08003] Hierarchical Decentralized Deep Reinforcement Learning Architecture for a Simulated Four-Legged Agent](http://arxiv.org/abs/2210.08003)</code></li>
<li>Summary: <p>Legged locomotion is widespread in nature and has inspired the design of
current robots. The controller of these legged robots is often realized as one
centralized instance. However, in nature, control of movement happens in a
hierarchical and decentralized fashion. Introducing these biological design
principles into robotic control systems has motivated this work. We tackle the
question whether decentralized and hierarchical control is beneficial for
legged robots and present a novel decentral, hierarchical architecture to
control a simulated legged agent. Three different tasks varying in complexity
are designed to benchmark five architectures (centralized, decentralized,
hierarchical and two different combinations of hierarchical decentralized
architectures). The results demonstrate that decentralizing the different
levels of the hierarchical architectures facilitates learning of the agent,
ensures more energy efficient movements as well as robustness towards new
unseen environments. Furthermore, this comparison sheds light on the importance
of modularity in hierarchical architectures to solve complex goal-directed
tasks. We provide an open-source code implementation of our architecture
(https://github.com/wzaielamri/hddrl).
</p></li>
</ul>

<h3>Title: Bayesian Spline Learning for Equation Discovery of Nonlinear Dynamics with Quantified Uncertainty. (arXiv:2210.08095v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08095">http://arxiv.org/abs/2210.08095</a></li>
<li>Code URL: <a href="https://github.com/luningsun/splinelearningequation">https://github.com/luningsun/splinelearningequation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08095] Bayesian Spline Learning for Equation Discovery of Nonlinear Dynamics with Quantified Uncertainty](http://arxiv.org/abs/2210.08095)</code></li>
<li>Summary: <p>Nonlinear dynamics are ubiquitous in science and engineering applications,
but the physics of most complex systems is far from being fully understood.
Discovering interpretable governing equations from measurement data can help us
understand and predict the behavior of complex dynamic systems. Although
extensive work has recently been done in this field, robustly distilling
explicit model forms from very sparse data with considerable noise remains
intractable. Moreover, quantifying and propagating the uncertainty of the
identified system from noisy data is challenging, and relevant literature is
still limited. To bridge this gap, we develop a novel Bayesian spline learning
framework to identify parsimonious governing equations of nonlinear
(spatio)temporal dynamics from sparse, noisy data with quantified uncertainty.
The proposed method utilizes spline basis to handle the data scarcity and
measurement noise, upon which a group of derivatives can be accurately computed
to form a library of candidate model terms. The equation residuals are used to
inform the spline learning in a Bayesian manner, where approximate Bayesian
uncertainty calibration techniques are employed to approximate posterior
distributions of the trainable parameters. To promote the sparsity, an
iterative sequential-threshold Bayesian learning approach is developed, using
the alternative direction optimization strategy to systematically approximate
L0 sparsity constraints. The proposed algorithm is evaluated on multiple
nonlinear dynamical systems governed by canonical ordinary and partial
differential equations, and the merit/superiority of the proposed method is
demonstrated by comparison with state-of-the-art methods.
</p></li>
</ul>

<h3>Title: D.MCA: Outlier Detection with Explicit Micro-Cluster Assignments. (arXiv:2210.08212v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08212">http://arxiv.org/abs/2210.08212</a></li>
<li>Code URL: <a href="https://github.com/11hifish/d.mca">https://github.com/11hifish/d.mca</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08212] D](http://arxiv.org/abs/2210.08212)</code></li>
<li>Summary: <p>How can we detect outliers, both scattered and clustered, and also explicitly
assign them to respective micro-clusters, without knowing apriori how many
micro-clusters exist? How can we perform both tasks in-house, i.e., without any
post-hoc processing, so that both detection and assignment can benefit
simultaneously from each other? Presenting outliers in separate micro-clusters
is informative to analysts in many real-world applications. However, a na\"ive
solution based on post-hoc clustering of the outliers detected by any existing
method suffers from two main drawbacks: (a) appropriate hyperparameter values
are commonly unknown for clustering, and most algorithms struggle with clusters
of varying shapes and densities; (b) detection and assignment cannot benefit
from one another. In this paper, we propose D.MCA to $\underline{D}$etect
outliers with explicit $\underline{M}$icro-$\underline{C}$luster
$\underline{A}$ssignment. Our method performs both detection and assignment
iteratively, and in-house, by using a novel strategy that prunes entire
micro-clusters out of the training set to improve the performance of the
detection. It also benefits from a novel strategy that avoids clustered
outliers to mask each other, which is a well-known problem in the literature.
Also, D.MCA is designed to be robust to a critical hyperparameter by employing
a hyperensemble "warm up" phase. Experiments performed on 16 real-world and
synthetic datasets demonstrate that D.MCA outperforms 8 state-of-the-art
competitors, especially on the explicit outlier micro-cluster assignment task.
</p></li>
</ul>

<h3>Title: Improving Your Graph Neural Networks: A High-Frequency Booster. (arXiv:2210.08251v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08251">http://arxiv.org/abs/2210.08251</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08251] Improving Your Graph Neural Networks: A High-Frequency Booster](http://arxiv.org/abs/2210.08251)</code></li>
<li>Summary: <p>Graph neural networks (GNNs) hold the promise of learning efficient
representations of graph-structured data, and one of its most important
applications is semi-supervised node classification. However, in this
application, GNN frameworks tend to fail due to the following issues:
over-smoothing and heterophily. The most popular GNNs are known to be focused
on the message-passing framework, and recent research shows that these GNNs are
often bounded by low-pass filters from a signal processing perspective. We thus
incorporate high-frequency information into GNNs to alleviate this genetic
problem. In this paper, we argue that the complement of the original graph
incorporates a high-pass filter and propose Complement Laplacian Regularization
(CLAR) for an efficient enhancement of high-frequency components. The
experimental results demonstrate that CLAR helps GNNs tackle over-smoothing,
improving the expressiveness of heterophilic graphs, which adds up to 3.6%
improvement over popular baselines and ensures topological robustness.
</p></li>
</ul>

<h3>Title: Linear Scalarization for Byzantine-robust learning on non-IID data. (arXiv:2210.08287v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08287">http://arxiv.org/abs/2210.08287</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08287] Linear Scalarization for Byzantine-robust learning on non-IID data](http://arxiv.org/abs/2210.08287)</code></li>
<li>Summary: <p>In this work we study the problem of Byzantine-robust learning when data
among clients is heterogeneous. We focus on poisoning attacks targeting the
convergence of SGD. Although this problem has received great attention; the
main Byzantine defenses rely on the IID assumption causing them to fail when
data distribution is non-IID even with no attack. We propose the use of Linear
Scalarization (LS) as an enhancing method to enable current defenses to
circumvent Byzantine attacks in the non-IID setting. The LS method is based on
the incorporation of a trade-off vector that penalizes the suspected malicious
clients. Empirical analysis corroborates that the proposed LS variants are
viable in the IID setting. For mild to strong non-IID data splits, LS is either
comparable or outperforming current approaches under state-of-the-art Byzantine
attack scenarios.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: A Novel Few-Shot Relation Extraction Pipeline Based on Adaptive Prototype Fusion. (arXiv:2210.08242v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08242">http://arxiv.org/abs/2210.08242</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08242] A Novel Few-Shot Relation Extraction Pipeline Based on Adaptive Prototype Fusion](http://arxiv.org/abs/2210.08242)</code></li>
<li>Summary: <p>Few-shot relation extraction (FSRE) aims at recognizing unseen relations by
learning with merely a handful of annotated instances. To more effectively
generalize to new relations, this paper proposes a novel pipeline for the FSRE
task based on adaptive prototype fusion. Specifically, for each relation class,
the pipeline fully explores the relation information by concatenating two types
of embedding, and then elaborately combine the relation representation with the
adaptive prototype fusion mechanism. The whole framework can be effectively and
efficiently optimized in an end-to-end fashion. Experiments on the benchmark
dataset FewRel 1.0 show a significant improvement of our method against
state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Trajectory Prediction for Vehicle Conflict Identification at Intersections Using Sequence-to-Sequence Recurrent Neural Networks. (arXiv:2210.08009v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08009">http://arxiv.org/abs/2210.08009</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08009] Trajectory Prediction for Vehicle Conflict Identification at Intersections Using Sequence-to-Sequence Recurrent Neural Networks](http://arxiv.org/abs/2210.08009)</code></li>
<li>Summary: <p>Surrogate safety measures in the form of conflict indicators are
indispensable components of the proactive traffic safety toolbox. Conflict
indicators can be classified into past-trajectory-based conflicts and
predicted-trajectory-based conflicts. While the calculation of the former class
of conflicts is deterministic and unambiguous, the latter category is computed
using predicted vehicle trajectories and is thus more stochastic. Consequently,
the accuracy of prediction-based conflicts is contingent on the accuracy of the
utilized trajectory prediction algorithm. Trajectory prediction can be a
challenging task, particularly at intersections where vehicle maneuvers are
diverse. Furthermore, due to limitations relating to the road user trajectory
extraction pipelines, accurate geometric representation of vehicles during
conflict analysis is a challenging task. Misrepresented geometries distort the
real distances between vehicles under observation. In this research, a
prediction-based conflict identification methodology was proposed. A
sequence-to-sequence Recurrent Neural Network was developed to sequentially
predict future vehicle trajectories for up to 3 seconds ahead. Furthermore, the
proposed network was trained using the CitySim Dataset to forecast both future
vehicle positions and headings to facilitate the prediction of future bounding
boxes, thus maintaining accurate vehicle geometric representations. It was
experimentally determined that the proposed method outperformed frequently used
trajectory prediction models for conflict analysis at intersections. A
comparison between Time-to-Collision (TTC) conflict identification using
vehicle bounding boxes versus the commonly used vehicle center points for
geometric representation was conducted. Compared to the bounding box method,
the center point approach often failed to identify TTC conflicts or
underestimated their severity.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning. (arXiv:2210.08090v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08090">http://arxiv.org/abs/2210.08090</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08090] Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning](http://arxiv.org/abs/2210.08090)</code></li>
<li>Summary: <p>An oft-cited challenge of federated learning is the presence of
heterogeneity. \emph{Data heterogeneity} refers to the fact that data from
different clients may follow very different distributions. \emph{System
heterogeneity} refers to the fact that client devices have different system
capabilities. A considerable number of federated optimization methods address
this challenge. In the literature, empirical evaluations usually start
federated training from random initialization. However, in many practical
applications of federated learning, the server has access to proxy data for the
training task that can be used to pre-train a model before starting federated
training. We empirically study the impact of starting from a pre-trained model
in federated learning using four standard federated learning benchmark
datasets. Unsurprisingly, starting from a pre-trained model reduces the
training time required to reach a target error rate and enables the training of
more accurate models (up to 40\%) than is possible when starting from random
initialization. Surprisingly, we also find that starting federated learning
from a pre-trained initialization reduces the effect of both data and system
heterogeneity. We recommend that future work proposing and evaluating federated
optimization methods evaluate the performance when starting from random and
pre-trained initializations. We also believe this study raises several
questions for further work on understanding the role of heterogeneity in
federated optimization.
</p></li>
</ul>

<h3>Title: A Primal-Dual Algorithm for Hybrid Federated Learning. (arXiv:2210.08106v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08106">http://arxiv.org/abs/2210.08106</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08106] A Primal-Dual Algorithm for Hybrid Federated Learning](http://arxiv.org/abs/2210.08106)</code></li>
<li>Summary: <p>Very few methods for hybrid federated learning, where clients only hold
subsets of both features and samples, exist. Yet, this scenario is very
important in practical settings. We provide a fast, robust algorithm for hybrid
federated learning that hinges on Fenchel Duality. We prove the convergence of
the algorithm to the same solution as if the model was trained centrally in a
variety of practical regimes. Furthermore, we provide experimental results that
demonstrate the performance improvements of the algorithm over a commonly used
method in federated learning, FedAvg. We also provide privacy considerations
and necessary steps to protect client data.
</p></li>
</ul>

<h3>Title: FedCross: Towards Accurate Federated Learning via Multi-Model Cross Aggregation. (arXiv:2210.08285v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08285">http://arxiv.org/abs/2210.08285</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08285] FedCross: Towards Accurate Federated Learning via Multi-Model Cross Aggregation](http://arxiv.org/abs/2210.08285)</code></li>
<li>Summary: <p>Due to the remarkable performance in preserving data privacy for
decentralized data scenarios, Federated Learning (FL) has been considered as a
promising distributed machine learning paradigm to deal with data silos
problems. Typically, conventional FL approaches adopts a one-to-multi training
scheme, where the cloud server keeps only one single global model for all the
involved clients for the purpose of model aggregation. However, this scheme
suffers from inferior classification performance, since only one global model
cannot always accommodate all the incompatible convergence directions of local
models, resulting in a low convergence rate and classification accuracy. To
address this issue, this paper presents an efficient FL framework named
FedCross, which adopts a novel multi-to-multi FL training scheme based on our
proposed similarity-based multi-model cross aggregation method. Unlike
traditional FL methods, in each round of FL training, FedCross uses a small set
of distinct intermediate models to conduct weighted fusion under the guidance
of model similarities. In this way, the intermediate models used by FedCross
can sufficiently respect the convergence characteristics of clients, thus
leading to much fewer conflicts in tuning the convergence directions of
clients. Finally, in the deployment stage, FedCross forms a global model for
all the clients by performing the federated averaging on the trained immediate
models.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Handling missing values in healthcare data: A systematic review of deep learning-based imputation techniques. (arXiv:2210.08258v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08258">http://arxiv.org/abs/2210.08258</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08258] Handling missing values in healthcare data: A systematic review of deep learning-based imputation techniques](http://arxiv.org/abs/2210.08258)</code></li>
<li>Summary: <p>Objective: The proper handling of missing values is critical to delivering
reliable estimates and decisions, especially in high-stakes fields such as
clinical research. The increasing diversity and complexity of data have led
many researchers to develop deep learning (DL)-based imputation techniques. We
conducted a systematic review to evaluate the use of these techniques, with a
particular focus on data types, aiming to assist healthcare researchers from
various disciplines in dealing with missing values.
</p></li>
</ul>

<p>Methods: We searched five databases (MEDLINE, Web of Science, Embase, CINAHL,
and Scopus) for articles published prior to August 2021 that applied DL-based
models to imputation. We assessed selected publications from four perspectives:
health data types, model backbone (i.e., main architecture), imputation
strategies, and comparison with non-DL-based methods. Based on data types, we
created an evidence map to illustrate the adoption of DL models.
</p>
<p>Results: We included 64 articles, of which tabular static (26.6%, 17/64) and
temporal data (37.5%, 24/64) were the most frequently investigated. We found
that model backbone(s) differed among data types as well as the imputation
strategy. The "integrated" strategy, that is, the imputation task being solved
concurrently with downstream tasks, was popular for tabular temporal (50%,
12/24) and multi-modal data (71.4%, 5/7), but limited for other data types.
Moreover, DL-based imputation methods yielded better imputation accuracy in
most studies, compared with non-DL-based methods.
</p>
<p>Conclusion: DL-based imputation models can be customized based on data type,
addressing the corresponding missing patterns, and its associated "integrated"
strategy can enhance the efficacy of imputation, especially in scenarios where
data is complex. Future research may focus on the portability and fairness of
DL-based models for healthcare data imputation.
</p>

<h2>interpretability</h2>
<h3>Title: UniRPG: Unified Discrete Reasoning over Table and Text as Program Generation. (arXiv:2210.08249v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.08249">http://arxiv.org/abs/2210.08249</a></li>
<li>Code URL: <a href="https://github.com/jd-ai-research-nlp/unirpg">https://github.com/jd-ai-research-nlp/unirpg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.08249] UniRPG: Unified Discrete Reasoning over Table and Text as Program Generation](http://arxiv.org/abs/2210.08249)</code></li>
<li>Summary: <p>Question answering requiring discrete reasoning, e.g., arithmetic computing,
comparison, and counting, over knowledge is a challenging task. In this paper,
we propose UniRPG, a semantic-parsing-based approach advanced in
interpretability and scalability, to perform unified discrete reasoning over
heterogeneous knowledge resources, i.e., table and text, as program generation.
Concretely, UniRPG consists of a neural programmer and a symbolic program
executor, where a program is the composition of a set of pre-defined general
atomic and higher-order operations and arguments extracted from table and text.
First, the programmer parses a question into a program by generating operations
and copying arguments, and then the executor derives answers from table and
text based on the program. To alleviate the costly program annotation issue, we
design a distant supervision approach for programmer learning, where pseudo
programs are automatically constructed without annotated derivations. Extensive
experiments on the TAT-QA dataset show that UniRPG achieves tremendous
improvements and enhances interpretability and scalability compared with
state-of-the-art methods, even without derivation annotation. Moreover, it
achieves promising performance on the textual dataset DROP without derivations.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
