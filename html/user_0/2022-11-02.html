<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Unsafe's Betrayal: Abusing Unsafe Rust in Binary Reverse Engineering toward Finding Memory-safety Bugs via Machine Learning. (arXiv:2211.00111v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00111">http://arxiv.org/abs/2211.00111</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00111] Unsafe's Betrayal: Abusing Unsafe Rust in Binary Reverse Engineering toward Finding Memory-safety Bugs via Machine Learning](http://arxiv.org/abs/2211.00111)</code></li>
<li>Summary: <p>Memory-safety bugs introduce critical software-security issues. Rust provides
memory-safe mechanisms to avoid memory-safety bugs in programming, while still
allowing unsafe escape hatches via unsafe code. However, the unsafe code that
enhances the usability of Rust provides clear spots for finding memory-safety
bugs in Rust source code. In this paper, we claim that these unsafe spots can
still be identifiable in Rust binary code via machine learning and be leveraged
for finding memory-safety bugs. To support our claim, we propose the tool
textttrustspot, that enables reverse engineering to learn an unsafe classifier
that proposes a list of functions in Rust binaries for downstream analysis. We
empirically show that the function proposals by textttrustspot can recall
$92.92\%$ of memory-safety bugs, while it covers only $16.79\%$ of the entire
binary code. As an application, we demonstrate that the function proposals are
used in targeted fuzzing on Rust packages, which contribute to reducing the
fuzzing time compared to non-targeted fuzzing.
</p></li>
</ul>

<h3>Title: Empowering Data Centers for Next Generation Trusted Computing. (arXiv:2211.00306v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00306">http://arxiv.org/abs/2211.00306</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00306] Empowering Data Centers for Next Generation Trusted Computing](http://arxiv.org/abs/2211.00306)</code></li>
<li>Summary: <p>Modern data centers have grown beyond CPU nodes to provide domain-specific
accelerators such as GPUs and FPGAs to their customers. From a security
standpoint, cloud customers want to protect their data. They are willing to pay
additional costs for trusted execution environments such as enclaves provided
by Intel SGX and AMD SEV. Unfortunately, the customers have to make a critical
choice -- either use domain-specific accelerators for speed or use CPU-based
confidential computing solutions. To bridge this gap, we aim to enable
data-center scale confidential computing that expands across CPUs and
accelerators. We argue that having wide-scale TEE-support for accelerators
presents a technically easier solution, but is far away from being a reality.
Instead, our hybrid design provides enclaved execution guarantees for
computation distributed over multiple CPU nodes and devices with/without TEE
support. Our solution scales gracefully in two dimensions -- it can handle a
large number of heterogeneous nodes and it can accommodate TEE-enabled devices
as and when they are available in the future. We observe marginal overheads of
$0.42$--$8\%$ on real-world AI data center workloads that are independent of
the number of nodes in the data center. We add custom TEE support to two
accelerators (AI and storage) and integrate it into our solution, thus
demonstrating that it can cater to future TEE devices.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: HDNet: Hierarchical Dynamic Network for Gait Recognition using Millimeter-Wave Radar. (arXiv:2211.00312v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00312">http://arxiv.org/abs/2211.00312</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00312] HDNet: Hierarchical Dynamic Network for Gait Recognition using Millimeter-Wave Radar](http://arxiv.org/abs/2211.00312)</code></li>
<li>Summary: <p>Gait recognition is widely used in diversified practical applications.
Currently, the most prevalent approach is to recognize human gait from RGB
images, owing to the progress of computer vision technologies. Nevertheless,
the perception capability of RGB cameras deteriorates in rough circumstances,
and visual surveillance may cause privacy invasion. Due to the robustness and
non-invasive feature of millimeter wave (mmWave) radar, radar-based gait
recognition has attracted increasing attention in recent years. In this
research, we propose a Hierarchical Dynamic Network (HDNet) for gait
recognition using mmWave radar. In order to explore more dynamic information,
we propose point flow as a novel point clouds descriptor. We also devise a
dynamic frame sampling module to promote the efficiency of computation without
deteriorating performance noticeably. To prove the superiority of our methods,
we perform extensive experiments on two public mmWave radar-based gait
recognition datasets, and the results demonstrate that our model is superior to
existing state-of-the-art methods.
</p></li>
</ul>

<h3>Title: No-audio speaking status detection in crowded settings via visual pose-based filtering and wearable acceleration. (arXiv:2211.00549v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00549">http://arxiv.org/abs/2211.00549</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00549] No-audio speaking status detection in crowded settings via visual pose-based filtering and wearable acceleration](http://arxiv.org/abs/2211.00549)</code></li>
<li>Summary: <p>Recognizing who is speaking in a crowded scene is a key challenge towards the
understanding of the social interactions going on within. Detecting speaking
status from body movement alone opens the door for the analysis of social
scenes in which personal audio is not obtainable. Video and wearable sensors
make it possible recognize speaking in an unobtrusive, privacy-preserving way.
When considering the video modality, in action recognition problems, a bounding
box is traditionally used to localize and segment out the target subject, to
then recognize the action taking place within it. However, cross-contamination,
occlusion, and the articulated nature of the human body, make this approach
challenging in a crowded scene. Here, we leverage articulated body poses for
subject localization and in the subsequent speech detection stage. We show that
the selection of local features around pose keypoints has a positive effect on
generalization performance while also significantly reducing the number of
local features considered, making for a more efficient method. Using two
in-the-wild datasets with different viewpoints of subjects, we investigate the
role of cross-contamination in this effect. We additionally make use of
acceleration measured through wearable sensors for the same task, and present a
multimodal approach combining both methods.
</p></li>
</ul>

<h3>Title: Amplifying Membership Exposure via Data Poisoning. (arXiv:2211.00463v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00463">http://arxiv.org/abs/2211.00463</a></li>
<li>Code URL: <a href="https://github.com/yfchen1994/poisoning_membership">https://github.com/yfchen1994/poisoning_membership</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00463] Amplifying Membership Exposure via Data Poisoning](http://arxiv.org/abs/2211.00463)</code></li>
<li>Summary: <p>As in-the-wild data are increasingly involved in the training stage, machine
learning applications become more susceptible to data poisoning attacks. Such
attacks typically lead to test-time accuracy degradation or controlled
misprediction. In this paper, we investigate the third type of exploitation of
data poisoning - increasing the risks of privacy leakage of benign training
samples. To this end, we demonstrate a set of data poisoning attacks to amplify
the membership exposure of the targeted class. We first propose a generic
dirty-label attack for supervised classification algorithms. We then propose an
optimization-based clean-label attack in the transfer learning scenario,
whereby the poisoning samples are correctly labeled and look "natural" to evade
human moderation. We extensively evaluate our attacks on computer vision
benchmarks. Our results show that the proposed attacks can substantially
increase the membership inference precision with minimum overall test-time
model performance degradation. To mitigate the potential negative impacts of
our attacks, we also investigate feasible countermeasures.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Synthetic ID Card Image Generation for Improving Presentation Attack Detection. (arXiv:2211.00098v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00098">http://arxiv.org/abs/2211.00098</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00098] Synthetic ID Card Image Generation for Improving Presentation Attack Detection](http://arxiv.org/abs/2211.00098)</code></li>
<li>Summary: <p>Currently, it is ever more common to access online services for activities
which formerly required physical attendance. From banking operations to visa
applications, a significant number of processes have been digitised, especially
since the advent of the COVID-19 pandemic, requiring remote biometric
authentication of the user. On the downside, some subjects intend to interfere
with the normal operation of remote systems for personal profit by using fake
identity documents, such as passports and ID cards. Deep learning solutions to
detect such frauds have been presented in the literature. However, due to
privacy concerns and the sensitive nature of personal identity documents,
developing a dataset with the necessary number of examples for training deep
neural networks is challenging. This work explores three methods for
synthetically generating ID card images to increase the amount of data while
training fraud-detection networks. These methods include computer vision
algorithms and Generative Adversarial Networks. Our results indicate that
databases can be supplemented with synthetic images without any loss in
performance for the print/scan Presentation Attack Instrument Species (PAIS)
and a loss in performance of 1% for the screen capture PAIS.
</p></li>
</ul>

<h3>Title: Universal Perturbation Attack on Differentiable No-Reference Image- and Video-Quality Metrics. (arXiv:2211.00366v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00366">http://arxiv.org/abs/2211.00366</a></li>
<li>Code URL: <a href="https://github.com/katiashh/uap_attack_on_quality_metrics">https://github.com/katiashh/uap_attack_on_quality_metrics</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00366] Universal Perturbation Attack on Differentiable No-Reference Image- and Video-Quality Metrics](http://arxiv.org/abs/2211.00366)</code></li>
<li>Summary: <p>Universal adversarial perturbation attacks are widely used to analyze image
classifiers that employ convolutional neural networks. Nowadays, some attacks
can deceive image- and video-quality metrics. So sustainability analysis of
these metrics is important. Indeed, if an attack can confuse the metric, an
attacker can easily increase quality scores. When developers of image- and
video-algorithms can boost their scores through detached processing, algorithm
comparisons are no longer fair. Inspired by the idea of universal adversarial
perturbation for classifiers, we suggest a new method to attack differentiable
no-reference quality metrics through universal perturbation. We applied this
method to seven no-reference image- and video-quality metrics (PaQ-2-PiQ,
Linearity, VSFA, MDTVSFA, KonCept512, Nima and SPAQ). For each one, we trained
a universal perturbation that increases the respective scores. We also propose
a method for assessing metric stability and identify the metrics that are the
most vulnerable and the most resistant to our attack. The existence of
successful universal perturbations appears to diminish the metric's ability to
provide reliable scores. We therefore recommend our proposed method as an
additional verification of metric reliability to complement traditional
subjective tests and benchmarks.
</p></li>
</ul>

<h3>Title: Adversarial Policies Beat Professional-Level Go AIs. (arXiv:2211.00241v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00241">http://arxiv.org/abs/2211.00241</a></li>
<li>Code URL: <a href="https://github.com/humancompatibleai/go_attack">https://github.com/humancompatibleai/go_attack</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00241] Adversarial Policies Beat Professional-Level Go AIs](http://arxiv.org/abs/2211.00241)</code></li>
<li>Summary: <p>We attack the state-of-the-art Go-playing AI system, KataGo, by training an
adversarial policy that plays against a frozen KataGo victim. Our attack
achieves a >99% win-rate against KataGo without search, and a >50% win-rate
when KataGo uses enough search to be near-superhuman. To the best of our
knowledge, this is the first successful end-to-end attack against a Go AI
playing at the level of a top human professional. Notably, the adversary does
not win by learning to play Go better than KataGo -- in fact, the adversary is
easily beaten by human amateurs. Instead, the adversary wins by tricking KataGo
into ending the game prematurely at a point that is favorable to the adversary.
Our results demonstrate that even professional-level AI systems may harbor
surprising failure modes. See https://goattack.alignmentfund.org/ for example
games.
</p></li>
</ul>

<h3>Title: Adversarial Training with Complementary Labels: On the Benefit of Gradually Informative Attacks. (arXiv:2211.00269v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00269">http://arxiv.org/abs/2211.00269</a></li>
<li>Code URL: <a href="https://github.com/RoyalSkye/ATCL">https://github.com/RoyalSkye/ATCL</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00269] Adversarial Training with Complementary Labels: On the Benefit of Gradually Informative Attacks](http://arxiv.org/abs/2211.00269)</code></li>
<li>Summary: <p>Adversarial training (AT) with imperfect supervision is significant but
receives limited attention. To push AT towards more practical scenarios, we
explore a brand new yet challenging setting, i.e., AT with complementary labels
(CLs), which specify a class that a data sample does not belong to. However,
the direct combination of AT with existing methods for CLs results in
consistent failure, but not on a simple baseline of two-stage training. In this
paper, we further explore the phenomenon and identify the underlying challenges
of AT with CLs as intractable adversarial optimization and low-quality
adversarial examples. To address the above problems, we propose a new learning
strategy using gradually informative attacks, which consists of two critical
components: 1) Warm-up Attack (Warm-up) gently raises the adversarial
perturbation budgets to ease the adversarial optimization with CLs; 2)
Pseudo-Label Attack (PLA) incorporates the progressively informative model
predictions into a corrected complementary loss. Extensive experiments are
conducted to demonstrate the effectiveness of our method on a range of
benchmarked datasets. The code is publicly available at:
https://github.com/RoyalSkye/ATCL.
</p></li>
</ul>

<h3>Title: HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly Detection. (arXiv:2211.00277v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00277">http://arxiv.org/abs/2211.00277</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00277] HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly Detection](http://arxiv.org/abs/2211.00277)</code></li>
<li>Summary: <p>Network or physical attacks on industrial equipment or computer systems may
cause massive losses. Therefore, a quick and accurate anomaly detection (AD)
based on monitoring data, especially the multivariate time-series (MTS) data,
is of great significance. As the key step of anomaly detection for MTS data,
learning the relations among different variables has been explored by many
approaches. However, most of the existing approaches do not consider the
heterogeneity between variables, that is, different types of variables
(continuous numerical variables, discrete categorical variables or hybrid
variables) may have different and distinctive edge distributions. In this
paper, we propose a novel semi-supervised anomaly detection framework based on
a heterogeneous feature network (HFN) for MTS, learning heterogeneous structure
information from a mass of unlabeled time-series data to improve the accuracy
of anomaly detection, and using attention coefficient to provide an explanation
for the detected anomalies. Specifically, we first combine the embedding
similarity subgraph generated by sensor embedding and feature value similarity
subgraph generated by sensor values to construct a time-series heterogeneous
graph, which fully utilizes the rich heterogeneous mutual information among
variables. Then, a prediction model containing nodes and channel attentions is
jointly optimized to obtain better time-series representations. This approach
fuses the state-of-the-art technologies of heterogeneous graph structure
learning (HGSL) and representation learning. The experiments on four sensor
datasets from real-world applications demonstrate that our approach detects the
anomalies more accurately than those baseline approaches, thus providing a
basis for the rapid positioning of anomalies.
</p></li>
</ul>

<h3>Title: Zero Day Threat Detection Using Metric Learning Autoencoders. (arXiv:2211.00441v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00441">http://arxiv.org/abs/2211.00441</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00441] Zero Day Threat Detection Using Metric Learning Autoencoders](http://arxiv.org/abs/2211.00441)</code></li>
<li>Summary: <p>The proliferation of zero-day threats (ZDTs) to companies' networks has been
immensely costly and requires novel methods to scan traffic for malicious
behavior at massive scale. The diverse nature of normal behavior along with the
huge landscape of attack types makes deep learning methods an attractive option
for their ability to capture highly-nonlinear behavior patterns. In this paper,
the authors demonstrate an improvement upon a previously introduced
methodology, which used a dual-autoencoder approach to identify ZDTs in network
flow telemetry. In addition to the previously-introduced asset-level graph
features, which help abstractly represent the role of a host in its network,
this new model uses metric learning to train the second autoencoder on labeled
attack data. This not only produces stronger performance, but it has the added
advantage of improving the interpretability of the model by allowing for
multiclass classification in the latent space. This can potentially save human
threat hunters time when they investigate predicted ZDTs by showing them which
known attack classes were nearby in the latent space. The models presented here
are also trained and evaluated with two more datasets, and continue to show
promising results even when generalizing to new network topologies.
</p></li>
</ul>

<h3>Title: The Perils of Learning From Unlabeled Data: Backdoor Attacks on Semi-supervised Learning. (arXiv:2211.00453v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00453">http://arxiv.org/abs/2211.00453</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00453] The Perils of Learning From Unlabeled Data: Backdoor Attacks on Semi-supervised Learning](http://arxiv.org/abs/2211.00453)</code></li>
<li>Summary: <p>Semi-supervised machine learning (SSL) is gaining popularity as it reduces
the cost of training ML models. It does so by using very small amounts of
(expensive, well-inspected) labeled data and large amounts of (cheap,
non-inspected) unlabeled data. SSL has shown comparable or even superior
performances compared to conventional fully-supervised ML techniques.
</p></li>
</ul>

<p>In this paper, we show that the key feature of SSL that it can learn from
(non-inspected) unlabeled data exposes SSL to strong poisoning attacks. In
fact, we argue that, due to its reliance on non-inspected unlabeled data,
poisoning is a much more severe problem in SSL than in conventional
fully-supervised ML.
</p>
<p>Specifically, we design a backdoor poisoning attack on SSL that can be
conducted by a weak adversary with no knowledge of target SSL pipeline. This is
unlike prior poisoning attacks in fully-supervised settings that assume strong
adversaries with practically-unrealistic capabilities. We show that by
poisoning only 0.2% of the unlabeled training data, our attack can cause
misclassification of more than 80% of test inputs (when they contain the
adversary's backdoor trigger). Our attacks remain effective across twenty
combinations of benchmark datasets and SSL algorithms, and even circumvent the
state-of-the-art defenses against backdoor attacks. Our work raises significant
concerns about the practical utility of existing SSL algorithms.
</p>

<h2>robust</h2>
<h3>Title: SAGE: Saliency-Guided Mixup with Optimal Rearrangements. (arXiv:2211.00113v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00113">http://arxiv.org/abs/2211.00113</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00113] SAGE: Saliency-Guided Mixup with Optimal Rearrangements](http://arxiv.org/abs/2211.00113)</code></li>
<li>Summary: <p>Data augmentation is a key element for training accurate models by reducing
overfitting and improving generalization. For image classification, the most
popular data augmentation techniques range from simple photometric and
geometrical transformations, to more complex methods that use visual saliency
to craft new training examples. As augmentation methods get more complex, their
ability to increase the test accuracy improves, yet, such methods become
cumbersome, inefficient and lead to poor out-of-domain generalization, as we
show in this paper. This motivates a new augmentation technique that allows for
high accuracy gains while being simple, efficient (i.e., minimal computation
overhead) and generalizable. To this end, we introduce Saliency-Guided Mixup
with Optimal Rearrangements (SAGE), which creates new training examples by
rearranging and mixing image pairs using visual saliency as guidance. By
explicitly leveraging saliency, SAGE promotes discriminative foreground objects
and produces informative new images useful for training. We demonstrate on
CIFAR-10 and CIFAR-100 that SAGE achieves better or comparable performance to
the state of the art while being more efficient. Additionally, evaluations in
the out-of-distribution setting, and few-shot learning on mini-ImageNet, show
that SAGE achieves improved generalization performance without trading off
robustness.
</p></li>
</ul>

<h3>Title: Is Facial Recognition Biased at Near-Infrared Spectrum As Well?. (arXiv:2211.00129v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00129">http://arxiv.org/abs/2211.00129</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00129] Is Facial Recognition Biased at Near-Infrared Spectrum As Well?](http://arxiv.org/abs/2211.00129)</code></li>
<li>Summary: <p>Published academic research and media articles suggest face recognition is
biased across demographics. Specifically, unequal performance is obtained for
women, dark-skinned people, and older adults. However, these published studies
have examined the bias of facial recognition in the visible spectrum (VIS).
Factors such as facial makeup, facial hair, skin color, and illumination
variation have been attributed to the bias of this technology at the VIS. The
near-infrared (NIR) spectrum offers an advantage over the VIS in terms of
robustness to factors such as illumination changes, facial makeup, and skin
color. Therefore, it is worthwhile to investigate the bias of facial
recognition at the near-infrared spectrum (NIR). This first study investigates
the bias of the face recognition systems at the NIR spectrum. To this aim, two
popular NIR facial image datasets namely, CASIA-Face-Africa and Notre-Dame-NIVL
consisting of African and Caucasian subjects, respectively, are used to
investigate the bias of facial recognition technology across gender and race.
Interestingly, experimental results suggest equitable face recognition
performance across gender and race at the NIR spectrum.
</p></li>
</ul>

<h3>Title: Improving Motion Forecasting for Autonomous Driving with the Cycle Consistency Loss. (arXiv:2211.00149v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00149">http://arxiv.org/abs/2211.00149</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00149] Improving Motion Forecasting for Autonomous Driving with the Cycle Consistency Loss](http://arxiv.org/abs/2211.00149)</code></li>
<li>Summary: <p>Robust motion forecasting of the dynamic scene is a critical component of an
autonomous vehicle. It is a challenging problem due to the heterogeneity in the
scene and the inherent uncertainties in the problem. To improve the accuracy of
motion forecasting, in this work, we identify a new consistency constraint in
this task, that is an agent's future trajectory should be coherent with its
history observations and visa versa. To leverage this property, we propose a
novel cycle consistency training scheme and define a novel cycle loss to
encourage this consistency. In particular, we reverse the predicted future
trajectory backward in time and feed it back into the prediction model to
predict the history and compute the loss as an additional cycle loss term.
Through our experiments on the Argoverse dataset, we demonstrate that cycle
loss can improve the performance of competitive motion forecasting models.
</p></li>
</ul>

<h3>Title: Frequency Cam: Imaging Periodic Signals in Real-Time. (arXiv:2211.00198v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00198">http://arxiv.org/abs/2211.00198</a></li>
<li>Code URL: <a href="https://github.com/berndpfrommer/frequency_cam">https://github.com/berndpfrommer/frequency_cam</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00198] Frequency Cam: Imaging Periodic Signals in Real-Time](http://arxiv.org/abs/2211.00198)</code></li>
<li>Summary: <p>Due to their high temporal resolution and large dynamic range event cameras
are uniquely suited for the analysis of time-periodic signals in an image. In
this work we present an efficient and fully asynchronous event camera algorithm
for detecting the fundamental frequency at which image pixels flicker. The
algorithm employs a second-order digital infinite impulse response (IIR) filter
to perform an approximate per-pixel brightness reconstruction and is more
robust to high-frequency noise than the baseline method we compare to. We
further demonstrate that using the falling edge of the signal leads to more
accurate period estimates than the rising edge, and that for certain signals
interpolating the zero-level crossings can further increase accuracy. Our
experiments find that the outstanding capabilities of the camera in detecting
frequencies up to 64kHz for a single pixel do not carry over to full sensor
imaging as readout bandwidth limitations become a serious obstacle. This
suggests that a hardware implementation closer to the sensor will allow for
greatly improved frequency imaging. We discuss the important design parameters
for fullsensor frequency imaging and present Frequency Cam, an open-source
implementation as a ROS node that can run on a single core of a laptop CPU at
more than 50 million events per second. It produces results that are
qualitatively very similar to those obtained from the closed source vibration
analysis module in Prophesee's Metavision Toolkit. The code for Frequency Cam
and a demonstration video can be found at
https://github.com/berndpfrommer/frequency_cam
</p></li>
</ul>

<h3>Title: GMF: General Multimodal Fusion Framework for Correspondence Outlier Rejection. (arXiv:2211.00207v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00207">http://arxiv.org/abs/2211.00207</a></li>
<li>Code URL: <a href="https://github.com/xiaoshuihuang/gmf">https://github.com/xiaoshuihuang/gmf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00207] GMF: General Multimodal Fusion Framework for Correspondence Outlier Rejection](http://arxiv.org/abs/2211.00207)</code></li>
<li>Summary: <p>Rejecting correspondence outliers enables to boost the correspondence
quality, which is a critical step in achieving high point cloud registration
accuracy. The current state-of-the-art correspondence outlier rejection methods
only utilize the structure features of the correspondences. However, texture
information is critical to reject the correspondence outliers in our human
vision system. In this paper, we propose General Multimodal Fusion (GMF) to
learn to reject the correspondence outliers by leveraging both the structure
and texture information. Specifically, two cross-attention-based fusion layers
are proposed to fuse the texture information from paired images and structure
information from point correspondences. Moreover, we propose a convolutional
position encoding layer to enhance the difference between Tokens and enable the
encoding feature pay attention to neighbor information. Our position encoding
layer will make the cross-attention operation integrate both local and global
information. Experiments on multiple datasets(3DMatch, 3DLoMatch, KITTI) and
recent state-of-the-art models (3DRegNet, DGR, PointDSC) prove that our GMF
achieves wide generalization ability and consistently improves the point cloud
registration accuracy. Furthermore, several ablation studies demonstrate the
robustness of the proposed GMF on different loss functions, lighting conditions
and noises.The code is available at https://github.com/XiaoshuiHuang/GMF.
</p></li>
</ul>

<h3>Title: Self-supervised Character-to-Character Distillation. (arXiv:2211.00288v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00288">http://arxiv.org/abs/2211.00288</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00288] Self-supervised Character-to-Character Distillation](http://arxiv.org/abs/2211.00288)</code></li>
<li>Summary: <p>Handling complicated text images (e.g., irregular structures, low resolution,
heavy occlusion, and even illumination), existing supervised text recognition
methods are data-hungry. Although these methods employ large-scale synthetic
text images to reduce the dependence on annotated real images, the domain gap
limits the recognition performance. Therefore, exploring the robust text
feature representation on unlabeled real images by self-supervised learning is
a good solution. However, existing self-supervised text recognition methods
only execute sequence-to-sequence representation learning by roughly splitting
the visual features along the horizontal axis, which will damage the character
structures. Besides, these sequential-level self-learning methods limit the
availability of geometric-based data augmentation, as large-scale geometry
augmentation leads to sequence-to-sequence inconsistency. To address the
above-mentioned issues, we proposed a novel self-supervised
character-to-character distillation method, CCD. Specifically, we delineate the
character structures of unlabeled real images by designing a self-supervised
character segmentation module, and further apply the segmentation results to
build character-level representation learning.
</p></li>
</ul>

<p>CCD differs from prior works in that we propose a character-level pretext
task to learn more fine-grained feature representations. Besides, compared with
the inflexible augmentations of sequence-to-sequence models, our work satisfies
character-to-character representation consistency, across various
transformations (e.g., geometry and colour), to generate robust text features
in the representative space. Experiments demonstrate that CCD achieves
state-of-the-art performance on publicly available text recognition benchmarks.
</p>

<h3>Title: Expansion of Visual Hints for Improved Generalization in Stereo Matching. (arXiv:2211.00392v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00392">http://arxiv.org/abs/2211.00392</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00392] Expansion of Visual Hints for Improved Generalization in Stereo Matching](http://arxiv.org/abs/2211.00392)</code></li>
<li>Summary: <p>We introduce visual hints expansion for guiding stereo matching to improve
generalization. Our work is motivated by the robustness of Visual Inertial
Odometry (VIO) in computer vision and robotics, where a sparse and unevenly
distributed set of feature points characterizes a scene. To improve stereo
matching, we propose to elevate 2D hints to 3D points. These sparse and
unevenly distributed 3D visual hints are expanded using a 3D random geometric
graph, which enhances the learning and inference process. We evaluate our
proposal on multiple widely adopted benchmarks and show improved performance
without access to additional sensors other than the image sequence. To
highlight practical applicability and symbiosis with visual odometry, we
demonstrate how our methods run on embedded hardware.
</p></li>
</ul>

<h3>Title: Signing Outside the Studio: Benchmarking Background Robustness for Continuous Sign Language Recognition. (arXiv:2211.00448v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00448">http://arxiv.org/abs/2211.00448</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00448] Signing Outside the Studio: Benchmarking Background Robustness for Continuous Sign Language Recognition](http://arxiv.org/abs/2211.00448)</code></li>
<li>Summary: <p>The goal of this work is background-robust continuous sign language
recognition. Most existing Continuous Sign Language Recognition (CSLR)
benchmarks have fixed backgrounds and are filmed in studios with a static
monochromatic background. However, signing is not limited only to studios in
the real world. In order to analyze the robustness of CSLR models under
background shifts, we first evaluate existing state-of-the-art CSLR models on
diverse backgrounds. To synthesize the sign videos with a variety of
backgrounds, we propose a pipeline to automatically generate a benchmark
dataset utilizing existing CSLR benchmarks. Our newly constructed benchmark
dataset consists of diverse scenes to simulate a real-world environment. We
observe even the most recent CSLR method cannot recognize glosses well on our
new dataset with changed backgrounds. In this regard, we also propose a simple
yet effective training scheme including (1) background randomization and (2)
feature disentanglement for CSLR models. The experimental results on our
dataset demonstrate that our method generalizes well to other unseen background
data with minimal additional training images.
</p></li>
</ul>

<h3>Title: Self-Supervised Intensity-Event Stereo Matching. (arXiv:2211.00509v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00509">http://arxiv.org/abs/2211.00509</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00509] Self-Supervised Intensity-Event Stereo Matching](http://arxiv.org/abs/2211.00509)</code></li>
<li>Summary: <p>Event cameras are novel bio-inspired vision sensors that output pixel-level
intensity changes in microsecond accuracy with a high dynamic range and low
power consumption. Despite these advantages, event cameras cannot be directly
applied to computational imaging tasks due to the inability to obtain
high-quality intensity and events simultaneously. This paper aims to connect a
standalone event camera and a modern intensity camera so that the applications
can take advantage of both two sensors. We establish this connection through a
multi-modal stereo matching task. We first convert events to a reconstructed
image and extend the existing stereo networks to this multi-modality condition.
We propose a self-supervised method to train the multi-modal stereo network
without using ground truth disparity data. The structure loss calculated on
image gradients is used to enable self-supervised learning on such multi-modal
data. Exploiting the internal stereo constraint between views with different
modalities, we introduce general stereo loss functions, including disparity
cross-consistency loss and internal disparity loss, leading to improved
performance and robustness compared to existing approaches. The experiments
demonstrate the effectiveness of the proposed method, especially the proposed
general stereo loss functions, on both synthetic and real datasets. At last, we
shed light on employing the aligned events and intensity images in downstream
tasks, e.g., video interpolation application.
</p></li>
</ul>

<h3>Title: Infinite-Dimensional Adaptive Boundary Observer for Inner-Domain Temperature Estimation of 3D Electrosurgical Processes using Surface Thermography Sensing. (arXiv:2211.00515v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00515">http://arxiv.org/abs/2211.00515</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00515] Infinite-Dimensional Adaptive Boundary Observer for Inner-Domain Temperature Estimation of 3D Electrosurgical Processes using Surface Thermography Sensing](http://arxiv.org/abs/2211.00515)</code></li>
<li>Summary: <p>We present a novel 3D adaptive observer framework for use in the
determination of subsurface organic tissue temperatures in electrosurgery. The
observer structure leverages pointwise 2D surface temperature readings obtained
from a real-time infrared thermographer for both parameter estimation and
temperature field observation. We introduce a novel approach to decoupled
parameter adaptation and estimation, wherein the parameter estimation can run
in real-time, while the observer loop runs on a slower time scale. To achieve
this, we introduce a novel parameter estimation method known as attention-based
noise-robust averaging, in which surface thermography time series are used to
directly estimate the tissue's diffusivity. Our observer contains a real-time
parameter adaptation component based on this diffusivity adaptation law, as
well as a Luenberger-type corrector based on the sensed surface temperature. In
this work, we also present a novel model structure adapted to the setting of
robotic surgery, wherein we model the electrosurgical heat distribution as a
compactly supported magnitude- and velocity-controlled heat source involving a
new nonlinear input mapping. We demonstrate satisfactory performance of the
adaptive observer in simulation, using real-life experimental ex vivo porcine
tissue data.
</p></li>
</ul>

<h3>Title: The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for Improving Adversarial Training. (arXiv:2211.00525v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00525">http://arxiv.org/abs/2211.00525</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00525] The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for Improving Adversarial Training](http://arxiv.org/abs/2211.00525)</code></li>
<li>Summary: <p>Although current deep learning techniques have yielded superior performance
on various computer vision tasks, yet they are still vulnerable to adversarial
examples. Adversarial training and its variants have been shown to be the most
effective approaches to defend against adversarial examples. These methods
usually regularize the difference between output probabilities for an
adversarial and its corresponding natural example. However, it may have a
negative impact if the model misclassifies a natural example. To circumvent
this issue, we propose a novel adversarial training scheme that encourages the
model to produce similar outputs for an adversarial example and its ``inverse
adversarial'' counterpart. These samples are generated to maximize the
likelihood in the neighborhood of natural examples. Extensive experiments on
various vision datasets and architectures demonstrate that our training method
achieves state-of-the-art robustness as well as natural accuracy. Furthermore,
using a universal version of inverse adversarial examples, we improve the
performance of single-step adversarial training techniques at a low
computational cost.
</p></li>
</ul>

<h3>Title: Why Is It Hate Speech? Masked Rationale Prediction for Explainable Hate Speech Detection. (arXiv:2211.00243v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00243">http://arxiv.org/abs/2211.00243</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00243] Why Is It Hate Speech? Masked Rationale Prediction for Explainable Hate Speech Detection](http://arxiv.org/abs/2211.00243)</code></li>
<li>Summary: <p>In a hate speech detection model, we should consider two critical aspects in
addition to detection performance-bias and explainability. Hate speech cannot
be identified based solely on the presence of specific words: the model should
be able to reason like humans and be explainable. To improve the performance
concerning the two aspects, we propose Masked Rationale Prediction (MRP) as an
intermediate task. MRP is a task to predict the masked human
rationales-snippets of a sentence that are grounds for human judgment-by
referring to surrounding tokens combined with their unmasked rationales. As the
model learns its reasoning ability based on rationales by MRP, it performs hate
speech detection robustly in terms of bias and explainability. The proposed
method generally achieves state-of-the-art performance in various metrics,
demonstrating its effectiveness for hate speech detection.
</p></li>
</ul>

<h3>Title: FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness. (arXiv:2211.00294v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00294">http://arxiv.org/abs/2211.00294</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00294] FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness](http://arxiv.org/abs/2211.00294)</code></li>
<li>Summary: <p>Despite being able to generate fluent and grammatical text, current Seq2Seq
summarization models still suffering from the unfaithful generation problem. In
this paper, we study the faithfulness of existing systems from a new
perspective of factual robustness which is the ability to correctly generate
factual information over adversarial unfaithful information. We first measure a
model's factual robustness by its success rate to defend against adversarial
attacks when generating factual information. The factual robustness analysis on
a wide range of current systems shows its good consistency with human judgments
on faithfulness. Inspired by these findings, we propose to improve the
faithfulness of a model by enhancing its factual robustness. Specifically, we
propose a novel training strategy, namely FRSUM, which teaches the model to
defend against both explicit adversarial samples and implicit factual
adversarial perturbations. Extensive automatic and human evaluation results
show that FRSUM consistently improves the faithfulness of various Seq2Seq
models, such as T5, BART.
</p></li>
</ul>

<h3>Title: DensePure: Understanding Diffusion Models towards Adversarial Robustness. (arXiv:2211.00322v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00322">http://arxiv.org/abs/2211.00322</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00322] DensePure: Understanding Diffusion Models towards Adversarial Robustness](http://arxiv.org/abs/2211.00322)</code></li>
<li>Summary: <p>Diffusion models have been recently employed to improve certified robustness
through the process of denoising. However, the theoretical understanding of why
diffusion models are able to improve the certified robustness is still lacking,
preventing from further improvement. In this study, we close this gap by
analyzing the fundamental properties of diffusion models and establishing the
conditions under which they can enhance certified robustness. This deeper
understanding allows us to propose a new method DensePure, designed to improve
the certified robustness of a pretrained model (i.e. classifier). Given an
(adversarial) input, DensePure consists of multiple runs of denoising via the
reverse process of the diffusion model (with different random seeds) to get
multiple reversed samples, which are then passed through the classifier,
followed by majority voting of inferred labels to make the final prediction.
This design of using multiple runs of denoising is informed by our theoretical
analysis of the conditional distribution of the reversed sample. Specifically,
when the data density of a clean sample is high, its conditional density under
the reverse process in a diffusion model is also high; thus sampling from the
latter conditional distribution can purify the adversarial example and return
the corresponding clean sample with a high probability. By using the highest
density point in the conditional distribution as the reversed sample, we
identify the robust region of a given instance under the diffusion model's
reverse process. We show that this robust region is a union of multiple convex
sets, and is potentially much larger than the robust regions identified in
previous works. In practice, DensePure can approximate the label of the high
density region in the conditional distribution so that it can enhance certified
robustness.
</p></li>
</ul>

<h3>Title: ARDIR: Improving Robustness using Knowledge Distillation of Internal Representation. (arXiv:2211.00239v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00239">http://arxiv.org/abs/2211.00239</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00239] ARDIR: Improving Robustness using Knowledge Distillation of Internal Representation](http://arxiv.org/abs/2211.00239)</code></li>
<li>Summary: <p>Adversarial training is the most promising method for learning robust models
against adversarial examples. A recent study has shown that knowledge
distillation between the same architectures is effective in improving the
performance of adversarial training. Exploiting knowledge distillation is a new
approach to improve adversarial training and has attracted much attention.
However, its performance is still insufficient. Therefore, we propose
Adversarial Robust Distillation with Internal Representation~(ARDIR) to utilize
knowledge distillation even more effectively. In addition to the output of the
teacher model, ARDIR uses the internal representation of the teacher model as a
label for adversarial training. This enables the student model to be trained
with richer, more informative labels. As a result, ARDIR can learn more robust
student models. We show that ARDIR outperforms previous methods in our
experiments.
</p></li>
</ul>

<h3>Title: End-to-End Optimization and Learning for Multiagent Ensembles. (arXiv:2211.00251v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00251">http://arxiv.org/abs/2211.00251</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00251] End-to-End Optimization and Learning for Multiagent Ensembles](http://arxiv.org/abs/2211.00251)</code></li>
<li>Summary: <p>Multiagent ensemble learning is an important class of algorithms aimed at
creating accurate and robust machine learning models by combining predictions
from individual agents. A key challenge for the design of these models is to
create effective rules to combine individual predictions for any particular
input sample.
</p></li>
</ul>

<p>This paper addresses this challenge and proposes a unique integration of
constrained optimization and learning to derive specialized consensus rules to
compose accurate predictions from a pretrained ensemble. The resulting
strategy, called end-to-end Multiagent ensemble Learning (e2e-MEL), learns to
select appropriate predictors to combine for a particular input sample. The
paper shows how to derive the ensemble learning task into a differentiable
selection program which is trained end-to-end within the ensemble learning
model. Results over standard benchmarks demonstrate the ability of e2e-MEL to
substantially outperform conventional consensus rules in a variety of settings.
</p>

<h3>Title: Meta-Learning for Unsupervised Outlier Detection with Optimal Transport. (arXiv:2211.00372v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00372">http://arxiv.org/abs/2211.00372</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00372] Meta-Learning for Unsupervised Outlier Detection with Optimal Transport](http://arxiv.org/abs/2211.00372)</code></li>
<li>Summary: <p>Automated machine learning has been widely researched and adopted in the
field of supervised classification and regression, but progress in unsupervised
settings has been limited. We propose a novel approach to automate outlier
detection based on meta-learning from previous datasets with outliers. Our
premise is that the selection of the optimal outlier detection technique
depends on the inherent properties of the data distribution. We leverage
optimal transport in particular, to find the dataset with the most similar
underlying distribution, and then apply the outlier detection techniques that
proved to work best for that data distribution. We evaluate the robustness of
our approach and find that it outperforms the state of the art methods in
unsupervised outlier detection. This approach can also be easily generalized to
automate other unsupervised settings.
</p></li>
</ul>

<h3>Title: Automated Imbalanced Learning. (arXiv:2211.00376v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00376">http://arxiv.org/abs/2211.00376</a></li>
<li>Code URL: <a href="https://github.com/prabhant/gama">https://github.com/prabhant/gama</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00376] Automated Imbalanced Learning](http://arxiv.org/abs/2211.00376)</code></li>
<li>Summary: <p>Automated Machine Learning has grown very successful in automating the
time-consuming, iterative tasks of machine learning model development. However,
current methods struggle when the data is imbalanced. Since many real-world
datasets are naturally imbalanced, and improper handling of this issue can lead
to quite useless models, this issue should be handled carefully. This paper
first introduces a new benchmark to study how different AutoML methods are
affected by label imbalance. Second, we propose strategies to better deal with
imbalance and integrate them into an existing AutoML framework. Finally, we
present a systematic study which evaluates the impact of these strategies and
find that their inclusion in AutoML systems significantly increases their
robustness against label imbalance.
</p></li>
</ul>

<h3>Title: A Simple, Yet Effective Approach to Finding Biases in Code Generation. (arXiv:2211.00609v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00609">http://arxiv.org/abs/2211.00609</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00609] A Simple, Yet Effective Approach to Finding Biases in Code Generation](http://arxiv.org/abs/2211.00609)</code></li>
<li>Summary: <p>Recently, scores of high-performing code generation systems have surfaced. As
has become a popular choice in many domains, code generation is often
approached using large language models as a core, trained under the masked or
causal language modeling schema. This work shows that current code generation
systems exhibit biases inherited from large language model backbones, which
might leak into generated code under specific circumstances.
</p></li>
</ul>

<p>To investigate the effect, we propose a framework that automatically removes
hints and exposes various biases that these code generation models use. We
apply our framework to three coding challenges and test it across
top-performing coding generation models. Our experiments reveal biases towards
specific prompt structure and exploitation of keywords during code generation.
Finally, we demonstrate how to use our framework as a data transformation
technique, which we find a promising direction toward more robust code
generation.
</p>

<h3>Title: Denoising neural networks for magnetic resonance spectroscopy. (arXiv:2211.00080v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00080">http://arxiv.org/abs/2211.00080</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00080] Denoising neural networks for magnetic resonance spectroscopy](http://arxiv.org/abs/2211.00080)</code></li>
<li>Summary: <p>In many scientific applications, measured time series are corrupted by noise
or distortions. Traditional denoising techniques often fail to recover the
signal of interest, particularly when the signal-to-noise ratio is low or when
certain assumptions on the signal and noise are violated. In this work, we
demonstrate that deep learning-based denoising methods can outperform
traditional techniques while exhibiting greater robustness to variation in
noise and signal characteristics. Our motivating example is magnetic resonance
spectroscopy, in which a primary goal is to detect the presence of
short-duration, low-amplitude radio frequency signals that are often obscured
by strong interference that can be difficult to separate from the signal using
traditional methods. We explore various deep learning architecture choices to
capture the inherently complex-valued nature of magnetic resonance signals. On
both synthetic and experimental data, we show that our deep learning-based
approaches can exceed performance of traditional techniques, providing a
powerful new class of methods for analysis of scientific time series data.
</p></li>
</ul>

<h3>Title: Informed Priors for Knowledge Integration in Trajectory Prediction. (arXiv:2211.00348v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00348">http://arxiv.org/abs/2211.00348</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00348] Informed Priors for Knowledge Integration in Trajectory Prediction](http://arxiv.org/abs/2211.00348)</code></li>
<li>Summary: <p>Informed machine learning methods allow the integration of prior knowledge
into learning systems. This can increase accuracy and robustness or reduce data
needs. However, existing methods often assume hard constraining knowledge, that
does not require to trade-off prior knowledge with observations, but can be
used to directly reduce the problem space. Other approaches use specific,
architectural changes as representation of prior knowledge, limiting
applicability. We propose an informed machine learning method, based on
continual learning. This allows the integration of arbitrary, prior knowledge,
potentially from multiple sources, and does not require specific architectures.
Furthermore, our approach enables probabilistic and multi-modal predictions,
that can improve predictive accuracy and robustness. We exemplify our approach
by applying it to a state-of-the-art trajectory predictor for autonomous
driving. This domain is especially dependent on informed learning approaches,
as it is subject to an overwhelming large variety of possible environments and
very rare events, while requiring robust and accurate predictions. We evaluate
our model on a commonly used benchmark dataset, only using data already
available in a conventional setup. We show that our method outperforms both
non-informed and informed learning methods, that are often used in the
literature. Furthermore, we are able to compete with a conventional baseline,
even using half as many observation examples.
</p></li>
</ul>

<h3>Title: Exploring Effects of Computational Parameter Changes to Image Recognition Systems. (arXiv:2211.00471v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00471">http://arxiv.org/abs/2211.00471</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00471] Exploring Effects of Computational Parameter Changes to Image Recognition Systems](http://arxiv.org/abs/2211.00471)</code></li>
<li>Summary: <p>Image recognition tasks typically use deep learning and require enormous
processing power, thus relying on hardware accelerators like GPUs and FPGAs for
fast, timely processing. Failure in real-time image recognition tasks can occur
due to incorrect mapping on hardware accelerators, which may lead to timing
uncertainty and incorrect behavior. Owing to the increased use of image
recognition tasks in safety-critical applications like autonomous driving and
medical imaging, it is imperative to assess their robustness to changes in the
computational environment as parameters like deep learning frameworks, compiler
optimizations for code generation, and hardware devices are not regulated with
varying impact on model performance and correctness. In this paper we conduct
robustness analysis of four popular image recognition models (MobileNetV2,
ResNet101V2, DenseNet121 and InceptionV3) with the ImageNet dataset, assessing
the impact of the following parameters in the model's computational
environment: (1) deep learning frameworks; (2) compiler optimizations; and (3)
hardware devices. We report sensitivity of model performance in terms of output
label and inference time for changes in each of these environment parameters.
We find that output label predictions for all four models are sensitive to
choice of deep learning framework (by up to 57%) and insensitive to other
parameters. On the other hand, model inference time was affected by all
environment parameters with changes in hardware device having the most effect.
The extent of effect was not uniform across models.
</p></li>
</ul>

<h3>Title: Optimal Complexity in Non-Convex Decentralized Learning over Time-Varying Networks. (arXiv:2211.00533v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00533">http://arxiv.org/abs/2211.00533</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00533] Optimal Complexity in Non-Convex Decentralized Learning over Time-Varying Networks](http://arxiv.org/abs/2211.00533)</code></li>
<li>Summary: <p>Decentralized optimization with time-varying networks is an emerging paradigm
in machine learning. It saves remarkable communication overhead in large-scale
deep training and is more robust in wireless scenarios especially when nodes
are moving. Federated learning can also be regarded as decentralized
optimization with time-varying communication patterns alternating between
global averaging and local updates.
</p></li>
</ul>

<p>While numerous studies exist to clarify its theoretical limits and develop
efficient algorithms, it remains unclear what the optimal complexity is for
non-convex decentralized stochastic optimization over time-varying networks.
The main difficulties lie in how to gauge the effectiveness when transmitting
messages between two nodes via time-varying communications, and how to
establish the lower bound when the network size is fixed (which is a
prerequisite in stochastic optimization). This paper resolves these challenges
and establish the first lower bound complexity. We also develop a new
decentralized algorithm to nearly attain the lower bound, showing the tightness
of the lower bound and the optimality of our algorithm.
</p>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: A new filter for dimensionality reduction and classification of hyperspectral images using GLCM features and mutual information. (arXiv:2211.00446v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00446">http://arxiv.org/abs/2211.00446</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00446] A new filter for dimensionality reduction and classification of hyperspectral images using GLCM features and mutual information](http://arxiv.org/abs/2211.00446)</code></li>
<li>Summary: <p>Dimensionality reduction is an important preprocessing step of the
hyperspectral images classification (HSI), it is inevitable task. Some methods
use feature selection or extraction algorithms based on spectral and spatial
information. In this paper, we introduce a new methodology for dimensionality
reduction and classification of HSI taking into account both spectral and
spatial information based on mutual information. We characterise the spatial
information by the texture features extracted from the grey level cooccurrence
matrix (GLCM); we use Homogeneity, Contrast, Correlation and Energy. For
classification, we use support vector machine (SVM). The experiments are
performed on three well-known hyperspectral benchmark datasets. The proposed
algorithm is compared with the state of the art methods. The obtained results
of this fusion show that our method outperforms the other approaches by
increasing the classification accuracy in a good timing. This method may be
improved for more performance
</p></li>
</ul>

<p>Keywords: hyperspectral images; classification; spectral and spatial
features; grey level cooccurrence matrix; GLCM; mutual information; support
vector machine; SVM.
</p>

<h3>Title: Geo-Information Harvesting from Social Media Data. (arXiv:2211.00543v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00543">http://arxiv.org/abs/2211.00543</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00543] Geo-Information Harvesting from Social Media Data](http://arxiv.org/abs/2211.00543)</code></li>
<li>Summary: <p>As unconventional sources of geo-information, massive imagery and text
messages from open platforms and social media form a temporally quasi-seamless,
spatially multi-perspective stream, but with unknown and diverse quality. Due
to its complementarity to remote sensing data, geo-information from these
sources offers promising perspectives, but harvesting is not trivial due to its
data characteristics. In this article, we address key aspects in the field,
including data availability, analysis-ready data preparation and data
management, geo-information extraction from social media text messages and
images, and the fusion of social media and remote sensing data. We then
showcase some exemplary geographic applications. In addition, we present the
first extensive discussion of ethical considerations of social media data in
the context of geo-information harvesting and geographic applications. With
this effort, we wish to stimulate curiosity and lay the groundwork for
researchers who intend to explore social media data for geo-applications. We
encourage the community to join forces by sharing their code and data.
</p></li>
</ul>

<h3>Title: Revisiting the Practical Effectiveness of Constituency Parse Extraction from Pre-trained Language Models. (arXiv:2211.00479v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00479">http://arxiv.org/abs/2211.00479</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00479] Revisiting the Practical Effectiveness of Constituency Parse Extraction from Pre-trained Language Models](http://arxiv.org/abs/2211.00479)</code></li>
<li>Summary: <p>Constituency Parse Extraction from Pre-trained Language Models (CPE-PLM) is a
recent paradigm that attempts to induce constituency parse trees relying only
on the internal knowledge of pre-trained language models. While attractive in
the perspective that similar to in-context learning, it does not require
task-specific fine-tuning, the practical effectiveness of such an approach
still remains unclear, except that it can function as a probe for investigating
language models' inner workings. In this work, we mathematically reformulate
CPE-PLM and propose two advanced ensemble methods tailored for it,
demonstrating that the new parsing paradigm can be competitive with common
unsupervised parsers by introducing a set of heterogeneous PLMs combined using
our techniques. Furthermore, we explore some scenarios where the trees
generated by CPE-PLM are practically useful. Specifically, we show that CPE-PLM
is more effective than typical supervised parsers in few-shot settings.
</p></li>
</ul>

<h3>Title: Clustering-Based Approaches for Symbolic Knowledge Extraction. (arXiv:2211.00234v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00234">http://arxiv.org/abs/2211.00234</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00234] Clustering-Based Approaches for Symbolic Knowledge Extraction](http://arxiv.org/abs/2211.00234)</code></li>
<li>Summary: <p>Opaque models belonging to the machine learning world are ever more exploited
in the most different application areas. These models, acting as black boxes
(BB) from the human perspective, cannot be entirely trusted if the application
is critical unless there exists a method to extract symbolic and human-readable
knowledge out of them. In this paper we analyse a recurrent design adopted by
symbolic knowledge extractors for BB regressors - that is, the creation of
rules associated with hypercubic input space regions. We argue that this kind
of partitioning may lead to suboptimal solutions when the data set at hand is
high-dimensional or does not satisfy symmetric constraints. We then propose a
(deep) clustering-based approach to be performed before symbolic knowledge
extraction to achieve better performance with data sets of any kind.
</p></li>
</ul>

<h3>Title: Evaluation Metrics for Symbolic Knowledge Extracted from Machine Learning Black Boxes: A Discussion Paper. (arXiv:2211.00238v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00238">http://arxiv.org/abs/2211.00238</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00238] Evaluation Metrics for Symbolic Knowledge Extracted from Machine Learning Black Boxes: A Discussion Paper](http://arxiv.org/abs/2211.00238)</code></li>
<li>Summary: <p>As opaque decision systems are being increasingly adopted in almost any
application field, issues about their lack of transparency and human
readability are a concrete concern for end-users. Amongst existing proposals to
associate human-interpretable knowledge with accurate predictions provided by
opaque models, there are rule extraction techniques, capable of extracting
symbolic knowledge out of an opaque model. However, how to assess the level of
readability of the extracted knowledge quantitatively is still an open issue.
Finding such a metric would be the key, for instance, to enable automatic
comparison between a set of different knowledge representations, paving the way
for the development of parameter autotuning algorithms for knowledge
extractors. In this paper we discuss the need for such a metric as well as the
criticalities of readability assessment and evaluation, taking into account the
most common knowledge representations while highlighting the most puzzling
issues.
</p></li>
</ul>

<h3>Title: Causal DAG extraction from a library of books or videos/movies. (arXiv:2211.00486v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00486">http://arxiv.org/abs/2211.00486</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00486] Causal DAG extraction from a library of books or videos/movies](http://arxiv.org/abs/2211.00486)</code></li>
<li>Summary: <p>Determining a causal DAG (directed acyclic graph) for a problem under
consideration, is a major roadblock when doing Judea Pearl's Causal Inference
(CI) in Statistics. The same problem arises when doing CI in Artificial
Intelligence (AI) and Machine Learning (ML). As with many problems in Science,
we think Nature has found an effective solution to this problem. We argue that
human and animal brains contain an explicit engine for doing CI, and that such
an engine uses as input an atlas (i.e., collection) of causal DAGs. We propose
a simple algorithm for constructing such an atlas from a library of books or
videos/movies. We illustrate our method by applying it to a database of
randomly generated Tic-Tac-Toe games. The software used to generate this
Tic-Tac-Toe example is open source and available at GitHub.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: FL Games: A Federated Learning Framework for Distribution Shifts. (arXiv:2211.00184v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00184">http://arxiv.org/abs/2211.00184</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00184] FL Games: A Federated Learning Framework for Distribution Shifts](http://arxiv.org/abs/2211.00184)</code></li>
<li>Summary: <p>Federated learning aims to train predictive models for data that is
distributed across clients, under the orchestration of a server. However,
participating clients typically each hold data from a different distribution,
which can yield to catastrophic generalization on data from a different client,
which represents a new domain. In this work, we argue that in order to
generalize better across non-i.i.d. clients, it is imperative to only learn
correlations that are stable and invariant across domains. We propose FL GAMES,
a game-theoretic framework for federated learning that learns causal features
that are invariant across clients. While training to achieve the Nash
equilibrium, the traditional best response strategy suffers from high-frequency
oscillations. We demonstrate that FL GAMES effectively resolves this challenge
and exhibits smooth performance curves. Further, FL GAMES scales well in the
number of clients, requires significantly fewer communication rounds, and is
agnostic to device heterogeneity. Through empirical evaluation, we demonstrate
that FL GAMES achieves high out-of-distribution performance on various
benchmarks.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Improving Fairness in Image Classification via Sketching. (arXiv:2211.00168v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00168">http://arxiv.org/abs/2211.00168</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00168] Improving Fairness in Image Classification via Sketching](http://arxiv.org/abs/2211.00168)</code></li>
<li>Summary: <p>Fairness is a fundamental requirement for trustworthy and human-centered
Artificial Intelligence (AI) system. However, deep neural networks (DNNs) tend
to make unfair predictions when the training data are collected from different
sub-populations with different attributes (i.e. color, sex, age), leading to
biased DNN predictions. We notice that such a troubling phenomenon is often
caused by data itself, which means that bias information is encoded to the DNN
along with the useful information (i.e. class information, semantic
information). Therefore, we propose to use sketching to handle this phenomenon.
Without losing the utility of data, we explore the image-to-sketching methods
that can maintain useful semantic information for the target classification
while filtering out the useless bias information. In addition, we design a fair
loss to further improve the model fairness. We evaluate our method through
extensive experiments on both general scene dataset and medical scene dataset.
Our results show that the desired image-to-sketching method improves model
fairness and achieves satisfactory results among state-of-the-art.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Hybrid CNN -Interpreter: Interpret local and global contexts for CNN-based Models. (arXiv:2211.00185v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00185">http://arxiv.org/abs/2211.00185</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00185] Hybrid CNN -Interpreter: Interpret local and global contexts for CNN-based Models](http://arxiv.org/abs/2211.00185)</code></li>
<li>Summary: <p>Convolutional neural network (CNN) models have seen advanced improvements in
performance in various domains, but lack of interpretability is a major barrier
to assurance and regulation during operation for acceptance and deployment of
AI-assisted applications. There have been many works on input interpretability
focusing on analyzing the input-output relations, but the internal logic of
models has not been clarified in the current mainstream interpretability
methods. In this study, we propose a novel hybrid CNN-interpreter through: (1)
An original forward propagation mechanism to examine the layer-specific
prediction results for local interpretability. (2) A new global
interpretability that indicates the feature correlation and filter importance
effects. By combining the local and global interpretabilities, hybrid
CNN-interpreter enables us to have a solid understanding and monitoring of
model context during the whole learning process with detailed and consistent
representations. Finally, the proposed interpretabilities have been
demonstrated to adapt to various CNN-based model structures.
</p></li>
</ul>

<h3>Title: Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small. (arXiv:2211.00593v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00593">http://arxiv.org/abs/2211.00593</a></li>
<li>Code URL: <a href="https://github.com/redwoodresearch/easy-transformer">https://github.com/redwoodresearch/easy-transformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00593] Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small](http://arxiv.org/abs/2211.00593)</code></li>
<li>Summary: <p>Research in mechanistic interpretability seeks to explain behaviors of
machine learning models in terms of their internal components. However, most
previous work either focuses on simple behaviors in small models, or describes
complicated behaviors in larger models with broad strokes. In this work, we
bridge this gap by presenting an explanation for how GPT-2 small performs a
natural language task called indirect object identification (IOI). Our
explanation encompasses 26 attention heads grouped into 7 main classes, which
we discovered using a combination of interpretability approaches relying on
causal interventions. To our knowledge, this investigation is the largest
end-to-end attempt at reverse-engineering a natural behavior "in the wild" in a
language model. We evaluate the reliability of our explanation using three
quantitative criteria--faithfulness, completeness and minimality. Though these
criteria support our explanation, they also point to remaining gaps in our
understanding. Our work provides evidence that a mechanistic understanding of
large ML models is feasible, opening opportunities to scale our understanding
to both larger models and more complex tasks.
</p></li>
</ul>

<h3>Title: Disentangled (Un)Controllable Features. (arXiv:2211.00086v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00086">http://arxiv.org/abs/2211.00086</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00086] Disentangled (Un)Controllable Features](http://arxiv.org/abs/2211.00086)</code></li>
<li>Summary: <p>In the context of MDPs with high-dimensional states, reinforcement learning
can achieve better results when using a compressed, low-dimensional
representation of the original input space. A variety of learning objectives
have therefore been used to learn useful representations. However, these
representations usually lack interpretability of the different features. We
propose a representation learning algorithm that is able to disentangle latent
features into a controllable and an uncontrollable part. The resulting
representations are easily interpretable and can be used for learning and
planning efficiently by leveraging the specific properties of the two parts. To
highlight the benefits of the approach, the disentangling properties of the
algorithm are illustrated in three different environments.
</p></li>
</ul>

<h3>Title: What is my math transformer doing? -- Three results on interpretability and generalization. (arXiv:2211.00170v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00170">http://arxiv.org/abs/2211.00170</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00170] What is my math transformer doing? -- Three results on interpretability and generalization](http://arxiv.org/abs/2211.00170)</code></li>
<li>Summary: <p>This paper investigates the failure cases and out-of-distribution behavior of
transformers trained on matrix inversion and eigenvalue decomposition. I show
that incorrect model predictions still retain deep mathematical properties of
the solution (e.g. correct eigenvalues, unit norm of eigenvectors), and that
almost all model failures can be attributed to, and predicted from, properties
of the problem or solution. This demonstrates that, when in doubt, math
transformers do not hallucinate absurd solutions (as was sometimes proposed)
but remain <code>roughly right''. I also show that the careful choice of a training
dataset can accelerate training, while allowing the model to generalize out of
its training distribution, invalidating the idea that transformers</code>merely
interpolate'' from memorized examples.
</p></li>
</ul>

<h3>Title: UNFIS: A Novel Neuro-Fuzzy Inference System with Unstructured Fuzzy Rules for Classification. (arXiv:2211.00599v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00599">http://arxiv.org/abs/2211.00599</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00599] UNFIS: A Novel Neuro-Fuzzy Inference System with Unstructured Fuzzy Rules for Classification](http://arxiv.org/abs/2211.00599)</code></li>
<li>Summary: <p>An important constraint of Fuzzy Inference Systems (FIS) is their structured
rules defined based on evaluating all input variables. Indeed, the length of
all fuzzy rules and the number of input variables are equal. However, in many
decision-making problems evaluating some conditions on a limited set of input
variables is sufficient to decide properly (unstructured rules). Therefore,
this constraint limits the performance, generalization, and interpretability of
the FIS. To address this issue, this paper presents a neuro-fuzzy inference
system for classification applications that can select different sets of input
variables for constructing each fuzzy rule. To realize this capability, a new
fuzzy selector neuron with an adaptive parameter is proposed that can select
input variables in the antecedent part of each fuzzy rule. Moreover, in this
paper, the consequent part of the Takagi-Sugeno-Kang FIS is also changed
properly to consider only the selected set of input variables. To learn the
parameters of the proposed architecture, a trust-region-based learning method
(General quasi-Levenberg-Marquardt (GqLM)) is proposed to minimize
cross-entropy in multiclass problems. The performance of the proposed method is
compared with some related previous approaches in some real-world
classification problems. Based on these comparisons the proposed method has
better or very close performance with a parsimonious structure consisting of
unstructured fuzzy.
</p></li>
</ul>

<h3>Title: Contextual Mixture of Experts: Integrating Knowledge into Predictive Modeling. (arXiv:2211.00558v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00558">http://arxiv.org/abs/2211.00558</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00558] Contextual Mixture of Experts: Integrating Knowledge into Predictive Modeling](http://arxiv.org/abs/2211.00558)</code></li>
<li>Summary: <p>This work proposes a new data-driven model devised to integrate process
knowledge into its structure to increase the human-machine synergy in the
process industry. The proposed Contextual Mixture of Experts (cMoE) explicitly
uses process knowledge along the model learning stage to mold the historical
data to represent operators' context related to the process through possibility
distributions. This model was evaluated in two real case studies for quality
prediction, including a sulfur recovery unit and a polymerization process. The
contextual mixture of experts was employed to represent different contexts in
both experiments. The results indicate that integrating process knowledge has
increased predictive performance while improving interpretability by providing
insights into the variables affecting the process's different regimes.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
