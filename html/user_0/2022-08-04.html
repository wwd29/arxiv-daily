<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Computation of Trusted Short Weierstrass Elliptic Curves for Cryptography. (arXiv:2208.01635v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01635">http://arxiv.org/abs/2208.01635</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01635] Computation of Trusted Short Weierstrass Elliptic Curves for Cryptography](http://arxiv.org/abs/2208.01635)</code></li>
<li>Summary: <p>Short Weierstrass's elliptic curves with underlying hard Elliptic Curve
Discrete Logarithm Problems was widely used in Cryptographic applications. This
paper introduces a new security notation 'trusted security' for computation
methods of elliptic curves for cryptography. Three additional "trusted security
acceptance criteria" is proposed to be met by the elliptic curves aimed for
cryptography. Further, two cryptographically secure elliptic curves over 256
bit and 384 bit prime fields are demonstrated which are secure from ECDLP, ECC
as well as trust perspectives. The proposed elliptic curves are successfully
subjected to thorough security analysis and performance evaluation with respect
to key generation and signing/verification and hence, proven for their
cryptographic suitability and great feasibility for acceptance by the
community.
</p></li>
</ul>

<h3>Title: CAPD: A Context-Aware, Policy-Driven Framework for Secure and Resilient IoBT Operations. (arXiv:2208.01703v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01703">http://arxiv.org/abs/2208.01703</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01703] CAPD: A Context-Aware, Policy-Driven Framework for Secure and Resilient IoBT Operations](http://arxiv.org/abs/2208.01703)</code></li>
<li>Summary: <p>The Internet of Battlefield Things (IoBT) will advance the operational
effectiveness of infantry units. However, this requires autonomous assets such
as sensors, drones, combat equipment, and uncrewed vehicles to collaborate,
securely share information, and be resilient to adversary attacks in contested
multi-domain operations. CAPD addresses this problem by providing a
context-aware, policy-driven framework supporting data and knowledge exchange
among autonomous entities in a battlespace. We propose an IoBT ontology that
facilitates controlled information sharing to enable semantic interoperability
between systems. Its key contributions include providing a knowledge graph with
a shared semantic schema, integration with background knowledge, efficient
mechanisms for enforcing data consistency and drawing inferences, and
supporting attribute-based access control. The sensors in the IoBT provide data
that create populated knowledge graphs based on the ontology. This paper
describes using CAPD to detect and mitigate adversary actions. CAPD enables
situational awareness using reasoning over the sensed data and SPARQL queries.
For example, adversaries can cause sensor failure or hijacking and disrupt the
tactical networks to degrade video surveillance. In such instances, CAPD uses
an ontology-based reasoner to see how alternative approaches can still support
the mission. Depending on bandwidth availability, the reasoner initiates the
creation of a reduced frame rate grayscale video by active transcoding or
transmits only still images. This ability to reason over the mission sensed
environment and attack context permits the autonomous IoBT system to exhibit
resilience in contested conditions.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Recognizing and Extracting Cybersecurtity-relevant Entities from Text. (arXiv:2208.01693v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01693">http://arxiv.org/abs/2208.01693</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01693] Recognizing and Extracting Cybersecurtity-relevant Entities from Text](http://arxiv.org/abs/2208.01693)</code></li>
<li>Summary: <p>Cyber Threat Intelligence (CTI) is information describing threat vectors,
vulnerabilities, and attacks and is often used as training data for AI-based
cyber defense systems such as Cybersecurity Knowledge Graphs (CKG). There is a
strong need to develop community-accessible datasets to train existing AI-based
cybersecurity pipelines to efficiently and accurately extract meaningful
insights from CTI. We have created an initial unstructured CTI corpus from a
variety of open sources that we are using to train and test cybersecurity
entity models using the spaCy framework and exploring self-learning methods to
automatically recognize cybersecurity entities. We also describe methods to
apply cybersecurity domain entity linking with existing world knowledge from
Wikidata. Our future work will survey and test spaCy NLP tools and create
methods for continuous integration of new information extracted from text.
</p></li>
</ul>

<h3>Title: Evaluation of Computational Approaches of Short Weierstrass Elliptic Curves for Cryptography. (arXiv:2208.01634v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01634">http://arxiv.org/abs/2208.01634</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01634] Evaluation of Computational Approaches of Short Weierstrass Elliptic Curves for Cryptography](http://arxiv.org/abs/2208.01634)</code></li>
<li>Summary: <p>The survey presents the evolution of Short Weierstrass elliptic curves after
their introduction in cryptography. Subsequently, this evolution resulted in
the establishment of present elliptic curve computational standards. We discuss
the chronology of attacks on Elliptic Curve Discrete Logarithm Problem and
investigate their countermeasures to highlight the evolved selection criteria
of cryptographically safe elliptic curves. Further, two popular deterministic
and random approaches for selection of Short Weierstrass elliptic curve for
cryptography are evaluated from computational, security and trust perspectives
and a trend in existent computational standards is demonstrated. Finally,
standard and non-standard elliptic curves are analysed to add a new insight
into their usability. There is no such survey conducted in past to the best of
our knowledge.
</p></li>
</ul>

<h3>Title: A New Implementation of Federated Learning for Privacy and Security Enhancement. (arXiv:2208.01826v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01826">http://arxiv.org/abs/2208.01826</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01826] A New Implementation of Federated Learning for Privacy and Security Enhancement](http://arxiv.org/abs/2208.01826)</code></li>
<li>Summary: <p>Motivated by the ever-increasing concerns on personal data privacy and the
rapidly growing data volume at local clients, federated learning (FL) has
emerged as a new machine learning setting. An FL system is comprised of a
central parameter server and multiple local clients. It keeps data at local
clients and learns a centralized model by sharing the model parameters learned
locally. No local data needs to be shared, and privacy can be well protected.
Nevertheless, since it is the model instead of the raw data that is shared, the
system can be exposed to the poisoning model attacks launched by malicious
clients. Furthermore, it is challenging to identify malicious clients since no
local client data is available on the server. Besides, membership inference
attacks can still be performed by using the uploaded model to estimate the
client's local data, leading to privacy disclosure. In this work, we first
propose a model update based federated averaging algorithm to defend against
Byzantine attacks such as additive noise attacks and sign-flipping attacks. The
individual client model initialization method is presented to provide further
privacy protections from the membership inference attacks by hiding the
individual local machine learning model. When combining these two schemes,
privacy and security can be both effectively enhanced. The proposed schemes are
proved to converge experimentally under non-IID data distribution when there
are no attacks. Under Byzantine attacks, the proposed schemes perform much
better than the classical model based FedAvg algorithm.
</p></li>
</ul>

<h3>Title: Our fingerprints don't fade from the Apps we touch: Fingerprinting the Android WebView. (arXiv:2208.01968v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01968">http://arxiv.org/abs/2208.01968</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01968] Our fingerprints don't fade from the Apps we touch: Fingerprinting the Android WebView](http://arxiv.org/abs/2208.01968)</code></li>
<li>Summary: <p>Numerous studies demonstrated that browser fingerprinting is detrimental to
users' security and privacy. However, little is known about the effects of
browser fingerprinting on Android hybrid apps -- where a stripped-down Chromium
browser is integrated into an app. These apps expand the attack surface by
employing two-way communication between native apps and the web. This paper
studies the impact of browser fingerprinting on these embedded browsers. To
this end, we instrument the Android framework to record and extract information
leveraged for fingerprinting. We study over 20,000 apps, including the most
popular apps from the Google play store. We exemplify security flaws and severe
information leaks in popular apps like Instagram. Our study reveals that
fingerprints in hybrid apps potentially contain account-specific and
device-specific information that identifies users across multiple devices
uniquely. Besides, our results show that the hybrid app browser does not always
adhere to standard browser-specific privacy policies.
</p></li>
</ul>

<h3>Title: Layered Binary Templating: Efficient Detection of Compiler- and Linker-introduced Leakage. (arXiv:2208.02093v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02093">http://arxiv.org/abs/2208.02093</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02093] Layered Binary Templating: Efficient Detection of Compiler- and Linker-introduced Leakage](http://arxiv.org/abs/2208.02093)</code></li>
<li>Summary: <p>Cache template attacks demonstrated automated leakage of user input in shared
libraries. However, for large binaries, the runtime is prohibitively high.
Other automated approaches focused on cryptographic implementations and media
software but are not directly applicable to user input. Hence, discovering and
eliminating all user input side-channel leakage on a cache-line granularity
within huge code bases are impractical.
</p></li>
</ul>

<p>In this paper, we present a new generic cache template attack technique,
LBTA, layered binary templating attacks. LBTA uses multiple coarser-grained
side channel layers as an extension to cache-line granularity templating to
speed up the runtime of cache templating attacks. We describe LBTA with a
variable number of layers with concrete side channels of different granularity,
ranging from 64 B to 2MB in practice and in theory beyond. In particular the
software-level page cache side channel in combination with the hardware-level
L3 cache side channel, already reduces the templating runtime by three orders
of magnitude. We apply LBTAs to different software projects and thereby
discover data deduplication and dead-stripping during compilation and linking
as novel security issues. We show that these mechanisms introduce large spatial
distances in binaries for data accessed during a keystroke, enabling reliable
leakage of keystrokes. Using LBTA on Chromium-based applications, we can build
a full unprivileged cache-based keylogger. Our findings show that all user
input to Chromium-based apps is affected and we demonstrate this on a selection
of popular apps including Signal, Threema, Discord, and password manager apps
like passky. As this is not a flaw of individual apps but the framework, we
conclude that all apps that use the framework will also be affected, i.e.,
hundreds of apps.
</p>

<h3>Title: A Novel Approach To Network Intrusion Detection System Using Deep Learning For Sdn: Futuristic Approach. (arXiv:2208.02094v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02094">http://arxiv.org/abs/2208.02094</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02094] A Novel Approach To Network Intrusion Detection System Using Deep Learning For Sdn: Futuristic Approach](http://arxiv.org/abs/2208.02094)</code></li>
<li>Summary: <p>Software-Defined Networking (SDN) is the next generation to change the
architecture of traditional networks. SDN is one of the promising solutions to
change the architecture of internet networks. Attacks become more common due to
the centralized nature of SDN architecture. It is vital to provide security for
the SDN. In this study, we propose a Network Intrusion Detection System-Deep
Learning module (NIDS-DL) approach in the context of SDN. Our suggested method
combines Network Intrusion Detection Systems (NIDS) with many types of deep
learning algorithms. Our approach employs 12 features extracted from 41
features in the NSL-KDD dataset using a feature selection method. We employed
classifiers (CNN, DNN, RNN, LSTM, and GRU). When we compare classifier scores,
our technique produced accuracy results of (98.63%, 98.53%, 98.13%, 98.04%, and
97.78%) respectively. The novelty of our new approach (NIDS-DL) uses 5 deep
learning classifiers and made pre-processing dataset to harvests the best
results. Our proposed approach was successful in binary classification and
detecting attacks, implying that our approach (NIDS-DL) might be used with
great efficiency in the future.
</p></li>
</ul>

<h3>Title: Abusing Commodity DRAMs in IoT Devices to Remotely Spy on Temperature. (arXiv:2208.02125v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02125">http://arxiv.org/abs/2208.02125</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02125] Abusing Commodity DRAMs in IoT Devices to Remotely Spy on Temperature](http://arxiv.org/abs/2208.02125)</code></li>
<li>Summary: <p>The ubiquity and pervasiveness of modern Internet of Things (IoT) devices
opens up vast possibilities for novel applications, but simultaneously also
allows spying on, and collecting data from, unsuspecting users to a previously
unseen extent. This paper details a new attack form in this vein, in which the
decay properties of widespread, off-the-shelf DRAM modules are exploited to
accurately sense the temperature in the vicinity of the DRAM-carrying device.
Among others, this enables adversaries to remotely and purely digitally spy on
personal behavior in users' private homes, or to collect security-critical data
in server farms, cloud storage centers, or commercial production lines. We
demonstrate that our attack can be performed by merely compromising the
software of an IoT device and does not require hardware modifications or
physical access at attack time. It can achieve temperature resolutions of up to
0.5{\deg}C over a range of 0{\deg}C to 70{\deg}C in practice. Perhaps most
interestingly, it even works in devices that do not have a dedicated
temperature sensor on board. To complete our work, we discuss practical attack
scenarios as well as possible countermeasures against our temperature espionage
attacks.
</p></li>
</ul>

<h3>Title: Scrypt Mining with ASICs. (arXiv:2208.02160v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02160">http://arxiv.org/abs/2208.02160</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02160] Scrypt Mining with ASICs](http://arxiv.org/abs/2208.02160)</code></li>
<li>Summary: <p>Cryptocurrencies have garnered a lot of attention by governments and internet
enthusiasts over the past three years. These currencies are celebrated for
their security and speedy transactions in a modern era of digital commerce.
Bitcoin was the first of these currencies to gain a large advantage over
subsequent iterations. Bitcoin was first conceived by Satoshi Nakamoto who
mentioned the concept of a cryptocurrency in his paper titled Bitcoin. It
featured new concepts such as proof of work and transactions which utilized
hash based encryption. One particular alternative cryptocurrency is known as
Litecoin. Backed by a memory intensive algorithm known as Scrypt, many
cryptocurrency enthusiasts have decided to celebrate this particular coin.
Scrypt expands on Bitcoin's proof of work algorithm by adding the amount of
work it takes to commit a transaction within the Litecoin network. Scrypt
forces more work on the device that is being used to perform the algorithm by
making frequent memory requests. This makes it difficult to create specialized
hardware to create new coins and to commit transactions due to the nature of
memory intensive applications.
</p></li>
</ul>

<h3>Title: Statistical Decoding 2.0: Reducing Decoding to LPN. (arXiv:2208.02201v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02201">http://arxiv.org/abs/2208.02201</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02201] Statistical Decoding 2](http://arxiv.org/abs/2208.02201)</code></li>
<li>Summary: <p>The security of code-based cryptography relies primarily on the hardness of
generic decoding with linear codes. The best generic decoding algorithms are
all improvements of an old algorithm due to Prange: they are known under the
name of information set decoders (ISD). A while ago, a generic decoding
algorithm which does not belong to this family was proposed: statistical
decoding. It is a randomized algorithm that requires the computation of a large
set of parity-checks of moderate weight, and uses some kind of majority voting
on these equations to recover the error. This algorithm was long forgotten
because even the best variants of it performed poorly when compared to the
simplest ISD algorithm.
</p></li>
</ul>

<p>We revisit this old algorithm by using parity-check equations in a more
general way. Here the parity-checks are used to get LPN samples with a secret
which is part of the error and the LPN noise is related to the weight of the
parity-checks we produce. The corresponding LPN problem is then solved by
standard Fourier techniques. By properly choosing the method of producing these
low weight equations and the size of the LPN problem, we are able to outperform
in this way significantly information set decodings at code rates smaller than
$0.3$. It gives for the first time after $60$ years, a better decoding
algorithm for a significant range which does not belong to the ISD family.
</p>

<h3>Title: Contrasting global approaches for identifying and managing cybersecurity risks in supply chains. (arXiv:2208.02244v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02244">http://arxiv.org/abs/2208.02244</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02244] Contrasting global approaches for identifying and managing cybersecurity risks in supply chains](http://arxiv.org/abs/2208.02244)</code></li>
<li>Summary: <p>Supply chains are increasingly targeted by threat actors. Using a recent
taxonomy, we contrast the diverse levels of detail given by national
authorities. The threat is commonly acknowledged, but guidance is disjointed.
NIST SP 800-161 aligns closely with the taxonomy and offers a potential pathway
towards a common set of principles.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: A Roadmap for Greater Public Use of Privacy-Sensitive Government Data: Workshop Report. (arXiv:2208.01636v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01636">http://arxiv.org/abs/2208.01636</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01636] A Roadmap for Greater Public Use of Privacy-Sensitive Government Data: Workshop Report](http://arxiv.org/abs/2208.01636)</code></li>
<li>Summary: <p>Government agencies collect and manage a wide range of ever-growing datasets.
While such data has the potential to support research and evidence-based policy
making, there are concerns that the dissemination of such data could infringe
upon the privacy of the individuals (or organizations) from whom such data was
collected. To appraise the current state of data sharing, as well as learn
about opportunities for stimulating such sharing at a faster pace, a virtual
workshop was held on May 21st and 26th, 2021, sponsored by the National Science
Foundation and National Institute of Standards and Technologies, where a
multinational collection of researchers and practitioners were brought together
to discuss their experiences and learn about recently developed technologies
for managing privacy while sharing data. The workshop specifically focused on
challenges and successes in government data sharing at various levels. The
first day focused on successful examples of new technology applied to sharing
of public data, including formal privacy techniques, synthetic data, and
cryptographic approaches. Day two emphasized brainstorming sessions on some of
the challenges and directions to address them.
</p></li>
</ul>

<h3>Title: CCTV-Exposure: An open-source system for measuring user's privacy exposure to mapped CCTV cameras based on geo-location (Extended Version). (arXiv:2208.02159v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02159">http://arxiv.org/abs/2208.02159</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02159] CCTV-Exposure: An open-source system for measuring user's privacy exposure to mapped CCTV cameras based on geo-location (Extended Version)](http://arxiv.org/abs/2208.02159)</code></li>
<li>Summary: <p>In this work, we present CCTV-Exposure -- the first CCTV-aware solution to
evaluate potential privacy exposure to closed-circuit television (CCTV)
cameras. The objective was to develop a toolset for quantifying human exposure
to CCTV cameras from a privacy perspective. Our novel approach is trajectory
analysis of the individuals, coupled with a database of geo-location mapped
CCTV cameras annotated with minimal yet sufficient meta-information. For this
purpose, CCTV-Exposure model based on a Global Positioning System (GPS)
tracking was applied to estimate individual privacy exposure in different
scenarios. The current investigation provides an application example and
validation of the modeling approach. The methodology and toolset developed and
implemented in this work provide time-sequence and location-sequence of the
exposure events, thus making possible association of the exposure with the
individual activities and cameras, and delivers main statistics on individual's
exposure to CCTV cameras with high spatio-temporal resolution.
</p></li>
</ul>

<h3>Title: Quantifying Temporal Privacy Leakage in Continuous Event Data Publishing. (arXiv:2208.01886v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01886">http://arxiv.org/abs/2208.01886</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01886] Quantifying Temporal Privacy Leakage in Continuous Event Data Publishing](http://arxiv.org/abs/2208.01886)</code></li>
<li>Summary: <p>Process mining employs event data extracted from different types of
information systems to discover and analyze actual processes. Event data often
contain highly sensitive information about the people who carry out activities
or the people for whom activities are performed. Therefore, privacy concerns in
process mining are receiving increasing attention. To alleviate privacy-related
risks, several privacy preservation techniques have been proposed. Differential
privacy is one of these techniques which provides strong privacy guarantees.
However, the proposed techniques presume that event data are released in only
one shot, whereas business processes are continuously executed. Hence, event
data are published repeatedly, resulting in additional risks. In this paper, we
demonstrate that continuously released event data are not independent, and the
correlation among different releases can result in privacy degradation when the
same differential privacy mechanism is applied to each release. We quantify
such privacy degradation in the form of temporal privacy leakages. We apply
continuous event data publishing scenarios to real-life event logs to
demonstrate privacy leakages.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Multiclass ASMA vs Targeted PGD Attack in Image Segmentation. (arXiv:2208.01844v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01844">http://arxiv.org/abs/2208.01844</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01844] Multiclass ASMA vs Targeted PGD Attack in Image Segmentation](http://arxiv.org/abs/2208.01844)</code></li>
<li>Summary: <p>Deep learning networks have demonstrated high performance in a large variety
of applications, such as image classification, speech recognition, and natural
language processing. However, there exists a major vulnerability exploited by
the use of adversarial attacks. An adversarial attack imputes images by
altering the input image very slightly, making it nearly undetectable to the
naked eye, but results in a very different classification by the network. This
paper explores the projected gradient descent (PGD) attack and the Adaptive
Mask Segmentation Attack (ASMA) on the image segmentation DeepLabV3 model using
two types of architectures: MobileNetV3 and ResNet50, It was found that PGD was
very consistent in changing the segmentation to be its target while the
generalization of ASMA to a multiclass target was not as effective. The
existence of such attack however puts all of image classification deep learning
networks in danger of exploitation.
</p></li>
</ul>

<h3>Title: Adversarial Camouflage for Node Injection Attack on Graphs. (arXiv:2208.01819v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01819">http://arxiv.org/abs/2208.01819</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01819] Adversarial Camouflage for Node Injection Attack on Graphs](http://arxiv.org/abs/2208.01819)</code></li>
<li>Summary: <p>Node injection attacks against Graph Neural Networks (GNNs) have received
emerging attention as a practical attack scenario, where the attacker injects
malicious nodes instead of modifying node features or edges to degrade the
performance of GNNs. Despite the initial success of node injection attacks, we
find that the injected nodes by existing methods are easy to be distinguished
from the original normal nodes by defense methods and limiting their attack
performance in practice. To solve the above issues, we devote to camouflage
node injection attack, i.e., camouflaging injected malicious nodes
(structure/attributes) as the normal ones that appear legitimate/imperceptible
to defense methods. The non-Euclidean nature of graph data and the lack of
human prior brings great challenges to the formalization, implementation, and
evaluation of camouflage on graphs. In this paper, we first propose and
formulate the camouflage of injected nodes from both the fidelity and diversity
of the ego networks centered around injected nodes. Then, we design an
adversarial CAmouflage framework for Node injection Attack, namely CANA, to
improve the camouflage while ensuring the attack performance. Several novel
indicators for graph camouflage are further designed for a comprehensive
evaluation. Experimental results demonstrate that when equipping existing node
injection attack methods with our proposed CANA framework, the attack
performance against defense methods as well as node camouflage is significantly
improved.
</p></li>
</ul>

<h3>Title: Mass Exit Attacks on the Lightning Network. (arXiv:2208.01908v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01908">http://arxiv.org/abs/2208.01908</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01908] Mass Exit Attacks on the Lightning Network](http://arxiv.org/abs/2208.01908)</code></li>
<li>Summary: <p>The Lightning Network (LN) has enjoyed rapid growth over recent years, and
has become the most popular scaling solution for the Bitcoin blockchain. The
security of the LN hinges on the ability of the nodes to close a channel by
settling their balances, which requires confirming a transaction on the Bitcoin
blockchain within a pre-agreed time period. This inherent timing restriction
that the LN must satisfy, make it susceptible to attacks that seek to increase
the congestion on the Bitcoin blockchain, thus preventing correct protocol
execution. We study the susceptibility of the LN to \emph{mass exit} attacks,
in the presence of a small coalition of adversarial nodes. This is a scenario
where an adversary forces a large set of honest protocol participants to
interact with the blockchain. We focus on two types of attacks: (i) The first
is a \emph{zombie} attack, where a set of $k$ nodes become unresponsive with
the goal to lock the funds of many channels for a period of time longer than
what the LN protocol dictates. (ii) The second is a \emph{mass double-spend}
attack, where a set of $k$ nodes attempt to steal funds by submitting many
closing transactions that settle channels using expired protocol states; this
causes many honest nodes to have to quickly respond by submitting invalidating
transactions. We show via simulations that, under historically-plausible
congestion conditions, with mild statistical assumptions on channel balances,
both of the attacks can be performed by a very small coalition. To perform our
simulations, we formulate the problem of finding a worst-case coalition of $k$
adversarial nodes as a graph cut problem. Our experimental findings are
supported by a theoretical justification based on the scale-free topology of
the LN.
</p></li>
</ul>

<h3>Title: Spectrum Focused Frequency Adversarial Attacks for Automatic Modulation Classification. (arXiv:2208.01919v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01919">http://arxiv.org/abs/2208.01919</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01919] Spectrum Focused Frequency Adversarial Attacks for Automatic Modulation Classification](http://arxiv.org/abs/2208.01919)</code></li>
<li>Summary: <p>Artificial intelligence (AI) technology has provided a potential solution for
automatic modulation recognition (AMC). Unfortunately, AI-based AMC models are
vulnerable to adversarial examples, which seriously threatens the efficient,
secure and trusted application of AI in AMC. This issue has attracted the
attention of researchers. Various studies on adversarial attacks and defenses
evolve in a spiral. However, the existing adversarial attack methods are all
designed in the time domain. They introduce more high-frequency components in
the frequency domain, due to abrupt updates in the time domain. For this issue,
from the perspective of frequency domain, we propose a spectrum focused
frequency adversarial attacks (SFFAA) for AMC model, and further draw on the
idea of meta-learning, propose a Meta-SFFAA algorithm to improve the
transferability in the black-box attacks. Extensive experiments, qualitative
and quantitative metrics demonstrate that the proposed algorithm can
concentrate the adversarial energy on the spectrum where the signal is located,
significantly improve the adversarial attack performance while maintaining the
concealment in the frequency domain.
</p></li>
</ul>

<h3>Title: Success of Uncertainty-Aware Deep Models Depends on Data Manifold Geometry. (arXiv:2208.01705v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01705">http://arxiv.org/abs/2208.01705</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01705] Success of Uncertainty-Aware Deep Models Depends on Data Manifold Geometry](http://arxiv.org/abs/2208.01705)</code></li>
<li>Summary: <p>For responsible decision making in safety-critical settings, machine learning
models must effectively detect and process edge-case data. Although existing
works show that predictive uncertainty is useful for these tasks, it is not
evident from literature which uncertainty-aware models are best suited for a
given dataset. Thus, we compare six uncertainty-aware deep learning models on a
set of edge-case tasks: robustness to adversarial attacks as well as
out-of-distribution and adversarial detection. We find that the geometry of the
data sub-manifold is an important factor in determining the success of various
models. Our finding suggests an interesting direction in the study of
uncertainty-aware deep learning models.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Robust RGB-D Fusion for Saliency Detection. (arXiv:2208.01762v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01762">http://arxiv.org/abs/2208.01762</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01762] Robust RGB-D Fusion for Saliency Detection](http://arxiv.org/abs/2208.01762)</code></li>
<li>Summary: <p>Efficiently exploiting multi-modal inputs for accurate RGB-D saliency
detection is a topic of high interest. Most existing works leverage cross-modal
interactions to fuse the two streams of RGB-D for intermediate features'
enhancement. In this process, a practical aspect of the low quality of the
available depths has not been fully considered yet. In this work, we aim for
RGB-D saliency detection that is robust to the low-quality depths which
primarily appear in two forms: inaccuracy due to noise and the misalignment to
RGB. To this end, we propose a robust RGB-D fusion method that benefits from
(1) layer-wise, and (2) trident spatial, attention mechanisms. On the one hand,
layer-wise attention (LWA) learns the trade-off between early and late fusion
of RGB and depth features, depending upon the depth accuracy. On the other
hand, trident spatial attention (TSA) aggregates the features from a wider
spatial context to address the depth misalignment problem. The proposed LWA and
TSA mechanisms allow us to efficiently exploit the multi-modal inputs for
saliency detection while being robust against low-quality depths. Our
experiments on five benchmark datasets demonstrate that the proposed fusion
method performs consistently better than the state-of-the-art fusion
alternatives.
</p></li>
</ul>

<h3>Title: Rethinking the Evaluation of Unbiased Scene Graph Generation. (arXiv:2208.01909v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01909">http://arxiv.org/abs/2208.01909</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01909] Rethinking the Evaluation of Unbiased Scene Graph Generation](http://arxiv.org/abs/2208.01909)</code></li>
<li>Summary: <p>Since the severe imbalanced predicate distributions in common subject-object
relations, current Scene Graph Generation (SGG) methods tend to predict
frequent predicate categories and fail to recognize rare ones. To improve the
robustness of SGG models on different predicate categories, recent research has
focused on unbiased SGG and adopted mean Recall@K (mR@K) as the main evaluation
metric. However, we discovered two overlooked issues about this de facto
standard metric mR@K, which makes current unbiased SGG evaluation vulnerable
and unfair: 1) mR@K neglects the correlations among predicates and
unintentionally breaks category independence when ranking all the triplet
predictions together regardless of the predicate categories, leading to the
performance of some predicates being underestimated. 2) mR@K neglects the
compositional diversity of different predicates and assigns excessively high
weights to some oversimple category samples with limited composable relation
triplet types. It totally conflicts with the goal of SGG task which encourages
models to detect more types of visual relationship triplets. In addition, we
investigate the under-explored correlation between objects and predicates,
which can serve as a simple but strong baseline for unbiased SGG. In this
paper, we refine mR@K and propose two complementary evaluation metrics for
unbiased SGG: Independent Mean Recall (IMR) and weighted IMR (wIMR). These two
metrics are designed by considering the category independence and diversity of
composable relation triplets, respectively. We compare the proposed metrics
with the de facto standard metrics through extensive experiments and discuss
the solutions to evaluate unbiased SGG in a more trustworthy way.
</p></li>
</ul>

<h3>Title: Decay2Distill: Leveraging spatial perturbation and regularization for self-supervised image denoisin. (arXiv:2208.01948v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01948">http://arxiv.org/abs/2208.01948</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01948] Decay2Distill: Leveraging spatial perturbation and regularization for self-supervised image denoisin](http://arxiv.org/abs/2208.01948)</code></li>
<li>Summary: <p>Unpaired image denoising has achieved promising development over the last few
years. Regardless of the performance, methods tend to heavily rely on
underlying noise properties or any assumption which is not always practical.
Alternatively, if we can ground the problem from a structural perspective
rather than noise statistics, we can achieve a more robust solution. with such
motivation, we propose a self-supervised denoising scheme that is unpaired and
relies on spatial degradation followed by a regularized refinement. Our method
shows considerable improvement over previous methods and exhibited consistent
performance over different data domains.
</p></li>
</ul>

<h3>Title: Localization and Classification of Parasitic Eggs in Microscopic Images Using an EfficientDet Detector. (arXiv:2208.01963v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01963">http://arxiv.org/abs/2208.01963</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01963] Localization and Classification of Parasitic Eggs in Microscopic Images Using an EfficientDet Detector](http://arxiv.org/abs/2208.01963)</code></li>
<li>Summary: <p>IPIs caused by protozoan and helminth parasites are among the most common
infections in humans in LMICs. They are regarded as a severe public health
concern, as they cause a wide array of potentially detrimental health
conditions. Researchers have been developing pattern recognition techniques for
the automatic identification of parasite eggs in microscopic images. Existing
solutions still need improvements to reduce diagnostic errors and generate
fast, efficient, and accurate results. Our paper addresses this and proposes a
multi-modal learning detector to localize parasitic eggs and categorize them
into 11 categories. The experiments were conducted on the novel
Chula-ParasiteEgg-11 dataset that was used to train both EfficientDet model
with EfficientNet-v2 backbone and EfficientNet-B7+SVM. The dataset has 11,000
microscopic training images from 11 categories. Our results show robust
performance with an accuracy of 92%, and an F1 score of 93%. Additionally, the
IOU distribution illustrates the high localization capability of the detector.
</p></li>
</ul>

<h3>Title: Convolutional Fine-Grained Classification with Self-Supervised Target Relation Regularization. (arXiv:2208.01997v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01997">http://arxiv.org/abs/2208.01997</a></li>
<li>Code URL: <a href="https://github.com/akonlau/dtrg">https://github.com/akonlau/dtrg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01997] Convolutional Fine-Grained Classification with Self-Supervised Target Relation Regularization](http://arxiv.org/abs/2208.01997)</code></li>
<li>Summary: <p>Fine-grained visual classification can be addressed by deep representation
learning under supervision of manually pre-defined targets (e.g., one-hot or
the Hadamard codes). Such target coding schemes are less flexible to model
inter-class correlation and are sensitive to sparse and imbalanced data
distribution as well. In light of this, this paper introduces a novel target
coding scheme -- dynamic target relation graphs (DTRG), which, as an auxiliary
feature regularization, is a self-generated structural output to be mapped from
input images. Specifically, online computation of class-level feature centers
is designed to generate cross-category distance in the representation space,
which can thus be depicted by a dynamic graph in a non-parametric manner.
Explicitly minimizing intra-class feature variations anchored on those
class-level centers can encourage learning of discriminative features.
Moreover, owing to exploiting inter-class dependency, the proposed target
graphs can alleviate data sparsity and imbalanceness in representation
learning. Inspired by recent success of the mixup style data augmentation, this
paper introduces randomness into soft construction of dynamic target relation
graphs to further explore relation diversity of target classes. Experimental
results can demonstrate the effectiveness of our method on a number of diverse
benchmarks of multiple visual classification tasks, especially achieving the
state-of-the-art performance on popular fine-grained object benchmarks and
superior robustness against sparse and imbalanced data. Source codes are made
publicly available at https://github.com/AkonLau/DTRG.
</p></li>
</ul>

<h3>Title: KD-SCFNet: Towards More Accurate and Efficient Salient Object Detection via Knowledge Distillation. (arXiv:2208.02178v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02178">http://arxiv.org/abs/2208.02178</a></li>
<li>Code URL: <a href="https://github.com/zhangjincv/kd-scfnet">https://github.com/zhangjincv/kd-scfnet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02178] KD-SCFNet: Towards More Accurate and Efficient Salient Object Detection via Knowledge Distillation](http://arxiv.org/abs/2208.02178)</code></li>
<li>Summary: <p>Most existing salient object detection (SOD) models are difficult to apply
due to the complex and huge model structures. Although some lightweight models
are proposed, the accuracy is barely satisfactory. In this paper, we design a
novel semantics-guided contextual fusion network (SCFNet) that focuses on the
interactive fusion of multi-level features for accurate and efficient salient
object detection. Furthermore, we apply knowledge distillation to SOD task and
provide a sizeable dataset KD-SOD80K. In detail, we transfer the rich knowledge
from a seasoned teacher to the untrained SCFNet through unlabeled images,
enabling SCFNet to learn a strong generalization ability to detect salient
objects more accurately. The knowledge distillation based SCFNet (KDSCFNet)
achieves comparable accuracy to the state-of-the-art heavyweight methods with
less than 1M parameters and 174 FPS real-time detection speed. Extensive
experiments demonstrate the robustness and effectiveness of the proposed
distillation method and SOD framework. Code and data:
https://github.com/zhangjinCV/KD-SCFNet.
</p></li>
</ul>

<h3>Title: Robust Learning of Deep Time Series Anomaly Detection Models with Contaminated Training Data. (arXiv:2208.01841v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01841">http://arxiv.org/abs/2208.01841</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01841] Robust Learning of Deep Time Series Anomaly Detection Models with Contaminated Training Data](http://arxiv.org/abs/2208.01841)</code></li>
<li>Summary: <p>Time series anomaly detection (TSAD) is an important data mining task with
numerous applications in the IoT era. In recent years, a large number of deep
neural network-based methods have been proposed, demonstrating significantly
better performance than conventional methods on addressing challenging TSAD
problems in a variety of areas. Nevertheless, these deep TSAD methods typically
rely on a clean training dataset that is not polluted by anomalies to learn the
"normal profile" of the underlying dynamics. This requirement is nontrivial
since a clean dataset can hardly be provided in practice. Moreover, without the
awareness of their robustness, blindly applying deep TSAD methods with
potentially contaminated training data can possibly incur significant
performance degradation in the detection phase. In this work, to tackle this
important challenge, we firstly investigate the robustness of commonly used
deep TSAD methods with contaminated training data which provides a guideline
for applying these methods when the provided training data are not guaranteed
to be anomaly-free. Furthermore, we propose a model-agnostic method which can
effectively improve the robustness of learning mainstream deep TSAD models with
potentially contaminated data. Experiment results show that our method can
consistently prevent or mitigate performance degradation of mainstream deep
TSAD models on widely used benchmark datasets.
</p></li>
</ul>

<h3>Title: Robust Graph Neural Networks using Weighted Graph Laplacian. (arXiv:2208.01853v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01853">http://arxiv.org/abs/2208.01853</a></li>
<li>Code URL: <a href="https://github.com/bharat-runwal/rwl-gnn">https://github.com/bharat-runwal/rwl-gnn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01853] Robust Graph Neural Networks using Weighted Graph Laplacian](http://arxiv.org/abs/2208.01853)</code></li>
<li>Summary: <p>Graph neural network (GNN) is achieving remarkable performances in a variety
of application domains. However, GNN is vulnerable to noise and adversarial
attacks in input data. Making GNN robust against noises and adversarial attacks
is an important problem. The existing defense methods for GNNs are
computationally demanding and are not scalable. In this paper, we propose a
generic framework for robustifying GNN known as Weighted Laplacian GNN
(RWL-GNN). The method combines Weighted Graph Laplacian learning with the GNN
implementation. The proposed method benefits from the positive
semi-definiteness property of Laplacian matrix, feature smoothness, and latent
features via formulating a unified optimization framework, which ensures the
adversarial/noisy edges are discarded and connections in the graph are
appropriately weighted. For demonstration, the experiments are conducted with
Graph convolutional neural network(GCNN) architecture, however, the proposed
framework is easily amenable to any existing GNN architecture. The simulation
results with benchmark dataset establish the efficacy of the proposed method,
both in accuracy and computational efficiency. Code can be accessed at
https://github.com/Bharat-Runwal/RWL-GNN.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Cross-Lingual Knowledge Transfer for Clinical Phenotyping. (arXiv:2208.01912v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01912">http://arxiv.org/abs/2208.01912</a></li>
<li>Code URL: <a href="https://github.com/neuron1682/cross-lingual-phenotype-prediction">https://github.com/neuron1682/cross-lingual-phenotype-prediction</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01912] Cross-Lingual Knowledge Transfer for Clinical Phenotyping](http://arxiv.org/abs/2208.01912)</code></li>
<li>Summary: <p>Clinical phenotyping enables the automatic extraction of clinical conditions
from patient records, which can be beneficial to doctors and clinics worldwide.
However, current state-of-the-art models are mostly applicable to clinical
notes written in English. We therefore investigate cross-lingual knowledge
transfer strategies to execute this task for clinics that do not use the
English language and have a small amount of in-domain data available. We
evaluate these strategies for a Greek and a Spanish clinic leveraging clinical
notes from different clinical domains such as cardiology, oncology and the ICU.
Our results reveal two strategies that outperform the state-of-the-art:
Translation-based methods in combination with domain-specific encoders and
cross-lingual encoders plus adapters. We find that these strategies perform
especially well for classifying rare phenotypes and we advise on which method
to prefer in which situation. Our results show that using multilingual data
overall improves clinical phenotyping models and can compensate for data
sparseness.
</p></li>
</ul>

<h3>Title: KPI-BERT: A Joint Named Entity Recognition and Relation Extraction Model for Financial Reports. (arXiv:2208.02140v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02140">http://arxiv.org/abs/2208.02140</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02140] KPI-BERT: A Joint Named Entity Recognition and Relation Extraction Model for Financial Reports](http://arxiv.org/abs/2208.02140)</code></li>
<li>Summary: <p>We present KPI-BERT, a system which employs novel methods of named entity
recognition (NER) and relation extraction (RE) to extract and link key
performance indicators (KPIs), e.g. "revenue" or "interest expenses", of
companies from real-world German financial documents. Specifically, we
introduce an end-to-end trainable architecture that is based on Bidirectional
Encoder Representations from Transformers (BERT) combining a recurrent neural
network (RNN) with conditional label masking to sequentially tag entities
before it classifies their relations. Our model also introduces a learnable
RNN-based pooling mechanism and incorporates domain expert knowledge by
explicitly filtering impossible relations. We achieve a substantially higher
prediction performance on a new practical dataset of German financial reports,
outperforming several strong baselines including a competing state-of-the-art
span-based entity tagging approach.
</p></li>
</ul>

<h3>Title: V-Coder: Adaptive AutoEncoder for Semantic Disclosure in Knowledge Graphs. (arXiv:2208.01735v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01735">http://arxiv.org/abs/2208.01735</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01735] V-Coder: Adaptive AutoEncoder for Semantic Disclosure in Knowledge Graphs](http://arxiv.org/abs/2208.01735)</code></li>
<li>Summary: <p>Semantic Web or Knowledge Graphs (KG) emerged to one of the most important
information source for intelligent systems requiring access to structured
knowledge. One of the major challenges is the extraction and processing of
unambiguous information from textual data. Following the human perception,
overlapping semantic linkages between two named entities become clear due to
our common-sense about the context a relationship lives in which is not the
case when we look at it from an automatically driven process of a machine. In
this work, we are interested in the problem of Relational Resolution within the
scope of KGs, i.e, we are investigating the inherent semantic of relationships
between entities within a network. We propose a new adaptive AutoEncoder,
called V-Coder, to identify relations inherently connecting entities from
different domains. Those relations can be considered as being ambiguous and are
candidates for disentanglement. Likewise to the Adaptive Learning Theory (ART),
our model learns new patterns from the KG by increasing units in a competitive
layer without discarding the previous observed patterns whilst learning the
quality of each relation separately. The evaluation on real-world datasets of
Freebase, Yago and NELL shows that the V-Coder is not only able to recover
links from corrupted input data, but also shows that the semantic disclosure of
relations in a KG show the tendency to improve link prediction. A semantic
evaluation wraps the evaluation up.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Differentially Private Vertical Federated Clustering. (arXiv:2208.01700v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01700">http://arxiv.org/abs/2208.01700</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01700] Differentially Private Vertical Federated Clustering](http://arxiv.org/abs/2208.01700)</code></li>
<li>Summary: <p>In many applications, multiple parties have private data regarding the same
set of users but on disjoint sets of attributes, and a server wants to leverage
the data to train a model. To enable model learning while protecting the
privacy of the data subjects, we need vertical federated learning (VFL)
techniques, where the data parties share only information for training the
model, instead of the private data. However, it is challenging to ensure that
the shared information maintains privacy while learning accurate models. To the
best of our knowledge, the algorithm proposed in this paper is the first
practical solution for differentially private vertical federated k-means
clustering, where the server can obtain a set of global centers with a provable
differential privacy guarantee. Our algorithm assumes an untrusted central
server that aggregates differentially private local centers and membership
encodings from local data parties. It builds a weighted grid as the synopsis of
the global dataset based on the received information. Final centers are
generated by running any k-means algorithm on the weighted grid. Our approach
for grid weight estimation uses a novel, light-weight, and differentially
private set intersection cardinality estimation algorithm based on the
Flajolet-Martin sketch. To improve the estimation accuracy in the setting with
more than two data parties, we further propose a refined version of the weights
estimation algorithm and a parameter tuning strategy to reduce the final
k-means utility to be close to that in the central private setting. We provide
theoretical utility analysis and experimental evaluation results for the
cluster centers computed by our algorithm and show that our approach performs
better both theoretically and empirically than the two baselines based on
existing techniques.
</p></li>
</ul>

<h3>Title: Asynchronous Federated Learning for Edge-assisted Vehicular Networks. (arXiv:2208.01901v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01901">http://arxiv.org/abs/2208.01901</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01901] Asynchronous Federated Learning for Edge-assisted Vehicular Networks](http://arxiv.org/abs/2208.01901)</code></li>
<li>Summary: <p>Vehicular networks enable vehicles support real-time vehicular applications
through training data. Due to the limited computing capability, vehicles
usually transmit data to a road side unit (RSU) at the network edge to process
data. However, vehicles are usually reluctant to share data with each other due
to the privacy issue. For the traditional federated learning (FL), vehicles
train the data locally to obtain a local model and then upload the local model
to the RSU to update the global model, thus the data privacy can be protected
through sharing model parameters instead of data. The traditional FL updates
the global model synchronously, i.e., the RSU needs to wait for all vehicles to
upload their models for the global model updating. However, vehicles may
usually drive out of the coverage of the RSU before they obtain their local
models through training, which reduces the accuracy of the global model. It is
necessary to propose an asynchronous federated learning (AFL) to solve this
problem, where the RSU updates the global model once it receives a local model
from a vehicle. However, the amount of data, computing capability and vehicle
mobility may affect the accuracy of the global model. In this paper, we jointly
consider the amount of data, computing capability and vehicle mobility to
design an AFL scheme to improve the accuracy of the global model. Extensive
simulation experiments have demonstrated that our scheme outperforms the FL
scheme
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: From Single Aircraft to Communities: A Neutral Interpretation of Air Traffic Complexity Dynamics. (arXiv:2208.01740v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01740">http://arxiv.org/abs/2208.01740</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01740] From Single Aircraft to Communities: A Neutral Interpretation of Air Traffic Complexity Dynamics](http://arxiv.org/abs/2208.01740)</code></li>
<li>Summary: <p>Present air traffic complexity metrics are defined considering the interests
of different management layers of ATM. These layers have different objectives
which in practice compete to maximize their own goals, which leads to
fragmented decision making. This fragmentation together with competing KPAs
requires transparent and neutral air traffic information to pave the way for an
explainable set of actions. In this paper, we introduce the concept of single
aircraft complexity, to determine the contribution of each aircraft to the
overall complexity of air traffic. Furthermore, we describe a methodology
extending this concept to define complex communities, which are groups of
interdependent aircraft that contribute the majority of the complexity in a
certain airspace. In order to showcase the methodology, a tool that visualizes
different outputs of the algorithm is developed. Through use-cases based on
synthetic and real historical traffic, we first show that the algorithm can
serve to formalize controller decisions as well as guide controllers to better
decisions. Further, we investigate how the provided information can be used to
increase transparency of the decision makers towards different airspace users,
which serves also to increase fairness and equity. Lastly, a sensitivity
analysis is conducted in order to systematically analyse how each input affects
the methodology.
</p></li>
</ul>

<h3>Title: A Lightweight Transmission Parameter Selection Scheme Using Reinforcement Learning for LoRaWAN. (arXiv:2208.01824v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01824">http://arxiv.org/abs/2208.01824</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01824] A Lightweight Transmission Parameter Selection Scheme Using Reinforcement Learning for LoRaWAN](http://arxiv.org/abs/2208.01824)</code></li>
<li>Summary: <p>The number of IoT devices is predicted to reach 125 billion by 2023. The
growth of IoT devices will intensify the collisions between devices, degrading
communication performance. Selecting appropriate transmission parameters, such
as channel and spreading factor (SF), can effectively reduce the collisions
between long-range (LoRa) devices. However, most of the schemes proposed in the
current literature are not easy to implement on an IoT device with limited
computational complexity and memory. To solve this issue, we propose a
lightweight transmission-parameter selection scheme, i.e., a joint channel and
SF selection scheme using reinforcement learning for low-power wide area
networking (LoRaWAN). In the proposed scheme, appropriate transmission
parameters can be selected by simple four arithmetic operations using only
Acknowledge (ACK) information. Additionally, we theoretically analyze the
computational complexity and memory requirement of our proposed scheme, which
verified that our proposed scheme could select transmission parameters with
extremely low computational complexity and memory requirement. Moreover, a
large number of experiments were implemented on the LoRa devices in the real
world to evaluate the effectiveness of our proposed scheme. The experimental
results demonstrate the following main phenomena. (1) Compared to other
lightweight transmission-parameter selection schemes, collisions between LoRa
devices can be efficiently avoided by our proposed scheme in LoRaWAN
irrespective of changes in the available channels. (2) The frame success rate
(FSR) can be improved by selecting access channels and using SFs as opposed to
only selecting access channels. (3) Since interference exists between adjacent
channels, FSR and fairness can be improved by increasing the interval of
adjacent available channels.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: The Importance of the Instantaneous Phase in Detecting Faces with Convolutional Neural Networks. (arXiv:2208.01638v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01638">http://arxiv.org/abs/2208.01638</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01638] The Importance of the Instantaneous Phase in Detecting Faces with Convolutional Neural Networks](http://arxiv.org/abs/2208.01638)</code></li>
<li>Summary: <p>Convolutional Neural Networks (CNN) have provided new and accurate methods
for processing digital images and videos. Yet, training CNNs is extremely
demanding in terms of computational resources. Also, for specific applications,
the standard use of transfer learning also tends to require far more resources
than what may be needed. Furthermore, the final systems tend to operate as
black boxes that are difficult to interpret. The current thesis considers the
problem of detecting faces from the AOLME video dataset. The AOLME dataset
consists of a large video collection of group interactions that are recorded in
unconstrained classroom environments. For the thesis, still image frames were
extracted at every minute from 18 24-minute videos. Then, each video frame was
divided into 9x5 blocks with 50x50 pixels each. For each of the 19440 blocks,
the percentage of face pixels was set as ground truth. Face detection was then
defined as a regression problem for determining the face pixel percentage for
each block. For testing different methods, 12 videos were used for training and
validation. The remaining 6 videos were used for testing. The thesis examines
the impact of using the instantaneous phase for the AOLME block-based face
detection application. For comparison, the thesis compares the use of the
Frequency Modulation image based on the instantaneous phase, the use of the
instantaneous amplitude, and the original gray scale image. To generate the FM
and AM inputs, the thesis uses dominant component analysis that aims to
decrease the training overhead while maintaining interpretability.
</p></li>
</ul>

<h3>Title: Unsupervised Discovery of Semantic Concepts in Satellite Imagery with Style-based Wavelet-driven Generative Models. (arXiv:2208.02089v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.02089">http://arxiv.org/abs/2208.02089</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.02089] Unsupervised Discovery of Semantic Concepts in Satellite Imagery with Style-based Wavelet-driven Generative Models](http://arxiv.org/abs/2208.02089)</code></li>
<li>Summary: <p>In recent years, considerable advancements have been made in the area of
Generative Adversarial Networks (GANs), particularly with the advent of
style-based architectures that address many key shortcomings - both in terms of
modeling capabilities and network interpretability. Despite these improvements,
the adoption of such approaches in the domain of satellite imagery is not
straightforward. Typical vision datasets used in generative tasks are
well-aligned and annotated, and exhibit limited variability. In contrast,
satellite imagery exhibits great spatial and spectral variability, wide
presence of fine, high-frequency details, while the tedious nature of
annotating satellite imagery leads to annotation scarcity - further motivating
developments in unsupervised learning. In this light, we present the first
pre-trained style- and wavelet-based GAN model that can readily synthesize a
wide gamut of realistic satellite images in a variety of settings and
conditions - while also preserving high-frequency information. Furthermore, we
show that by analyzing the intermediate activations of our network, one can
discover a multitude of interpretable semantic directions that facilitate the
guided synthesis of satellite images in terms of high-level concepts (e.g.,
urbanization) without using any form of supervision. Via a set of qualitative
and quantitative experiments we demonstrate the efficacy of our framework, in
terms of suitability for downstream tasks (e.g., data augmentation), quality of
synthetic imagery, as well as generalization capabilities to unseen datasets.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
