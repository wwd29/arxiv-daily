<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-10-02</h1>
<h3>Title: Language-centered Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Hua Yan, Heng Tan, Yi Ding, Peifei Zhou, Vinod Namboodiri, Yu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00003">https://arxiv.org/abs/2410.00003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00003">https://arxiv.org/pdf/2410.00003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00003]] Language-centered Human Activity Recognition(https://arxiv.org/abs/2410.00003)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human Activity Recognition (HAR) using Inertial Measurement Unit (IMU) sensors is critical for applications in healthcare, safety, and industrial production. However, variations in activity patterns, device types, and sensor placements create distribution gaps across datasets, reducing the performance of HAR models. To address this, we propose LanHAR, a novel system that leverages Large Language Models (LLMs) to generate semantic interpretations of sensor readings and activity labels for cross-dataset HAR. This approach not only mitigates cross-dataset heterogeneity but also enhances the recognition of new activities. LanHAR employs an iterative re-generation method to produce high-quality semantic interpretations with LLMs and a two-stage training framework that bridges the semantic interpretations of sensor readings and activity labels. This ultimately leads to a lightweight sensor encoder suitable for mobile deployment, enabling any sensor reading to be mapped into the semantic interpretation space. Experiments on four public datasets demonstrate that our approach significantly outperforms state-of-the-art methods in both cross-dataset HAR and new activity recognition. The source code will be made publicly available.</li>
</ul>

<h3>Title: TREB: a BERT attempt for imputing tabular data imputation</h3>
<ul>
<li><strong>Authors: </strong>Shuyue Wang, Wenjun Zhou, Han drk-m-s Jiang, Shuo Wang, Ren Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00022">https://arxiv.org/abs/2410.00022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00022">https://arxiv.org/pdf/2410.00022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00022]] TREB: a BERT attempt for imputing tabular data imputation(https://arxiv.org/abs/2410.00022)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>TREB, a novel tabular imputation framework utilizing BERT, introduces a groundbreaking approach for handling missing values in tabular data. Unlike traditional methods that often overlook the specific demands of imputation, TREB leverages the robust capabilities of BERT to address this critical task. While many BERT-based approaches for tabular data have emerged, they frequently under-utilize the language model's full potential. To rectify this, TREB employs a BERT-based model fine-tuned specifically for the task of imputing real-valued continuous numbers in tabular datasets. The paper comprehensively addresses the unique challenges posed by tabular data imputation, emphasizing the importance of context-based interconnections. The effectiveness of TREB is validated through rigorous evaluation using the California Housing dataset. The results demonstrate its ability to preserve feature interrelationships and accurately impute missing values. Moreover, the authors shed light on the computational efficiency and environmental impact of TREB, quantifying the floating-point operations (FLOPs) and carbon footprint associated with its training and deployment.</li>
</ul>

<h3>Title: Prediction and Detection of Terminal Diseases Using Internet of Medical Things: A Review</h3>
<ul>
<li><strong>Authors: </strong>Akeem Temitope Otapo, Alice Othmani, Ghazaleh Khodabandelou, Zuheng Ming</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00034">https://arxiv.org/abs/2410.00034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00034">https://arxiv.org/pdf/2410.00034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00034]] Prediction and Detection of Terminal Diseases Using Internet of Medical Things: A Review(https://arxiv.org/abs/2410.00034)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>The integration of Artificial Intelligence (AI) and the Internet of Medical Things (IoMT) in healthcare, through Machine Learning (ML) and Deep Learning (DL) techniques, has advanced the prediction and diagnosis of chronic diseases. AI-driven models such as XGBoost, Random Forest, CNNs, and LSTM RNNs have achieved over 98\% accuracy in predicting heart disease, chronic kidney disease (CKD), Alzheimer's disease, and lung cancer, using datasets from platforms like Kaggle, UCI, private institutions, and real-time IoMT sources. However, challenges persist due to variations in data quality, patient demographics, and formats from different hospitals and research sources. The incorporation of IoMT data, which is vast and heterogeneous, adds complexities in ensuring interoperability and security to protect patient privacy. AI models often struggle with overfitting, performing well in controlled environments but less effectively in real-world clinical settings. Moreover, multi-morbidity scenarios especially for rare diseases like dementia, stroke, and cancers remain insufficiently addressed. Future research should focus on data standardization and advanced preprocessing techniques to improve data quality and interoperability. Transfer learning and ensemble methods are crucial for improving model generalizability across clinical settings. Additionally, the exploration of disease interactions and the development of predictive models for chronic illness intersections is needed. Creating standardized frameworks and open-source tools for integrating federated learning, blockchain, and differential privacy into IoMT systems will also ensure robust data privacy and security.</li>
</ul>

<h3>Title: A Novel Spinor-Based Embedding Model for Transformers</h3>
<ul>
<li><strong>Authors: </strong>Rick White</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00038">https://arxiv.org/abs/2410.00038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00038">https://arxiv.org/pdf/2410.00038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00038]] A Novel Spinor-Based Embedding Model for Transformers(https://arxiv.org/abs/2410.00038)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This paper proposes a novel approach to word embeddings in Transformer models by utilizing spinors from geometric algebra. Spinors offer a rich mathematical framework capable of capturing complex relationships and transformations in high-dimensional spaces. By encoding words as spinors, we aim to enhance the expressiveness and robustness of language representations. We present the theoretical foundations of spinors, detail their integration into Transformer architectures, and discuss potential advantages and challenges.</li>
</ul>

<h3>Title: Artificial intelligence-based blockchain-driven financial default prediction</h3>
<ul>
<li><strong>Authors: </strong>Junjun Huang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00044">https://arxiv.org/abs/2410.00044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00044">https://arxiv.org/pdf/2410.00044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00044]] Artificial intelligence-based blockchain-driven financial default prediction(https://arxiv.org/abs/2410.00044)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>With the rapid development of technology, blockchain and artificial intelligence technology are playing a huge role in all walks of life. In the financial sector, blockchain solves many security problems in data storage and management in traditional systems with its advantages of decentralization and security. And artificial intelligence has huge advantages in financial forecasting and risk management through its powerful algorithmic modeling capabilities. In financial default prediction using blockchain and artificial intelligence technology is a very powerful application. Blockchain technology guarantees the credibility of data and consistency on all nodes, and machine learning builds a high-level default prediction model through detailed analysis of big data. This study offers financial institutions new thoughts on financial technology in terms of credit risk mitigation and financial system stabilization.</li>
</ul>

<h3>Title: Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph</h3>
<ul>
<li><strong>Authors: </strong>Guancheng Wan, Zewen Liu, Max S.Y. Lau, B. Aditya Prakash, Wei Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00049">https://arxiv.org/abs/2410.00049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00049">https://arxiv.org/pdf/2410.00049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00049]] Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph(https://arxiv.org/abs/2410.00049)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Effective epidemic forecasting is critical for public health strategies and efficient medical resource allocation, especially in the face of rapidly spreading infectious diseases. However, existing deep-learning methods often overlook the dynamic nature of epidemics and fail to account for the specific mechanisms of disease transmission. In response to these challenges, we introduce an innovative end-to-end framework called Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph (EARTH) in this paper. To learn continuous and regional disease transmission patterns, we first propose EANO, which seamlessly integrates the neural ODE approach with the epidemic mechanism, considering the complex spatial spread process during epidemic evolution. Additionally, we introduce GLTG to model global infection trends and leverage these signals to guide local transmission dynamically. To accommodate both the global coherence of epidemic trends and the local nuances of epidemic transmission patterns, we build a cross-attention approach to fuse the most meaningful information for forecasting. Through the smooth synergy of both components, EARTH offers a more robust and flexible approach to understanding and predicting the spread of infectious diseases. Extensive experiments show EARTH superior performance in forecasting real-world epidemics compared to state-of-the-art methods. The code will be available at this https URL.</li>
</ul>

<h3>Title: Generalizing Consistency Policy to Visual RL with Prioritized Proximal Experience Regularization</h3>
<ul>
<li><strong>Authors: </strong>Haoran Li, Zhennan Jiang, Yuhui Chen, Dongbin Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00051">https://arxiv.org/abs/2410.00051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00051">https://arxiv.org/pdf/2410.00051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00051]] Generalizing Consistency Policy to Visual RL with Prioritized Proximal Experience Regularization(https://arxiv.org/abs/2410.00051)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With high-dimensional state spaces, visual reinforcement learning (RL) faces significant challenges in exploitation and exploration, resulting in low sample efficiency and training stability. As a time-efficient diffusion model, although consistency models have been validated in online state-based RL, it is still an open question whether it can be extended to visual RL. In this paper, we investigate the impact of non-stationary distribution and the actor-critic framework on consistency policy in online RL, and find that consistency policy was unstable during the training, especially in visual RL with the high-dimensional state space. To this end, we suggest sample-based entropy regularization to stabilize the policy training, and propose a consistency policy with prioritized proximal experience regularization (CP3ER) to improve sample efficiency. CP3ER achieves new state-of-the-art (SOTA) performance in 21 tasks across DeepMind control suite and Meta-world. To our knowledge, CP3ER is the first method to apply diffusion/consistency models to visual RL and demonstrates the potential of consistency models in visual RL. More visualization results are available at this https URL.</li>
</ul>

<h3>Title: DelayPTC-LLM: Metro Passenger Travel Choice Prediction under Train Delays with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chen Chen, Yuxin He, Hao Wang, Jingjing Chen, Qin Luo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00052">https://arxiv.org/abs/2410.00052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00052">https://arxiv.org/pdf/2410.00052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00052]] DelayPTC-LLM: Metro Passenger Travel Choice Prediction under Train Delays with Large Language Models(https://arxiv.org/abs/2410.00052)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Train delays can propagate rapidly throughout the Urban Rail Transit (URT) network under networked operation conditions, posing significant challenges to operational departments. Accurately predicting passenger travel choices under train delays can provide interpretable insights into the redistribution of passenger flow, offering crucial decision support for emergency response and service recovery. However, the diversity of travel choices due to passenger heterogeneity and the sparsity of delay events leads to issues of data sparsity and sample imbalance in the travel choices dataset under metro delays. It is challenging to model this problem using traditional machine learning approaches, which typically rely on large, balanced datasets. Given the strengths of large language models (LLMs) in text processing, understanding, and their capabilities in small-sample and even zero-shot learning, this paper proposes a novel Passenger Travel Choice prediction framework under metro delays with the Large Language Model (DelayPTC-LLM). The well-designed prompting engineering is developed to guide the LLM in making and rationalizing predictions about travel choices, taking into account passenger heterogeneity and features of the delay events. Utilizing real-world data from Shenzhen Metro, including Automated Fare Collection (AFC) data and detailed delay logs, a comparative analysis of DelayPTC-LLM with traditional prediction models demonstrates the superior capability of LLMs in handling complex, sparse datasets commonly encountered under disruption of transportation systems. The results validate the advantages of DelayPTC-LLM in terms of predictive accuracy and its potential to provide actionable insights for big traffic data.</li>
</ul>

<h3>Title: Frequency-adaptive Multi-scale Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Jizu Huang, Rukang You, Tao Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00053">https://arxiv.org/abs/2410.00053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00053">https://arxiv.org/pdf/2410.00053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00053]] Frequency-adaptive Multi-scale Deep Neural Networks(https://arxiv.org/abs/2410.00053)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-scale deep neural networks (MscaleDNNs) with downing-scaling mapping have demonstrated superiority over traditional DNNs in approximating target functions characterized by high frequency features. However, the performance of MscaleDNNs heavily depends on the parameters in the downing-scaling mapping, which limits their broader application. In this work, we establish a fitting error bound to explain why MscaleDNNs are advantageous for approximating high frequency functions. Building on this insight, we construct a hybrid feature embedding to enhance the accuracy and robustness of the downing-scaling mapping. To reduce the dependency of MscaleDNNs on parameters in the downing-scaling mapping, we propose frequency-adaptive MscaleDNNs, which adaptively adjust these parameters based on a posterior error estimate that captures the frequency information of the fitted functions. Numerical examples, including wave propagation and the propagation of a localized solution of the schr$\ddot{\text{o}}$dinger equation with a smooth potential near the semi-classical limit, are presented. These examples demonstrate that the frequency-adaptive MscaleDNNs improve accuracy by two to three orders of magnitude compared to standard MscaleDNNs.</li>
</ul>

<h3>Title: Transferable Unsupervised Outlier Detection Framework for Human Semantic Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Zheng Zhang, Hossein Amiri, Dazhou Yu, Yuntong Hu, Liang Zhao, Andreas Zufle</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00054">https://arxiv.org/abs/2410.00054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00054">https://arxiv.org/pdf/2410.00054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00054]] Transferable Unsupervised Outlier Detection Framework for Human Semantic Trajectories(https://arxiv.org/abs/2410.00054)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Semantic trajectories, which enrich spatial-temporal data with textual information such as trip purposes or location activities, are key for identifying outlier behaviors critical to healthcare, social security, and urban planning. Traditional outlier detection relies on heuristic rules, which requires domain knowledge and limits its ability to identify unseen outliers. Besides, there lacks a comprehensive approach that can jointly consider multi-modal data across spatial, temporal, and textual dimensions. Addressing the need for a domain-agnostic model, we propose the Transferable Outlier Detection for Human Semantic Trajectories (TOD4Traj) framework.TOD4Traj first introduces a modality feature unification module to align diverse data feature representations, enabling the integration of multi-modal information and enhancing transferability across different datasets. A contrastive learning module is further pro-posed for identifying regular mobility patterns both temporally and across populations, allowing for a joint detection of outliers based on individual consistency and group majority patterns. Our experimental results have shown TOD4Traj's superior performance over existing models, demonstrating its effectiveness and adaptability in detecting human trajectory outliers across various datasets.</li>
</ul>

<h3>Title: Survey of Security and Data Attacks on Machine Unlearning In Financial and E-Commerce</h3>
<ul>
<li><strong>Authors: </strong>Carl E.J. Brodzinski</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00055">https://arxiv.org/abs/2410.00055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00055">https://arxiv.org/pdf/2410.00055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00055]] Survey of Security and Data Attacks on Machine Unlearning In Financial and E-Commerce(https://arxiv.org/abs/2410.00055)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense, attack, robust, membership infer</a></li>
<li><strong>Abstract: </strong>This paper surveys the landscape of security and data attacks on machine unlearning, with a focus on financial and e-commerce applications. We discuss key privacy threats such as Membership Inference Attacks and Data Reconstruction Attacks, where adversaries attempt to infer or reconstruct data that should have been removed. In addition, we explore security attacks including Machine Unlearning Data Poisoning, Unlearning Request Attacks, and Machine Unlearning Jailbreak Attacks, which target the underlying mechanisms of unlearning to manipulate or corrupt the model. To mitigate these risks, various defense strategies are examined, including differential privacy, robust cryptographic guarantees, and Zero-Knowledge Proofs (ZKPs), offering verifiable and tamper-proof unlearning mechanisms. These approaches are essential for safeguarding data integrity and privacy in high-stakes financial and e-commerce contexts, where compromised models can lead to fraud, data leaks, and reputational damage. This survey highlights the need for continued research and innovation in secure machine unlearning, as well as the importance of developing strong defenses against evolving attack vectors.</li>
</ul>

<h3>Title: STTM: A New Approach Based Spatial-Temporal Transformer And Memory Network For Real-time Pressure Signal In On-demand Food Delivery</h3>
<ul>
<li><strong>Authors: </strong>Jiang Wang, Haibin Wei, Xiaowei Xu, Jiacheng Shi, Jian Nie, Longzhi Du, Taixu Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00057">https://arxiv.org/abs/2410.00057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00057">https://arxiv.org/pdf/2410.00057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00057]] STTM: A New Approach Based Spatial-Temporal Transformer And Memory Network For Real-time Pressure Signal In On-demand Food Delivery(https://arxiv.org/abs/2410.00057)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>On-demand Food Delivery (OFD) services have become very common around the world. For example, on the this http URL platform, users place more than 15 million food orders every day. Predicting the Real-time Pressure Signal (RPS) is crucial for OFD services, as it is primarily used to measure the current status of pressure on the logistics system. When RPS rises, the pressure increases, and the platform needs to quickly take measures to prevent the logistics system from being overloaded. Usually, the average delivery time for all orders within a business district is used to represent RPS. Existing research on OFD services primarily focuses on predicting the delivery time of orders, while relatively less attention has been given to the study of the RPS. Previous research directly applies general models such as DeepFM, RNN, and GNN for prediction, but fails to adequately utilize the unique temporal and spatial characteristics of OFD services, and faces issues with insufficient sensitivity during sudden severe weather conditions or peak periods. To address these problems, this paper proposes a new method based on Spatio-Temporal Transformer and Memory Network (STTM). Specifically, we use a novel Spatio-Temporal Transformer structure to learn logistics features across temporal and spatial dimensions and encode the historical information of a business district and its neighbors, thereby learning both temporal and spatial information. Additionally, a Memory Network is employed to increase sensitivity to abnormal events. Experimental results on the real-world dataset show that STTM significantly outperforms previous methods in both offline experiments and the online A/B test, demonstrating the effectiveness of this method.</li>
</ul>

<h3>Title: IDEA: An Inverse Domain Expert Adaptation Based Active DNN IP Protection Method</h3>
<ul>
<li><strong>Authors: </strong>Chaohui Xu, Qi Cui, Jinxin Dong, Weiyang He, Chip-Hong Chang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00059">https://arxiv.org/abs/2410.00059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00059">https://arxiv.org/pdf/2410.00059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00059]] IDEA: An Inverse Domain Expert Adaptation Based Active DNN IP Protection Method(https://arxiv.org/abs/2410.00059)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Illegitimate reproduction, distribution and derivation of Deep Neural Network (DNN) models can inflict economic loss, reputation damage and even privacy infringement. Passive DNN intellectual property (IP) protection methods such as watermarking and fingerprinting attempt to prove the ownership upon IP violation, but they are often too late to stop catastrophic damage of IP abuse and too feeble against strong adversaries. In this paper, we propose IDEA, an Inverse Domain Expert Adaptation based proactive DNN IP protection method featuring active authorization and source traceability. IDEA generalizes active authorization as an inverse problem of domain adaptation. The multi-adaptive optimization is solved by a mixture-of-experts model with one real and two fake experts. The real expert re-optimizes the source model to correctly classify test images with a unique model user key steganographically embedded. The fake experts are trained to output random prediction on test images without or with incorrect user key embedded by minimizing their mutual information (MI) with the real expert. The MoE model is knowledge distilled into a unified protected model to avoid leaking the expert model features by maximizing their MI with additional multi-layer attention and contrastive representation loss optimization. IDEA not only prevents unauthorized users without the valid key to access the functional model, but also enable the model owner to validate the deployed model and trace the source of IP infringement. We extensively evaluate IDEA on five datasets and four DNN models to demonstrate its effectiveness in authorization control, culprit tracing success rate, and robustness against various attacks.</li>
</ul>

<h3>Title: Neural Decompiling of Tracr Transformers</h3>
<ul>
<li><strong>Authors: </strong>Hannes Thurnherr, Kaspar Riesen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00061">https://arxiv.org/abs/2410.00061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00061">https://arxiv.org/pdf/2410.00061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00061]] Neural Decompiling of Tracr Transformers(https://arxiv.org/abs/2410.00061)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recently, the transformer architecture has enabled substantial progress in many areas of pattern recognition and machine learning. However, as with other neural network models, there is currently no general method available to explain their inner workings. The present paper represents a first step towards this direction. We utilize \textit{Transformer Compiler for RASP} (Tracr) to generate a large dataset of pairs of transformer weights and corresponding RASP programs. Based on this dataset, we then build and train a model, with the aim of recovering the RASP code from the compiled model. We demonstrate that the simple form of Tracr compiled transformer weights is interpretable for such a decompiler model. In an empirical evaluation, our model achieves exact reproductions on more than 30\% of the test objects, while the remaining 70\% can generally be reproduced with only few errors. Additionally, more than 70\% of the programs, produced by our model, are functionally equivalent to the ground truth, and therefore a valid decompilation of the Tracr compiled transformer weights.</li>
</ul>

<h3>Title: An interdisciplinary exploration of trade-offs between energy, privacy and accuracy aspects of data</h3>
<ul>
<li><strong>Authors: </strong>Pepijn de Reus, Kyra Dresen, Ana Oprescu, Kristina Irion, Ans Kolk</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00069">https://arxiv.org/abs/2410.00069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00069">https://arxiv.org/pdf/2410.00069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00069]] An interdisciplinary exploration of trade-offs between energy, privacy and accuracy aspects of data(https://arxiv.org/abs/2410.00069)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>The digital era has raised many societal challenges, including ICT's rising energy consumption and protecting privacy of personal data processing. This paper considers both aspects in relation to machine learning accuracy in an interdisciplinary exploration. We first present a method to measure the effects of privacy-enhancing techniques on data utility and energy consumption. The environmental-privacy-accuracy trade-offs are discovered through an experimental set-up. We subsequently take a storytelling approach to translate these technical findings to experts in non-ICT fields. We draft two examples for a governmental and auditing setting to contextualise our results. Ultimately, users face the task of optimising their data processing operations in a trade-off between energy, privacy, and accuracy considerations where the impact of their decisions is context-sensitive.</li>
</ul>

<h3>Title: Collaborative Knowledge Distillation via a Learning-by-Education Node Community</h3>
<ul>
<li><strong>Authors: </strong>Anestis Kaimakamidis, Ioannis Mademlis, Ioannis Pitas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00074">https://arxiv.org/abs/2410.00074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00074">https://arxiv.org/pdf/2410.00074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00074]] Collaborative Knowledge Distillation via a Learning-by-Education Node Community(https://arxiv.org/abs/2410.00074)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>A novel Learning-by-Education Node Community framework (LENC) for Collaborative Knowledge Distillation (CKD) is presented, which facilitates continual collective learning through effective knowledge exchanges among diverse deployed Deep Neural Network (DNN) peer nodes. These DNNs dynamically and autonomously adopt either the role of a student, seeking knowledge, or that of a teacher, imparting knowledge, fostering a collaborative learning environment. The proposed framework enables efficient knowledge transfer among participating DNN nodes as needed, while enhancing their learning capabilities and promoting their collaboration. LENC addresses the challenges of handling diverse training data distributions and the limitations of individual DNN node learning abilities. It ensures the exploitation of the best available teacher knowledge upon learning a new task and protects the DNN nodes from catastrophic forgetting. Additionally, it innovates by enabling collaborative multitask knowledge distillation, while addressing the problem of task-agnostic continual learning, as DNN nodes have no information on task boundaries. Experimental evaluation on a proof-of-concept implementation demonstrates the LENC framework's functionalities and benefits across multiple DNN learning and inference scenarios. The conducted experiments showcase its ability to gradually maximize the average test accuracy of the community of interacting DNN nodes in image classification problems, by appropriately leveraging the collective knowledge of all node peers. The LENC framework achieves state-of-the-art performance in on-line unlabelled CKD.</li>
</ul>

<h3>Title: A Survey on Diffusion Models for Inverse Problems</h3>
<ul>
<li><strong>Authors: </strong>Giannis Daras, Hyungjin Chung, Chieh-Hsin Lai, Yuki Mitsufuji, Jong Chul Ye, Peyman Milanfar, Alexandros G. Dimakis, Mauricio Delbracio</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00083">https://arxiv.org/abs/2410.00083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00083">https://arxiv.org/pdf/2410.00083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00083]] A Survey on Diffusion Models for Inverse Problems(https://arxiv.org/abs/2410.00083)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have become increasingly popular for generative modeling due to their ability to generate high-quality samples. This has unlocked exciting new possibilities for solving inverse problems, especially in image restoration and reconstruction, by treating diffusion models as unsupervised priors. This survey provides a comprehensive overview of methods that utilize pre-trained diffusion models to solve inverse problems without requiring further training. We introduce taxonomies to categorize these methods based on both the problems they address and the techniques they employ. We analyze the connections between different approaches, offering insights into their practical implementation and highlighting important considerations. We further discuss specific challenges and potential solutions associated with using latent diffusion models for inverse problems. This work aims to be a valuable resource for those interested in learning about the intersection of diffusion models and inverse problems.</li>
</ul>

<h3>Title: ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zhen Han, Zeyinzi Jiang, Yulin Pan, Jingfeng Zhang, Chaojie Mao, Chenwei Xie, Yu Liu, Jingren Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00086">https://arxiv.org/abs/2410.00086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00086">https://arxiv.org/pdf/2410.00086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00086]] ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer(https://arxiv.org/abs/2410.00086)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as a powerful generative technology and have been found to be applicable in various scenarios. Most existing foundational diffusion models are primarily designed for text-guided visual generation and do not support multi-modal conditions, which are essential for many visual editing tasks. This limitation prevents these foundational diffusion models from serving as a unified model in the field of visual generation, like GPT-4 in the natural language processing field. In this work, we propose ACE, an All-round Creator and Editor, which achieves comparable performance compared to those expert models in a wide range of visual generation tasks. To achieve this goal, we first introduce a unified condition format termed Long-context Condition Unit (LCU), and propose a novel Transformer-based diffusion model that uses LCU as input, aiming for joint training across various generation and editing tasks. Furthermore, we propose an efficient data collection approach to address the issue of the absence of available training data. It involves acquiring pairwise images with synthesis-based or clustering-based pipelines and supplying these pairs with accurate textual instructions by leveraging a fine-tuned multi-modal large language model. To comprehensively evaluate the performance of our model, we establish a benchmark of manually annotated pairs data across a variety of visual generation tasks. The extensive experimental results demonstrate the superiority of our model in visual generation fields. Thanks to the all-in-one capabilities of our model, we can easily build a multi-modal chat system that responds to any interactive request for image creation using a single model to serve as the backend, avoiding the cumbersome pipeline typically employed in visual agents. Code and models will be available on the project page: this https URL.</li>
</ul>

<h3>Title: Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ji Liu, Jiaxiang Ren, Ruoming Jin, Zijie Zhang, Yang Zhou, Patrick Valduriez, Dejing Dou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00131">https://arxiv.org/abs/2410.00131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00131">https://arxiv.org/pdf/2410.00131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00131]] Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models(https://arxiv.org/abs/2410.00131)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, large language model</a></li>
<li><strong>Abstract: </strong>As a promising paradigm to collaboratively train models with decentralized data, Federated Learning (FL) can be exploited to fine-tune Large Language Models (LLMs). While LLMs correspond to huge size, the scale of the training data significantly increases, which leads to tremendous amounts of computation and communication costs. The training data is generally non-Independent and Identically Distributed (non-IID), which requires adaptive data processing within each device. Although Low Rank Adaptation (LoRA) can significantly reduce the scale of parameters to update in the fine-tuning process, it still takes unaffordable time to transfer the low-rank parameters of all the layers in LLMs. In this paper, we propose a Fisher Information-based Efficient Curriculum Federated Learning framework (FibecFed) with two novel methods, i.e., adaptive federated curriculum learning and efficient sparse parameter update. First, we propose a fisher information-based method to adaptively sample data within each device to improve the effectiveness of the FL fine-tuning process. Second, we dynamically select the proper layers for global aggregation and sparse parameters for local update with LoRA so as to improve the efficiency of the FL fine-tuning process. Extensive experimental results based on 10 datasets demonstrate that FibecFed yields excellent performance (up to 45.35% in terms of accuracy) and superb fine-tuning speed (up to 98.61% faster) compared with 17 baseline approaches).</li>
</ul>

<h3>Title: CVVLSNet: Vehicle Location and Speed Estimation Using Partial Connected Vehicle Trajectory Data</h3>
<ul>
<li><strong>Authors: </strong>Jiachen Ye, Dingyu Wang, Shaocheng Jia, Xin Pei, Zi Yang, Yi Zhang, S.C. Wong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00132">https://arxiv.org/abs/2410.00132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00132">https://arxiv.org/pdf/2410.00132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00132]] CVVLSNet: Vehicle Location and Speed Estimation Using Partial Connected Vehicle Trajectory Data(https://arxiv.org/abs/2410.00132)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Real-time estimation of vehicle locations and speeds is crucial for developing many beneficial transportation applications in traffic management and control, e.g., adaptive signal control. Recent advances in communication technologies facilitate the emergence of connected vehicles (CVs), which can share traffic information with nearby CVs or infrastructures. At the early stage of connectivity, only a portion of vehicles are CVs. The locations and speeds for those non-CVs (NCs) are not accessible and must be estimated to obtain the full traffic information. To address the above problem, this paper proposes a novel CV-based Vehicle Location and Speed estimation network, CVVLSNet, to simultaneously estimate the vehicle locations and speeds exclusively using partial CV trajectory data. A road cell occupancy (RCO) method is first proposed to represent the variable vehicle state information. Spatiotemporal interactions can be integrated by simply fusing the RCO representations. Then, CVVLSNet, taking the Coding-RAte TransformEr (CRATE) network as a backbone, is introduced to estimate the vehicle locations and speeds. Moreover, physical vehicle size constraints are also considered in loss functions. Extensive experiments indicate that the proposed method significantly outperformed the existing method under various CV penetration rates, signal timings, and volume-to-capacity ratios.</li>
</ul>

<h3>Title: Semantic-Driven Topic Modeling Using Transformer-Based Embeddings and Clustering Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Melkamu Abay Mersha, Mesay Gemeda yigezu, Jugal Kalita</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00134">https://arxiv.org/abs/2410.00134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00134">https://arxiv.org/pdf/2410.00134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00134]] Semantic-Driven Topic Modeling Using Transformer-Based Embeddings and Clustering Algorithms(https://arxiv.org/abs/2410.00134)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Topic modeling is a powerful technique to discover hidden topics and patterns within a collection of documents without prior knowledge. Traditional topic modeling and clustering-based techniques encounter challenges in capturing contextual semantic information. This study introduces an innovative end-to-end semantic-driven topic modeling technique for the topic extraction process, utilizing advanced word and document embeddings combined with a powerful clustering algorithm. This semantic-driven approach represents a significant advancement in topic modeling methodologies. It leverages contextual semantic information to extract coherent and meaningful topics. Specifically, our model generates document embeddings using pre-trained transformer-based language models, reduces the dimensions of the embeddings, clusters the embeddings based on semantic similarity, and generates coherent topics for each cluster. Compared to ChatGPT and traditional topic modeling algorithms, our model provides more coherent and meaningful topics.</li>
</ul>

<h3>Title: Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!</h3>
<ul>
<li><strong>Authors: </strong>Divya Patel, Pathik Patel, Ankush Chander, Sourish Dasgupta, Tanmoy Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00149">https://arxiv.org/abs/2410.00149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00149">https://arxiv.org/pdf/2410.00149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00149]] Are Large Language Models In-Context Personalized Summarizers? Get an iCOPERNICUS Test Done!(https://arxiv.org/abs/2410.00149)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have succeeded considerably in In-Context-Learning (ICL) based summarization. However, saliency is subject to the users' specific preference histories. Hence, we need reliable In-Context Personalization Learning (ICPL) capabilities within such LLMs. For any arbitrary LLM to exhibit ICPL, it needs to have the ability to discern contrast in user profiles. A recent study proposed a measure for degree-of-personalization called EGISES for the first time. EGISES measures a model's responsiveness to user profile differences. However, it cannot test if a model utilizes all three types of cues provided in ICPL prompts: (i) example summaries, (ii) user's reading histories, and (iii) contrast in user profiles. To address this, we propose the iCOPERNICUS framework, a novel In-COntext PERsonalization learNIng sCrUtiny of Summarization capability in LLMs that uses EGISES as a comparative measure. As a case-study, we evaluate 17 state-of-the-art LLMs based on their reported ICL performances and observe that 15 models' ICPL degrades (min: 1.6%; max: 3.6%) when probed with richer prompts, thereby showing lack of true ICPL.</li>
</ul>

<h3>Title: Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems</h3>
<ul>
<li><strong>Authors: </strong>Stephen Miner, Yoshiki Takashima, Simeng Han, Ferhat Erata, Timos Antonopoulos, Ruzica Piskac, Scott J Shapiro</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00151">https://arxiv.org/abs/2410.00151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00151">https://arxiv.org/pdf/2410.00151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00151]] Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems(https://arxiv.org/abs/2410.00151)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Benchmarks are critical for measuring progress of math reasoning abilities of Large Language Models (LLMs). However, existing widely-used benchmarks such as GSM8K have been rendered less useful as multiple cutting-edge LLMs achieve over 94% accuracy. While harder benchmarks have been proposed, their creation is often manual and expensive. We present Scheherazade, an automated approach for producing challenging mathematical reasoning benchmarks by logically chaining mathematical reasoning problems. We propose two different chaining methods, forward chaining and backward chaining, which require reasoning forward and backward through the chain respectively. We apply Scheherazade on GSM8K to create GSM8K-Scheherazade and evaluate 3 frontier LLMs and OpenAI's o1-preview on it. We show that while frontier models' performance declines precipitously at only a few questions chained, a preliminary evaluation suggests o1-preview performance persists up to 5 questions chained backwards. In addition, while all other models perform worse when problems are chained backwards, o1-preview performs better on backward-chained benchmarks. We will release the dataset and code publicly.</li>
</ul>

<h3>Title: Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution</h3>
<ul>
<li><strong>Authors: </strong>Haiyan Zhao, Heng Zhao, Bo Shen, Ali Payani, Fan Yang, Mengnan Du</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00153">https://arxiv.org/abs/2410.00153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00153">https://arxiv.org/pdf/2410.00153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00153]] Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution(https://arxiv.org/abs/2410.00153)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Probing learned concepts in large language models (LLMs) is crucial for understanding how semantic knowledge is encoded internally. Training linear classifiers on probing tasks is a principle approach to denote the vector of a certain concept in the representation space. However, the single vector identified for a concept varies with both data and training, making it less robust and weakening its effectiveness in real-world applications. To address this challenge, we propose an approach to approximate the subspace representing a specific concept. Built on linear probing classifiers, we extend the concept vectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's effectiveness through measuring its faithfulness and plausibility across multiple LLMs with different sizes and architectures. Additionally, we use representation intervention tasks to showcase its efficacy in real-world applications such as emotion steering. Experimental results indicate that GCS concept vectors have the potential to balance steering performance and maintaining the fluency in natural language generation tasks.</li>
</ul>

<h3>Title: KV-Compress: Paged KV-Cache Compression with Variable Compression Rates per Attention Head</h3>
<ul>
<li><strong>Authors: </strong>Isaac Rehg</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00161">https://arxiv.org/abs/2410.00161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00161">https://arxiv.org/pdf/2410.00161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00161]] KV-Compress: Paged KV-Cache Compression with Variable Compression Rates per Attention Head(https://arxiv.org/abs/2410.00161)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Context lengths of Large Language Models (LLMs) have exploded in recent years, with 128k-token context becoming a standard and million-token context becoming a reality. Efficiently supporting long-context inference remains challenging as the memory that must be allocated in key-value (KV) cache for a generation scales with its context length, limiting the number of long-context requests that can be served concurrently under a given memory budget. KV cache compression can mitigate this issue by removing under-utilized KVs from each attention head's cache and reducing its memory footprint. Higher theoretical compression rates can be achieved when the number of removed KVs varies across attention heads, but application of such a strategy within existing inference frameworks adds fragmentation and cannot realize the theoretical compression rates in physical memory. We introduce KV-Compress, a novel compression method that evicts contiguous KV blocks within a PagedAttention framework, reducing the memory footprint of the KV cache proportionally to this theoretical compression rate. Our method achieves state-of-the-art performance on LongBench for both Mistral-7B-Instruct-v0.2 and Llama-3.1-8B-Instruct while lowering the total number of compressed KVs by 4x compared with prior methods. Evaluations on Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct-FP8 achieve compression rates up to 8x with negligible impact on performance, and up to 64x while retaining over 90% of full-cache performance for all but three of the suite's subsets. We benchmark an integration of our method with vLLM that increases total throughput by up to 5.18x by enabling larger decoding batches.</li>
</ul>

<h3>Title: Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Pedro Henrique Paiola, Gabriel Lino Garcia, João Renato Ribeiro Manesco, Mateus Roder, Douglas Rodrigues, João Paulo Papa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00163">https://arxiv.org/abs/2410.00163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00163">https://arxiv.org/pdf/2410.00163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00163]] Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation(https://arxiv.org/abs/2410.00163)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This study evaluates the performance of large language models (LLMs) as medical agents in Portuguese, aiming to develop a reliable and relevant virtual assistant for healthcare professionals. The HealthCareMagic-100k-en and MedQuAD datasets, translated from English using GPT-3.5, were used to fine-tune the ChatBode-7B model using the PEFT-QLoRA method. The InternLM2 model, with initial training on medical data, presented the best overall performance, with high precision and adequacy in metrics such as accuracy, completeness and safety. However, DrBode models, derived from ChatBode, exhibited a phenomenon of catastrophic forgetting of acquired medical knowledge. Despite this, these models performed frequently or even better in aspects such as grammaticality and coherence. A significant challenge was low inter-rater agreement, highlighting the need for more robust assessment protocols. This work paves the way for future research, such as evaluating multilingual models specific to the medical field, improving the quality of training data, and developing more consistent evaluation methodologies for the medical field.</li>
</ul>

<h3>Title: EEG Emotion Copilot: Pruning LLMs for Emotional EEG Interpretation with Assisted Medical Record Generation</h3>
<ul>
<li><strong>Authors: </strong>Hongyu Chen, Weiming Zeng, Chengcheng Chen, Luhui Cai, Fei Wang, Lei Wang, Wei Zhang, Yueyang Li, Hongjie Yan, Wai Ting Siok, Nizhuan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00166">https://arxiv.org/abs/2410.00166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00166">https://arxiv.org/pdf/2410.00166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00166]] EEG Emotion Copilot: Pruning LLMs for Emotional EEG Interpretation with Assisted Medical Record Generation(https://arxiv.org/abs/2410.00166)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, extraction, large language model</a></li>
<li><strong>Abstract: </strong>In the fields of affective computing (AC) and brain-machine interface (BMI), the analysis of physiological and behavioral signals to discern individual emotional states has emerged as a critical research frontier. While deep learning-based approaches have made notable strides in EEG emotion recognition, particularly in feature extraction and pattern recognition, significant challenges persist in achieving end-to-end emotion computation, including real-time processing, individual adaptation, and seamless user interaction. This paper presents the EEG Emotion Copilot, a system leveraging a lightweight large language model (LLM) operating in a local setting. The system is designed to first recognize emotional states directly from EEG signals, subsequently generate personalized diagnostic and treatment suggestions, and finally support the automation of electronic medical records. The proposed solution emphasizes both the accuracy of emotion recognition and an enhanced user experience, facilitated by an intuitive interface for participant interaction. We further discuss the construction of the data framework, model pruning, training, and deployment strategies aimed at improving real-time performance and computational efficiency. Privacy concerns are also addressed, with a focus on ethical data collection, processing, and the protection of users' personal information. Through these efforts, we aim to advance the application of AC in the medical domain, offering innovative approaches to mental health diagnostics and treatment.</li>
</ul>

<h3>Title: GaNDLF-Synth: A Framework to Democratize Generative AI for (Bio)Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Sarthak Pati, Szymon Mazurek, Spyridon Bakas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00173">https://arxiv.org/abs/2410.00173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00173">https://arxiv.org/pdf/2410.00173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00173]] GaNDLF-Synth: A Framework to Democratize Generative AI for (Bio)Medical Imaging(https://arxiv.org/abs/2410.00173)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative Artificial Intelligence (GenAI) is a field of AI that creates new data samples from existing ones. It utilizing deep learning to overcome the scarcity and regulatory constraints of healthcare data by generating new data points that integrate seamlessly with original datasets. This paper explores the background and motivation for GenAI, and introduces the Generally Nuanced Deep Learning Framework for Synthesis (GaNDLF-Synth) to address a significant gap in the literature and move towards democratizing the implementation and assessment of image synthesis tasks in healthcare. GaNDLF-Synth describes a unified abstraction for various synthesis algorithms, including autoencoders, generative adversarial networks, and diffusion models. Leveraging the GANDLF-core framework, it supports diverse data modalities and distributed computing, ensuring scalability and reproducibility through extensive unit testing. The aim of GaNDLF-Synth is to lower the entry barrier for GenAI, and make it more accessible and extensible by the wider scientific community.</li>
</ul>

<h3>Title: Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse</h3>
<ul>
<li><strong>Authors: </strong>Rongchen Guo, Isar Nejadgholi, Hillary Dawkins, Kathleen C. Fraser, Svetlana Kiritchenko</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00175">https://arxiv.org/abs/2410.00175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00175">https://arxiv.org/pdf/2410.00175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00175]] Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse(https://arxiv.org/abs/2410.00175)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work provides an explanatory view of how LLMs can apply moral reasoning to both criticize and defend sexist language. We assessed eight large language models, all of which demonstrated the capability to provide explanations grounded in varying moral perspectives for both critiquing and endorsing views that reflect sexist assumptions. With both human and automatic evaluation, we show that all eight models produce comprehensible and contextually relevant text, which is helpful in understanding diverse views on how sexism is perceived. Also, through analysis of moral foundations cited by LLMs in their arguments, we uncover the diverse ideological perspectives in models' outputs, with some models aligning more with progressive or conservative views on gender roles and sexism. Based on our observations, we caution against the potential misuse of LLMs to justify sexist language. We also highlight that LLMs can serve as tools for understanding the roots of sexist beliefs and designing well-informed interventions. Given this dual capacity, it is crucial to monitor LLMs and design safety mechanisms for their use in applications that involve sensitive societal topics, such as sexism.</li>
</ul>

<h3>Title: Evaluating the fairness of task-adaptive pretraining on unlabeled test data before few-shot text classification</h3>
<ul>
<li><strong>Authors: </strong>Kush Dubey</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00179">https://arxiv.org/abs/2410.00179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00179">https://arxiv.org/pdf/2410.00179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00179]] Evaluating the fairness of task-adaptive pretraining on unlabeled test data before few-shot text classification(https://arxiv.org/abs/2410.00179)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Few-shot learning benchmarks are critical for evaluating modern NLP techniques. It is possible, however, that benchmarks favor methods which easily make use of unlabeled text, because researchers can use unlabeled text from the test set to pretrain their models. Given the dearth of research on this potential problem, we run experiments to quantify the bias caused by pretraining on unlabeled test set text instead of on unlabeled, independently drawn text. Controlled few-shot and zero-shot experiments on 25 classification tasks and 3 language models -- BERT, GPT-2, and Mistral 7B -- do not find evidence of overoptimism. Furthermore, we demonstrate the importance of repeated subsampling when studying few-shot text classification, and recommend that few-shot learning benchmarks include multiple training folds. Code and data are available at this https URL.</li>
</ul>

<h3>Title: Zero-Shot Classification of Crisis Tweets Using Instruction-Finetuned Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Emma McDaniel, Samuel Scheele, Jeff Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00182">https://arxiv.org/abs/2410.00182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00182">https://arxiv.org/pdf/2410.00182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00182]] Zero-Shot Classification of Crisis Tweets Using Instruction-Finetuned Large Language Models(https://arxiv.org/abs/2410.00182)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Social media posts are frequently identified as a valuable source of open-source intelligence for disaster response, and pre-LLM NLP techniques have been evaluated on datasets of crisis tweets. We assess three commercial large language models (OpenAI GPT-4o, Gemini 1.5-flash-001 and Anthropic Claude-3-5 Sonnet) capabilities in zero-shot classification of short social media posts. In one prompt, the models are asked to perform two classification tasks: 1) identify if the post is informative in a humanitarian context; and 2) rank and provide probabilities for the post in relation to 16 possible humanitarian classes. The posts being classified are from the consolidated crisis tweet dataset, CrisisBench. Results are evaluated using macro, weighted, and binary F1-scores. The informative classification task, generally performed better without extra information, while for the humanitarian label classification providing the event that occurred during which the tweet was mined, resulted in better performance. Further, we found that the models have significantly varying performance by dataset, which raises questions about dataset quality.</li>
</ul>

<h3>Title: Evaluating the performance of state-of-the-art esg domain-specific pre-trained large language models in text classification against existing models and traditional machine learning techniques</h3>
<ul>
<li><strong>Authors: </strong>Tin Yuet Chung, Majid Latifi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00207">https://arxiv.org/abs/2410.00207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00207">https://arxiv.org/pdf/2410.00207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00207]] Evaluating the performance of state-of-the-art esg domain-specific pre-trained large language models in text classification against existing models and traditional machine learning techniques(https://arxiv.org/abs/2410.00207)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This research investigates the classification of Environmental, Social, and Governance (ESG) information within textual disclosures. The aim is to develop and evaluate binary classification models capable of accurately identifying and categorizing E, S and G-related content respectively. The motivation for this research stems from the growing importance of ESG considerations in investment decisions and corporate accountability. Accurate and efficient classification of ESG information is crucial for stakeholders to understand the impact of companies on sustainability and to make informed decisions. The research uses a quantitative approach involving data collection, data preprocessing, and the development of ESG-focused Large Language Models (LLMs) and traditional machine learning (Support Vector Machines, XGBoost) classifiers. Performance evaluation guides iterative refinement until satisfactory metrics are achieved. The research compares traditional machine learning techniques (Support Vector Machines, XGBoost), state-of-the-art language model (FinBERT-ESG) and fine-tuned LLMs like Llama 2, by employing standard Natural Language Processing performance metrics such as accuracy, precision, recall, F1-score. A novel fine-tuning method, Qlora, is applied to LLMs, resulting in significant performance improvements across all ESG domains. The research also develops domain-specific fine-tuned models, such as EnvLlama 2-Qlora, SocLlama 2-Qlora, and GovLlama 2-Qlora, which demonstrate impressive results in ESG text classification.</li>
</ul>

<h3>Title: Characterizing and Efficiently Accelerating Multimodal Generation Model Inference</h3>
<ul>
<li><strong>Authors: </strong>Yejin Lee, Anna Sun, Basil Hosmer, Bilge Acun, Can Balioglu, Changhan Wang, Charles David Hernandez, Christian Puhrsch, Daniel Haziza, Driss Guessous, Francisco Massa, Jacob Kahn, Jeffrey Wan, Jeremy Reizenstein, Jiaqi Zhai, Joe Isaacson, Joel Schlosser, Juan Pino, Kaushik Ram Sadagopan, Leonid Shamis, Linjian Ma, Min-Jae Hwang, Mingda Chen, Mostafa Elhoushi, Pedro Rodriguez, Ram Pasunuru, Scott Yih, Sravya Popuri, Xing Liu, Carole-Jean Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00215">https://arxiv.org/abs/2410.00215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00215">https://arxiv.org/pdf/2410.00215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00215]] Characterizing and Efficiently Accelerating Multimodal Generation Model Inference(https://arxiv.org/abs/2410.00215)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Generative artificial intelligence (AI) technology is revolutionizing the computing industry. Not only its applications have broadened to various sectors but also poses new system design and optimization opportunities. The technology is capable of understanding and responding in multiple modalities. However, the advanced capability currently comes with significant system resource demands. To sustainably scale generative AI capabilities to billions of users in the world, inference must be fast and efficient. This paper pinpoints key system design and optimization opportunities by characterizing a family of emerging multi-modal generation models on real systems. Auto-regressive token generation is a critical latency performance bottleneck, typically dominated by GPU idle time. In addition to memory-intensive attention across the generative AI models, linear operations constitute significant inference latency due to the feed forward networks in Transformer-based models. We demonstrate that state-of-the-art optimization levers, spanning from applications to system software and hardware, set a 3.88x better baseline.</li>
</ul>

<h3>Title: Probabilistic Classification of Near-Surface Shallow-Water Sediments using A Portable Free-Fall Penetrometer</h3>
<ul>
<li><strong>Authors: </strong>Md Rejwanur Rahman, Adrian Rodriguez-Marek, Nina Stark, Grace Massey, Carl Friedrichs, Kelly M. Dorgan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00225">https://arxiv.org/abs/2410.00225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00225">https://arxiv.org/pdf/2410.00225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00225]] Probabilistic Classification of Near-Surface Shallow-Water Sediments using A Portable Free-Fall Penetrometer(https://arxiv.org/abs/2410.00225)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The geotechnical evaluation of seabed sediments is important for engineering projects and naval applications, offering valuable insights into sediment properties, behavior, and strength. Obtaining high-quality seabed samples can be a challenging task, making in-situ testing an essential part of site characterization. Free Fall Penetrometers (FFP) have emerged as robust tools for rapidly profiling seabed surface sediments, even in energetic nearshore or estuarine conditions and shallow as well as deep depths. While methods for interpretation of traditional offshore Cone Penetration Testing (CPT) data are well-established, their adaptation to FFP data is still an area of research. In this study, we introduce an innovative approach that utilizes machine learning algorithms to create a sediment behavior classification system based on portable free fall penetrometer (PFFP) data. The proposed model leverages PFFP measurements obtained from locations such as Sequim Bay (Washington), the Potomac River, and the York River (Virginia). The result shows 91.1\% accuracy in the class prediction, with the classes representing cohesionless sediment with little to no plasticity, cohesionless sediment with some plasticity, cohesive sediment with low plasticity, and cohesive sediment with high plasticity. The model prediction not only provides the predicted class but also yields an estimate of inherent uncertainty associated with the prediction, which can provide valuable insight about different sediment behaviors. These uncertainties typically range from very low to very high, with lower uncertainties being more common, but they can increase significantly dpending on variations in sediment composition, environmental conditions, and operational techniques. By quantifying uncertainty, the model offers a more comprehensive and informed approach to sediment classification.</li>
</ul>

<h3>Title: Quantized and Asynchronous Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Tomas Ortega, Hamid Jafarkhani</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00242">https://arxiv.org/abs/2410.00242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00242">https://arxiv.org/pdf/2410.00242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00242]] Quantized and Asynchronous Federated Learning(https://arxiv.org/abs/2410.00242)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, federate</a></li>
<li><strong>Abstract: </strong>Recent advances in federated learning have shown that asynchronous variants can be faster and more scalable than their synchronous counterparts. However, their design does not include quantization, which is necessary in practice to deal with the communication bottleneck. To bridge this gap, we develop a novel algorithm, Quantized Asynchronous Federated Learning (QAFeL), which introduces a hidden-state quantization scheme to avoid the error propagation caused by direct quantization. QAFeL also includes a buffer to aggregate client updates, ensuring scalability and compatibility with techniques such as secure aggregation. Furthermore, we prove that QAFeL achieves an $\mathcal{O}(1/\sqrt{T})$ ergodic convergence rate for stochastic gradient descent on non-convex objectives, which is the optimal order of complexity, without requiring bounded gradients or uniform client arrivals. We also prove that the cross-term error between staleness and quantization only affects the higher-order error terms. We validate our theoretical findings on standard benchmarks.</li>
</ul>

<h3>Title: Enhancing Pre-Trained Language Models for Vulnerability Detection via Semantic-Preserving Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Weiliang Qi (1), Jiahao Cao (2), Darsh Poddar (3), Sophia Li (4), Xinda Wang (5) ((1) University of Texas at Dallas, (2) Tsinghua University, (3) Lebanon Trail High School, (4) Lovejoy High School)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00249">https://arxiv.org/abs/2410.00249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00249">https://arxiv.org/pdf/2410.00249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00249]] Enhancing Pre-Trained Language Models for Vulnerability Detection via Semantic-Preserving Data Augmentation(https://arxiv.org/abs/2410.00249)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>With the rapid development and widespread use of advanced network systems, software vulnerabilities pose a significant threat to secure communications and networking. Learning-based vulnerability detection systems, particularly those leveraging pre-trained language models, have demonstrated significant potential in promptly identifying vulnerabilities in communication networks and reducing the risk of exploitation. However, the shortage of accurately labeled vulnerability datasets hinders further progress in this field. Failing to represent real-world vulnerability data variety and preserve vulnerability semantics, existing augmentation approaches provide limited or even counterproductive contributions to model training. In this paper, we propose a data augmentation technique aimed at enhancing the performance of pre-trained language models for vulnerability detection. Given the vulnerability dataset, our method performs natural semantic-preserving program transformation to generate a large volume of new samples with enriched data diversity and variety. By incorporating our augmented dataset in fine-tuning a series of representative code pre-trained models (i.e., CodeBERT, GraphCodeBERT, UnixCoder, and PDBERT), up to 10.1% increase in accuracy and 23.6% increase in F1 can be achieved in the vulnerability detection task. Comparison results also show that our proposed method can substantially outperform other prominent vulnerability augmentation approaches.</li>
</ul>

<h3>Title: A Methodology for Explainable Large Language Models with Integrated Gradients and Linguistic Analysis in Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Marina Ribeiro (1 and 2), Bárbara Malcorra (2), Natália B. Mota (2 and 3), Rodrigo Wilkens (4 and 5), Aline Villavicencio (5 and 6)Lilian C. Hubner (7), César Rennó-Costa (1) ((1) Bioinformatics Multidisciplinary Environment (BioME), Digital Metropolis Institute (IMD), Federal University of Rio Grande do Norte (UFRN), Natal (RN), Brazil, (2) Research Department at Mobile Brain, Mobile Brain, Rio de Janeiro (RJ), Brazil, (3) Institute of Psychiatry (IPUB), Federal University of Rio de Janeiro (UFRJ), Rio de Janeiro (RJ), Brazil, (4) Department of Computer Science, The University of Exeter, Exeter, UK, (5) Institute for Data Science and Artificial Intelligence at the University of Exeter, Exeter, UK, (6) Department of Computer Science, The University of Sheffield, Sheffield, UK, (7) School of Humanities, Pontifical Catholic University of Rio Grande do Sul (PUCRS), Porto Alegre (RS), Brazil)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00250">https://arxiv.org/abs/2410.00250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00250">https://arxiv.org/pdf/2410.00250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00250]] A Methodology for Explainable Large Language Models with Integrated Gradients and Linguistic Analysis in Text Classification(https://arxiv.org/abs/2410.00250)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Neurological disorders that affect speech production, such as Alzheimer's Disease (AD), significantly impact the lives of both patients and caregivers, whether through social, psycho-emotional effects or other aspects not yet fully understood. Recent advancements in Large Language Model (LLM) architectures have developed many tools to identify representative features of neurological disorders through spontaneous speech. However, LLMs typically lack interpretability, meaning they do not provide clear and specific reasons for their decisions. Therefore, there is a need for methods capable of identifying the representative features of neurological disorders in speech and explaining clearly why these features are relevant. This paper presents an explainable LLM method, named SLIME (Statistical and Linguistic Insights for Model Explanation), capable of identifying lexical components representative of AD and indicating which components are most important for the LLM's decision. In developing this method, we used an English-language dataset consisting of transcriptions from the Cookie Theft picture description task. The LLM Bidirectional Encoder Representations from Transformers (BERT) classified the textual descriptions as either AD or control groups. To identify representative lexical features and determine which are most relevant to the model's decision, we used a pipeline involving Integrated Gradients (IG), Linguistic Inquiry and Word Count (LIWC), and statistical analysis. Our method demonstrates that BERT leverages lexical components that reflect a reduction in social references in AD and identifies which further improve the LLM's accuracy. Thus, we provide an explainability tool that enhances confidence in applying LLMs to neurological clinical contexts, particularly in the study of neurodegeneration.</li>
</ul>

<h3>Title: Enhanced Credit Score Prediction Using Ensemble Deep Learning Model</h3>
<ul>
<li><strong>Authors: </strong>Qianwen Xing, Chang Yu, Sining Huang, Qi Zheng, Xingyu Mu, Mengying Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00256">https://arxiv.org/abs/2410.00256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00256">https://arxiv.org/pdf/2410.00256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00256]] Enhanced Credit Score Prediction Using Ensemble Deep Learning Model(https://arxiv.org/abs/2410.00256)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In contemporary economic society, credit scores are crucial for every participant. A robust credit evaluation system is essential for the profitability of core businesses such as credit cards, loans, and investments for commercial banks and the financial sector. This paper combines high-performance models like XGBoost and LightGBM, already widely used in modern banking systems, with the powerful TabNet model. We have developed a potent model capable of accurately determining credit score levels by integrating Random Forest, XGBoost, and TabNet, and through the stacking technique in ensemble modeling. This approach surpasses the limitations of single models and significantly advances the precise credit score prediction. In the following sections, we will explain the techniques we used and thoroughly validate our approach by comprehensively comparing a series of metrics such as Precision, Recall, F1, and AUC. By integrating Random Forest, XGBoost, and with the TabNet deep learning architecture, these models complement each other, demonstrating exceptionally strong overall performance.</li>
</ul>

<h3>Title: DoPAMine: Domain-specific Pre-training Adaptation from seed-guided data Mining</h3>
<ul>
<li><strong>Authors: </strong>Vinayak Arannil, Sourav Sanjukta Bhabesh, Neha Narwal, Sai Nikhil Thirandas, Darren Yow-Bang Wang, Graham Horwood, Alex Anto Chirayath, Gouri Pandeshwar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00260">https://arxiv.org/abs/2410.00260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00260">https://arxiv.org/pdf/2410.00260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00260]] DoPAMine: Domain-specific Pre-training Adaptation from seed-guided data Mining(https://arxiv.org/abs/2410.00260)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable ability to generalize effectively across numerous industry domains while executing a range of tasks. Many of these competencies are obtained from the data utilized during the pre-training phase of the Language Models (LMs). However, these models exhibit limitations when tasked with performing in specialized or low-resource industry domains. More recent approaches use LLMs for generating domain-specific synthetic data but most often they lack in truthfulness and complexity. Alternatively, in cases where domain data is available like healthcare and finance most of the LMs are proprietary necessitating the need for a scalable method to curate real world industry specific pre-training data. In this work, we propose an automated and scalable framework - DoPAMine:Domain-specific Pre-training Adaptation from seed-guided data Mining, to mine domain specific training data from a large data corpus for domain adaptation of a LM. The framework leverages the parametric knowledge of a LLM to generate diverse and representative seed data tailored to a specific domain which is then used to mine real world data from a large data corpus like Common Crawl. We evaluated our framework's performance in the continual pre-training (CPT) setting by training two domain specific 7B parameter LMs in healthcare and finance with data mined via DoPAMine. Our experiments show that DoPAMine boosts the performance of pre-trained LLMs on average by 4.9% and 5.1% in zero-shot and 5-shot settings respectively on healthcare tasks from MMLU, MedQA, MedMCQA and PubMedQA datasets, and 2.9% and 6.7% for zero-shot and 5-shot settings respectively on finance tasks from FiQA-SA, FPB and Headlines datasets when compared to the baseline.</li>
</ul>

<h3>Title: Procedure-Aware Surgical Video-language Pretraining with Hierarchical Knowledge Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00263">https://arxiv.org/abs/2410.00263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00263">https://arxiv.org/pdf/2410.00263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00263]] Procedure-Aware Surgical Video-language Pretraining with Hierarchical Knowledge Augmentation(https://arxiv.org/abs/2410.00263)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Surgical video-language pretraining (VLP) faces unique challenges due to the knowledge domain gap and the scarcity of multi-modal data. This study aims to bridge the gap by addressing issues regarding textual information loss in surgical lecture videos and the spatial-temporal challenges of surgical VLP. We propose a hierarchical knowledge augmentation approach and a novel Procedure-Encoded Surgical Knowledge-Augmented Video-Language Pretraining (PeskaVLP) framework to tackle these issues. The knowledge augmentation uses large language models (LLM) for refining and enriching surgical concepts, thus providing comprehensive language supervision and reducing the risk of overfitting. PeskaVLP combines language supervision with visual self-supervision, constructing hard negative samples and employing a Dynamic Time Warping (DTW) based loss function to effectively comprehend the cross-modal procedural alignment. Extensive experiments on multiple public surgical scene understanding and cross-modal retrieval datasets show that our proposed method significantly improves zero-shot transferring performance and offers a generalist visual representation for further advancements in surgical scene understanding.</li>
</ul>

<h3>Title: Class-Agnostic Visio-Temporal Scene Sketch Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Aleyna Kütük, Tevfik Metin Sezgin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00266">https://arxiv.org/abs/2410.00266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00266">https://arxiv.org/pdf/2410.00266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00266]] Class-Agnostic Visio-Temporal Scene Sketch Semantic Segmentation(https://arxiv.org/abs/2410.00266)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Scene sketch semantic segmentation is a crucial task for various applications including sketch-to-image retrieval and scene understanding. Existing sketch segmentation methods treat sketches as bitmap images, leading to the loss of temporal order among strokes due to the shift from vector to image format. Moreover, these methods struggle to segment objects from categories absent in the training data. In this paper, we propose a Class-Agnostic Visio-Temporal Network (CAVT) for scene sketch semantic segmentation. CAVT employs a class-agnostic object detector to detect individual objects in a scene and groups the strokes of instances through its post-processing module. This is the first approach that performs segmentation at both the instance and stroke levels within scene sketches. Furthermore, there is a lack of free-hand scene sketch datasets with both instance and stroke-level class annotations. To fill this gap, we collected the largest Free-hand Instance- and Stroke-level Scene Sketch Dataset (FrISS) that contains 1K scene sketches and covers 403 object classes with dense annotations. Extensive experiments on FrISS and other datasets demonstrate the superior performance of our method over state-of-the-art scene sketch segmentation models. The code and dataset will be made public after acceptance.</li>
</ul>

<h3>Title: KPCA-CAM: Visual Explainability of Deep Computer Vision Models using Kernel PCA</h3>
<ul>
<li><strong>Authors: </strong>Sachin Karmani, Thanushon Sivakaran, Gaurav Prasad, Mehmet Ali, Wenbo Yang, Sheyang Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00267">https://arxiv.org/abs/2410.00267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00267">https://arxiv.org/pdf/2410.00267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00267]] KPCA-CAM: Visual Explainability of Deep Computer Vision Models using Kernel PCA(https://arxiv.org/abs/2410.00267)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Deep learning models often function as black boxes, providing no straightforward reasoning for their predictions. This is particularly true for computer vision models, which process tensors of pixel values to generate outcomes in tasks such as image classification and object detection. To elucidate the reasoning of these models, class activation maps (CAMs) are used to highlight salient regions that influence a model's output. This research introduces KPCA-CAM, a technique designed to enhance the interpretability of Convolutional Neural Networks (CNNs) through improved class activation maps. KPCA-CAM leverages Principal Component Analysis (PCA) with the kernel trick to capture nonlinear relationships within CNN activations more effectively. By mapping data into higher-dimensional spaces with kernel functions and extracting principal components from this transformed hyperplane, KPCA-CAM provides more accurate representations of the underlying data manifold. This enables a deeper understanding of the features influencing CNN decisions. Empirical evaluations on the ILSVRC dataset across different CNN models demonstrate that KPCA-CAM produces more precise activation maps, providing clearer insights into the model's reasoning compared to existing CAM algorithms. This research advances CAM techniques, equipping researchers and practitioners with a powerful tool to gain deeper insights into CNN decision-making processes and overall behaviors.</li>
</ul>

<h3>Title: Comprehensive Performance Modeling and System Design Insights for Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Shashank Subramanian, Ermal Rrapaj, Peter Harrington, Smeet Chheda, Steven Farrell, Brian Austin, Samuel Williams, Nicholas Wright, Wahid Bhimji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00273">https://arxiv.org/abs/2410.00273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00273">https://arxiv.org/pdf/2410.00273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00273]] Comprehensive Performance Modeling and System Design Insights for Foundation Models(https://arxiv.org/abs/2410.00273)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative AI, in particular large transformer models, are increasingly driving HPC system design in science and industry. We analyze performance characteristics of such transformer models and discuss their sensitivity to the transformer type, parallelization strategy, and HPC system features (accelerators and interconnects). We utilize a performance model that allows us to explore this complex design space and highlight its key components. We find that different transformer types demand different parallelism and system characteristics at different training regimes. Large Language Models are performant with 3D parallelism and amplify network needs only at pre-training scales with reduced dependence on accelerator capacity and bandwidth. On the other hand, long-sequence transformers, representative of scientific foundation models, place a more uniform dependence on network and capacity with necessary 4D parallelism. Our analysis emphasizes the need for closer performance modeling of different transformer types keeping system features in mind and demonstrates a path towards this. Our code is available as open-source.</li>
</ul>

<h3>Title: On Large Uni- and Multi-modal Models for Unsupervised Classification of Social Media Images: Nature's Contribution to People as case study</h3>
<ul>
<li><strong>Authors: </strong>Rohaifa Khaldi, Domingo Alcaraz-Segura, Ignacio Sánchez-Herrera, Javier Martinez-Lopez, Carlos Javier Navarro, Siham Tabik</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00275">https://arxiv.org/abs/2410.00275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00275">https://arxiv.org/pdf/2410.00275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00275]] On Large Uni- and Multi-modal Models for Unsupervised Classification of Social Media Images: Nature's Contribution to People as case study(https://arxiv.org/abs/2410.00275)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Social media images have shown to be a valuable source of information for understanding human interactions with important subjects such as cultural heritage, biodiversity and nature among others. The task of grouping such images into a number of semantically meaningful clusters without labels is challenging given the high diversity and complex nature of the visual content of these images in addition to their large volume. On the other hand, the last advances in Large Visual Models (LVM), Large Language Models (LLM) and Large Visual Language Models (LVLM) provide an important opportunity to explore new productive and scalable solutions. This works proposes, analyzes, and compares various approaches based on one or more state-of-the art LVM, LLM and LVLM, for mapping social media images into a number of pre-defined classes. As case study, we consider the problem of understanding the interactions between human and nature, also known as Nature's Contribution to People or Cultural Ecosystem Services (CES). Our experiments reveal that the top-performing approaches, delivering highly competitive results, are the fine-tuned LVM DINOv2 on a small labeled dataset and LVLM models like the proprietary GPT-4 (gpt-4o-mini) using a simple prompt.</li>
</ul>

<h3>Title: Performance Evaluation of Deep Learning-based Quadrotor UAV Detection and Tracking Methods</h3>
<ul>
<li><strong>Authors: </strong>Mohssen E. Elshaar, Zeyad M. Manaa, Mohammed R. Elbalshy, Abdul Jabbar Siddiqui, Ayman M. Abdallah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00285">https://arxiv.org/abs/2410.00285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00285">https://arxiv.org/pdf/2410.00285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00285]] Performance Evaluation of Deep Learning-based Quadrotor UAV Detection and Tracking Methods(https://arxiv.org/abs/2410.00285)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Unmanned Aerial Vehicles (UAVs) are becoming more popular in various sectors, offering many benefits, yet introducing significant challenges to privacy and safety. This paper investigates state-of-the-art solutions for detecting and tracking quadrotor UAVs to address these concerns. Cutting-edge deep learning models, specifically the YOLOv5 and YOLOv8 series, are evaluated for their performance in identifying UAVs accurately and quickly. Additionally, robust tracking systems, BoT-SORT and Byte Track, are integrated to ensure reliable monitoring even under challenging conditions. Our tests on the DUT dataset reveal that while YOLOv5 models generally outperform YOLOv8 in detection accuracy, the YOLOv8 models excel in recognizing less distinct objects, demonstrating their adaptability and advanced capabilities. Furthermore, BoT-SORT demonstrated superior performance over Byte Track, achieving higher IoU and lower center error in most cases, indicating more accurate and stable tracking. Code: this https URL Tracking demo: this https URL</li>
</ul>

<h3>Title: Insight: A Multi-Modal Diagnostic Pipeline using LLMs for Ocular Surface Disease Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Chun-Hsiao Yeh, Jiayun Wang, Andrew D. Graham, Andrea J. Liu, Bo Tan, Yubei Chen, Yi Ma, Meng C. Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00292">https://arxiv.org/abs/2410.00292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00292">https://arxiv.org/pdf/2410.00292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00292]] Insight: A Multi-Modal Diagnostic Pipeline using LLMs for Ocular Surface Disease Diagnosis(https://arxiv.org/abs/2410.00292)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate diagnosis of ocular surface diseases is critical in optometry and ophthalmology, which hinge on integrating clinical data sources (e.g., meibography imaging and clinical metadata). Traditional human assessments lack precision in quantifying clinical observations, while current machine-based methods often treat diagnoses as multi-class classification problems, limiting the diagnoses to a predefined closed-set of curated answers without reasoning the clinical relevance of each variable to the diagnosis. To tackle these challenges, we introduce an innovative multi-modal diagnostic pipeline (MDPipe) by employing large language models (LLMs) for ocular surface disease diagnosis. We first employ a visual translator to interpret meibography images by converting them into quantifiable morphology data, facilitating their integration with clinical metadata and enabling the communication of nuanced medical insight to LLMs. To further advance this communication, we introduce a LLM-based summarizer to contextualize the insight from the combined morphology and clinical metadata, and generate clinical report summaries. Finally, we refine the LLMs' reasoning ability with domain-specific insight from real-life clinician diagnoses. Our evaluation across diverse ocular surface disease diagnosis benchmarks demonstrates that MDPipe outperforms existing standards, including GPT-4, and provides clinically sound rationales for diagnoses.</li>
</ul>

<h3>Title: GSPR: Multimodal Place Recognition Using 3D Gaussian Splatting for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Zhangshuo Qi, Junyi Ma, Jingyi Xu, Zijie Zhou, Luqi Cheng, Guangming Xiong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00299">https://arxiv.org/abs/2410.00299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00299">https://arxiv.org/pdf/2410.00299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00299]] GSPR: Multimodal Place Recognition Using 3D Gaussian Splatting for Autonomous Driving(https://arxiv.org/abs/2410.00299)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Place recognition is a crucial module to ensure autonomous vehicles obtain usable localization information in GPS-denied environments. In recent years, multimodal place recognition methods have gained increasing attention due to their ability to overcome the weaknesses of unimodal sensor systems by leveraging complementary information from different modalities. However, challenges arise from the necessity of harmonizing data across modalities and exploiting the spatio-temporal correlations between them sufficiently. In this paper, we propose a 3D Gaussian Splatting-based multimodal place recognition neural network dubbed GSPR. It explicitly combines multi-view RGB images and LiDAR point clouds into a spatio-temporally unified scene representation with the proposed Multimodal Gaussian Splatting. A network composed of 3D graph convolution and transformer is designed to extract high-level spatio-temporal features and global descriptors from the Gaussian scenes for place recognition. We evaluate our method on the nuScenes dataset, and the experimental results demonstrate that our method can effectively leverage complementary strengths of both multi-view cameras and LiDAR, achieving SOTA place recognition performance while maintaining solid generalization ability. Our open-source code is available at this https URL.</li>
</ul>

<h3>Title: RadGazeGen: Radiomics and Gaze-guided Medical Image Generation using Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Moinak Bhattacharya, Gagandeep Singh, Shubham Jain, Prateek Prasanna</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00307">https://arxiv.org/abs/2410.00307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00307">https://arxiv.org/pdf/2410.00307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00307]] RadGazeGen: Radiomics and Gaze-guided Medical Image Generation using Diffusion Models(https://arxiv.org/abs/2410.00307)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this work, we present RadGazeGen, a novel framework for integrating experts' eye gaze patterns and radiomic feature maps as controls to text-to-image diffusion models for high fidelity medical image generation. Despite the recent success of text-to-image diffusion models, text descriptions are often found to be inadequate and fail to convey detailed disease-specific information to these models to generate clinically accurate images. The anatomy, disease texture patterns, and location of the disease are extremely important to generate realistic images; moreover the fidelity of image generation can have significant implications in downstream tasks involving disease diagnosis or treatment repose assessment. Hence, there is a growing need to carefully define the controls used in diffusion models for medical image generation. Eye gaze patterns of radiologists are important visuo-cognitive information, indicative of subtle disease patterns and spatial location. Radiomic features further provide important subvisual cues regarding disease phenotype. In this work, we propose to use these gaze patterns in combination with standard radiomics descriptors, as controls, to generate anatomically correct and disease-aware medical images. RadGazeGen is evaluated for image generation quality and diversity on the REFLACX dataset. To demonstrate clinical applicability, we also show classification performance on the generated images from the CheXpert test set (n=500) and long-tailed learning performance on the MIMIC-CXR-LT test set (n=23550).</li>
</ul>

<h3>Title: Ask, Pose, Unite: Scaling Data Acquisition for Close Interactions with Vision Language Models</h3>
<ul>
<li><strong>Authors: </strong>Laura Bravo-Sánchez, Jaewoo Heo, Zhenzhen Weng, Kuan-Chieh Wang, Serena Yeung-Levy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00309">https://arxiv.org/abs/2410.00309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00309">https://arxiv.org/pdf/2410.00309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00309]] Ask, Pose, Unite: Scaling Data Acquisition for Close Interactions with Vision Language Models(https://arxiv.org/abs/2410.00309)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Social dynamics in close human interactions pose significant challenges for Human Mesh Estimation (HME), particularly due to the complexity of physical contacts and the scarcity of training data. Addressing these challenges, we introduce a novel data generation method that utilizes Large Vision Language Models (LVLMs) to annotate contact maps which guide test-time optimization to produce paired image and pseudo-ground truth meshes. This methodology not only alleviates the annotation burden but also enables the assembly of a comprehensive dataset specifically tailored for close interactions in HME. Our Ask Pose Unite (APU) dataset, comprising over 6.2k human mesh pairs in contact covering diverse interaction types, is curated from images depicting naturalistic person-to-person scenes. We empirically show that using our dataset to train a diffusion-based contact prior, used as guidance during optimization, improves mesh estimation on unseen interactions. Our work addresses longstanding challenges of data scarcity for close interactions in HME enhancing the field's capabilities of handling complex interaction scenarios.</li>
</ul>

<h3>Title: PointAD: Comprehending 3D Anomalies from Points and Pixels for Zero-shot 3D Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Qihang Zhou, Jiangtao Yan, Shibo He, Wenchao Meng, Jiming Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00320">https://arxiv.org/abs/2410.00320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00320">https://arxiv.org/pdf/2410.00320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00320]] PointAD: Comprehending 3D Anomalies from Points and Pixels for Zero-shot 3D Anomaly Detection(https://arxiv.org/abs/2410.00320)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Zero-shot (ZS) 3D anomaly detection is a crucial yet unexplored field that addresses scenarios where target 3D training samples are unavailable due to practical concerns like privacy protection. This paper introduces PointAD, a novel approach that transfers the strong generalization capabilities of CLIP for recognizing 3D anomalies on unseen objects. PointAD provides a unified framework to comprehend 3D anomalies from both points and pixels. In this framework, PointAD renders 3D anomalies into multiple 2D renderings and projects them back into 3D space. To capture the generic anomaly semantics into PointAD, we propose hybrid representation learning that optimizes the learnable text prompts from 3D and 2D through auxiliary point clouds. The collaboration optimization between point and pixel representations jointly facilitates our model to grasp underlying 3D anomaly patterns, contributing to detecting and segmenting anomalies of unseen diverse 3D objects. Through the alignment of 3D and 2D space, our model can directly integrate RGB information, further enhancing the understanding of 3D anomalies in a plug-and-play manner. Extensive experiments show the superiority of PointAD in ZS 3D anomaly detection across diverse unseen objects.</li>
</ul>

<h3>Title: A Cat Is A Cat (Not A Dog!): Unraveling Information Mix-ups in Text-to-Image Encoders through Causal Analysis and Embedding Optimization</h3>
<ul>
<li><strong>Authors: </strong>Chieh-Yun Chen, Li-Wu Tsao, Chiang Tseng, Hong-Han Shuai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00321">https://arxiv.org/abs/2410.00321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00321">https://arxiv.org/pdf/2410.00321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00321]] A Cat Is A Cat (Not A Dog!): Unraveling Information Mix-ups in Text-to-Image Encoders through Causal Analysis and Embedding Optimization(https://arxiv.org/abs/2410.00321)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper analyzes the impact of causal manner in the text encoder of text-to-image (T2I) diffusion models, which can lead to information bias and loss. Previous works have focused on addressing the issues through the denoising process. However, there is no research discussing how text embedding contributes to T2I models, especially when generating more than one object. In this paper, we share a comprehensive analysis of text embedding: i) how text embedding contributes to the generated images and ii) why information gets lost and biases towards the first-mentioned object. Accordingly, we propose a simple but effective text embedding balance optimization method, which is training-free, with an improvement of 90.05% on information balance in stable diffusion. Furthermore, we propose a new automatic evaluation metric that quantifies information loss more accurately than existing methods, achieving 81% concordance with human assessments. This metric effectively measures the presence and accuracy of objects, addressing the limitations of current distribution scores like CLIP's text-image similarities.</li>
</ul>

<h3>Title: EnzymeFlow: Generating Reaction-specific Enzyme Catalytic Pockets through Flow Matching and Co-Evolutionary Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Chenqing Hua, Yong Liu, Dinghuai Zhang, Odin Zhang, Sitao Luan, Kevin K. Yang, Guy Wolf, Doina Precup, Shuangjia Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00327">https://arxiv.org/abs/2410.00327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00327">https://arxiv.org/pdf/2410.00327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00327]] EnzymeFlow: Generating Reaction-specific Enzyme Catalytic Pockets through Flow Matching and Co-Evolutionary Dynamics(https://arxiv.org/abs/2410.00327)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Enzyme design is a critical area in biotechnology, with applications ranging from drug development to synthetic biology. Traditional methods for enzyme function prediction or protein binding pocket design often fall short in capturing the dynamic and complex nature of enzyme-substrate interactions, particularly in catalytic processes. To address the challenges, we introduce EnzymeFlow, a generative model that employs flow matching with hierarchical pre-training and enzyme-reaction co-evolution to generate catalytic pockets for specific substrates and catalytic reactions. Additionally, we introduce a large-scale, curated, and validated dataset of enzyme-reaction pairs, specifically designed for the catalytic pocket generation task, comprising a total of $328,192$ pairs. By incorporating evolutionary dynamics and reaction-specific adaptations, EnzymeFlow becomes a powerful model for designing enzyme pockets, which is capable of catalyzing a wide range of biochemical reactions. Experiments on the new dataset demonstrate the model's effectiveness in designing high-quality, functional enzyme catalytic pockets, paving the way for advancements in enzyme engineering and synthetic biology. We provide EnzymeFlow code at this https URL with notebook demonstration at this https URL.</li>
</ul>

<h3>Title: Preserving Generalization of Language models in Few-shot Continual Relation Extraction</h3>
<ul>
<li><strong>Authors: </strong>Quyen Tran, Nguyen Xuan Thanh, Nguyen Hoang Anh, Nam Le Hai, Trung Le, Linh Van Ngo, Thien Huu Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00334">https://arxiv.org/abs/2410.00334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00334">https://arxiv.org/pdf/2410.00334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00334]] Preserving Generalization of Language models in Few-shot Continual Relation Extraction(https://arxiv.org/abs/2410.00334)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Few-shot Continual Relations Extraction (FCRE) is an emerging and dynamic area of study where models can sequentially integrate knowledge from new relations with limited labeled data while circumventing catastrophic forgetting and preserving prior knowledge from pre-trained backbones. In this work, we introduce a novel method that leverages often-discarded language model heads. By employing these components via a mutual information maximization strategy, our approach helps maintain prior knowledge from the pre-trained backbone and strategically aligns the primary classification head, thereby enhancing model performance. Furthermore, we explore the potential of Large Language Models (LLMs), renowned for their wealth of knowledge, in addressing FCRE challenges. Our comprehensive experimental results underscore the efficacy of the proposed method and offer valuable insights for future work.</li>
</ul>

<h3>Title: SyntheOcc: Synthesize Geometric-Controlled Street View Images through 3D Semantic MPIs</h3>
<ul>
<li><strong>Authors: </strong>Leheng Li, Weichao Qiu, Yingjie Cai, Xu Yan, Qing Lian, Bingbing Liu, Ying-Cong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00337">https://arxiv.org/abs/2410.00337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00337">https://arxiv.org/pdf/2410.00337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00337]] SyntheOcc: Synthesize Geometric-Controlled Street View Images through 3D Semantic MPIs(https://arxiv.org/abs/2410.00337)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The advancement of autonomous driving is increasingly reliant on high-quality annotated datasets, especially in the task of 3D occupancy prediction, where the occupancy labels require dense 3D annotation with significant human effort. In this paper, we propose SyntheOcc, which denotes a diffusion model that Synthesize photorealistic and geometric-controlled images by conditioning Occupancy labels in driving scenarios. This yields an unlimited amount of diverse, annotated, and controllable datasets for applications like training perception models and simulation. SyntheOcc addresses the critical challenge of how to efficiently encode 3D geometric information as conditional input to a 2D diffusion model. Our approach innovatively incorporates 3D semantic multi-plane images (MPIs) to provide comprehensive and spatially aligned 3D scene descriptions for conditioning. As a result, SyntheOcc can generate photorealistic multi-view images and videos that faithfully align with the given geometric labels (semantics in 3D voxel space). Extensive qualitative and quantitative evaluations of SyntheOcc on the nuScenes dataset prove its effectiveness in generating controllable occupancy datasets that serve as an effective data augmentation to perception models.</li>
</ul>

<h3>Title: A Taxonomy of Loss Functions for Stochastic Optimal Control</h3>
<ul>
<li><strong>Authors: </strong>Carles Domingo-Enrich</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00345">https://arxiv.org/abs/2410.00345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00345">https://arxiv.org/pdf/2410.00345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00345]] A Taxonomy of Loss Functions for Stochastic Optimal Control(https://arxiv.org/abs/2410.00345)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Stochastic optimal control (SOC) aims to direct the behavior of noisy systems and has widespread applications in science, engineering, and artificial intelligence. In particular, reward fine-tuning of diffusion and flow matching models and sampling from unnormalized methods can be recast as SOC problems. A recent work has introduced Adjoint Matching (Domingo-Enrich et al., 2024), a loss function for SOC problems that vastly outperforms existing loss functions in the reward fine-tuning setup. The goal of this work is to clarify the connections between all the existing (and some new) SOC loss functions. Namely, we show that SOC loss functions can be grouped into classes that share the same gradient in expectation, which means that their optimization landscape is the same; they only differ in their gradient variance. We perform simple SOC experiments to understand the strengths and weaknesses of different loss functions.</li>
</ul>

<h3>Title: Revisiting the Role of Texture in 3D Person Re-identification</h3>
<ul>
<li><strong>Authors: </strong>Huy Nguyen, Kien Nguyen, Akila Pemasiri, Sridha Sridharan, Clinton Fookes</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00348">https://arxiv.org/abs/2410.00348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00348">https://arxiv.org/pdf/2410.00348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00348]] Revisiting the Role of Texture in 3D Person Re-identification(https://arxiv.org/abs/2410.00348)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>This study introduces a new framework for 3D person re-identification (re-ID) that leverages readily available high-resolution texture data in 3D reconstruction to improve the performance and explainability of the person re-ID task. We propose a method to emphasize texture in 3D person re-ID models by incorporating UVTexture mapping, which better differentiates human subjects. Our approach uniquely combines UVTexture and its heatmaps with 3D models to visualize and explain the person re-ID process. In particular, the visualization and explanation are achieved through activation maps and attribute-based attention maps, which highlight the important regions and features contributing to the person re-ID decision. Our contributions include: (1) a novel technique for emphasizing texture in 3D models using UVTexture processing, (2) an innovative method for explicating person re-ID matches through a combination of 3D models and UVTexture mapping, and (3) achieving state-of-the-art performance in 3D person re-ID. We ensure the reproducibility of our results by making all data, codes, and models publicly available.</li>
</ul>

<h3>Title: Efficient Training of Large Vision Models via Advanced Automated Progressive Learning</h3>
<ul>
<li><strong>Authors: </strong>Changlin Li, Jiawei Zhang, Sihao Lin, Zongxin Yang, Junwei Liang, Xiaodan Liang, Xiaojun Chang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00350">https://arxiv.org/abs/2410.00350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00350">https://arxiv.org/pdf/2410.00350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00350]] Efficient Training of Large Vision Models via Advanced Automated Progressive Learning(https://arxiv.org/abs/2410.00350)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>The rapid advancements in Large Vision Models (LVMs), such as Vision Transformers (ViTs) and diffusion models, have led to an increasing demand for computational resources, resulting in substantial financial and environmental costs. This growing challenge highlights the necessity of developing efficient training methods for LVMs. Progressive learning, a training strategy in which model capacity gradually increases during training, has shown potential in addressing these challenges. In this paper, we present an advanced automated progressive learning (AutoProg) framework for efficient training of LVMs. We begin by focusing on the pre-training of LVMs, using ViTs as a case study, and propose AutoProg-One, an AutoProg scheme featuring momentum growth (MoGrow) and a one-shot growth schedule search. Beyond pre-training, we extend our approach to tackle transfer learning and fine-tuning of LVMs. We expand the scope of AutoProg to cover a wider range of LVMs, including diffusion models. First, we introduce AutoProg-Zero, by enhancing the AutoProg framework with a novel zero-shot unfreezing schedule search, eliminating the need for one-shot supernet training. Second, we introduce a novel Unique Stage Identifier (SID) scheme to bridge the gap during network growth. These innovations, integrated with the core principles of AutoProg, offer a comprehensive solution for efficient training across various LVM scenarios. Extensive experiments show that AutoProg accelerates ViT pre-training by up to 1.85x on ImageNet and accelerates fine-tuning of diffusion models by up to 2.86x, with comparable or even higher performance. This work provides a robust and scalable approach to efficient training of LVMs, with potential applications in a wide range of vision tasks. Code: this https URL</li>
</ul>

<h3>Title: Hierarchical Organization Simulacra in the Investment Sector</h3>
<ul>
<li><strong>Authors: </strong>Chung-Chi Chen, Hiroya Takamura, Ichiro Kobayashi, Yusuke Miyao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00354">https://arxiv.org/abs/2410.00354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00354">https://arxiv.org/pdf/2410.00354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00354]] Hierarchical Organization Simulacra in the Investment Sector(https://arxiv.org/abs/2410.00354)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper explores designing artificial organizations with professional behavior in investments using a multi-agent simulation. The method mimics hierarchical decision-making in investment firms, using news articles to inform decisions. A large-scale study analyzing over 115,000 news articles of 300 companies across 15 years compared this approach against professional traders' decisions. Results show that hierarchical simulations align closely with professional choices, both in frequency and profitability. However, the study also reveals biases in decision-making, where changes in prompt wording and perceived agent seniority significantly influence outcomes. This highlights both the potential and limitations of large language models in replicating professional financial decision-making.</li>
</ul>

<h3>Title: Self-controller: Controlling LLMs with Multi-round Step-by-step Self-awareness</h3>
<ul>
<li><strong>Authors: </strong>Xiao Peng, Xufan Geng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00359">https://arxiv.org/abs/2410.00359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00359">https://arxiv.org/pdf/2410.00359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00359]] Self-controller: Controlling LLMs with Multi-round Step-by-step Self-awareness(https://arxiv.org/abs/2410.00359)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The applications of large language models (LLMs) have been widely spread across all domains. However, the basic abilities such as the controllability of LLMs are still limited. To address this, we propose "Self-controller", a novel agentic framework bringing self-awareness into LLMs' reasoning logic. The core idea of this work is to maintain states based on the LLM's response, letting the LLM become self-aware of current status and think step by step in a multi-round chain-of-thought paradigm. Our experiment on the state of textual length has shown the controllability and effectiveness of the Self-controller. We further implement a binary search algorithm to accelerate the generation process based on the linearity and monotonicity of the textual length state. Another advantage of the Self-controller comes with DeepSeek's Context Caching technology, which significantly saves computational token consumption when a cluster of conversations shares the same prefix of context. Theoretically, we prove that in this scenario the extra time complexity is $O(c \log n)$. Results of the back-of-the-envelope estimation suggest that the token consumption of our method is no more than twice as much as that of the trivial single-round generation. Furthermore, our ablation study on word constraints demonstrates the Self-controller's consistent controllability across all foundation models.</li>
</ul>

<h3>Title: TFCT-I2P: Three stream fusion network with color aware transformer for image-to-point cloud registration</h3>
<ul>
<li><strong>Authors: </strong>Muyao Peng, Pei An, Zichen Wan, You Yang, Qiong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00360">https://arxiv.org/abs/2410.00360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00360">https://arxiv.org/pdf/2410.00360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00360]] TFCT-I2P: Three stream fusion network with color aware transformer for image-to-point cloud registration(https://arxiv.org/abs/2410.00360)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Along with the advancements in artificial intelligence technologies, image-to-point-cloud registration (I2P) techniques have made significant strides. Nevertheless, the dimensional differences in the features of points cloud (three-dimension) and image (two-dimension) continue to pose considerable challenges to their development. The primary challenge resides in the inability to leverage the features of one modality to augment those of another, thereby complicating the alignment of features within the latent space. To address this challenge, we propose an image-to-point-cloud method named as TFCT-I2P. Initially, we introduce a Three-Stream Fusion Network (TFN), which integrates color information from images with structural information from point clouds, facilitating the alignment of features from both modalities. Subsequently, to effectively mitigate patch-level misalignments introduced by the inclusion of color information, we design a Color-Aware Transformer (CAT). Finally, we conduct extensive experiments on 7Scenes, RGB-D Scenes V2, ScanNet V2, and a self-collected dataset. The results demonstrate that TFCT-I2P surpasses state-of-the-art methods by 1.5% in Inlier Ratio, 0.4% in Feature Matching Recall, and 5.4% in Registration Recall. Therefore, we believe that the proposed TFCT-I2P contributes to the advancement of I2P registration.</li>
</ul>

<h3>Title: PclGPT: A Large Language Model for Patronizing and Condescending Language Detection</h3>
<ul>
<li><strong>Authors: </strong>Hongbo Wang, Mingda Li, Junyu Lu, Hebin Xia, Liang Yang, Bo Xu, Ruizhu Liu, Hongfei Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00361">https://arxiv.org/abs/2410.00361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00361">https://arxiv.org/pdf/2410.00361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00361]] PclGPT: A Large Language Model for Patronizing and Condescending Language Detection(https://arxiv.org/abs/2410.00361)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Disclaimer: Samples in this paper may be harmful and cause discomfort! Patronizing and condescending language (PCL) is a form of speech directed at vulnerable groups. As an essential branch of toxic language, this type of language exacerbates conflicts and confrontations among Internet communities and detrimentally impacts disadvantaged groups. Traditional pre-trained language models (PLMs) perform poorly in detecting PCL due to its implicit toxicity traits like hypocrisy and false sympathy. With the rise of large language models (LLMs), we can harness their rich emotional semantics to establish a paradigm for exploring implicit toxicity. In this paper, we introduce PclGPT, a comprehensive LLM benchmark designed specifically for PCL. We collect, annotate, and integrate the Pcl-PT/SFT dataset, and then develop a bilingual PclGPT-EN/CN model group through a comprehensive pre-training and supervised fine-tuning staircase process to facilitate implicit toxic detection. Group detection results and fine-grained detection from PclGPT and other models reveal significant variations in the degree of bias in PCL towards different vulnerable groups, necessitating increased societal attention to protect them.</li>
</ul>

<h3>Title: FedPT: Federated Proxy-Tuning of Large Language Models on Resource-Constrained Edge Devices</h3>
<ul>
<li><strong>Authors: </strong>Zhidong Gao, Yu Zhang, Zhenxiao Zhang, Yanmin Gong, Yuanxiong Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00362">https://arxiv.org/abs/2410.00362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00362">https://arxiv.org/pdf/2410.00362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00362]] FedPT: Federated Proxy-Tuning of Large Language Models on Resource-Constrained Edge Devices(https://arxiv.org/abs/2410.00362)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>Despite demonstrating superior performance across a variety of linguistic tasks, pre-trained large language models (LMs) often require fine-tuning on specific datasets to effectively address different downstream tasks. However, fine-tuning these LMs for downstream tasks necessitates collecting data from individuals, which raises significant privacy concerns. Federated learning (FL) has emerged as the de facto solution, enabling collaborative model training without sharing raw data. While promising, federated fine-tuning of large LMs faces significant challenges, including restricted access to model parameters and high computation, communication, and memory overhead. To address these challenges, this paper introduces \textbf{Fed}erated \textbf{P}roxy-\textbf{T}uning (FedPT), a novel framework for federated fine-tuning of black-box large LMs, requiring access only to their predictions over the output vocabulary instead of their parameters. Specifically, devices in FedPT first collaboratively tune a smaller LM, and then the server combines the knowledge learned by the tuned small LM with the knowledge learned by the larger pre-trained LM to construct a large proxy-tuned LM that can reach the performance of directly tuned large LMs. The experimental results demonstrate that FedPT can significantly reduce computation, communication, and memory overhead while maintaining competitive performance compared to directly federated fine-tuning of large LMs. FedPT offers a promising solution for efficient, privacy-preserving fine-tuning of large LMs on resource-constrained devices, broadening the accessibility and applicability of state-of-the-art large LMs.</li>
</ul>

<h3>Title: Unleashing the Potentials of Likelihood Composition for Multi-modal Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shitian Zhao, Renrui Zhang, Xu Luo, Yan Wang, Shanghang Zhang, Peng Gao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00363">https://arxiv.org/abs/2410.00363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00363">https://arxiv.org/pdf/2410.00363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00363]] Unleashing the Potentials of Likelihood Composition for Multi-modal Language Models(https://arxiv.org/abs/2410.00363)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Model fusing has always been an important topic, especially in an era where large language models (LLM) and multi-modal language models (MLM) with different architectures, parameter sizes and training pipelines, are being created all the time. In this work, we propose a post-hoc framework, aiming at fusing heterogeneous models off-the-shell, which we call \textit{likelihood composition}, and the basic idea is to compose multiple models' likelihood distribution when doing a multi-choice visual-question-answering task. Here the core concept, \textit{likelihood}, is actually the log-probability of the candidate answer. In \textit{likelihood composition}, we introduce some basic operations: \textit{debias}, \textit{highlight}, \textit{majority-vote} and \textit{ensemble}. By combining (composing) these basic elements, we get the mixed composition methods: \textit{mix-composition}. Through conducting comprehensive experiments on 9 VQA datasets and 10 MLMs, we prove the effectiveness of \textit{mix-composition} compared with simple \textit{ensemble} or \textit{majority-vote} methods. In this framework, people can propose new basic composition methods and combine them to get the new mixed composition methods. We hope our proposed \textit{likelihood composition} can provide a new perspective of fusing heterogeneous models and inspire the exploration under this framework.</li>
</ul>

<h3>Title: Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare</h3>
<ul>
<li><strong>Authors: </strong>Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00366">https://arxiv.org/abs/2410.00366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00366">https://arxiv.org/pdf/2410.00366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00366]] Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare(https://arxiv.org/abs/2410.00366)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>The rapid advancements in artificial intelligence (AI) have revolutionized smart healthcare, driving innovations in wearable technologies, continuous monitoring devices, and intelligent diagnostic systems. However, security, explainability, robustness, and performance optimization challenges remain critical barriers to widespread adoption in clinical environments. This research presents an innovative algorithmic method using the Adaptive Feature Evaluator (AFE) algorithm to improve feature selection in healthcare datasets and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT), the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby enhancing predictive accuracy and interpretability. The proposed method is validated across three diverse healthcare datasets using six distinct machine learning algorithms, demonstrating its robustness and superiority over conventional feature selection techniques. The results underscore the transformative potential of AFE in smart healthcare, enabling personalized and transparent patient care. Notably, the AFE algorithm, when combined with a Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting its capability to improve clinical decision-making processes in real-world healthcare applications.</li>
</ul>

<h3>Title: Descriptor: Face Detection Dataset for Programmable Threshold-Based Sparse-Vision</h3>
<ul>
<li><strong>Authors: </strong>Riadul Islam, Sri Ranga Sai Krishna Tummala, Joey Mulé, Rohith Kankipati, Suraj Jalapally, Dhandeep Challagundla, Chad Howard, Ryan Robucci</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00368">https://arxiv.org/abs/2410.00368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00368">https://arxiv.org/pdf/2410.00368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00368]] Descriptor: Face Detection Dataset for Programmable Threshold-Based Sparse-Vision(https://arxiv.org/abs/2410.00368)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Smart focal-plane and in-chip image processing has emerged as a crucial technology for vision-enabled embedded systems with energy efficiency and privacy. However, the lack of special datasets providing examples of the data that these neuromorphic sensors compute to convey visual information has hindered the adoption of these promising technologies. Neuromorphic imager variants, including event-based sensors, produce various representations such as streams of pixel addresses representing time and locations of intensity changes in the focal plane, temporal-difference data, data sifted/thresholded by temporal differences, image data after applying spatial transformations, optical flow data, and/or statistical representations. To address the critical barrier to entry, we provide an annotated, temporal-threshold-based vision dataset specifically designed for face detection tasks derived from the same videos used for Aff-Wild2. By offering multiple threshold levels (e.g., 4, 8, 12, and 16), this dataset allows for comprehensive evaluation and optimization of state-of-the-art neural architectures under varying conditions and settings compared to traditional methods. The accompanying tool flow for generating event data from raw videos further enhances accessibility and usability. We anticipate that this resource will significantly support the development of robust vision systems based on smart sensors that can process based on temporal-difference thresholds, enabling more accurate and efficient object detection and localization and ultimately promoting the broader adoption of low-power, neuromorphic imaging technologies. To support further research, we publicly released the dataset at \url{this https URL}.</li>
</ul>

<h3>Title: Robust Traffic Forecasting against Spatial Shift over Years</h3>
<ul>
<li><strong>Authors: </strong>Hongjun Wang, Jiyuan Chen, Tong Pan, Zheng Dong, Lingyu Zhang, Renhe Jiang, Xuan Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DB, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00373">https://arxiv.org/abs/2410.00373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00373">https://arxiv.org/pdf/2410.00373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00373]] Robust Traffic Forecasting against Spatial Shift over Years(https://arxiv.org/abs/2410.00373)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Recent advancements in Spatiotemporal Graph Neural Networks (ST-GNNs) and Transformers have demonstrated promising potential for traffic forecasting by effectively capturing both temporal and spatial correlations. The generalization ability of spatiotemporal models has received considerable attention in recent scholarly discourse. However, no substantive datasets specifically addressing traffic out-of-distribution (OOD) scenarios have been proposed. Existing ST-OOD methods are either constrained to testing on extant data or necessitate manual modifications to the dataset. Consequently, the generalization capacity of current spatiotemporal models in OOD scenarios remains largely underexplored. In this paper, we investigate state-of-the-art models using newly proposed traffic OOD benchmarks and, surprisingly, find that these models experience a significant decline in performance. Through meticulous analysis, we attribute this decline to the models' inability to adapt to previously unobserved spatial relationships. To address this challenge, we propose a novel Mixture of Experts (MoE) framework, which learns a set of graph generators (i.e., graphons) during training and adaptively combines them to generate new graphs based on novel environmental conditions to handle spatial distribution shifts during testing. We further extend this concept to the Transformer architecture, achieving substantial improvements. Our method is both parsimonious and efficacious, and can be seamlessly integrated into any spatiotemporal model, outperforming current state-of-the-art approaches in addressing spatial dynamics.</li>
</ul>

<h3>Title: CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset</h3>
<ul>
<li><strong>Authors: </strong>Xiao Wang, Fuling Wang, Yuehang Li, Qingchuan Ma, Shiao Wang, Bo Jiang, Chuanfu Li, Jin Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00379">https://arxiv.org/abs/2410.00379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00379">https://arxiv.org/pdf/2410.00379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00379]] CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset(https://arxiv.org/abs/2410.00379)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>X-ray image-based medical report generation (MRG) is a pivotal area in artificial intelligence which can significantly reduce diagnostic burdens and patient wait times. Despite significant progress, we believe that the task has reached a bottleneck due to the limited benchmark datasets and the existing large models' insufficient capability enhancements in this specialized domain. Specifically, the recently released CheXpert Plus dataset lacks comparative evaluation algorithms and their results, providing only the dataset itself. This situation makes the training, evaluation, and comparison of subsequent algorithms challenging. Thus, we conduct a comprehensive benchmarking of existing mainstream X-ray report generation models and large language models (LLMs), on the CheXpert Plus dataset. We believe that the proposed benchmark can provide a solid comparative basis for subsequent algorithms and serve as a guide for researchers to quickly grasp the state-of-the-art models in this field. More importantly, we propose a large model for the X-ray image report generation using a multi-stage pre-training strategy, including self-supervised autoregressive generation and Xray-report contrastive learning, and supervised fine-tuning. Extensive experimental results indicate that the autoregressive pre-training based on Mamba effectively encodes X-ray images, and the image-text contrastive pre-training further aligns the feature spaces, achieving better experimental results. Source code can be found on \url{this https URL}.</li>
</ul>

<h3>Title: GLMHA A Guided Low-rank Multi-Head Self-Attention for Efficient Image Restoration and Spectral Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Zaid Ilyas, Naveed Akhtar, David Suter, Syed Zulqarnain Gilani</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00380">https://arxiv.org/abs/2410.00380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00380">https://arxiv.org/pdf/2410.00380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00380]] GLMHA A Guided Low-rank Multi-Head Self-Attention for Efficient Image Restoration and Spectral Reconstruction(https://arxiv.org/abs/2410.00380)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Image restoration and spectral reconstruction are longstanding computer vision tasks. Currently, CNN-transformer hybrid models provide state-of-the-art performance for these tasks. The key common ingredient in the architectural designs of these models is Channel-wise Self-Attention (CSA). We first show that CSA is an overall low-rank operation. Then, we propose an instance-Guided Low-rank Multi-Head selfattention (GLMHA) to replace the CSA for a considerable computational gain while closely retaining the original model performance. Unique to the proposed GLMHA is its ability to provide computational gain for both short and long input sequences. In particular, the gain is in terms of both Floating Point Operations (FLOPs) and parameter count reduction. This is in contrast to the existing popular computational complexity reduction techniques, e.g., Linformer, Performer, and Reformer, for whom FLOPs overpower the efficient design tricks for the shorter input sequences. Moreover, parameter reduction remains unaccounted for in the existing this http URL perform an extensive evaluation for the tasks of spectral reconstruction from RGB images, spectral reconstruction from snapshot compressive imaging, motion deblurring, and image deraining by enhancing the best-performing models with our GLMHA. Our results show up to a 7.7 Giga FLOPs reduction with 370K fewer parameters required to closely retain the original performance of the best-performing models that employ CSA.</li>
</ul>

<h3>Title: Generative Precipitation Downscaling using Score-based Diffusion with Wasserstein Regularization</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Liu, James Doss-Gollin, Guha Balakrishnan, Ashok Veeraraghavan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00381">https://arxiv.org/abs/2410.00381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00381">https://arxiv.org/pdf/2410.00381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00381]] Generative Precipitation Downscaling using Score-based Diffusion with Wasserstein Regularization(https://arxiv.org/abs/2410.00381)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Understanding local risks from extreme rainfall, such as flooding, requires both long records (to sample rare events) and high-resolution products (to assess localized hazards). Unfortunately, there is a dearth of long-record and high-resolution products that can be used to understand local risk and precipitation science. In this paper, we present a novel generative diffusion model that downscales (super-resolves) globally available Climate Prediction Center (CPC) gauge-based precipitation products and ERA5 reanalysis data to generate kilometer-scale precipitation estimates. Downscaling gauge-based precipitation from 55 km to 1 km while recovering extreme rainfall signals poses significant challenges. To enforce our model (named WassDiff) to produce well-calibrated precipitation intensity values, we introduce a Wasserstein Distance Regularization (WDR) term for the score-matching training objective in the diffusion denoising process. We show that WDR greatly enhances the model's ability to capture extreme values compared to diffusion without WDR. Extensive evaluation shows that WassDiff has better reconstruction accuracy and bias scores than conventional score-based diffusion models. Case studies of extreme weather phenomena, like tropical storms and cold fronts, demonstrate WassDiff's ability to produce appropriate spatial patterns while capturing extremes. Such downscaling capability enables the generation of extensive km-scale precipitation datasets from existing historical global gauge records and current gauge measurements in areas without high-resolution radar.</li>
</ul>

<h3>Title: Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Shota Takashiro, Takeshi Kojima, Andrew Gambardella, Qi Cao, Yusuke Iwasawa, Yutaka Matsuo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00382">https://arxiv.org/abs/2410.00382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00382">https://arxiv.org/pdf/2410.00382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00382]] Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning(https://arxiv.org/abs/2410.00382)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) are applied across diverse domains, the ability to selectively unlearn specific information has become increasingly essential. For instance, LLMs are expected to provide confidential information to authorized internal users, such as employees or trusted partners, while withholding it from external users, including the general public and unauthorized entities. In response to this challenge, we propose a novel method termed ``in-context knowledge unlearning'', which enables the model to selectively forget information in test-time based on the context of the query. Our method fine-tunes pre-trained LLMs to enable prompt unlearning of target knowledge within the context, while preserving other knowledge. Experiments on the TOFU and AGE datasets using Llama2-7B/13B and Mistral-7B models show our method achieves up to 95% forgetting accuracy while retaining 80% of unrelated knowledge, significantly outperforming baselines in both in-domain and out-of-domain scenarios. Further investigation into the model's internal behavior revealed that while fine-tuned LLMs generate correct predictions in the middle layers and maintain them up to the final layer, they make the decision to forget at the last layer, i.e., ``LLMs pretend to forget''. Our findings offer valuable insights into enhancing the robustness of unlearning mechanisms in LLMs, setting a foundation for future research in the field.</li>
</ul>

<h3>Title: STGformer: Efficient Spatiotemporal Graph Transformer for Traffic Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Hongjun Wang, Jiyuan Chen, Tong Pan, Zheng Dong, Lingyu Zhang, Renhe Jiang, Xuan Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00385">https://arxiv.org/abs/2410.00385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00385">https://arxiv.org/pdf/2410.00385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00385]] STGformer: Efficient Spatiotemporal Graph Transformer for Traffic Forecasting(https://arxiv.org/abs/2410.00385)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Traffic forecasting is a cornerstone of smart city management, enabling efficient resource allocation and transportation planning. Deep learning, with its ability to capture complex nonlinear patterns in spatiotemporal (ST) data, has emerged as a powerful tool for traffic forecasting. While graph neural networks (GCNs) and transformer-based models have shown promise, their computational demands often hinder their application to real-world road networks, particularly those with large-scale spatiotemporal interactions. To address these challenges, we propose a novel spatiotemporal graph transformer (STGformer) architecture. STGformer effectively balances the strengths of GCNs and Transformers, enabling efficient modeling of both global and local traffic patterns while maintaining a manageable computational footprint. Unlike traditional approaches that require multiple attention layers, STG attention block captures high-order spatiotemporal interactions in a single layer, significantly reducing computational cost. In particular, STGformer achieves a 100x speedup and a 99.8\% reduction in GPU memory usage compared to STAEformer during batch inference on a California road graph with 8,600 sensors. We evaluate STGformer on the LargeST benchmark and demonstrate its superiority over state-of-the-art Transformer-based methods such as PDFormer and STAEformer, which underline STGformer's potential to revolutionize traffic forecasting by overcoming the computational and memory limitations of existing approaches, making it a promising foundation for future spatiotemporal modeling tasks.</li>
</ul>

<h3>Title: Seamless Augmented Reality Integration in Arthroscopy: A Pipeline for Articular Reconstruction and Guidance</h3>
<ul>
<li><strong>Authors: </strong>Hongchao Shu, Mingxu Liu, Lalithkumar Seenivasan, Suxi Gu, Ping-Cheng Ku, Jonathan Knopf, Russell Taylor, Mathias Unberath</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00386">https://arxiv.org/abs/2410.00386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00386">https://arxiv.org/pdf/2410.00386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00386]] Seamless Augmented Reality Integration in Arthroscopy: A Pipeline for Articular Reconstruction and Guidance(https://arxiv.org/abs/2410.00386)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Arthroscopy is a minimally invasive surgical procedure used to diagnose and treat joint problems. The clinical workflow of arthroscopy typically involves inserting an arthroscope into the joint through a small incision, during which surgeons navigate and operate largely by relying on their visual assessment through the arthroscope. However, the arthroscope's restricted field of view and lack of depth perception pose challenges in navigating complex articular structures and achieving surgical precision during procedures. Aiming at enhancing intraoperative awareness, we present a robust pipeline that incorporates simultaneous localization and mapping, depth estimation, and 3D Gaussian splatting to realistically reconstruct intra-articular structures solely based on monocular arthroscope video. Extending 3D reconstruction to Augmented Reality (AR) applications, our solution offers AR assistance for articular notch measurement and annotation anchoring in a human-in-the-loop manner. Compared to traditional Structure-from-Motion and Neural Radiance Field-based methods, our pipeline achieves dense 3D reconstruction and competitive rendering fidelity with explicit 3D representation in 7 minutes on average. When evaluated on four phantom datasets, our method achieves RMSE = 2.21mm reconstruction error, PSNR = 32.86 and SSIM = 0.89 on average. Because our pipeline enables AR reconstruction and guidance directly from monocular arthroscopy without any additional data and/or hardware, our solution may hold the potential for enhancing intraoperative awareness and facilitating surgical precision in arthroscopy. Our AR measurement tool achieves accuracy within 1.59 +/- 1.81mm and the AR annotation tool achieves a mIoU of 0.721.</li>
</ul>

<h3>Title: Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Bhargav Shandilya, Alexis Palmer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00387">https://arxiv.org/abs/2410.00387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00387">https://arxiv.org/pdf/2410.00387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00387]] Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation(https://arxiv.org/abs/2410.00387)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The data and compute requirements of current language modeling technology pose challenges for the processing and analysis of low-resource languages. Declarative linguistic knowledge has the potential to partially bridge this data scarcity gap by providing models with useful inductive bias in the form of language-specific rules. In this paper, we propose a retrieval augmented generation (RAG) framework backed by a large language model (LLM) to correct the output of a smaller model for the linguistic task of morphological glossing. We leverage linguistic information to make up for the lack of data and trainable parameters, while allowing for inputs from written descriptive grammars interpreted and distilled through an LLM. The results demonstrate that significant leaps in performance and efficiency are possible with the right combination of: a) linguistic inputs in the form of grammars, b) the interpretive power of LLMs, and c) the trainability of smaller token classification networks. We show that a compact, RAG-supported model is highly effective in data-scarce settings, achieving a new state-of-the-art for this task and our target languages. Our work also offers documentary linguists a more reliable and more usable tool for morphological glossing by providing well-reasoned explanations and confidence scores for each output.</li>
</ul>

<h3>Title: CusConcept: Customized Visual Concept Decomposition with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zhi Xu, Shaozhe Hao, Kai Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00398">https://arxiv.org/abs/2410.00398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00398">https://arxiv.org/pdf/2410.00398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00398]] CusConcept: Customized Visual Concept Decomposition with Diffusion Models(https://arxiv.org/abs/2410.00398)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Enabling generative models to decompose visual concepts from a single image is a complex and challenging problem. In this paper, we study a new and challenging task, customized concept decomposition, wherein the objective is to leverage diffusion models to decompose a single image and generate visual concepts from various perspectives. To address this challenge, we propose a two-stage framework, CusConcept (short for Customized Visual Concept Decomposition), to extract customized visual concept embedding vectors that can be embedded into prompts for text-to-image generation. In the first stage, CusConcept employs a vocabulary-guided concept decomposition mechanism to build vocabularies along human-specified conceptual axes. The decomposed concepts are obtained by retrieving corresponding vocabularies and learning anchor weights. In the second stage, joint concept refinement is performed to enhance the fidelity and quality of generated images. We further curate an evaluation benchmark for assessing the performance of the open-world concept decomposition task. Our approach can effectively generate high-quality images of the decomposed concepts and produce related lexical predictions as secondary outcomes. Extensive qualitative and quantitative experiments demonstrate the effectiveness of CusConcept.</li>
</ul>

<h3>Title: TikGuard: A Deep Learning Transformer-Based Solution for Detecting Unsuitable TikTok Content for Kids</h3>
<ul>
<li><strong>Authors: </strong>Mazen Balat, Mahmoud Essam Gabr, Hend Bakr, Ahmed B. Zaky</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00403">https://arxiv.org/abs/2410.00403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00403">https://arxiv.org/pdf/2410.00403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00403]] TikGuard: A Deep Learning Transformer-Based Solution for Detecting Unsuitable TikTok Content for Kids(https://arxiv.org/abs/2410.00403)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The rise of short-form videos on platforms like TikTok has brought new challenges in safeguarding young viewers from inappropriate content. Traditional moderation methods often fall short in handling the vast and rapidly changing landscape of user-generated videos, increasing the risk of children encountering harmful material. This paper introduces TikGuard, a transformer-based deep learning approach aimed at detecting and flagging content unsuitable for children on TikTok. By using a specially curated dataset, TikHarm, and leveraging advanced video classification techniques, TikGuard achieves an accuracy of 86.7%, showing a notable improvement over existing methods in similar contexts. While direct comparisons are limited by the uniqueness of the TikHarm dataset, TikGuard's performance highlights its potential in enhancing content moderation, contributing to a safer online experience for minors. This study underscores the effectiveness of transformer models in video classification and sets a foundation for future research in this area.</li>
</ul>

<h3>Title: Metric-Based Few-Shot Learning for Exercise Repetition Counting with IMU Data</h3>
<ul>
<li><strong>Authors: </strong>Yooseok Lim, Sujee Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00407">https://arxiv.org/abs/2410.00407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00407">https://arxiv.org/pdf/2410.00407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00407]] Metric-Based Few-Shot Learning for Exercise Repetition Counting with IMU Data(https://arxiv.org/abs/2410.00407)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study develops a method to automatically count exercise repetitions by analyzing IMU signals, with a focus on a universal exercise repetition counting task that counts all types of exercise movements, including novel exercises not seen during training, using a single model. A key challenge in developing such a model is handling the considerable variation in peak patterns across different types of exercises. Since peak patterns can vary significantly between different exercises as well as between individuals performing the same exercise, the model needs to learn a complex embedding space of sensor data to generalize effectively. To address this challenge, we propose a repetition counting technique utilizing a deep metric-based few-shot learning approach, designed to handle both existing and novel exercises. By redefining the counting task as a few-shot classification problem, the method is capable of detecting peak repetition patterns in exercises not seen during training. The approach employs a Siamese network with triplet loss, optimizing the embedding space to distinguish between peak and non-peak frames. The proposed framework is composed of three main phases: standard classification training, few-shot training, and fine-tuning for novel exercises, followed by post-processing to refine the final repetition counts. Evaluation results demonstrate the effectiveness of the proposed approach, showing an 86.8% probability of accurately counting ten or more repetitions within a single set across 28 different exercises. This performance highlights the model's ability to generalize across various exercise types, including those not present in the training data. Such robustness and adaptability make the system a strong candidate for real-time implementation in fitness and healthcare applications.</li>
</ul>

<h3>Title: TPN: Transferable Proto-Learning Network towards Few-shot Document-Level Relation Extraction</h3>
<ul>
<li><strong>Authors: </strong>Yu Zhang, Zhao Kang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00412">https://arxiv.org/abs/2410.00412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00412">https://arxiv.org/pdf/2410.00412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00412]] TPN: Transferable Proto-Learning Network towards Few-shot Document-Level Relation Extraction(https://arxiv.org/abs/2410.00412)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Few-shot document-level relation extraction suffers from poor performance due to the challenging cross-domain transferability of NOTA (none-of-the-above) relation representation. In this paper, we introduce a Transferable Proto-Learning Network (TPN) to address the challenging issue. It comprises three core components: Hybrid Encoder hierarchically encodes semantic content of input text combined with attention information to enhance the relation representations. As a plug-and-play module for Out-of-Domain (OOD) Detection, Transferable Proto-Learner computes NOTA prototype through an adaptive learnable block, effectively mitigating NOTA bias across various domains. Dynamic Weighting Calibrator detects relation-specific classification confidence, serving as dynamic weights to calibrate the NOTA-dominant loss function. Finally, to bolster the model's cross-domain performance, we complement it with virtual adversarial training (VAT). We conduct extensive experimental analyses on FREDo and ReFREDo, demonstrating the superiority of TPN. Compared to state-of-the-art methods, our approach achieves competitive performance with approximately half the parameter size. Data and code are available at this https URL.</li>
</ul>

<h3>Title: Semantic Parsing with Candidate Expressions for Knowledge Base Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Daehwan Nam, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00414">https://arxiv.org/abs/2410.00414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00414">https://arxiv.org/pdf/2410.00414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00414]] Semantic Parsing with Candidate Expressions for Knowledge Base Question Answering(https://arxiv.org/abs/2410.00414)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Semantic parsers convert natural language to logical forms, which can be evaluated on knowledge bases (KBs) to produce denotations. Recent semantic parsers have been developed with sequence-to-sequence (seq2seq) pre-trained language models (PLMs) or large language models, where the models treat logical forms as sequences of tokens. For syntactic and semantic validity, the semantic parsers use grammars that enable constrained decoding. However, the grammars lack the ability to utilize large information of KBs, although logical forms contain representations of KB elements, such as entities or relations. In this work, we propose a grammar augmented with candidate expressions for semantic parsing on a large KB with a seq2seq PLM. The grammar defines actions as production rules, and our semantic parser predicts actions during inference under the constraints by types and candidate expressions. We apply the grammar to knowledge base question answering, where the constraints by candidate expressions assist a semantic parser to generate valid KB elements. In experiments on two benchmarks, KQA Pro and Overnight, the constraints by candidate expressions increased the accuracy of our semantic parser, whether it was trained with strong supervision or weak supervision. Our semantic parser achieved state-of-the-art accuracies on KQA Pro and Overnight.</li>
</ul>

<h3>Title: Are LLMs Aware that Some Questions are not Open-ended?</h3>
<ul>
<li><strong>Authors: </strong>Dongjie Yang, Hai Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00423">https://arxiv.org/abs/2410.00423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00423">https://arxiv.org/pdf/2410.00423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00423]] Are LLMs Aware that Some Questions are not Open-ended?(https://arxiv.org/abs/2410.00423)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown the impressive capability of answering questions in a wide range of scenarios. However, when LLMs face different types of questions, it is worth exploring whether LLMs are aware that some questions have limited answers and need to respond more deterministically but some do not. We refer to this as question awareness of LLMs. The lack of question awareness in LLMs leads to two phenomena that LLMs are: (1) too casual to answer non-open-ended questions or (2) too boring to answer open-ended questions. In this paper, we first evaluate the question awareness in LLMs. The experimental results show that LLMs have the issues of lacking awareness of questions in certain domains, e.g. factual knowledge, resulting in hallucinations during the generation. To mitigate these, we propose a method called Question Awareness Temperature Sampling (QuATS). This method enhances the question awareness of LLMs by adaptively adjusting the output distributions based on question features. The automatic adjustment in QuATS eliminates the need for manual temperature tuning in text generation and consistently improves model performance in various benchmarks.</li>
</ul>

<h3>Title: PrivTuner with Homomorphic Encryption and LoRA: A P3EFT Scheme for Privacy-Preserving Parameter-Efficient Fine-Tuning of AI Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Yang Li, Wenhan Yu, Jun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00433">https://arxiv.org/abs/2410.00433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00433">https://arxiv.org/pdf/2410.00433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00433]] PrivTuner with Homomorphic Encryption and LoRA: A P3EFT Scheme for Privacy-Preserving Parameter-Efficient Fine-Tuning of AI Foundation Models(https://arxiv.org/abs/2410.00433)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>AI foundation models have recently demonstrated impressive capabilities across a wide range of tasks. Fine-tuning (FT) is a method of customizing a pre-trained AI foundation model by further training it on a smaller, targeted dataset. In this paper, we initiate the study of the Privacy-Preserving Parameter-Efficient FT (P3EFT) framework, which can be viewed as the intersection of Parameter-Efficient FT (PEFT) and Privacy-Preserving FT (PPFT). PEFT modifies only a small subset of the model's parameters to achieve FT (i.e., adapting a pre-trained model to a specific dataset), while PPFT uses privacy-preserving technologies to protect the confidentiality of the model during the FT process. There have been many studies on PEFT or PPFT but very few on their fusion, which motivates our work on P3EFT to achieve both parameter efficiency and model privacy. To exemplify our P3EFT, we present the PrivTuner scheme, which incorporates Fully Homomorphic Encryption (FHE) enabled privacy protection into LoRA (short for ``Low-Rank Adapter''). Intuitively speaking, PrivTuner allows the model owner and the external data owners to collaboratively implement PEFT with encrypted data. After describing PrivTuner in detail, we further investigate its energy consumption and privacy protection. Then, we consider a PrivTuner system over wireless communications and formulate a joint optimization problem to adaptively minimize energy while maximizing privacy protection, with the optimization variables including FDMA bandwidth allocation, wireless transmission power, computational resource allocation, and privacy protection. A resource allocation algorithm is devised to solve the problem. Experiments demonstrate that our algorithm can significantly reduce energy consumption while adapting to different privacy requirements.</li>
</ul>

<h3>Title: Scene Graph Disentanglement and Composition for Generalizable Complex Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Yunnan Wang, Ziqiang Li, Zequn Zhang, Wenyao Zhang, Baao Xie, Xihui Liu, Wenjun Zeng, Xin Jin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00447">https://arxiv.org/abs/2410.00447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00447">https://arxiv.org/pdf/2410.00447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00447]] Scene Graph Disentanglement and Composition for Generalizable Complex Image Generation(https://arxiv.org/abs/2410.00447)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>There has been exciting progress in generating images from natural language or layout conditions. However, these methods struggle to faithfully reproduce complex scenes due to the insufficient modeling of multiple objects and their relationships. To address this issue, we leverage the scene graph, a powerful structured representation, for complex image generation. Different from the previous works that directly use scene graphs for generation, we employ the generative capabilities of variational autoencoders and diffusion models in a generalizable manner, compositing diverse disentangled visual clues from scene graphs. Specifically, we first propose a Semantics-Layout Variational AutoEncoder (SL-VAE) to jointly derive (layouts, semantics) from the input scene graph, which allows a more diverse and reasonable generation in a one-to-many mapping. We then develop a Compositional Masked Attention (CMA) integrated with a diffusion model, incorporating (layouts, semantics) with fine-grained attributes as generation guidance. To further achieve graph manipulation while keeping the visual content consistent, we introduce a Multi-Layered Sampler (MLS) for an "isolated" image editing effect. Extensive experiments demonstrate that our method outperforms recent competitors based on text, layout, or scene graph, in terms of generation rationality and controllability.</li>
</ul>

<h3>Title: Adversarial Suffixes May Be Features Too!</h3>
<ul>
<li><strong>Authors: </strong>Wei Zhao, Zhe Li, Yige Li, Jun Sun</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00451">https://arxiv.org/abs/2410.00451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00451">https://arxiv.org/pdf/2410.00451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00451]] Adversarial Suffixes May Be Features Too!(https://arxiv.org/abs/2410.00451)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Despite significant ongoing efforts in safety alignment, large language models (LLMs) such as GPT-4 and LLaMA 3 remain vulnerable to jailbreak attacks that can induce harmful behaviors, including those triggered by adversarial suffixes. Building on prior research, we hypothesize that these adversarial suffixes are not mere bugs but may represent features that can dominate the LLM's behavior. To evaluate this hypothesis, we conduct several experiments. First, we demonstrate that benign features can be effectively made to function as adversarial suffixes, i.e., we develop a feature extraction method to extract sample-agnostic features from benign dataset in the form of suffixes and show that these suffixes may effectively compromise safety alignment. Second, we show that adversarial suffixes generated from jailbreak attacks may contain meaningful features, i.e., appending the same suffix to different prompts results in responses exhibiting specific characteristics. Third, we show that such benign-yet-safety-compromising features can be easily introduced through fine-tuning using only benign datasets, i.e., even in the absence of harmful content. This highlights the critical risk posed by dominating benign features in the training data and calls for further research to reinforce LLM safety alignment. Our code and data is available at \url{this https URL}.</li>
</ul>

<h3>Title: A Scheduling-Aware Defense Against Prefetching-Based Side-Channel Attacks</h3>
<ul>
<li><strong>Authors: </strong>Till Schlüter, Nils Ole Tippenhauer</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00452">https://arxiv.org/abs/2410.00452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00452">https://arxiv.org/pdf/2410.00452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00452]] A Scheduling-Aware Defense Against Prefetching-Based Side-Channel Attacks(https://arxiv.org/abs/2410.00452)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack</a></li>
<li><strong>Abstract: </strong>Modern computer processors use microarchitectural optimization mechanisms to improve performance. As a downside, such optimizations are prone to introducing side-channel vulnerabilities. Speculative loading of memory, called prefetching, is common in real-world CPUs and may cause such side-channel vulnerabilities: Prior work has shown that it can be exploited to bypass process isolation and leak secrets, such as keys used in RSA, AES, and ECDH implementations. However, to this date, no effective and efficient countermeasure has been presented that secures software on systems with affected prefetchers. In this work, we answer the question: How can a process defend against prefetch-based side channels? We first systematize prefetching-based side-channel vulnerabilities presented in academic literature so far. Next, we design and implement PreFence, a scheduling-aware defense against these side channels that allows processes to disable the prefetcher temporarily during security-critical operations. We implement our countermeasure for an x86_64 and an ARM processor; it can be adapted to any platform that allows to disable the prefetcher. We evaluate our defense and find that our solution reliably stops prefetch leakage. Our countermeasure causes negligible performance impact while no security-relevant code is executed, and its worst case performance is comparable to completely turning off the prefetcher. The expected average performance impact depends on the security-relevant code in the application and can be negligible as we demonstrate with a simple web server application. We expect our countermeasure could widely be integrated in commodity OS, and even be extended to signal generally security-relevant code to the kernel to allow coordinated application of countermeasures.</li>
</ul>

<h3>Title: UniAdapt: A Universal Adapter for Knowledge Calibration</h3>
<ul>
<li><strong>Authors: </strong>Tai D. Nguyen, Long H. Pham, Jun Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00454">https://arxiv.org/abs/2410.00454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00454">https://arxiv.org/pdf/2410.00454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00454]] UniAdapt: A Universal Adapter for Knowledge Calibration(https://arxiv.org/abs/2410.00454)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) require frequent updates to correct errors and keep pace with continuously evolving knowledge in a timely and effective manner. Recent research in it model editing has highlighted the challenges in balancing generalization and locality, especially in the context of lifelong model editing. We discover that inserting knowledge directly into the model often causes conflicts and potentially disrupts other unrelated pre-trained knowledge. To address this problem, we introduce UniAdapt, a universal adapter for knowledge calibration. Inspired by the Mixture of Experts architecture and Retrieval-Augmented Generation, UniAdapt is designed with a vector-assisted router that is responsible for routing inputs to appropriate experts. The router maintains a vector store, including multiple shards, to construct routing vectors based on semantic similarity search results. UniAdapt is fully model-agnostic and designed for seamless plug-and-play integration. Experimental results show that UniAdapt outperforms existing lifelong model editors and achieves exceptional results in most metrics.</li>
</ul>

<h3>Title: Enabling Synergistic Full-Body Control in Prompt-Based Co-Speech Motion Generation</h3>
<ul>
<li><strong>Authors: </strong>Bohong Chen, Yumeng Li, Yao-Xiang Ding, Tianjia Shao, Kun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00464">https://arxiv.org/abs/2410.00464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00464">https://arxiv.org/pdf/2410.00464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00464]] Enabling Synergistic Full-Body Control in Prompt-Based Co-Speech Motion Generation(https://arxiv.org/abs/2410.00464)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Current co-speech motion generation approaches usually focus on upper body gestures following speech contents only, while lacking supporting the elaborate control of synergistic full-body motion based on text prompts, such as talking while walking. The major challenges lie in 1) the existing speech-to-motion datasets only involve highly limited full-body motions, making a wide range of common human activities out of training distribution; 2) these datasets also lack annotated user prompts. To address these challenges, we propose SynTalker, which utilizes the off-the-shelf text-to-motion dataset as an auxiliary for supplementing the missing full-body motion and prompts. The core technical contributions are two-fold. One is the multi-stage training process which obtains an aligned embedding space of motion, speech, and prompts despite the significant distributional mismatch in motion between speech-to-motion and text-to-motion datasets. Another is the diffusion-based conditional inference process, which utilizes the separate-then-combine strategy to realize fine-grained control of local body parts. Extensive experiments are conducted to verify that our approach supports precise and flexible control of synergistic full-body motion generation based on both speeches and user prompts, which is beyond the ability of existing approaches.</li>
</ul>

<h3>Title: Deep Multimodal Fusion for Semantic Segmentation of Remote Sensing Earth Observation Data</h3>
<ul>
<li><strong>Authors: </strong>Ivica Dimitrovski, Vlatko Spasev, Ivan Kitanovski</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00469">https://arxiv.org/abs/2410.00469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00469">https://arxiv.org/pdf/2410.00469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00469]] Deep Multimodal Fusion for Semantic Segmentation of Remote Sensing Earth Observation Data(https://arxiv.org/abs/2410.00469)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate semantic segmentation of remote sensing imagery is critical for various Earth observation applications, such as land cover mapping, urban planning, and environmental monitoring. However, individual data sources often present limitations for this task. Very High Resolution (VHR) aerial imagery provides rich spatial details but cannot capture temporal information about land cover changes. Conversely, Satellite Image Time Series (SITS) capture temporal dynamics, such as seasonal variations in vegetation, but with limited spatial resolution, making it difficult to distinguish fine-scale objects. This paper proposes a late fusion deep learning model (LF-DLM) for semantic segmentation that leverages the complementary strengths of both VHR aerial imagery and SITS. The proposed model consists of two independent deep learning branches. One branch integrates detailed textures from aerial imagery captured by UNetFormer with a Multi-Axis Vision Transformer (MaxViT) backbone. The other branch captures complex spatio-temporal dynamics from the Sentinel-2 satellite image time series using a U-Net with Temporal Attention Encoder (U-TAE). This approach leads to state-of-the-art results on the FLAIR dataset, a large-scale benchmark for land cover segmentation using multi-source optical imagery. The findings highlight the importance of multi-modality fusion in improving the accuracy and robustness of semantic segmentation in remote sensing applications.</li>
</ul>

<h3>Title: ViDAS: Vision-based Danger Assessment and Scoring</h3>
<ul>
<li><strong>Authors: </strong>Pranav Gupta, Advith Krishnan, Naman Nanda, Ananth Eswar, Deeksha Agarwal, Pratham Gohil, Pratyush Goel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00477">https://arxiv.org/abs/2410.00477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00477">https://arxiv.org/pdf/2410.00477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00477]] ViDAS: Vision-based Danger Assessment and Scoring(https://arxiv.org/abs/2410.00477)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a novel dataset aimed at advancing danger analysis and assessment by addressing the challenge of quantifying danger in video content and identifying how human-like a Large Language Model (LLM) evaluator is for the same. This is achieved by compiling a collection of 100 YouTube videos featuring various events. Each video is annotated by human participants who provided danger ratings on a scale from 0 (no danger to humans) to 10 (life-threatening), with precise timestamps indicating moments of heightened danger. Additionally, we leverage LLMs to independently assess the danger levels in these videos using video summaries. We introduce Mean Squared Error (MSE) scores for multimodal meta-evaluation of the alignment between human and LLM danger assessments. Our dataset not only contributes a new resource for danger assessment in video content but also demonstrates the potential of LLMs in achieving human-like evaluations.</li>
</ul>

<h3>Title: MCGM: Mask Conditional Text-to-Image Generative Model</h3>
<ul>
<li><strong>Authors: </strong>Rami Skaik, Leonardo Rossi, Tomaso Fontanini, Andrea Prati</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00483">https://arxiv.org/abs/2410.00483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00483">https://arxiv.org/pdf/2410.00483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00483]] MCGM: Mask Conditional Text-to-Image Generative Model(https://arxiv.org/abs/2410.00483)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in generative models have revolutionized the field of artificial intelligence, enabling the creation of highly-realistic and detailed images. In this study, we propose a novel Mask Conditional Text-to-Image Generative Model (MCGM) that leverages the power of conditional diffusion models to generate pictures with specific poses. Our model builds upon the success of the Break-a-scene [1] model in generating new scenes using a single image with multiple subjects and incorporates a mask embedding injection that allows the conditioning of the generation process. By introducing this additional level of control, MCGM offers a flexible and intuitive approach for generating specific poses for one or more subjects learned from a single image, empowering users to influence the output based on their requirements. Through extensive experimentation and evaluation, we demonstrate the effectiveness of our proposed model in generating high-quality images that meet predefined mask conditions and improving the current Break-a-scene generative model.</li>
</ul>

<h3>Title: A Hitchhikers Guide to Fine-Grained Face Forgery Detection Using Common Sense Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Niki Maria Foteinopoulou, Enjie Ghorbel, Djamila Aouada</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00485">https://arxiv.org/abs/2410.00485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00485">https://arxiv.org/pdf/2410.00485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00485]] A Hitchhikers Guide to Fine-Grained Face Forgery Detection Using Common Sense Reasoning(https://arxiv.org/abs/2410.00485)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, explainability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Explainability in artificial intelligence is crucial for restoring trust, particularly in areas like face forgery detection, where viewers often struggle to distinguish between real and fabricated content. Vision and Large Language Models (VLLM) bridge computer vision and natural language, offering numerous applications driven by strong common-sense reasoning. Despite their success in various tasks, the potential of vision and language remains underexplored in face forgery detection, where they hold promise for enhancing explainability by leveraging the intrinsic reasoning capabilities of language to analyse fine-grained manipulation areas. As such, there is a need for a methodology that converts face forgery detection to a Visual Question Answering (VQA) task to systematically and fairly evaluate these capabilities. Previous efforts for unified benchmarks in deepfake detection have focused on the simpler binary task, overlooking evaluation protocols for fine-grained detection and text-generative models. We propose a multi-staged approach that diverges from the traditional binary decision paradigm to address this gap. In the first stage, we assess the models' performance on the binary task and their sensitivity to given instructions using several prompts. In the second stage, we delve deeper into fine-grained detection by identifying areas of manipulation in a multiple-choice VQA setting. In the third stage, we convert the fine-grained detection to an open-ended question and compare several matching strategies for the multi-label classification task. Finally, we qualitatively evaluate the fine-grained responses of the VLLMs included in the benchmark. We apply our benchmark to several popular models, providing a detailed comparison of binary, multiple-choice, and open-ended VQA evaluation across seven datasets. \url{this https URL}</li>
</ul>

<h3>Title: Self-Updatable Large Language Models with Parameter Integration</h3>
<ul>
<li><strong>Authors: </strong>Yu Wang, Xinshuang Liu, Xiusi Chen, Sean O'Brien, Junda Wu, Julian McAuley</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00487">https://arxiv.org/abs/2410.00487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00487">https://arxiv.org/pdf/2410.00487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00487]] Self-Updatable Large Language Models with Parameter Integration(https://arxiv.org/abs/2410.00487)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite significant advancements in large language models (LLMs), the rapid and frequent integration of small-scale experiences, such as interactions with surrounding objects, remains a substantial challenge. Two critical factors in assimilating these experiences are (1) Efficacy: the ability to accurately remember recent events; (2) Retention: the capacity to recall long-past experiences. Current methods either embed experiences within model parameters using continual learning, model editing, or knowledge distillation techniques, which often struggle with rapid updates and complex interactions, or rely on external storage to achieve long-term retention, thereby increasing storage requirements. In this paper, we propose SELF-PARAM (Self-Updatable Large Language Models with Parameter Integration). SELF-PARAM requires no extra parameters while ensuring near-optimal efficacy and long-term retention. Our method employs a training objective that minimizes the Kullback-Leibler (KL) divergence between the predictions of an original model (with access to contextual information) and a target model (without such access). By generating diverse question-answer pairs related to the knowledge and minimizing the KL divergence across this dataset, we update the target model to internalize the knowledge seamlessly within its parameters. Evaluations on question-answering and conversational recommendation tasks demonstrate that SELF-PARAM significantly outperforms existing methods, even when accounting for non-zero storage requirements. This advancement paves the way for more efficient and scalable integration of experiences in large language models by embedding knowledge directly into model parameters.</li>
</ul>

<h3>Title: Drone Stereo Vision for Radiata Pine Branch Detection and Distance Measurement: Utilizing Deep Learning and YOLO Integration</h3>
<ul>
<li><strong>Authors: </strong>Yida Lin, Bing Xue, Mengjie Zhang, Sam Schofield, Richard Green</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00503">https://arxiv.org/abs/2410.00503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00503">https://arxiv.org/pdf/2410.00503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00503]] Drone Stereo Vision for Radiata Pine Branch Detection and Distance Measurement: Utilizing Deep Learning and YOLO Integration(https://arxiv.org/abs/2410.00503)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This research focuses on the development of a drone equipped with pruning tools and a stereo vision camera to accurately detect and measure the spatial positions of tree branches. YOLO is employed for branch segmentation, while two depth estimation approaches, monocular and stereo, are investigated. In comparison to SGBM, deep learning techniques produce more refined and accurate depth maps. In the absence of ground-truth data, a fine-tuning process using deep neural networks is applied to approximate optimal depth values. This methodology facilitates precise branch detection and distance measurement, addressing critical challenges in the automation of pruning operations. The results demonstrate notable advancements in both accuracy and efficiency, underscoring the potential of deep learning to drive innovation and enhance automation in the agricultural sector.</li>
</ul>

<h3>Title: FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization</h3>
<ul>
<li><strong>Authors: </strong>Mingye Zhu, Yi Liu, Quan Wang, Junbo Guo, Zhendong Mao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00508">https://arxiv.org/abs/2410.00508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00508">https://arxiv.org/pdf/2410.00508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00508]] FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization(https://arxiv.org/abs/2410.00508)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent breakthroughs in preference alignment have significantly improved Large Language Models' ability to generate texts that align with human preferences and values. However, current alignment metrics typically emphasize the post-hoc overall improvement, while overlooking a critical aspect: regression, which refers to the backsliding on previously correctly-handled data after updates. This potential pitfall may arise from excessive fine-tuning on already well-aligned data, which subsequently leads to over-alignment and degeneration. To address this challenge, we propose FlipGuard, a constrained optimization approach to detect and mitigate update regression with focal attention. Specifically, FlipGuard identifies performance degradation using a customized reward characterization and strategically enforces a constraint to encourage conditional congruence with the pre-aligned model during training. Comprehensive experiments demonstrate that FlipGuard effectively alleviates update regression while demonstrating excellent overall performance, with the added benefit of knowledge preservation while aligning preferences.</li>
</ul>

<h3>Title: Advancing RVFL networks: Robust classification with the HawkEye loss function</h3>
<ul>
<li><strong>Authors: </strong>Mushir Akhtar, M. Tanveer, Mohd. Arshad</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00510">https://arxiv.org/abs/2410.00510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00510">https://arxiv.org/pdf/2410.00510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00510]] Advancing RVFL networks: Robust classification with the HawkEye loss function(https://arxiv.org/abs/2410.00510)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Random vector functional link (RVFL), a variant of single-layer feedforward neural network (SLFN), has garnered significant attention due to its lower computational cost and robustness to overfitting. Despite its advantages, the RVFL network's reliance on the square error loss function makes it highly sensitive to outliers and noise, leading to degraded model performance in real-world applications. To remedy it, we propose the incorporation of the HawkEye loss (H-loss) function into the RVFL framework. The H-loss function features nice mathematical properties, including smoothness and boundedness, while simultaneously incorporating an insensitive zone. Each characteristic brings its own advantages: 1) Boundedness limits the impact of extreme errors, enhancing robustness against outliers; 2) Smoothness facilitates the use of gradient-based optimization algorithms, ensuring stable and efficient convergence; and 3) The insensitive zone mitigates the effect of minor discrepancies and noise. Leveraging the H-loss function, we embed it into the RVFL framework and develop a novel robust RVFL model termed H-RVFL. Notably, this work addresses a significant gap, as no bounded loss function has been incorporated into RVFL to date. The non-convex optimization of the proposed H-RVFL is effectively addressed by the Nesterov accelerated gradient (NAG) algorithm, whose computational complexity is also discussed. The proposed H-RVFL model's effectiveness is validated through extensive experiments on $40$ benchmark datasets from UCI and KEEL repositories, with and without label noise. The results highlight significant improvements in robustness and efficiency, establishing the H-RVFL model as a powerful tool for applications in noisy and outlier-prone environments.</li>
</ul>

<h3>Title: Exploring the Learning Capabilities of Language Models using LEVERWORLDS</h3>
<ul>
<li><strong>Authors: </strong>Eitan Wagner, Amir Feder, Omri Abend</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00519">https://arxiv.org/abs/2410.00519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00519">https://arxiv.org/pdf/2410.00519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00519]] Exploring the Learning Capabilities of Language Models using LEVERWORLDS(https://arxiv.org/abs/2410.00519)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Learning a model of a stochastic setting often involves learning both general structure rules and specific properties of the instance. This paper investigates the interplay between learning the general and the specific in various learning methods, with emphasis on sample efficiency. We design a framework called {\sc LeverWorlds}, which allows the generation of simple physics-inspired worlds that follow a similar generative process with different distributions, and their instances can be expressed in natural language. These worlds allow for controlled experiments to assess the sample complexity of different learning methods. We experiment with classic learning algorithms as well as Transformer language models, both with fine-tuning and In-Context Learning (ICL). Our general finding is that (1) Transformers generally succeed in the task; but (2) they are considerably less sample efficient than classic methods that make stronger assumptions about the structure, such as Maximum Likelihood Estimation and Logistic Regression. This finding is in tension with the recent tendency to use Transformers as general-purpose estimators. We propose an approach that leverages the ICL capabilities of contemporary language models to apply simple algorithms for this type of data. Our experiments show that models currently struggle with the task but show promising potential.</li>
</ul>

<h3>Title: Deep Model Interpretation with Limited Data : A Coreset-based Approach</h3>
<ul>
<li><strong>Authors: </strong>Hamed Behzadi-Khormouji, José Oramas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00524">https://arxiv.org/abs/2410.00524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00524">https://arxiv.org/pdf/2410.00524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00524]] Deep Model Interpretation with Limited Data : A Coreset-based Approach(https://arxiv.org/abs/2410.00524)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Model Interpretation aims at the extraction of insights from the internals of a trained model. A common approach to address this task is the characterization of relevant features internally encoded in the model that are critical for its proper operation. Despite recent progress of these methods, they come with the weakness of being computationally expensive due to the dense evaluation of datasets that they require. As a consequence, research on the design of these methods have focused on smaller data subsets which may led to reduced insights. To address these computational costs, we propose a coreset-based interpretation framework that utilizes coreset selection methods to sample a representative subset of the large dataset for the interpretation task. Towards this goal, we propose a similarity-based evaluation protocol to assess the robustness of model interpretation methods towards the amount data they take as input. Experiments considering several interpretation methods, DNN models, and coreset selection methods show the effectiveness of the proposed framework.</li>
</ul>

<h3>Title: Benchmarking Large Language Models for Conversational Question Answering in Multi-instructional Documents</h3>
<ul>
<li><strong>Authors: </strong>Shiwei Wu, Chen Zhang, Yan Gao, Qimeng Wang, Tong Xu, Yao Hu, Enhong Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00526">https://arxiv.org/abs/2410.00526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00526">https://arxiv.org/pdf/2410.00526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00526]] Benchmarking Large Language Models for Conversational Question Answering in Multi-instructional Documents(https://arxiv.org/abs/2410.00526)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instructional documents are rich sources of knowledge for completing various tasks, yet their unique challenges in conversational question answering (CQA) have not been thoroughly explored. Existing benchmarks have primarily focused on basic factual question-answering from single narrative documents, making them inadequate for assessing a model`s ability to comprehend complex real-world instructional documents and provide accurate step-by-step guidance in daily life. To bridge this gap, we present InsCoQA, a novel benchmark tailored for evaluating large language models (LLMs) in the context of CQA with instructional documents. Sourced from extensive, encyclopedia-style instructional content, InsCoQA assesses models on their ability to retrieve, interpret, and accurately summarize procedural guidance from multiple documents, reflecting the intricate and multi-faceted nature of real-world instructional tasks. Additionally, to comprehensively assess state-of-the-art LLMs on the InsCoQA benchmark, we propose InsEval, an LLM-assisted evaluator that measures the integrity and accuracy of generated responses and procedural instructions.</li>
</ul>

<h3>Title: Differentially Private Active Learning: Balancing Effective Data Selection and Privacy</h3>
<ul>
<li><strong>Authors: </strong>Kristian Schwethelm, Johannes Kaiser, Jonas Kuntzer, Mehmet Yigitsoy, Daniel Rueckert, Georgios Kaissis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00542">https://arxiv.org/abs/2410.00542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00542">https://arxiv.org/pdf/2410.00542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00542]] Differentially Private Active Learning: Balancing Effective Data Selection and Privacy(https://arxiv.org/abs/2410.00542)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Active learning (AL) is a widely used technique for optimizing data labeling in machine learning by iteratively selecting, labeling, and training on the most informative data. However, its integration with formal privacy-preserving methods, particularly differential privacy (DP), remains largely underexplored. While some works have explored differentially private AL for specialized scenarios like online learning, the fundamental challenge of combining AL with DP in standard learning settings has remained unaddressed, severely limiting AL's applicability in privacy-sensitive domains. This work addresses this gap by introducing differentially private active learning (DP-AL) for standard learning settings. We demonstrate that naively integrating DP-SGD training into AL presents substantial challenges in privacy budget allocation and data utilization. To overcome these challenges, we propose step amplification, which leverages individual sampling probabilities in batch creation to maximize data point participation in training steps, thus optimizing data utilization. Additionally, we investigate the effectiveness of various acquisition functions for data selection under privacy constraints, revealing that many commonly used functions become impractical. Our experiments on vision and natural language processing tasks show that DP-AL can improve performance for specific datasets and model architectures. However, our findings also highlight the limitations of AL in privacy-constrained environments, emphasizing the trade-offs between privacy, model accuracy, and data selection accuracy.</li>
</ul>

<h3>Title: AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Ziyang Luo, Xin Li, Hongzhan Lin, Jing Ma, Lidong Bing</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00558">https://arxiv.org/abs/2410.00558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00558">https://arxiv.org/pdf/2410.00558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00558]] AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation(https://arxiv.org/abs/2410.00558)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The impressive performance of proprietary LLMs like GPT4 in code generation has led to a trend to replicate these capabilities in open-source models through knowledge distillation (e.g. Code Evol-Instruct). However, these efforts often neglect the crucial aspect of response quality, relying heavily on teacher models for direct response distillation. This paradigm, especially for complex instructions, can degrade the quality of synthesized data, compromising the knowledge distillation process. To this end, our study introduces the Adaptive Modular Response Evolution (AMR-Evol) framework, which employs a two-stage process to refine response distillation. The first stage, modular decomposition, breaks down the direct response into more manageable sub-modules. The second stage, adaptive response evolution, automatically evolves the response with the related function modules. Our experiments with three popular code benchmarks (HumanEval, MBPP, and EvalPlus) attest to the superiority of the AMR-Evol framework over baseline response distillation methods. By comparing with the open-source Code LLMs trained on a similar scale of data, we observed performance enhancements: more than +3.0 points on HumanEval-Plus and +1.0 points on MBPP-Plus, which underscores the effectiveness of our framework. Our codes are available at this https URL.</li>
</ul>

<h3>Title: Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Jie Cheng, Ruixi Qiao, Gang Xiong, Qinghai Miao, Yingwei Ma, Binhua Li, Yongbin Li, Yisheng Lv</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00564">https://arxiv.org/abs/2410.00564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00564">https://arxiv.org/pdf/2410.00564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00564]] Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining(https://arxiv.org/abs/2410.00564)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>A significant aspiration of offline reinforcement learning (RL) is to develop a generalist agent with high capabilities from large and heterogeneous datasets. However, prior approaches that scale offline RL either rely heavily on expert trajectories or struggle to generalize to diverse unseen tasks. Inspired by the excellent generalization of world model in conditional video generation, we explore the potential of image observation-based world model for scaling offline RL and enhancing generalization on novel tasks. In this paper, we introduce JOWA: Jointly-Optimized World-Action model, an offline model-based RL agent pretrained on multiple Atari games to learn general-purpose representation and decision-making ability. Our method jointly optimizes a world-action model through shared transformer backbone, which stabilize temporal difference learning with large models during pretraining. Moreover, we propose an provably efficient and parallelizable planning algorithm to compensate for the Q-value estimation error and thus search out better policies. Experimental results indicate that our largest agent, with 150 million parameters, achieves 78.9% human-level performance on pretrained games using only 10% subsampled offline data, outperforming existing state-of-the-art large-scale offline RL baselines by 31.6% on averange. Furthermore, JOWA scales favorably with model capacity and can sample-efficiently transfer to novel games using only 5k offline fine-tuning data corresponding to about 4 trajectories per game, which demonstrates superior generalization of JOWA. We will release codes at this https URL.</li>
</ul>

<h3>Title: Deep activity propagation via weight initialization in spiking neural networks</h3>
<ul>
<li><strong>Authors: </strong>Aurora Micheli, Olaf Booij, Jan van Gemert, Nergis Tömen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00580">https://arxiv.org/abs/2410.00580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00580">https://arxiv.org/pdf/2410.00580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00580]] Deep activity propagation via weight initialization in spiking neural networks(https://arxiv.org/abs/2410.00580)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spiking Neural Networks (SNNs) and neuromorphic computing offer bio-inspired advantages such as sparsity and ultra-low power consumption, providing a promising alternative to conventional networks. However, training deep SNNs from scratch remains a challenge, as SNNs process and transmit information by quantizing the real-valued membrane potentials into binary spikes. This can lead to information loss and vanishing spikes in deeper layers, impeding effective training. While weight initialization is known to be critical for training deep neural networks, what constitutes an effective initial state for a deep SNN is not well-understood. Existing weight initialization methods designed for conventional networks (ANNs) are often applied to SNNs without accounting for their distinct computational properties. In this work we derive an optimal weight initialization method specifically tailored for SNNs, taking into account the quantization operation. We show theoretically that, unlike standard approaches, this method enables the propagation of activity in deep SNNs without loss of spikes. We demonstrate this behavior in numerical simulations of SNNs with up to 100 layers across multiple time steps. We present an in-depth analysis of the numerical conditions, regarding layer width and neuron hyperparameters, which are necessary to accurately apply our theoretical findings. Furthermore, our experiments on MNIST demonstrate higher accuracy and faster convergence when using the proposed weight initialization scheme. Finally, we show that the newly introduced weight initialization is robust against variations in several network and neuron hyperparameters.</li>
</ul>

<h3>Title: Can We Remove the Ground? Obstacle-aware Point Cloud Compression for Remote Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Pengxi Zeng, Alberto Presta, Jonah Reinis, Dinesh Bharadia, Hang Qiu, Pamela Cosman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00582">https://arxiv.org/abs/2410.00582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00582">https://arxiv.org/pdf/2410.00582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00582]] Can We Remove the Ground? Obstacle-aware Point Cloud Compression for Remote Object Detection(https://arxiv.org/abs/2410.00582)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Efficient point cloud (PC) compression is crucial for streaming applications, such as augmented reality and cooperative perception. Classic PC compression techniques encode all the points in a frame. Tailoring compression towards perception tasks at the receiver side, we ask the question, "Can we remove the ground points during transmission without sacrificing the detection performance?" Our study reveals a strong dependency on the ground from state-of-the-art (SOTA) 3D object detection models, especially on those points below and around the object. In this work, we propose a lightweight obstacle-aware Pillar-based Ground Removal (PGR) algorithm. PGR filters out ground points that do not provide context to object recognition, significantly improving compression ratio without sacrificing the receiver side perception performance. Not using heavy object detection or semantic segmentation models, PGR is light-weight, highly parallelizable, and effective. Our evaluations on KITTI and Waymo Open Dataset show that SOTA detection models work equally well with PGR removing 20-30% of the points, with a speeding of 86 FPS.</li>
</ul>

<h3>Title: GERA: Geometric Embedding for Efficient Point Registration Analysis</h3>
<ul>
<li><strong>Authors: </strong>Geng Li, Haozhi Cao, Mingyang Liu, Shenghai Yuan, Jianfei Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00589">https://arxiv.org/abs/2410.00589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00589">https://arxiv.org/pdf/2410.00589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00589]] GERA: Geometric Embedding for Efficient Point Registration Analysis(https://arxiv.org/abs/2410.00589)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Point cloud registration aims to provide estimated transformations to align point clouds, which plays a crucial role in pose estimation of various navigation systems, such as surgical guidance systems and autonomous vehicles. Despite the impressive performance of recent models on benchmark datasets, many rely on complex modules like KPConv and Transformers, which impose significant computational and memory demands. These requirements hinder their practical application, particularly in resource-constrained environments such as mobile robotics. In this paper, we propose a novel point cloud registration network that leverages a pure MLP architecture, constructing geometric information offline. This approach eliminates the computational and memory burdens associated with traditional complex feature extractors and significantly reduces inference time and resource consumption. Our method is the first to replace 3D coordinate inputs with offline-constructed geometric encoding, improving generalization and stability, as demonstrated by Maximum Mean Discrepancy (MMD) comparisons. This efficient and accurate geometric representation marks a significant advancement in point cloud analysis, particularly for applications requiring fast and reliability.</li>
</ul>

<h3>Title: Style-Specific Neurons for Steering LLMs in Text Style Transfer</h3>
<ul>
<li><strong>Authors: </strong>Wen Lai, Viktor Hangya, Alexander Fraser</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00593">https://arxiv.org/abs/2410.00593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00593">https://arxiv.org/pdf/2410.00593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00593]] Style-Specific Neurons for Steering LLMs in Text Style Transfer(https://arxiv.org/abs/2410.00593)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Text style transfer (TST) aims to modify the style of a text without altering its original meaning. Large language models (LLMs) demonstrate superior performance across multiple tasks, including TST. However, in zero-shot setups, they tend to directly copy a significant portion of the input text to the output without effectively changing its style. To enhance the stylistic variety and fluency of the text, we present sNeuron-TST, a novel approach for steering LLMs using style-specific neurons in TST. Specifically, we identify neurons associated with the source and target styles and deactivate source-style-only neurons to give target-style words a higher probability, aiming to enhance the stylistic diversity of the generated text. However, we find that this deactivation negatively impacts the fluency of the generated text, which we address by proposing an improved contrastive decoding method that accounts for rapid token probability shifts across layers caused by deactivated source-style neurons. Empirical experiments demonstrate the effectiveness of the proposed method on six benchmarks, encompassing formality, toxicity, politics, politeness, authorship, and sentiment.</li>
</ul>

<h3>Title: Detecci\'on Autom\'atica de Patolog\'ias en Notas Cl\'inicas en Espa\~nol Combinando Modelos de Lenguaje y Ontolog\'ias M\'edicos</h3>
<ul>
<li><strong>Authors: </strong>Léon-Paul Schaub Torre, Pelayo Quirós, Helena García Mieres</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00616">https://arxiv.org/abs/2410.00616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00616">https://arxiv.org/pdf/2410.00616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00616]] Detecci\'on Autom\'atica de Patolog\'ias en Notas Cl\'inicas en Espa\~nol Combinando Modelos de Lenguaje y Ontolog\'ias M\'edicos(https://arxiv.org/abs/2410.00616)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper we present a hybrid method for the automatic detection of dermatological pathologies in medical reports. We use a large language model combined with medical ontologies to predict, given a first appointment or follow-up medical report, the pathology a person may suffer from. The results show that teaching the model to learn the type, severity and location on the body of a dermatological pathology as well as in which order it has to learn these three features significantly increases its accuracy. The article presents the demonstration of state-of-the-art results for classification of medical texts with a precision of 0.84, micro and macro F1-score of 0.82 and 0.75, and makes both the method and the dataset used available to the community. -- En este artículo presentamos un método híbrido para la detección automática de patologías dermatológicas en informes médicos. Usamos un modelo de lenguaje amplio en español combinado con ontologías médicas para predecir, dado un informe médico de primera cita o de seguimiento, la patología del paciente. Los resultados muestran que el tipo, la gravedad y el sitio en el cuerpo de una patología dermatológica, así como en qué orden tiene un modelo que aprender esas tres características, aumentan su precisión. El artículo presenta la demostración de resultados comparables al estado del arte de clasificación de textos médicos con una precisión de 0.84, micro y macro F1-score de 0.82 y 0.75, y deja a disposición de la comunidad tanto el método como el conjunto de datos utilizado.</li>
</ul>

<h3>Title: An Illumination-Robust Feature Extractor Augmented by Relightable 3D Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Shunyi Zhao, Zehuan Yu, Zuxin Fan, Zhihao Zhou, Lecheng Ruan, Qining Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00629">https://arxiv.org/abs/2410.00629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00629">https://arxiv.org/pdf/2410.00629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00629]] An Illumination-Robust Feature Extractor Augmented by Relightable 3D Reconstruction(https://arxiv.org/abs/2410.00629)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Visual features, whose description often relies on the local intensity and gradient direction, have found wide applications in robot navigation and localization in recent years. However, the extraction of visual features is usually disturbed by the variation of illumination conditions, making it challenging for real-world applications. Previous works have addressed this issue by establishing datasets with variations in illumination conditions, but can be costly and time-consuming. This paper proposes a design procedure for an illumination-robust feature extractor, where the recently developed relightable 3D reconstruction techniques are adopted for rapid and direct data generation with varying illumination conditions. A self-supervised framework is proposed for extracting features with advantages in repeatability for key points and similarity for descriptors across good and bad illumination conditions. Experiments are conducted to demonstrate the effectiveness of the proposed method for robust feature extraction. Ablation studies also indicate the effectiveness of the self-supervised framework design.</li>
</ul>

<h3>Title: Integrating PETs into Software Applications: A Game-Based Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Maisha Boteju, Thilina Ranbaduge, Dinusha Vatsalan, Nalin Arachchilage</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00661">https://arxiv.org/abs/2410.00661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00661">https://arxiv.org/pdf/2410.00661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00661]] Integrating PETs into Software Applications: A Game-Based Learning Approach(https://arxiv.org/abs/2410.00661)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>The absence of data protection measures in software applications leads to data breaches, threatening end-user privacy and causing instabilities in organisations that developed those software. Privacy Enhancing Technologies (PETs) emerge as promising safeguards against data breaches. PETs minimise threats to personal data while enabling software to extract valuable insights from them. However, software developers often lack the adequate knowledge and awareness to develop PETs integrated software. This issue is exacerbated by insufficient PETs related learning approaches customised for software developers. Therefore, we propose "PETs-101", a novel game-based learning framework that motivates developers to integrate PETs into software. By doing so, it aims to improve developers' privacy-preserving software development behaviour rather than simply delivering the learning content on PETs. In future, the proposed framework will be empirically investigated and used as a foundation for developing an educational gaming intervention that trains developers to put PETs into practice.</li>
</ul>

<h3>Title: GMT: Enhancing Generalizable Neural Rendering via Geometry-Driven Multi-Reference Texture Transfer</h3>
<ul>
<li><strong>Authors: </strong>Youngho Yoon, Hyun-Kurl Jang, Kuk-Jin Yoon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00672">https://arxiv.org/abs/2410.00672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00672">https://arxiv.org/pdf/2410.00672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00672]] GMT: Enhancing Generalizable Neural Rendering via Geometry-Driven Multi-Reference Texture Transfer(https://arxiv.org/abs/2410.00672)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Novel view synthesis (NVS) aims to generate images at arbitrary viewpoints using multi-view images, and recent insights from neural radiance fields (NeRF) have contributed to remarkable improvements. Recently, studies on generalizable NeRF (G-NeRF) have addressed the challenge of per-scene optimization in NeRFs. The construction of radiance fields on-the-fly in G-NeRF simplifies the NVS process, making it well-suited for real-world applications. Meanwhile, G-NeRF still struggles in representing fine details for a specific scene due to the absence of per-scene optimization, even with texture-rich multi-view source inputs. As a remedy, we propose a Geometry-driven Multi-reference Texture transfer network (GMT) available as a plug-and-play module designed for G-NeRF. Specifically, we propose ray-imposed deformable convolution (RayDCN), which aligns input and reference features reflecting scene geometry. Additionally, the proposed texture preserving transformer (TP-Former) aggregates multi-view source features while preserving texture information. Consequently, our module enables direct interaction between adjacent pixels during the image enhancement process, which is deficient in G-NeRF models with an independent rendering process per pixel. This addresses constraints that hinder the ability to capture high-frequency details. Experiments show that our plug-and-play module consistently improves G-NeRF models on various benchmark datasets.</li>
</ul>

<h3>Title: User-Guided Verification of Security Protocols via Sound Animation</h3>
<ul>
<li><strong>Authors: </strong>Kangfeng Ye, Roberto Metere, Poonam Yadav</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00676">https://arxiv.org/abs/2410.00676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00676">https://arxiv.org/pdf/2410.00676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00676]] User-Guided Verification of Security Protocols via Sound Animation(https://arxiv.org/abs/2410.00676)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Current formal verification of security protocols relies on specialized researchers and complex tools, inaccessible to protocol designers who informally evaluate their work with emulators. This paper addresses this gap by embedding symbolic analysis into the design process. Our approach implements the Dolev-Yao attack model using a variant of CSP based on Interaction Trees (ITrees) to compile protocols into animators -- executable programs that designers can use for debugging and inspection. To guarantee the soundness of our compilation, we mechanised our approach in the theorem prover Isabelle/HOL. As traditionally done with symbolic tools, we refer to the Diffie-Hellman key exchange and the Needham-Schroeder public-key protocol (and Lowe's patched variant). We demonstrate how our animator can easily reveal the mechanics of attacks and verify corrections. This work facilitates security integration at the design level and supports further security property analysis and software-engineered integrations.</li>
</ul>

<h3>Title: Advanced Arabic Alphabet Sign Language Recognition Using Transfer Learning and Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Mazen Balat, Rewaa Awaad, Hend Adel, Ahmed B. Zaky, Salah A. Aly</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00681">https://arxiv.org/abs/2410.00681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00681">https://arxiv.org/pdf/2410.00681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00681]] Advanced Arabic Alphabet Sign Language Recognition Using Transfer Learning and Transformer Models(https://arxiv.org/abs/2410.00681)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents an Arabic Alphabet Sign Language recognition approach, using deep learning methods in conjunction with transfer learning and transformer-based models. We study the performance of the different variants on two publicly available datasets, namely ArSL2018 and AASL. This task will make full use of state-of-the-art CNN architectures like ResNet50, MobileNetV2, and EfficientNetB7, and the latest transformer models such as Google ViT and Microsoft Swin Transformer. These pre-trained models have been fine-tuned on the above datasets in an attempt to capture some unique features of Arabic sign language motions. Experimental results present evidence that the suggested methodology can receive a high recognition accuracy, by up to 99.6\% and 99.43\% on ArSL2018 and AASL, respectively. That is far beyond the previously reported state-of-the-art approaches. This performance opens up even more avenues for communication that may be more accessible to Arabic-speaking deaf and hard-of-hearing, and thus encourages an inclusive society.</li>
</ul>

<h3>Title: Efficient Technical Term Translation: A Knowledge Distillation Approach for Parenthetical Terminology Translation</h3>
<ul>
<li><strong>Authors: </strong>Jiyoon Myung, Jihyeon Park, Jungki Son, Kyungro Lee, Joohyung Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00683">https://arxiv.org/abs/2410.00683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00683">https://arxiv.org/pdf/2410.00683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00683]] Efficient Technical Term Translation: A Knowledge Distillation Approach for Parenthetical Terminology Translation(https://arxiv.org/abs/2410.00683)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper addresses the challenge of accurately translating technical terms, which are crucial for clear communication in specialized fields. We introduce the Parenthetical Terminology Translation (PTT) task, designed to mitigate potential inaccuracies by displaying the original term in parentheses alongside its translation. To implement this approach, we generated a representative PTT dataset using a collaborative approach with large language models and applied knowledge distillation to fine-tune traditional Neural Machine Translation (NMT) models and small-sized Large Language Models (sLMs). Additionally, we developed a novel evaluation metric to assess both overall translation accuracy and the correct parenthetical presentation of terms. Our findings indicate that sLMs did not consistently outperform NMT models, with fine-tuning proving more effective than few-shot prompting, particularly in models with continued pre-training in the target language. These insights contribute to the advancement of more reliable terminology translation methodologies.</li>
</ul>

<h3>Title: Beyond Minimax Rates in Group Distributionally Robust Optimization via a Novel Notion of Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Quan Nguyen, Nishant A. Mehta, Cristóbal Guzmán</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00690">https://arxiv.org/abs/2410.00690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00690">https://arxiv.org/pdf/2410.00690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00690]] Beyond Minimax Rates in Group Distributionally Robust Optimization via a Novel Notion of Sparsity(https://arxiv.org/abs/2410.00690)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The minimax sample complexity of group distributionally robust optimization (GDRO) has been determined up to a $\log(K)$ factor, for $K$ the number of groups. In this work, we venture beyond the minimax perspective via a novel notion of sparsity that we dub $(\lambda, \beta)$-sparsity. In short, this condition means that at any parameter $\theta$, there is a set of at most $\beta$ groups whose risks at $\theta$ all are at least $\lambda$ larger than the risks of the other groups. To find an $\epsilon$-optimal $\theta$, we show via a novel algorithm and analysis that the $\epsilon$-dependent term in the sample complexity can swap a linear dependence on $K$ for a linear dependence on the potentially much smaller $\beta$. This improvement leverages recent progress in sleeping bandits, showing a fundamental connection between the two-player zero-sum game optimization framework for GDRO and per-action regret bounds in sleeping bandits. The aforementioned result assumes having a particular $\lambda$ as input. Perhaps surprisingly, we next show an adaptive algorithm which, up to log factors, gets sample complexity that adapts to the best $(\lambda, \beta)$-sparsity condition that holds. Finally, for a particular input $\lambda$, we also show how to get a dimension-free sample complexity result.</li>
</ul>

<h3>Title: Investigating the Impact of Model Complexity in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jing Luo, Huiyuan Wang, Weiran Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00699">https://arxiv.org/abs/2410.00699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00699">https://arxiv.org/pdf/2410.00699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00699]] Investigating the Impact of Model Complexity in Large Language Models(https://arxiv.org/abs/2410.00699)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) based on the pre-trained fine-tuning paradigm have become pivotal in solving natural language processing tasks, consistently achieving state-of-the-art performance. Nevertheless, the theoretical understanding of how model complexity influences fine-tuning performance remains challenging and has not been well explored yet. In this paper, we focus on autoregressive LLMs and propose to employ Hidden Markov Models (HMMs) to model them. Based on the HMM modeling, we investigate the relationship between model complexity and the generalization capability in downstream tasks. Specifically, we consider a popular tuning paradigm for downstream tasks, head tuning, where all pre-trained parameters are frozen and only individual heads are trained atop pre-trained LLMs. Our theoretical analysis reveals that the risk initially increases and then decreases with rising model complexity, showcasing a "double descent" phenomenon. In this case, the initial "descent" is degenerate, signifying that the "sweet spot" where bias and variance are balanced occurs when the model size is zero. Obtaining the presented in this study conclusion confronts several challenges, primarily revolving around effectively modeling autoregressive LLMs and downstream tasks, as well as conducting a comprehensive risk analysis for multivariate regression. Our research is substantiated by experiments conducted on data generated from HMMs, which provided empirical support and alignment with our theoretical insights.</li>
</ul>

<h3>Title: Mining Your Own Secrets: Diffusion Classifier Scores for Continual Personalization of Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Saurav Jha, Shiqi Yang, Masato Ishii, Mengjie Zhao, Christian Simon, Jehanzeb Mirza, Dong Gong, Lina Yao, Shusuke Takahashi, Yuki Mitsufuji</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00700">https://arxiv.org/abs/2410.00700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00700">https://arxiv.org/pdf/2410.00700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00700]] Mining Your Own Secrets: Diffusion Classifier Scores for Continual Personalization of Text-to-Image Diffusion Models(https://arxiv.org/abs/2410.00700)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>Personalized text-to-image diffusion models have grown popular for their ability to efficiently acquire a new concept from user-defined text descriptions and a few images. However, in the real world, a user may wish to personalize a model on multiple concepts but one at a time, with no access to the data from previous concepts due to storage/privacy concerns. When faced with this continual learning (CL) setup, most personalization methods fail to find a balance between acquiring new concepts and retaining previous ones -- a challenge that continual personalization (CP) aims to solve. Inspired by the successful CL methods that rely on class-specific information for regularization, we resort to the inherent class-conditioned density estimates, also known as diffusion classifier (DC) scores, for continual personalization of text-to-image diffusion models. Namely, we propose using DC scores for regularizing the parameter-space and function-space of text-to-image diffusion models, to achieve continual personalization. Using several diverse evaluation setups, datasets, and metrics, we show that our proposed regularization-based CP methods outperform the state-of-the-art C-LoRA, and other baselines. Finally, by operating in the replay-free CL setup and on low-rank adapters, our method incurs zero storage and parameter overhead, respectively, over the state-of-the-art.</li>
</ul>

<h3>Title: BioFace3D: A fully automatic pipeline for facial biomarkers extraction of 3D face reconstructions segmented from MRI</h3>
<ul>
<li><strong>Authors: </strong>Álvaro Heredia-Lidón, Luis M. Echeverry-Quiceno, Alejandro González, Noemí Hostalet, Edith Pomarol-Clotet, Juan Fortea, Mar Fatjó-Vilas, Neus Martínez-Abadías, Xavier Sevillano</a></li>
<li><strong>Subjects: </strong>cs.CV, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00711">https://arxiv.org/abs/2410.00711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00711">https://arxiv.org/pdf/2410.00711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00711]] BioFace3D: A fully automatic pipeline for facial biomarkers extraction of 3D face reconstructions segmented from MRI(https://arxiv.org/abs/2410.00711)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Facial dysmorphologies have emerged as potential critical indicators in the diagnosis and prognosis of genetic, psychotic and rare disorders. While in certain conditions these dysmorphologies are severe, in other cases may be subtle and not perceivable to the human eye, requiring precise quantitative tools for their identification. Manual coding of facial dysmorphologies is a burdensome task and is subject to inter- and intra-observer variability. To overcome this gap, we present BioFace3D as a fully automatic tool for the calculation of facial biomarkers using facial models reconstructed from magnetic resonance images. The tool is divided into three automatic modules for the extraction of 3D facial models from magnetic resonance images, the registration of homologous 3D landmarks encoding facial morphology, and the calculation of facial biomarkers from anatomical landmarks coordinates using geometric morphometrics techniques.</li>
</ul>

<h3>Title: RAD: A Dataset and Benchmark for Real-Life Anomaly Detection with Robotic Observations</h3>
<ul>
<li><strong>Authors: </strong>Kaichen Zhou, Yang Cao, Teawhan Kim, Hao Zhao, Hao Dong, Kai Ming Ting, Ye Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00713">https://arxiv.org/abs/2410.00713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00713">https://arxiv.org/pdf/2410.00713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00713]] RAD: A Dataset and Benchmark for Real-Life Anomaly Detection with Robotic Observations(https://arxiv.org/abs/2410.00713)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in industrial anomaly detection have been hindered by the lack of realistic datasets that accurately represent real-world conditions. Existing algorithms are often developed and evaluated using idealized datasets, which deviate significantly from real-life scenarios characterized by environmental noise and data corruption such as fluctuating lighting conditions, variable object poses, and unstable camera positions. To address this gap, we introduce the Realistic Anomaly Detection (RAD) dataset, the first multi-view RGB-based anomaly detection dataset specifically collected using a real robot arm, providing unique and realistic data scenarios. RAD comprises 4765 images across 13 categories and 4 defect types, collected from more than 50 viewpoints, providing a comprehensive and realistic benchmark. This multi-viewpoint setup mirrors real-world conditions where anomalies may not be detectable from every perspective. Moreover, by sampling varying numbers of views, the algorithm's performance can be comprehensively evaluated across different viewpoints. This approach enhances the thoroughness of performance assessment and helps improve the algorithm's robustness. Besides, to support 3D multi-view reconstruction algorithms, we propose a data augmentation method to improve the accuracy of pose estimation and facilitate the reconstruction of 3D point clouds. We systematically evaluate state-of-the-art RGB-based and point cloud-based models using RAD, identifying limitations and future research directions. The code and dataset could found at this https URL</li>
</ul>

<h3>Title: Pseudo-Non-Linear Data Augmentation via Energy Minimization</h3>
<ul>
<li><strong>Authors: </strong>Pingbang Hu, Mahito Sugiyama</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00718">https://arxiv.org/abs/2410.00718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00718">https://arxiv.org/pdf/2410.00718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00718]] Pseudo-Non-Linear Data Augmentation via Energy Minimization(https://arxiv.org/abs/2410.00718)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>We propose a novel and interpretable data augmentation method based on energy-based modeling and principles from information geometry. Unlike black-box generative models, which rely on deep neural networks, our approach replaces these non-interpretable transformations with explicit, theoretically grounded ones, ensuring interpretability and strong guarantees such as energy minimization. Central to our method is the introduction of the backward projection algorithm, which reverses dimension reduction to generate new data. Empirical results demonstrate that our method achieves competitive performance with black-box generative models while offering greater transparency and interpretability.</li>
</ul>

<h3>Title: Show Me What's Wrong: Combining Charts and Text to Guide Data Analysis</h3>
<ul>
<li><strong>Authors: </strong>Beatriz Feliciano, Rita Costa, Jean Alves, Javier Liébana, Diogo Duarte, Pedro Bizarro</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00727">https://arxiv.org/abs/2410.00727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00727">https://arxiv.org/pdf/2410.00727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00727]] Show Me What's Wrong: Combining Charts and Text to Guide Data Analysis(https://arxiv.org/abs/2410.00727)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Analyzing and finding anomalies in multi-dimensional datasets is a cumbersome but vital task across different domains. In the context of financial fraud detection, analysts must quickly identify suspicious activity among transactional data. This is an iterative process made of complex exploratory tasks such as recognizing patterns, grouping, and comparing. To mitigate the information overload inherent to these steps, we present a tool combining automated information highlights, Large Language Model generated textual insights, and visual analytics, facilitating exploration at different levels of detail. We perform a segmentation of the data per analysis area and visually represent each one, making use of automated visual cues to signal which require more attention. Upon user selection of an area, our system provides textual and graphical summaries. The text, acting as a link between the high-level and detailed views of the chosen segment, allows for a quick understanding of relevant details. A thorough exploration of the data comprising the selection can be done through graphical representations. The feedback gathered in a study performed with seven domain experts suggests our tool effectively supports and guides exploratory analysis, easing the identification of suspicious information.</li>
</ul>

<h3>Title: Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Lakshmi Nair</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00731">https://arxiv.org/abs/2410.00731</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00731">https://arxiv.org/pdf/2410.00731</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00731]] Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion(https://arxiv.org/abs/2410.00731)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Synthetic data generation is an important application of machine learning in the field of medical imaging. While existing approaches have successfully applied fine-tuned diffusion models for synthesizing medical images, we explore potential improvements to this pipeline through feature-aligned diffusion. Our approach aligns intermediate features of the diffusion model to the output features of an expert, and our preliminary findings show an improvement of 9% in generation accuracy and ~0.12 in SSIM diversity. Our approach is also synergistic with existing methods, and easily integrated into diffusion training pipelines for improvements. We make our code available at \url{this https URL}.</li>
</ul>

<h3>Title: Optimizing Token Usage on Large Language Model Conversations Using the Design Structure Matrix</h3>
<ul>
<li><strong>Authors: </strong>Ramon Maria Garcia Alarcia, Alessandro Golkar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00749">https://arxiv.org/abs/2410.00749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00749">https://arxiv.org/pdf/2410.00749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00749]] Optimizing Token Usage on Large Language Model Conversations Using the Design Structure Matrix(https://arxiv.org/abs/2410.00749)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models become ubiquitous in many sectors and tasks, there is a need to reduce token usage, overcoming challenges such as short context windows, limited output sizes, and costs associated with token intake and generation, especially in API-served LLMs. This work brings the Design Structure Matrix from the engineering design discipline into LLM conversation optimization. Applied to a use case in which the LLM conversation is about the design of a spacecraft and its subsystems, the DSM, with its analysis tools such as clustering and sequencing, demonstrates being an effective tool to organize the conversation, minimizing the number of tokens sent to or retrieved from the LLM at once, as well as grouping chunks that can be allocated to different context windows. Hence, this work broadens the current set of methodologies for token usage optimization and opens new avenues for the integration of engineering design practices into LLMs.</li>
</ul>

<h3>Title: Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting</h3>
<ul>
<li><strong>Authors: </strong>Stephen Meisenbacher, Florian Matthes</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00751">https://arxiv.org/abs/2410.00751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00751">https://arxiv.org/pdf/2410.00751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00751]] Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting(https://arxiv.org/abs/2410.00751)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>The field of privacy-preserving Natural Language Processing has risen in popularity, particularly at a time when concerns about privacy grow with the proliferation of Large Language Models. One solution consistently appearing in recent literature has been the integration of Differential Privacy (DP) into NLP techniques. In this paper, we take these approaches into critical view, discussing the restrictions that DP integration imposes, as well as bring to light the challenges that such restrictions entail. To accomplish this, we focus on $\textbf{DP-Prompt}$, a recent method for text privatization leveraging language models to rewrite texts. In particular, we explore this rewriting task in multiple scenarios, both with DP and without DP. To drive the discussion on the merits of DP in NLP, we conduct empirical utility and privacy experiments. Our results demonstrate the need for more discussion on the usability of DP in NLP and its benefits over non-DP approaches.</li>
</ul>

<h3>Title: Targeted synthetic data generation for tabular data via hardness characterization</h3>
<ul>
<li><strong>Authors: </strong>Tommaso Ferracci, Leonie Tabea Goldmann, Anton Hinel, Francesco Sanna Passino</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00759">https://arxiv.org/abs/2410.00759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00759">https://arxiv.org/pdf/2410.00759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00759]] Targeted synthetic data generation for tabular data via hardness characterization(https://arxiv.org/abs/2410.00759)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Synthetic data generation has been proven successful in improving model performance and robustness in the context of scarce or low-quality data. Using the data valuation framework to statistically identify beneficial and detrimental observations, we introduce a novel augmentation pipeline that generates only high-value training points based on hardness characterization. We first demonstrate via benchmarks on real data that Shapley-based data valuation methods perform comparably with learning-based methods in hardness characterisation tasks, while offering significant theoretical and computational advantages. Then, we show that synthetic data generators trained on the hardest points outperform non-targeted data augmentation on simulated data and on a large scale credit default prediction task. In particular, our approach improves the quality of out-of-sample predictions and it is computationally more efficient compared to non-targeted methods.</li>
</ul>

<h3>Title: DeepAerialMapper: Deep Learning-based Semi-automatic HD Map Creation for Highly Automated Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Robert Krajewski, Huijo Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00769">https://arxiv.org/abs/2410.00769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00769">https://arxiv.org/pdf/2410.00769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00769]] DeepAerialMapper: Deep Learning-based Semi-automatic HD Map Creation for Highly Automated Vehicles(https://arxiv.org/abs/2410.00769)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>High-definition maps (HD maps) play a crucial role in the development, safety validation, and operation of highly automated vehicles. Efficiently collecting up-to-date sensor data from road segments and obtaining accurate maps from these are key challenges in HD map creation. Commonly used methods, such as dedicated measurement vehicles and crowd-sourced data from series vehicles, often face limitations in commercial viability. Although high-resolution aerial imagery offers a cost-effective or even free alternative, it requires significant manual effort and time to transform it into maps. In this paper, we introduce a semi-automatic method for creating HD maps from high-resolution aerial imagery. Our method involves training neural networks to semantically segment aerial images into classes relevant to HD maps. The resulting segmentation is then hierarchically post-processed to generate a prototypical HD map of visible road elements. Exporting the map to the Lanelet2 format allows easy extension for different use cases using standard tools. To train and evaluate our method, we created a dataset using public aerial imagery of urban road segments in Germany. In our evaluation, we achieved an automatic mapping of lane markings and road borders with a recall and precision exceeding 96%. The source code for our method is publicly available at this https URL.</li>
</ul>

<h3>Title: Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting</h3>
<ul>
<li><strong>Authors: </strong>Chen Cai, Zheng Wang, Jianjun Gao, Wenyang Liu, Ye Lu, Runzhong Zhang, Kim-Hui Yap</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00771">https://arxiv.org/abs/2410.00771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00771">https://arxiv.org/pdf/2410.00771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00771]] Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting(https://arxiv.org/abs/2410.00771)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, the rapid increase in online video content has underscored the limitations of static Video Question Answering (VideoQA) models trained on fixed datasets, as they struggle to adapt to new questions or tasks posed by newly available content. In this paper, we explore the novel challenge of VideoQA within a continual learning framework, and empirically identify a critical issue: fine-tuning a large language model (LLM) for a sequence of tasks often results in catastrophic forgetting. To address this, we propose Collaborative Prompting (ColPro), which integrates specific question constraint prompting, knowledge acquisition prompting, and visual temporal awareness prompting. These prompts aim to capture textual question context, visual content, and video temporal dynamics in VideoQA, a perspective underexplored in prior research. Experimental results on the NExT-QA and DramaQA datasets show that ColPro achieves superior performance compared to existing approaches, achieving 55.14\% accuracy on NExT-QA and 71.24\% accuracy on DramaQA, highlighting its practical relevance and effectiveness.</li>
</ul>

<h3>Title: Decoding Hate: Exploring Language Models' Reactions to Hate Speech</h3>
<ul>
<li><strong>Authors: </strong>Paloma Piot, Javier Parapar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00775">https://arxiv.org/abs/2410.00775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00775">https://arxiv.org/pdf/2410.00775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00775]] Decoding Hate: Exploring Language Models' Reactions to Hate Speech(https://arxiv.org/abs/2410.00775)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hate speech is a harmful form of online expression, often manifesting as derogatory posts. It is a significant risk in digital environments. With the rise of Large Language Models (LLMs), there is concern about their potential to replicate hate speech patterns, given their training on vast amounts of unmoderated internet data. Understanding how LLMs respond to hate speech is crucial for their responsible deployment. However, the behaviour of LLMs towards hate speech has been limited compared. This paper investigates the reactions of seven state-of-the-art LLMs (LLaMA 2, Vicuna, LLaMA 3, Mistral, GPT-3.5, GPT-4, and Gemini Pro) to hate speech. Through qualitative analysis, we aim to reveal the spectrum of responses these models produce, highlighting their capacity to handle hate speech inputs. We also discuss strategies to mitigate hate speech generation by LLMs, particularly through fine-tuning and guideline guardrailing. Finally, we explore the models' responses to hate speech framed in politically correct language.</li>
</ul>

<h3>Title: Local-to-Global Self-Supervised Representation Learning for Diabetic Retinopathy Grading</h3>
<ul>
<li><strong>Authors: </strong>Mostafa Hajighasemloua, Samad Sheikhaei, Hamid Soltanian-Zadeha</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00779">https://arxiv.org/abs/2410.00779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00779">https://arxiv.org/pdf/2410.00779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00779]] Local-to-Global Self-Supervised Representation Learning for Diabetic Retinopathy Grading(https://arxiv.org/abs/2410.00779)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Artificial intelligence algorithms have demonstrated their image classification and segmentation ability in the past decade. However, artificial intelligence algorithms perform less for actual clinical data than those used for simulations. This research aims to present a novel hybrid learning model using self-supervised learning and knowledge distillation, which can achieve sufficient generalization and robustness. The self-attention mechanism and tokens employed in ViT, besides the local-to-global learning approach used in the hybrid model, enable the proposed algorithm to extract a high-dimensional and high-quality feature space from images. To demonstrate the proposed neural network's capability in classifying and extracting feature spaces from medical images, we use it on a dataset of Diabetic Retinopathy images, specifically the EyePACS dataset. This dataset is more complex structurally and challenging regarding damaged areas than other medical images. For the first time in this study, self-supervised learning and knowledge distillation are used to classify this dataset. In our algorithm, for the first time among all self-supervised learning and knowledge distillation models, the test dataset is 50% larger than the training dataset. Unlike many studies, we have not removed any images from the dataset. Finally, our algorithm achieved an accuracy of 79.1% in the linear classifier and 74.36% in the k-NN algorithm for multiclass classification. Compared to a similar state-of-the-art model, our results achieved higher accuracy and more effective representation spaces.</li>
</ul>

<h3>Title: Fast Multiplication and the PLWE-RLWE Equivalence for an Infinite Family of Cyclotomic Subextensions</h3>
<ul>
<li><strong>Authors: </strong>Joonas Ahola, Iván Blanco-Chacón, Wilmar Bolaños, Antti Haavikko, Camilla Hollanti, Rodrigo Martín Sánchez-Ledesma</a></li>
<li><strong>Subjects: </strong>cs.CR, math.NT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00792">https://arxiv.org/abs/2410.00792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00792">https://arxiv.org/pdf/2410.00792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00792]] Fast Multiplication and the PLWE-RLWE Equivalence for an Infinite Family of Cyclotomic Subextensions(https://arxiv.org/abs/2410.00792)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>We prove the equivalence between the Ring Learning With Errors (RLWE) and the Polynomial Learning With Errors (PLWE) problems for the maximal totally real subfield of the $2^r 3^s$-th cyclotomic field for $r \geq 3$ and $s \geq 1$. Moreover, we describe a fast algorithm for computing the product of two elements in the ring of integers of these subfields. This multiplication algorithm has quasilinear complexity in the dimension of the field, as it makes use of the fast Discrete Cosine Transform (DCT). Our approach assumes that the two input polynomials are given in a basis of Chebyshev-like polynomials, in contrast to the customary power basis. To validate this assumption, we prove that the change of basis from the power basis to the Chebyshev-like basis can be computed with $\mathcal{O}(n \log n)$ arithmetic operations, where $n$ is the problem dimension. Finally, we provide a heuristic and theoretical comparison of the vulnerability to some attacks for the $p$-th cyclotomic field versus the maximal totally real subextension of the $4p$-th cyclotomic field for a reasonable set of parameters of cryptographic size.</li>
</ul>

<h3>Title: A generative framework to bridge data-driven models and scientific theories in language neuroscience</h3>
<ul>
<li><strong>Authors: </strong>Richard Antonello, Chandan Singh, Shailee Jain, Aliyah Hsu, Jianfeng Gao, Bin Yu, Alexander Huth</a></li>
<li><strong>Subjects: </strong>cs.CL, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00812">https://arxiv.org/abs/2410.00812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00812">https://arxiv.org/pdf/2410.00812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00812]] A generative framework to bridge data-driven models and scientific theories in language neuroscience(https://arxiv.org/abs/2410.00812)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Representations from large language models are highly effective at predicting BOLD fMRI responses to language stimuli. However, these representations are largely opaque: it is unclear what features of the language stimulus drive the response in each brain area. We present generative explanation-mediated validation, a framework for generating concise explanations of language selectivity in the brain and then validating those explanations in follow-up experiments that use synthetic stimuli. This approach is successful at explaining selectivity both in individual voxels and cortical regions of interest (ROIs).We show that explanatory accuracy is closely related to the predictive power and stability of the underlying statistical models. These results demonstrate that LLMs can be used to bridge the widening gap between data-driven models and formal scientific theories.</li>
</ul>

<h3>Title: Towards Fairness and Privacy: A Novel Data Pre-processing Optimization Framework for Non-binary Protected Attributes</h3>
<ul>
<li><strong>Authors: </strong>Manh Khoi Duong, Stefan Conrad</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00836">https://arxiv.org/abs/2410.00836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00836">https://arxiv.org/pdf/2410.00836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00836]] Towards Fairness and Privacy: A Novel Data Pre-processing Optimization Framework for Non-binary Protected Attributes(https://arxiv.org/abs/2410.00836)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, fair</a></li>
<li><strong>Abstract: </strong>The reason behind the unfair outcomes of AI is often rooted in biased datasets. Therefore, this work presents a framework for addressing fairness by debiasing datasets containing a (non-)binary protected attribute. The framework proposes a combinatorial optimization problem where heuristics such as genetic algorithms can be used to solve for the stated fairness objectives. The framework addresses this by finding a data subset that minimizes a certain discrimination measure. Depending on a user-defined setting, the framework enables different use cases, such as data removal, the addition of synthetic data, or exclusive use of synthetic data. The exclusive use of synthetic data in particular enhances the framework's ability to preserve privacy while optimizing for fairness. In a comprehensive evaluation, we demonstrate that under our framework, genetic algorithms can effectively yield fairer datasets compared to the original data. In contrast to prior work, the framework exhibits a high degree of flexibility as it is metric- and task-agnostic, can be applied to both binary or non-binary protected attributes, and demonstrates efficient runtime.</li>
</ul>

<h3>Title: Uncertainty-aware Reward Model: Teaching Reward Models to Know What is Unknown</h3>
<ul>
<li><strong>Authors: </strong>Xingzhou Lou, Dong Yan, Wei Shen, Yuzi Yan, Jian Xie, Junge Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00847">https://arxiv.org/abs/2410.00847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00847">https://arxiv.org/pdf/2410.00847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00847]] Uncertainty-aware Reward Model: Teaching Reward Models to Know What is Unknown(https://arxiv.org/abs/2410.00847)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reward models (RM) play a critical role in aligning generations of large language models (LLM) to human expectations. However, prevailing RMs fail to capture the stochasticity within human preferences and cannot effectively evaluate the reliability of reward predictions. To address these issues, we propose Uncertain-aware RM (URM) and Uncertain-aware RM Ensemble (URME) to incorporate and manage uncertainty in reward modeling. URM can model the distribution of disentangled attributes within human preferences, while URME quantifies uncertainty through discrepancies in the ensemble, thereby identifying potential lack of knowledge during reward evaluation. Experiment results indicate that the proposed URM achieves state-of-the-art performance compared to models with the same size, demonstrating the effectiveness of modeling uncertainty within human preferences. Furthermore, empirical results show that through uncertainty quantification, URM and URME can identify unreliable predictions to improve the quality of reward evaluations.</li>
</ul>

<h3>Title: Timber! Poisoning Decision Trees</h3>
<ul>
<li><strong>Authors: </strong>Stefano Calzavara, Lorenzo Cazzaro, Massimo Vettori</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00862">https://arxiv.org/abs/2410.00862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00862">https://arxiv.org/pdf/2410.00862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00862]] Timber! Poisoning Decision Trees(https://arxiv.org/abs/2410.00862)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>We present Timber, the first white-box poisoning attack targeting decision trees. Timber is based on a greedy attack strategy leveraging sub-tree retraining to efficiently estimate the damage performed by poisoning a given training instance. The attack relies on a tree annotation procedure which enables sorting training instances so that they are processed in increasing order of computational cost of sub-tree retraining. This sorting yields a variant of Timber supporting an early stopping criterion designed to make poisoning attacks more efficient and feasible on larger datasets. We also discuss an extension of Timber to traditional random forest models, which is useful because decision trees are normally combined into ensembles to improve their predictive power. Our experimental evaluation on public datasets shows that our attacks outperform existing baselines in terms of effectiveness, efficiency or both. Moreover, we show that two representative defenses can mitigate the effect of our attacks, but fail at effectively thwarting them.</li>
</ul>

<h3>Title: On the Implications of Verbose LLM Outputs: A Case Study in Translation Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Eleftheria Briakou, Zhongtao Liu, Colin Cherry, Markus Freitag</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00863">https://arxiv.org/abs/2410.00863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00863">https://arxiv.org/pdf/2410.00863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00863]] On the Implications of Verbose LLM Outputs: A Case Study in Translation Evaluation(https://arxiv.org/abs/2410.00863)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This paper investigates the impact of verbose LLM translations on evaluation. We first demonstrate the prevalence of this behavior across several LLM outputs drawn from the WMT 2024 general shared task on machine translation. We then identify the primary triggers of verbosity, including safety, copyright concerns, and insufficient context in short input queries. Finally, we show that ignoring this behavior unfairly penalizes more verbose LLMs according to both automatic and human evaluations, highlighting the need to address this issue for more accurate future evaluations.</li>
</ul>

<h3>Title: MAP: Unleashing Hybrid Mamba-Transformer Vision Backbone's Potential with Masked Autoregressive Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Yunze Liu, Li Yi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00871">https://arxiv.org/abs/2410.00871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00871">https://arxiv.org/pdf/2410.00871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00871]] MAP: Unleashing Hybrid Mamba-Transformer Vision Backbone's Potential with Masked Autoregressive Pretraining(https://arxiv.org/abs/2410.00871)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Mamba has achieved significant advantages in long-context modeling and autoregressive tasks, but its scalability with large parameters remains a major limitation in vision applications. pretraining is a widely used strategy to enhance backbone model performance. Although the success of Masked Autoencoder in Transformer pretraining is well recognized, it does not significantly improve Mamba's visual learning performance. We found that using the correct autoregressive pretraining can significantly boost the performance of the Mamba architecture. Based on this analysis, we propose Masked Autoregressive Pretraining (MAP) to pretrain a hybrid Mamba-Transformer vision backbone network. This strategy combines the strengths of both MAE and Autoregressive pretraining, improving the performance of Mamba and Transformer modules within a unified paradigm. Additionally, in terms of integrating Mamba and Transformer modules, we empirically found that inserting Transformer layers at regular intervals within Mamba layers can significantly enhance downstream task performance. Experimental results show that both the pure Mamba architecture and the hybrid Mamba-Transformer vision backbone network pretrained with MAP significantly outperform other pretraining strategies, achieving state-of-the-art performance. We validate the effectiveness of the method on both 2D and 3D datasets and provide detailed ablation studies to support the design choices for each component.</li>
</ul>

<h3>Title: Review of blockchain application with Graph Neural Networks, Graph Convolutional Networks and Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Amy Ancelotti, Claudia Liason</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00875">https://arxiv.org/abs/2410.00875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00875">https://arxiv.org/pdf/2410.00875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00875]] Review of blockchain application with Graph Neural Networks, Graph Convolutional Networks and Convolutional Neural Networks(https://arxiv.org/abs/2410.00875)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>This paper reviews the applications of Graph Neural Networks (GNNs), Graph Convolutional Networks (GCNs), and Convolutional Neural Networks (CNNs) in blockchain technology. As the complexity and adoption of blockchain networks continue to grow, traditional analytical methods are proving inadequate in capturing the intricate relationships and dynamic behaviors of decentralized systems. To address these limitations, deep learning models such as GNNs, GCNs, and CNNs offer robust solutions by leveraging the unique graph-based and temporal structures inherent in blockchain architectures. GNNs and GCNs, in particular, excel in modeling the relational data of blockchain nodes and transactions, making them ideal for applications such as fraud detection, transaction verification, and smart contract analysis. Meanwhile, CNNs can be adapted to analyze blockchain data when represented as structured matrices, revealing hidden temporal and spatial patterns in transaction flows. This paper explores how these models enhance the efficiency, security, and scalability of both linear blockchains and Directed Acyclic Graph (DAG)-based systems, providing a comprehensive overview of their strengths and future research directions. By integrating advanced neural network techniques, we aim to demonstrate the potential of these models in revolutionizing blockchain analytics, paving the way for more sophisticated decentralized applications and improved network performance.</li>
</ul>

<h3>Title: Replacing Paths with Connection-Biased Attention for Knowledge Graph Completion</h3>
<ul>
<li><strong>Authors: </strong>Sharmishtha Dutta, Alex Gittens, Mohammed J. Zaki, Charu C. Aggarwal</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00876">https://arxiv.org/abs/2410.00876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00876">https://arxiv.org/pdf/2410.00876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00876]] Replacing Paths with Connection-Biased Attention for Knowledge Graph Completion(https://arxiv.org/abs/2410.00876)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Knowledge graph (KG) completion aims to identify additional facts that can be inferred from the existing facts in the KG. Recent developments in this field have explored this task in the inductive setting, where at test time one sees entities that were not present during training; the most performant models in the inductive setting have employed path encoding modules in addition to standard subgraph encoding modules. This work similarly focuses on KG completion in the inductive setting, without the explicit use of path encodings, which can be time-consuming and introduces several hyperparameters that require costly hyperparameter optimization. Our approach uses a Transformer-based subgraph encoding module only; we introduce connection-biased attention and entity role embeddings into the subgraph encoding module to eliminate the need for an expensive and time-consuming path encoding module. Evaluations on standard inductive KG completion benchmark datasets demonstrate that our Connection-Biased Link Prediction (CBLiP) model has superior performance to models that do not use path information. Compared to models that utilize path information, CBLiP shows competitive or superior performance while being faster. Additionally, to show that the effectiveness of connection-biased attention and entity role embeddings also holds in the transductive setting, we compare CBLiP's performance on the relation prediction task in the transductive setting.</li>
</ul>

<h3>Title: Empirical Perturbation Analysis of Linear System Solvers from a Data Poisoning Perspective</h3>
<ul>
<li><strong>Authors: </strong>Yixin Liu, Arielle Carr, Lichao Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00878">https://arxiv.org/abs/2410.00878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00878">https://arxiv.org/pdf/2410.00878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00878]] Empirical Perturbation Analysis of Linear System Solvers from a Data Poisoning Perspective(https://arxiv.org/abs/2410.00878)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>The perturbation analysis of linear solvers applied to systems arising broadly in machine learning settings -- for instance, when using linear regression models -- establishes an important perspective when reframing these analyses through the lens of a data poisoning attack. By analyzing solvers' responses to such attacks, this work aims to contribute to the development of more robust linear solvers and provide insights into poisoning attacks on linear solvers. In particular, we investigate how the errors in the input data will affect the fitting error and accuracy of the solution from a linear system-solving algorithm under perturbations common in adversarial attacks. We propose data perturbation through two distinct knowledge levels, developing a poisoning optimization and studying two methods of perturbation: Label-guided Perturbation (LP) and Unconditioning Perturbation (UP). Existing works mainly focus on deriving the worst-case perturbation bound from a theoretical perspective, and the analysis is often limited to specific kinds of linear system solvers. Under the circumstance that the data is intentionally perturbed -- as is the case with data poisoning -- we seek to understand how different kinds of solvers react to these perturbations, identifying those algorithms most impacted by different types of adversarial attacks.</li>
</ul>

<h3>Title: Flex3D: Feed-Forward 3D Generation With Flexible Reconstruction Model And Input View Curation</h3>
<ul>
<li><strong>Authors: </strong>Junlin Han, Jianyuan Wang, Andrea Vedaldi, Philip Torr, Filippos Kokkinos</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00890">https://arxiv.org/abs/2410.00890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00890">https://arxiv.org/pdf/2410.00890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00890]] Flex3D: Feed-Forward 3D Generation With Flexible Reconstruction Model And Input View Curation(https://arxiv.org/abs/2410.00890)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Generating high-quality 3D content from text, single images, or sparse view images remains a challenging task with broad this http URL methods typically employ multi-view diffusion models to synthesize multi-view images, followed by a feed-forward process for 3D reconstruction. However, these approaches are often constrained by a small and fixed number of input views, limiting their ability to capture diverse viewpoints and, even worse, leading to suboptimal generation results if the synthesized views are of poor quality. To address these limitations, we propose Flex3D, a novel two-stage framework capable of leveraging an arbitrary number of high-quality input views. The first stage consists of a candidate view generation and curation pipeline. We employ a fine-tuned multi-view image diffusion model and a video diffusion model to generate a pool of candidate views, enabling a rich representation of the target 3D object. Subsequently, a view selection pipeline filters these views based on quality and consistency, ensuring that only the high-quality and reliable views are used for reconstruction. In the second stage, the curated views are fed into a Flexible Reconstruction Model (FlexRM), built upon a transformer architecture that can effectively process an arbitrary number of inputs. FlemRM directly outputs 3D Gaussian points leveraging a tri-plane representation, enabling efficient and detailed 3D generation. Through extensive exploration of design and training strategies, we optimize FlexRM to achieve superior performance in both reconstruction and generation tasks. Our results demonstrate that Flex3D achieves state-of-the-art performance, with a user study winning rate of over 92% in 3D generation tasks when compared to several of the latest feed-forward 3D generative models.</li>
</ul>

<h3>Title: Addition is All You Need for Energy-efficient Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hongyin Luo, Wei Sun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.00907">https://arxiv.org/abs/2410.00907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.00907">https://arxiv.org/pdf/2410.00907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.00907]] Addition is All You Need for Energy-efficient Language Models(https://arxiv.org/abs/2410.00907)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Large neural networks spend most computation on floating point tensor multiplications. In this work, we find that a floating point multiplier can be approximated by one integer adder with high precision. We propose the linear-complexity multiplication L-Mul algorithm that approximates floating point number multiplication with integer addition operations. The new algorithm costs significantly less computation resource than 8-bit floating point multiplication but achieves higher precision. Compared to 8-bit floating point multiplications, the proposed method achieves higher precision but consumes significantly less bit-level computation. Since multiplying floating point numbers requires substantially higher energy compared to integer addition operations, applying the L-Mul operation in tensor processing hardware can potentially reduce 95% energy cost by element-wise floating point tensor multiplications and 80% energy cost of dot products. We calculated the theoretical error expectation of L-Mul, and evaluated the algorithm on a wide range of textual, visual, and symbolic tasks, including natural language understanding, structural reasoning, mathematics, and commonsense question answering. Our numerical analysis experiments agree with the theoretical error estimation, which indicates that L-Mul with 4-bit mantissa achieves comparable precision as float8_e4m3 multiplications, and L-Mul with 3-bit mantissa outperforms float8_e5m2. Evaluation results on popular benchmarks show that directly applying L-Mul to the attention mechanism is almost lossless. We further show that replacing all floating point multiplications with 3-bit mantissa L-Mul in a transformer model achieves equivalent precision as using float8_e4m3 as accumulation precision in both fine-tuning and inference.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
