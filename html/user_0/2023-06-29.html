<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Secure and Fast Asynchronous Vertical Federated Learning via Cascaded Hybrid Optimization. (arXiv:2306.16077v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16077">http://arxiv.org/abs/2306.16077</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16077] Secure and Fast Asynchronous Vertical Federated Learning via Cascaded Hybrid Optimization](http://arxiv.org/abs/2306.16077) #secure</code></li>
<li>Summary: <p>Vertical Federated Learning (VFL) attracts increasing attention because it
empowers multiple parties to jointly train a privacy-preserving model over
vertically partitioned data. Recent research has shown that applying
zeroth-order optimization (ZOO) has many advantages in building a practical VFL
algorithm. However, a vital problem with the ZOO-based VFL is its slow
convergence rate, which limits its application in handling modern large models.
To address this problem, we propose a cascaded hybrid optimization method in
VFL. In this method, the downstream models (clients) are trained with ZOO to
protect privacy and ensure that no internal information is shared. Meanwhile,
the upstream model (server) is updated with first-order optimization (FOO)
locally, which significantly improves the convergence rate, making it feasible
to train the large models without compromising privacy and security. We
theoretically prove that our VFL framework converges faster than the ZOO-based
VFL, as the convergence of our framework is not limited by the size of the
server model, making it effective for training large models with the major part
on the server. Extensive experiments demonstrate that our method achieves
faster convergence than the ZOO-based VFL framework, while maintaining an
equivalent level of privacy protection. Moreover, we show that the convergence
of our VFL is comparable to the unsafe FOO-based VFL baseline. Additionally, we
demonstrate that our method makes the training of a large model feasible.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Boosting Adversarial Transferability with Learnable Patch-wise Masks. (arXiv:2306.15931v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15931">http://arxiv.org/abs/2306.15931</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15931] Boosting Adversarial Transferability with Learnable Patch-wise Masks](http://arxiv.org/abs/2306.15931) #security</code></li>
<li>Summary: <p>Adversarial examples have raised widespread attention in security-critical
applications because of their transferability across different models. Although
many methods have been proposed to boost adversarial transferability, a gap
still exists in the practical demand. In this paper, we argue that the
model-specific discriminative regions are a key factor to cause the
over-fitting to the source model, and thus reduce the transferability to the
target model. For that, a patch-wise mask is utilized to prune the
model-specific regions when calculating adversarial perturbations. To
accurately localize these regions, we present a learnable approach to optimize
the mask automatically. Specifically, we simulate the target models in our
framework, and adjust the patch-wise mask according to the feedback of
simulated models. To improve the efficiency, Differential Evolutionary (DE)
algorithm is utilized to search for patch-wise masks for a specific image.
During iterative attacks, the learned masks are applied to the image to drop
out the patches related to model-specific regions, thus making the gradients
more generic and improving the adversarial transferability. The proposed
approach is a pre-processing method and can be integrated with existing
gradient-based methods to further boost the transfer attack success rate.
Extensive experiments on the ImageNet dataset demonstrate the effectiveness of
our method. We incorporate the proposed approach with existing methods in the
ensemble attacks and achieve an average success rate of 93.01% against seven
advanced defense methods, which can effectively enhance the state-of-the-art
transfer-based attack performance.
</p></li>
</ul>

<h3>Title: A Diamond Model Analysis on Twitter's Biggest Hack. (arXiv:2306.15878v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15878">http://arxiv.org/abs/2306.15878</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15878] A Diamond Model Analysis on Twitter's Biggest Hack](http://arxiv.org/abs/2306.15878) #security</code></li>
<li>Summary: <p>Cyberattacks have prominently increased over the past few years now, and have
targeted actors from a wide variety of domains. Understanding the motivation,
infrastructure, attack vectors, etc. behind such attacks is vital to
proactively work against preventing such attacks in the future and also to
analyze the economic and social impact of such attacks. In this paper, we
leverage the diamond model to perform an intrusion analysis case study of the
2020 Twitter account hijacking Cyberattack. We follow this standardized
incident response model to map the adversary, capability, infrastructure, and
victim and perform a comprehensive analysis of the attack, and the impact posed
by the attack from a Cybersecurity policy standpoint.
</p></li>
</ul>

<h3>Title: Retrospective: Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors. (arXiv:2306.16093v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16093">http://arxiv.org/abs/2306.16093</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16093] Retrospective: Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors](http://arxiv.org/abs/2306.16093) #security</code></li>
<li>Summary: <p>Our ISCA 2014 paper provided the first scientific and detailed
characterization, analysis, and real-system demonstration of what is now
popularly known as the RowHammer phenomenon (or vulnerability) in modern
commodity DRAM chips, which are used as main memory in almost all modern
computing systems. It experimentally demonstrated that more than 80% of all
DRAM modules we tested from the three major DRAM vendors were vulnerable to the
RowHammer read disturbance phenomenon: one can predictably induce bitflips
(i.e., data corruption) in real DRAM modules by repeatedly accessing a DRAM row
and thus causing electrical disturbance to physically nearby rows. We showed
that a simple unprivileged user-level program induced RowHammer bitflips in
multiple real systems and suggested that a security attack can be built using
this proof-of-concept to hijack control of the system or cause other harm. To
solve the RowHammer problem, our paper examined seven different approaches
(including a novel probabilistic approach that has very low cost), some of
which influenced or were adopted in different industrial products.
</p></li>
</ul>

<p>Many later works from various research communities examined RowHammer,
building real security attacks, proposing new defenses, further analyzing the
problem at various (e.g., device/circuit, architecture, and system) levels, and
exploiting RowHammer for various purposes (e.g., to reverse-engineer DRAM
chips). Industry has worked to mitigate the problem, changing both memory
controllers and DRAM standards/chips. Two major DRAM vendors finally wrote
papers on the topic in 2023, describing their current approaches to mitigate
RowHammer. Research &amp; development on RowHammer in both academia &amp; industry
continues to be very active and fascinating.
</p>
<p>This short retrospective provides a brief analysis of our ISCA 2014 paper and
its impact.
</p>

<h2>privacy</h2>
<h3>Title: Differentially Private Video Activity Recognition. (arXiv:2306.15742v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15742">http://arxiv.org/abs/2306.15742</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15742] Differentially Private Video Activity Recognition](http://arxiv.org/abs/2306.15742) #privacy</code></li>
<li>Summary: <p>In recent years, differential privacy has seen significant advancements in
image classification; however, its application to video activity recognition
remains under-explored. This paper addresses the challenges of applying
differential privacy to video activity recognition, which primarily stem from:
(1) a discrepancy between the desired privacy level for entire videos and the
nature of input data processed by contemporary video architectures, which are
typically short, segmented clips; and (2) the complexity and sheer size of
video datasets relative to those in image classification, which render
traditional differential privacy methods inadequate. To tackle these issues, we
propose Multi-Clip DP-SGD, a novel framework for enforcing video-level
differential privacy through clip-based classification models. This method
samples multiple clips from each video, averages their gradients, and applies
gradient clipping in DP-SGD without incurring additional privacy loss.
Moreover, we incorporate a parameter-efficient transfer learning strategy to
make the model scalable for large-scale video datasets. Through extensive
evaluations on the UCF-101 and HMDB-51 datasets, our approach exhibits
impressive performance, achieving 81% accuracy with a privacy budget of
epsilon=5 on UCF-101, marking a 76% improvement compared to a direct
application of DP-SGD. Furthermore, we demonstrate that our transfer learning
strategy is versatile and can enhance differentially private image
classification across an array of datasets including CheXpert, ImageNet,
CIFAR-10, and CIFAR-100.
</p></li>
</ul>

<h3>Title: Malware Finances and Operations: a Data-Driven Study of the Value Chain for Infections and Compromised Access. (arXiv:2306.15726v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15726">http://arxiv.org/abs/2306.15726</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15726] Malware Finances and Operations: a Data-Driven Study of the Value Chain for Infections and Compromised Access](http://arxiv.org/abs/2306.15726) #privacy</code></li>
<li>Summary: <p>We investigate the criminal market dynamics of infostealer malware and
publish three evidence datasets on malware infections and trade. We justify the
value chain between illicit enterprises using the datasets, compare the prices
and added value, and use the value chain to identify the most effective
countermeasures.
</p></li>
</ul>

<p>We begin by examining infostealer malware victim logs shared by actors on
hacking forums, and extract victim information and mask sensitive data to
protect privacy. We find access to these same victims for sale at Genesis
Market. This technically sophisticated marketplace provides its own browser to
access victim's online accounts. We collect a second dataset and discover that
91% of prices fall between 1--20 US dollars, with a median of 5 US dollars.
</p>
<p>Database Market sells access to compromised online accounts. We produce yet
another dataset, finding 91% of prices fall between 1--30 US dollars, with a
median of 7 US dollars.
</p>

<h3>Title: Probing the Transition to Dataset-Level Privacy in ML Models Using an Output-Specific and Data-Resolved Privacy Profile. (arXiv:2306.15790v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15790">http://arxiv.org/abs/2306.15790</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15790] Probing the Transition to Dataset-Level Privacy in ML Models Using an Output-Specific and Data-Resolved Privacy Profile](http://arxiv.org/abs/2306.15790) #privacy</code></li>
<li>Summary: <p>Differential privacy (DP) is the prevailing technique for protecting user
data in machine learning models. However, deficits to this framework include a
lack of clarity for selecting the privacy budget $\epsilon$ and a lack of
quantification for the privacy leakage for a particular data row by a
particular trained model. We make progress toward these limitations and a new
perspective by which to visualize DP results by studying a privacy metric that
quantifies the extent to which a model trained on a dataset using a DP
mechanism is ``covered" by each of the distributions resulting from training on
neighboring datasets. We connect this coverage metric to what has been
established in the literature and use it to rank the privacy of individual
samples from the training set in what we call a privacy profile. We
additionally show that the privacy profile can be used to probe an observed
transition to indistinguishability that takes place in the neighboring
distributions as $\epsilon$ decreases, which we suggest is a tool that can
enable the selection of $\epsilon$ by the ML practitioner wishing to make use
of DP.
</p></li>
</ul>

<h3>Title: Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15865">http://arxiv.org/abs/2306.15865</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15865] Differentially Private Distributed Estimation and Learning](http://arxiv.org/abs/2306.15865) #privacy</code></li>
<li>Summary: <p>We study distributed estimation and learning problems in a networked
environment in which agents exchange information to estimate unknown
statistical properties of random variables from their privately observed
samples. By exchanging information about their private observations, the agents
can collectively estimate the unknown quantities, but they also face privacy
risks. The goal of our aggregation schemes is to combine the observed data
efficiently over time and across the network, while accommodating the privacy
needs of the agents and without any coordination beyond their local
neighborhoods. Our algorithms enable the participating agents to estimate a
complete sufficient statistic from private signals that are acquired offline or
online over time, and to preserve the privacy of their signals and network
neighborhoods. This is achieved through linear aggregation schemes with
adjusted randomization schemes that add noise to the exchanged estimates
subject to differential privacy (DP) constraints. In every case, we demonstrate
the efficiency of our algorithms by proving convergence to the estimators of a
hypothetical, omniscient observer that has central access to all of the
signals. We also provide convergence rate analysis and finite-time performance
guarantees and show that the noise that minimizes the convergence time to the
best estimates is the Laplace noise, with parameters corresponding to each
agent's sensitivity to their signal and network characteristics. Finally, to
supplement and validate our theoretical results, we run experiments on
real-world data from the US Power Grid Network and electric consumption data
from German Households to estimate the average power consumption of power
stations and households under all privacy regimes.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Fast Recognition of birds in offshore wind farms based on an improved deep learning model. (arXiv:2306.16019v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16019">http://arxiv.org/abs/2306.16019</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16019] Fast Recognition of birds in offshore wind farms based on an improved deep learning model](http://arxiv.org/abs/2306.16019) #protect</code></li>
<li>Summary: <p>The safety of wind turbines is a prerequisite for the stable operation of
offshore wind farms. However, bird damage poses a direct threat to the safe
operation of wind turbines and wind turbine blades. In addition, millions of
birds are killed by wind turbines every year. In order to protect the
ecological environment and maintain the safe operation of offshore wind
turbines, and to address the problem of the low detection capability of current
target detection algorithms in low-light environments such as at night, this
paper proposes a method to improve the network performance by integrating the
CBAM attention mechanism and the RetinexNet network into YOLOv5. First, the
training set images are fed into the YOLOv5 network with integrated CBAM
attention module for training, and the optimal weight model is stored. Then,
low-light images are enhanced and denoised using Decom-Net and Enhance-Net, and
the accuracy is tested on the optimal weight model. In addition, the k-means++
clustering algorithm is used to optimise the anchor box selection method, which
solves the problem of unstable initial centroids and achieves better clustering
results. Experimental results show that the accuracy of this model in bird
detection tasks can reach 87.40%, an increase of 21.25%. The model can detect
birds near wind turbines in real time and shows strong stability in night,
rainy and shaky conditions, proving that the model can ensure the safe and
stable operation of wind turbines.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks. (arXiv:2306.16415v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16415">http://arxiv.org/abs/2306.16415</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16415] On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks](http://arxiv.org/abs/2306.16415) #defense</code></li>
<li>Summary: <p>The increasing access to data poses both opportunities and risks in deep
learning, as one can manipulate the behaviors of deep learning models with
malicious training samples. Such attacks are known as data poisoning. Recent
advances in defense strategies against data poisoning have highlighted the
effectiveness of aggregation schemes in achieving state-of-the-art results in
certified poisoning robustness. However, the practical implications of these
approaches remain unclear. Here we focus on Deep Partition Aggregation, a
representative aggregation defense, and assess its practical aspects, including
efficiency, performance, and robustness. For evaluations, we use ImageNet
resized to a resolution of 64 by 64 to enable evaluations at a larger scale
than previous ones. Firstly, we demonstrate a simple yet practical approach to
scaling base models, which improves the efficiency of training and inference
for aggregation defenses. Secondly, we provide empirical evidence supporting
the data-to-complexity ratio, i.e. the ratio between the data set size and
sample complexity, as a practical estimation of the maximum number of base
models that can be deployed while preserving accuracy. Last but not least, we
point out how aggregation defenses boost poisoning robustness empirically
through the poisoning overfitting phenomenon, which is the key underlying
mechanism for the empirical poisoning robustness of aggregations. Overall, our
findings provide valuable insights for practical implementations of aggregation
defenses to mitigate the threat of data poisoning.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Face Morphing Attack Detection with Denoising Diffusion Probabilistic Models. (arXiv:2306.15733v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15733">http://arxiv.org/abs/2306.15733</a></li>
<li>Code URL: <a href="https://github.com/MIvanovska/MAD-DDPM">https://github.com/MIvanovska/MAD-DDPM</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15733] Face Morphing Attack Detection with Denoising Diffusion Probabilistic Models](http://arxiv.org/abs/2306.15733) #attack</code></li>
<li>Summary: <p>Morphed face images have recently become a growing concern for existing face
verification systems, as they are relatively easy to generate and can be used
to impersonate someone's identity for various malicious purposes. Efficient
Morphing Attack Detection (MAD) that generalizes well across different morphing
techniques is, therefore, of paramount importance. Existing MAD techniques
predominantly rely on discriminative models that learn from examples of bona
fide and morphed images and, as a result, often exhibit sub-optimal
generalization performance when confronted with unknown types of morphing
attacks. To address this problem, we propose a novel, diffusion-based MAD
method in this paper that learns only from the characteristics of bona fide
images. Various forms of morphing attacks are then detected by our model as
out-of-distribution samples. We perform rigorous experiments over four
different datasets (CASIA-WebFace, FRLL-Morphs, FERET-Morphs and FRGC-Morphs)
and compare the proposed solution to both discriminatively-trained and
once-class MAD models. The experimental results show that our MAD model
achieves highly competitive results on all considered datasets.
</p></li>
</ul>

<h3>Title: IMPOSITION: Implicit Backdoor Attack through Scenario Injection. (arXiv:2306.15755v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15755">http://arxiv.org/abs/2306.15755</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15755] IMPOSITION: Implicit Backdoor Attack through Scenario Injection](http://arxiv.org/abs/2306.15755) #attack</code></li>
<li>Summary: <p>This paper presents a novel backdoor attack called IMPlicit BackdOor Attack
through Scenario InjecTION (IMPOSITION) that does not require direct poisoning
of the training data. Instead, the attack leverages a realistic scenario from
the training data as a trigger to manipulate the model's output during
inference. This type of attack is particularly dangerous as it is stealthy and
difficult to detect. The paper focuses on the application of this attack in the
context of Autonomous Driving (AD) systems, specifically targeting the
trajectory prediction module. To implement the attack, we design a trigger
mechanism that mimics a set of cloned behaviors in the driving scene, resulting
in a scenario that triggers the attack. The experimental results demonstrate
that IMPOSITION is effective in attacking trajectory prediction models while
maintaining high performance in untargeted scenarios. Our proposed method
highlights the growing importance of research on the trustworthiness of Deep
Neural Network (DNN) models, particularly in safety-critical applications.
Backdoor attacks pose a significant threat to the safety and reliability of DNN
models, and this paper presents a new perspective on backdooring DNNs. The
proposed IMPOSITION paradigm and the demonstration of its severity in the
context of AD systems are significant contributions of this paper. We highlight
the impact of the proposed attacks via empirical studies showing how IMPOSITION
can easily compromise the safety of AD systems.
</p></li>
</ul>

<h3>Title: Evaluating Similitude and Robustness of Deep Image Denoising Models via Adversarial Attack. (arXiv:2306.16050v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16050">http://arxiv.org/abs/2306.16050</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16050] Evaluating Similitude and Robustness of Deep Image Denoising Models via Adversarial Attack](http://arxiv.org/abs/2306.16050) #attack</code></li>
<li>Summary: <p>Deep neural networks (DNNs) have a wide range of applications in the field of
image denoising, and they are superior to traditional image denoising. However,
DNNs inevitably show vulnerability, which is the weak robustness in the face of
adversarial attacks. In this paper, we find some similitudes between existing
deep image denoising methods, as they are consistently fooled by adversarial
attacks. First, denoising-PGD is proposed which is a denoising model full
adversarial method. The current mainstream non-blind denoising models (DnCNN,
FFDNet, ECNDNet, BRDNet), blind denoising models (DnCNN-B, Noise2Noise,
RDDCNN-B, FAN), and plug-and-play (DPIR, CurvPnP) and unfolding denoising
models (DeamNet) applied to grayscale and color images can be attacked by the
same set of methods. Second, since the transferability of denoising-PGD is
prominent in the image denoising task, we design experiments to explore the
characteristic of the latent under the transferability. We correlate
transferability with similitude and conclude that the deep image denoising
models have high similitude. Third, we investigate the characteristic of the
adversarial space and use adversarial training to complement the vulnerability
of deep image denoising to adversarial attacks on image denoising. Finally, we
constrain this adversarial attack method and propose the L2-denoising-PGD image
denoising adversarial attack method that maintains the Gaussian distribution.
Moreover, the model-driven image denoising BM3D shows some resistance in the
face of adversarial attacks.
</p></li>
</ul>

<h3>Title: Distributional Modeling for Location-Aware Adversarial Patches. (arXiv:2306.16131v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16131">http://arxiv.org/abs/2306.16131</a></li>
<li>Code URL: <a href="https://github.com/heathcliff-saku/dopatch">https://github.com/heathcliff-saku/dopatch</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16131] Distributional Modeling for Location-Aware Adversarial Patches](http://arxiv.org/abs/2306.16131) #attack</code></li>
<li>Summary: <p>Adversarial patch is one of the important forms of performing adversarial
attacks in the physical world. To improve the naturalness and aggressiveness of
existing adversarial patches, location-aware patches are proposed, where the
patch's location on the target object is integrated into the optimization
process to perform attacks. Although it is effective, efficiently finding the
optimal location for placing the patches is challenging, especially under the
black-box attack settings. In this paper, we propose the Distribution-Optimized
Adversarial Patch (DOPatch), a novel method that optimizes a multimodal
distribution of adversarial locations instead of individual ones. DOPatch has
several benefits: Firstly, we find that the locations' distributions across
different models are pretty similar, and thus we can achieve efficient
query-based attacks to unseen models using a distributional prior optimized on
a surrogate model. Secondly, DOPatch can generate diverse adversarial samples
by characterizing the distribution of adversarial locations. Thus we can
improve the model's robustness to location-aware patches via carefully designed
Distributional-Modeling Adversarial Training (DOP-DMAT). We evaluate DOPatch on
various face recognition and image recognition tasks and demonstrate its
superiority and efficiency over existing methods. We also conduct extensive
ablation studies and analyses to validate the effectiveness of our method and
provide insights into the distribution of adversarial locations.
</p></li>
</ul>

<h3>Title: Condorcet Attack Against Fair Transaction Ordering. (arXiv:2306.15743v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15743">http://arxiv.org/abs/2306.15743</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15743] Condorcet Attack Against Fair Transaction Ordering](http://arxiv.org/abs/2306.15743) #attack</code></li>
<li>Summary: <p>We introduce the Condorcet attack, a new threat to fair transaction ordering.
Specifically, the attack undermines batch-order-fairness, the strongest notion
of transaction fair ordering proposed to date. The batch-order-fairness
guarantees that a transaction tx is ordered before tx' if a majority of nodes
in the system receive tx before tx'; the only exception (due to an
impossibility result) is when tx and tx' fall into a so-called "Condorcet
cycle". When this happens, tx and tx' along with other transactions within the
cycle are placed in a batch, and any unfairness inside a batch is ignored. In
the Condorcet attack, an adversary attempts to undermine the system's fairness
by imposing Condorcet cycles to the system. In this work, we show that the
adversary can indeed impose a Condorcet cycle by submitting as few as two
otherwise legitimate transactions to the system. Remarkably, the adversary
(e.g., a malicious client) can achieve this even when all the nodes in the
system behave honestly. A notable feature of the attack is that it is capable
of "trapping" transactions that do not naturally fall inside a cycle, i.e.
those that are transmitted at significantly different times (with respect to
the network latency). To mitigate the attack, we propose three methods based on
three different complementary approaches. We show the effectiveness of the
proposed mitigation methods through simulations, and explain their limitations.
</p></li>
</ul>

<h3>Title: Can Twitter be used to Acquire Reliable Alerts against Novel Cyber Attacks?. (arXiv:2306.16087v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16087">http://arxiv.org/abs/2306.16087</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16087] Can Twitter be used to Acquire Reliable Alerts against Novel Cyber Attacks?](http://arxiv.org/abs/2306.16087) #attack</code></li>
<li>Summary: <p>Time-relevant and accurate threat information from public domains are
essential for cyber security. In a constantly evolving threat landscape, such
information assists security researchers in thwarting attack strategies. In
this work, we collect and analyze threat-related information from Twitter to
extract intelligence for proactive security. We first use a convolutional
neural network to classify the tweets as containing or not valuable threat
indicators. In particular, to gather threat intelligence from social media, the
proposed approach collects pertinent Indicators of Compromise (IoCs) from
tweets, such as IP addresses, URLs, File hashes, domain addresses, and CVE IDs.
Then, we analyze the IoCs to confirm whether they are reliable and valuable for
threat intelligence using performance indicators, such as correctness,
timeliness, and overlap. We also evaluate how fast Twitter shares IoCs compared
to existing threat intelligence services. Furthermore, through machine learning
models, we classify Twitter accounts as either automated or human-operated and
delve into the role of bot accounts in disseminating cyber threat information
on social media. Our results demonstrate that Twitter is growing into a
powerful platform for gathering precise and pertinent malware IoCs and a
reliable source for mining threat intelligence.
</p></li>
</ul>

<h3>Title: Seeing is Believing: Detecting Sybil Attack in FANET by Matching Visual and Auditory Domains. (arXiv:2306.16339v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16339">http://arxiv.org/abs/2306.16339</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16339] Seeing is Believing: Detecting Sybil Attack in FANET by Matching Visual and Auditory Domains](http://arxiv.org/abs/2306.16339) #attack</code></li>
<li>Summary: <p>The flying ad hoc network (FANET) will play a crucial role in the B5G/6G era
since it provides wide coverage and on-demand deployment services in a
distributed manner. The detection of Sybil attacks is essential to ensure
trusted communication in FANET. Nevertheless, the conventional methods only
utilize the untrusted information that UAV nodes passively <code>heard'' from the</code>auditory" domain (AD), resulting in severe communication disruptions and even
collision accidents. In this paper, we present a novel VA-matching solution
that matches the neighbors observed from both the AD and the <code>visual'' domain
(VD), which is the first solution that enables UAVs to accurately correlate
what they</code>see'' from VD and ``hear'' from AD to detect the Sybil attacks.
Relative entropy is utilized to describe the similarity of observed
characteristics from dual domains. The dynamic weight algorithm is proposed to
distinguish neighbors according to the characteristics' popularity. The
matching model of neighbors observed from AD and VD is established and solved
by the vampire bat optimizer. Experiment results show that the proposed
VA-matching solution removes the unreliability of individual characteristics
and single domains. It significantly outperforms the conventional RSSI-based
method in detecting Sybil attacks. Furthermore, it has strong robustness and
achieves high precision and recall rates.
</p></li>
</ul>

<h3>Title: The Power of Telemetry: Uncovering Software-Based Side-Channel Attacks on Apple M1/M2 Systems. (arXiv:2306.16391v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16391">http://arxiv.org/abs/2306.16391</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16391] The Power of Telemetry: Uncovering Software-Based Side-Channel Attacks on Apple M1/M2 Systems](http://arxiv.org/abs/2306.16391) #attack</code></li>
<li>Summary: <p>Power analysis is a class of side-channel attacks, where power consumption
data is used to infer sensitive information and extract secrets from a system.
Traditionally, such attacks required physical access to the target, as well as
specialized devices to measure the power consumption with enough precision. The
PLATYPUS attack has shown that on-chip power meter capabilities exposed to a
software interface might form a new class of power side-channel attacks. This
paper presents a software-based power side-channel attack on Apple Silicon
M1/M2 platforms, exploiting the System Management Controller (SMC) and its
power-related keys, which provides access to the on-chip power meters through a
software interface to user space software. We observed data-dependent power
consumption reporting from such keys and analyzed the correlations between the
power consumption and the processed data. Our work also demonstrated how an
unprivileged user mode application successfully recovers bytes from an AES
encryption key from a cryptographic service supported by a kernel mode driver
in macOS. Furthermore, we discuss the impact of software-based power
side-channels in the industry, possible countermeasures, and the overall
implications of software interfaces for modern on-chip power management
systems.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Evidential Detection and Tracking Collaboration: New Problem, Benchmark and Algorithm for Robust Anti-UAV System. (arXiv:2306.15767v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15767">http://arxiv.org/abs/2306.15767</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15767] Evidential Detection and Tracking Collaboration: New Problem, Benchmark and Algorithm for Robust Anti-UAV System](http://arxiv.org/abs/2306.15767) #robust</code></li>
<li>Summary: <p>Unmanned Aerial Vehicles (UAVs) have been widely used in many areas,
including transportation, surveillance, and military. However, their potential
for safety and privacy violations is an increasing issue and highly limits
their broader applications, underscoring the critical importance of UAV
perception and defense (anti-UAV). Still, previous works have simplified such
an anti-UAV task as a tracking problem, where the prior information of UAVs is
always provided; such a scheme fails in real-world anti-UAV tasks (i.e. complex
scenes, indeterminate-appear and -reappear UAVs, and real-time UAV
surveillance). In this paper, we first formulate a new and practical anti-UAV
problem featuring the UAVs perception in complex scenes without prior UAVs
information. To benchmark such a challenging task, we propose the largest UAV
dataset dubbed AntiUAV600 and a new evaluation metric. The AntiUAV600 comprises
600 video sequences of challenging scenes with random, fast, and small-scale
UAVs, with over 723K thermal infrared frames densely annotated with bounding
boxes. Finally, we develop a novel anti-UAV approach via an evidential
collaboration of global UAVs detection and local UAVs tracking, which
effectively tackles the proposed problem and can serve as a strong baseline for
future research. Extensive experiments show our method outperforms SOTA
approaches and validate the ability of AntiUAV600 to enhance UAV perception
performance due to its large scale and complexity. Our dataset, pretrained
models, and source codes will be released publically.
</p></li>
</ul>

<h3>Title: Angle Sensitive Pixels for Lensless Imaging on Spherical Sensors. (arXiv:2306.15953v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15953">http://arxiv.org/abs/2306.15953</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15953] Angle Sensitive Pixels for Lensless Imaging on Spherical Sensors](http://arxiv.org/abs/2306.15953) #robust</code></li>
<li>Summary: <p>We propose OrbCam, a lensless architecture for imaging with spherical
sensors. Prior work in lensless imager techniques have focused largely on using
planar sensors; for such designs, it is important to use a modulation element,
e.g. amplitude or phase masks, to construct a invertible imaging system. In
contrast, we show that the diversity of pixel orientations on a curved surface
is sufficient to improve the conditioning of the mapping between the scene and
the sensor. Hence, when imaging on a spherical sensor, all pixels can have the
same angular response function such that the lensless imager is comprised of
pixels that are identical to each other and differ only in their orientations.
We provide the computational tools for the design of the angular response of
the pixels in a spherical sensor that leads to well-conditioned and
noise-robust measurements. We validate our design in both simulation and a lab
prototype. The implications of our design is that the lensless imaging can be
enabled easily for curved and flexible surfaces thereby opening up a new set of
application domains.
</p></li>
</ul>

<h3>Title: Bridging the Gap: Neural Collapse Inspired Prompt Tuning for Generalization under Class Imbalance. (arXiv:2306.15955v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15955">http://arxiv.org/abs/2306.15955</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15955] Bridging the Gap: Neural Collapse Inspired Prompt Tuning for Generalization under Class Imbalance](http://arxiv.org/abs/2306.15955) #robust</code></li>
<li>Summary: <p>Large-scale vision-language (V-L) models have demonstrated remarkable
generalization capabilities for downstream tasks through prompt tuning.
However, their performance suffers significantly in the presence of class
imbalance, a common issue in real-world scenarios. In this paper, we
investigate the effects of class imbalance on the generalization performance of
V-L models and extend Neural Collapse phenomenon to these models, revealing the
geometric reasons behind the impact of class imbalance on their generalization
ability. To address this problem, we propose Neural Collapse based Prompt
Tuning (NPT), a novel method that optimizes prompts so that both text and image
features satisfy the same simplex ETF structure. NPT incorporates two
regularization terms, geometric de-biasing and multi-modal isomorphism, to
enhance the robustness of V-L models under class imbalance conditions while
maintaining their generalization capabilities. Our comprehensive experiments
show that NPT outperforms existing prompt learning techniques across 11 diverse
image recognition datasets, achieving an absolute average gain of 2.63\% for
novel classes and 2.47\% for harmonic mean when facing imbalanced data.
</p></li>
</ul>

<h3>Title: Lifelong Change Detection: Continuous Domain Adaptation for Small Object Change Detection in Every Robot Navigation. (arXiv:2306.16086v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16086">http://arxiv.org/abs/2306.16086</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16086] Lifelong Change Detection: Continuous Domain Adaptation for Small Object Change Detection in Every Robot Navigation](http://arxiv.org/abs/2306.16086) #robust</code></li>
<li>Summary: <p>The recently emerging research area in robotics, ground view change
detection, suffers from its ill-posed-ness because of visual uncertainty
combined with complex nonlinear perspective projection. To regularize the
ill-posed-ness, the commonly applied supervised learning methods (e.g.,
CSCD-Net) rely on manually annotated high-quality object-class-specific priors.
In this work, we consider general application domains where no manual
annotation is available and present a fully self-supervised approach. The
present approach adopts the powerful and versatile idea that object changes
detected during everyday robot navigation can be reused as additional priors to
improve future change detection tasks. Furthermore, a robustified framework is
implemented and verified experimentally in a new challenging practical
application scenario: ground-view small object change detection.
</p></li>
</ul>

<h3>Title: Mitigating the Accuracy-Robustness Trade-off via Multi-Teacher Adversarial Distillation. (arXiv:2306.16170v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16170">http://arxiv.org/abs/2306.16170</a></li>
<li>Code URL: <a href="https://github.com/zhaoshiji123/mtard-extension">https://github.com/zhaoshiji123/mtard-extension</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16170] Mitigating the Accuracy-Robustness Trade-off via Multi-Teacher Adversarial Distillation](http://arxiv.org/abs/2306.16170) #robust</code></li>
<li>Summary: <p>Adversarial training is a practical approach for improving the robustness of
deep neural networks against adversarial attacks. Although bringing reliable
robustness, the performance toward clean examples is negatively affected after
adversarial training, which means a trade-off exists between accuracy and
robustness. Recently, some studies have tried to use knowledge distillation
methods in adversarial training, achieving competitive performance in improving
the robustness but the accuracy for clean samples is still limited. In this
paper, to mitigate the accuracy-robustness trade-off, we introduce the
Multi-Teacher Adversarial Robustness Distillation (MTARD) to guide the model's
adversarial training process by applying a strong clean teacher and a strong
robust teacher to handle the clean examples and adversarial examples,
respectively. During the optimization process, to ensure that different
teachers show similar knowledge scales, we design the Entropy-Based Balance
algorithm to adjust the teacher's temperature and keep the teachers'
information entropy consistent. Besides, to ensure that the student has a
relatively consistent learning speed from multiple teachers, we propose the
Normalization Loss Balance algorithm to adjust the learning weights of
different types of knowledge. A series of experiments conducted on public
datasets demonstrate that MTARD outperforms the state-of-the-art adversarial
training and distillation methods against various adversarial attacks.
</p></li>
</ul>

<h3>Title: Pseudo-Bag Mixup Augmentation for Multiple Instance Learning Based Whole Slide Image Classification. (arXiv:2306.16180v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16180">http://arxiv.org/abs/2306.16180</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16180] Pseudo-Bag Mixup Augmentation for Multiple Instance Learning Based Whole Slide Image Classification](http://arxiv.org/abs/2306.16180) #robust</code></li>
<li>Summary: <p>Given the special situation of modeling gigapixel images, multiple instance
learning (MIL) has become one of the most important frameworks for Whole Slide
Image (WSI) classification. In current practice, most MIL networks often face
two unavoidable problems in training: i) insufficient WSI data, and ii) the
data memorization nature inherent in neural networks. These problems may hinder
MIL models from adequate and efficient training, suppressing the continuous
performance promotion of classification models on WSIs. Inspired by the basic
idea of Mixup, this paper proposes a Pseudo-bag Mixup (PseMix) data
augmentation scheme to improve the training of MIL models. This scheme
generalizes the Mixup strategy for general images to special WSIs via
pseudo-bags so as to be applied in MIL-based WSI classification. Cooperated by
pseudo-bags, our PseMix fulfills the critical size alignment and semantic
alignment in Mixup strategy. Moreover, it is designed as an efficient and
decoupled method adaptive to MIL, neither involving time-consuming operations
nor relying on MIL model predictions. Comparative experiments and ablation
studies are specially designed to evaluate the effectiveness and advantages of
our PseMix. Test results show that PseMix could often improve the performance
of MIL networks in WSI classification. Besides, it could also boost the
generalization capacity of MIL models, and promote their robustness to patch
occlusion and noisy labels. Our source code is available at
https://github.com/liupei101/PseMix.
</p></li>
</ul>

<h3>Title: MultiZoo &amp; MultiBench: A Standardized Toolkit for Multimodal Deep Learning. (arXiv:2306.16413v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16413">http://arxiv.org/abs/2306.16413</a></li>
<li>Code URL: <a href="https://github.com/pliang279/MultiBench">https://github.com/pliang279/MultiBench</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16413] MultiZoo &amp; MultiBench: A Standardized Toolkit for Multimodal Deep Learning](http://arxiv.org/abs/2306.16413) #robust</code></li>
<li>Summary: <p>Learning multimodal representations involves integrating information from
multiple heterogeneous sources of data. In order to accelerate progress towards
understudied modalities and tasks while ensuring real-world robustness, we
release MultiZoo, a public toolkit consisting of standardized implementations
of > 20 core multimodal algorithms and MultiBench, a large-scale benchmark
spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas.
Together, these provide an automated end-to-end machine learning pipeline that
simplifies and standardizes data loading, experimental setup, and model
evaluation. To enable holistic evaluation, we offer a comprehensive methodology
to assess (1) generalization, (2) time and space complexity, and (3) modality
robustness. MultiBench paves the way towards a better understanding of the
capabilities and limitations of multimodal models, while ensuring ease of use,
accessibility, and reproducibility. Our toolkits are publicly available, will
be regularly updated, and welcome inputs from the community.
</p></li>
</ul>

<h3>Title: MAT: Mixed-Strategy Game of Adversarial Training in Fine-tuning. (arXiv:2306.15826v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15826">http://arxiv.org/abs/2306.15826</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15826] MAT: Mixed-Strategy Game of Adversarial Training in Fine-tuning](http://arxiv.org/abs/2306.15826) #robust</code></li>
<li>Summary: <p>Fine-tuning large-scale pre-trained language models has been demonstrated
effective for various natural language processing (NLP) tasks. Previous studies
have established that incorporating adversarial training during the fine-tuning
stage can significantly enhance model generalization and robustness. However,
from the perspective of game theory, such utilizations of adversarial training
correspond to pure-strategy games, which are inherently limited in terms of the
scope of their strategies, thereby still having room for improvement. In order
to push the performance boundaries, we propose a novel Mixed-strategy
Adversarial Training algorithm (MAT). Methodologically, we derive the Nash
equilibrium of a mixed-strategy game for adversarial training using Entropy
Mirror Descent to establish MAT by sampling method. To verify the effectiveness
of MAT, we conducted extensive benchmark experiments on large-scale pre-trained
models, such as BERT and RoBERTa. MAT significantly outperforms the
state-of-the-art methods on both the GLUE and ANLI benchmarks in terms of
generalization and robustness.
</p></li>
</ul>

<h3>Title: DCT: Dual Channel Training of Action Embeddings for Reinforcement Learning with Large Discrete Action Spaces. (arXiv:2306.15913v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15913">http://arxiv.org/abs/2306.15913</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15913] DCT: Dual Channel Training of Action Embeddings for Reinforcement Learning with Large Discrete Action Spaces](http://arxiv.org/abs/2306.15913) #robust</code></li>
<li>Summary: <p>The ability to learn robust policies while generalizing over large discrete
action spaces is an open challenge for intelligent systems, especially in noisy
environments that face the curse of dimensionality. In this paper, we present a
novel framework to efficiently learn action embeddings that simultaneously
allow us to reconstruct the original action as well as to predict the expected
future state. We describe an encoder-decoder architecture for action embeddings
with a dual channel loss that balances between action reconstruction and state
prediction accuracy. We use the trained decoder in conjunction with a standard
reinforcement learning algorithm that produces actions in the embedding space.
Our architecture is able to outperform two competitive baselines in two diverse
environments: a 2D maze environment with more than 4000 discrete noisy actions,
and a product recommendation task that uses real-world e-commerce transaction
data. Empirical results show that the model results in cleaner action
embeddings, and the improved representations help learn better policies with
earlier convergence.
</p></li>
</ul>

<h3>Title: Graph Interpolation via Fast Fused-Gromovization. (arXiv:2306.15963v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15963">http://arxiv.org/abs/2306.15963</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15963] Graph Interpolation via Fast Fused-Gromovization](http://arxiv.org/abs/2306.15963) #robust</code></li>
<li>Summary: <p>Graph data augmentation has proven to be effective in enhancing the
generalizability and robustness of graph neural networks (GNNs) for graph-level
classifications. However, existing methods mainly focus on augmenting the graph
signal space and the graph structure space independently, overlooking their
joint interaction. This paper addresses this limitation by formulating the
problem as an optimal transport problem that aims to find an optimal strategy
for matching nodes between graphs considering the interactions between graph
structures and signals. To tackle this problem, we propose a novel graph mixup
algorithm dubbed FGWMixup, which leverages the Fused Gromov-Wasserstein (FGW)
metric space to identify a "midpoint" of the source graphs. To improve the
scalability of our approach, we introduce a relaxed FGW solver that accelerates
FGWMixup by enhancing the convergence rate from $\mathcal{O}(t^{-1})$ to
$\mathcal{O}(t^{-2})$. Extensive experiments conducted on five datasets,
utilizing both classic (MPNNs) and advanced (Graphormers) GNN backbones,
demonstrate the effectiveness of FGWMixup in improving the generalizability and
robustness of GNNs.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: A Novel Two Stream Decision Level Fusion of Vision and Inertial Sensors Data for Automatic Multimodal Human Activity Recognition System. (arXiv:2306.15765v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15765">http://arxiv.org/abs/2306.15765</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15765] A Novel Two Stream Decision Level Fusion of Vision and Inertial Sensors Data for Automatic Multimodal Human Activity Recognition System](http://arxiv.org/abs/2306.15765) #extraction</code></li>
<li>Summary: <p>This paper presents a novel multimodal human activity recognition system. It
uses a two-stream decision level fusion of vision and inertial sensors. In the
first stream, raw RGB frames are passed to a part affinity field-based pose
estimation network to detect the keypoints of the user. These keypoints are
then pre-processed and inputted in a sliding window fashion to a specially
designed convolutional neural network for the spatial feature extraction
followed by regularized LSTMs to calculate the temporal features. The outputs
of LSTM networks are then inputted to fully connected layers for
classification. In the second stream, data obtained from inertial sensors are
pre-processed and inputted to regularized LSTMs for the feature extraction
followed by fully connected layers for the classification. At this stage, the
SoftMax scores of two streams are then fused using the decision level fusion
which gives the final prediction. Extensive experiments are conducted to
evaluate the performance. Four multimodal standard benchmark datasets (UP-Fall
detection, UTD-MHAD, Berkeley-MHAD, and C-MHAD) are used for experimentations.
The accuracies obtained by the proposed system are 96.9 %, 97.6 %, 98.7 %, and
95.9 % respectively on the UP-Fall Detection, UTDMHAD, Berkeley-MHAD, and
C-MHAD datasets. These results are far superior than the current
state-of-the-art methods.
</p></li>
</ul>

<h3>Title: An Efficient Deep Convolutional Neural Network Model For Yoga Pose Recognition Using Single Images. (arXiv:2306.15768v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15768">http://arxiv.org/abs/2306.15768</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15768] An Efficient Deep Convolutional Neural Network Model For Yoga Pose Recognition Using Single Images](http://arxiv.org/abs/2306.15768) #extraction</code></li>
<li>Summary: <p>Pose recognition deals with designing algorithms to locate human body joints
in a 2D/3D space and run inference on the estimated joint locations for
predicting the poses. Yoga poses consist of some very complex postures. It
imposes various challenges on the computer vision algorithms like occlusion,
inter-class similarity, intra-class variability, viewpoint complexity, etc.
This paper presents YPose, an efficient deep convolutional neural network (CNN)
model to recognize yoga asanas from RGB images. The proposed model consists of
four steps as follows: (a) first, the region of interest (ROI) is segmented
using segmentation based approaches to extract the ROI from the original
images; (b) second, these refined images are passed to a CNN architecture based
on the backbone of EfficientNets for feature extraction; (c) third, dense
refinement blocks, adapted from the architecture of densely connected networks
are added to learn more diversified features; and (d) fourth, global average
pooling and fully connected layers are applied for the classification of the
multi-level hierarchy of the yoga poses. The proposed model has been tested on
the Yoga-82 dataset. It is a publicly available benchmark dataset for yoga pose
recognition. Experimental results show that the proposed model achieves the
state-of-the-art on this dataset. The proposed model obtained an accuracy of
93.28%, which is an improvement over the earlier state-of-the-art (79.35%) with
a margin of approximately 13.9%. The code will be made publicly available.
</p></li>
</ul>

<h3>Title: UTRNet: High-Resolution Urdu Text Recognition In Printed Documents. (arXiv:2306.15782v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15782">http://arxiv.org/abs/2306.15782</a></li>
<li>Code URL: <a href="https://github.com/abdur75648/UTRNet-High-Resolution-Urdu-Text-Recognition">https://github.com/abdur75648/UTRNet-High-Resolution-Urdu-Text-Recognition</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15782] UTRNet: High-Resolution Urdu Text Recognition In Printed Documents](http://arxiv.org/abs/2306.15782) #extraction</code></li>
<li>Summary: <p>In this paper, we propose a novel approach to address the challenges of
printed Urdu text recognition using high-resolution, multi-scale semantic
feature extraction. Our proposed UTRNet architecture, a hybrid CNN-RNN model,
demonstrates state-of-the-art performance on benchmark datasets. To address the
limitations of previous works, which struggle to generalize to the intricacies
of the Urdu script and the lack of sufficient annotated real-world data, we
have introduced the UTRSet-Real, a large-scale annotated real-world dataset
comprising over 11,000 lines and UTRSet-Synth, a synthetic dataset with 20,000
lines closely resembling real-world and made corrections to the ground truth of
the existing IIITH dataset, making it a more reliable resource for future
research. We also provide UrduDoc, a benchmark dataset for Urdu text line
detection in scanned documents. Additionally, we have developed an online tool
for end-to-end Urdu OCR from printed documents by integrating UTRNet with a
text detection model. Our work not only addresses the current limitations of
Urdu OCR but also paves the way for future research in this area and
facilitates the continued advancement of Urdu OCR technology. The project page
with source code, datasets, annotations, trained models, and online tool is
available at abdur75648.github.io/UTRNet.
</p></li>
</ul>

<h3>Title: AFPN: Asymptotic Feature Pyramid Network for Object Detection. (arXiv:2306.15988v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15988">http://arxiv.org/abs/2306.15988</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15988] AFPN: Asymptotic Feature Pyramid Network for Object Detection](http://arxiv.org/abs/2306.15988) #extraction</code></li>
<li>Summary: <p>Multi-scale features are of great importance in encoding objects with scale
variance in object detection tasks. A common strategy for multi-scale feature
extraction is adopting the classic top-down and bottom-up feature pyramid
networks. However, these approaches suffer from the loss or degradation of
feature information, impairing the fusion effect of non-adjacent levels. This
paper proposes an asymptotic feature pyramid network (AFPN) to support direct
interaction at non-adjacent levels. AFPN is initiated by fusing two adjacent
low-level features and asymptotically incorporates higher-level features into
the fusion process. In this way, the larger semantic gap between non-adjacent
levels can be avoided. Given the potential for multi-object information
conflicts to arise during feature fusion at each spatial location, adaptive
spatial fusion operation is further utilized to mitigate these inconsistencies.
We incorporate the proposed AFPN into both two-stage and one-stage object
detection frameworks and evaluate with the MS-COCO 2017 validation and test
datasets. Experimental evaluation shows that our method achieves more
competitive results than other state-of-the-art feature pyramid networks. The
code is available at
\href{https://github.com/gyyang23/AFPN}{https://github.com/gyyang23/AFPN}.
</p></li>
</ul>

<h3>Title: Learning to Pan-sharpening with Memories of Spatial Details. (arXiv:2306.16181v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16181">http://arxiv.org/abs/2306.16181</a></li>
<li>Code URL: <a href="https://github.com/zhao-tian-yi/learning-to-pan-sharpening-with-memories-of-spatial-details">https://github.com/zhao-tian-yi/learning-to-pan-sharpening-with-memories-of-spatial-details</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16181] Learning to Pan-sharpening with Memories of Spatial Details](http://arxiv.org/abs/2306.16181) #extraction</code></li>
<li>Summary: <p>Pan-sharpening, as one of the most commonly used techniques in remote sensing
systems, aims to inject spatial details from panchromatic images into
multi-spectral images to obtain high-resolution MS images. Since deep learning
has received widespread attention because of its powerful fitting ability and
efficient feature extraction, a variety of pan-sharpening methods have been
proposed to achieve remarkable performance. However, current pan-sharpening
methods usually require the paired PAN and MS images as the input, which limits
their usage in some scenarios. To address this issue, in this paper, we observe
that the spatial details from PAN images are mainly high-frequency cues, i.e.,
the edges reflect the contour of input PAN images. This motivates us to develop
a PAN-agnostic representation to store some base edges, so as to compose the
contour for the corresponding PAN image via them. As a result, we can perform
the pan-sharpening task with only the MS image when inference. To this end, a
memory-based network is adapted to extract and memorize the spatial details
during the training phase and is used to replace the process of obtaining
spatial information from PAN images when inference, which is called
Memory-based Spatial Details Network (MSDN). We finally integrate the proposed
MSDN module into the existing DL-based pan-sharpening methods to achieve an
end-to-end pan-sharpening network. With extensive experiments on the Gaofen1
and WorldView-4 satellites, we verify that our method constructs good spatial
details without PAN images and achieves the best performance. The code is
available at
https://github.com/Zhao-Tian-yi/Learning-to-Pan-sharpening-with-Memories-of-Spatial-Details.git.
</p></li>
</ul>

<h3>Title: Sentence-to-Label Generation Framework for Multi-task Learning of Japanese Sentence Classification and Named Entity Recognition. (arXiv:2306.15978v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15978">http://arxiv.org/abs/2306.15978</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15978] Sentence-to-Label Generation Framework for Multi-task Learning of Japanese Sentence Classification and Named Entity Recognition](http://arxiv.org/abs/2306.15978) #extraction</code></li>
<li>Summary: <p>Information extraction(IE) is a crucial subfield within natural language
processing. In this study, we introduce a Sentence Classification and Named
Entity Recognition Multi-task (SCNM) approach that combines Sentence
Classification (SC) and Named Entity Recognition (NER). We develop a
Sentence-to-Label Generation (SLG) framework for SCNM and construct a Wikipedia
dataset containing both SC and NER. Using a format converter, we unify input
formats and employ a generative model to generate SC-labels, NER-labels, and
associated text segments. We propose a Constraint Mechanism (CM) to improve
generated format accuracy. Our results show SC accuracy increased by 1.13
points and NER by 1.06 points in SCNM compared to standalone tasks, with CM
raising format accuracy from 63.61 to 100. The findings indicate mutual
reinforcement effects between SC and NER, and integration enhances both tasks'
performance.
</p></li>
</ul>

<h3>Title: cuSLINK: Single-linkage Agglomerative Clustering on the GPU. (arXiv:2306.16354v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16354">http://arxiv.org/abs/2306.16354</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16354] cuSLINK: Single-linkage Agglomerative Clustering on the GPU](http://arxiv.org/abs/2306.16354) #extraction</code></li>
<li>Summary: <p>In this paper, we propose cuSLINK, a novel and state-of-the-art reformulation
of the SLINK algorithm on the GPU which requires only $O(Nk)$ space and uses a
parameter $k$ to trade off space and time. We also propose a set of novel and
reusable building blocks that compose cuSLINK. These building blocks include
highly optimized computational patterns for $k$-NN graph construction, spanning
trees, and dendrogram cluster extraction. We show how we used our primitives to
implement cuSLINK end-to-end on the GPU, further enabling a wide range of
real-world data mining and machine learning applications that were once
intractable. In addition to being a primary computational bottleneck in the
popular HDBSCAN algorithm, the impact of our end-to-end cuSLINK algorithm spans
a large range of important applications, including cluster analysis in social
and computer networks, natural language processing, and computer vision. Users
can obtain cuSLINK at
https://docs.rapids.ai/api/cuml/latest/api/#agglomerative-clustering
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: NIPD: A Federated Learning Person Detection Benchmark Based on Real-World Non-IID Data. (arXiv:2306.15932v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15932">http://arxiv.org/abs/2306.15932</a></li>
<li>Code URL: <a href="https://github.com/ShenSuanZiZhen/NIID_Person_Detection">https://github.com/ShenSuanZiZhen/NIID_Person_Detection</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15932] NIPD: A Federated Learning Person Detection Benchmark Based on Real-World Non-IID Data](http://arxiv.org/abs/2306.15932) #federate</code></li>
<li>Summary: <p>Federated learning (FL), a privacy-preserving distributed machine learning,
has been rapidly applied in wireless communication networks. FL enables
Internet of Things (IoT) clients to obtain well-trained models while preventing
privacy leakage. Person detection can be deployed on edge devices with limited
computing power if combined with FL to process the video data directly at the
edge. However, due to the different hardware and deployment scenarios of
different cameras, the data collected by the camera present non-independent and
identically distributed (non-IID), and the global model derived from FL
aggregation is less effective. Meanwhile, existing research lacks public data
set for real-world FL object detection, which is not conducive to studying the
non-IID problem on IoT cameras. Therefore, we open source a non-IID IoT person
detection (NIPD) data set, which is collected from five different cameras. To
our knowledge, this is the first true device-based non-IID person detection
data set. Based on this data set, we explain how to establish a FL experimental
platform and provide a benchmark for non-IID person detection. NIPD is expected
to promote the application of FL and the security of smart city.
</p></li>
</ul>

<h3>Title: Multi-Site Clinical Federated Learning using Recursive and Attentive Models and NVFlare. (arXiv:2306.16367v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16367">http://arxiv.org/abs/2306.16367</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16367] Multi-Site Clinical Federated Learning using Recursive and Attentive Models and NVFlare](http://arxiv.org/abs/2306.16367) #federate</code></li>
<li>Summary: <p>The prodigious growth of digital health data has precipitated a mounting
interest in harnessing machine learning methodologies, such as natural language
processing (NLP), to scrutinize medical records, clinical notes, and other
text-based health information. Although NLP techniques have exhibited
substantial potential in augmenting patient care and informing clinical
decision-making, data privacy and adherence to regulations persist as critical
concerns. Federated learning (FL) emerges as a viable solution, empowering
multiple organizations to train machine learning models collaboratively without
disseminating raw data. This paper proffers a pragmatic approach to medical NLP
by amalgamating FL, NLP models, and the NVFlare framework, developed by NVIDIA.
We introduce two exemplary NLP models, the Long-Short Term Memory (LSTM)-based
model and Bidirectional Encoder Representations from Transformers (BERT), which
have demonstrated exceptional performance in comprehending context and
semantics within medical data. This paper encompasses the development of an
integrated framework that addresses data privacy and regulatory compliance
challenges while maintaining elevated accuracy and performance, incorporating
BERT pretraining, and comprehensively substantiating the efficacy of the
proposed approach.
</p></li>
</ul>

<h3>Title: VERTICES: Efficient Two-Party Vertical Federated Linear Model with TTP-aided Secret Sharing. (arXiv:2306.16139v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16139">http://arxiv.org/abs/2306.16139</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16139] VERTICES: Efficient Two-Party Vertical Federated Linear Model with TTP-aided Secret Sharing](http://arxiv.org/abs/2306.16139) #federate</code></li>
<li>Summary: <p>Vertical Federated Learning (VFL) has emerged as one of the most predominant
approaches for secure collaborative machine learning where the training data is
partitioned by features among multiple parties. Most VFL algorithms primarily
rely on two fundamental privacy-preserving techniques: Homomorphic Encryption
(HE) and secure Multi-Party Computation (MPC). Though generally considered with
stronger privacy guarantees, existing general-purpose MPC frameworks suffer
from expensive computation and communication overhead and are inefficient
especially under VFL settings. This study centers around MPC-based VFL
algorithms and presents a novel approach for two-party vertical federated
linear models via an efficient secret sharing (SS) scheme with a trusted
coordinator. Our approach can achieve significant acceleration of the training
procedure in vertical federated linear models of between 2.5x and 6.6x than
other existing MPC frameworks under the same security setting.
</p></li>
</ul>

<h3>Title: Federated Generative Learning with Foundation Models. (arXiv:2306.16064v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16064">http://arxiv.org/abs/2306.16064</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16064] Federated Generative Learning with Foundation Models](http://arxiv.org/abs/2306.16064) #federate</code></li>
<li>Summary: <p>Existing federated learning solutions focus on transmitting features,
parameters or gadients between clients and server, which suffer from serious
low-efficiency and privacy-leakage problems. Thanks to the emerging foundation
generative models, we propose a novel federated learning framework, namely
Federated Generative Learning, that transmits prompts associated with
distributed training data between clients and server. The informative training
data can be synthesized remotely based on received prompts containing little
privacy and the foundation generative models. The new framework possesses
multiple advantages, including improved communication efficiency, better
resilience to distribution shift, substantial performance gains, and enhanced
privacy protection, which are verified in extensive experiments on ImageNet and
DomainNet datasets.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Challenges of Zero-Shot Recognition with Vision-Language Models: Granularity and Correctness. (arXiv:2306.16048v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16048">http://arxiv.org/abs/2306.16048</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16048] Challenges of Zero-Shot Recognition with Vision-Language Models: Granularity and Correctness](http://arxiv.org/abs/2306.16048) #fair</code></li>
<li>Summary: <p>This paper investigates the challenges of applying vision-language models
(VLMs) to zero-shot visual recognition tasks in an open-world setting, with a
focus on contrastive vision-language models such as CLIP. We first examine the
performance of VLMs on concepts of different granularity levels. We propose a
way to fairly evaluate the performance discrepancy under two experimental
setups and find that VLMs are better at recognizing fine-grained concepts.
Furthermore, we find that the similarity scores from VLMs do not strictly
reflect the correctness of the textual inputs given visual input. We propose an
evaluation protocol to test our hypothesis that the scores can be biased
towards more informative descriptions, and the nature of the similarity score
between embedding makes it challenging for VLMs to recognize the correctness
between similar but wrong descriptions. Our study highlights the challenges of
using VLMs in open-world settings and suggests directions for future research
to improve their zero-shot capabilities.
</p></li>
</ul>

<h3>Title: Systematic analysis of the impact of label noise correction on ML Fairness. (arXiv:2306.15994v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15994">http://arxiv.org/abs/2306.15994</a></li>
<li>Code URL: <a href="https://github.com/reluzita/fair-lnc-evaluation">https://github.com/reluzita/fair-lnc-evaluation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15994] Systematic analysis of the impact of label noise correction on ML Fairness](http://arxiv.org/abs/2306.15994) #fair</code></li>
<li>Summary: <p>Arbitrary, inconsistent, or faulty decision-making raises serious concerns,
and preventing unfair models is an increasingly important challenge in Machine
Learning. Data often reflect past discriminatory behavior, and models trained
on such data may reflect bias on sensitive attributes, such as gender, race, or
age. One approach to developing fair models is to preprocess the training data
to remove the underlying biases while preserving the relevant information, for
example, by correcting biased labels. While multiple label noise correction
methods are available, the information about their behavior in identifying
discrimination is very limited. In this work, we develop an empirical
methodology to systematically evaluate the effectiveness of label noise
correction techniques in ensuring the fairness of models trained on biased
datasets. Our methodology involves manipulating the amount of label noise and
can be used with fairness benchmarks but also with standard ML datasets. We
apply the methodology to analyze six label noise correction methods according
to several fairness metrics on standard OpenML datasets. Our results suggest
that the Hybrid Label Noise Correction method achieves the best trade-off
between predictive performance and fairness. Clustering-Based Correction can
reduce discrimination the most, however, at the cost of lower predictive
performance.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Dynamic Path-Controllable Deep Unfolding Network for Compressive Sensing. (arXiv:2306.16060v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16060">http://arxiv.org/abs/2306.16060</a></li>
<li>Code URL: <a href="https://github.com/songjiechong/dpc-dun">https://github.com/songjiechong/dpc-dun</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16060] Dynamic Path-Controllable Deep Unfolding Network for Compressive Sensing](http://arxiv.org/abs/2306.16060) #interpretability</code></li>
<li>Summary: <p>Deep unfolding network (DUN) that unfolds the optimization algorithm into a
deep neural network has achieved great success in compressive sensing (CS) due
to its good interpretability and high performance. Each stage in DUN
corresponds to one iteration in optimization. At the test time, all the
sampling images generally need to be processed by all stages, which comes at a
price of computation burden and is also unnecessary for the images whose
contents are easier to restore. In this paper, we focus on CS reconstruction
and propose a novel Dynamic Path-Controllable Deep Unfolding Network (DPC-DUN).
DPC-DUN with our designed path-controllable selector can dynamically select a
rapid and appropriate route for each image and is slimmable by regulating
different performance-complexity tradeoffs. Extensive experiments show that our
DPC-DUN is highly flexible and can provide excellent performance and dynamic
adjustment to get a suitable tradeoff, thus addressing the main requirements to
become appealing in practice. Codes are available at
https://github.com/songjiechong/DPC-DUN.
</p></li>
</ul>

<h3>Title: Interpretable Anomaly Detection in Cellular Networks by Learning Concepts in Variational Autoencoders. (arXiv:2306.15938v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15938">http://arxiv.org/abs/2306.15938</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15938] Interpretable Anomaly Detection in Cellular Networks by Learning Concepts in Variational Autoencoders](http://arxiv.org/abs/2306.15938) #interpretability</code></li>
<li>Summary: <p>This paper addresses the challenges of detecting anomalies in cellular
networks in an interpretable way and proposes a new approach using variational
autoencoders (VAEs) that learn interpretable representations of the latent
space for each Key Performance Indicator (KPI) in the dataset. This enables the
detection of anomalies based on reconstruction loss and Z-scores. We ensure the
interpretability of the anomalies via additional information centroids (c)
using the K-means algorithm to enhance representation learning. We evaluate the
performance of the model by analyzing patterns in the latent dimension for
specific KPIs and thereby demonstrate the interpretability and anomalies. The
proposed framework offers a faster and autonomous solution for detecting
anomalies in cellular networks and showcases the potential of deep
learning-based algorithms in handling big data.
</p></li>
</ul>

<h3>Title: Structure in Reinforcement Learning: A Survey and Open Problems. (arXiv:2306.16021v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16021">http://arxiv.org/abs/2306.16021</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16021] Structure in Reinforcement Learning: A Survey and Open Problems](http://arxiv.org/abs/2306.16021) #interpretability</code></li>
<li>Summary: <p>Reinforcement Learning (RL), bolstered by the expressive capabilities of Deep
Neural Networks (DNNs) for function approximation, has demonstrated
considerable success in numerous applications. However, its practicality in
addressing a wide range of real-world scenarios, characterized by diverse and
unpredictable dynamics, noisy signals, and large state and action spaces,
remains limited. This limitation stems from issues such as poor data
efficiency, limited generalization capabilities, a lack of safety guarantees,
and the absence of interpretability, among other factors. To overcome these
challenges and improve performance across these crucial metrics, one promising
avenue is to incorporate additional structural information about the problem
into the RL learning process. Various sub-fields of RL have proposed methods
for incorporating such inductive biases. We amalgamate these diverse
methodologies under a unified framework, shedding light on the role of
structure in the learning problem, and classify these methods into distinct
patterns of incorporating structure. By leveraging this comprehensive
framework, we provide valuable insights into the challenges associated with
structured RL and lay the groundwork for a design pattern perspective on RL
research. This novel perspective paves the way for future advancements and aids
in the development of more effective and efficient RL algorithms that can
potentially handle real-world scenarios better.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h3>Title: Content-Aware Quantization Index Modulation:Leveraging Data Statistics for Enhanced Image Watermarking. (arXiv:2306.15896v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15896">http://arxiv.org/abs/2306.15896</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15896] Content-Aware Quantization Index Modulation:Leveraging Data Statistics for Enhanced Image Watermarking](http://arxiv.org/abs/2306.15896) #watermark</code></li>
<li>Summary: <p>Image watermarking techniques have continuously evolved to address new
challenges and incorporate advanced features. The advent of data-driven
approaches has enabled the processing and analysis of large volumes of data,
extracting valuable insights and patterns. In this paper, we propose two
content-aware quantization index modulation (QIM) algorithms: Content-Aware QIM
(CA-QIM) and Content-Aware Minimum Distortion QIM (CAMD-QIM). These algorithms
aim to improve the embedding distortion of QIM-based watermarking schemes by
considering the statistics of the cover signal vectors and messages. CA-QIM
introduces a canonical labeling approach, where the closest coset to each cover
vector is determined during the embedding process. An adjacency matrix is
constructed to capture the relationships between the cover vectors and
messages. CAMD-QIM extends the concept of minimum distortion (MD) principle to
content-aware QIM. Instead of quantizing the carriers to lattice points,
CAMD-QIM quantizes them to close points in the correct decoding region.
Canonical labeling is also employed in CAMD-QIM to enhance its performance.
Simulation results demonstrate the effectiveness of CA-QIM and CAMD-QIM in
reducing embedding distortion compared to traditional QIM. The combination of
canonical labeling and the minimum distortion principle proves to be powerful,
minimizing the need for changes to most cover vectors/carriers. These
content-aware QIM algorithms provide improved performance and robustness for
watermarking applications.
</p></li>
</ul>

<h2>diffusion</h2>
<h3>Title: Approximated Prompt Tuning for Vision-Language Pre-trained Models. (arXiv:2306.15706v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15706">http://arxiv.org/abs/2306.15706</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15706] Approximated Prompt Tuning for Vision-Language Pre-trained Models](http://arxiv.org/abs/2306.15706) #diffusion</code></li>
<li>Summary: <p>Prompt tuning is a parameter-efficient way to deploy large-scale pre-trained
models to downstream tasks by adding task-specific tokens. In terms of
vision-language pre-trained (VLP) models, prompt tuning often requires a large
number of learnable tokens to bridge the gap between the pre-training and
downstream tasks, which greatly exacerbates the already high computational
overhead. In this paper, we revisit the principle of prompt tuning for
Transformer-based VLP models and reveal that the impact of soft prompt tokens
can be actually approximated via independent information diffusion steps,
thereby avoiding the expensive global attention modeling and reducing the
computational complexity to a large extent. Based on this finding, we propose a
novel Approximated Prompt Tuning (APT) approach towards efficient VL transfer
learning. To validate APT, we apply it to two representative VLP models, namely
ViLT and METER, and conduct extensive experiments on a bunch of downstream
tasks. Meanwhile, the generalization of APT is also validated on CLIP for image
classification. The experimental results not only show the superior performance
gains and computation efficiency of APT against the conventional prompt tuning
methods, e.g., +6.6% accuracy and -64.62% additional computation overhead on
METER, but also confirm its merits over other parameter-efficient transfer
learning approaches.
</p></li>
</ul>

<h3>Title: Easing Color Shifts in Score-Based Diffusion Models. (arXiv:2306.15832v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15832">http://arxiv.org/abs/2306.15832</a></li>
<li>Code URL: <a href="https://github.com/bischtob/easing-color-shifts">https://github.com/bischtob/easing-color-shifts</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15832] Easing Color Shifts in Score-Based Diffusion Models](http://arxiv.org/abs/2306.15832) #diffusion</code></li>
<li>Summary: <p>Generated images of score-based models can suffer from errors in their
spatial means, an effect, referred to as a color shift, which grows for larger
images. This paper introduces a computationally inexpensive solution to
mitigate color shifts in score-based diffusion models. We propose a simple
nonlinear bypass connection in the score network, designed to process the
spatial mean of the input and to predict the mean of the score function. This
network architecture substantially improves the resulting spatial means of the
generated images, and we show that the improvement is approximately independent
of the size of the generated images. As a result, our solution offers a
comparatively inexpensive solution for the color shift problem across image
sizes. Lastly, we discuss the origin of color shifts in an idealized setting in
order to motivate our approach.
</p></li>
</ul>

<h3>Title: SVNR: Spatially-variant Noise Removal with Denoising Diffusion. (arXiv:2306.16052v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16052">http://arxiv.org/abs/2306.16052</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16052] SVNR: Spatially-variant Noise Removal with Denoising Diffusion](http://arxiv.org/abs/2306.16052) #diffusion</code></li>
<li>Summary: <p>Denoising diffusion models have recently shown impressive results in
generative tasks. By learning powerful priors from huge collections of training
images, such models are able to gradually modify complete noise to a clean
natural image via a sequence of small denoising steps, seemingly making them
well-suited for single image denoising. However, effectively applying denoising
diffusion models to removal of realistic noise is more challenging than it may
seem, since their formulation is based on additive white Gaussian noise, unlike
noise in real-world images. In this work, we present SVNR, a novel formulation
of denoising diffusion that assumes a more realistic, spatially-variant noise
model. SVNR enables using the noisy input image as the starting point for the
denoising diffusion process, in addition to conditioning the process on it. To
this end, we adapt the diffusion process to allow each pixel to have its own
time embedding, and propose training and inference schemes that support
spatially-varying time maps. Our formulation also accounts for the correlation
that exists between the condition image and the samples along the modified
diffusion process. In our experiments we demonstrate the advantages of our
approach over a strong diffusion model baseline, as well as over a
state-of-the-art single image denoising method.
</p></li>
</ul>

<h3>Title: DiffComplete: Diffusion-based Generative 3D Shape Completion. (arXiv:2306.16329v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16329">http://arxiv.org/abs/2306.16329</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16329] DiffComplete: Diffusion-based Generative 3D Shape Completion](http://arxiv.org/abs/2306.16329) #diffusion</code></li>
<li>Summary: <p>We introduce a new diffusion-based approach for shape completion on 3D range
scans. Compared with prior deterministic and probabilistic methods, we strike a
balance between realism, multi-modality, and high fidelity. We propose
DiffComplete by casting shape completion as a generative task conditioned on
the incomplete shape. Our key designs are two-fold. First, we devise a
hierarchical feature aggregation mechanism to inject conditional features in a
spatially-consistent manner. So, we can capture both local details and broader
contexts of the conditional inputs to control the shape completion. Second, we
propose an occupancy-aware fusion strategy in our model to enable the
completion of multiple partial shapes and introduce higher flexibility on the
input conditions. DiffComplete sets a new SOTA performance (e.g., 40% decrease
on l_1 error) on two large-scale 3D shape completion benchmarks. Our completed
shapes not only have a realistic outlook compared with the deterministic
methods but also exhibit high similarity to the ground truths compared with the
probabilistic alternatives. Further, DiffComplete has strong generalizability
on objects of entirely unseen classes for both synthetic and real data,
eliminating the need for model re-training in various applications.
</p></li>
</ul>

<h3>Title: Asymptotic-Preserving Convolutional DeepONets Capture the Diffusive Behavior of the Multiscale Linear Transport Equations. (arXiv:2306.15891v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15891">http://arxiv.org/abs/2306.15891</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15891] Asymptotic-Preserving Convolutional DeepONets Capture the Diffusive Behavior of the Multiscale Linear Transport Equations](http://arxiv.org/abs/2306.15891) #diffusion</code></li>
<li>Summary: <p>In this paper, we introduce two types of novel Asymptotic-Preserving
Convolutional Deep Operator Networks (APCONs) designed to address the
multiscale time-dependent linear transport problem. We observe that the vanilla
physics-informed DeepONets with modified MLP may exhibit instability in
maintaining the desired limiting macroscopic behavior. Therefore, this
necessitates the utilization of an asymptotic-preserving loss function. Drawing
inspiration from the heat kernel in the diffusion equation, we propose a new
architecture called Convolutional Deep Operator Networks, which employ multiple
local convolution operations instead of a global heat kernel, along with
pooling and activation operations in each filter layer. Our APCON methods
possess a parameter count that is independent of the grid size and are capable
of capturing the diffusive behavior of the linear transport problem. Finally,
we validate the effectiveness of our methods through several numerical
examples.
</p></li>
</ul>

<h3>Title: MyDigitalFootprint: an extensive context dataset for pervasive computing applications at the edge. (arXiv:2306.15990v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15990">http://arxiv.org/abs/2306.15990</a></li>
<li>Code URL: <a href="https://github.com/contextkit/mydigitalfootprint">https://github.com/contextkit/mydigitalfootprint</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15990] MyDigitalFootprint: an extensive context dataset for pervasive computing applications at the edge](http://arxiv.org/abs/2306.15990) #diffusion</code></li>
<li>Summary: <p>The widespread diffusion of connected smart devices has contributed to the
rapid expansion and evolution of the Internet at its edge. Personal mobile
devices interact with other smart objects in their surroundings, adapting
behavior based on rapidly changing user context. The ability of mobile devices
to process this data locally is crucial for quick adaptation. This can be
achieved through a single elaboration process integrated into user applications
or a middleware platform for context processing. However, the lack of public
datasets considering user context complexity in the mobile environment hinders
research progress. We introduce MyDigitalFootprint, a large-scale dataset
comprising smartphone sensor data, physical proximity information, and Online
Social Networks interactions. This dataset supports multimodal context
recognition and social relationship modeling. It spans two months of
measurements from 31 volunteer users in their natural environment, allowing for
unrestricted behavior. Existing public datasets focus on limited context data
for specific applications, while ours offers comprehensive information on the
user context in the mobile environment. To demonstrate the dataset's
effectiveness, we present three context-aware applications utilizing various
machine learning tasks: (i) a social link prediction algorithm based on
physical proximity data, (ii) daily-life activity recognition using
smartphone-embedded sensors data, and (iii) a pervasive context-aware
recommender system. Our dataset, with its heterogeneity of information, serves
as a valuable resource to validate new research in mobile and edge computing.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h3>Title: On the Universal Adversarial Perturbations for Efficient Data-free Adversarial Detection. (arXiv:2306.15705v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15705">http://arxiv.org/abs/2306.15705</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15705] On the Universal Adversarial Perturbations for Efficient Data-free Adversarial Detection](http://arxiv.org/abs/2306.15705) #data-free</code></li>
<li>Summary: <p>Detecting adversarial samples that are carefully crafted to fool the model is
a critical step to socially-secure applications. However, existing adversarial
detection methods require access to sufficient training data, which brings
noteworthy concerns regarding privacy leakage and generalizability. In this
work, we validate that the adversarial sample generated by attack algorithms is
strongly related to a specific vector in the high-dimensional inputs. Such
vectors, namely UAPs (Universal Adversarial Perturbations), can be calculated
without original training data. Based on this discovery, we propose a
data-agnostic adversarial detection framework, which induces different
responses between normal and adversarial samples to UAPs. Experimental results
show that our method achieves competitive detection performance on various text
classification tasks, and maintains an equivalent time consumption to normal
inference.
</p></li>
</ul>

<h2>transformer</h2>
<h3>Title: Structured State Space Models for Multiple Instance Learning in Digital Pathology. (arXiv:2306.15789v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15789">http://arxiv.org/abs/2306.15789</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15789] Structured State Space Models for Multiple Instance Learning in Digital Pathology](http://arxiv.org/abs/2306.15789) #transformer</code></li>
<li>Summary: <p>Multiple instance learning is an ideal mode of analysis for histopathology
data, where vast whole slide images are typically annotated with a single
global label. In such cases, a whole slide image is modelled as a collection of
tissue patches to be aggregated and classified. Common models for performing
this classification include recurrent neural networks and transformers.
Although powerful compression algorithms, such as deep pre-trained neural
networks, are used to reduce the dimensionality of each patch, the sequences
arising from whole slide images remain excessively long, routinely containing
tens of thousands of patches. Structured state space models are an emerging
alternative for sequence modelling, specifically designed for the efficient
modelling of long sequences. These models invoke an optimal projection of an
input sequence into memory units that compress the entire sequence. In this
paper, we propose the use of state space models as a multiple instance learner
to a variety of problems in digital pathology. Across experiments in metastasis
detection, cancer subtyping, mutation classification, and multitask learning,
we demonstrate the competitiveness of this new class of models with existing
state of the art approaches. Our code is available at
https://github.com/MICS-Lab/s4_digital_pathology.
</p></li>
</ul>

<h3>Title: Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners. (arXiv:2306.15876v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15876">http://arxiv.org/abs/2306.15876</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15876] Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners](http://arxiv.org/abs/2306.15876) #transformer</code></li>
<li>Summary: <p>Representation learning has been evolving from traditional supervised
training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous
works have demonstrated their pros and cons in specific scenarios, i.e., CL and
supervised pre-training excel at capturing longer-range global patterns and
enabling better feature discrimination, while MIM can introduce more local and
diverse attention across all transformer layers. In this paper, we explore how
to obtain a model that combines their strengths. We start by examining previous
feature distillation and mask feature reconstruction methods and identify their
limitations. We find that their increasing diversity mainly derives from the
asymmetric designs, but these designs may in turn compromise the discrimination
ability. In order to better obtain both discrimination and diversity, we
propose a simple but effective Hybrid Distillation strategy, which utilizes
both the supervised/CL teacher and the MIM teacher to jointly guide the student
model. Hybrid Distill imitates the token relations of the MIM teacher to
alleviate attention collapse, as well as distills the feature maps of the
supervised/CL teacher to enable discrimination. Furthermore, a progressive
redundant token masking strategy is also utilized to reduce the distilling
costs and avoid falling into local optima. Experiment results prove that Hybrid
Distill can achieve superior performance on different benchmarks.
</p></li>
</ul>

<h3>Title: The 2nd Place Solution for 2023 Waymo Open Sim Agents Challenge. (arXiv:2306.15914v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15914">http://arxiv.org/abs/2306.15914</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15914] The 2nd Place Solution for 2023 Waymo Open Sim Agents Challenge](http://arxiv.org/abs/2306.15914) #transformer</code></li>
<li>Summary: <p>In this technical report, we present the 2nd place solution of 2023 Waymo
Open Sim Agents Challenge (WOSAC)[4]. We propose a simple yet effective
autoregressive method for simulating multi-agent behaviors, which is built upon
a well-known multimodal motion forecasting framework called Motion Transformer
(MTR)[5] with postprocessing algorithms applied. Our submission named MTR+++
achieves 0.4697 on the Realism Meta metric in 2023 WOSAC. Besides, a modified
model based on MTR named MTR_E is proposed after the challenge, which has a
better score 0.4911 and is ranked the 3rd on the leaderboard of WOSAC as of
June 25, 2023.
</p></li>
</ul>

<h3>Title: $\mathbf{C}^2$Former: Calibrated and Complementary Transformer for RGB-Infrared Object Detection. (arXiv:2306.16175v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16175">http://arxiv.org/abs/2306.16175</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16175] $\mathbf{C}^2$Former: Calibrated and Complementary Transformer for RGB-Infrared Object Detection](http://arxiv.org/abs/2306.16175) #transformer</code></li>
<li>Summary: <p>Object detection on visible (RGB) and infrared (IR) images, as an emerging
solution to facilitate robust detection for around-the-clock applications, has
received extensive attention in recent years. With the help of IR images,
object detectors have been more reliable and robust in practical applications
by using RGB-IR combined information. However, existing methods still suffer
from modality miscalibration and fusion imprecision problems. Since transformer
has the powerful capability to model the pairwise correlations between
different features, in this paper, we propose a novel Calibrated and
Complementary Transformer called $\mathrm{C}^2$Former to address these two
problems simultaneously. In $\mathrm{C}^2$Former, we design an Inter-modality
Cross-Attention (ICA) module to obtain the calibrated and complementary
features by learning the cross-attention relationship between the RGB and IR
modality. To reduce the computational cost caused by computing the global
attention in ICA, an Adaptive Feature Sampling (AFS) module is introduced to
decrease the dimension of feature maps. Because $\mathrm{C}^2$Former performs
in the feature domain, it can be embedded into existed RGB-IR object detectors
via the backbone network. Thus, one single-stage and one two-stage object
detector both incorporating our $\mathrm{C}^2$Former are constructed to
evaluate its effectiveness and versatility. With extensive experiments on the
DroneVehicle and KAIST RGB-IR datasets, we verify that our method can fully
utilize the RGB-IR complementary information and achieve robust detection
results. The code is available at
https://github.com/yuanmaoxun/Calibrated-and-Complementary-Transformer-for-RGB-Infrared-Object-Detection.git.
</p></li>
</ul>

<h3>Title: FLuRKA: Fast fused Low-Rank &amp; Kernel Attention. (arXiv:2306.15799v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15799">http://arxiv.org/abs/2306.15799</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15799] FLuRKA: Fast fused Low-Rank &amp; Kernel Attention](http://arxiv.org/abs/2306.15799) #transformer</code></li>
<li>Summary: <p>Many efficient approximate self-attention techniques have become prevalent
since the inception of the transformer architecture. Two popular classes of
these techniques are low-rank and kernel methods. Each of these methods has its
own strengths. We observe these strengths synergistically complement each other
and exploit these synergies to fuse low-rank and kernel methods, producing a
new class of transformers: FLuRKA (Fast Low-Rank and Kernel Attention). FLuRKA
provide sizable performance gains over these approximate techniques and are of
high quality. We theoretically and empirically evaluate both the runtime
performance and quality of FLuRKA. Our runtime analysis posits a variety of
parameter configurations where FLuRKA exhibit speedups and our accuracy
analysis bounds the error of FLuRKA with respect to full-attention. We
instantiate three FLuRKA variants which experience empirical speedups of up to
3.3x and 1.7x over low-rank and kernel methods respectively. This translates to
speedups of up to 30x over models with full-attention. With respect to model
quality, FLuRKA can match the accuracy of low-rank and kernel methods on GLUE
after pre-training on wiki-text 103. When pre-training on a fixed time budget,
FLuRKA yield better perplexity scores than models with full-attention.
</p></li>
</ul>

<h3>Title: Confidence-Calibrated Ensemble Dense Phrase Retrieval. (arXiv:2306.15917v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15917">http://arxiv.org/abs/2306.15917</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15917] Confidence-Calibrated Ensemble Dense Phrase Retrieval](http://arxiv.org/abs/2306.15917) #transformer</code></li>
<li>Summary: <p>In this paper, we consider the extent to which the transformer-based Dense
Passage Retrieval (DPR) algorithm, developed by (Karpukhin et. al. 2020), can
be optimized without further pre-training. Our method involves two particular
insights: we apply the DPR context encoder at various phrase lengths (e.g.
one-sentence versus five-sentence segments), and we take a
confidence-calibrated ensemble prediction over all of these different
segmentations. This somewhat exhaustive approach achieves start-of-the-art
results on benchmark datasets such as Google NQ and SQuAD. We also apply our
method to domain-specific datasets, and the results suggest how different
granularities are optimal for different domains
</p></li>
</ul>

<h3>Title: Accelerating Transducers through Adjacent Token Merging. (arXiv:2306.16009v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16009">http://arxiv.org/abs/2306.16009</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16009] Accelerating Transducers through Adjacent Token Merging](http://arxiv.org/abs/2306.16009) #transformer</code></li>
<li>Summary: <p>Recent end-to-end automatic speech recognition (ASR) systems often utilize a
Transformer-based acoustic encoder that generates embedding at a high frame
rate. However, this design is inefficient, particularly for long speech signals
due to the quadratic computation of self-attention. To address this, we propose
a new method, Adjacent Token Merging (A-ToMe), which gradually combines
adjacent tokens with high similarity scores between their key values. In this
way, the total time step could be reduced, and the inference of both the
encoder and joint network is accelerated. Experiments on LibriSpeech show that
our method can reduce 57% of tokens and improve the inference speed on GPU by
70% without any notable loss of accuracy. Additionally, we demonstrate that
A-ToMe is also an effective solution to reduce tokens in long-form ASR, where
the input speech consists of multiple utterances.
</p></li>
</ul>

<h3>Title: SkillNet-X: A Multilingual Multitask Model with Sparsely Activated Skills. (arXiv:2306.16176v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16176">http://arxiv.org/abs/2306.16176</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16176] SkillNet-X: A Multilingual Multitask Model with Sparsely Activated Skills](http://arxiv.org/abs/2306.16176) #transformer</code></li>
<li>Summary: <p>Traditional multitask learning methods basically can only exploit common
knowledge in task- or language-wise, which lose either cross-language or
cross-task knowledge. This paper proposes a general multilingual multitask
model, named SkillNet-X, which enables a single model to tackle many different
tasks from different languages. To this end, we define several
language-specific skills and task-specific skills, each of which corresponds to
a skill module. SkillNet-X sparsely activates parts of the skill modules which
are relevant either to the target task or the target language. Acting as
knowledge transit hubs, skill modules are capable of absorbing task-related
knowledge and language-related knowledge consecutively. Based on Transformer,
we modify the multi-head attention layer and the feed forward network layer to
accommodate skill modules. We evaluate SkillNet-X on eleven natural language
understanding datasets in four languages. Results show that SkillNet-X performs
better than task-specific baselines and two multitask learning baselines (i.e.,
dense joint model and Mixture-of-Experts model). Furthermore, skill
pre-training further improves the performance of SkillNet-X on almost all
datasets. To investigate the generalization of our model, we conduct
experiments on two new tasks and find that SkillNet-X significantly outperforms
baselines.
</p></li>
</ul>

<h3>Title: HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution. (arXiv:2306.15794v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15794">http://arxiv.org/abs/2306.15794</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15794] HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution](http://arxiv.org/abs/2306.15794) #transformer</code></li>
<li>Summary: <p>Genomic (DNA) sequences encode an enormous amount of information for gene
regulation and protein synthesis. Similar to natural language models,
researchers have proposed foundation models in genomics to learn generalizable
features from unlabeled genome data that can then be fine-tuned for downstream
tasks such as identifying regulatory elements. Due to the quadratic scaling of
attention, previous Transformer-based genomic models have used 512 to 4k tokens
as context (<0.001% of the human genome), significantly limiting the modeling
of long-range interactions in DNA. In addition, these methods rely on
tokenizers to aggregate meaningful DNA units, losing single nucleotide
resolution where subtle genetic variations can completely alter protein
function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a large
language model based on implicit convolutions was shown to match attention in
quality while allowing longer context lengths and lower time complexity.
Leveraging Hyenas new long-range capabilities, we present HyenaDNA, a genomic
foundation model pretrained on the human reference genome with context lengths
of up to 1 million tokens at the single nucleotide-level, an up to 500x
increase over previous dense attention-based models. HyenaDNA scales
sub-quadratically in sequence length (training up to 160x faster than
Transformer), uses single nucleotide tokens, and has full global context at
each layer. We explore what longer context enables - including the first use of
in-context learning in genomics for simple adaptation to novel tasks without
updating pretrained model weights. On fine-tuned benchmarks from the Nucleotide
Transformer, HyenaDNA reaches state-of-the-art (SotA) on 12 of 17 datasets
using a model with orders of magnitude less parameters and pretraining data. On
the GenomicBenchmarks, HyenaDNA surpasses SotA on all 8 datasets on average by
+9 accuracy points.
</p></li>
</ul>

<h3>Title: RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$. (arXiv:2306.15909v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15909">http://arxiv.org/abs/2306.15909</a></li>
<li>Code URL: <a href="https://github.com/bhatiaabhinav/rl3">https://github.com/bhatiaabhinav/rl3</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15909] RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$](http://arxiv.org/abs/2306.15909) #transformer</code></li>
<li>Summary: <p>Meta reinforcement learning (meta-RL) methods such as RL$^2$ have emerged as
promising approaches for learning data-efficient RL algorithms tailored to a
given task distribution. However, these RL algorithms struggle with
long-horizon tasks and out-of-distribution tasks since they rely on recurrent
neural networks to process the sequence of experiences instead of summarizing
them into general RL components such as value functions. Moreover, even
transformers have a practical limit to the length of histories they can
efficiently reason about before training and inference costs become
prohibitive. In contrast, traditional RL algorithms are data-inefficient since
they do not leverage domain knowledge, but they do converge to an optimal
policy as more data becomes available. In this paper, we propose RL$^3$, a
principled hybrid approach that combines traditional RL and meta-RL by
incorporating task-specific action-values learned through traditional RL as an
input to the meta-RL neural network. We show that RL$^3$ earns greater
cumulative reward on long-horizon and out-of-distribution tasks compared to
RL$^2$, while maintaining the efficiency of the latter in the short term.
Experiments are conducted on both custom and benchmark discrete domains from
the meta-RL literature that exhibit a range of short-term, long-term, and
complex dependencies.
</p></li>
</ul>

<h3>Title: Mass Spectra Prediction with Structural Motif-based Graph Neural Networks. (arXiv:2306.16085v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16085">http://arxiv.org/abs/2306.16085</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16085] Mass Spectra Prediction with Structural Motif-based Graph Neural Networks](http://arxiv.org/abs/2306.16085) #transformer</code></li>
<li>Summary: <p>Mass spectra, which are agglomerations of ionized fragments from targeted
molecules, play a crucial role across various fields for the identification of
molecular structures. A prevalent analysis method involves spectral library
searches,where unknown spectra are cross-referenced with a database. The
effectiveness of such search-based approaches, however, is restricted by the
scope of the existing mass spectra database, underscoring the need to expand
the database via mass spectra prediction. In this research, we propose the
Motif-based Mass Spectrum Prediction Network (MoMS-Net), a system that predicts
mass spectra using the information derived from structural motifs and the
implementation of Graph Neural Networks (GNNs). We have tested our model across
diverse mass spectra and have observed its superiority over other existing
models. MoMS-Net considers substructure at the graph level, which facilitates
the incorporation of long-range dependencies while using less memory compared
to the graph transformer model.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: xAI-CycleGAN, a Cycle-Consistent Generative Assistive Network. (arXiv:2306.15760v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15760">http://arxiv.org/abs/2306.15760</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15760] xAI-CycleGAN, a Cycle-Consistent Generative Assistive Network](http://arxiv.org/abs/2306.15760) #generative</code></li>
<li>Summary: <p>In the domain of unsupervised image-to-image transformation using generative
transformative models, CycleGAN has become the architecture of choice. One of
the primary downsides of this architecture is its relatively slow rate of
convergence. In this work, we use discriminator-driven explainability to speed
up the convergence rate of the generative model by using saliency maps from the
discriminator that mask the gradients of the generator during backpropagation,
based on the work of Nagisetty et al., and also introducing the saliency map on
input, added onto a Gaussian noise mask, by using an interpretable latent
variable based on Wang M.'s Mask CycleGAN. This allows for an explainability
fusion in both directions, and utilizing the noise-added saliency map on input
as evidence-based counterfactual filtering. This new architecture has much
higher rate of convergence than a baseline CycleGAN architecture while
preserving the image quality.
</p></li>
</ul>

<h3>Title: Toward Mesh-Invariant 3D Generative Deep Learning with Geometric Measures. (arXiv:2306.15762v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15762">http://arxiv.org/abs/2306.15762</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15762] Toward Mesh-Invariant 3D Generative Deep Learning with Geometric Measures](http://arxiv.org/abs/2306.15762) #generative</code></li>
<li>Summary: <p>3D generative modeling is accelerating as the technology allowing the capture
of geometric data is developing. However, the acquired data is often
inconsistent, resulting in unregistered meshes or point clouds. Many generative
learning algorithms require correspondence between each point when comparing
the predicted shape and the target shape. We propose an architecture able to
cope with different parameterizations, even during the training phase. In
particular, our loss function is built upon a kernel-based metric over a
representation of meshes using geometric measures such as currents and
varifolds. The latter allows to implement an efficient dissimilarity measure
with many desirable properties such as robustness to resampling of the mesh or
point cloud. We demonstrate the efficiency and resilience of our model with a
generative learning task of human faces.
</p></li>
</ul>

<h3>Title: Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications. (arXiv:2306.16143v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16143">http://arxiv.org/abs/2306.16143</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16143] Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications](http://arxiv.org/abs/2306.16143) #generative</code></li>
<li>Summary: <p>User experience (UX) is a part of human-computer interaction (HCI) research
and focuses on increasing intuitiveness, transparency, simplicity, and trust
for system users. Most of the UX research for machine learning (ML) or natural
language processing (NLP) focuses on a data-driven methodology, i.e., it fails
to focus on users' requirements, and engages domain users mainly for usability
evaluation. Moreover, more typical UX methods tailor the systems towards user
usability, unlike learning about the user needs first. The paper proposes a
methodology for integrating generative UX research into developing domain NLP
applications. Generative UX research employs domain users at the initial stages
of prototype development, i.e., ideation and concept evaluation, and the last
stage for evaluating the change in user value. In the case study, we report the
full-cycle prototype development of a domain-specific semantic search for daily
operations in the process industry. Our case study shows that involving domain
experts increases their interest and trust in the final NLP application.
Moreover, we show that synergetic UX+NLP research efficiently considers data-
and user-driven opportunities and constraints, which can be crucial for NLP
applications in narrow domains
</p></li>
</ul>

<h3>Title: High Fidelity Image Counterfactuals with Probabilistic Causal Models. (arXiv:2306.15764v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15764">http://arxiv.org/abs/2306.15764</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15764] High Fidelity Image Counterfactuals with Probabilistic Causal Models](http://arxiv.org/abs/2306.15764) #generative</code></li>
<li>Summary: <p>We present a general causal generative modelling framework for accurate
estimation of high fidelity image counterfactuals with deep structural causal
models. Estimation of interventional and counterfactual queries for
high-dimensional structured variables, such as images, remains a challenging
task. We leverage ideas from causal mediation analysis and advances in
generative modelling to design new deep causal mechanisms for structured
variables in causal models. Our experiments demonstrate that our proposed
mechanisms are capable of accurate abduction and estimation of direct, indirect
and total effects as measured by axiomatic soundness of counterfactuals.
</p></li>
</ul>

<h3>Title: Recent Advances in Optimal Transport for Machine Learning. (arXiv:2306.16156v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16156">http://arxiv.org/abs/2306.16156</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16156] Recent Advances in Optimal Transport for Machine Learning](http://arxiv.org/abs/2306.16156) #generative</code></li>
<li>Summary: <p>Recently, Optimal Transport has been proposed as a probabilistic framework in
Machine Learning for comparing and manipulating probability distributions. This
is rooted in its rich history and theory, and has offered new solutions to
different problems in machine learning, such as generative modeling and
transfer learning. In this survey we explore contributions of Optimal Transport
for Machine Learning over the period 2012 -- 2022, focusing on four sub-fields
of Machine Learning: supervised, unsupervised, transfer and reinforcement
learning. We further highlight the recent development in computational Optimal
Transport, and its interplay with Machine Learning practice.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Let Segment Anything Help Image Dehaze. (arXiv:2306.15870v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15870">http://arxiv.org/abs/2306.15870</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15870] Let Segment Anything Help Image Dehaze](http://arxiv.org/abs/2306.15870) #large language model</code></li>
<li>Summary: <p>The large language model and high-level vision model have achieved impressive
performance improvements with large datasets and model sizes. However,
low-level computer vision tasks, such as image dehaze and blur removal, still
rely on a small number of datasets and small-sized models, which generally
leads to overfitting and local optima. Therefore, we propose a framework to
integrate large-model prior into low-level computer vision tasks. Just as with
the task of image segmentation, the degradation of haze is also
texture-related. So we propose to detect gray-scale coding, network channel
expansion, and pre-dehaze structures to integrate large-model prior knowledge
into any low-level dehazing network. We demonstrate the effectiveness and
applicability of large models in guiding low-level visual tasks through
different datasets and algorithms comparison experiments. Finally, we
demonstrate the effect of grayscale coding, network channel expansion, and
recurrent network structures through ablation experiments. Under the conditions
where additional data and training resources are not required, we successfully
prove that the integration of large-model prior knowledge will improve the
dehaze performance and save training time for low-level visual tasks.
</p></li>
</ul>

<h3>Title: Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language. (arXiv:2306.16410v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16410">http://arxiv.org/abs/2306.16410</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16410] Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language](http://arxiv.org/abs/2306.16410) #large language model</code></li>
<li>Summary: <p>We propose LENS, a modular approach for tackling computer vision problems by
leveraging the power of large language models (LLMs). Our system uses a
language model to reason over outputs from a set of independent and highly
descriptive vision modules that provide exhaustive information about an image.
We evaluate the approach on pure computer vision settings such as zero- and
few-shot object recognition, as well as on vision and language problems. LENS
can be applied to any off-the-shelf LLM and we find that the LLMs with LENS
perform highly competitively with much bigger and much more sophisticated
systems, without any multimodal training whatsoever. We open-source our code at
https://github.com/ContextualAI/lens and provide an interactive demo.
</p></li>
</ul>

<h3>Title: Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost. (arXiv:2306.15766v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15766">http://arxiv.org/abs/2306.15766</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15766] Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost](http://arxiv.org/abs/2306.15766) #large language model</code></li>
<li>Summary: <p>State-of-the-art supervised NLP models achieve high accuracy but are also
susceptible to failures on inputs from low-data regimes, such as domains that
are not represented in training data. As an approximation to collecting
ground-truth labels for the specific domain, we study the use of large language
models (LLMs) for annotating inputs and improving the generalization of NLP
models. Specifically, given a budget for LLM annotations, we present an
algorithm for sampling the most informative inputs to annotate and retrain the
NLP model. We find that popular active learning strategies such as
uncertainty-based sampling do not work well. Instead, we propose a sampling
strategy based on the difference in prediction scores between the base model
and the finetuned NLP model, utilizing the fact that most NLP models are
finetuned from a base model. Experiments with classification (semantic
similarity) and ranking (semantic search) tasks show that our sampling strategy
leads to significant gains in accuracy for both the training and target
domains.
</p></li>
</ul>

<h3>Title: Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias. (arXiv:2306.15895v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15895">http://arxiv.org/abs/2306.15895</a></li>
<li>Code URL: <a href="https://github.com/yueyu1030/attrprompt">https://github.com/yueyu1030/attrprompt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15895] Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias](http://arxiv.org/abs/2306.15895) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) have been recently leveraged as training data
generators for various natural language processing (NLP) tasks. While previous
research has explored different approaches to training models using generated
data, they generally rely on simple class-conditional prompts, which may limit
the diversity of the generated data and inherit systematic biases of LLM. Thus,
we investigate training data generation with diversely attributed prompts
(e.g., specifying attributes like length and style), which have the potential
to yield diverse and attributed generated data. Our investigation focuses on
datasets with high cardinality and diverse domains, wherein we demonstrate that
attributed prompts outperform simple class-conditional prompts in terms of the
resulting model's performance. Additionally, we present a comprehensive
empirical study on data generation encompassing vital aspects like bias,
diversity, and efficiency, and highlight three key observations: firstly,
synthetic datasets generated by simple prompts exhibit significant biases, such
as regional bias; secondly, attribute diversity plays a pivotal role in
enhancing model performance; lastly, attributed prompts achieve the performance
of simple class-conditional prompts while utilizing only 5\% of the querying
cost of ChatGPT associated with the latter. We release the generated dataset
and used prompts to facilitate future research. The data and code will be
available on \url{https://github.com/yueyu1030/AttrPrompt}.
</p></li>
</ul>

<h3>Title: Prompting Large Language Models for Zero-Shot Domain Adaptation in Speech Recognition. (arXiv:2306.16007v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16007">http://arxiv.org/abs/2306.16007</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16007] Prompting Large Language Models for Zero-Shot Domain Adaptation in Speech Recognition](http://arxiv.org/abs/2306.16007) #large language model</code></li>
<li>Summary: <p>The integration of Language Models (LMs) has proven to be an effective way to
address domain shifts in speech recognition. However, these approaches usually
require a significant amount of target domain text data for the training of
LMs. Different from these methods, in this work, with only a domain-specific
text prompt, we propose two zero-shot ASR domain adaptation methods using
LLaMA, a 7-billion-parameter large language model (LLM). LLM is used in two
ways: 1) second-pass rescoring: reranking N-best hypotheses of a given ASR
system with LLaMA; 2) deep LLM-fusion: incorporating LLM into the decoder of an
encoder-decoder based ASR system. Experiments show that, with only one domain
prompt, both methods can effectively reduce word error rates (WER) on
out-of-domain TedLium-2 and SPGISpeech datasets. Especially, the deep
LLM-fusion has the advantage of better recall of entity and out-of-vocabulary
words.
</p></li>
</ul>

<h3>Title: ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases. (arXiv:2306.16092v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16092">http://arxiv.org/abs/2306.16092</a></li>
<li>Code URL: <a href="https://github.com/pku-yuangroup/chatlaw">https://github.com/pku-yuangroup/chatlaw</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16092] ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases](http://arxiv.org/abs/2306.16092) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have shown the potential to revolutionize
natural language processing tasks in various domains, sparking great interest
in vertical-specific large models. However, unlike proprietary models such as
BloombergGPT and FinGPT, which have leveraged their unique data accumulations
to make strides in the finance domain, there hasn't not many similar large
language models in the Chinese legal domain to facilitate its digital
transformation.
</p></li>
</ul>

<p>In this paper, we propose an open-source legal large language model named
ChatLaw. Due to the importance of data quality, we carefully designed a legal
domain fine-tuning dataset. Additionally, to overcome the problem of model
hallucinations in legal data screening during reference data retrieval, we
introduce a method that combines vector database retrieval with keyword
retrieval to effectively reduce the inaccuracy of relying solely on vector
database retrieval. Furthermore, we propose a self-attention method to enhance
the ability of large models to overcome errors present in reference data,
further optimizing the issue of model hallucinations at the model level and
improving the problem-solving capabilities of large models. We also
open-sourced our model and part of the data at
https://github.com/PKU-YuanGroup/ChatLaw.
</p>

<h3>Title: Is ChatGPT a Biomedical Expert? -- Exploring the Zero-Shot Performance of Current GPT Models in Biomedical Tasks. (arXiv:2306.16108v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16108">http://arxiv.org/abs/2306.16108</a></li>
<li>Code URL: <a href="https://github.com/samyateia/bioasq">https://github.com/samyateia/bioasq</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16108] Is ChatGPT a Biomedical Expert? -- Exploring the Zero-Shot Performance of Current GPT Models in Biomedical Tasks](http://arxiv.org/abs/2306.16108) #large language model</code></li>
<li>Summary: <p>We assessed the performance of commercial Large Language Models (LLMs)
GPT-3.5-Turbo and GPT-4 on tasks from the 2023 BioASQ challenge. In Task 11b
Phase B, which is focused on answer generation, both models demonstrated
competitive abilities with leading systems. Remarkably, they achieved this with
simple zero-shot learning, grounded with relevant snippets. Even without
relevant snippets, their performance was decent, though not on par with the
best systems. Interestingly, the older and cheaper GPT-3.5-Turbo system was
able to compete with GPT-4 in the grounded Q&amp;A setting on factoid and list
answers. In Task 11b Phase A, focusing on retrieval, query expansion through
zero-shot learning improved performance, but the models fell short compared to
other systems. The code needed to rerun these experiments is available through
GitHub.
</p></li>
</ul>

<h3>Title: CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models. (arXiv:2306.16244v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16244">http://arxiv.org/abs/2306.16244</a></li>
<li>Code URL: <a href="https://github.com/yfhuangxxxx/cbbq">https://github.com/yfhuangxxxx/cbbq</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16244] CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models](http://arxiv.org/abs/2306.16244) #large language model</code></li>
<li>Summary: <p>Holistically measuring societal biases of large language models is crucial
for detecting and reducing ethical risks in highly capable AI models. In this
work, we present a Chinese Bias Benchmark dataset that consists of over 100K
questions jointly constructed by human experts and generative language models,
covering stereotypes and societal biases in 14 social dimensions related to
Chinese culture and values. The curation process contains 4 essential steps:
bias identification via extensive literature review, ambiguous context
generation, AI-assisted disambiguous context generation, snd manual review \&amp;
recomposition. The testing instances in the dataset are automatically derived
from 3K+ high-quality templates manually authored with stringent quality
control. The dataset exhibits wide coverage and high diversity. Extensive
experiments demonstrate the effectiveness of the dataset in detecting model
bias, with all 10 publicly available Chinese large language models exhibiting
strong bias in certain categories. Additionally, we observe from our
experiments that fine-tuned models could, to a certain extent, heed
instructions and avoid generating outputs that are morally harmful in some
types, in the way of "moral self-correction". Our dataset and results are
publicly available at
\href{https://github.com/YFHuangxxxx/CBBQ}{https://github.com/YFHuangxxxx/CBBQ},
offering debiasing research opportunities to a widened community.
</p></li>
</ul>

<h3>Title: Leveraging GPT-4 for Food Effect Summarization to Enhance Product-Specific Guidance Development via Iterative Prompting. (arXiv:2306.16275v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16275">http://arxiv.org/abs/2306.16275</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16275] Leveraging GPT-4 for Food Effect Summarization to Enhance Product-Specific Guidance Development via Iterative Prompting](http://arxiv.org/abs/2306.16275) #large language model</code></li>
<li>Summary: <p>Food effect summarization from New Drug Application (NDA) is an essential
component of product-specific guidance (PSG) development and assessment.
However, manual summarization of food effect from extensive drug application
review documents is time-consuming, which arouses a need to develop automated
methods. Recent advances in large language models (LLMs) such as ChatGPT and
GPT-4, have demonstrated great potential in improving the effectiveness of
automated text summarization, but its ability regarding the accuracy in
summarizing food effect for PSG assessment remains unclear. In this study, we
introduce a simple yet effective approach, iterative prompting, which allows
one to interact with ChatGPT or GPT-4 more effectively and efficiently through
multi-turn interaction. Specifically, we propose a three-turn iterative
prompting approach to food effect summarization in which the keyword-focused
and length-controlled prompts are respectively provided in consecutive turns to
refine the quality of the generated summary. We conduct a series of extensive
evaluations, ranging from automated metrics to FDA professionals and even
evaluation by GPT-4, on 100 NDA review documents selected over the past five
years. We observe that the summary quality is progressively improved throughout
the process. Moreover, we find that GPT-4 performs better than ChatGPT, as
evaluated by FDA professionals (43% vs. 12%) and GPT-4 (64% vs. 35%).
Importantly, all the FDA professionals unanimously rated that 85% of the
summaries generated by GPT-4 are factually consistent with the golden reference
summary, a finding further supported by GPT-4 rating of 72% consistency. These
results strongly suggest a great potential for GPT-4 to draft food effect
summaries that could be reviewed by FDA professionals, thereby improving the
efficiency of PSG assessment cycle and promoting the generic drug product
development.
</p></li>
</ul>

<h3>Title: Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models. (arXiv:2306.16322v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16322">http://arxiv.org/abs/2306.16322</a></li>
<li>Code URL: <a href="https://github.com/arbml/taqyim">https://github.com/arbml/taqyim</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16322] Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models](http://arxiv.org/abs/2306.16322) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) have demonstrated impressive performance on
various downstream tasks without requiring fine-tuning, including ChatGPT, a
chat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite having
a lower training proportion compared to English, these models also exhibit
remarkable capabilities in other languages. In this study, we assess the
performance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks:
sentiment analysis, translation, transliteration, paraphrasing, part of speech
tagging, summarization, and diacritization. Our findings reveal that GPT-4
outperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct an
extensive analysis of the sentiment analysis task, providing insights into how
LLMs achieve exceptional results on a challenging dialectal dataset.
Additionally, we introduce a new Python interface
https://github.com/ARBML/Taqyim that facilitates the evaluation of these tasks
effortlessly.
</p></li>
</ul>

<h3>Title: Towards Measuring the Representation of Subjective Global Opinions in Language Models. (arXiv:2306.16388v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16388">http://arxiv.org/abs/2306.16388</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16388] Towards Measuring the Representation of Subjective Global Opinions in Language Models](http://arxiv.org/abs/2306.16388) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) may not equitably represent diverse global
perspectives on societal issues. In this paper, we develop a quantitative
framework to evaluate whose opinions model-generated responses are more similar
to. We first build a dataset, GlobalOpinionQA, comprised of questions and
answers from cross-national surveys designed to capture diverse opinions on
global issues across different countries. Next, we define a metric that
quantifies the similarity between LLM-generated survey responses and human
responses, conditioned on country. With our framework, we run three experiments
on an LLM trained to be helpful, honest, and harmless with Constitutional AI.
By default, LLM responses tend to be more similar to the opinions of certain
populations, such as those from the USA, and some European and South American
countries, highlighting the potential for biases. When we prompt the model to
consider a particular country's perspective, responses shift to be more similar
to the opinions of the prompted populations, but can reflect harmful cultural
stereotypes. When we translate GlobalOpinionQA questions to a target language,
the model's responses do not necessarily become the most similar to the
opinions of speakers of those languages. We release our dataset for others to
use and build on. Our data is at
https://huggingface.co/datasets/Anthropic/llm_global_opinions. We also provide
an interactive visualization at https://llmglobalvalues.anthropic.com.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: MAE-GEBD:Winning the CVPR'2023 LOVEU-GEBD Challenge. (arXiv:2306.15704v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15704">http://arxiv.org/abs/2306.15704</a></li>
<li>Code URL: <a href="https://github.com/contentandmaterialportrait/mae-gebd">https://github.com/contentandmaterialportrait/mae-gebd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15704] MAE-GEBD:Winning the CVPR'2023 LOVEU-GEBD Challenge](http://arxiv.org/abs/2306.15704) #segmentation</code></li>
<li>Summary: <p>The Generic Event Boundary Detection (GEBD) task aims to build a model for
segmenting videos into segments by detecting general event boundaries
applicable to various classes. In this paper, based on last year's MAE-GEBD
method, we have improved our model performance on the GEBD task by adjusting
the data processing strategy and loss function. Based on last year's approach,
we extended the application of pseudo-label to a larger dataset and made many
experimental attempts. In addition, we applied focal loss to concentrate more
on difficult samples and improved our model performance. Finally, we improved
the segmentation alignment strategy used last year, and dynamically adjusted
the segmentation alignment method according to the boundary density and
duration of the video, so that our model can be more flexible and fully
applicable in different situations. With our method, we achieve an F1 score of
86.03% on the Kinetics-GEBD test set, which is a 0.09% improvement in the F1
score compared to our 2022 Kinetics-GEBD method.
</p></li>
</ul>

<h3>Title: GraSS: Contrastive Learning with Gradient Guided Sampling Strategy for Remote Sensing Image Semantic Segmentation. (arXiv:2306.15868v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15868">http://arxiv.org/abs/2306.15868</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15868] GraSS: Contrastive Learning with Gradient Guided Sampling Strategy for Remote Sensing Image Semantic Segmentation](http://arxiv.org/abs/2306.15868) #segmentation</code></li>
<li>Summary: <p>Self-supervised contrastive learning (SSCL) has achieved significant
milestones in remote sensing image (RSI) understanding. Its essence lies in
designing an unsupervised instance discrimination pretext task to extract image
features from a large number of unlabeled images that are beneficial for
downstream tasks. However, existing instance discrimination based SSCL suffer
from two limitations when applied to the RSI semantic segmentation task: 1)
Positive sample confounding issue; 2) Feature adaptation bias. It introduces a
feature adaptation bias when applied to semantic segmentation tasks that
require pixel-level or object-level features. In this study, We observed that
the discrimination information can be mapped to specific regions in RSI through
the gradient of unsupervised contrastive loss, these specific regions tend to
contain singular ground objects. Based on this, we propose contrastive learning
with Gradient guided Sampling Strategy (GraSS) for RSI semantic segmentation.
GraSS consists of two stages: Instance Discrimination warm-up (ID warm-up) and
Gradient guided Sampling contrastive training (GS training). The ID warm-up
aims to provide initial discrimination information to the contrastive loss
gradients. The GS training stage aims to utilize the discrimination information
contained in the contrastive loss gradients and adaptively select regions in
RSI patches that contain more singular ground objects, in order to construct
new positive and negative samples. Experimental results on three open datasets
demonstrate that GraSS effectively enhances the performance of SSCL in
high-resolution RSI semantic segmentation. Compared to seven baseline methods
from five different types of SSCL, GraSS achieves an average improvement of
1.57\% and a maximum improvement of 3.58\% in terms of mean intersection over
the union. The source code is available at https://github.com/GeoX-Lab/GraSS
</p></li>
</ul>

<h3>Title: Towards Open Vocabulary Learning: A Survey. (arXiv:2306.15880v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15880">http://arxiv.org/abs/2306.15880</a></li>
<li>Code URL: <a href="https://github.com/jianzongwu/awesome-open-vocabulary">https://github.com/jianzongwu/awesome-open-vocabulary</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15880] Towards Open Vocabulary Learning: A Survey](http://arxiv.org/abs/2306.15880) #segmentation</code></li>
<li>Summary: <p>In the field of visual scene understanding, deep neural networks have made
impressive advancements in various core tasks like segmentation, tracking, and
detection. However, most approaches operate on the close-set assumption,
meaning that the model can only identify pre-defined categories that are
present in the training set. Recently, open vocabulary settings were proposed
due to the rapid progress of vision language pre-training. These new approaches
seek to locate and recognize categories beyond the annotated label space. The
open vocabulary approach is more general, practical, and effective compared to
weakly supervised and zero-shot settings. This paper provides a thorough review
of open vocabulary learning, summarizing and analyzing recent developments in
the field. In particular, we begin by comparing it to related concepts such as
zero-shot learning, open-set recognition, and out-of-distribution detection.
Then, we review several closely related tasks in the case of segmentation and
detection, including long-tail problems, few-shot, and zero-shot settings. For
the method survey, we first present the basic knowledge of detection and
segmentation in close-set as the preliminary knowledge. Next, we examine
various scenarios in which open vocabulary learning is used, identifying common
design elements and core ideas. Then, we compare the recent detection and
segmentation approaches in commonly used datasets and benchmarks. Finally, we
conclude with insights, issues, and discussions regarding future research
directions. To our knowledge, this is the first comprehensive literature review
of open vocabulary learning. We keep tracing related works at
https://github.com/jianzongwu/Awesome-Open-Vocabulary.
</p></li>
</ul>

<h3>Title: Incremental Learning on Food Instance Segmentation. (arXiv:2306.15910v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.15910">http://arxiv.org/abs/2306.15910</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.15910] Incremental Learning on Food Instance Segmentation](http://arxiv.org/abs/2306.15910) #segmentation</code></li>
<li>Summary: <p>Food instance segmentation is essential to estimate the serving size of
dishes in a food image. The recent cutting-edge techniques for instance
segmentation are deep learning networks with impressive segmentation quality
and fast computation. Nonetheless, they are hungry for data and expensive for
annotation. This paper proposes an incremental learning framework to optimize
the model performance given a limited data labelling budget. The power of the
framework is a novel difficulty assessment model, which forecasts how
challenging an unlabelled sample is to the latest trained instance segmentation
model. The data collection procedure is divided into several stages, each in
which a new sample package is collected. The framework allocates the labelling
budget to the most difficult samples. The unlabelled samples that meet a
certain qualification from the assessment model are used to generate
pseudo-labels. Eventually, the manual labels and pseudo-labels are sent to the
training data to improve the instance segmentation model. On four large-scale
food datasets, our proposed framework outperforms current incremental learning
benchmarks and achieves competitive performance with the model trained on fully
annotated samples.
</p></li>
</ul>

<h3>Title: Fast Marching Energy CNN. (arXiv:2306.16109v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16109">http://arxiv.org/abs/2306.16109</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16109] Fast Marching Energy CNN](http://arxiv.org/abs/2306.16109) #segmentation</code></li>
<li>Summary: <p>Leveraging geodesic distances and the geometrical information they convey is
key for many data-oriented applications in imaging. Geodesic distance
computation has been used for long for image segmentation using Image based
metrics. We introduce a new method by generating isotropic Riemannian metrics
adapted to a problem using CNN and give as illustrations an example of
application. We then apply this idea to the segmentation of brain tumours as
unit balls for the geodesic distance computed with the metric potential output
by a CNN, thus imposing geometrical and topological constraints on the output
mask. We show that geodesic distance modules work well in machine learning
frameworks and can be used to achieve state-of-the-art performances while
ensuring geometrical and/or topological properties.
</p></li>
</ul>

<h3>Title: INSTA-BEEER: Explicit Error Estimation and Refinement for Fast and Accurate Unseen Object Instance Segmentation. (arXiv:2306.16132v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16132">http://arxiv.org/abs/2306.16132</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16132] INSTA-BEEER: Explicit Error Estimation and Refinement for Fast and Accurate Unseen Object Instance Segmentation](http://arxiv.org/abs/2306.16132) #segmentation</code></li>
<li>Summary: <p>Efficient and accurate segmentation of unseen objects is crucial for robotic
manipulation. However, it remains challenging due to over- or
under-segmentation. Although existing refinement methods can enhance the
segmentation quality, they fix only minor boundary errors or are not
sufficiently fast. In this work, we propose INSTAnce Boundary Explicit Error
Estimation and Refinement (INSTA-BEEER), a novel refinement model that allows
for adding and deleting instances and sharpening boundaries. Leveraging an
error-estimation-then-refinement scheme, the model first estimates the
pixel-wise boundary explicit errors: true positive, true negative, false
positive, and false negative pixels of the instance boundary in the initial
segmentation. It then refines the initial segmentation using these error
estimates as guidance. Experiments show that the proposed model significantly
enhances segmentation, achieving state-of-the-art performance. Furthermore,
with a fast runtime (less than 0.1 s), the model consistently improves
performance across various initial segmentation methods, making it highly
suitable for practical robotic applications.
</p></li>
</ul>

<h3>Title: Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection. (arXiv:2306.16186v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16186">http://arxiv.org/abs/2306.16186</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16186] Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection](http://arxiv.org/abs/2306.16186) #segmentation</code></li>
<li>Summary: <p>Fabric defect segmentation is integral to textile quality control. Despite
this, the scarcity of high-quality annotated data and the diversity of fabric
defects present significant challenges to the application of deep learning in
this field. These factors limit the generalization and segmentation performance
of existing models, impeding their ability to handle the complexity of diverse
fabric types and defects. To overcome these obstacles, this study introduces an
innovative method to infuse specialized knowledge of fabric defects into the
Segment Anything Model (SAM), a large-scale visual model. By introducing and
training a unique set of fabric defect-related parameters, this approach
seamlessly integrates domain-specific knowledge into SAM without the need for
extensive modifications to the pre-existing model parameters. The revamped SAM
model leverages generalized image understanding learned from large-scale
natural image datasets while incorporating fabric defect-specific knowledge,
ensuring its proficiency in fabric defect segmentation tasks. The experimental
results reveal a significant improvement in the model's segmentation
performance, attributable to this novel amalgamation of generic and
fabric-specific knowledge. When benchmarking against popular existing
segmentation models across three datasets, our proposed model demonstrates a
substantial leap in performance. Its impressive results in cross-dataset
comparisons and few-shot learning experiments further demonstrate its potential
for practical applications in textile quality control.
</p></li>
</ul>

<h3>Title: Land Cover Segmentation with Sparse Annotations from Sentinel-2 Imagery. (arXiv:2306.16252v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16252">http://arxiv.org/abs/2306.16252</a></li>
<li>Code URL: <a href="https://github.com/links-ads/spada">https://github.com/links-ads/spada</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16252] Land Cover Segmentation with Sparse Annotations from Sentinel-2 Imagery](http://arxiv.org/abs/2306.16252) #segmentation</code></li>
<li>Summary: <p>Land cover (LC) segmentation plays a critical role in various applications,
including environmental analysis and natural disaster management. However,
generating accurate LC maps is a complex and time-consuming task that requires
the expertise of multiple annotators and regular updates to account for
environmental changes. In this work, we introduce SPADA, a framework for fuel
map delineation that addresses the challenges associated with LC segmentation
using sparse annotations and domain adaptation techniques for semantic
segmentation. Performance evaluations using reliable ground truths, such as
LUCAS and Urban Atlas, demonstrate the technique's effectiveness. SPADA
outperforms state-of-the-art semantic segmentation approaches as well as
third-party products, achieving a mean Intersection over Union (IoU) score of
42.86 and an F1 score of 67.93 on Urban Atlas and LUCAS, respectively.
</p></li>
</ul>

<h3>Title: RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation based on Visual Foundation Model. (arXiv:2306.16269v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16269">http://arxiv.org/abs/2306.16269</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16269] RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation based on Visual Foundation Model](http://arxiv.org/abs/2306.16269) #segmentation</code></li>
<li>Summary: <p>Leveraging vast training data (SA-1B), the foundation Segment Anything Model
(SAM) proposed by Meta AI Research exhibits remarkable generalization and
zero-shot capabilities. Nonetheless, as a category-agnostic instance
segmentation method, SAM heavily depends on prior manual guidance involving
points, boxes, and coarse-grained masks. Additionally, its performance on
remote sensing image segmentation tasks has yet to be fully explored and
demonstrated. In this paper, we consider designing an automated instance
segmentation approach for remote sensing images based on the SAM foundation
model, incorporating semantic category information. Inspired by prompt
learning, we propose a method to learn the generation of appropriate prompts
for SAM input. This enables SAM to produce semantically discernible
segmentation results for remote sensing images, which we refer to as
RSPrompter. We also suggest several ongoing derivatives for instance
segmentation tasks, based on recent developments in the SAM community, and
compare their performance with RSPrompter. Extensive experimental results on
the WHU building, NWPU VHR-10, and SSDD datasets validate the efficacy of our
proposed method. Our code is accessible at
\url{https://kyanchen.github.io/RSPrompter}.
</p></li>
</ul>

<h3>Title: Point2Point : A Framework for Efficient Deep Learning on Hilbert sorted Point Clouds with applications in Spatio-Temporal Occupancy Prediction. (arXiv:2306.16306v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.16306">http://arxiv.org/abs/2306.16306</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.16306] Point2Point : A Framework for Efficient Deep Learning on Hilbert sorted Point Clouds with applications in Spatio-Temporal Occupancy Prediction](http://arxiv.org/abs/2306.16306) #segmentation</code></li>
<li>Summary: <p>The irregularity and permutation invariance of point cloud data pose
challenges for effective learning. Conventional methods for addressing this
issue involve converting raw point clouds to intermediate representations such
as 3D voxel grids or range images. While such intermediate representations
solve the problem of permutation invariance, they can result in significant
loss of information. Approaches that do learn on raw point clouds either have
trouble in resolving neighborhood relationships between points or are too
complicated in their formulation. In this paper, we propose a novel approach to
representing point clouds as a locality preserving 1D ordering induced by the
Hilbert space-filling curve. We also introduce Point2Point, a neural
architecture that can effectively learn on Hilbert-sorted point clouds. We show
that Point2Point shows competitive performance on point cloud segmentation and
generation tasks. Finally, we show the performance of Point2Point on
Spatio-temporal Occupancy prediction from Point clouds.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
