<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Confidential Consortium Framework: Secure Multiparty Applications with Confidentiality, Integrity, and High Availability. (arXiv:2310.11559v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11559">http://arxiv.org/abs/2310.11559</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11559]] Confidential Consortium Framework: Secure Multiparty Applications with Confidentiality, Integrity, and High Availability(http://arxiv.org/abs/2310.11559)</code></li>
<li>Summary: <p>Confidentiality, integrity protection, and high availability, abbreviated to
CIA, are essential properties for trustworthy data systems. The rise of cloud
computing and the growing demand for multiparty applications however means that
building modern CIA systems is more challenging than ever. In response, we
present the Confidential Consortium Framework (CCF), a general-purpose
foundation for developing secure stateful CIA applications. CCF combines
centralized compute with decentralized trust, supporting deployment on
untrusted cloud infrastructure and transparent governance by mutually untrusted
parties. CCF leverages hardware-based trusted execution environments for
remotely verifiable confidentiality and code integrity. This is coupled with
state machine replication backed by an auditable immutable ledger for data
integrity and high availability. CCF enables each service to bring its own
application logic, custom multiparty governance model, and deployment scenario,
decoupling the operators of nodes from the consortium that governs them. CCF is
open-source and available now at https://github.com/microsoft/CCF.
</p></li>
</ul>

<h3>Title: On the Classification of Weierstrass Elliptic Curves over $\mathbb{Z}_n$. (arXiv:2310.11768v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11768">http://arxiv.org/abs/2310.11768</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11768]] On the Classification of Weierstrass Elliptic Curves over $\mathbb{Z}_n$(http://arxiv.org/abs/2310.11768)</code></li>
<li>Summary: <p>The development of secure cryptographic protocols and the subsequent attack
mechanisms have been placed in the literature with the utmost curiosity.
</p>
<p>While sophisticated quantum attacks bring a concern to the classical
cryptographic protocols present in the applications used in everyday life, the
necessity of developing post-quantum protocols is felt primarily.
</p>
<p>In post-quantum cryptography, elliptic curve-base protocols are exciting to
the researchers.
</p>
<p>While the comprehensive study of elliptic curves over finite fields is well
known, the extended study over finite rings is still missing.
</p>
<p>In this work, we generalize the study of Weierstrass elliptic curves over
finite ring $\mathbb{Z}_n$ through classification.
</p>
<p>Several expressions to compute critical factors in studying elliptic curves
are conferred.
</p>
<p>An all-around computational classification on the Weierstrass elliptic curves
over $\mathbb{Z}_n$ for rigorous understanding is also attached to this work.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: The Efficacy of Transformer-based Adversarial Attacks in Security Domains. (arXiv:2310.11597v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11597">http://arxiv.org/abs/2310.11597</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11597]] The Efficacy of Transformer-based Adversarial Attacks in Security Domains(http://arxiv.org/abs/2310.11597)</code></li>
<li>Summary: <p>Today, the security of many domains rely on the use of Machine Learning to
detect threats, identify vulnerabilities, and safeguard systems from attacks.
Recently, transformer architectures have improved the state-of-the-art
performance on a wide range of tasks such as malware detection and network
intrusion detection. But, before abandoning current approaches to transformers,
it is crucial to understand their properties and implications on cybersecurity
applications. In this paper, we evaluate the robustness of transformers to
adversarial samples for system defenders (i.e., resiliency to adversarial
perturbations generated on different types of architectures) and their
adversarial strength for system attackers (i.e., transferability of adversarial
samples generated by transformers to other target models). To that effect, we
first fine-tune a set of pre-trained transformer, Convolutional Neural Network
(CNN), and hybrid (an ensemble of transformer and CNN) models to solve
different downstream image-based tasks. Then, we use an attack algorithm to
craft 19,367 adversarial examples on each model for each task. The
transferability of these adversarial examples is measured by evaluating each
set on other models to determine which models offer more adversarial strength,
and consequently, more robustness against these attacks. We find that the
adversarial examples crafted on transformers offer the highest transferability
rate (i.e., 25.7% higher than the average) onto other models. Similarly,
adversarial examples crafted on other models have the lowest rate of
transferability (i.e., 56.7% lower than the average) onto transformers. Our
work emphasizes the importance of studying transformer architectures for
attacking and defending models in security domains, and suggests using them as
the primary architecture in transfer attack settings.
</p></li>
</ul>

<h3>Title: Evolving Bitcoin Custody. (arXiv:2310.11911v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11911">http://arxiv.org/abs/2310.11911</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11911]] Evolving Bitcoin Custody(http://arxiv.org/abs/2310.11911)</code></li>
<li>Summary: <p>The broad topic of this thesis is the design and analysis of Bitcoin custody
systems. Both the technology and threat landscape are evolving constantly.
Therefore, custody systems, defence strategies, and risk models should be
adaptive too.
</p>
<p>We introduce Bitcoin custody by describing the different types, design
principles, phases and functions of custody systems. We review the technology
stack of these systems and focus on the fundamentals; key-management and
privacy. We present a perspective we call the systems view. It is an attempt to
capture the full complexity of a custody system, including technology, people,
and processes. We review existing custody systems and standards.
</p>
<p>We explore Bitcoin covenants. This is a mechanism to enforce constraints on
transaction sequences. Although previous work has proposed how to construct and
apply Bitcoin covenants, these require modifying the consensus rules of
Bitcoin, a notoriously difficult task. We introduce the first detailed
exposition and security analysis of a deleted-key covenant protocol, which is
compatible with current consensus rules. We demonstrate a range of security
models for deleted-key covenants which seem practical, in particular, when
applied in autonomous (user-controlled) custody systems. We conclude with a
comparative analysis with previous proposals.
</p>
<p>Covenants are often proclaimed to be an important primitive for custody
systems, but no complete design has been proposed to validate that claim. To
address this, we propose an autonomous custody system called Ajolote which uses
deleted-key covenants to enforce a vault sequence. We evaluate Ajolote with; a
model of its state dynamics, a privacy analysis, and a risk model. We propose a
threat model for custody systems which captures a realistic attacker for a
system with offline devices and user-verification. We perform ceremony analysis
to construct the risk model.
</p></li>
</ul>

<h3>Title: Envisioning the Future of Cyber Security in Post-Quantum Era: A Survey on PQ Standardization, Applications, Challenges and Opportunities. (arXiv:2310.12037v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12037">http://arxiv.org/abs/2310.12037</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12037]] Envisioning the Future of Cyber Security in Post-Quantum Era: A Survey on PQ Standardization, Applications, Challenges and Opportunities(http://arxiv.org/abs/2310.12037)</code></li>
<li>Summary: <p>The rise of quantum computers exposes vulnerabilities in current public key
cryptographic protocols, necessitating the development of secure post-quantum
(PQ) schemes. Hence, we conduct a comprehensive study on various PQ approaches,
covering the constructional design, structural vulnerabilities, and offer
security assessments, implementation evaluations, and a particular focus on
side-channel attacks. We analyze global standardization processes, evaluate
their metrics in relation to real-world applications, and primarily focus on
standardized PQ schemes, selected additional signature competition candidates,
and PQ-secure cutting-edge schemes beyond standardization. Finally, we present
visions and potential future directions for a seamless transition to the PQ
era.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation. (arXiv:2310.11730v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11730">http://arxiv.org/abs/2310.11730</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11730]] Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation(http://arxiv.org/abs/2310.11730)</code></li>
<li>Summary: <p>Heterogeneous information network (HIN), which contains rich semantics
depicted by meta-paths, has become a powerful tool to alleviate data sparsity
in recommender systems. Existing HIN-based recommendations hold the data
centralized storage assumption and conduct centralized model training. However,
the real-world data is often stored in a distributed manner for privacy
concerns, resulting in the failure of centralized HIN-based recommendations. In
this paper, we suggest the HIN is partitioned into private HINs stored in the
client side and shared HINs in the server. Following this setting, we propose a
federated heterogeneous graph neural network (FedHGNN) based framework, which
can collaboratively train a recommendation model on distributed HINs without
leaking user privacy. Specifically, we first formalize the privacy definition
in the light of differential privacy for HIN-based federated recommendation,
which aims to protect user-item interactions of private HIN as well as user's
high-order patterns from shared HINs. To recover the broken meta-path based
semantics caused by distributed data storage and satisfy the proposed privacy,
we elaborately design a semantic-preserving user interactions publishing
method, which locally perturbs user's high-order patterns as well as related
user-item interactions for publishing. After that, we propose a HGNN model for
recommendation, which conducts node- and semantic-level aggregations to capture
recovered semantics. Extensive experiments on three datasets demonstrate our
model outperforms existing methods by a large margin (up to 34% in HR@10 and
42% in NDCG@10) under an acceptable privacy budget.
</p></li>
</ul>

<h3>Title: Quantifying Privacy Risks of Prompts in Visual Prompt Learning. (arXiv:2310.11970v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11970">http://arxiv.org/abs/2310.11970</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11970]] Quantifying Privacy Risks of Prompts in Visual Prompt Learning(http://arxiv.org/abs/2310.11970)</code></li>
<li>Summary: <p>Large-scale pre-trained models are increasingly adapted to downstream tasks
through a new paradigm called prompt learning. In contrast to fine-tuning,
prompt learning does not update the pre-trained model's parameters. Instead, it
only learns an input perturbation, namely prompt, to be added to the downstream
task data for predictions. Given the fast development of prompt learning, a
well-generalized prompt inevitably becomes a valuable asset as significant
effort and proprietary data are used to create it. This naturally raises the
question of whether a prompt may leak the proprietary information of its
training data. In this paper, we perform the first comprehensive privacy
assessment of prompts learned by visual prompt learning through the lens of
property inference and membership inference attacks. Our empirical evaluation
shows that the prompts are vulnerable to both attacks. We also demonstrate that
the adversary can mount a successful property inference attack with limited
cost. Moreover, we show that membership inference attacks against prompts can
be successful with relaxed adversarial assumptions. We further make some
initial investigations on the defenses and observe that our method can mitigate
the membership inference attacks with a decent utility-defense trade-off but
fails to defend against property inference attacks. We hope our results can
shed light on the privacy risks of the popular prompt learning paradigm. To
facilitate the research in this direction, we will share our code and models
with the community.
</p></li>
</ul>

<h3>Title: A Cautionary Tale: On the Role of Reference Data in Empirical Privacy Defenses. (arXiv:2310.12112v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12112">http://arxiv.org/abs/2310.12112</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12112]] A Cautionary Tale: On the Role of Reference Data in Empirical Privacy Defenses(http://arxiv.org/abs/2310.12112)</code></li>
<li>Summary: <p>Within the realm of privacy-preserving machine learning, empirical privacy
defenses have been proposed as a solution to achieve satisfactory levels of
training data privacy without a significant drop in model utility. Most
existing defenses against membership inference attacks assume access to
reference data, defined as an additional dataset coming from the same (or a
similar) underlying distribution as training data. Despite the common use of
reference data, previous works are notably reticent about defining and
evaluating reference data privacy. As gains in model utility and/or training
data privacy may come at the expense of reference data privacy, it is essential
that all three aspects are duly considered. In this paper, we first examine the
availability of reference data and its privacy treatment in previous works and
demonstrate its necessity for fairly comparing defenses. Second, we propose a
baseline defense that enables the utility-privacy tradeoff with respect to both
training and reference data to be easily understood. Our method is formulated
as an empirical risk minimization with a constraint on the generalization
error, which, in practice, can be evaluated as a weighted empirical risk
minimization (WERM) over the training and reference datasets. Although we
conceived of WERM as a simple baseline, our experiments show that,
surprisingly, it outperforms the most well-studied and current state-of-the-art
empirical privacy defenses using reference data for nearly all relative privacy
levels of reference and training data. Our investigation also reveals that
these existing methods are unable to effectively trade off reference data
privacy for model utility and/or training data privacy. Overall, our work
highlights the need for a proper evaluation of the triad model utility /
training data privacy / reference data privacy when comparing privacy defenses.
</p></li>
</ul>

<h3>Title: Learning under Label Proportions for Text Classification. (arXiv:2310.11707v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11707">http://arxiv.org/abs/2310.11707</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11707]] Learning under Label Proportions for Text Classification(http://arxiv.org/abs/2310.11707)</code></li>
<li>Summary: <p>We present one of the preliminary NLP works under the challenging setup of
Learning from Label Proportions (LLP), where the data is provided in an
aggregate form called bags and only the proportion of samples in each class as
the ground truth. This setup is inline with the desired characteristics of
training models under Privacy settings and Weakly supervision. By
characterizing some irregularities of the most widely used baseline technique
DLLP, we propose a novel formulation that is also robust. This is accompanied
with a learnability result that provides a generalization bound under LLP.
Combining this formulation with a self-supervised objective, our method
achieves better results as compared to the baselines in almost 87% of the
experimental configurations which include large scale models for both long and
short range texts across multiple metrics.
</p></li>
</ul>

<h3>Title: Unintended Memorization in Large ASR Models, and How to Mitigate It. (arXiv:2310.11739v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11739">http://arxiv.org/abs/2310.11739</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11739]] Unintended Memorization in Large ASR Models, and How to Mitigate It(http://arxiv.org/abs/2310.11739)</code></li>
<li>Summary: <p>It is well-known that neural networks can unintentionally memorize their
training examples, causing privacy concerns. However, auditing memorization in
large non-auto-regressive automatic speech recognition (ASR) models has been
challenging due to the high compute cost of existing methods such as hardness
calibration. In this work, we design a simple auditing method to measure
memorization in large ASR models without the extra compute overhead.
Concretely, we speed up randomly-generated utterances to create a mapping
between vocal and text information that is difficult to learn from typical
training examples. Hence, accurate predictions only for sped-up training
examples can serve as clear evidence for memorization, and the corresponding
accuracy can be used to measure memorization. Using the proposed method, we
showcase memorization in the state-of-the-art ASR models. To mitigate
memorization, we tried gradient clipping during training to bound the influence
of any individual example on the final model. We empirically show that clipping
each example's gradient can mitigate memorization for sped-up training examples
with up to 16 repetitions in the training set. Furthermore, we show that in
large-scale distributed training, clipping the average gradient on each compute
core maintains neutral model quality and compute cost while providing strong
privacy protection.
</p></li>
</ul>

<h3>Title: Black-Box Training Data Identification in GANs via Detector Networks. (arXiv:2310.12063v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12063">http://arxiv.org/abs/2310.12063</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12063]] Black-Box Training Data Identification in GANs via Detector Networks(http://arxiv.org/abs/2310.12063)</code></li>
<li>Summary: <p>Since their inception Generative Adversarial Networks (GANs) have been
popular generative models across images, audio, video, and tabular data. In
this paper we study whether given access to a trained GAN, as well as fresh
samples from the underlying distribution, if it is possible for an attacker to
efficiently identify if a given point is a member of the GAN's training data.
This is of interest for both reasons related to copyright, where a user may
want to determine if their copyrighted data has been used to train a GAN, and
in the study of data privacy, where the ability to detect training set
membership is known as a membership inference attack. Unlike the majority of
prior work this paper investigates the privacy implications of using GANs in
black-box settings, where the attack only has access to samples from the
generator, rather than access to the discriminator as well. We introduce a
suite of membership inference attacks against GANs in the black-box setting and
evaluate our attacks on image GANs trained on the CIFAR10 dataset and tabular
GANs trained on genomic data. Our most successful attack, called The Detector,
involve training a second network to score samples based on their likelihood of
being generated by the GAN, as opposed to a fresh sample from the distribution.
We prove under a simple model of the generator that the detector is an
approximately optimal membership inference attack. Across a wide range of
tabular and image datasets, attacks, and GAN architectures, we find that
adversaries can orchestrate non-trivial privacy attacks when provided with
access to samples from the generator. At the same time, the attack success
achievable against GANs still appears to be lower compared to other generative
and discriminative models; this leaves the intriguing open question of whether
GANs are in fact more private, or if it is a matter of developing stronger
attacks.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: In defense of parameter sharing for model-compression. (arXiv:2310.11611v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11611">http://arxiv.org/abs/2310.11611</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11611]] In defense of parameter sharing for model-compression(http://arxiv.org/abs/2310.11611)</code></li>
<li>Summary: <p>When considering a model architecture, there are several ways to reduce its
memory footprint. Historically, popular approaches included selecting smaller
architectures and creating sparse networks through pruning. More recently,
randomized parameter-sharing (RPS) methods have gained traction for model
compression at start of training. In this paper, we comprehensively assess the
trade-off between memory and accuracy across RPS, pruning techniques, and
building smaller models. Our findings demonstrate that RPS, which is both data
and model-agnostic, consistently outperforms/matches smaller models and all
moderately informed pruning strategies, such as MAG, SNIP, SYNFLOW, and GRASP,
across the entire compression range. This advantage becomes particularly
pronounced in higher compression scenarios. Notably, even when compared to
highly informed pruning techniques like Lottery Ticket Rewinding (LTR), RPS
exhibits superior performance in high compression settings. This points out
inherent capacity advantage that RPS enjoys over sparse models. Theoretically,
we establish RPS as a superior technique in terms of memory-efficient
representation when compared to pruning for linear models. This paper argues in
favor of paradigm shift towards RPS based models. During our rigorous
evaluation of RPS, we identified issues in the state-of-the-art RPS technique
ROAST, specifically regarding stability (ROAST's sensitivity to initialization
hyperparameters, often leading to divergence) and Pareto-continuity (ROAST's
inability to recover the accuracy of the original model at zero compression).
We provably address both of these issues. We refer to the modified RPS, which
incorporates our improvements, as STABLE-RPS.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks. (arXiv:2310.11595v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11595">http://arxiv.org/abs/2310.11595</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11595]] WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks(http://arxiv.org/abs/2310.11595)</code></li>
<li>Summary: <p>Due to the popularity of Artificial Intelligence (AI) technology, numerous
backdoor attacks are designed by adversaries to mislead deep neural network
predictions by manipulating training samples and training processes. Although
backdoor attacks are effective in various real scenarios, they still suffer
from the problems of both low fidelity of poisoned samples and non-negligible
transfer in latent space, which make them easily detectable by existing
backdoor detection algorithms. To overcome the weakness, this paper proposes a
novel frequency-based backdoor attack method named WaveAttack, which obtains
image high-frequency features through Discrete Wavelet Transform (DWT) to
generate backdoor triggers. Furthermore, we introduce an asymmetric frequency
obfuscation method, which can add an adaptive residual in the training and
inference stage to improve the impact of triggers and further enhance the
effectiveness of WaveAttack. Comprehensive experimental results show that
WaveAttack not only achieves higher stealthiness and effectiveness, but also
outperforms state-of-the-art (SOTA) backdoor attack methods in the fidelity of
images by up to 28.27\% improvement in PSNR, 1.61\% improvement in SSIM, and
70.59\% reduction in IS. Our code is available at
https://anonymous.4open.science/r/AnonymousRep-701D.
</p></li>
</ul>

<h3>Title: Domain-Generalized Face Anti-Spoofing with Unknown Attacks. (arXiv:2310.11758v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11758">http://arxiv.org/abs/2310.11758</a></li>
<li>Code URL: https://github.com/ai-application-and-integration-lab/dgua_fas</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11758]] Domain-Generalized Face Anti-Spoofing with Unknown Attacks(http://arxiv.org/abs/2310.11758)</code></li>
<li>Summary: <p>Although face anti-spoofing (FAS) methods have achieved remarkable
performance on specific domains or attack types, few studies have focused on
the simultaneous presence of domain changes and unknown attacks, which is
closer to real application scenarios. To handle domain-generalized unknown
attacks, we introduce a new method, DGUA-FAS, which consists of a
Transformer-based feature extractor and a synthetic unknown attack sample
generator (SUASG). The SUASG network simulates unknown attack samples to assist
the training of the feature extractor. Experimental results show that our
method achieves superior performance on domain generalization FAS with known or
unknown attacks.
</p></li>
</ul>

<h3>Title: Revisiting Transferable Adversarial Image Examples: Attack Categorization, Evaluation Guidelines, and New Insights. (arXiv:2310.11850v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11850">http://arxiv.org/abs/2310.11850</a></li>
<li>Code URL: https://github.com/zhengyuzhao/transferattackeval</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11850]] Revisiting Transferable Adversarial Image Examples: Attack Categorization, Evaluation Guidelines, and New Insights(http://arxiv.org/abs/2310.11850)</code></li>
<li>Summary: <p>Transferable adversarial examples raise critical security concerns in
real-world, black-box attack scenarios. However, in this work, we identify two
main problems in common evaluation practices: (1) For attack transferability,
lack of systematic, one-to-one attack comparison and fair hyperparameter
settings. (2) For attack stealthiness, simply no comparisons. To address these
problems, we establish new evaluation guidelines by (1) proposing a novel
attack categorization strategy and conducting systematic and fair
intra-category analyses on transferability, and (2) considering diverse
imperceptibility metrics and finer-grained stealthiness characteristics from
the perspective of attack traceback. To this end, we provide the first
large-scale evaluation of transferable adversarial examples on ImageNet,
involving 23 representative attacks against 9 representative defenses. Our
evaluation leads to a number of new insights, including consensus-challenging
ones: (1) Under a fair attack hyperparameter setting, one early attack method,
DI, actually outperforms all the follow-up methods. (2) A state-of-the-art
defense, DiffPure, actually gives a false sense of (white-box) security since
it is indeed largely bypassed by our (black-box) transferable attacks. (3) Even
when all attacks are bounded by the same $L_p$ norm, they lead to dramatically
different stealthiness performance, which negatively correlates with their
transferability performance. Overall, our work demonstrates that existing
problematic evaluations have indeed caused misleading conclusions and missing
points, and as a result, hindered the assessment of the actual progress in this
field.
</p></li>
</ul>

<h3>Title: IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks. (arXiv:2310.11890v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11890">http://arxiv.org/abs/2310.11890</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11890]] IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks(http://arxiv.org/abs/2310.11890)</code></li>
<li>Summary: <p>We introduce a novel approach to counter adversarial attacks, namely, image
resampling. Image resampling transforms a discrete image into a new one,
simulating the process of scene recapturing or rerendering as specified by a
geometrical transformation. The underlying rationale behind our idea is that
image resampling can alleviate the influence of adversarial perturbations while
preserving essential semantic information, thereby conferring an inherent
advantage in defending against adversarial attacks. To validate this concept,
we present a comprehensive study on leveraging image resampling to defend
against adversarial attacks. We have developed basic resampling methods that
employ interpolation strategies and coordinate shifting magnitudes. Our
analysis reveals that these basic methods can partially mitigate adversarial
attacks. However, they come with apparent limitations: the accuracy of clean
images noticeably decreases, while the improvement in accuracy on adversarial
examples is not substantial. We propose implicit representation-driven image
resampling (IRAD) to overcome these limitations. First, we construct an
implicit continuous representation that enables us to represent any input image
within a continuous coordinate space. Second, we introduce SampleNet, which
automatically generates pixel-wise shifts for resampling in response to
different inputs. Furthermore, we can extend our approach to the
state-of-the-art diffusion-based method, accelerating it with fewer time steps
while preserving its defense capability. Extensive experiments demonstrate that
our method significantly enhances the adversarial robustness of diverse deep
models against various attacks while maintaining high accuracy on clean images.
</p></li>
</ul>

<h3>Title: Exploring Decision-based Black-box Attacks on Face Forgery Detection. (arXiv:2310.12017v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12017">http://arxiv.org/abs/2310.12017</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12017]] Exploring Decision-based Black-box Attacks on Face Forgery Detection(http://arxiv.org/abs/2310.12017)</code></li>
<li>Summary: <p>Face forgery generation technologies generate vivid faces, which have raised
public concerns about security and privacy. Many intelligent systems, such as
electronic payment and identity verification, rely on face forgery detection.
Although face forgery detection has successfully distinguished fake faces,
recent studies have demonstrated that face forgery detectors are very
vulnerable to adversarial examples. Meanwhile, existing attacks rely on network
architectures or training datasets instead of the predicted labels, which leads
to a gap in attacking deployed applications. To narrow this gap, we first
explore the decision-based attacks on face forgery detection. However, applying
existing decision-based attacks directly suffers from perturbation
initialization failure and low image quality. First, we propose cross-task
perturbation to handle initialization failures by utilizing the high
correlation of face features on different tasks. Then, inspired by using
frequency cues by face forgery detection, we propose the frequency
decision-based attack. We add perturbations in the frequency domain and then
constrain the visual quality in the spatial domain. Finally, extensive
experiments demonstrate that our method achieves state-of-the-art attack
performance on FaceForensics++, CelebDF, and industrial APIs, with high query
efficiency and guaranteed image quality. Further, the fake faces by our method
can pass face forgery detection and face recognition, which exposes the
security problems of face forgery detectors.
</p></li>
</ul>

<h3>Title: PhishReplicant: A Language Model-based Approach to Detect Generated Squatting Domain Names. (arXiv:2310.11763v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11763">http://arxiv.org/abs/2310.11763</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11763]] PhishReplicant: A Language Model-based Approach to Detect Generated Squatting Domain Names(http://arxiv.org/abs/2310.11763)</code></li>
<li>Summary: <p>Domain squatting is a technique used by attackers to create domain names for
phishing sites. In recent phishing attempts, we have observed many domain names
that use multiple techniques to evade existing methods for domain squatting.
These domain names, which we call generated squatting domains (GSDs), are quite
different in appearance from legitimate domain names and do not contain brand
names, making them difficult to associate with phishing. In this paper, we
propose a system called PhishReplicant that detects GSDs by focusing on the
linguistic similarity of domain names. We analyzed newly registered and
observed domain names extracted from certificate transparency logs, passive
DNS, and DNS zone files. We detected 3,498 domain names acquired by attackers
in a four-week experiment, of which 2,821 were used for phishing sites within a
month of detection. We also confirmed that our proposed system outperformed
existing systems in both detection accuracy and number of domain names
detected. As an in-depth analysis, we examined 205k GSDs collected over 150
days and found that phishing using GSDs was distributed globally. However,
attackers intensively targeted brands in specific regions and industries. By
analyzing GSDs in real time, we can block phishing sites before or immediately
after they appear.
</p></li>
</ul>

<h3>Title: Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning. (arXiv:2310.11594v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11594">http://arxiv.org/abs/2310.11594</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11594]] Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning(http://arxiv.org/abs/2310.11594)</code></li>
<li>Summary: <p>In today's data-driven landscape, the delicate equilibrium between
safeguarding user privacy and unleashing data potential stands as a paramount
concern. Federated learning, which enables collaborative model training without
necessitating data sharing, has emerged as a privacy-centric solution. This
decentralized approach brings forth security challenges, notably poisoning and
backdoor attacks where malicious entities inject corrupted data. Our research,
initially spurred by test-time evasion attacks, investigates the intersection
of adversarial training and backdoor attacks within federated learning,
introducing Adversarial Robustness Unhardening (ARU). ARU is employed by a
subset of adversaries to intentionally undermine model robustness during
decentralized training, rendering models susceptible to a broader range of
evasion attacks. We present extensive empirical experiments evaluating ARU's
impact on adversarial training and existing robust aggregation defenses against
poisoning and backdoor attacks. Our findings inform strategies for enhancing
ARU to counter current defensive measures and highlight the limitations of
existing defenses, offering insights into bolstering defenses against ARU.
</p></li>
</ul>

<h3>Title: Adversarial Training for Physics-Informed Neural Networks. (arXiv:2310.11789v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11789">http://arxiv.org/abs/2310.11789</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11789]] Adversarial Training for Physics-Informed Neural Networks(http://arxiv.org/abs/2310.11789)</code></li>
<li>Summary: <p>Physics-informed neural networks have shown great promise in solving partial
differential equations. However, due to insufficient robustness, vanilla PINNs
often face challenges when solving complex PDEs, especially those involving
multi-scale behaviors or solutions with sharp or oscillatory characteristics.
To address these issues, based on the projected gradient descent adversarial
attack, we proposed an adversarial training strategy for PINNs termed by
AT-PINNs. AT-PINNs enhance the robustness of PINNs by fine-tuning the model
with adversarial samples, which can accurately identify model failure locations
and drive the model to focus on those regions during training. AT-PINNs can
also perform inference with temporal causality by selecting the initial
collocation points around temporal initial values. We implement AT-PINNs to the
elliptic equation with multi-scale coefficients, Poisson equation with
multi-peak solutions, Burgers equation with sharp solutions and the Allen-Cahn
equation. The results demonstrate that AT-PINNs can effectively locate and
reduce failure regions. Moreover, AT-PINNs are suitable for solving complex
PDEs, since locating failure regions through adversarial attacks is independent
of the size of failure regions or the complexity of the distribution.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Rethinking Class-incremental Learning in the Era of Large Pre-trained Models via Test-Time Adaptation. (arXiv:2310.11482v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11482">http://arxiv.org/abs/2310.11482</a></li>
<li>Code URL: https://github.com/iemprog/ttacil</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11482]] Rethinking Class-incremental Learning in the Era of Large Pre-trained Models via Test-Time Adaptation(http://arxiv.org/abs/2310.11482)</code></li>
<li>Summary: <p>Class-incremental learning (CIL) is a challenging task that involves
continually learning to categorize classes into new tasks without forgetting
previously learned information. The advent of the large pre-trained models
(PTMs) has fast-tracked the progress in CIL due to the highly transferable PTM
representations, where tuning a small set of parameters results in
state-of-the-art performance when compared with the traditional CIL methods
that are trained from scratch. However, repeated fine-tuning on each task
destroys the rich representations of the PTMs and further leads to forgetting
previous tasks. To strike a balance between the stability and plasticity of
PTMs for CIL, we propose a novel perspective of eliminating training on every
new task and instead performing test-time adaptation (TTA) directly on the test
instances. Concretely, we propose "Test-Time Adaptation for Class-Incremental
Learning" (TTACIL) that first fine-tunes Layer Norm parameters of the PTM on
each test instance for learning task-specific features, and then resets them
back to the base model to preserve stability. As a consequence, TTACIL does not
undergo any forgetting, while benefiting each task with the rich PTM features.
Additionally, by design, our method is robust to common data corruptions. Our
TTACIL outperforms several state-of-the-art CIL methods when evaluated on
multiple CIL benchmarks under both clean and corrupted data.
</p></li>
</ul>

<h3>Title: Holistic Parking Slot Detection with Polygon-Shaped Representations. (arXiv:2310.11629v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11629">http://arxiv.org/abs/2310.11629</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11629]] Holistic Parking Slot Detection with Polygon-Shaped Representations(http://arxiv.org/abs/2310.11629)</code></li>
<li>Summary: <p>Current parking slot detection in advanced driver-assistance systems (ADAS)
primarily relies on ultrasonic sensors. This method has several limitations
such as the need to scan the entire parking slot before detecting it, the
incapacity of detecting multiple slots in a row, and the difficulty of
classifying them. Due to the complex visual environment, vehicles are equipped
with surround view camera systems to detect vacant parking slots. Previous
research works in this field mostly use image-domain models to solve the
problem. These two-stage approaches separate the 2D detection and 3D pose
estimation steps using camera calibration. In this paper, we propose one-step
Holistic Parking Slot Network (HPS-Net), a tailor-made adaptation of the You
Only Look Once (YOLO)v4 algorithm. This camera-based approach directly outputs
the four vertex coordinates of the parking slot in topview domain, instead of a
bounding box in raw camera images. Several visible points and shapes can be
proposed from different angles. A novel regression loss function named
polygon-corner Generalized Intersection over Union (GIoU) for polygon vertex
position optimization is also proposed to manage the slot orientation and to
distinguish the entrance line. Experiments show that HPS-Net can detect various
vacant parking slots with a F1-score of 0.92 on our internal Valeo Parking
Slots Dataset (VPSD) and 0.99 on the public dataset PS2.0. It provides a
satisfying generalization and robustness in various parking scenarios, such as
indoor (F1: 0.86) or paved ground (F1: 0.91). Moreover, it achieves a real-time
detection speed of 17 FPS on Nvidia Drive AGX Xavier. A demo video can be found
at https://streamable.com/75j7sj.
</p></li>
</ul>

<h3>Title: RGM: A Robust Generalist Matching Model. (arXiv:2310.11755v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11755">http://arxiv.org/abs/2310.11755</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11755]] RGM: A Robust Generalist Matching Model(http://arxiv.org/abs/2310.11755)</code></li>
<li>Summary: <p>Finding corresponding pixels within a pair of images is a fundamental
computer vision task with various applications. Due to the specific
requirements of different tasks like optical flow estimation and local feature
matching, previous works are primarily categorized into dense matching and
sparse feature matching focusing on specialized architectures along with
task-specific datasets, which may somewhat hinder the generalization
performance of specialized models. In this paper, we propose a deep model for
sparse and dense matching, termed RGM (Robust Generalist Matching). In
particular, we elaborately design a cascaded GRU module for refinement by
exploring the geometric similarity iteratively at multiple scales following an
additional uncertainty estimation module for sparsification. To narrow the gap
between synthetic training samples and real-world scenarios, we build a new,
large-scale dataset with sparse correspondence ground truth by generating
optical flow supervision with greater intervals. As such, we are able to mix up
various dense and sparse matching datasets, significantly improving the
training diversity. The generalization capacity of our proposed RGM is greatly
improved by learning the matching and uncertainty estimation in a two-stage
manner on the large, mixed data. Superior performance is achieved for zero-shot
matching and downstream geometry estimation across multiple datasets,
outperforming the previous methods by a large margin.
</p></li>
</ul>

<h3>Title: HB-net: Holistic bursting cell cluster integrated network for occluded multi-objects recognition. (arXiv:2310.11834v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11834">http://arxiv.org/abs/2310.11834</a></li>
<li>Code URL: https://github.com/d-lab438/hb-net</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11834]] HB-net: Holistic bursting cell cluster integrated network for occluded multi-objects recognition(http://arxiv.org/abs/2310.11834)</code></li>
<li>Summary: <p>Within the realm of image recognition, a specific category of multi-label
classification (MLC) challenges arises when objects within the visual field may
occlude one another, demanding simultaneous identification of both occluded and
occluding objects. Traditional convolutional neural networks (CNNs) can tackle
these challenges; however, those models tend to be bulky and can only attain
modest levels of accuracy. Leveraging insights from cutting-edge neural science
research, specifically the Holistic Bursting (HB) cell, this paper introduces a
pioneering integrated network framework named HB-net. Built upon the foundation
of HB cell clusters, HB-net is designed to address the intricate task of
simultaneously recognizing multiple occluded objects within images. Various
Bursting cell cluster structures are introduced, complemented by an evidence
accumulation mechanism. Testing is conducted on multiple datasets comprising
digits and letters. The results demonstrate that models incorporating the HB
framework exhibit a significant $2.98\%$ enhancement in recognition accuracy
compared to models without the HB framework ($1.0298$ times, $p=0.0499$).
Although in high-noise settings, standard CNNs exhibit slightly greater
robustness when compared to HB-net models, the models that combine the HB
framework and EA mechanism achieve a comparable level of accuracy and
resilience to ResNet50, despite having only three convolutional layers and
approximately $1/30$ of the parameters. The findings of this study offer
valuable insights for improving computer vision algorithms. The essential code
is provided at https://github.com/d-lab438/hb-net.git.
</p></li>
</ul>

<h3>Title: Robust Class-Conditional Distribution Alignment for Partial Domain Adaptation. (arXiv:2310.12060v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12060">http://arxiv.org/abs/2310.12060</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12060]] Robust Class-Conditional Distribution Alignment for Partial Domain Adaptation(http://arxiv.org/abs/2310.12060)</code></li>
<li>Summary: <p>Unwanted samples from private source categories in the learning objective of
a partial domain adaptation setup can lead to negative transfer and reduce
classification performance. Existing methods, such as re-weighting or
aggregating target predictions, are vulnerable to this issue, especially during
initial training stages, and do not adequately address overlapping categorical
distributions. We propose a solution to overcome these limitations by exploring
beyond the first-order moments for robust alignment of categorical
distributions. We employ objectives that optimize the intra and inter-class
distributions in a domain-invariant fashion and design a robust pseudo-labeling
for efficient target supervision. Our approach incorporates a complement
entropy objective module to reduce classification uncertainty and flatten
incorrect category predictions. The experimental findings and ablation analysis
of the proposed modules demonstrate the superior performance of our proposed
model compared to benchmarks.
</p></li>
</ul>

<h3>Title: Learning from Rich Semantics and Coarse Locations for Long-tailed Object Detection. (arXiv:2310.12152v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12152">http://arxiv.org/abs/2310.12152</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12152]] Learning from Rich Semantics and Coarse Locations for Long-tailed Object Detection(http://arxiv.org/abs/2310.12152)</code></li>
<li>Summary: <p>Long-tailed object detection (LTOD) aims to handle the extreme data imbalance
in real-world datasets, where many tail classes have scarce instances. One
popular strategy is to explore extra data with image-level labels, yet it
produces limited results due to (1) semantic ambiguity -- an image-level label
only captures a salient part of the image, ignoring the remaining rich
semantics within the image; and (2) location sensitivity -- the label highly
depends on the locations and crops of the original image, which may change
after data transformations like random cropping. To remedy this, we propose
RichSem, a simple but effective method, which is robust to learn rich semantics
from coarse locations without the need of accurate bounding boxes. RichSem
leverages rich semantics from images, which are then served as additional soft
supervision for training detectors. Specifically, we add a semantic branch to
our detector to learn these soft semantics and enhance feature representations
for long-tailed object detection. The semantic branch is only used for training
and is removed during inference. RichSem achieves consistent improvements on
both overall and rare-category of LVIS under different backbones and detectors.
Our method achieves state-of-the-art performance without requiring complex
training and testing procedures. Moreover, we show the effectiveness of our
method on other long-tailed datasets with additional experiments. Code is
available at \url{https://github.com/MengLcool/RichSem}.
</p></li>
</ul>

<h3>Title: BaitBuster-Bangla: A Comprehensive Dataset for Clickbait Detection in Bangla with Multi-Feature and Multi-Modal Analysis. (arXiv:2310.11465v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11465">http://arxiv.org/abs/2310.11465</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11465]] BaitBuster-Bangla: A Comprehensive Dataset for Clickbait Detection in Bangla with Multi-Feature and Multi-Modal Analysis(http://arxiv.org/abs/2310.11465)</code></li>
<li>Summary: <p>This study presents a large multi-modal Bangla YouTube clickbait dataset
consisting of 253,070 data points collected through an automated process using
the YouTube API and Python web automation frameworks. The dataset contains 18
diverse features categorized into metadata, primary content, engagement
statistics, and labels for individual videos from 58 Bangla YouTube channels. A
rigorous preprocessing step has been applied to denoise, deduplicate, and
remove bias from the features, ensuring unbiased and reliable analysis. As the
largest and most robust clickbait corpus in Bangla to date, this dataset
provides significant value for natural language processing and data science
researchers seeking to advance modeling of clickbait phenomena in low-resource
languages. Its multi-modal nature allows for comprehensive analyses of
clickbait across content, user interactions, and linguistic dimensions to
develop more sophisticated detection methods with cross-linguistic
applications.
</p></li>
</ul>

<h3>Title: Unveiling the General Intelligence Factor in Language Models: A Psychometric Approach. (arXiv:2310.11616v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11616">http://arxiv.org/abs/2310.11616</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11616]] Unveiling the General Intelligence Factor in Language Models: A Psychometric Approach(http://arxiv.org/abs/2310.11616)</code></li>
<li>Summary: <p>This study uncovers the factor of general intelligence, or g, in language
models, extending the psychometric theory traditionally applied to humans and
certain animal species. Utilizing factor analysis on two extensive datasets -
Open LLM Leaderboard with 1,232 models and General Language Understanding
Evaluation (GLUE) Leaderboard with 88 models - we find compelling evidence for
a unidimensional, highly stable g factor that accounts for 85% of the variance
in model performance. The study also finds a moderate correlation of .48
between model size and g. The discovery of g in language models offers a
unified metric for model evaluation and opens new avenues for more robust,
g-based model ability assessment. These findings lay the foundation for
understanding and future research on artificial general intelligence from a
psychometric perspective and have practical implications for model evaluation
and development.
</p></li>
</ul>

<h3>Title: Learn Your Tokens: Word-Pooled Tokenization for Language Modeling. (arXiv:2310.11628v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11628">http://arxiv.org/abs/2310.11628</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11628]] Learn Your Tokens: Word-Pooled Tokenization for Language Modeling(http://arxiv.org/abs/2310.11628)</code></li>
<li>Summary: <p>Language models typically tokenize text into subwords, using a deterministic,
hand-engineered heuristic of combining characters into longer surface-level
strings such as 'ing' or whole words. Recent literature has repeatedly shown
the limitations of such a tokenization strategy, particularly for documents not
written in English and for representing numbers. On the other extreme,
byte/character-level language models are much less restricted but suffer from
increased sequence description lengths and a subsequent quadratic expansion in
self-attention computation. Recent attempts to compress and limit these context
lengths with fixed size convolutions is helpful but completely ignores the word
boundary. This paper considers an alternative 'learn your tokens' scheme which
utilizes the word boundary to pool bytes/characters into word representations,
which are fed to the primary language model, before again decoding individual
characters/bytes per word in parallel. We find that our moderately expressive
and moderately fast end-to-end tokenizer outperform by over 300% both subwords
and byte/character models over the intrinsic language modeling metric of
next-word prediction across datasets. It particularly outshines on rare words,
outperforming by a factor of 30! We extensively study the language modeling
setup for all three categories of tokenizers and theoretically analyze how our
end-to-end models can also be a strong trade-off in efficiency and robustness.
</p></li>
</ul>

<h3>Title: Filling in the Gaps: Efficient Event Coreference Resolution using Graph Autoencoder Networks. (arXiv:2310.11965v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11965">http://arxiv.org/abs/2310.11965</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11965]] Filling in the Gaps: Efficient Event Coreference Resolution using Graph Autoencoder Networks(http://arxiv.org/abs/2310.11965)</code></li>
<li>Summary: <p>We introduce a novel and efficient method for Event Coreference Resolution
(ECR) applied to a lower-resourced language domain. By framing ECR as a graph
reconstruction task, we are able to combine deep semantic embeddings with
structural coreference chain knowledge to create a parameter-efficient family
of Graph Autoencoder models (GAE). Our method significantly outperforms
classical mention-pair methods on a large Dutch event coreference corpus in
terms of overall score, efficiency and training speed. Additionally, we show
that our models are consistently able to classify more difficult coreference
links and are far more robust in low-data settings when compared to
transformer-based mention-pair coreference algorithms.
</p></li>
</ul>

<h3>Title: CORE: A Few-Shot Company Relation Classification Dataset for Robust Domain Adaptation. (arXiv:2310.12024v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12024">http://arxiv.org/abs/2310.12024</a></li>
<li>Code URL: https://github.com/pnborchert/core</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12024]] CORE: A Few-Shot Company Relation Classification Dataset for Robust Domain Adaptation(http://arxiv.org/abs/2310.12024)</code></li>
<li>Summary: <p>We introduce CORE, a dataset for few-shot relation classification (RC)
focused on company relations and business entities. CORE includes 4,708
instances of 12 relation types with corresponding textual evidence extracted
from company Wikipedia pages. Company names and business entities pose a
challenge for few-shot RC models due to the rich and diverse information
associated with them. For example, a company name may represent the legal
entity, products, people, or business divisions depending on the context.
Therefore, deriving the relation type between entities is highly dependent on
textual context. To evaluate the performance of state-of-the-art RC models on
the CORE dataset, we conduct experiments in the few-shot domain adaptation
setting. Our results reveal substantial performance gaps, confirming that
models trained on different domains struggle to adapt to CORE. Interestingly,
we find that models trained on CORE showcase improved out-of-domain
performance, which highlights the importance of high-quality data for robust
domain adaptation. Specifically, the information richness embedded in business
entities allows models to focus on contextual nuances, reducing their reliance
on superficial clues such as relation-specific verbs. In addition to the
dataset, we provide relevant code snippets to facilitate reproducibility and
encourage further research in the field.
</p></li>
</ul>

<h3>Title: Malicious Agent Detection for Robust Multi-Agent Collaborative Perception. (arXiv:2310.11901v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11901">http://arxiv.org/abs/2310.11901</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11901]] Malicious Agent Detection for Robust Multi-Agent Collaborative Perception(http://arxiv.org/abs/2310.11901)</code></li>
<li>Summary: <p>Recently, multi-agent collaborative (MAC) perception has been proposed and
outperformed the traditional single-agent perception in many applications, such
as autonomous driving. However, MAC perception is more vulnerable to
adversarial attacks than single-agent perception due to the information
exchange. The attacker can easily degrade the performance of a victim agent by
sending harmful information from a malicious agent nearby. In this paper, we
extend adversarial attacks to an important perception task -- MAC object
detection, where generic defenses such as adversarial training are no longer
effective against these attacks. More importantly, we propose Malicious Agent
Detection (MADE), a reactive defense specific to MAC perception that can be
deployed by each agent to accurately detect and then remove any potential
malicious agent in its local collaboration network. In particular, MADE
inspects each agent in the network independently using a semi-supervised
anomaly detector based on a double-hypothesis test with the Benjamini-Hochberg
procedure to control the false positive rate of the inference. For the two
hypothesis tests, we propose a match loss statistic and a collaborative
reconstruction loss statistic, respectively, both based on the consistency
between the agent to be inspected and the ego agent where our detector is
deployed. We conduct comprehensive evaluations on a benchmark 3D dataset
V2X-sim and a real-road dataset DAIR-V2X and show that with the protection of
MADE, the drops in the average precision compared with the best-case "oracle"
defender against our attack are merely 1.28% and 0.34%, respectively, much
lower than 8.92% and 10.00% for adversarial training, respectively.
</p></li>
</ul>

<h3>Title: Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction. (arXiv:2310.11466v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11466">http://arxiv.org/abs/2310.11466</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11466]] Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction(http://arxiv.org/abs/2310.11466)</code></li>
<li>Summary: <p>Protein structure-based property prediction has emerged as a promising
approach for various biological tasks, such as protein function prediction and
sub-cellular location estimation. The existing methods highly rely on
experimental protein structure data and fail in scenarios where these data are
unavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were
utilized as alternatives. However, we observed that current practices, which
simply employ accurately predicted structures during inference, suffer from
notable degradation in prediction accuracy. While similar phenomena have been
extensively studied in general fields (e.g., Computer Vision) as model
robustness, their impact on protein property prediction remains unexplored. In
this paper, we first investigate the reason behind the performance decrease
when utilizing predicted structures, attributing it to the structure embedding
bias from the perspective of structure representation learning. To study this
problem, we identify a Protein 3D Graph Structure Learning Problem for Robust
Protein Property Prediction (PGSL-RP3), collect benchmark datasets, and present
a protein Structure embedding Alignment Optimization framework (SAO) to
mitigate the problem of structure embedding bias between the predicted and
experimental protein structures. Extensive experiments have shown that our
framework is model-agnostic and effective in improving the property prediction
of both predicted structures and experimental structures. The benchmark
datasets and codes will be released to benefit the community.
</p></li>
</ul>

<h3>Title: Robust-MBFD: A Robust Deep Learning System for Motor Bearing Faults Detection Using Multiple Deep Learning Training Strategies and A Novel Double Loss Function. (arXiv:2310.11477v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11477">http://arxiv.org/abs/2310.11477</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11477]] Robust-MBFD: A Robust Deep Learning System for Motor Bearing Faults Detection Using Multiple Deep Learning Training Strategies and A Novel Double Loss Function(http://arxiv.org/abs/2310.11477)</code></li>
<li>Summary: <p>This paper presents a comprehensive analysis of motor bearing fault detection
(MBFD), which involves the task of identifying faults in a motor bearing based
on its vibration. To this end, we first propose and evaluate various machine
learning based systems for the MBFD task. Furthermore, we propose three deep
learning based systems for the MBFD task, each of which explores one of the
following training strategies: supervised learning, semi-supervised learning,
and unsupervised learning. The proposed machine learning based systems and deep
learning based systems are evaluated, compared, and then they are used to
identify the best model for the MBFD task. We conducted extensive experiments
on various benchmark datasets of motor bearing faults, including those from the
American Society for Mechanical Failure Prevention Technology (MFPT), Case
Western Reserve University Bearing Center (CWRU), and the Condition Monitoring
of Bearing Damage in Electromechanical Drive Systems from Paderborn University
(PU). The experimental results on different datasets highlight two main
contributions of this study. First, we prove that deep learning based systems
are more effective than machine learning based systems for the MBFD task.
Second, we achieve a robust and general deep learning based system with a novel
loss function for the MBFD task on several benchmark datasets, demonstrating
its potential for real-life MBFD applications.
</p></li>
</ul>

<h3>Title: When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2310.11569v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11569">http://arxiv.org/abs/2310.11569</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11569]] When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting(http://arxiv.org/abs/2310.11569)</code></li>
<li>Summary: <p>Probabilistic hierarchical time-series forecasting is an important variant of
time-series forecasting, where the goal is to model and forecast multivariate
time-series that have underlying hierarchical relations. Most methods focus on
point predictions and do not provide well-calibrated probabilistic forecasts
distributions. Recent state-of-art probabilistic forecasting methods also
impose hierarchical relations on point predictions and samples of distribution
which does not account for coherency of forecast distributions. Previous works
also silently assume that datasets are always consistent with given
hierarchical relations and do not adapt to real-world datasets that show
deviation from this assumption. We close both these gap and propose PROFHiT,
which is a fully probabilistic hierarchical forecasting model that jointly
models forecast distribution of entire hierarchy. PROFHiT uses a flexible
probabilistic Bayesian approach and introduces a novel Distributional Coherency
regularization to learn from hierarchical relations for entire forecast
distribution that enables robust and calibrated forecasts as well as adapt to
datasets of varying hierarchical consistency. On evaluating PROFHiT over wide
range of datasets, we observed 41-88% better performance in accuracy and
significantly better calibration. Due to modeling the coherency over full
distribution, we observed that PROFHiT can robustly provide reliable forecasts
even if up to 10% of input time-series data is missing where other methods'
performance severely degrade by over 70%.
</p></li>
</ul>

<h3>Title: TK-KNN: A Balanced Distance-Based Pseudo Labeling Approach for Semi-Supervised Intent Classification. (arXiv:2310.11607v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11607">http://arxiv.org/abs/2310.11607</a></li>
<li>Code URL: https://github.com/servicenow/tk-knn</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11607]] TK-KNN: A Balanced Distance-Based Pseudo Labeling Approach for Semi-Supervised Intent Classification(http://arxiv.org/abs/2310.11607)</code></li>
<li>Summary: <p>The ability to detect intent in dialogue systems has become increasingly
important in modern technology. These systems often generate a large amount of
unlabeled data, and manually labeling this data requires substantial human
effort. Semi-supervised methods attempt to remedy this cost by using a model
trained on a few labeled examples and then by assigning pseudo-labels to
further a subset of unlabeled examples that has a model prediction confidence
higher than a certain threshold. However, one particularly perilous consequence
of these methods is the risk of picking an imbalanced set of examples across
classes, which could lead to poor labels. In the present work, we describe
Top-K K-Nearest Neighbor (TK-KNN), which uses a more robust pseudo-labeling
approach based on distance in the embedding space while maintaining a balanced
set of pseudo-labeled examples across classes through a ranking-based approach.
Experiments on several datasets show that TK-KNN outperforms existing models,
particularly when labeled data is scarce on popular datasets such as CLINC150
and Banking77. Code is available at https://github.com/ServiceNow/tk-knn
</p></li>
</ul>

<h3>Title: PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly Detection. (arXiv:2310.11676v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11676">http://arxiv.org/abs/2310.11676</a></li>
<li>Code URL: https://github.com/campanulabells/prem-gad</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11676]] PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly Detection(http://arxiv.org/abs/2310.11676)</code></li>
<li>Summary: <p>Node-level graph anomaly detection (GAD) plays a critical role in identifying
anomalous nodes from graph-structured data in various domains such as medicine,
social networks, and e-commerce. However, challenges have arisen due to the
diversity of anomalies and the dearth of labeled data. Existing methodologies -
reconstruction-based and contrastive learning - while effective, often suffer
from efficiency issues, stemming from their complex objectives and elaborate
modules. To improve the efficiency of GAD, we introduce a simple method termed
PREprocessing and Matching (PREM for short). Our approach streamlines GAD,
reducing time and memory consumption while maintaining powerful anomaly
detection capabilities. Comprising two modules - a pre-processing module and an
ego-neighbor matching module - PREM eliminates the necessity for
message-passing propagation during training, and employs a simple contrastive
loss, leading to considerable reductions in training time and memory usage.
Moreover, through rigorous evaluations of five real-world datasets, our method
demonstrated robustness and effectiveness. Notably, when validated on the ACM
dataset, PREM achieved a 5% improvement in AUC, a 9-fold increase in training
speed, and sharply reduce memory usage compared to the most efficient baseline.
</p></li>
</ul>

<h3>Title: NeuroCUT: A Neural Approach for Robust Graph Partitioning. (arXiv:2310.11787v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11787">http://arxiv.org/abs/2310.11787</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11787]] NeuroCUT: A Neural Approach for Robust Graph Partitioning(http://arxiv.org/abs/2310.11787)</code></li>
<li>Summary: <p>Graph partitioning aims to divide a graph into $k$ disjoint subsets while
optimizing a specific partitioning objective. The majority of formulations
related to graph partitioning exhibit NP-hardness due to their combinatorial
nature. As a result, conventional approximation algorithms rely on heuristic
methods, sometimes with approximation guarantees and sometimes without.
Unfortunately, traditional approaches are tailored for specific partitioning
objectives and do not generalize well across other known partitioning
objectives from the literature. To overcome this limitation, and learn
heuristics from the data directly, neural approaches have emerged,
demonstrating promising outcomes. In this study, we extend this line of work
through a novel framework, NeuroCut. NeuroCut introduces two key innovations
over prevailing methodologies. First, it is inductive to both graph topology
and the partition count, which is provided at query time. Second, by leveraging
a reinforcement learning based framework over node representations derived from
a graph neural network, NeuroCut can accommodate any optimization objective,
even those encompassing non-differentiable functions. Through empirical
evaluation, we demonstrate that NeuroCut excels in identifying high-quality
partitions, showcases strong generalization across a wide spectrum of
partitioning objectives, and exhibits resilience to topological modifications.
</p></li>
</ul>

<h3>Title: Understanding Reward Ambiguity Through Optimal Transport Theory in Inverse Reinforcement Learning. (arXiv:2310.12055v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12055">http://arxiv.org/abs/2310.12055</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12055]] Understanding Reward Ambiguity Through Optimal Transport Theory in Inverse Reinforcement Learning(http://arxiv.org/abs/2310.12055)</code></li>
<li>Summary: <p>In inverse reinforcement learning (IRL), the central objective is to infer
underlying reward functions from observed expert behaviors in a way that not
only explains the given data but also generalizes to unseen scenarios. This
ensures robustness against reward ambiguity where multiple reward functions can
equally explain the same expert behaviors. While significant efforts have been
made in addressing this issue, current methods often face challenges with
high-dimensional problems and lack a geometric foundation. This paper harnesses
the optimal transport (OT) theory to provide a fresh perspective on these
challenges. By utilizing the Wasserstein distance from OT, we establish a
geometric framework that allows for quantifying reward ambiguity and
identifying a central representation or centroid of reward functions. These
insights pave the way for robust IRL methodologies anchored in geometric
interpretations, offering a structured approach to tackle reward ambiguity in
high-dimensional settings.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: DBDNet:Partial-to-Partial Point Cloud Registration with Dual Branches Decoupling. (arXiv:2310.11733v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11733">http://arxiv.org/abs/2310.11733</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11733]] DBDNet:Partial-to-Partial Point Cloud Registration with Dual Branches Decoupling(http://arxiv.org/abs/2310.11733)</code></li>
<li>Summary: <p>Point cloud registration plays a crucial role in various computer vision
tasks, and usually demands the resolution of partial overlap registration in
practice. Most existing methods perform a serial calculation of rotation and
translation, while jointly predicting overlap during registration, this
coupling tends to degenerate the registration performance. In this paper, we
propose an effective registration method with dual branches decoupling for
partial-to-partial registration, dubbed as DBDNet. Specifically, we introduce a
dual branches structure to eliminate mutual interference error between rotation
and translation by separately creating two individual correspondence matrices.
For partial-to-partial registration, we consider overlap prediction as a
preordering task before the registration procedure. Accordingly, we present an
overlap predictor that benefits from explicit feature interaction, which is
achieved by the powerful attention mechanism to accurately predict pointwise
masks. Furthermore, we design a multi-resolution feature extraction network to
capture both local and global patterns thus enhancing both overlap prediction
and registration module. Experimental results on both synthetic and real
datasets validate the effectiveness of our proposed method.
</p></li>
</ul>

<h3>Title: MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and Phonetic Domains for Speech Representation Learning. (arXiv:2310.11541v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11541">http://arxiv.org/abs/2310.11541</a></li>
<li>Code URL: https://github.com/noetits/must_p-srl</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11541]] MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and Phonetic Domains for Speech Representation Learning(http://arxiv.org/abs/2310.11541)</code></li>
<li>Summary: <p>In this paper, we present a methodology for linguistic feature extraction,
focusing particularly on automatically syllabifying words in multiple
languages, with a design to be compatible with a forced-alignment tool, the
Montreal Forced Aligner (MFA). In both the textual and phonetic domains, our
method focuses on the extraction of phonetic transcriptions from text, stress
marks, and a unified automatic syllabification (in text and phonetic domains).
The system was built with open-source components and resources. Through an
ablation study, we demonstrate the efficacy of our approach in automatically
syllabifying words from several languages (English, French and Spanish).
Additionally, we apply the technique to the transcriptions of the CMU ARCTIC
dataset, generating valuable annotations available
online\footnote{\url{https://github.com/noetits/MUST_P-SRL}} that are ideal for
speech representation learning, speech unit discovery, and disentanglement of
speech factors in several speech-related fields.
</p></li>
</ul>

<h3>Title: Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding. (arXiv:2310.11721v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11721">http://arxiv.org/abs/2310.11721</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11721]] Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding(http://arxiv.org/abs/2310.11721)</code></li>
<li>Summary: <p>Chain-of-Thought (CoT) is a technique that guides Large Language Models
(LLMs) to decompose complex tasks into multi-step reasoning through
intermediate steps in natural language form. Briefly, CoT enables LLMs to think
step by step. However, although many Natural Language Understanding (NLU) tasks
also require thinking step by step, LLMs perform less well than small-scale
Masked Language Models (MLMs). To migrate CoT from LLMs to MLMs, we propose
Chain-of-Thought Tuning (CoTT), a two-step reasoning framework based on prompt
tuning, to implement step-by-step thinking for MLMs on NLU tasks. From the
perspective of CoT, CoTT's two-step framework enables MLMs to implement task
decomposition; CoTT's prompt tuning allows intermediate steps to be used in
natural language form. Thereby, the success of CoT can be extended to NLU tasks
through MLMs. To verify the effectiveness of CoTT, we conduct experiments on
two NLU tasks: hierarchical classification and relation extraction, and the
results show that CoTT outperforms baselines and achieves state-of-the-art
performance.
</p></li>
</ul>

<h3>Title: Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas Incidents for Preventing Future Failures. (arXiv:2310.12074v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12074">http://arxiv.org/abs/2310.12074</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12074]] Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas Incidents for Preventing Future Failures(http://arxiv.org/abs/2310.12074)</code></li>
<li>Summary: <p>This paper introduces a new IncidentAI dataset for safety prevention.
Different from prior corpora that usually contain a single task, our dataset
comprises three tasks: named entity recognition, cause-effect extraction, and
information retrieval. The dataset is annotated by domain experts who have at
least six years of practical experience as high-pressure gas conservation
managers. We validate the contribution of the dataset in the scenario of safety
prevention. Preliminary results on the three tasks show that NLP techniques are
beneficial for analyzing incident reports to prevent future failures. The
dataset facilitates future research in NLP and incident management communities.
The access to the dataset is also provided (the IncidentAI dataset is available
at: https://github.com/Cinnamon/incident-ai-dataset).
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Effective and Efficient Federated Tree Learning on Hybrid Data. (arXiv:2310.11865v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11865">http://arxiv.org/abs/2310.11865</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11865]] Effective and Efficient Federated Tree Learning on Hybrid Data(http://arxiv.org/abs/2310.11865)</code></li>
<li>Summary: <p>Federated learning has emerged as a promising distributed learning paradigm
that facilitates collaborative learning among multiple parties without
transferring raw data. However, most existing federated learning studies focus
on either horizontal or vertical data settings, where the data of different
parties are assumed to be from the same feature or sample space. In practice, a
common scenario is the hybrid data setting, where data from different parties
may differ both in the features and samples. To address this, we propose
HybridTree, a novel federated learning approach that enables federated tree
learning on hybrid data. We observe the existence of consistent split rules in
trees. With the help of these split rules, we theoretically show that the
knowledge of parties can be incorporated into the lower layers of a tree. Based
on our theoretical analysis, we propose a layer-level solution that does not
need frequent communication traffic to train a tree. Our experiments
demonstrate that HybridTree can achieve comparable accuracy to the centralized
setting with low computational and communication overhead. HybridTree can
achieve up to 8 times speedup compared with the other baselines.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Evaluating the Fairness of Discriminative Foundation Models in Computer Vision. (arXiv:2310.11867v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11867">http://arxiv.org/abs/2310.11867</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11867]] Evaluating the Fairness of Discriminative Foundation Models in Computer Vision(http://arxiv.org/abs/2310.11867)</code></li>
<li>Summary: <p>We propose a novel taxonomy for bias evaluation of discriminative foundation
models, such as Contrastive Language-Pretraining (CLIP), that are used for
labeling tasks. We then systematically evaluate existing methods for mitigating
bias in these models with respect to our taxonomy. Specifically, we evaluate
OpenAI's CLIP and OpenCLIP models for key applications, such as zero-shot
classification, image retrieval and image captioning. We categorize desired
behaviors based around three axes: (i) if the task concerns humans; (ii) how
subjective the task is (i.e., how likely it is that people from a diverse range
of backgrounds would agree on a labeling); and (iii) the intended purpose of
the task and if fairness is better served by impartiality (i.e., making
decisions independent of the protected attributes) or representation (i.e.,
making decisions to maximize diversity). Finally, we provide quantitative
fairness evaluations for both binary-valued and multi-valued protected
attributes over ten diverse datasets. We find that fair PCA, a post-processing
method for fair representations, works very well for debiasing in most of the
aforementioned tasks while incurring only minor loss of performance. However,
different debiasing approaches vary in their effectiveness depending on the
task. Hence, one should choose the debiasing approach depending on the specific
use case.
</p></li>
</ul>

<h3>Title: Exploring Fairness in Pre-trained Visual Transformer based Natural and GAN Generated Image Detection Systems and Understanding the Impact of Image Compression in Fairness. (arXiv:2310.12076v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12076">http://arxiv.org/abs/2310.12076</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12076]] Exploring Fairness in Pre-trained Visual Transformer based Natural and GAN Generated Image Detection Systems and Understanding the Impact of Image Compression in Fairness(http://arxiv.org/abs/2310.12076)</code></li>
<li>Summary: <p>It is not only sufficient to construct computational models that can
accurately classify or detect fake images from real images taken from a camera,
but it is also important to ensure whether these computational models are fair
enough or produce biased outcomes that can eventually harm certain social
groups or cause serious security threats. Exploring fairness in forensic
algorithms is an initial step towards correcting these biases. Since visual
transformers are recently being widely used in most image classification based
tasks due to their capability to produce high accuracies, this study tries to
explore bias in the transformer based image forensic algorithms that classify
natural and GAN generated images. By procuring a bias evaluation corpora, this
study analyzes bias in gender, racial, affective, and intersectional domains
using a wide set of individual and pairwise bias evaluation measures. As the
generalizability of the algorithms against image compression is an important
factor to be considered in forensic tasks, this study also analyzes the role of
image compression on model bias. Hence to study the impact of image compression
on model bias, a two phase evaluation setting is followed, where a set of
experiments is carried out in the uncompressed evaluation setting and the other
in the compressed evaluation setting.
</p></li>
</ul>

<h3>Title: A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation. (arXiv:2310.12127v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12127">http://arxiv.org/abs/2310.12127</a></li>
<li>Code URL: https://github.com/milanlproc/interpretability-mt-gender-bias</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12127]] A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation(http://arxiv.org/abs/2310.12127)</code></li>
<li>Summary: <p>Recent instruction fine-tuned models can solve multiple NLP tasks when
prompted to do so, with machine translation (MT) being a prominent use case.
However, current research often focuses on standard performance benchmarks,
leaving compelling fairness and ethical considerations behind. In MT, this
might lead to misgendered translations, resulting, among other harms, in the
perpetuation of stereotypes and prejudices. In this work, we address this gap
by investigating whether and to what extent such models exhibit gender bias in
machine translation and how we can mitigate it. Concretely, we compute
established gender bias metrics on the WinoMT corpus from English to German and
Spanish. We discover that IFT models default to male-inflected translations,
even disregarding female occupational stereotypes. Next, using interpretability
methods, we unveil that models systematically overlook the pronoun indicating
the gender of a target occupation in misgendered translations. Finally, based
on this finding, we propose an easy-to-implement and effective bias mitigation
solution based on few-shot learning that leads to significantly fairer
translations.
</p></li>
</ul>

<h3>Title: Fairer and More Accurate Tabular Models Through NAS. (arXiv:2310.12145v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12145">http://arxiv.org/abs/2310.12145</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12145]] Fairer and More Accurate Tabular Models Through NAS(http://arxiv.org/abs/2310.12145)</code></li>
<li>Summary: <p>Making models algorithmically fairer in tabular data has been long studied,
with techniques typically oriented towards fixes which usually take a neural
model with an undesirable outcome and make changes to how the data are
ingested, what the model weights are, or how outputs are processed. We employ
an emergent and different strategy where we consider updating the model's
architecture and training hyperparameters to find an entirely new model with
better outcomes from the beginning of the debiasing procedure. In this work, we
propose using multi-objective Neural Architecture Search (NAS) and
Hyperparameter Optimization (HPO) in the first application to the very
challenging domain of tabular data. We conduct extensive exploration of
architectural and hyperparameter spaces (MLP, ResNet, and FT-Transformer)
across diverse datasets, demonstrating the dependence of accuracy and fairness
metrics of model predictions on hyperparameter combinations. We show that
models optimized solely for accuracy with NAS often fail to inherently address
fairness concerns. We propose a novel approach that jointly optimizes
architectural and training hyperparameters in a multi-objective constraint of
both accuracy and fairness. We produce architectures that consistently Pareto
dominate state-of-the-art bias mitigation methods either in fairness, accuracy
or both, all of this while being Pareto-optimal over hyperparameters achieved
through single-objective (accuracy) optimization runs. This research
underscores the promise of automating fairness and accuracy optimization in
deep learning models.
</p></li>
</ul>

<h2>interpretability</h2>
<h2>explainability</h2>
<h3>Title: Rather a Nurse than a Physician -- Contrastive Explanations under Investigation. (arXiv:2310.11906v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11906">http://arxiv.org/abs/2310.11906</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11906]] Rather a Nurse than a Physician -- Contrastive Explanations under Investigation(http://arxiv.org/abs/2310.11906)</code></li>
<li>Summary: <p>Contrastive explanations, where one decision is explained in contrast to
another, are supposed to be closer to how humans explain a decision than
non-contrastive explanations, where the decision is not necessarily referenced
to an alternative. This claim has never been empirically validated. We analyze
four English text-classification datasets (SST2, DynaSent, BIOS and
DBpedia-Animals). We fine-tune and extract explanations from three different
models (RoBERTa, GTP-2, and T5), each in three different sizes and apply three
post-hoc explainability methods (LRP, GradientxInput, GradNorm). We furthermore
collect and release human rationale annotations for a subset of 100 samples
from the BIOS dataset for contrastive and non-contrastive settings. A
cross-comparison between model-based rationales and human annotations, both in
contrastive and non-contrastive settings, yields a high agreement between the
two settings for models as well as for humans. Moreover, model-based
explanations computed in both settings align equally well with human
rationales. Thus, we empirically find that humans do not necessarily explain in
a contrastive manner.9 pages, long paper at ACL 2022 proceedings.
</p></li>
</ul>

<h3>Title: Emptying the Ocean with a Spoon: Should We Edit Models?. (arXiv:2310.11958v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11958">http://arxiv.org/abs/2310.11958</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11958]] Emptying the Ocean with a Spoon: Should We Edit Models?(http://arxiv.org/abs/2310.11958)</code></li>
<li>Summary: <p>We call into question the recently popularized method of direct model editing
as a means of correcting factual errors in LLM generations. We contrast model
editing with three similar but distinct approaches that pursue better defined
objectives: (1) retrieval-based architectures, which decouple factual memory
from inference and linguistic capabilities embodied in LLMs; (2) concept
erasure methods, which aim at preventing systemic bias in generated text; and
(3) attribution methods, which aim at grounding generations into identified
textual sources. We argue that direct model editing cannot be trusted as a
systematic remedy for the disadvantages inherent to LLMs, and while it has
proven potential in improving model explainability, it opens risks by
reinforcing the notion that models can be trusted for factuality. We call for
cautious promotion and application of model editing as part of the LLM
deployment process, and for responsibly limiting the use cases of LLMs to those
not relying on editing as a critical component.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment. (arXiv:2310.11513v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11513">http://arxiv.org/abs/2310.11513</a></li>
<li>Code URL: https://github.com/djghosh13/geneval</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11513]] GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment(http://arxiv.org/abs/2310.11513)</code></li>
<li>Summary: <p>Recent breakthroughs in diffusion models, multimodal pretraining, and
efficient finetuning have led to an explosion of text-to-image generative
models. Given human evaluation is expensive and difficult to scale, automated
methods are critical for evaluating the increasingly large number of new
models. However, most current automated evaluation metrics like FID or
CLIPScore only offer a holistic measure of image quality or image-text
alignment, and are unsuited for fine-grained or instance-level analysis. In
this paper, we introduce GenEval, an object-focused framework to evaluate
compositional image properties such as object co-occurrence, position, count,
and color. We show that current object detection models can be leveraged to
evaluate text-to-image models on a variety of generation tasks with strong
human agreement, and that other discriminative vision models can be linked to
this pipeline to further verify properties like object color. We then evaluate
several open-source text-to-image models and analyze their relative generative
capabilities on our benchmark. We find that recent models demonstrate
significant improvement on these tasks, though they are still lacking in
complex capabilities such as spatial relations and attribute binding. Finally,
we demonstrate how GenEval might be used to help discover existing failure
modes, in order to inform development of the next generation of text-to-image
models. Our code to run the GenEval framework is publicly available at
https://github.com/djghosh13/geneval.
</p></li>
</ul>

<h3>Title: Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts. (arXiv:2310.11784v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11784">http://arxiv.org/abs/2310.11784</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11784]] Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts(http://arxiv.org/abs/2310.11784)</code></li>
<li>Summary: <p>Recent text-to-3D generation methods achieve impressive 3D content creation
capacity thanks to the advances in image diffusion models and optimizing
strategies. However, current methods struggle to generate correct 3D content
for a complex prompt in semantics, i.e., a prompt describing multiple
interacted objects binding with different attributes. In this work, we propose
a general framework named Progressive3D, which decomposes the entire generation
into a series of locally progressive editing steps to create precise 3D content
for complex prompts, and we constrain the content change to only occur in
regions determined by user-defined region prompts in each editing step.
Furthermore, we propose an overlapped semantic component suppression technique
to encourage the optimization process to focus more on the semantic differences
between prompts. Extensive experiments demonstrate that the proposed
Progressive3D framework generates precise 3D content for prompts with complex
semantics and is general for various text-to-3D methods driven by different 3D
representations.
</p></li>
</ul>

<h3>Title: To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ... For Now. (arXiv:2310.11868v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11868">http://arxiv.org/abs/2310.11868</a></li>
<li>Code URL: https://github.com/optml-group/diffusion-mu-attack</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11868]] To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images (http://arxiv.org/abs/2310.11868)</code></li>
<li>Summary: <p>The recent advances in diffusion models (DMs) have revolutionized the
generation of complex and diverse images. However, these models also introduce
potential safety hazards, such as the production of harmful content and
infringement of data copyrights. Although there have been efforts to create
safety-driven unlearning methods to counteract these challenges, doubts remain
about their capabilities. To bridge this uncertainty, we propose an evaluation
framework built upon adversarial attacks (also referred to as adversarial
prompts), in order to discern the trustworthiness of these safety-driven
unlearned DMs. Specifically, our research explores the (worst-case) robustness
of unlearned DMs in eradicating unwanted concepts, styles, and objects,
assessed by the generation of adversarial prompts. We develop a novel
adversarial learning approach called UnlearnDiff that leverages the inherent
classification capabilities of DMs to streamline the generation of adversarial
prompts, making it as simple for DMs as it is for image classification attacks.
This technique streamlines the creation of adversarial prompts, making the
process as intuitive for generative modeling as it is for image classification
assaults. Through comprehensive benchmarking, we assess the unlearning
robustness of five prevalent unlearned DMs across multiple tasks. Our results
underscore the effectiveness and efficiency of UnlearnDiff when compared to
state-of-the-art adversarial prompting methods. Codes are available at
https://github.com/OPTML-Group/Diffusion-MU-Attack. WARNING: This paper
contains model outputs that may be offensive in nature.
</p></li>
</ul>

<h3>Title: Image Super-resolution Via Latent Diffusion: A Sampling-space Mixture Of Experts And Frequency-augmented Decoder Approach. (arXiv:2310.12004v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12004">http://arxiv.org/abs/2310.12004</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12004]] Image Super-resolution Via Latent Diffusion: A Sampling-space Mixture Of Experts And Frequency-augmented Decoder Approach(http://arxiv.org/abs/2310.12004)</code></li>
<li>Summary: <p>The recent use of diffusion prior, enhanced by pre-trained text-image models,
has markedly elevated the performance of image super-resolution (SR). To
alleviate the huge computational cost required by pixel-based diffusion SR,
latent-based methods utilize a feature encoder to transform the image and then
implement the SR image generation in a compact latent space. Nevertheless,
there are two major issues that limit the performance of latent-based
diffusion. First, the compression of latent space usually causes reconstruction
distortion. Second, huge computational cost constrains the parameter scale of
the diffusion model. To counteract these issues, we first propose a frequency
compensation module that enhances the frequency components from latent space to
pixel space. The reconstruction distortion (especially for high-frequency
information) can be significantly decreased. Then, we propose to use
Sample-Space Mixture of Experts (SS-MoE) to achieve more powerful latent-based
SR, which steadily improves the capacity of the model without a significant
increase in inference costs. These carefully crafted designs contribute to
performance improvements in largely explored 4x blind super-resolution
benchmarks and extend to large magnification factors, i.e., 8x image SR
benchmarks. The code is available at https://github.com/amandaluof/moe_sr.
</p></li>
</ul>

<h3>Title: InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation. (arXiv:2310.11976v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11976">http://arxiv.org/abs/2310.11976</a></li>
<li>Code URL: https://github.com/rzhwang/infodiffusion</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11976]] InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation(http://arxiv.org/abs/2310.11976)</code></li>
<li>Summary: <p>Diffusion models have garnered considerable interest in the field of text
generation. Several studies have explored text diffusion models with different
structures and applied them to various tasks, including named entity
recognition and summarization. However, there exists a notable disparity
between the "easy-first" text generation process of current diffusion models
and the "keyword-first" natural text generation process of humans, which has
received limited attention. To bridge this gap, we propose InfoDiffusion, a
non-autoregressive text diffusion model. Our approach introduces a
"keyinfo-first" generation strategy and incorporates a noise schedule based on
the amount of text information. In addition, InfoDiffusion combines
self-conditioning with a newly proposed partially noising model structure.
Experimental results show that InfoDiffusion outperforms the baseline model in
terms of generation quality and diversity, as well as exhibiting higher
sampling efficiency.
</p></li>
</ul>

<h3>Title: Reflection-Equivariant Diffusion for 3D Structure Determination from Isotopologue Rotational Spectra in Natural Abundance. (arXiv:2310.11609v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11609">http://arxiv.org/abs/2310.11609</a></li>
<li>Code URL: https://github.com/aspuru-guzik-group/kreed</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11609]] Reflection-Equivariant Diffusion for 3D Structure Determination from Isotopologue Rotational Spectra in Natural Abundance(http://arxiv.org/abs/2310.11609)</code></li>
<li>Summary: <p>Structure determination is necessary to identify unknown organic molecules,
such as those in natural products, forensic samples, the interstellar medium,
and laboratory syntheses. Rotational spectroscopy enables structure
determination by providing accurate 3D information about small organic
molecules via their moments of inertia. Using these moments, Kraitchman
analysis determines isotopic substitution coordinates, which are the unsigned
$|x|,|y|,|z|$ coordinates of all atoms with natural isotopic abundance,
including carbon, nitrogen, and oxygen. While unsigned substitution coordinates
can verify guesses of structures, the missing $+/-$ signs make it challenging
to determine the actual structure from the substitution coordinates alone. To
tackle this inverse problem, we develop KREED (Kraitchman
REflection-Equivariant Diffusion), a generative diffusion model that infers a
molecule's complete 3D structure from its molecular formula, moments of
inertia, and unsigned substitution coordinates of heavy atoms. KREED's top-1
predictions identify the correct 3D structure with &gt;98% accuracy on the QM9 and
GEOM datasets when provided with substitution coordinates of all heavy atoms
with natural isotopic abundance. When substitution coordinates are restricted
to only a subset of carbons, accuracy is retained at 91% on QM9 and 32% on
GEOM. On a test set of experimentally measured substitution coordinates
gathered from the literature, KREED predicts the correct all-atom 3D structure
in 25 of 33 cases, demonstrating experimental applicability for context-free 3D
structure determination with rotational spectroscopy.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: DIAR: Deep Image Alignment and Reconstruction using Swin Transformers. (arXiv:2310.11605v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11605">http://arxiv.org/abs/2310.11605</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11605]] DIAR: Deep Image Alignment and Reconstruction using Swin Transformers(http://arxiv.org/abs/2310.11605)</code></li>
<li>Summary: <p>When taking images of some occluded content, one is often faced with the
problem that every individual image frame contains unwanted artifacts, but a
collection of images contains all relevant information if properly aligned and
aggregated. In this paper, we attempt to build a deep learning pipeline that
simultaneously aligns a sequence of distorted images and reconstructs them. We
create a dataset that contains images with image distortions, such as lighting,
specularities, shadows, and occlusion. We create perspective distortions with
corresponding ground-truth homographies as labels. We use our dataset to train
Swin transformer models to analyze sequential image data. The attention maps
enable the model to detect relevant image content and differentiate it from
outliers and artifacts. We further explore using neural feature maps as
alternatives to classical key point detectors. The feature maps of trained
convolutional layers provide dense image descriptors that can be used to find
point correspondences between images. We utilize this to compute coarse image
alignments and explore its limitations.
</p></li>
</ul>

<h3>Title: VST++: Efficient and Stronger Visual Saliency Transformer. (arXiv:2310.11725v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11725">http://arxiv.org/abs/2310.11725</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11725]] VST++: Efficient and Stronger Visual Saliency Transformer(http://arxiv.org/abs/2310.11725)</code></li>
<li>Summary: <p>While previous CNN-based models have exhibited promising results for salient
object detection (SOD), their ability to explore global long-range dependencies
is restricted. Our previous work, the Visual Saliency Transformer (VST),
addressed this constraint from a transformer-based sequence-to-sequence
perspective, to unify RGB and RGB-D SOD. In VST, we developed a multi-task
transformer decoder that concurrently predicts saliency and boundary outcomes
in a pure transformer architecture. Moreover, we introduced a novel token
upsampling method called reverse T2T for predicting a high-resolution saliency
map effortlessly within transformer-based structures. Building upon the VST
model, we further propose an efficient and stronger VST version in this work,
i.e. VST++. To mitigate the computational costs of the VST model, we propose a
Select-Integrate Attention (SIA) module, partitioning foreground into
fine-grained segments and aggregating background information into a single
coarse-grained token. To incorporate 3D depth information with low cost, we
design a novel depth position encoding method tailored for depth maps.
Furthermore, we introduce a token-supervised prediction loss to provide
straightforward guidance for the task-related tokens. We evaluate our VST++
model across various transformer-based backbones on RGB, RGB-D, and RGB-T SOD
benchmark datasets. Experimental results show that our model outperforms
existing methods while achieving a 25% reduction in computational costs without
significant performance compromise. The demonstrated strong ability for
generalization, enhanced performance, and heightened efficiency of our VST++
model highlight its potential.
</p></li>
</ul>

<h3>Title: Field-testing items using artificial intelligence: Natural language processing with transformers. (arXiv:2310.11655v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11655">http://arxiv.org/abs/2310.11655</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11655]] Field-testing items using artificial intelligence: Natural language processing with transformers(http://arxiv.org/abs/2310.11655)</code></li>
<li>Summary: <p>Five thousand variations of the RoBERTa model, an artificially intelligent
"transformer" that can understand text language, completed an English literacy
exam with 29 multiple-choice questions. Data were used to calculate the
psychometric properties of the items, which showed some degree of agreement to
those obtained from human examinee data.
</p></li>
</ul>

<h3>Title: Superiority of Softmax: Unveiling the Performance Edge Over Linear Attention. (arXiv:2310.11685v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11685">http://arxiv.org/abs/2310.11685</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11685]] Superiority of Softmax: Unveiling the Performance Edge Over Linear Attention(http://arxiv.org/abs/2310.11685)</code></li>
<li>Summary: <p>Large transformer models have achieved state-of-the-art results in numerous
natural language processing tasks. Among the pivotal components of the
transformer architecture, the attention mechanism plays a crucial role in
capturing token interactions within sequences through the utilization of
softmax function.
</p>
<p>Conversely, linear attention presents a more computationally efficient
alternative by approximating the softmax operation with linear complexity.
However, it exhibits substantial performance degradation when compared to the
traditional softmax attention mechanism.
</p>
<p>In this paper, we bridge the gap in our theoretical understanding of the
reasons behind the practical performance gap between softmax and linear
attention. By conducting a comprehensive comparative analysis of these two
attention mechanisms, we shed light on the underlying reasons for why softmax
attention outperforms linear attention in most scenarios.
</p></li>
</ul>

<h3>Title: Investigating semantic subspaces of Transformer sentence embeddings through linear structural probing. (arXiv:2310.11923v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11923">http://arxiv.org/abs/2310.11923</a></li>
<li>Code URL: https://github.com/macleginn/semantic-subspaces-code</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11923]] Investigating semantic subspaces of Transformer sentence embeddings through linear structural probing(http://arxiv.org/abs/2310.11923)</code></li>
<li>Summary: <p>The question of what kinds of linguistic information are encoded in different
layers of Transformer-based language models is of considerable interest for the
NLP community. Existing work, however, has overwhelmingly focused on word-level
representations and encoder-only language models with the masked-token training
objective. In this paper, we present experiments with semantic structural
probing, a method for studying sentence-level representations via finding a
subspace of the embedding space that provides suitable task-specific pairwise
distances between data-points. We apply our method to language models from
different families (encoder-only, decoder-only, encoder-decoder) and of
different sizes in the context of two tasks, semantic textual similarity and
natural-language inference. We find that model families differ substantially in
their performance and layer dynamics, but that the results are largely
model-size invariant.
</p></li>
</ul>

<h3>Title: Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for Long Sequences. (arXiv:2310.11960v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11960">http://arxiv.org/abs/2310.11960</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11960]] Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for Long Sequences(http://arxiv.org/abs/2310.11960)</code></li>
<li>Summary: <p>Transformer-based models have achieved state-of-the-art performance in many
areas. However, the quadratic complexity of self-attention with respect to the
input length hinders the applicability of Transformer-based models to long
sequences. To address this, we present Fast Multipole Attention, a new
attention mechanism that uses a divide-and-conquer strategy to reduce the time
and memory complexity of attention for sequences of length $n$ from
$\mathcal{O}(n^2)$ to $\mathcal{O}(n \log n)$ or $O(n)$, while retaining a
global receptive field. The hierarchical approach groups queries, keys, and
values into $\mathcal{O}( \log n)$ levels of resolution, where groups at
greater distances are increasingly larger in size and the weights to compute
group quantities are learned. As such, the interaction between tokens far from
each other is considered in lower resolution in an efficient hierarchical
manner. The overall complexity of Fast Multipole Attention is $\mathcal{O}(n)$
or $\mathcal{O}(n \log n)$, depending on whether the queries are down-sampled
or not. This multi-level divide-and-conquer strategy is inspired by fast
summation methods from $n$-body physics and the Fast Multipole Method. We
perform evaluation on autoregressive and bidirectional language modeling tasks
and compare our Fast Multipole Attention model with other efficient attention
variants on medium-size datasets. We find empirically that the Fast Multipole
Transformer performs much better than other efficient transformers in terms of
memory size and accuracy. The Fast Multipole Attention mechanism has the
potential to empower large language models with much greater sequence lengths,
taking the full context into account in an efficient, naturally hierarchical
manner during training and when generating long sequences.
</p></li>
</ul>

<h3>Title: AMR Parsing with Causal Hierarchical Attention and Pointers. (arXiv:2310.11964v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11964">http://arxiv.org/abs/2310.11964</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11964]] AMR Parsing with Causal Hierarchical Attention and Pointers(http://arxiv.org/abs/2310.11964)</code></li>
<li>Summary: <p>Translation-based AMR parsers have recently gained popularity due to their
simplicity and effectiveness. They predict linearized graphs as free texts,
avoiding explicit structure modeling. However, this simplicity neglects
structural locality in AMR graphs and introduces unnecessary tokens to
represent coreferences. In this paper, we introduce new target forms of AMR
parsing and a novel model, CHAP, which is equipped with causal hierarchical
attention and the pointer mechanism, enabling the integration of structures
into the Transformer decoder. We empirically explore various alternative
modeling options. Experiments show that our model outperforms baseline models
on four out of five benchmarks in the setting of no additional data.
</p></li>
</ul>

<h3>Title: From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers. (arXiv:2310.11984v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11984">http://arxiv.org/abs/2310.11984</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11984]] From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers(http://arxiv.org/abs/2310.11984)</code></li>
<li>Summary: <p>Since its introduction, the transformer model has demonstrated outstanding
performance across various tasks. However, there are still unresolved issues
regarding length generalization, particularly in algorithmic tasks. In this
paper, we investigate the inherent capabilities of transformer models in
learning arithmetic algorithms, such as addition and multiplication. Through
experiments and attention analysis, we identify a number of crucial factors for
achieving optimal length generalization. We show that transformer models are
able to generalize to long lengths with the help of targeted attention biasing.
We then introduce Attention Bias Calibration (ABC), a calibration stage that
enables the model to automatically learn the proper attention biases, which we
link to mechanisms in relative position encoding. We demonstrate that using
ABC, the transformer model can achieve unprecedented perfect length
generalization on certain arithmetic tasks.
</p></li>
</ul>

<h3>Title: SPEED: Speculative Pipelined Execution for Efficient Decoding. (arXiv:2310.12072v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12072">http://arxiv.org/abs/2310.12072</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12072]] SPEED: Speculative Pipelined Execution for Efficient Decoding(http://arxiv.org/abs/2310.12072)</code></li>
<li>Summary: <p>Generative Large Language Models (LLMs) based on the Transformer architecture
have recently emerged as a dominant foundation model for a wide range of
Natural Language Processing tasks. Nevertheless, their application in real-time
scenarios has been highly restricted due to the significant inference latency
associated with these models. This is particularly pronounced due to the
autoregressive nature of generative LLM inference, where tokens are generated
sequentially since each token depends on all previous output tokens. It is
therefore challenging to achieve any token-level parallelism, making inference
extremely memory-bound. In this work, we propose SPEED, which improves
inference efficiency by speculatively executing multiple future tokens in
parallel with the current token using predicted values based on early-layer
hidden states. For Transformer decoders that employ parameter sharing, the
memory operations for the tokens executing in parallel can be amortized, which
allows us to accelerate generative LLM inference. We demonstrate the efficiency
of our method in terms of latency reduction relative to model accuracy and
demonstrate how speculation allows for training deeper decoders with parameter
sharing with minimal runtime overhead.
</p></li>
</ul>

<h3>Title: Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers. (arXiv:2310.12118v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12118">http://arxiv.org/abs/2310.12118</a></li>
<li>Code URL: https://github.com/cyberiada/cartography-for-compositionality</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12118]] Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers(http://arxiv.org/abs/2310.12118)</code></li>
<li>Summary: <p>Neural networks have revolutionized language modeling and excelled in various
downstream tasks. However, the extent to which these models achieve
compositional generalization comparable to human cognitive abilities remains a
topic of debate. While existing approaches in the field have mainly focused on
novel architectures and alternative learning paradigms, we introduce a
pioneering method harnessing the power of dataset cartography (Swayamdipta et
al., 2020). By strategically identifying a subset of compositional
generalization data using this approach, we achieve a remarkable improvement in
model accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets.
Notably, our technique incorporates dataset cartography as a curriculum
learning criterion, eliminating the need for hyperparameter tuning while
consistently achieving superior performance. Our findings highlight the
untapped potential of dataset cartography in unleashing the full capabilities
of compositional generalization within Transformer models. Our code is
available at https://github.com/cyberiada/cartography-for-compositionality.
</p></li>
</ul>

<h3>Title: SHARCS: Efficient Transformers through Routing with Dynamic Width Sub-networks. (arXiv:2310.12126v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12126">http://arxiv.org/abs/2310.12126</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12126]] SHARCS: Efficient Transformers through Routing with Dynamic Width Sub-networks(http://arxiv.org/abs/2310.12126)</code></li>
<li>Summary: <p>We introduce SHARCS for adaptive inference that takes into account the
hardness of input samples. SHARCS can train a router on any transformer
network, enabling the model to direct different samples to sub-networks with
varying widths. Our experiments demonstrate that: (1) SHARCS outperforms or
complements existing per-sample adaptive inference methods across various
classification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes
across different architectures and can be even applied to compressed and
efficient transformer encoders to further improve their efficiency; (3) SHARCS
can provide a 2 times inference speed up at an insignificant drop in accuracy.
</p></li>
</ul>

<h3>Title: Free-text Keystroke Authentication using Transformers: A Comparative Study of Architectures and Loss Functions. (arXiv:2310.11640v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11640">http://arxiv.org/abs/2310.11640</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11640]] Free-text Keystroke Authentication using Transformers: A Comparative Study of Architectures and Loss Functions(http://arxiv.org/abs/2310.11640)</code></li>
<li>Summary: <p>Keystroke biometrics is a promising approach for user identification and
verification, leveraging the unique patterns in individuals' typing behavior.
In this paper, we propose a Transformer-based network that employs
self-attention to extract informative features from keystroke sequences,
surpassing the performance of traditional Recurrent Neural Networks. We explore
two distinct architectures, namely bi-encoder and cross-encoder, and compare
their effectiveness in keystroke authentication. Furthermore, we investigate
different loss functions, including triplet, batch-all triplet, and WDCL loss,
along with various distance metrics such as Euclidean, Manhattan, and cosine
distances. These experiments allow us to optimize the training process and
enhance the performance of our model. To evaluate our proposed model, we employ
the Aalto desktop keystroke dataset. The results demonstrate that the
bi-encoder architecture with batch-all triplet loss and cosine distance
achieves the best performance, yielding an exceptional Equal Error Rate of
0.0186%. Furthermore, alternative algorithms for calculating similarity scores
are explored to enhance accuracy. Notably, the utilization of a one-class
Support Vector Machine reduces the Equal Error Rate to an impressive 0.0163%.
The outcomes of this study indicate that our model surpasses the previous
state-of-the-art in free-text keystroke authentication. These findings
contribute to advancing the field of keystroke authentication and offer
practical implications for secure user verification systems.
</p></li>
</ul>

<h3>Title: Recasting Continual Learning as Sequence Modeling. (arXiv:2310.11952v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11952">http://arxiv.org/abs/2310.11952</a></li>
<li>Code URL: https://github.com/soochan-lee/cl-as-seq</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11952]] Recasting Continual Learning as Sequence Modeling(http://arxiv.org/abs/2310.11952)</code></li>
<li>Summary: <p>In this work, we aim to establish a strong connection between two significant
bodies of machine learning research: continual learning and sequence modeling.
That is, we propose to formulate continual learning as a sequence modeling
problem, allowing advanced sequence models to be utilized for continual
learning. Under this formulation, the continual learning process becomes the
forward pass of a sequence model. By adopting the meta-continual learning (MCL)
framework, we can train the sequence model at the meta-level, on multiple
continual learning episodes. As a specific example of our new formulation, we
demonstrate the application of Transformers and their efficient variants as MCL
methods. Our experiments on seven benchmarks, covering both classification and
regression, show that sequence models can be an attractive solution for general
MCL.
</p></li>
</ul>

<h3>Title: Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture. (arXiv:2310.12109v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12109">http://arxiv.org/abs/2310.12109</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12109]] Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture(http://arxiv.org/abs/2310.12109)</code></li>
<li>Summary: <p>Machine learning models are increasingly being scaled in both sequence length
and model dimension to reach longer contexts and better performance. However,
existing architectures such as Transformers scale quadratically along both
these axes. We ask: are there performant architectures that can scale
sub-quadratically along sequence length and model dimension? We introduce
Monarch Mixer (M2), a new architecture that uses the same sub-quadratic
primitive along both sequence length and model dimension: Monarch matrices, a
simple class of expressive structured matrices that captures many linear
transforms, achieves high hardware efficiency on GPUs, and scales
sub-quadratically. As a proof of concept, we explore the performance of M2 in
three domains: non-causal BERT-style language modeling, ViT-style image
classification, and causal GPT-style language modeling. For non-causal
BERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE
quality with up to 27% fewer parameters, and achieves up to 9.1$\times$ higher
throughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in
accuracy, with only half the parameters. Causal GPT-style models introduce a
technical challenge: enforcing causality via masking introduces a quadratic
bottleneck. To alleviate this bottleneck, we develop a novel theoretical view
of Monarch matrices based on multivariate polynomial evaluation and
interpolation, which lets us parameterize M2 to be causal while remaining
sub-quadratic. Using this parameterization, M2 matches GPT-style Transformers
at 360M parameters in pretraining perplexity on The PILE--showing for the first
time that it may be possible to match Transformer quality without attention or
MLPs.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Bayesian Flow Networks in Continual Learning. (arXiv:2310.12001v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12001">http://arxiv.org/abs/2310.12001</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12001]] Bayesian Flow Networks in Continual Learning(http://arxiv.org/abs/2310.12001)</code></li>
<li>Summary: <p>Bayesian Flow Networks (BFNs) has been recently proposed as one of the most
promising direction to universal generative modelling, having ability to learn
any of the data type. Their power comes from the expressiveness of neural
networks and Bayesian inference which make them suitable in the context of
continual learning. We delve into the mechanics behind BFNs and conduct the
experiments to empirically verify the generative capabilities on non-stationary
data.
</p></li>
</ul>

<h3>Title: On the Benefit of Generative Foundation Models for Human Activity Recognition. (arXiv:2310.12085v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12085">http://arxiv.org/abs/2310.12085</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12085]] On the Benefit of Generative Foundation Models for Human Activity Recognition(http://arxiv.org/abs/2310.12085)</code></li>
<li>Summary: <p>In human activity recognition (HAR), the limited availability of annotated
data presents a significant challenge. Drawing inspiration from the latest
advancements in generative AI, including Large Language Models (LLMs) and
motion synthesis models, we believe that generative AI can address this data
scarcity by autonomously generating virtual IMU data from text descriptions.
Beyond this, we spotlight several promising research pathways that could
benefit from generative AI for the community, including the generating
benchmark datasets, the development of foundational models specific to HAR, the
exploration of hierarchical structures within HAR, breaking down complex
activities, and applications in health sensing and activity summarization.
</p></li>
</ul>

<h3>Title: Eliciting Human Preferences with Language Models. (arXiv:2310.11589v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11589">http://arxiv.org/abs/2310.11589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11589]] Eliciting Human Preferences with Language Models(http://arxiv.org/abs/2310.11589)</code></li>
<li>Summary: <p>Language models (LMs) can be directed to perform target tasks by using
labeled examples or natural language prompts. But selecting examples or writing
prompts for can be challenging--especially in tasks that involve unusual edge
cases, demand precise articulation of nebulous preferences, or require an
accurate mental model of LM behavior. We propose to use *LMs themselves* to
guide the task specification process. In this paper, we introduce **Generative
Active Task Elicitation (GATE)**: a learning framework in which models elicit
and infer intended behavior through free-form, language-based interaction with
users. We study GATE in three domains: email validation, content
recommendation, and moral reasoning. In preregistered experiments, we show that
LMs prompted to perform GATE (e.g., by generating open-ended questions or
synthesizing informative edge cases) elicit responses that are often more
informative than user-written prompts or labels. Users report that interactive
task elicitation requires less effort than prompting or example labeling and
surfaces novel considerations not initially anticipated by users. Our findings
suggest that LM-driven elicitation can be a powerful tool for aligning models
to complex human preferences and values.
</p></li>
</ul>

<h3>Title: On the Evaluation of Generative Models in Distributed Learning Tasks. (arXiv:2310.11714v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11714">http://arxiv.org/abs/2310.11714</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11714]] On the Evaluation of Generative Models in Distributed Learning Tasks(http://arxiv.org/abs/2310.11714)</code></li>
<li>Summary: <p>The evaluation of deep generative models including generative adversarial
networks (GANs) and diffusion models has been extensively studied in the
literature. While the existing evaluation methods mainly target a centralized
learning problem with training data stored by a single client, many
applications of generative models concern distributed learning settings, e.g.
the federated learning scenario, where training data are collected by and
distributed among several clients. In this paper, we study the evaluation of
generative models in distributed learning tasks with heterogeneous data
distributions. First, we focus on the Fr\'echet inception distance (FID) and
consider the following FID-based aggregate scores over the clients: 1) FID-avg
as the mean of clients' individual FID scores, 2) FID-all as the FID distance
of the trained model to the collective dataset containing all clients' data. We
prove that the model rankings according to the FID-all and FID-avg scores could
be inconsistent, which can lead to different optimal generative models
according to the two aggregate scores. Next, we consider the kernel inception
distance (KID) and similarly define the KID-avg and KID-all aggregations.
Unlike the FID case, we prove that KID-all and KID-avg result in the same
rankings of generative models. We perform several numerical experiments on
standard image datasets and training schemes to support our theoretical
findings on the evaluation of generative models in distributed learning
problems.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: ChatGPT-guided Semantics for Zero-shot Learning. (arXiv:2310.11657v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11657">http://arxiv.org/abs/2310.11657</a></li>
<li>Code URL: https://github.com/fhshubho/cgs-zsl</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11657]] ChatGPT-guided Semantics for Zero-shot Learning(http://arxiv.org/abs/2310.11657)</code></li>
<li>Summary: <p>Zero-shot learning (ZSL) aims to classify objects that are not observed or
seen during training. It relies on class semantic description to transfer
knowledge from the seen classes to the unseen classes. Existing methods of
obtaining class semantics include manual attributes or automatic word vectors
from language models (like word2vec). We know attribute annotation is costly,
whereas automatic word-vectors are relatively noisy. To address this problem,
we explore how ChatGPT, a large language model, can enhance class semantics for
ZSL tasks. ChatGPT can be a helpful source to obtain text descriptions for each
class containing related attributes and semantics. We use the word2vec model to
get a word vector using the texts from ChatGPT. Then, we enrich word vectors by
combining the word embeddings from class names and descriptions generated by
ChatGPT. More specifically, we leverage ChatGPT to provide extra supervision
for the class description, eventually benefiting ZSL models. We evaluate our
approach on various 2D image (CUB and AwA) and 3D point cloud (ModelNet10,
ModelNet40, and ScanObjectNN) datasets and show that it improves ZSL
performance. Our work contributes to the ZSL literature by applying ChatGPT for
class semantics enhancement and proposing a novel word vector fusion method.
</p></li>
</ul>

<h3>Title: MISAR: A Multimodal Instructional System with Augmented Reality. (arXiv:2310.11699v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11699">http://arxiv.org/abs/2310.11699</a></li>
<li>Code URL: https://github.com/nguyennm1024/misar</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11699]] MISAR: A Multimodal Instructional System with Augmented Reality(http://arxiv.org/abs/2310.11699)</code></li>
<li>Summary: <p>Augmented reality (AR) requires the seamless integration of visual, auditory,
and linguistic channels for optimized human-computer interaction. While
auditory and visual inputs facilitate real-time and contextual user guidance,
the potential of large language models (LLMs) in this landscape remains largely
untapped. Our study introduces an innovative method harnessing LLMs to
assimilate information from visual, auditory, and contextual modalities.
Focusing on the unique challenge of task performance quantification in AR, we
utilize egocentric video, speech, and context analysis. The integration of LLMs
facilitates enhanced state estimation, marking a step towards more adaptive AR
systems. Code, dataset, and demo will be available at
https://github.com/nguyennm1024/misar.
</p></li>
</ul>

<h3>Title: Unveiling the Siren's Song: Towards Reliable Fact-Conflicting Hallucination Detection. (arXiv:2310.12086v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12086">http://arxiv.org/abs/2310.12086</a></li>
<li>Code URL: https://github.com/zjunlp/factchd</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12086]] Unveiling the Siren's Song: Towards Reliable Fact-Conflicting Hallucination Detection(http://arxiv.org/abs/2310.12086)</code></li>
<li>Summary: <p>Large Language Models (LLMs), such as ChatGPT/GPT-4, have garnered widespread
attention owing to their myriad of practical applications, yet their adoption
has been constrained by issues of fact-conflicting hallucinations across web
platforms. The assessment of factuality in text, produced by LLMs, remains
inadequately explored, extending not only to the judgment of vanilla facts but
also encompassing the evaluation of factual errors emerging in complex
inferential tasks like multi-hop, and etc. In response, we introduce FactCHD, a
fact-conflicting hallucination detection benchmark meticulously designed for
LLMs. Functioning as a pivotal tool in evaluating factuality within
"Query-Respons" contexts, our benchmark assimilates a large-scale dataset,
encapsulating a broad spectrum of factuality patterns, such as vanilla,
multi-hops, comparison, and set-operation patterns. A distinctive feature of
our benchmark is its incorporation of fact-based chains of evidence, thereby
facilitating comprehensive and conducive factual reasoning throughout the
assessment process. We evaluate multiple LLMs, demonstrating the effectiveness
of the benchmark and current methods fall short of faithfully detecting factual
errors. Furthermore, we present TRUTH-TRIANGULATOR that synthesizes reflective
considerations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming
to yield more credible detection through the amalgamation of predictive results
and evidence. The benchmark dataset and source code will be made available in
https://github.com/zjunlp/FactCHD.
</p></li>
</ul>

<h3>Title: Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling. (arXiv:2310.12100v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12100">http://arxiv.org/abs/2310.12100</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12100]] Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling(http://arxiv.org/abs/2310.12100)</code></li>
<li>Summary: <p>Large language models (LLMs) and vision language models (VLMs) demonstrate
excellent performance on a wide range of tasks by scaling up parameter counts
from O(10^9) to O(10^{12}) levels and further beyond. These large scales make
it impossible to adapt and deploy fully specialized models given a task of
interest. Parameter-efficient fine-tuning (PEFT) emerges as a promising
direction to tackle the adaptation and serving challenges for such large
models. We categorize PEFT techniques into two types: intrusive and
non-intrusive. Intrusive PEFT techniques directly change a model's internal
architecture. Though more flexible, they introduce significant complexities for
training and serving. Non-intrusive PEFT techniques leave the internal
architecture unchanged and only adapt model-external parameters, such as
embeddings for input. In this work, we describe AdaLink as a non-intrusive PEFT
technique that achieves competitive performance compared to SoTA intrusive PEFT
(LoRA) and full model fine-tuning (FT) on various tasks. We evaluate using both
text-only and multimodal tasks, with experiments that account for both
parameter-count scaling and training regime (with and without instruction
tuning).
</p></li>
</ul>

<h3>Title: Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection. (arXiv:2310.11511v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11511">http://arxiv.org/abs/2310.11511</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11511]] Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection(http://arxiv.org/abs/2310.11511)</code></li>
<li>Summary: <p>Despite their remarkable capabilities, large language models (LLMs) often
produce responses containing factual inaccuracies due to their sole reliance on
the parametric knowledge they encapsulate. Retrieval-Augmented Generation
(RAG), an ad hoc approach that augments LMs with retrieval of relevant
knowledge, decreases such issues. However, indiscriminately retrieving and
incorporating a fixed number of retrieved passages, regardless of whether
retrieval is necessary, or passages are relevant, diminishes LM versatility or
can lead to unhelpful response generation. We introduce a new framework called
Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's
quality and factuality through retrieval and self-reflection. Our framework
trains a single arbitrary LM that adaptively retrieves passages on-demand, and
generates and reflects on retrieved passages and its own generations using
special tokens, called reflection tokens. Generating reflection tokens makes
the LM controllable during the inference phase, enabling it to tailor its
behavior to diverse task requirements. Experiments show that Self-RAG (7B and
13B parameters) significantly outperforms state-of-the-art LLMs and
retrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG
outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA,
reasoning and fact verification tasks, and it shows significant gains in
improving factuality and citation accuracy for long-form generations relative
to these models.
</p></li>
</ul>

<h3>Title: Group Preference Optimization: Few-Shot Alignment of Large Language Models. (arXiv:2310.11523v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11523">http://arxiv.org/abs/2310.11523</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11523]] Group Preference Optimization: Few-Shot Alignment of Large Language Models(http://arxiv.org/abs/2310.11523)</code></li>
<li>Summary: <p>Many applications of large language models (LLMs), ranging from chatbots to
creative writing, require nuanced subjective judgments that can differ
significantly across different groups. Existing alignment algorithms can be
expensive to align for each group, requiring prohibitive amounts of
group-specific preference data and computation for real-world use cases. We
introduce Group Preference Optimization (GPO), an alignment framework that
steers language models to preferences of individual groups in a few-shot
manner. In GPO, we augment the base LLM with an independent transformer module
trained to predict the preferences of a group for the LLM generations. For
few-shot learning, we parameterize this module as an in-context autoregressive
transformer and train it via meta-learning on several groups. We empirically
validate the efficacy of GPO through rigorous evaluations using LLMs with
varied sizes on three human opinion adaptation tasks. These tasks involve
adapting to the preferences of US demographic groups, global countries, and
individual users. Our results demonstrate that GPO not only aligns models more
accurately but also requires fewer group-specific preferences, and less
training and inference computing resources, outperforming existing strategies
such as in-context steering and fine-tuning methods.
</p></li>
</ul>

<h3>Title: Multi-stage Large Language Model Correction for Speech Recognition. (arXiv:2310.11532v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11532">http://arxiv.org/abs/2310.11532</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11532]] Multi-stage Large Language Model Correction for Speech Recognition(http://arxiv.org/abs/2310.11532)</code></li>
<li>Summary: <p>In this paper, we investigate the usage of large language models (LLMs) to
improve the performance of competitive speech recognition systems. Different
from traditional language models that focus on one single data domain, the rise
of LLMs brings us the opportunity to push the limit of state-of-the-art ASR
performance, and at the same time to achieve higher robustness and generalize
effectively across multiple domains. Motivated by this, we propose a novel
multi-stage approach to combine traditional language model re-scoring and LLM
prompting. Specifically, the proposed method has two stages: the first stage
uses a language model to re-score an N-best list of ASR hypotheses and run a
confidence check; The second stage uses prompts to a LLM to perform ASR error
correction on less confident results from the first stage. Our experimental
results demonstrate the effectiveness of the proposed method by showing a 10% ~
20% relative improvement in WER over a competitive ASR system -- across
multiple test domains.
</p></li>
</ul>

<h3>Title: Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging. (arXiv:2310.11564v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11564">http://arxiv.org/abs/2310.11564</a></li>
<li>Code URL: https://github.com/joeljang/rlphf</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11564]] Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging(http://arxiv.org/abs/2310.11564)</code></li>
<li>Summary: <p>While Reinforcement Learning from Human Feedback (RLHF) aligns Large Language
Models (LLMs) with general, aggregate human preferences, it is suboptimal for
learning diverse, individual perspectives. In this work, we study Reinforcement
Learning from Personalized Human Feedback (RLPHF) problem, wherein LLMs are
aligned to multiple (sometimes conflicting) preferences by modeling alignment
as a Multi-Objective Reinforcement Learning (MORL) problem. Compared to strong
single-objective baselines, we show that we can achieve personalized alignment
by decomposing preferences into multiple dimensions. These dimensions are
defined based on personalizations that are declared as desirable by the user.
In this work, we show that they can be efficiently trained independently in a
distributed manner and combined effectively post-hoc through parameter merging.
The code is available at https://github.com/joeljang/RLPHF.
</p></li>
</ul>

<h3>Title: What is a good question? Task-oriented asking with fact-level masking. (arXiv:2310.11571v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11571">http://arxiv.org/abs/2310.11571</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11571]] What is a good question? Task-oriented asking with fact-level masking(http://arxiv.org/abs/2310.11571)</code></li>
<li>Summary: <p>Asking questions is an important element of real-life collaboration on
reasoning tasks like question answering. For example, a legal assistant chatbot
may be unable to make accurate recommendations without specific information on
the user's circumstances. However, large language models are usually deployed
to solve reasoning tasks directly without asking follow-up questions to the
user or third parties. We term this problem task-oriented asking (TOA).
Zero-shot chat models can perform TOA, but their training is primarily based on
next-token prediction rather than whether questions contribute to successful
collaboration. To enable the training and evaluation of TOA models, we present
a definition and framework for natural language task-oriented asking, the
problem of generating questions that result in answers useful for a reasoning
task. We also present fact-level masking (FLM), a procedure for converting
natural language datasets into self-supervised TOA datasets by omitting
particular critical facts. Finally, we generate a TOA dataset from the HotpotQA
dataset using FLM and evaluate several zero-shot language models on it. Our
experiments show that current zero-shot models struggle to ask questions that
retrieve useful information, as compared to human annotators. These results
demonstrate an opportunity to use FLM datasets and the TOA framework to train
and evaluate better TOA models.
</p></li>
</ul>

<h3>Title: Automated Evaluation of Personalized Text Generation using Large Language Models. (arXiv:2310.11593v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11593">http://arxiv.org/abs/2310.11593</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11593]] Automated Evaluation of Personalized Text Generation using Large Language Models(http://arxiv.org/abs/2310.11593)</code></li>
<li>Summary: <p>Personalized text generation presents a specialized mechanism for delivering
content that is specific to a user's personal context. While the research
progress in this area has been rapid, evaluation still presents a challenge.
Traditional automated metrics such as BLEU and ROUGE primarily measure lexical
similarity to human-written references, and are not able to distinguish
personalization from other subtle semantic aspects, thus falling short of
capturing the nuances of personalized generated content quality. On the other
hand, human judgments are costly to obtain, especially in the realm of
personalized evaluation. Inspired by these challenges, we explore the use of
large language models (LLMs) for evaluating personalized text generation, and
examine their ability to understand nuanced user context. We present AuPEL, a
novel evaluation method that distills three major semantic aspects of the
generated text: personalization, quality and relevance, and automatically
measures these aspects. To validate the effectiveness of AuPEL, we design
carefully controlled experiments and compare the accuracy of the evaluation
judgments made by LLMs versus that of judgements made by human annotators, and
conduct rigorous analyses of the consistency and sensitivity of the proposed
metric. We find that, compared to existing evaluation metrics, AuPEL not only
distinguishes and ranks models based on their personalization abilities more
accurately, but also presents commendable consistency and efficiency for this
task. Our work suggests that using LLMs as the evaluators of personalized text
generation is superior to traditional text similarity metrics, even though
interesting new challenges still remain.
</p></li>
</ul>

<h3>Title: MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations. (arXiv:2310.11634v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11634">http://arxiv.org/abs/2310.11634</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11634]] MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations(http://arxiv.org/abs/2310.11634)</code></li>
<li>Summary: <p>Humans possess a remarkable ability to assign novel interpretations to
linguistic expressions, enabling them to learn new words and understand
community-specific connotations. However, Large Language Models (LLMs) have a
knowledge cutoff and are costly to finetune repeatedly. Therefore, it is
crucial for LLMs to learn novel interpretations in-context. In this paper, we
systematically analyse the ability of LLMs to acquire novel interpretations
using in-context learning. To facilitate our study, we introduce MAGNIFICo, an
evaluation suite implemented within a text-to-SQL semantic parsing framework
that incorporates diverse tokens and prompt settings to simulate real-world
complexity. Experimental results on MAGNIFICo demonstrate that LLMs exhibit a
surprisingly robust capacity for comprehending novel interpretations from
natural language descriptions as well as from discussions within long
conversations. Nevertheless, our findings also highlight the need for further
improvements, particularly when interpreting unfamiliar words or when composing
multiple novel interpretations simultaneously in the same example.
Additionally, our analysis uncovers the semantic predispositions in LLMs and
reveals the impact of recency bias for information presented in long contexts.
</p></li>
</ul>

<h3>Title: Systematic Assessment of Factual Knowledge in Large Language Models. (arXiv:2310.11638v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11638">http://arxiv.org/abs/2310.11638</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11638]] Systematic Assessment of Factual Knowledge in Large Language Models(http://arxiv.org/abs/2310.11638)</code></li>
<li>Summary: <p>Previous studies have relied on existing question-answering benchmarks to
evaluate the knowledge stored in large language models (LLMs). However, this
approach has limitations regarding factual knowledge coverage, as it mostly
focuses on generic domains which may overlap with the pretraining data. This
paper proposes a framework to systematically assess the factual knowledge of
LLMs by leveraging knowledge graphs (KGs). Our framework automatically
generates a set of questions and expected answers from the facts stored in a
given KG, and then evaluates the accuracy of LLMs in answering these questions.
We systematically evaluate the state-of-the-art LLMs with KGs in generic and
specific domains. The experiment shows that ChatGPT is consistently the top
performer across all domains. We also find that LLMs performance depends on the
instruction finetuning, domain and question complexity and is prone to
adversarial context.
</p></li>
</ul>

<h3>Title: Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs. (arXiv:2310.11689v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11689">http://arxiv.org/abs/2310.11689</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11689]] Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs(http://arxiv.org/abs/2310.11689)</code></li>
<li>Summary: <p>Large language models (LLMs) have recently shown great advances in a variety
of tasks, including natural language understanding and generation. However,
their use in high-stakes decision-making scenarios is still limited due to the
potential for errors. Selective prediction is a technique that can be used to
improve the reliability of the LLMs by allowing them to abstain from making
predictions when they are unsure of the answer. In this work, we propose a
novel framework for adaptation with self-evaluation to improve the selective
prediction performance of LLMs. Our framework is based on the idea of using
parameter-efficient tuning to adapt the LLM to the specific task at hand while
improving its ability to perform self-evaluation. We evaluate our method on a
variety of question-answering (QA) datasets and show that it outperforms
state-of-the-art selective prediction methods. For example, on the CoQA
benchmark, our method improves the AUACC from 91.23% to 92.63% and improves the
AUROC from 74.61% to 80.25%.
</p></li>
</ul>

<h3>Title: Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning. (arXiv:2310.11716v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11716">http://arxiv.org/abs/2310.11716</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11716]] Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning(http://arxiv.org/abs/2310.11716)</code></li>
<li>Summary: <p>Recent advancements in Large Language Models (LLMs) have expanded the
horizons of natural language understanding and generation. Notably, the output
control and alignment with the input of LLMs can be refined through instruction
tuning. However, as highlighted in several studies, low-quality data in the
training set are usually detrimental to instruction tuning, resulting in
inconsistent or even misleading LLM outputs. We propose a novel method, termed
"reflection-tuning," which addresses the problem by self-improvement and
judging capabilities of LLMs. This approach utilizes an oracle LLM to recycle
the original training data by introspecting and enhancing the quality of
instructions and responses in the data. Extensive experiments on widely used
evaluation benchmarks show that LLMs trained with our recycled data outperform
those trained with existing datasets in various benchmarks.
</p></li>
</ul>

<h3>Title: Quantify Health-Related Atomic Knowledge in Chinese Medical Large Language Models: A Computational Analysis. (arXiv:2310.11722v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11722">http://arxiv.org/abs/2310.11722</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11722]] Quantify Health-Related Atomic Knowledge in Chinese Medical Large Language Models: A Computational Analysis(http://arxiv.org/abs/2310.11722)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have the potential to revolutionize the way
users self-diagnose through search engines by offering direct and efficient
suggestions. Recent studies primarily focused on the quality of LLMs evaluated
by GPT-4 or their ability to pass medical exams, no studies have quantified the
extent of health-related atomic knowledge stored in LLMs' memory, which is the
basis of LLMs to provide more factual suggestions. In this paper, we first
constructed a benchmark, including the most common types of atomic knowledge in
user self-diagnosis queries, with 17 atomic types and a total of 14, 048 pieces
of atomic knowledge. Then, we evaluated both generic and specialized LLMs on
the benchmark. The experimental results showcased that generic LLMs perform
better than specialized LLMs in terms of atomic knowledge and
instruction-following ability. Error analysis revealed that both generic and
specialized LLMs are sycophantic, e.g., always catering to users' claims when
it comes to unknown knowledge. Besides, generic LLMs showed stronger safety,
which can be learned by specialized LLMs through distilled data. We further
explored different types of data commonly adopted for fine-tuning specialized
LLMs, i.e., real-world, semi-distilled, and distilled data, and found that
distilled data can benefit LLMs most.
</p></li>
</ul>

<h3>Title: A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction. (arXiv:2310.11761v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11761">http://arxiv.org/abs/2310.11761</a></li>
<li>Code URL: https://github.com/srhthu/lm-compeval-legal</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11761]] A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction(http://arxiv.org/abs/2310.11761)</code></li>
<li>Summary: <p>Large language models (LLMs) have demonstrated great potential for
domain-specific applications, such as the law domain. However, recent disputes
over GPT-4's law evaluation raise questions concerning their performance in
real-world legal tasks. To systematically investigate their competency in the
law, we design practical baseline solutions based on LLMs and test on the task
of legal judgment prediction. In our solutions, LLMs can work alone to answer
open questions or coordinate with an information retrieval (IR) system to learn
from similar cases or solve simplified multi-choice questions. We show that
similar cases and multi-choice options, namely label candidates, included in
prompts can help LLMs recall domain knowledge that is critical for expertise
legal reasoning. We additionally present an intriguing paradox wherein an IR
system surpasses the performance of LLM+IR due to limited gains acquired by
weaker LLMs from powerful IR systems. In such cases, the role of LLMs becomes
redundant. Our evaluation pipeline can be easily extended into other tasks to
facilitate evaluations in other domains. Code is available at
https://github.com/srhthu/LM-CompEval-Legal
</p></li>
</ul>

<h3>Title: The Curious Case of Hallucinatory Unanswerablity: Finding Truths in the Hidden States of Over-Confident Large Language Models. (arXiv:2310.11877v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11877">http://arxiv.org/abs/2310.11877</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11877]] The Curious Case of Hallucinatory Unanswerablity: Finding Truths in the Hidden States of Over-Confident Large Language Models(http://arxiv.org/abs/2310.11877)</code></li>
<li>Summary: <p>Large language models (LLMs) have been shown to possess impressive
capabilities, while also raising crucial concerns about the faithfulness of
their responses. A primary issue arising in this context is the management of
unanswerable queries by LLMs, which often results in hallucinatory behavior,
due to overconfidence. In this paper, we explore the behavior of LLMs when
presented with unanswerable queries. We ask: do models \textbf{represent} the
fact that the question is unanswerable when generating a hallucinatory answer?
Our results show strong indications that such models encode the answerability
of an input query, with the representation of the first decoded token often
being a strong indicator. These findings shed new light on the spatial
organization within the latent representations of LLMs, unveiling previously
unexplored facets of these models. Moreover, they pave the way for the
development of improved decoding techniques with better adherence to factual
generation, particularly in scenarios where query unanswerability is a concern.
</p></li>
</ul>

<h3>Title: MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models. (arXiv:2310.11954v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11954">http://arxiv.org/abs/2310.11954</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11954]] MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models(http://arxiv.org/abs/2310.11954)</code></li>
<li>Summary: <p>AI-empowered music processing is a diverse field that encompasses dozens of
tasks, ranging from generation tasks (e.g., timbre synthesis) to comprehension
tasks (e.g., music classification). For developers and amateurs, it is very
difficult to grasp all of these task to satisfy their requirements in music
processing, especially considering the huge differences in the representations
of music data and the model applicability across platforms among various tasks.
Consequently, it is necessary to build a system to organize and integrate these
tasks, and thus help practitioners to automatically analyze their demand and
call suitable tools as solutions to fulfill their requirements. Inspired by the
recent success of large language models (LLMs) in task automation, we develop a
system, named MusicAgent, which integrates numerous music-related tools and an
autonomous workflow to address user requirements. More specifically, we build
1) toolset that collects tools from diverse sources, including Hugging Face,
GitHub, and Web API, etc. 2) an autonomous workflow empowered by LLMs (e.g.,
ChatGPT) to organize these tools and automatically decompose user requests into
multiple sub-tasks and invoke corresponding music tools. The primary goal of
this system is to free users from the intricacies of AI-music tools, enabling
them to concentrate on the creative aspect. By granting users the freedom to
effortlessly combine tools, the system offers a seamless and enriching music
experience.
</p></li>
</ul>

<h3>Title: Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models. (arXiv:2310.12049v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12049">http://arxiv.org/abs/2310.12049</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12049]] Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models(http://arxiv.org/abs/2310.12049)</code></li>
<li>Summary: <p>Existing text scaling methods often require a large corpus, struggle with
short texts, or require labeled data. We develop a text scaling method that
leverages the pattern recognition capabilities of generative large language
models (LLMs). Specifically, we propose concept-guided chain-of-thought
(CGCoT), which uses prompts designed to summarize ideas and identify target
parties in texts to generate concept-specific breakdowns, in many ways similar
to guidance for human coder content analysis. CGCoT effectively shifts pairwise
text comparisons from a reasoning problem to a pattern recognition problem. We
then pairwise compare concept-specific breakdowns using an LLM. We use the
results of these pairwise comparisons to estimate a scale using the
Bradley-Terry model. We use this approach to scale affective speech on Twitter.
Our measures correlate more strongly with human judgments than alternative
approaches like Wordfish. Besides a small set of pilot data to develop the
CGCoT prompts, our measures require no additional labeled data and produce
binary predictions comparable to a RoBERTa-Large model fine-tuned on thousands
of human-labeled tweets. We demonstrate how combining substantive knowledge
with LLMs can create state-of-the-art measures of abstract concepts.
</p></li>
</ul>

<h3>Title: Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education. (arXiv:2310.12059v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12059">http://arxiv.org/abs/2310.12059</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12059]] Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education(http://arxiv.org/abs/2310.12059)</code></li>
<li>Summary: <p>In this paper, we evaluate the ability of large language models (LLMs) to
perform multiple choice symbol binding (MCSB) for multiple choice question
answering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus
on Vietnamese, with fewer challenging MCQA datasets than in English. The two
existing datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent
research in Vietnamese natural language processing (NLP) has focused on the
Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to
2023 to evaluate ChatGPT. However, these studies have mainly focused on how
ChatGPT solves the VNHSGE step by step. We aim to create a novel and
high-quality dataset by providing structured guidelines for typing LaTeX
formulas for mathematics, physics, chemistry, and biology. This dataset can be
used to evaluate the MCSB ability of LLMs and smaller language models (LMs)
because it is typed in a strict LaTeX style. We focus on predicting the
character (A, B, C, or D) that is the most likely answer to a question, given
the context of the question. Our evaluation of six well-known LLMs, namely
BLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the
ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising
results on the MCSB ability of LLMs for Vietnamese. The dataset is available
for research purposes only.
</p></li>
</ul>

<h3>Title: Pseudointelligence: A Unifying Framework for Language Model Evaluation. (arXiv:2310.12135v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12135">http://arxiv.org/abs/2310.12135</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12135]] Pseudointelligence: A Unifying Framework for Language Model Evaluation(http://arxiv.org/abs/2310.12135)</code></li>
<li>Summary: <p>With large language models surpassing human performance on an increasing
number of benchmarks, we must take a principled approach for targeted
evaluation of model capabilities. Inspired by pseudorandomness, we propose
pseudointelligence, which captures the maxim that "(perceived) intelligence
lies in the eye of the beholder". That is, that claims of intelligence are
meaningful only when their evaluator is taken into account. Concretely, we
propose a complexity-theoretic framework of model evaluation cast as a dynamic
interaction between a model and a learned evaluator. We demonstrate that this
framework can be used to reason about two case studies in language model
evaluation, as well as analyze existing evaluation methods.
</p></li>
</ul>

<h3>Title: Towards Graph Foundation Models: A Survey and Beyond. (arXiv:2310.11829v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11829">http://arxiv.org/abs/2310.11829</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11829]] Towards Graph Foundation Models: A Survey and Beyond(http://arxiv.org/abs/2310.11829)</code></li>
<li>Summary: <p>Emerging as fundamental building blocks for diverse artificial intelligence
applications, foundation models have achieved notable success across natural
language processing and many other domains. Parallelly, graph machine learning
has witnessed a transformative shift, with shallow methods giving way to deep
learning approaches. The emergence and homogenization capabilities of
foundation models have piqued the interest of graph machine learning
researchers, sparking discussions about developing the next graph learning
paradigm that is pre-trained on broad graph data and can be adapted to a wide
range of downstream graph tasks. However, there is currently no clear
definition and systematic analysis for this type of work. In this article, we
propose the concept of graph foundation models (GFMs), and provide the first
comprehensive elucidation on their key characteristics and technologies.
Following that, we categorize existing works towards GFMs into three categories
based on their reliance on graph neural networks and large language models.
Beyond providing a comprehensive overview of the current landscape of graph
foundation models, this article also discusses potential research directions
for this evolving field.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: High-Resolution Building and Road Detection from Sentinel-2. (arXiv:2310.11622v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11622">http://arxiv.org/abs/2310.11622</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11622]] High-Resolution Building and Road Detection from Sentinel-2(http://arxiv.org/abs/2310.11622)</code></li>
<li>Summary: <p>Mapping buildings and roads automatically with remote sensing typically
requires high-resolution imagery, which is expensive to obtain and often
sparsely available. In this work we demonstrate how multiple 10 m resolution
Sentinel-2 images can be used to generate 50 cm resolution building and road
segmentation masks. This is done by training a `student' model with access to
Sentinel-2 images to reproduce the predictions of a `teacher' model which has
access to corresponding high-resolution imagery. While the predictions do not
have all the fine detail of the teacher model, we find that we are able to
retain much of the performance: for building segmentation we achieve 78.3%
mIoU, compared to the high-resolution teacher model accuracy of 85.3% mIoU. We
also describe a related method for counting individual buildings in a
Sentinel-2 patch which achieves R^2 = 0.91 against true counts. This work opens
up new possibilities for using freely available Sentinel-2 imagery for a range
of tasks that previously could only be done with high-resolution satellite
imagery.
</p></li>
</ul>

<h3>Title: Multi Task Consistency Guided Source-Free Test-Time Domain Adaptation Medical Image Segmentation. (arXiv:2310.11766v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11766">http://arxiv.org/abs/2310.11766</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11766]] Multi Task Consistency Guided Source-Free Test-Time Domain Adaptation Medical Image Segmentation(http://arxiv.org/abs/2310.11766)</code></li>
<li>Summary: <p>Source-free test-time adaptation for medical image segmentation aims to
enhance the adaptability of segmentation models to diverse and previously
unseen test sets of the target domain, which contributes to the
generalizability and robustness of medical image segmentation models without
access to the source domain. Ensuring consistency between target edges and
paired inputs is crucial for test-time adaptation. To improve the performance
of test-time domain adaptation, we propose a multi task consistency guided
source-free test-time domain adaptation medical image segmentation method which
ensures the consistency of the local boundary predictions and the global
prototype representation. Specifically, we introduce a local boundary
consistency constraint method that explores the relationship between tissue
region segmentation and tissue boundary localization tasks. Additionally, we
propose a global feature consistency constraint toto enhance the intra-class
compactness. We conduct extensive experiments on the segmentation of benchmark
fundus images. Compared to prediction directly by the source domain model, the
segmentation Dice score is improved by 6.27\% and 0.96\% in RIM-ONE-r3 and
Drishti GS datasets, respectively. Additionally, the results of experiments
demonstrate that our proposed method outperforms existing competitive domain
adaptation segmentation algorithms.
</p></li>
</ul>

<h3>Title: Panoptic Out-of-Distribution Segmentation. (arXiv:2310.11797v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11797">http://arxiv.org/abs/2310.11797</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11797]] Panoptic Out-of-Distribution Segmentation(http://arxiv.org/abs/2310.11797)</code></li>
<li>Summary: <p>Deep learning has led to remarkable strides in scene understanding with
panoptic segmentation emerging as a key holistic scene interpretation task.
However, the performance of panoptic segmentation is severely impacted in the
presence of out-of-distribution (OOD) objects i.e. categories of objects that
deviate from the training distribution. To overcome this limitation, we propose
Panoptic Out-of Distribution Segmentation for joint pixel-level semantic
in-distribution and out-of-distribution classification with instance
prediction. We extend two established panoptic segmentation benchmarks,
Cityscapes and BDD100K, with out-of-distribution instance segmentation
annotations, propose suitable evaluation metrics, and present multiple strong
baselines. Importantly, we propose the novel PoDS architecture with a shared
backbone, an OOD contextual module for learning global and local OOD object
cues, and dual symmetrical decoders with task-specific heads that employ our
alignment-mismatch strategy for better OOD generalization. Combined with our
data augmentation strategy, this approach facilitates progressive learning of
out-of-distribution objects while maintaining in-distribution performance. We
perform extensive evaluations that demonstrate that our proposed PoDS network
effectively addresses the main challenges and substantially outperforms the
baselines. We make the dataset, code, and trained models publicly available at
<a href="http://pods.cs.uni-freiburg.de.">this http URL</a>
</p></li>
</ul>

<h3>Title: VQ-NeRF: Neural Reflectance Decomposition and Editing with Vector Quantization. (arXiv:2310.11864v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11864">http://arxiv.org/abs/2310.11864</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11864]] VQ-NeRF: Neural Reflectance Decomposition and Editing with Vector Quantization(http://arxiv.org/abs/2310.11864)</code></li>
<li>Summary: <p>We propose VQ-NeRF, a two-branch neural network model that incorporates
Vector Quantization (VQ) to decompose and edit reflectance fields in 3D scenes.
Conventional neural reflectance fields use only continuous representations to
model 3D scenes, despite the fact that objects are typically composed of
discrete materials in reality. This lack of discretization can result in noisy
material decomposition and complicated material editing. To address these
limitations, our model consists of a continuous branch and a discrete branch.
The continuous branch follows the conventional pipeline to predict decomposed
materials, while the discrete branch uses the VQ mechanism to quantize
continuous materials into individual ones. By discretizing the materials, our
model can reduce noise in the decomposition process and generate a segmentation
map of discrete materials. Specific materials can be easily selected for
further editing by clicking on the corresponding area of the segmentation
outcomes. Additionally, we propose a dropout-based VQ codeword ranking strategy
to predict the number of materials in a scene, which reduces redundancy in the
material segmentation process. To improve usability, we also develop an
interactive interface to further assist material editing. We evaluate our model
on both computer-generated and real-world scenes, demonstrating its superior
performance. To the best of our knowledge, our model is the first to enable
discrete material editing in 3D scenes.
</p></li>
</ul>

<h3>Title: SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment. (arXiv:2310.12031v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12031">http://arxiv.org/abs/2310.12031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12031]] SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment(http://arxiv.org/abs/2310.12031)</code></li>
<li>Summary: <p>This paper presents an adaptive transformer model named SegmATRon for
embodied image semantic segmentation. Its distinctive feature is the adaptation
of model weights during inference on several images using a hybrid
multicomponent loss function. We studied this model on datasets collected in
the photorealistic Habitat and the synthetic AI2-THOR Simulators. We showed
that obtaining additional images using the agent's actions in an indoor
environment can improve the quality of semantic segmentation. The code of the
proposed approach and datasets are publicly available at
https://github.com/wingrune/SegmATRon.
</p></li>
</ul>

<h3>Title: Improving Long Document Topic Segmentation Models With Enhanced Coherence Modeling. (arXiv:2310.11772v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11772">http://arxiv.org/abs/2310.11772</a></li>
<li>Code URL: https://github.com/alibaba-damo-academy/spokennlp</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11772]] Improving Long Document Topic Segmentation Models With Enhanced Coherence Modeling(http://arxiv.org/abs/2310.11772)</code></li>
<li>Summary: <p>Topic segmentation is critical for obtaining structured long documents and
improving downstream tasks like information retrieval. Due to its ability of
automatically exploring clues of topic shift from a large amount of labeled
data, recent supervised neural models have greatly promoted the development of
long document topic segmentation, but leaving the deeper relationship of
semantic coherence and topic segmentation underexplored. Therefore, this paper
enhances the supervised model's ability to capture coherence from both
structure and similarity perspectives to further improve the topic segmentation
performance, including the Topic-aware Sentence Structure Prediction (TSSP) and
Contrastive Semantic Similarity Learning (CSSL). Specifically, the TSSP task is
proposed to force the model to comprehend structural information by learning
the original relations of adjacent sentences in a disarrayed document, which is
constructed by jointly disrupting the original document at the topic and
sentence levels. In addition, we utilize inter- and intra-topic information to
construct contrastive samples and design the CSSL objective to ensure that the
sentences representations in the same topic have higher semantic similarity,
while those in different topics are less similar. Extensive experiments show
that the Longformer with our approach significantly outperforms old
state-of-the-art (SOTA) methods. Our approach improves $F_{1}$ of old SOTA by
3.42 (73.74 -&gt; 77.16) and reduces $P_{k}$ by 1.11 points (15.0 -&gt; 13.89) on
WIKI-727K and achieves an average reduction of 0.83 points on $P_{k}$ on
WikiSection. The average $P_{k}$ drop of 2.82 points on the two out-of-domain
datasets also illustrates the robustness of our approach
</p></li>
</ul>

<h3>Title: Too Good To Be True: performance overestimation in (re)current practices for Human Activity Recognition. (arXiv:2310.11950v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11950">http://arxiv.org/abs/2310.11950</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11950]] Too Good To Be True: performance overestimation in (re)current practices for Human Activity Recognition(http://arxiv.org/abs/2310.11950)</code></li>
<li>Summary: <p>Today, there are standard and well established procedures within the Human
Activity Recognition (HAR) pipeline. However, some of these conventional
approaches lead to accuracy overestimation. In particular, sliding windows for
data segmentation followed by standard random k-fold cross validation, produce
biased results. An analysis of previous literature and present-day studies,
surprisingly, shows that these are common approaches in state-of-the-art
studies on HAR. It is important to raise awareness in the scientific community
about this problem, whose negative effects are being overlooked. Otherwise,
publications of biased results lead to papers that report lower accuracies,
with correct unbiased methods, harder to publish. Several experiments with
different types of datasets and different types of classification models allow
us to exhibit the problem and show it persists independently of the method or
dataset.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
