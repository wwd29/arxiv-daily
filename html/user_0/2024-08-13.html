<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-08-13</h1>
<h3>Title: Comment on "An Efficient Privacy-Preserving Ranked Multi-Keyword Retrieval for Multiple Data Owners in Outsourced Cloud"</h3>
<ul>
<li><strong>Authors: </strong>Uma Sankararao Varri</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05218">https://arxiv.org/abs/2408.05218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05218">https://arxiv.org/pdf/2408.05218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05218]] Comment on "An Efficient Privacy-Preserving Ranked Multi-Keyword Retrieval for Multiple Data Owners in Outsourced Cloud"(https://arxiv.org/abs/2408.05218)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Protecting the privacy of keywords in the field of search over outsourced cloud data is a challenging task. In IEEE Transactions on Services Computing (Vol. 17 No. 2, March/April 2024), Li et al. proposed PRMKR: efficient privacy-preserving ranked multi-keyword retrieval scheme, which was claimed to resist keyword guessing attack. However, we show that the scheme fails to resist keyword guessing attack, index privacy, and trapdoor privacy. Further, we propose a solution to address the above said issues by correcting the errors in the important equations of the scheme.</li>
</ul>

<h3>Title: LightPHE: Integrating Partially Homomorphic Encryption into Python with Extensive Cloud Environment Evaluations</h3>
<ul>
<li><strong>Authors: </strong>Sefik Ilkin Serengil, Alper Ozpinar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05219">https://arxiv.org/abs/2408.05219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05219">https://arxiv.org/pdf/2408.05219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05219]] LightPHE: Integrating Partially Homomorphic Encryption into Python with Extensive Cloud Environment Evaluations(https://arxiv.org/abs/2408.05219)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust</a></li>
<li><strong>Abstract: </strong>Homomorphic encryption enables computations on encrypted data without accessing private keys, enhancing security in cloud environments. Without this technology, updates need to be performed on-premises or require transmitting private keys to the cloud, increasing security risks. Fully homomorphic encryption (FHE) supports both additive and multiplicative operations on ciphertexts, while partially homomorphic encryption (PHE) supports either addition or multiplication, offering a more efficient and practical solution. This study introduces LightPHE, a lightweight hybrid PHE framework for Python, designed to address the lack of existing PHE libraries. LightPHE integrates multiple PHE algorithms with a modular and extensible design, ensuring robustness and usability for rapid prototyping and secure application development. Cloud-based experiments were conducted on Google Colab (Normal, A100 GPU, L4 GPU, T4 High RAM, TPU2) and Microsoft Azure Spark to evaluate LightPHE's performance and scalability. Key metrics such as key generation, encryption, decryption, and homomorphic operations were assessed. Results showed LightPHE's superior performance in high-computation environments like Colab A100 GPU and TPU2, while also offering viable options for cost-effective setups like Colab Normal and Azure Spark. Comparative analyses demonstrated LightPHE's efficiency and scalability, making it suitable for various applications. The benchmarks offer insights into selecting appropriate cloud environments based on performance needs, highlighting LightPHE's potential to advance homomorphic encryption for secure and efficient cloud-based data processing.</li>
</ul>

<h3>Title: Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nunzio Lore, Alireza (Sepehr)Ilami, Babak Heydari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.ET, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05241">https://arxiv.org/abs/2408.05241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05241">https://arxiv.org/pdf/2408.05241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05241]] Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models(https://arxiv.org/abs/2408.05241)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As the performance of larger, newer Large Language Models continues to improve for strategic Theory of Mind (ToM) tasks, the demand for these state of the art models increases commensurately. However, their deployment is costly both in terms of processing power and time. In this paper, we investigate the feasibility of creating smaller, simulation-ready agents by way of fine-tuning. To do this, we present a large pre-trained model with 20 unique scenarios that combine a social context with a social dilemma, recording its answers, and using them for Q\&A fine-tuning on a smaller model of the same family. Our focus is on in-context game-theoretic decision-making, the same domain within which human interaction occurs and that requires both a theory of mind (or a semblance thereof) and an understanding of social dynamics. We find that the fine-tuned smaller language model exhibited significant performance closer to that of its larger relative, and that their improvements extended in areas and contexts beyond the ones provided in the training examples. On average for all games, through fine-tuning, the smaller model showed a \%46 improvement in aligning with the behavior of the larger model, with \%100 representing complete alignment. This suggests that our pipeline represents an efficient method to transmit some form of theory of mind to smaller models, creating improved and cheaply deployable algorithms in the process. Despite their simplicity and their associated shortcomings and limitations, our findings represent a stepping stone in the pursuit and training of specialized models for strategic and social decision making.</li>
</ul>

<h3>Title: FLASH: Federated Learning-Based LLMs for Advanced Query Processing in Social Networks through RAG</h3>
<ul>
<li><strong>Authors: </strong>Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.IR, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05242">https://arxiv.org/abs/2408.05242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05242">https://arxiv.org/pdf/2408.05242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05242]] FLASH: Federated Learning-Based LLMs for Advanced Query Processing in Social Networks through RAG(https://arxiv.org/abs/2408.05242)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Our paper introduces a novel approach to social network information retrieval and user engagement through a personalized chatbot system empowered by Federated Learning GPT. The system is designed to seamlessly aggregate and curate diverse social media data sources, including user posts, multimedia content, and trending news. Leveraging Federated Learning techniques, the GPT model is trained on decentralized data sources to ensure privacy and security while providing personalized insights and recommendations. Users interact with the chatbot through an intuitive interface, accessing tailored information and real-time updates on social media trends and user-generated content. The system's innovative architecture enables efficient processing of input files, parsing and enriching text data with metadata, and generating relevant questions and answers using advanced language models. By facilitating interactive access to a wealth of social network information, this personalized chatbot system represents a significant advancement in social media communication and knowledge dissemination.</li>
</ul>

<h3>Title: SocFedGPT: Federated GPT-based Adaptive Content Filtering System Leveraging User Interactions in Social Networks</h3>
<ul>
<li><strong>Authors: </strong>Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.IR, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05243">https://arxiv.org/abs/2408.05243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05243">https://arxiv.org/pdf/2408.05243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05243]] SocFedGPT: Federated GPT-based Adaptive Content Filtering System Leveraging User Interactions in Social Networks(https://arxiv.org/abs/2408.05243)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Our study presents a multifaceted approach to enhancing user interaction and content relevance in social media platforms through a federated learning framework. We introduce personalized GPT and Context-based Social Media LLM models, utilizing federated learning for privacy and security. Four client entities receive a base GPT-2 model and locally collected social media data, with federated aggregation ensuring up-to-date model maintenance. Subsequent modules focus on categorizing user posts, computing user persona scores, and identifying relevant posts from friends' lists. A quantifying social engagement approach, coupled with matrix factorization techniques, facilitates personalized content suggestions in real-time. An adaptive feedback loop and readability score algorithm also enhance the quality and relevance of content presented to users. Our system offers a comprehensive solution to content filtering and recommendation, fostering a tailored and engaging social media experience while safeguarding user privacy.</li>
</ul>

<h3>Title: Zero-day attack and ransomware detection</h3>
<ul>
<li><strong>Authors: </strong>Steven Jabulani Nhlapo, Mike Nkongolo Wa Nkongolo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05244">https://arxiv.org/abs/2408.05244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05244">https://arxiv.org/pdf/2408.05244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05244]] Zero-day attack and ransomware detection(https://arxiv.org/abs/2408.05244)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Zero-day and ransomware attacks continue to challenge traditional Network Intrusion Detection Systems (NIDS), revealing their limitations in timely threat classification. Despite efforts to reduce false positives and negatives, significant attacks persist, highlighting the need for advanced solutions. Machine Learning (ML) models show promise in enhancing NIDS. This study uses the UGRansome dataset to train various ML models for zero-day and ransomware attacks detection. The finding demonstrates that Random Forest Classifier (RFC), XGBoost, and Ensemble Methods achieved perfect scores in accuracy, precision, recall, and F1-score. In contrast, Support Vector Machine (SVM) and Naive Bayes (NB) models performed poorly. Comparison with other studies shows Decision Trees and Ensemble Methods improvements, with accuracy around 99.4% and 97.7%, respectively. Future research should explore Synthetic Minority Over-sampling Techniques (SMOTEs) and diverse or versatile datasets to improve real-time recognition of zero-day and ransomware attacks.</li>
</ul>

<h3>Title: Differentially Private Data Release on Graphs: Inefficiencies and Unfairness</h3>
<ul>
<li><strong>Authors: </strong>Ferdinando Fioretto, Diptangshu Sen, Juba Ziani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05246">https://arxiv.org/abs/2408.05246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05246">https://arxiv.org/pdf/2408.05246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05246]] Differentially Private Data Release on Graphs: Inefficiencies and Unfairness(https://arxiv.org/abs/2408.05246)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>Networks are crucial components of many sectors, including telecommunications, healthcare, finance, energy, and transportation.The information carried in such networks often contains sensitive user data, like location data for commuters and packet data for online users. Therefore, when considering data release for networks, one must ensure that data release mechanisms do not leak information about individuals, quantified in a precise mathematical sense. Differential Privacy (DP) is the widely accepted, formal, state-of-the-art technique, which has found use in a variety of real-life settings including the 2020 U.S. Census, Apple users' device data, or Google's location data. Yet, the use of DP comes with new challenges, as the noise added for privacy introduces inaccuracies or biases and further, DP techniques can also distribute these biases disproportionately across different populations, inducing fairness issues. The goal of this paper is to characterize the impact of DP on bias and unfairness in the context of releasing information about networks, taking a departure from previous work which has studied these effects in the context of private population counts release (such as in the U.S. Census). To this end, we consider a network release problem where the network structure is known to all, but the weights on edges must be released privately. We consider the impact of this private release on a simple downstream decision-making task run by a third-party, which is to find the shortest path between any two pairs of nodes and recommend the best route to users. This setting is of highly practical relevance, mirroring scenarios in transportation networks, where preserving privacy while providing accurate routing information is crucial. Our work provides theoretical foundations and empirical evidence into the bias and unfairness arising due to privacy in these networked decision problems.</li>
</ul>

<h3>Title: The Role and Applications of Airport Digital Twin in Cyberattack Protection during the Generative AI Era</h3>
<ul>
<li><strong>Authors: </strong>Abraham Itzhak Weinberg</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05248">https://arxiv.org/abs/2408.05248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05248">https://arxiv.org/pdf/2408.05248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05248]] The Role and Applications of Airport Digital Twin in Cyberattack Protection during the Generative AI Era(https://arxiv.org/abs/2408.05248)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, generative</a></li>
<li><strong>Abstract: </strong>In recent years, the threat facing airports from growing and increasingly sophisticated cyberattacks has become evident. Airports are considered a strategic national asset, so protecting them from attacks, specifically cyberattacks, is a crucial mission. One way to increase airports' security is by using Digital Twins (DTs). This paper shows and demonstrates how DTs can enhance the security mission. The integration of DTs with Generative AI (GenAI) algorithms can lead to synergy and new frontiers in fighting cyberattacks. The paper exemplifies ways to model cyberattack scenarios using simulations and generate synthetic data for testing defenses. It also discusses how DTs can be used as a crucial tool for vulnerability assessment by identifying weaknesses, prioritizing, and accelerating remediations in case of cyberattacks. Moreover, the paper demonstrates approaches for anomaly detection and threat hunting using Machine Learning (ML) and GenAI algorithms. Additionally, the paper provides impact prediction and recovery coordination methods that can be used by DT operators and stakeholders. It also introduces ways to harness the human factor by integrating training and simulation algorithms with Explainable AI (XAI) into the DT platforms. Lastly, the paper offers future applications and technologies that can be utilized in DT environments.</li>
</ul>

<h3>Title: Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review</h3>
<ul>
<li><strong>Authors: </strong>Anshu Ankolekar, Sebastian Boie, Maryam Abdollahyan, Emanuela Gadaleta, Seyed Alireza Hasheminasab, Guang Yang, Charles Beauville, Nikolaos Dikaios, George Anthony Kastis, Michael Bussmann, Sara Khalid, Hagen Kruger, Philippe Lambin, Giorgos Papanastasiou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05249">https://arxiv.org/abs/2408.05249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05249">https://arxiv.org/pdf/2408.05249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05249]] Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review(https://arxiv.org/abs/2408.05249)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has emerged as a promising solution to address the limitations of centralised machine learning (ML) in oncology, particularly in overcoming privacy concerns and harnessing the power of diverse, multi-center data. This systematic review synthesises current knowledge on the state-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer. Distinct from previous surveys, our comprehensive review critically evaluates the real-world implementation and impact of FL on cancer care, demonstrating its effectiveness in enhancing ML generalisability, performance and data privacy in clinical settings and data. We evaluated state-of-the-art advances in FL, demonstrating its growing adoption amid tightening data privacy regulations. FL outperformed centralised ML in 15 out of the 25 studies reviewed, spanning diverse ML models and clinical applications, and facilitating integration of multi-modal information for precision medicine. Despite the current challenges identified in reproducibility, standardisation and methodology across studies, the demonstrable benefits of FL in harnessing real-world data and addressing clinical needs highlight its significant potential for advancing cancer research. We propose that future research should focus on addressing these limitations and investigating further advanced FL methods, to fully harness data diversity and realise the transformative power of cutting-edge FL in cancer care.</li>
</ul>

<h3>Title: From Text to Insight: Leveraging Large Language Models for Performance Evaluation in Management</h3>
<ul>
<li><strong>Authors: </strong>Ning Li, Huaikang Zhou, Mingze Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.ET, cs.HC, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05328">https://arxiv.org/abs/2408.05328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05328">https://arxiv.org/pdf/2408.05328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05328]] From Text to Insight: Leveraging Large Language Models for Performance Evaluation in Management(https://arxiv.org/abs/2408.05328)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study explores the potential of Large Language Models (LLMs), specifically GPT-4, to enhance objectivity in organizational task performance evaluations. Through comparative analyses across two studies, including various task performance outputs, we demonstrate that LLMs can serve as a reliable and even superior alternative to human raters in evaluating knowledge-based performance outputs, which are a key contribution of knowledge workers. Our results suggest that GPT ratings are comparable to human ratings but exhibit higher consistency and reliability. Additionally, combined multiple GPT ratings on the same performance output show strong correlations with aggregated human performance ratings, akin to the consensus principle observed in performance evaluation literature. However, we also find that LLMs are prone to contextual biases, such as the halo effect, mirroring human evaluative biases. Our research suggests that while LLMs are capable of extracting meaningful constructs from text-based data, their scope is currently limited to specific forms of performance evaluation. By highlighting both the potential and limitations of LLMs, our study contributes to the discourse on AI role in management studies and sets a foundation for future research to refine AI theoretical and practical applications in management.</li>
</ul>

<h3>Title: Monero Traceability Heuristics: Wallet Application Bugs and the Mordinal-P2Pool Perspective</h3>
<ul>
<li><strong>Authors: </strong>Nada Hammad, Friedhelm Victor</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05332">https://arxiv.org/abs/2408.05332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05332">https://arxiv.org/pdf/2408.05332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05332]] Monero Traceability Heuristics: Wallet Application Bugs and the Mordinal-P2Pool Perspective(https://arxiv.org/abs/2408.05332)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Privacy-focused cryptoassets like Monero are intentionally difficult to trace. Over the years, several traceability heuristics have been proposed, most of which have been rendered ineffective with subsequent protocol upgrades. Between 2019 and 2023, Monero wallet application bugs "Differ By One" and "10 Block Decoy Bug" have been observed and identified and discussed in the Monero community. In addition, a decentralized mining pool named P2Pool has proliferated, and a controversial UTXO NFT imitation known as Mordinals has been tried for Monero. In this paper, we systematically describe the traceability heuristics that have emerged from these developments, and evaluate their quality based on ground truth, and through pairwise comparisons. We also explore the temporal perspective, and show which of these heuristics have been applicable over the past years, what fraction of decoys could be eliminated and what the remaining effective ring size is. Our findings illustrate that most of the heuristics have a high precision, that the "10 Block Decoy Bug" and the Coinbase decoy identification heuristics have had the most impact between 2019 and 2023, and that the former could be used to evaluate future heuristics, if they are also applicable during that time frame.</li>
</ul>

<h3>Title: DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Saidul Islam, Enamul Hoque, Shafiq Joty, Md Tahmid Rahman Laskar, Md Rizwan Parvez</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05346">https://arxiv.org/abs/2408.05346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05346">https://arxiv.org/pdf/2408.05346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05346]] DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts(https://arxiv.org/abs/2408.05346)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Data-driven storytelling is a powerful method for conveying insights by combining narrative techniques with visualizations and text. These stories integrate visual aids, such as highlighted bars and lines in charts, along with textual annotations explaining insights. However, creating such stories requires a deep understanding of the data and meticulous narrative planning, often necessitating human intervention, which can be time-consuming and mentally taxing. While Large Language Models (LLMs) excel in various NLP tasks, their ability to generate coherent and comprehensive data stories remains underexplored. In this work, we introduce a novel task for data story generation and a benchmark containing 1,449 stories from diverse sources. To address the challenges of crafting coherent data stories, we propose a multiagent framework employing two LLM agents designed to replicate the human storytelling process: one for understanding and describing the data (Reflection), generating the outline, and narration, and another for verification at each intermediary step. While our agentic framework generally outperforms non-agentic counterparts in both model-based and human evaluations, the results also reveal unique challenges in data story generation.</li>
</ul>

<h3>Title: Enabling Quick, Accurate Crowdsourced Annotation for Elevation-Aware Flood Extent Mapping</h3>
<ul>
<li><strong>Authors: </strong>Landon Dyken, Saugat Adhikari, Pravin Poudel, Steve Petruzza, Da Yan, Will Usher, Sidharth Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05350">https://arxiv.org/abs/2408.05350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05350">https://arxiv.org/pdf/2408.05350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05350]] Enabling Quick, Accurate Crowdsourced Annotation for Elevation-Aware Flood Extent Mapping(https://arxiv.org/abs/2408.05350)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In order to assess damage and properly allocate relief efforts, mapping the extent of flood events is a necessary and important aspect of disaster management. In recent years, deep learning methods have evolved as an effective tool to quickly label high-resolution imagery and provide necessary flood extent mappings. These methods, though, require large amounts of annotated training data to create models that are accurate and robust to new flooded imagery. In this work, we provide FloodTrace, an application that enables effective crowdsourcing for flooded region annotation for machine learning training data, removing the requirement for annotation to be done solely by researchers. We accomplish this through two orthogonal methods within our application, informed by requirements from domain experts. First, we utilize elevation-guided annotation tools and 3D rendering to inform user annotation decisions with digital elevation model data, improving annotation accuracy. For this purpose, we provide a unique annotation method that uses topological data analysis to outperform the state-of-the-art elevation-guided annotation tool in efficiency. Second, we provide a framework for researchers to review aggregated crowdsourced annotations and correct inaccuracies using methods inspired by uncertainty visualization. We conducted a user study to confirm the application effectiveness in which 266 graduate students annotated high-resolution aerial imagery from Hurricane Matthew in North Carolina. Experimental results show the accuracy and efficiency benefits of our application apply even for untrained users. In addition, using our aggregation and correction framework, flood detection models trained on crowdsourced annotations were able to achieve performance equal to models trained on expert-labeled annotations, while requiring a fraction of the time on the part of the researcher.</li>
</ul>

<h3>Title: Spherical World-Locking for Audio-Visual Localization in Egocentric Videos</h3>
<ul>
<li><strong>Authors: </strong>Heeseung Yun, Ruohan Gao, Ishwarya Ananthabhotla, Anurag Kumar, Jacob Donley, Chao Li, Gunhee Kim, Vamsi Krishna Ithapu, Calvin Murdock</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05364">https://arxiv.org/abs/2408.05364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05364">https://arxiv.org/pdf/2408.05364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05364]] Spherical World-Locking for Audio-Visual Localization in Egocentric Videos(https://arxiv.org/abs/2408.05364)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Egocentric videos provide comprehensive contexts for user and scene understanding, spanning multisensory perception to behavioral interaction. We propose Spherical World-Locking (SWL) as a general framework for egocentric scene representation, which implicitly transforms multisensory streams with respect to measurements of head orientation. Compared to conventional head-locked egocentric representations with a 2D planar field-of-view, SWL effectively offsets challenges posed by self-motion, allowing for improved spatial synchronization between input modalities. Using a set of multisensory embeddings on a worldlocked sphere, we design a unified encoder-decoder transformer architecture that preserves the spherical structure of the scene representation, without requiring expensive projections between image and world coordinate systems. We evaluate the effectiveness of the proposed framework on multiple benchmark tasks for egocentric video understanding, including audio-visual active speaker localization, auditory spherical source localization, and behavior anticipation in everyday activities.</li>
</ul>

<h3>Title: FiST-Financial Style Transfer with Hallucination and Creativity Control Framework</h3>
<ul>
<li><strong>Authors: </strong>Sohini Roychowdhury, Marko Krema, Brian Moore, Xingjian Lai, Dike Effedua, Bharat Jethwani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05365">https://arxiv.org/abs/2408.05365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05365">https://arxiv.org/pdf/2408.05365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05365]] FiST-Financial Style Transfer with Hallucination and Creativity Control Framework(https://arxiv.org/abs/2408.05365)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Financial report generation using general purpose large language models pose two major challenges, including the lack of compound sentences and hallucinations. Advanced prompt engineering and retrieval augmented generation (RAG) techniques are incapable of curing the writing style discrepancies. In this work we propose a novel two-stage fine-tuning process wherein public domain financial reports are processed into prompt-completions and augmented using simple LLM prompts to then enable sectional financial report generation using minimal instructions and tabular data inputs. Our proposed fine-tuning framework results doubles the number of correct questions answers and reduces hallucinations by over 50%. Additionally, the two-stage fine tuned models have lower perplexity, improved ROUGE, TER and BLEU scores, higher creativity and knowledge density with lower uncertainty and cross entropy.</li>
</ul>

<h3>Title: SAMSA: Efficient Transformer for Many Data Modalities</h3>
<ul>
<li><strong>Authors: </strong>Minh Lenhat, Viet Anh Nguyen, Khoa Nguyen, Duong Duc Hieu, Dao Huu Hung, Truong Son Hy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05391">https://arxiv.org/abs/2408.05391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05391">https://arxiv.org/pdf/2408.05391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05391]] SAMSA: Efficient Transformer for Many Data Modalities(https://arxiv.org/abs/2408.05391)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The versatility of self-attention mechanism earned transformers great success in almost all data modalities, with limitations on the quadratic complexity and difficulty of training. Efficient transformers, on the other hand, often rely on clever data-modality-dependent construction to get over the quadratic complexity of transformers. This greatly hinders their applications on different data modalities, which is one of the pillars of contemporary foundational modeling. In this paper, we lay the groundwork for efficient foundational modeling by proposing SAMSA - SAMpling-Self-Attention, a context-aware linear complexity self-attention mechanism that works well on multiple data modalities. Our mechanism is based on a differentiable sampling without replacement method we discovered. This enables the self-attention module to attend to the most important token set, where the importance is defined by data. Moreover, as differentiability is not needed in inference, the sparse formulation of our method costs little time overhead, further lowering computational costs. In short, SAMSA achieved competitive or even SOTA results on many benchmarks, while being faster in inference, compared to other very specialized models. Against full self-attention, real inference time significantly decreases while performance ranges from negligible degradation to outperformance. We release our source code in the repository: this https URL</li>
</ul>

<h3>Title: PersonViT: Large-scale Self-supervised Vision Transformer for Person Re-Identificat</h3>
<ul>
<li><strong>Authors: </strong>Bin Hu, Xinggang Wang, Wenyu Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05398">https://arxiv.org/abs/2408.05398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05398">https://arxiv.org/pdf/2408.05398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05398]] PersonViT: Large-scale Self-supervised Vision Transformer for Person Re-Identificat(https://arxiv.org/abs/2408.05398)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Person Re-Identification (ReID) aims to retrieve relevant individuals in non-overlapping camera images and has a wide range of applications in the field of public safety. In recent years, with the development of Vision Transformer (ViT) and self-supervised learning techniques, the performance of person ReID based on self-supervised pre-training has been greatly improved. Person ReID requires extracting highly discriminative local fine-grained features of the human body, while traditional ViT is good at extracting context-related global features, making it difficult to focus on local human body features. To this end, this article introduces the recently emerged Masked Image Modeling (MIM) self-supervised learning method into person ReID, and effectively extracts high-quality global and local features through large-scale unsupervised pre-training by combining masked image modeling and discriminative contrastive learning, and then conducts supervised fine-tuning training in the person ReID task. This person feature extraction method based on ViT with masked image modeling (PersonViT) has the good characteristics of unsupervised, scalable, and strong generalization capabilities, overcoming the problem of difficult annotation in supervised person ReID, and achieves state-of-the-art results on publicly available benchmark datasets, including MSMT17, Market1501, DukeMTMC-reID, and Occluded-Duke. The code and pre-trained models of the PersonViT method are released at this https URL to promote further research in the person ReID fie</li>
</ul>

<h3>Title: LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification</h3>
<ul>
<li><strong>Authors: </strong>Hongde Liu, Chenyuan He, Feiyang Meng, Changyong Niu, Yuxiang Jia</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05404">https://arxiv.org/abs/2408.05404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05404">https://arxiv.org/pdf/2408.05404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05404]] LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification(https://arxiv.org/abs/2408.05404)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Metaphor Components Identification (MCI) contributes to enhancing machine understanding of metaphors, thereby advancing downstream natural language processing tasks. However, the complexity, diversity, and dependency on context and background knowledge pose significant challenges for MCI. Large language models (LLMs) offer new avenues for accurate comprehension of complex natural language texts due to their strong semantic analysis and extensive commonsense knowledge. In this research, a new LLM-based framework is proposed, named Linguistics-aware In-context Learning with Data Augmentation (LaiDA). Specifically, ChatGPT and supervised fine-tuning are utilized to tailor a high-quality dataset. LaiDA incorporates a simile dataset for pre-training. A graph attention network encoder generates linguistically rich feature representations to retrieve similar examples. Subsequently, LLM is fine-tuned with prompts that integrate linguistically similar examples. LaiDA ranked 2nd in Subtask 2 of NLPCC2024 Shared Task 9, demonstrating its effectiveness. Code and data are available at this https URL.</li>
</ul>

<h3>Title: RSL-BA: Rolling Shutter Line Bundle Adjustment</h3>
<ul>
<li><strong>Authors: </strong>Yongcong Zhang, Bangyan Liao, Yifei Xue, Chen Lu, Peidong Liu, Yizhen Lao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05409">https://arxiv.org/abs/2408.05409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05409">https://arxiv.org/pdf/2408.05409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05409]] RSL-BA: Rolling Shutter Line Bundle Adjustment(https://arxiv.org/abs/2408.05409)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The line is a prevalent element in man-made environments, inherently encoding spatial structural information, thus making it a more robust choice for feature representation in practical applications. Despite its apparent advantages, previous rolling shutter bundle adjustment (RSBA) methods have only supported sparse feature points, which lack robustness, particularly in degenerate environments. In this paper, we introduce the first rolling shutter line-based bundle adjustment solution, RSL-BA. Specifically, we initially establish the rolling shutter camera line projection theory utilizing Plücker line parameterization. Subsequently, we derive a series of reprojection error formulations which are stable and efficient. Finally, we theoretically and experimentally demonstrate that our method can prevent three common degeneracies, one of which is first discovered in this paper. Extensive synthetic and real data experiments demonstrate that our method achieves efficiency and accuracy comparable to existing point-based rolling shutter bundle adjustment solutions.</li>
</ul>

<h3>Title: Style-Preserving Lip Sync via Audio-Aware Style Reference</h3>
<ul>
<li><strong>Authors: </strong>Weizhi Zhong, Jichang Li, Yinqi Cai, Liang Lin, Guanbin Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05412">https://arxiv.org/abs/2408.05412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05412">https://arxiv.org/pdf/2408.05412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05412]] Style-Preserving Lip Sync via Audio-Aware Style Reference(https://arxiv.org/abs/2408.05412)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Audio-driven lip sync has recently drawn significant attention due to its widespread application in the multimedia domain. Individuals exhibit distinct lip shapes when speaking the same utterance, attributed to the unique speaking styles of individuals, posing a notable challenge for audio-driven lip sync. Earlier methods for such task often bypassed the modeling of personalized speaking styles, resulting in sub-optimal lip sync conforming to the general styles. Recent lip sync techniques attempt to guide the lip sync for arbitrary audio by aggregating information from a style reference video, yet they can not preserve the speaking styles well due to their inaccuracy in style aggregation. This work proposes an innovative audio-aware style reference scheme that effectively leverages the relationships between input audio and reference audio from style reference video to address the style-preserving audio-driven lip sync. Specifically, we first develop an advanced Transformer-based model adept at predicting lip motion corresponding to the input audio, augmented by the style information aggregated through cross-attention layers from style reference video. Afterwards, to better render the lip motion into realistic talking face video, we devise a conditional latent diffusion model, integrating lip motion through modulated convolutional layers and fusing reference facial images via spatial cross-attention layers. Extensive experiments validate the efficacy of the proposed approach in achieving precise lip sync, preserving speaking styles, and generating high-fidelity, realistic talking face videos.</li>
</ul>

<h3>Title: High-fidelity and Lip-synced Talking Face Synthesis via Landmark-based Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Weizhi Zhong, Junfan Lin, Peixin Chen, Liang Lin, Guanbin Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05416">https://arxiv.org/abs/2408.05416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05416">https://arxiv.org/pdf/2408.05416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05416]] High-fidelity and Lip-synced Talking Face Synthesis via Landmark-based Diffusion Model(https://arxiv.org/abs/2408.05416)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Audio-driven talking face video generation has attracted increasing attention due to its huge industrial potential. Some previous methods focus on learning a direct mapping from audio to visual content. Despite progress, they often struggle with the ambiguity of the mapping process, leading to flawed results. An alternative strategy involves facial structural representations (e.g., facial landmarks) as intermediaries. This multi-stage approach better preserves the appearance details but suffers from error accumulation due to the independent optimization of different stages. Moreover, most previous methods rely on generative adversarial networks, prone to training instability and mode collapse. To address these challenges, our study proposes a novel landmark-based diffusion model for talking face generation, which leverages facial landmarks as intermediate representations while enabling end-to-end optimization. Specifically, we first establish the less ambiguous mapping from audio to landmark motion of lip and jaw. Then, we introduce an innovative conditioning module called TalkFormer to align the synthesized motion with the motion represented by landmarks via differentiable cross-attention, which enables end-to-end optimization for improved lip synchronization. Besides, TalkFormer employs implicit feature warping to align the reference image features with the target motion for preserving more appearance details. Extensive experiments demonstrate that our approach can synthesize high-fidelity and lip-synced talking face videos, preserving more subject appearance details from the reference image.</li>
</ul>

<h3>Title: Modeling Multi-Step Scientific Processes with Graph Transformer Networks</h3>
<ul>
<li><strong>Authors: </strong>Amanda A. Volk, Robert W. Epps, Jeffrey G. Ethier, Luke A. Baldwin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05425">https://arxiv.org/abs/2408.05425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05425">https://arxiv.org/pdf/2408.05425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05425]] Modeling Multi-Step Scientific Processes with Graph Transformer Networks(https://arxiv.org/abs/2408.05425)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This work presents the use of graph learning for the prediction of multi-step experimental outcomes for applications across experimental research, including material science, chemistry, and biology. The viability of geometric learning for regression tasks was benchmarked against a collection of linear models through a combination of simulated and real-world data training studies. First, a selection of five arbitrarily designed multi-step surrogate functions were developed to reflect various features commonly found within experimental processes. A graph transformer network outperformed all tested linear models in scenarios that featured hidden interactions between process steps and sequence dependent features, while retaining equivalent performance in sequence agnostic scenarios. Then, a similar comparison was applied to real-world literature data on algorithm guided colloidal atomic layer deposition. Using the complete reaction sequence as training data, the graph neural network outperformed all linear models in predicting the three spectral properties for most training set sizes. Further implementation of graph neural networks and geometric representation of scientific processes for the prediction of experiment outcomes could lead to algorithm driven navigation of higher dimension parameter spaces and efficient exploration of more dynamic systems.</li>
</ul>

<h3>Title: SAM-FNet: SAM-Guided Fusion Network for Laryngo-Pharyngeal Tumor Detection</h3>
<ul>
<li><strong>Authors: </strong>Jia Wei, Yun Li, Meiyu Qiu, Hongyu Chen, Xiaomao Fan, Wenbin Lei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05426">https://arxiv.org/abs/2408.05426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05426">https://arxiv.org/pdf/2408.05426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05426]] SAM-FNet: SAM-Guided Fusion Network for Laryngo-Pharyngeal Tumor Detection(https://arxiv.org/abs/2408.05426)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Laryngo-pharyngeal cancer (LPC) is a highly fatal malignant disease affecting the head and neck region. Previous studies on endoscopic tumor detection, particularly those leveraging dual-branch network architectures, have shown significant advancements in tumor detection. These studies highlight the potential of dual-branch networks in improving diagnostic accuracy by effectively integrating global and local (lesion) feature extraction. However, they are still limited in their capabilities to accurately locate the lesion region and capture the discriminative feature information between the global and local branches. To address these issues, we propose a novel SAM-guided fusion network (SAM-FNet), a dual-branch network for laryngo-pharyngeal tumor detection. By leveraging the powerful object segmentation capabilities of the Segment Anything Model (SAM), we introduce the SAM into the SAM-FNet to accurately segment the lesion region. Furthermore, we propose a GAN-like feature optimization (GFO) module to capture the discriminative features between the global and local branches, enhancing the fusion feature complementarity. Additionally, we collect two LPC datasets from the First Affiliated Hospital (FAHSYSU) and the Sixth Affiliated Hospital (SAHSYSU) of Sun Yat-sen University. The FAHSYSU dataset is used as the internal dataset for training the model, while the SAHSYSU dataset is used as the external dataset for evaluating the model's performance. Extensive experiments on both datasets of FAHSYSU and SAHSYSU demonstrate that the SAM-FNet can achieve competitive results, outperforming the state-of-the-art counterparts. The source code of SAM-FNet is available at the URL of this https URL.</li>
</ul>

<h3>Title: Detecting Masquerade Attacks in Controller Area Networks Using Graph Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>William Marfo, Pablo Moriano, Deepak K. Tosh, Shirley V. Moore</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05427">https://arxiv.org/abs/2408.05427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05427">https://arxiv.org/pdf/2408.05427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05427]] Detecting Masquerade Attacks in Controller Area Networks Using Graph Machine Learning(https://arxiv.org/abs/2408.05427)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Modern vehicles rely on a myriad of electronic control units (ECUs) interconnected via controller area networks (CANs) for critical operations. Despite their ubiquitous use and reliability, CANs are susceptible to sophisticated cyberattacks, particularly masquerade attacks, which inject false data that mimic legitimate messages at the expected frequency. These attacks pose severe risks such as unintended acceleration, brake deactivation, and rogue steering. Traditional intrusion detection systems (IDS) often struggle to detect these subtle intrusions due to their seamless integration into normal traffic. This paper introduces a novel framework for detecting masquerade attacks in the CAN bus using graph machine learning (ML). We hypothesize that the integration of shallow graph embeddings with time series features derived from CAN frames enhances the detection of masquerade attacks. We show that by representing CAN bus frames as message sequence graphs (MSGs) and enriching each node with contextual statistical attributes from time series, we can enhance detection capabilities across various attack patterns compared to using only graph-based features. Our method ensures a comprehensive and dynamic analysis of CAN frame interactions, improving robustness and efficiency. Extensive experiments on the ROAD dataset validate the effectiveness of our approach, demonstrating statistically significant improvements in the detection rates of masquerade attacks compared to a baseline that uses only graph-based features, as confirmed by Mann-Whitney U and Kolmogorov-Smirnov tests (p < 0.05).</li>
</ul>

<h3>Title: Ensemble everything everywhere: Multi-scale aggregation for adversarial robustness</h3>
<ul>
<li><strong>Authors: </strong>Stanislav Fort, Balaji Lakshminarayanan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05446">https://arxiv.org/abs/2408.05446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05446">https://arxiv.org/pdf/2408.05446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05446]] Ensemble everything everywhere: Multi-scale aggregation for adversarial robustness(https://arxiv.org/abs/2408.05446)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial examples pose a significant challenge to the robustness, reliability and alignment of deep neural networks. We propose a novel, easy-to-use approach to achieving high-quality representations that lead to adversarial robustness through the use of multi-resolution input representations and dynamic self-ensembling of intermediate layer predictions. We demonstrate that intermediate layer predictions exhibit inherent robustness to adversarial attacks crafted to fool the full classifier, and propose a robust aggregation mechanism based on Vickrey auction that we call \textit{CrossMax} to dynamically ensemble them. By combining multi-resolution inputs and robust ensembling, we achieve significant adversarial robustness on CIFAR-10 and CIFAR-100 datasets without any adversarial training or extra data, reaching an adversarial accuracy of $\approx$72% (CIFAR-10) and $\approx$48% (CIFAR-100) on the RobustBench AutoAttack suite ($L_\infty=8/255)$ with a finetuned ImageNet-pretrained ResNet152. This represents a result comparable with the top three models on CIFAR-10 and a +5 % gain compared to the best current dedicated approach on CIFAR-100. Adding simple adversarial training on top, we get $\approx$78% on CIFAR-10 and $\approx$51% on CIFAR-100, improving SOTA by 5 % and 9 % respectively and seeing greater gains on the harder dataset. We validate our approach through extensive experiments and provide insights into the interplay between adversarial robustness, and the hierarchical nature of deep representations. We show that simple gradient-based attacks against our model lead to human-interpretable images of the target classes as well as interpretable image changes. As a byproduct, using our multi-resolution prior, we turn pre-trained classifiers and CLIP models into controllable image generators and develop successful transferable attacks on large vision language models.</li>
</ul>

<h3>Title: EV-MGDispNet: Motion-Guided Event-Based Stereo Disparity Estimation Network with Left-Right Consistency</h3>
<ul>
<li><strong>Authors: </strong>Junjie Jiang, Hao Zhuang, Xinjie Huang, Delei Kong, Zheng Fang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05452">https://arxiv.org/abs/2408.05452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05452">https://arxiv.org/pdf/2408.05452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05452]] EV-MGDispNet: Motion-Guided Event-Based Stereo Disparity Estimation Network with Left-Right Consistency(https://arxiv.org/abs/2408.05452)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Event cameras have the potential to revolutionize the field of robot vision, particularly in areas like stereo disparity estimation, owing to their high temporal resolution and high dynamic range. Many studies use deep learning for event camera stereo disparity estimation. However, these methods fail to fully exploit the temporal information in the event stream to acquire clear event representations. Additionally, there is room for further reduction in pixel shifts in the feature maps before constructing the cost volume. In this paper, we propose EV-MGDispNet, a novel event-based stereo disparity estimation method. Firstly, we propose an edge-aware aggregation (EAA) module, which fuses event frames and motion confidence maps to generate a novel clear event representation. Then, we propose a motion-guided attention (MGA) module, where motion confidence maps utilize deformable transformer encoders to enhance the feature map with more accurate edges. Finally, we also add a census left-right consistency loss function to enhance the left-right consistency of stereo event representation. Through conducting experiments within challenging real-world driving scenarios, we validate that our method outperforms currently known state-of-the-art methods in terms of mean absolute error (MAE) and root mean square error (RMSE) metrics.</li>
</ul>

<h3>Title: Multimodal generative semantic communication based on latent diffusion model</h3>
<ul>
<li><strong>Authors: </strong>Weiqi Fu, Lianming Xu, Xin Wu, Haoyang Wei, Li Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05455">https://arxiv.org/abs/2408.05455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05455">https://arxiv.org/pdf/2408.05455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05455]] Multimodal generative semantic communication based on latent diffusion model(https://arxiv.org/abs/2408.05455)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>In emergencies, the ability to quickly and accurately gather environmental data and command information, and to make timely decisions, is particularly critical. Traditional semantic communication frameworks, primarily based on a single modality, are susceptible to complex environments and lighting conditions, thereby limiting decision accuracy. To this end, this paper introduces a multimodal generative semantic communication framework named mm-GESCO. The framework ingests streams of visible and infrared modal image data, generates fused semantic segmentation maps, and transmits them using a combination of one-hot encoding and zlib compression techniques to enhance data transmission efficiency. At the receiving end, the framework can reconstruct the original multimodal images based on the semantic maps. Additionally, a latent diffusion model based on contrastive learning is designed to align different modal data within the latent space, allowing mm-GESCO to reconstruct latent features of any modality presented at the input. Experimental results demonstrate that mm-GESCO achieves a compression ratio of up to 200 times, surpassing the performance of existing semantic communication frameworks and exhibiting excellent performance in downstream tasks such as object classification and detection.</li>
</ul>

<h3>Title: Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph Representation</h3>
<ul>
<li><strong>Authors: </strong>Wenbo Shang, Xuliang Zhu, Xin Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05456">https://arxiv.org/abs/2408.05456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05456">https://arxiv.org/pdf/2408.05456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05456]] Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph Representation(https://arxiv.org/abs/2408.05456)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Unified graph representation learning aims to produce node embeddings, which can be applied to multiple downstream applications. However, existing studies based on graph neural networks and language models either suffer from the limitations of numerous training needed toward specific downstream predictions or have shallow semantic features. In this work, we propose a novel Path-LLM model to learn unified graph representation, which leverages a powerful large language model (LLM) to incorporate our proposed path features. Our Path-LLM framework consists of several well-designed techniques. First, we develop a new mechanism of long-to-short shortest path (L2SP) selection, which covers essential connections between different dense groups. An in-depth comparison of different path selection plans is offered to illustrate the strength of our designed L2SP. Then, we design path textualization to obtain L2SP-based training texts. Next, we feed the texts into a self-supervised LLM training process to learn embeddings. Extensive experiments on benchmarks validate the superiority of Path-LLM against the state-of-the-art WalkLM method on two classical graph learning tasks (node classification and link prediction) and one NP-hard graph query processing task (keyword search), meanwhile saving more than 90% of training paths.</li>
</ul>

<h3>Title: Investigating Instruction Tuning Large Language Models on Graphs</h3>
<ul>
<li><strong>Authors: </strong>Kerui Zhu, Bo-Wei Huang, Bowen Jin, Yizhu Jiao, Ming Zhong, Kevin Chang, Shou-De Lin, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05457">https://arxiv.org/abs/2408.05457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05457">https://arxiv.org/pdf/2408.05457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05457]] Investigating Instruction Tuning Large Language Models on Graphs(https://arxiv.org/abs/2408.05457)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inspired by the recent advancements of Large Language Models (LLMs) in NLP tasks, there's growing interest in applying LLMs to graph-related tasks. This study delves into the capabilities of instruction-following LLMs for engaging with real-world graphs, aiming to offer empirical insights into how LLMs can effectively interact with graphs and generalize across graph tasks. We begin by constructing a dataset designed for instruction tuning, which comprises a diverse collection of 79 graph-related tasks from academic and e-commerce domains, featuring 44,240 training instances and 18,960 test samples. Utilizing this benchmark, our initial investigation focuses on identifying the optimal graph representation that serves as a conduit for LLMs to understand complex graph structures. Our findings indicate that JSON format for graph representation consistently outperforms natural language and code formats across various LLMs and graph types. Furthermore, we examine the key factors that influence the generalization abilities of instruction-tuned LLMs by evaluating their performance on both in-domain and out-of-domain graph tasks.</li>
</ul>

<h3>Title: FuXi Weather: An end-to-end machine learning weather data assimilation and forecasting system</h3>
<ul>
<li><strong>Authors: </strong>Xiuyu Sun, Xiaohui Zhong, Xiaoze Xu, Yuanqing Huang, Hao Li, Jie Feng, Wei Han, Libo Wu, Yuan Qi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05472">https://arxiv.org/abs/2408.05472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05472">https://arxiv.org/pdf/2408.05472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05472]] FuXi Weather: An end-to-end machine learning weather data assimilation and forecasting system(https://arxiv.org/abs/2408.05472)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Operational numerical weather prediction systems consist of three fundamental components: the global observing system for data collection, data assimilation for generating initial conditions, and the forecasting model to predict future weather conditions. While NWP have undergone a quiet revolution, with forecast skills progressively improving over the past few decades, their advancement has slowed due to challenges such as high computational costs and the complexities associated with assimilating an increasing volume of observational data and managing finer spatial grids. Advances in machine learning offer an alternative path towards more efficient and accurate weather forecasts. The rise of machine learning based weather forecasting models has also spurred the development of machine learning based DA models or even purely machine learning based weather forecasting systems. This paper introduces FuXi Weather, an end-to-end machine learning based weather forecasting system. FuXi Weather employs specialized data preprocessing and multi-modal data fusion techniques to integrate information from diverse sources under all-sky conditions, including microwave sounders from 3 polar-orbiting satellites and radio occultation data from Global Navigation Satellite System. Operating on a 6-hourly DA and forecasting cycle, FuXi Weather independently generates robust and accurate 10-day global weather forecasts at a spatial resolution of 0.25\textdegree. It surpasses the European Centre for Medium-range Weather Forecasts high-resolution forecasts in terms of predictability, extending the skillful forecast lead times for several key weather variables such as the geopotential height at 500 hPa from 9.25 days to 9.5 days. The system's high computational efficiency and robust performance, even with limited observations, demonstrates its potential as a promising alternative to traditional NWP systems.</li>
</ul>

<h3>Title: A Structural Feature-Based Approach for Comprehensive Graph Classification</h3>
<ul>
<li><strong>Authors: </strong>Saiful Islam, Md. Nahid Hasan, Pitambar Khanra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05474">https://arxiv.org/abs/2408.05474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05474">https://arxiv.org/pdf/2408.05474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05474]] A Structural Feature-Based Approach for Comprehensive Graph Classification(https://arxiv.org/abs/2408.05474)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>The increasing prevalence of graph-structured data across various domains has intensified greater interest in graph classification tasks. While numerous sophisticated graph learning methods have emerged, their complexity often hinders practical implementation. In this article, we address this challenge by proposing a method that constructs feature vectors based on fundamental graph structural properties. We demonstrate that these features, despite their simplicity, are powerful enough to capture the intrinsic characteristics of graphs within the same class. We explore the efficacy of our approach using three distinct machine learning methods, highlighting how our feature-based classification leverages the inherent structural similarities of graphs within the same class to achieve accurate classification. A key advantage of our approach is its simplicity, which makes it accessible and adaptable to a broad range of applications, including social network analysis, bioinformatics, and cybersecurity. Furthermore, we conduct extensive experiments to validate the performance of our method, showing that it not only reveals a competitive performance but in some cases surpasses the accuracy of more complex, state-of-the-art techniques. Our findings suggest that a focus on fundamental graph features can provide a robust and efficient alternative for graph classification, offering significant potential for both research and practical applications.</li>
</ul>

<h3>Title: ReToMe-VA: Recursive Token Merging for Video Diffusion-based Unrestricted Adversarial Attack</h3>
<ul>
<li><strong>Authors: </strong>Ziyi Gao, Kai Chen, Zhipeng Wei, Tingshu Mou, Jingjing Chen, Zhiyu Tan, Hao Li, Yu-Gang Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05479">https://arxiv.org/abs/2408.05479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05479">https://arxiv.org/pdf/2408.05479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05479]] ReToMe-VA: Recursive Token Merging for Video Diffusion-based Unrestricted Adversarial Attack(https://arxiv.org/abs/2408.05479)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Recent diffusion-based unrestricted attacks generate imperceptible adversarial examples with high transferability compared to previous unrestricted attacks and restricted attacks. However, existing works on diffusion-based unrestricted attacks are mostly focused on images yet are seldom explored in videos. In this paper, we propose the Recursive Token Merging for Video Diffusion-based Unrestricted Adversarial Attack (ReToMe-VA), which is the first framework to generate imperceptible adversarial video clips with higher transferability. Specifically, to achieve spatial imperceptibility, ReToMe-VA adopts a Timestep-wise Adversarial Latent Optimization (TALO) strategy that optimizes perturbations in diffusion models' latent space at each denoising step. TALO offers iterative and accurate updates to generate more powerful adversarial frames. TALO can further reduce memory consumption in gradient computation. Moreover, to achieve temporal imperceptibility, ReToMe-VA introduces a Recursive Token Merging (ReToMe) mechanism by matching and merging tokens across video frames in the self-attention module, resulting in temporally consistent adversarial videos. ReToMe concurrently facilitates inter-frame interactions into the attack process, inducing more diverse and robust gradients, thus leading to better adversarial transferability. Extensive experiments demonstrate the efficacy of ReToMe-VA, particularly in surpassing state-of-the-art attacks in adversarial transferability by more than 14.16% on average.</li>
</ul>

<h3>Title: ZePo: Zero-Shot Portrait Stylization with Faster Sampling</h3>
<ul>
<li><strong>Authors: </strong>Jin Liu, Huaibo Huang, Jie Cao, Ran He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05492">https://arxiv.org/abs/2408.05492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05492">https://arxiv.org/pdf/2408.05492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05492]] ZePo: Zero-Shot Portrait Stylization with Faster Sampling(https://arxiv.org/abs/2408.05492)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion-based text-to-image generation models have significantly advanced the field of art content synthesis. However, current portrait stylization methods generally require either model fine-tuning based on examples or the employment of DDIM Inversion to revert images to noise space, both of which substantially decelerate the image generation process. To overcome these limitations, this paper presents an inversion-free portrait stylization framework based on diffusion models that accomplishes content and style feature fusion in merely four sampling steps. We observed that Latent Consistency Models employing consistency distillation can effectively extract representative Consistency Features from noisy images. To blend the Consistency Features extracted from both content and style images, we introduce a Style Enhancement Attention Control technique that meticulously merges content and style features within the attention space of the target image. Moreover, we propose a feature merging strategy to amalgamate redundant features in Consistency Features, thereby reducing the computational load of attention control. Extensive experiments have validated the effectiveness of our proposed framework in enhancing stylization efficiency and fidelity. The code is available at \url{this https URL}.</li>
</ul>

<h3>Title: MABR: A Multilayer Adversarial Bias Removal Approach Without Prior Bias Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Maxwell J. Yin, Boyu Wang, Charles Ling</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05497">https://arxiv.org/abs/2408.05497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05497">https://arxiv.org/pdf/2408.05497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05497]] MABR: A Multilayer Adversarial Bias Removal Approach Without Prior Bias Knowledge(https://arxiv.org/abs/2408.05497)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Models trained on real-world data often mirror and exacerbate existing social biases. Traditional methods for mitigating these biases typically require prior knowledge of the specific biases to be addressed, such as gender or racial biases, and the social groups associated with each instance. In this paper, we introduce a novel adversarial training strategy that operates independently of prior bias-type knowledge and protected attribute labels. Our approach proactively identifies biases during model training by utilizing auxiliary models, which are trained concurrently by predicting the performance of the main model without relying on task labels. Additionally, we implement these auxiliary models at various levels of the feature maps of the main model, enabling the detection of a broader and more nuanced range of bias features. Through experiments on racial and gender biases in sentiment and occupation classification tasks, our method effectively reduces social biases without the need for demographic annotations. Moreover, our approach not only matches but often surpasses the efficacy of methods that require detailed demographic insights, marking a significant advancement in bias mitigation techniques.</li>
</ul>

<h3>Title: PointNCBW: Towards Dataset Ownership Verification for Point Clouds via Negative Clean-label Backdoor Watermark</h3>
<ul>
<li><strong>Authors: </strong>Cheng Wei, Yang Wang, Kuofeng Gao, Shuo Shao, Yiming Li, Zhibo Wang, Zhan Qin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05500">https://arxiv.org/abs/2408.05500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05500">https://arxiv.org/pdf/2408.05500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05500]] PointNCBW: Towards Dataset Ownership Verification for Point Clouds via Negative Clean-label Backdoor Watermark(https://arxiv.org/abs/2408.05500)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, steal, watermark</a></li>
<li><strong>Abstract: </strong>Recently, point clouds have been widely used in computer vision, whereas their collection is time-consuming and expensive. As such, point cloud datasets are the valuable intellectual property of their owners and deserve protection. To detect and prevent unauthorized use of these datasets, especially for commercial or open-sourced ones that cannot be sold again or used commercially without permission, we intend to identify whether a suspicious third-party model is trained on our protected dataset under the black-box setting. We achieve this goal by designing a scalable clean-label backdoor-based dataset watermark for point clouds that ensures both effectiveness and stealthiness. Unlike existing clean-label watermark schemes, which are susceptible to the number of categories, our method could watermark samples from all classes instead of only from the target one. Accordingly, it can still preserve high effectiveness even on large-scale datasets with many classes. Specifically, we perturb selected point clouds with non-target categories in both shape-wise and point-wise manners before inserting trigger patterns without changing their labels. The features of perturbed samples are similar to those of benign samples from the target class. As such, models trained on the watermarked dataset will have a distinctive yet stealthy backdoor behavior, i.e., misclassifying samples from the target class whenever triggers appear, since the trained DNNs will treat the inserted trigger pattern as a signal to deny predicting the target label. We also design a hypothesis-test-guided dataset ownership verification based on the proposed watermark. Extensive experiments on benchmark datasets are conducted, verifying the effectiveness of our method and its resistance to potential removal methods.</li>
</ul>

<h3>Title: GEM: Context-Aware Gaze EstiMation with Visual Search Behavior Matching for Chest Radiograph</h3>
<ul>
<li><strong>Authors: </strong>Shaonan Liu, Wenting Chen, Jie Liu, Xiaoling Luo, Linlin Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05502">https://arxiv.org/abs/2408.05502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05502">https://arxiv.org/pdf/2408.05502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05502]] GEM: Context-Aware Gaze EstiMation with Visual Search Behavior Matching for Chest Radiograph(https://arxiv.org/abs/2408.05502)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Gaze estimation is pivotal in human scene comprehension tasks, particularly in medical diagnostic analysis. Eye-tracking technology facilitates the recording of physicians' ocular movements during image interpretation, thereby elucidating their visual attention patterns and information-processing strategies. In this paper, we initially define the context-aware gaze estimation problem in medical radiology report settings. To understand the attention allocation and cognitive behavior of radiologists during the medical image interpretation process, we propose a context-aware Gaze EstiMation (GEM) network that utilizes eye gaze data collected from radiologists to simulate their visual search behavior patterns throughout the image interpretation process. It consists of a context-awareness module, visual behavior graph construction, and visual behavior matching. Within the context-awareness module, we achieve intricate multimodal registration by establishing connections between medical reports and images. Subsequently, for a more accurate simulation of genuine visual search behavior patterns, we introduce a visual behavior graph structure, capturing such behavior through high-order relationships (edges) between gaze points (nodes). To maintain the authenticity of visual behavior, we devise a visual behavior-matching approach, adjusting the high-order relationships between them by matching the graph constructed from real and estimated gaze points. Extensive experiments on four publicly available datasets demonstrate the superiority of GEM over existing methods and its strong generalizability, which also provides a new direction for the effective utilization of diverse modalities in medical image interpretation and enhances the interpretability of models in the field of medical imaging. this https URL</li>
</ul>

<h3>Title: Disentangled Noisy Correspondence Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhuohang Dang, Minnan Luo, Jihong Wang, Chengyou Jia, Haochen Han, Herun Wan, Guang Dai, Xiaojun Chang, Jingdong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05503">https://arxiv.org/abs/2408.05503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05503">https://arxiv.org/pdf/2408.05503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05503]] Disentangled Noisy Correspondence Learning(https://arxiv.org/abs/2408.05503)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Cross-modal retrieval is crucial in understanding latent correspondences across modalities. However, existing methods implicitly assume well-matched training data, which is impractical as real-world data inevitably involves imperfect alignments, i.e., noisy correspondences. Although some works explore similarity-based strategies to address such noise, they suffer from sub-optimal similarity predictions influenced by modality-exclusive information (MEI), e.g., background noise in images and abstract definitions in texts. This issue arises as MEI is not shared across modalities, thus aligning it in training can markedly mislead similarity predictions. Moreover, although intuitive, directly applying previous cross-modal disentanglement methods suffers from limited noise tolerance and disentanglement efficacy. Inspired by the robustness of information bottlenecks against noise, we introduce DisNCL, a novel information-theoretic framework for feature Disentanglement in Noisy Correspondence Learning, to adaptively balance the extraction of MII and MEI with certifiable optimal cross-modal disentanglement efficacy. DisNCL then enhances similarity predictions in modality-invariant subspace, thereby greatly boosting similarity-based alleviation strategy for noisy correspondences. Furthermore, DisNCL introduces soft matching targets to model noisy many-to-many relationships inherent in multi-modal input for noise-robust and accurate cross-modal alignment. Extensive experiments confirm DisNCL's efficacy by 2% average recall improvement. Mutual information estimation and visualization results show that DisNCL learns meaningful MII/MEI subspaces, validating our theoretical analyses.</li>
</ul>

<h3>Title: Your Context Is Not an Array: Unveiling Random Access Limitations in Transformers</h3>
<ul>
<li><strong>Authors: </strong>MohammadReza Ebrahimi, Sunny Panchal, Roland Memisevic</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05506">https://arxiv.org/abs/2408.05506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05506">https://arxiv.org/pdf/2408.05506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05506]] Your Context Is Not an Array: Unveiling Random Access Limitations in Transformers(https://arxiv.org/abs/2408.05506)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Despite their recent successes, Transformer-based large language models show surprising failure modes. A well-known example of such failure modes is their inability to length-generalize: solving problem instances at inference time that are longer than those seen during training. In this work, we further explore the root cause of this failure by performing a detailed analysis of model behaviors on the simple parity task. Our analysis suggests that length generalization failures are intricately related to a model's inability to perform random memory accesses within its context window. We present supporting evidence for this hypothesis by demonstrating the effectiveness of methodologies that circumvent the need for indexing or that enable random token access indirectly, through content-based addressing. We further show where and how the failure to perform random memory access manifests through attention map visualizations.</li>
</ul>

<h3>Title: PointMT: Efficient Point Cloud Analysis with Hybrid MLP-Transformer Architecture</h3>
<ul>
<li><strong>Authors: </strong>Qiang Zheng, Chao Zhang, Jian Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05508">https://arxiv.org/abs/2408.05508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05508">https://arxiv.org/pdf/2408.05508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05508]] PointMT: Efficient Point Cloud Analysis with Hybrid MLP-Transformer Architecture(https://arxiv.org/abs/2408.05508)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years, point cloud analysis methods based on the Transformer architecture have made significant progress, particularly in the context of multimedia applications such as 3D modeling, virtual reality, and autonomous systems. However, the high computational resource demands of the Transformer architecture hinder its scalability, real-time processing capabilities, and deployment on mobile devices and other platforms with limited computational resources. This limitation remains a significant obstacle to its practical application in scenarios requiring on-device intelligence and multimedia processing. To address this challenge, we propose an efficient point cloud analysis architecture, \textbf{Point} \textbf{M}LP-\textbf{T}ransformer (PointMT). This study tackles the quadratic complexity of the self-attention mechanism by introducing a linear complexity local attention mechanism for effective feature aggregation. Additionally, to counter the Transformer's focus on token differences while neglecting channel differences, we introduce a parameter-free channel temperature adaptation mechanism that adaptively adjusts the attention weight distribution in each channel, enhancing the precision of feature aggregation. To improve the Transformer's slow convergence speed due to the limited scale of point cloud datasets, we propose an MLP-Transformer hybrid module, which significantly enhances the model's convergence speed. Furthermore, to boost the feature representation capability of point tokens, we refine the classification head, enabling point tokens to directly participate in prediction. Experimental results on multiple evaluation benchmarks demonstrate that PointMT achieves performance comparable to state-of-the-art methods while maintaining an optimal balance between performance and accuracy.</li>
</ul>

<h3>Title: SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Yuze Zhao, Jintao Huang, Jinghan Hu, Daoze Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05517">https://arxiv.org/abs/2408.05517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05517">https://arxiv.org/pdf/2408.05517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05517]] SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning(https://arxiv.org/abs/2408.05517)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recent development in Large Language Models (LLMs) and Multi-modal Large Language Models (MLLMs) have leverage Attention-based Transformer architectures and achieved superior performance and generalization capabilities. They have since covered extensive areas of traditional learning tasks. For instance, text-based tasks such as text-classification and sequence-labeling, as well as multi-modal tasks like Visual Question Answering (VQA) and Optical Character Recognition (OCR), which were previously addressed using different models, can now be tackled based on one foundation model. Consequently, the training and lightweight fine-tuning of LLMs and MLLMs, especially those based on Transformer architecture, has become particularly important. In recognition of these overwhelming needs, we develop SWIFT, a customizable one-stop infrastructure for large models. With support of over $300+$ LLMs and $50+$ MLLMs, SWIFT stands as the open-source framework that provide the \textit{most comprehensive support} for fine-tuning large models. In particular, it is the first training framework that provides systematic support for MLLMs. In addition to the core functionalities of fine-tuning, SWIFT also integrates post-training processes such as inference, evaluation, and model quantization, to facilitate fast adoptions of large models in various application scenarios. With a systematic integration of various training techniques, SWIFT offers helpful utilities such as benchmark comparisons among different training techniques for large models. For fine-tuning models specialized in agent framework, we show that notable improvements on the ToolBench leader-board can be achieved by training with customized dataset on SWIFT, with an increase of 5.2\%-21.8\% in the Act.EM metric over various baseline models, a reduction in hallucination by 1.6\%-14.1\%, and an average performance improvement of 8\%-17\%.</li>
</ul>

<h3>Title: Long working distance portable smartphone microscopy for metallic mesh defect detection</h3>
<ul>
<li><strong>Authors: </strong>Zhengang Lu, Hongsheng Qin, Jing Li, Ming Sun, Jiubin Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05518">https://arxiv.org/abs/2408.05518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05518">https://arxiv.org/pdf/2408.05518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05518]] Long working distance portable smartphone microscopy for metallic mesh defect detection(https://arxiv.org/abs/2408.05518)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Metallic mesh is a transparent electromagnetic shielding film with a fine metal line structure. However, it can develop defects that affect the optoelectronic performance whether in the production preparation or in actual use. The development of in-situ non-destructive testing (NDT) devices for metallic mesh requires long working distances, reflective optical path design, and miniaturization. To address the limitations of existing smartphone microscopes, which feature short working distances and inadequate transmission imaging for industrial in-situ inspection, we propose a novel long-working distance reflective smartphone microscopy system (LD-RSM). LD-RSM builds a 4f optical imaging system with external optical components and a smartphone, utilizing a beam splitter to achieve reflective imaging with the illumination system and imaging system on the same side of the sample. It achieves an optical resolution of 4.92$\mu$m and a working distance of up to 22.23 mm. Additionally, we introduce a dual prior weighted Robust Principal Component Analysis (DW-RPCA) for defect detection. This approach leverages spectral filter fusion and Hough transform to model different defect types, enhancing the accuracy and efficiency of defect identification. Coupled with an optimized threshold segmentation algorithm, DW-RPCA method achieves a pixel-level accuracy of 84.8%. Our work showcases strong potential for growth in the field of in-situ on-line inspection of industrial products.</li>
</ul>

<h3>Title: Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs</h3>
<ul>
<li><strong>Authors: </strong>Kexin Ma, Ruochun Jin, Xi Wang, Huan Chen, Jing Ren, Yuhua Tang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05524">https://arxiv.org/abs/2408.05524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05524">https://arxiv.org/pdf/2408.05524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05524]] Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs(https://arxiv.org/abs/2408.05524)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Large Language Models (RALMs) have made significant strides in enhancing the accuracy of generated responses.However, existing research often overlooks the data quality issues within retrieval results, often caused by inaccurate existing vector-distance-based retrieval methods.We propose to boost the precision of RALMs' answers from a data quality perspective through the Context-Driven Index Trimming (CDIT) framework, where Context Matching Dependencies (CMDs) are employed as logical data quality rules to capture and regulate the consistency between retrieved contexts.Based on the semantic comprehension capabilities of Large Language Models (LLMs), CDIT can effectively identify and discard retrieval results that are inconsistent with the query context and further modify indexes in the database, thereby improving answer quality.Experiments demonstrate on challenging question-answering tasks.Also, the flexibility of CDIT is verified through its compatibility with various language models and indexing methods, which offers a promising approach to bolster RALMs' data quality and retrieval precision jointly.</li>
</ul>

<h3>Title: Convergence Analysis for Deep Sparse Coding via Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Jianfei Li, Han Feng, Ding-Xuan Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, cs.IT, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05540">https://arxiv.org/abs/2408.05540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05540">https://arxiv.org/pdf/2408.05540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05540]] Convergence Analysis for Deep Sparse Coding via Convolutional Neural Networks(https://arxiv.org/abs/2408.05540)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>In this work, we explore the intersection of sparse coding theory and deep learning to enhance our understanding of feature extraction capabilities in advanced neural network architectures. We begin by introducing a novel class of Deep Sparse Coding (DSC) models and establish a thorough theoretical analysis of their uniqueness and stability properties. By applying iterative algorithms to these DSC models, we derive convergence rates for convolutional neural networks (CNNs) in their ability to extract sparse features. This provides a strong theoretical foundation for the use of CNNs in sparse feature learning tasks. We additionally extend this convergence analysis to more general neural network architectures, including those with diverse activation functions, as well as self-attention and transformer-based models. This broadens the applicability of our findings to a wide range of deep learning methods for deep sparse feature extraction. Inspired by the strong connection between sparse coding and CNNs, we also explore training strategies to encourage neural networks to learn more sparse features. Through numerical experiments, we demonstrate the effectiveness of these approaches, providing valuable insights for the design of efficient and interpretable deep learning models.</li>
</ul>

<h3>Title: P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for Optimizing LLM Training</h3>
<ul>
<li><strong>Authors: </strong>Yingxuan Yang, Huayi Wang, Muning Wen, Weinan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05541">https://arxiv.org/abs/2408.05541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05541">https://arxiv.org/pdf/2408.05541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05541]] P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for Optimizing LLM Training(https://arxiv.org/abs/2408.05541)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the rapidly evolving field of Large Language Models (LLMs), selecting high-quality data for fine-tuning is essential. This paper focuses on task-specific data pruning and selection to enhance fine-tuning. We introduce an innovative framework, termed P3, which improves LLM performance through a dynamic, adaptive training strategy. Specifically, P3 comprises the following components: (1) Policy-driven Difficulty Measurement: we begin by measuring the difficulty of data based on the model's real-time performance, transitioning from static, predefined metrics to more dynamic and adaptable ones. (2) Pace-adaptive Selection: we employ self-paced learning (SPL) to gradually select increasingly challenging data, thereby progressively enhancing the model's performance. (3) Diversity Promotion: we integrate Determinantal Point Process (DPP) into the selection process to promote the diversity within and between samples, enriching the learning process. We have validated our method on two well-known LLM datasets, APPS and MATH, designed for logical reasoning scenarios. The results show that our P3 framework significantly improves training outcomes compared to traditional methods. By fundamentally refining data selection and utilization strategies, P3 not only advances theoretical understanding of dynamic training approaches but also provides a versatile framework that can revolutionize model training in natural language processing.</li>
</ul>

<h3>Title: PixelFade: Privacy-preserving Person Re-identification with Noise-guided Progressive Replacement</h3>
<ul>
<li><strong>Authors: </strong>Delong Zhang, Yi-Xing Peng, Xiao-Ming Wu, Ancong Wu, Wei-Shi Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05543">https://arxiv.org/abs/2408.05543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05543">https://arxiv.org/pdf/2408.05543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05543]] PixelFade: Privacy-preserving Person Re-identification with Noise-guided Progressive Replacement(https://arxiv.org/abs/2408.05543)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Online person re-identification services face privacy breaches from potential data leakage and recovery attacks, exposing cloud-stored images to malicious attackers and triggering public concern. The privacy protection of pedestrian images is crucial. Previous privacy-preserving person re-identification methods are unable to resist recovery attacks and compromise accuracy. In this paper, we propose an iterative method (PixelFade) to optimize pedestrian images into noise-like images to resist recovery attacks. We first give an in-depth study of protected images from previous privacy methods, which reveal that the chaos of protected images can disrupt the learning of recovery models. Accordingly, Specifically, we propose Noise-guided Objective Function with the feature constraints of a specific authorization model, optimizing pedestrian images to normal-distributed noise images while preserving their original identity information as per the authorization model. To solve the above non-convex optimization problem, we propose a heuristic optimization algorithm that alternately performs the Constraint Operation and the Partial Replacement Operation. This strategy not only safeguards that original pixels are replaced with noises to protect privacy, but also guides the images towards an improved optimization direction to effectively preserve discriminative features. Extensive experiments demonstrate that our PixelFade outperforms previous methods in resisting recovery attacks and Re-ID performance. The code is available at this https URL.</li>
</ul>

<h3>Title: Multi-layer Sequence Labeling-based Joint Biomedical Event Extraction</h3>
<ul>
<li><strong>Authors: </strong>Gongchi Chen, Pengchao Wu, Jinghang Gu, Longhua Qian, Guodong Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05545">https://arxiv.org/abs/2408.05545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05545">https://arxiv.org/pdf/2408.05545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05545]] Multi-layer Sequence Labeling-based Joint Biomedical Event Extraction(https://arxiv.org/abs/2408.05545)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In recent years, biomedical event extraction has been dominated by complicated pipeline and joint methods, which need to be simplified. In addition, existing work has not effectively utilized trigger word information explicitly. Hence, we propose MLSL, a method based on multi-layer sequence labeling for joint biomedical event extraction. MLSL does not introduce prior knowledge and complex structures. Moreover, it explicitly incorporates the information of candidate trigger words into the sequence labeling to learn the interaction relationships between trigger words and argument roles. Based on this, MLSL can learn well with just a simple workflow. Extensive experimentation demonstrates the superiority of MLSL in terms of extraction performance compared to other state-of-the-art methods.</li>
</ul>

<h3>Title: Large Language Model-based Role-Playing for Personalized Medical Jargon Extraction</h3>
<ul>
<li><strong>Authors: </strong>Jung Hoon Lim, Sunjae Kwon, Zonghai Yao, John P.Lalor, Hong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05555">https://arxiv.org/abs/2408.05555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05555">https://arxiv.org/pdf/2408.05555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05555]] Large Language Model-based Role-Playing for Personalized Medical Jargon Extraction(https://arxiv.org/abs/2408.05555)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>Previous studies reveal that Electronic Health Records (EHR), which have been widely adopted in the U.S. to allow patients to access their personal medical information, do not have high readability to patients due to the prevalence of medical jargon. Tailoring medical notes to individual comprehension by identifying jargon that is difficult for each person will enhance the utility of generative models. We present the first quantitative analysis to measure the impact of role-playing in LLM in medical term extraction. By comparing the results of Mechanical Turk workers over 20 sentences, our study demonstrates that LLM role-playing improves F1 scores in 95% of cases across 14 different socio-demographic backgrounds. Furthermore, applying role-playing with in-context learning outperformed the previous state-of-the-art models. Our research showed that ChatGPT can improve traditional medical term extraction systems by utilizing role-play to deliver personalized patient education, a potential that previous models had not achieved.</li>
</ul>

<h3>Title: Evolutionary Neural Architecture Search for 3D Point Cloud Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yisheng Yang, Guodong Du, Chean Khim Toa, Ho-Kin Tang, Sim Kuan Goh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05556">https://arxiv.org/abs/2408.05556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05556">https://arxiv.org/pdf/2408.05556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05556]] Evolutionary Neural Architecture Search for 3D Point Cloud Analysis(https://arxiv.org/abs/2408.05556)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Neural architecture search (NAS) automates neural network design by using optimization algorithms to navigate architecture spaces, reducing the burden of manual architecture design. While NAS has achieved success, applying it to emerging domains, such as analyzing unstructured 3D point clouds, remains underexplored due to the data lying in non-Euclidean spaces, unlike images. This paper presents Success-History-based Self-adaptive Differential Evolution with a Joint Point Interaction Dimension Search (SHSADE-PIDS), an evolutionary NAS framework that encodes discrete deep neural network architectures to continuous spaces and performs searches in the continuous spaces for efficient point cloud neural architectures. Comprehensive experiments on challenging 3D segmentation and classification benchmarks demonstrate SHSADE-PIDS's capabilities. It discovered highly efficient architectures with higher accuracy, significantly advancing prior NAS techniques. For segmentation on SemanticKITTI, SHSADE-PIDS attained 64.51% mean IoU using only 0.55M parameters and 4.5GMACs, reducing overhead by over 22-26X versus other top methods. For ModelNet40 classification, it achieved 93.4% accuracy with just 1.31M parameters, surpassing larger models. SHSADE-PIDS provided valuable insights into bridging evolutionary algorithms with neural architecture optimization, particularly for emerging frontiers like point cloud learning.</li>
</ul>

<h3>Title: Object Re-identification via Spatial-temporal Fusion Networks and Causal Identity Matching</h3>
<ul>
<li><strong>Authors: </strong>Hye-Geun Kim, Yong-Hyuk Moon, Yeong-Jun Cho</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05558">https://arxiv.org/abs/2408.05558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05558">https://arxiv.org/pdf/2408.05558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05558]] Object Re-identification via Spatial-temporal Fusion Networks and Causal Identity Matching(https://arxiv.org/abs/2408.05558)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Object re-identification (ReID) in large camera networks has many challenges. First, the similar appearances of objects degrade ReID performances. This challenge cannot be addressed by existing appearance-based ReID methods. Second, most ReID studies are performed in laboratory settings and do not consider ReID problems in real-world scenarios. To overcome these challenges, we introduce a novel ReID framework that leverages a spatial-temporal fusion network and causal identity matching (CIM). The framework estimates camera network topology using the proposed adaptive Parzen window and combines appearance features with spatial-temporal cue within the Fusion Network. It achieved outstanding performance across several datasets, including VeRi776, Vehicle-3I, and Market-1501, achieving up to 99.70% rank-1 accuracy and 95.5% mAP. Furthermore, the proposed CIM approach, which dynamically assigns gallery sets based on the camera network topology, further improved ReID accuracy and robustness in real-world settings, evidenced by a 94.95% mAP and 95.19% F1 score on the Vehicle-3I dataset. The experimental results support the effectiveness of incorporating spatial-temporal information and CIM for real-world ReID scenarios regardless of the data domain (e.g., vehicle, person).</li>
</ul>

<h3>Title: Incremental Gauss-Newton Descent for Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Mikalai Korbit, Mario Zanon</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05560">https://arxiv.org/abs/2408.05560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05560">https://arxiv.org/pdf/2408.05560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05560]] Incremental Gauss-Newton Descent for Machine Learning(https://arxiv.org/abs/2408.05560)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Stochastic Gradient Descent (SGD) is a popular technique used to solve problems arising in machine learning. While very effective, SGD also has some weaknesses and various modifications of the basic algorithm have been proposed in order to at least partially tackle them, mostly yielding accelerated versions of SGD. Filling a gap in the literature, we present a modification of the SGD algorithm exploiting approximate second-order information based on the Gauss-Newton approach. The new method, which we call Incremental Gauss-Newton Descent (IGND), has essentially the same computational burden as standard SGD, appears to converge faster on certain classes of problems, and can also be accelerated. The key intuition making it possible to implement IGND efficiently is that, in the incremental case, approximate second-order information can be condensed into a scalar value that acts as a scaling constant of the update. We derive IGND starting from the theory supporting Gauss-Newton methods in a general setting and then explain how IGND can also be interpreted as a well-scaled version of SGD, which makes tuning the algorithm simpler, and provides increased robustness. Finally, we show how IGND can be used in practice by solving supervised learning tasks as well as reinforcement learning problems. The simulations show that IGND can significantly outperform SGD while performing at least as well as SGD in the worst case.</li>
</ul>

<h3>Title: Document-Level Event Extraction with Definition-Driven ICL</h3>
<ul>
<li><strong>Authors: </strong>Zhuoyuan Liu, Yilin Luo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05566">https://arxiv.org/abs/2408.05566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05566">https://arxiv.org/pdf/2408.05566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05566]] Document-Level Event Extraction with Definition-Driven ICL(https://arxiv.org/abs/2408.05566)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>In the field of Natural Language Processing (NLP), Large Language Models (LLMs) have shown great potential in document-level event extraction tasks, but existing methods face challenges in the design of prompts. To address this issue, we propose an optimization strategy called "Definition-driven Document-level Event Extraction (DDEE)." By adjusting the length of the prompt and enhancing the clarity of heuristics, we have significantly improved the event extraction performance of LLMs. We used data balancing techniques to solve the long-tail effect problem, enhancing the model's generalization ability for event types. At the same time, we refined the prompt to ensure it is both concise and comprehensive, adapting to the sensitivity of LLMs to the style of prompts. In addition, the introduction of structured heuristic methods and strict limiting conditions has improved the precision of event and argument role extraction. These strategies not only solve the prompt engineering problems of LLMs in document-level event extraction but also promote the development of event extraction technology, providing new research perspectives for other tasks in the NLP field.</li>
</ul>

<h3>Title: Camera Perspective Transformation to Bird's Eye View via Spatial Transformer Model for Road Intersection Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Rukesh Prajapati, Amr S. El-Wakeel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05577">https://arxiv.org/abs/2408.05577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05577">https://arxiv.org/pdf/2408.05577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05577]] Camera Perspective Transformation to Bird's Eye View via Spatial Transformer Model for Road Intersection Monitoring(https://arxiv.org/abs/2408.05577)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Road intersection monitoring and control research often utilize bird's eye view (BEV) simulators. In real traffic settings, achieving a BEV akin to that in a simulator necessitates the deployment of drones or specific sensor mounting, which is neither feasible nor practical. Consequently, traffic intersection management remains confined to simulation environments given these constraints. In this paper, we address the gap between simulated environments and real-world implementation by introducing a novel deep-learning model that converts a single camera's perspective of a road intersection into a BEV. We created a simulation environment that closely resembles a real-world traffic junction. The proposed model transforms the vehicles into BEV images, facilitating road intersection monitoring and control model processing. Inspired by image transformation techniques, we propose a Spatial-Transformer Double Decoder-UNet (SDD-UNet) model that aims to eliminate the transformed image distortions. In addition, the model accurately estimates the vehicle's positions and enables the direct application of simulation-trained models in real-world contexts. SDD-UNet model achieves an average dice similarity coefficient (DSC) above 95% which is 40% better than the original UNet model. The mean absolute error (MAE) is 0.102 and the centroid of the predicted mask is 0.14 meters displaced, on average, indicating high accuracy.</li>
</ul>

<h3>Title: Cryptographically Secure Pseudo-Random Number Generation (CS-PRNG) Design using Robust Chaotic Tent Map (RCTM)</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Irfan, Muhammad Asif Khan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05580">https://arxiv.org/abs/2408.05580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05580">https://arxiv.org/pdf/2408.05580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05580]] Cryptographically Secure Pseudo-Random Number Generation (CS-PRNG) Design using Robust Chaotic Tent Map (RCTM)(https://arxiv.org/abs/2408.05580)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust</a></li>
<li><strong>Abstract: </strong>Chaos, a nonlinear dynamical system, favors cryptography due to their inherent sensitive dependence on the initial condition, mixing, and ergodicity property. In recent years, the nonlinear behavior of chaotic maps has been utilized as a random source to generate pseudo-random number generation for cryptographic services. For chaotic maps having Robust chaos, dense, chaotic orbits exist for the range of parameter space the occurrence of chaotic attractors in some neighborhoods of parameter space and the absence of periodic windows. Thus, the robust chaotic map shows assertive chaotic behavior for larger parameters space with a positive Lyapunov exponent. This paper presents a novel method to generate cryptographically secure pseudo-random numbers (CSPRNG) using a robust chaotic tent map (RCTM). We proposed a new set of equations featuring modulo and scaling operators that achieve vast parameter space by keeping chaotic orbit globally stable and robust. The dynamic behavior of the RCTM is studied first by plotting the bifurcation diagram that shows chaotic behavior for different parameters, which the positive Lyapunov exponent verifies. We iterated the RCTM to generate pseudo-random bits using a simple thresholding method. Various statistical tests are performed that ascertain the randomness of generated secure pseudo-random bits. It includes NIST 800-22 test suite, ENT statistical test suite, TestU01 test suite, key space analysis, key sensitivity analysis, correlation analysis, histogram analysis, and differential analysis. The proposed scheme has achieved larger key space as compared with existing methods. The results show that the proposed PRBG algorithm can generate CSPRNG.</li>
</ul>

<h3>Title: Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Jacob K Christopher, Brian R Bartoldson, Bhavya Kailkhura, Ferdinando Fioretto</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05636">https://arxiv.org/abs/2408.05636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05636">https://arxiv.org/pdf/2408.05636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05636]] Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion(https://arxiv.org/abs/2408.05636)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding has emerged as a widely adopted method to accelerate large language model inference without sacrificing the quality of the model outputs. While this technique has facilitated notable speed improvements by enabling parallel sequence verification, its efficiency remains inherently limited by the reliance on incremental token generation in existing draft models. To overcome this limitation, this paper proposes an adaptation of speculative decoding which uses discrete diffusion models to generate draft sequences. This allows parallelization of both the drafting and verification steps, providing significant speed-ups to the inference process. Our proposed approach, \textit{Speculative Diffusion Decoding (SpecDiff)}, is validated on standard language generation benchmarks and empirically demonstrated to provide a \textbf{up to 8.7x speed-up over standard generation processes and up to 2.5x speed-up over existing speculative decoding approaches.}</li>
</ul>

<h3>Title: Federated Smoothing Proximal Gradient for Quantile Regression with Non-Convex Penalties</h3>
<ul>
<li><strong>Authors: </strong>Reza Mirzaeifard, Diyako Ghaderyan, Stefan Werner</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05640">https://arxiv.org/abs/2408.05640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05640">https://arxiv.org/pdf/2408.05640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05640]] Federated Smoothing Proximal Gradient for Quantile Regression with Non-Convex Penalties(https://arxiv.org/abs/2408.05640)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Distributed sensors in the internet-of-things (IoT) generate vast amounts of sparse data. Analyzing this high-dimensional data and identifying relevant predictors pose substantial challenges, especially when data is preferred to remain on the device where it was collected for reasons such as data integrity, communication bandwidth, and privacy. This paper introduces a federated quantile regression algorithm to address these challenges. Quantile regression provides a more comprehensive view of the relationship between variables than mean regression models. However, traditional approaches face difficulties when dealing with nonconvex sparse penalties and the inherent non-smoothness of the loss function. For this purpose, we propose a federated smoothing proximal gradient (FSPG) algorithm that integrates a smoothing mechanism with the proximal gradient framework, thereby enhancing both precision and computational speed. This integration adeptly handles optimization over a network of devices, each holding local data samples, making it particularly effective in federated learning scenarios. The FSPG algorithm ensures steady progress and reliable convergence in each iteration by maintaining or reducing the value of the objective function. By leveraging nonconvex penalties, such as the minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD), the proposed method can identify and preserve key predictors within sparse models. Comprehensive simulations validate the robust theoretical foundations of the proposed algorithm and demonstrate improved estimation precision and reliable convergence.</li>
</ul>

<h3>Title: Eigen Attention: Attention in Low-Rank Space for KV Cache Compression</h3>
<ul>
<li><strong>Authors: </strong>Utkarsh Saxena, Gobinda Saha, Sakshi Choudhary, Kaushik Roy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05646">https://arxiv.org/abs/2408.05646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05646">https://arxiv.org/pdf/2408.05646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05646]] Eigen Attention: Attention in Low-Rank Space for KV Cache Compression(https://arxiv.org/abs/2408.05646)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) represent a groundbreaking advancement in the domain of natural language processing due to their impressive reasoning abilities. Recently, there has been considerable interest in increasing the context lengths for these models to enhance their applicability to complex tasks. However, at long context lengths and large batch sizes, the key-value (KV) cache, which stores the attention keys and values, emerges as the new bottleneck in memory usage during inference. To address this, we propose Eigen Attention, which performs the attention operation in a low-rank space, thereby reducing the KV cache memory overhead. Our proposed approach is orthogonal to existing KV cache compression techniques and can be used synergistically with them. Through extensive experiments over OPT, MPT, and Llama model families, we demonstrate that Eigen Attention results in up to 40% reduction in KV cache sizes and up to 60% reduction in attention operation latency with minimal drop in performance.</li>
</ul>

<h3>Title: Advancing Pavement Distress Detection in Developing Countries: A Novel Deep Learning Approach with Locally-Collected Datasets</h3>
<ul>
<li><strong>Authors: </strong>Blessing Agyei Kyem, Eugene Kofi Okrah Denteh, Joshua Kofi Asamoah, Kenneth Adomako Tutu, Armstrong Aboah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05649">https://arxiv.org/abs/2408.05649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05649">https://arxiv.org/pdf/2408.05649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05649]] Advancing Pavement Distress Detection in Developing Countries: A Novel Deep Learning Approach with Locally-Collected Datasets(https://arxiv.org/abs/2408.05649)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Road infrastructure maintenance in developing countries faces unique challenges due to resource constraints and diverse environmental factors. This study addresses the critical need for efficient, accurate, and locally-relevant pavement distress detection methods in these regions. We present a novel deep learning approach combining YOLO (You Only Look Once) object detection models with a Convolutional Block Attention Module (CBAM) to simultaneously detect and classify multiple pavement distress types. The model demonstrates robust performance in detecting and classifying potholes, longitudinal cracks, alligator cracks, and raveling, with confidence scores ranging from 0.46 to 0.93. While some misclassifications occur in complex scenarios, these provide insights into unique challenges of pavement assessment in developing countries. Additionally, we developed a web-based application for real-time distress detection from images and videos. This research advances automated pavement distress detection and provides a tailored solution for developing countries, potentially improving road safety, optimizing maintenance strategies, and contributing to sustainable transportation infrastructure development.</li>
</ul>

<h3>Title: Performance Evaluation of YOLOv8 Model Configurations, for Instance Segmentation of Strawberry Fruit Development Stages in an Open Field Environment</h3>
<ul>
<li><strong>Authors: </strong>Abdul-Razak Alhassan Gamani, Ibrahim Arhin, Adrena Kyeremateng Asamoah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05661">https://arxiv.org/abs/2408.05661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05661">https://arxiv.org/pdf/2408.05661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05661]] Performance Evaluation of YOLOv8 Model Configurations, for Instance Segmentation of Strawberry Fruit Development Stages in an Open Field Environment(https://arxiv.org/abs/2408.05661)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate identification of strawberries during their maturing stages is crucial for optimizing yield management, and pest control, and making informed decisions related to harvest and post-harvest logistics. This study evaluates the performance of YOLOv8 model configurations for instance segmentation of strawberries into ripe and unripe stages in an open field environment. The YOLOv8n model demonstrated superior segmentation accuracy with a mean Average Precision (mAP) of 80.9\%, outperforming other YOLOv8 configurations. In terms of inference speed, YOLOv8n processed images at 12.9 milliseconds, while YOLOv8s, the least-performing model, processed at 22.2 milliseconds. Over 86 test images with 348 ground truth labels, YOLOv8n detected 235 ripe fruit classes and 51 unripe fruit classes out of 251 ground truth ripe fruits and 97 unripe ground truth labels, respectively. In comparison, YOLOv8s detected 204 ripe fruits and 37 unripe fruits. Overall, YOLOv8n achieved the fastest inference speed of 24.2 milliseconds, outperforming YOLOv8s, YOLOv8m, YOLOv8l, and YOLOv8x, which processed images at 33.0 milliseconds, 44.3 milliseconds, 53.6 milliseconds, and 62.5 milliseconds, respectively. These results underscore the potential of advanced object segmentation algorithms to address complex visual recognition tasks in open-field agriculture effectively to address complex visual recognition tasks in open-field agriculture effectively.</li>
</ul>

<h3>Title: Utilizing Large Language Models to Optimize the Detection and Explainability of Phishing Websites</h3>
<ul>
<li><strong>Authors: </strong>Sayak Saha Roy, Shirin Nilizadeh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.HC, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05667">https://arxiv.org/abs/2408.05667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05667">https://arxiv.org/pdf/2408.05667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05667]] Utilizing Large Language Models to Optimize the Detection and Explainability of Phishing Websites(https://arxiv.org/abs/2408.05667)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, explainability, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce PhishLang, an open-source, lightweight Large Language Model (LLM) specifically designed for phishing website detection through contextual analysis of the website. Unlike traditional heuristic or machine learning models that rely on static features and struggle to adapt to new threats and deep learning models that are computationally intensive, our model utilizes the advanced language processing capabilities of LLMs to learn granular features that are characteristic of phishing attacks. Furthermore, PhishLang operates with minimal data preprocessing and offers performance comparable to leading deep learning tools, while being significantly faster and less resource-intensive. Over a 3.5-month testing period, PhishLang successfully identified approximately 26K phishing URLs, many of which were undetected by popular antiphishing blocklists, thus demonstrating its potential to aid current detection measures. We also evaluate PhishLang against several realistic adversarial attacks and develop six patches that make it very robust against such threats. Furthermore, we integrate PhishLang with GPT-3.5 Turbo to create \textit{explainable blocklisting} - warnings that provide users with contextual information about different features that led to a website being marked as phishing. Finally, we have open-sourced the PhishLang framework and developed a Chromium-based browser extension and URL scanner website, which implement explainable warnings for end-users.</li>
</ul>

<h3>Title: StealthDiffusion: Towards Evading Diffusion Forensic Detection through Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Ziyin Zhou, Ke Sun, Zhongxi Chen, Huafeng Kuang, Xiaoshuai Sun, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05669">https://arxiv.org/abs/2408.05669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05669">https://arxiv.org/pdf/2408.05669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05669]] StealthDiffusion: Towards Evading Diffusion Forensic Detection through Diffusion Model(https://arxiv.org/abs/2408.05669)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The rapid progress in generative models has given rise to the critical task of AI-Generated Content Stealth (AIGC-S), which aims to create AI-generated images that can evade both forensic detectors and human inspection. This task is crucial for understanding the vulnerabilities of existing detection methods and developing more robust techniques. However, current adversarial attacks often introduce visible noise, have poor transferability, and fail to address spectral differences between AI-generated and genuine images. To address this, we propose StealthDiffusion, a framework based on stable diffusion that modifies AI-generated images into high-quality, imperceptible adversarial examples capable of evading state-of-the-art forensic detectors. StealthDiffusion comprises two main components: Latent Adversarial Optimization, which generates adversarial perturbations in the latent space of stable diffusion, and Control-VAE, a module that reduces spectral differences between the generated adversarial images and genuine images without affecting the original diffusion model's generation process. Extensive experiments show that StealthDiffusion is effective in both white-box and black-box settings, transforming AI-generated images into high-quality adversarial forgeries with frequency spectra similar to genuine images. These forgeries are classified as genuine by advanced forensic classifiers and are difficult for humans to distinguish.</li>
</ul>

<h3>Title: Swarm-Net: Firmware Attestation in IoT Swarms using Graph Neural Networks and Volatile Memory</h3>
<ul>
<li><strong>Authors: </strong>Varun Kohli, Bhavya Kohli, Muhammad Naveed Aman, Biplab Sikdar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05680">https://arxiv.org/abs/2408.05680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05680">https://arxiv.org/pdf/2408.05680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05680]] Swarm-Net: Firmware Attestation in IoT Swarms using Graph Neural Networks and Volatile Memory(https://arxiv.org/abs/2408.05680)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust</a></li>
<li><strong>Abstract: </strong>The Internet of Things (IoT) is a network of billions of interconnected, primarily low-end embedded devices. Despite large-scale deployment, studies have highlighted critical security concerns in IoT networks, many of which stem from firmware-related issues. Furthermore, IoT swarms have become more prevalent in industries, smart homes, and agricultural applications, among others. Malicious activity on one node in a swarm can propagate to larger network sections. Although several Remote Attestation (RA) techniques have been proposed, they are limited by their latency, availability, complexity, hardware assumptions, and uncertain access to firmware copies under Intellectual Property (IP) rights. We present Swarm-Net, a novel swarm attestation technique that exploits the inherent, interconnected, graph-like structure of IoT networks along with the runtime information stored in the Static Random Access Memory (SRAM) using Graph Neural Networks (GNN) to detect malicious firmware and its downstream effects. We also present the first datasets on SRAM-based swarm attestation encompassing different types of firmware and edge relationships. In addition, a secure swarm attestation protocol is presented. Swarm-Net is not only computationally lightweight but also does not require a copy of the firmware. It achieves a 99.96% attestation rate on authentic firmware, 100% detection rate on anomalous firmware, and 99% detection rate on propagated anomalies, at a communication overhead and inference latency of ~1 second and ~10^{-5} seconds (on a laptop CPU), respectively. In addition to the collected datasets, Swarm-Net's effectiveness is evaluated on simulated trace replay, random trace perturbation, and dropped attestation responses, showing robustness against such threats. Lastly, we compare Swarm-Net with past works and present a security analysis.</li>
</ul>

<h3>Title: SRTFD: Scalable Real-Time Fault Diagnosis through Online Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Dandan Zhao, Karthick Sharma, Hongpeng Yin, Yuxin Qi, Shuhao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05681">https://arxiv.org/abs/2408.05681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05681">https://arxiv.org/pdf/2408.05681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05681]] SRTFD: Scalable Real-Time Fault Diagnosis through Online Continual Learning(https://arxiv.org/abs/2408.05681)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fault diagnosis (FD) is essential for maintaining operational safety and minimizing economic losses by detecting system abnormalities. Recently, deep learning (DL)-driven FD methods have gained prominence, offering significant improvements in precision and adaptability through the utilization of extensive datasets and advanced DL models. Modern industrial environments, however, demand FD methods that can handle new fault types, dynamic conditions, large-scale data, and provide real-time responses with minimal prior information. Although online continual learning (OCL) demonstrates potential in addressing these requirements by enabling DL models to continuously learn from streaming data, it faces challenges such as data redundancy, imbalance, and limited labeled data. To overcome these limitations, we propose SRTFD, a scalable real-time fault diagnosis framework that enhances OCL with three critical methods: Retrospect Coreset Selection (RCS), which selects the most relevant data to reduce redundant training and improve efficiency; Global Balance Technique (GBT), which ensures balanced coreset selection and robust model performance; and Confidence and Uncertainty-driven Pseudo-label Learning (CUPL), which updates the model using unlabeled data for continuous adaptation. Extensive experiments on a real-world dataset and two public simulated datasets demonstrate SRTFD's effectiveness and potential for providing advanced, scalable, and precise fault diagnosis in modern industrial systems.</li>
</ul>

<h3>Title: The Bandit Whisperer: Communication Learning for Restless Bandits</h3>
<ul>
<li><strong>Authors: </strong>Yunfan Zhao, Tonghan Wang, Dheeraj Nagaraj, Aparna Taneja, Milind Tambe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05686">https://arxiv.org/abs/2408.05686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05686">https://arxiv.org/pdf/2408.05686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05686]] The Bandit Whisperer: Communication Learning for Restless Bandits(https://arxiv.org/abs/2408.05686)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Applying Reinforcement Learning (RL) to Restless Multi-Arm Bandits (RMABs) offers a promising avenue for addressing allocation problems with resource constraints and temporal dynamics. However, classic RMAB models largely overlook the challenges of (systematic) data errors - a common occurrence in real-world scenarios due to factors like varying data collection protocols and intentional noise for differential privacy. We demonstrate that conventional RL algorithms used to train RMABs can struggle to perform well in such settings. To solve this problem, we propose the first communication learning approach in RMABs, where we study which arms, when involved in communication, are most effective in mitigating the influence of such systematic data errors. In our setup, the arms receive Q-function parameters from similar arms as messages to guide behavioral policies, steering Q-function updates. We learn communication strategies by considering the joint utility of messages across all pairs of arms and using a Q-network architecture that decomposes the joint utility. Both theoretical and empirical evidence validate the effectiveness of our method in significantly improving RMAB performance across diverse problems.</li>
</ul>

<h3>Title: A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Koushik Biswas, Ridal Pal, Shaswat Patel, Debesh Jha, Meghana Karri, Amit Reza, Gorkem Durak, Alpay Medetalibeyoglu, Matthew Antalek, Yury Velichko, Daniela Ladner, Amir Borhani, Ulas Bagci</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05692">https://arxiv.org/abs/2408.05692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05692">https://arxiv.org/pdf/2408.05692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05692]] A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation(https://arxiv.org/abs/2408.05692)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurately segmenting different organs from medical images is a critical prerequisite for computer-assisted diagnosis and intervention planning. This study proposes a deep learning-based approach for segmenting various organs from CT and MRI scans and classifying diseases. Our study introduces a novel technique integrating momentum within residual blocks for enhanced training dynamics in medical image analysis. We applied our method in two distinct tasks: segmenting liver, lung, & colon data and classifying abdominal pelvic CT and MRI scans. The proposed approach has shown promising results, outperforming state-of-the-art methods on publicly available benchmarking datasets. For instance, in the lung segmentation dataset, our approach yielded significant enhancements over the TransNetR model, including a 5.72% increase in dice score, a 5.04% improvement in mean Intersection over Union (mIoU), an 8.02% improvement in recall, and a 4.42% improvement in precision. Hence, incorporating momentum led to state-of-the-art performance in both segmentation and classification tasks, representing a significant advancement in the field of medical imaging.</li>
</ul>

<h3>Title: ICSFuzz: Collision Detector Bug Discovery in Autonomous Driving Simulators</h3>
<ul>
<li><strong>Authors: </strong>Weiwei Fu, Heqing Huang, Yifan Zhang, Ke Zhang, Jin Huang, Wei-Bin Lee, Jianping Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05694">https://arxiv.org/abs/2408.05694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05694">https://arxiv.org/pdf/2408.05694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05694]] ICSFuzz: Collision Detector Bug Discovery in Autonomous Driving Simulators(https://arxiv.org/abs/2408.05694)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>With the increasing adoption of autonomous vehicles, ensuring the reliability of autonomous driving systems (ADSs) deployed on autonomous vehicles has become a significant concern. Driving simulators have emerged as crucial platforms for testing autonomous driving systems, offering realistic, dynamic, and configurable environments. However, existing simulation-based ADS testers have largely overlooked the reliability of the simulators, potentially leading to overlooked violation scenarios and subsequent safety security risks during real-world deployment. In our investigations, we identified that collision detectors in simulators could fail to detect and report collisions in certain collision scenarios, referred to as ignored collision scenarios. This paper aims to systematically discover ignored collision scenarios to improve the reliability of autonomous driving simulators. To this end, we present ICSFuzz, a black-box fuzzing approach to discover ignored collision scenarios efficiently. Drawing upon the fact that the ignored collision scenarios are a sub-type of collision scenarios, our approach starts with the determined collision scenarios. Following the guidance provided by empirically studied factors contributing to collisions, we selectively mutate arbitrary collision scenarios in a step-wise manner toward the ignored collision scenarios and effectively discover them. We compare ICSFuzz with DriveFuzz, a state-of-the-art simulation-based ADS testing method, by replacing its oracle with our ignored-collision-aware oracle. The evaluation demonstrates that ICSFuzz outperforms DriveFuzz by finding 10-20x more ignored collision scenarios with a 20-70x speedup. All the discovered ignored collisions have been confirmed by developers with one CVE ID assigned.</li>
</ul>

<h3>Title: MacFormer: Semantic Segmentation with Fine Object Boundaries</h3>
<ul>
<li><strong>Authors: </strong>Guoan Xu, Wenfeng Huang, Tao Wu, Ligeng Chen, Wenjing Jia, Guangwei Gao, Xiatian Zhu, Stuart Perry</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05699">https://arxiv.org/abs/2408.05699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05699">https://arxiv.org/pdf/2408.05699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05699]] MacFormer: Semantic Segmentation with Fine Object Boundaries(https://arxiv.org/abs/2408.05699)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation involves assigning a specific category to each pixel in an image. While Vision Transformer-based models have made significant progress, current semantic segmentation methods often struggle with precise predictions in localized areas like object boundaries. To tackle this challenge, we introduce a new semantic segmentation architecture, ``MacFormer'', which features two key components. Firstly, using learnable agent tokens, a Mutual Agent Cross-Attention (MACA) mechanism effectively facilitates the bidirectional integration of features across encoder and decoder layers. This enables better preservation of low-level features, such as elementary edges, during decoding. Secondly, a Frequency Enhancement Module (FEM) in the decoder leverages high-frequency and low-frequency components to boost features in the frequency domain, benefiting object boundaries with minimal computational complexity increase. MacFormer is demonstrated to be compatible with various network architectures and outperforms existing methods in both accuracy and efficiency on benchmark datasets ADE20K and Cityscapes under different computational constraints.</li>
</ul>

<h3>Title: Predicting Chaotic System Behavior using Machine Learning Techniques</h3>
<ul>
<li><strong>Authors: </strong>Huaiyuan Rao, Yichen Zhao, Qiang Lai</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05702">https://arxiv.org/abs/2408.05702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05702">https://arxiv.org/pdf/2408.05702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05702]] Predicting Chaotic System Behavior using Machine Learning Techniques(https://arxiv.org/abs/2408.05702)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, machine learning techniques, particularly deep learning, have demonstrated superior performance over traditional time series forecasting methods across various applications, including both single-variable and multi-variable predictions. This study aims to investigate the capability of i) Next Generation Reservoir Computing (NG-RC) ii) Reservoir Computing (RC) iii) Long short-term Memory (LSTM) for predicting chaotic system behavior, and to compare their performance in terms of accuracy, efficiency, and robustness. These methods are applied to predict time series obtained from four representative chaotic systems including Lorenz, Rössler, Chen, Qi systems. In conclusion, we found that NG-RC is more computationally efficient and offers greater potential for predicting chaotic system behavior.</li>
</ul>

<h3>Title: Efficient Diffusion Transformer with Step-wise Dynamic Attention Mediators</h3>
<ul>
<li><strong>Authors: </strong>Yifan Pu, Zhuofan Xia, Jiayi Guo, Dongchen Han, Qixiu Li, Duo Li, Yuhui Yuan, Ji Li, Yizeng Han, Shiji Song, Gao Huang, Xiu Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05710">https://arxiv.org/abs/2408.05710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05710">https://arxiv.org/pdf/2408.05710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05710]] Efficient Diffusion Transformer with Step-wise Dynamic Attention Mediators(https://arxiv.org/abs/2408.05710)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>This paper identifies significant redundancy in the query-key interactions within self-attention mechanisms of diffusion transformer models, particularly during the early stages of denoising diffusion steps. In response to this observation, we present a novel diffusion transformer framework incorporating an additional set of mediator tokens to engage with queries and keys separately. By modulating the number of mediator tokens during the denoising generation phases, our model initiates the denoising process with a precise, non-ambiguous stage and gradually transitions to a phase enriched with detail. Concurrently, integrating mediator tokens simplifies the attention module's complexity to a linear scale, enhancing the efficiency of global attention processes. Additionally, we propose a time-step dynamic mediator token adjustment mechanism that further decreases the required computational FLOPs for generation, simultaneously facilitating the generation of high-quality images within the constraints of varied inference budgets. Extensive experiments demonstrate that the proposed method can improve the generated image quality while also reducing the inference cost of diffusion transformers. When integrated with the recent work SiT, our method achieves a state-of-the-art FID score of 2.01. The source code is available at this https URL.</li>
</ul>

<h3>Title: Contrastive masked auto-encoders based self-supervised hashing for 2D image and 3D point cloud cross-modal retrieval</h3>
<ul>
<li><strong>Authors: </strong>Rukai Wei, Heng Cui, Yu Liu, Yufeng Hou, Yanzhao Xie, Ke Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05711">https://arxiv.org/abs/2408.05711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05711">https://arxiv.org/pdf/2408.05711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05711]] Contrastive masked auto-encoders based self-supervised hashing for 2D image and 3D point cloud cross-modal retrieval(https://arxiv.org/abs/2408.05711)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Implementing cross-modal hashing between 2D images and 3D point-cloud data is a growing concern in real-world retrieval systems. Simply applying existing cross-modal approaches to this new task fails to adequately capture latent multi-modal semantics and effectively bridge the modality gap between 2D and 3D. To address these issues without relying on hand-crafted labels, we propose contrastive masked autoencoders based self-supervised hashing (CMAH) for retrieval between images and point-cloud data. We start by contrasting 2D-3D pairs and explicitly constraining them into a joint Hamming space. This contrastive learning process ensures robust discriminability for the generated hash codes and effectively reduces the modality gap. Moreover, we utilize multi-modal auto-encoders to enhance the model's understanding of multi-modal semantics. By completing the masked image/point-cloud data modeling task, the model is encouraged to capture more localized clues. In addition, the proposed multi-modal fusion block facilitates fine-grained interactions among different modalities. Extensive experiments on three public datasets demonstrate that the proposed CMAH significantly outperforms all baseline methods.</li>
</ul>

<h3>Title: SSL: A Self-similarity Loss for Improving Generative Image Super-resolution</h3>
<ul>
<li><strong>Authors: </strong>Du Chen, Zhengqiang Zhang, Jie Liang, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05713">https://arxiv.org/abs/2408.05713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05713">https://arxiv.org/pdf/2408.05713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05713]] SSL: A Self-similarity Loss for Improving Generative Image Super-resolution(https://arxiv.org/abs/2408.05713)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative adversarial networks (GAN) and generative diffusion models (DM) have been widely used in real-world image super-resolution (Real-ISR) to enhance the image perceptual quality. However, these generative models are prone to generating visual artifacts and false image structures, resulting in unnatural Real-ISR results. Based on the fact that natural images exhibit high self-similarities, i.e., a local patch can have many similar patches to it in the whole image, in this work we propose a simple yet effective self-similarity loss (SSL) to improve the performance of generative Real-ISR models, enhancing the hallucination of structural and textural details while reducing the unpleasant visual artifacts. Specifically, we compute a self-similarity graph (SSG) of the ground-truth image, and enforce the SSG of Real-ISR output to be close to it. To reduce the training cost and focus on edge areas, we generate an edge mask from the ground-truth image, and compute the SSG only on the masked pixels. The proposed SSL serves as a general plug-and-play penalty, which could be easily applied to the off-the-shelf Real-ISR models. Our experiments demonstrate that, by coupling with SSL, the performance of many state-of-the-art Real-ISR models, including those GAN and DM based ones, can be largely improved, reproducing more perceptually realistic image details and eliminating many false reconstructions and visual artifacts. Codes and supplementary material can be found at this https URL</li>
</ul>

<h3>Title: Deep Learning with Data Privacy via Residual Perturbation</h3>
<ul>
<li><strong>Authors: </strong>Wenqi Tao, Huaming Ling, Zuoqiang Shi, Bao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05723">https://arxiv.org/abs/2408.05723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05723">https://arxiv.org/pdf/2408.05723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05723]] Deep Learning with Data Privacy via Residual Perturbation(https://arxiv.org/abs/2408.05723)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Protecting data privacy in deep learning (DL) is of crucial importance. Several celebrated privacy notions have been established and used for privacy-preserving DL. However, many existing mechanisms achieve privacy at the cost of significant utility degradation and computational overhead. In this paper, we propose a stochastic differential equation-based residual perturbation for privacy-preserving DL, which injects Gaussian noise into each residual mapping of ResNets. Theoretically, we prove that residual perturbation guarantees differential privacy (DP) and reduces the generalization gap of DL. Empirically, we show that residual perturbation is computationally efficient and outperforms the state-of-the-art differentially private stochastic gradient descent (DPSGD) in utility maintenance without sacrificing membership privacy.</li>
</ul>

<h3>Title: A Training-Free Framework for Video License Plate Tracking and Recognition with Only One-Shot</h3>
<ul>
<li><strong>Authors: </strong>Haoxuan Ding, Qi Wang, Junyu Gao, Qiang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05729">https://arxiv.org/abs/2408.05729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05729">https://arxiv.org/pdf/2408.05729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05729]] A Training-Free Framework for Video License Plate Tracking and Recognition with Only One-Shot(https://arxiv.org/abs/2408.05729)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Traditional license plate detection and recognition models are often trained on closed datasets, limiting their ability to handle the diverse license plate formats across different regions. The emergence of large-scale pre-trained models has shown exceptional generalization capabilities, enabling few-shot and zero-shot learning. We propose OneShotLP, a training-free framework for video-based license plate detection and recognition, leveraging these advanced models. Starting with the license plate position in the first video frame, our method tracks this position across subsequent frames using a point tracking module, creating a trajectory of prompts. These prompts are input into a segmentation module that uses a promptable large segmentation model to generate local masks of the license plate regions. The segmented areas are then processed by multimodal large language models (MLLMs) for accurate license plate recognition. OneShotLP offers significant advantages, including the ability to function effectively without extensive training data and adaptability to various license plate styles. Experimental results on UFPR-ALPR and SSIG-SegPlate datasets demonstrate the superior accuracy of our approach compared to traditional methods. This highlights the potential of leveraging pre-trained models for diverse real-world applications in intelligent transportation systems. The code is available at this https URL.</li>
</ul>

<h3>Title: Disposable-key-based image encryption for collaborative learning of Vision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Rei Aso, Sayaka Shiota, Hitoshi Kiya</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05737">https://arxiv.org/abs/2408.05737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05737">https://arxiv.org/pdf/2408.05737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05737]] Disposable-key-based image encryption for collaborative learning of Vision Transformer(https://arxiv.org/abs/2408.05737)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, federate, transformer</a></li>
<li><strong>Abstract: </strong>We propose a novel method for securely training the vision transformer (ViT) with sensitive data shared from multiple clients similar to privacy-preserving federated learning. In the proposed method, training images are independently encrypted by each client where encryption keys can be prepared by each client, and ViT is trained by using these encrypted images for the first time. The method allows clients not only to dispose of the keys but to also reduce the communication costs between a central server and the clients. In image classification experiments, we verify the effectiveness of the proposed method on the CIFAR-10 dataset in terms of classification accuracy and the use of restricted random permutation matrices.</li>
</ul>

<h3>Title: MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation</h3>
<ul>
<li><strong>Authors: </strong>Jianping Zhou, Junhao Li, Guanjie Zheng, Xinbing Wang, Chenghu Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05740">https://arxiv.org/abs/2408.05740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05740">https://arxiv.org/pdf/2408.05740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05740]] MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation(https://arxiv.org/abs/2408.05740)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Missing values are prevalent in multivariate time series, compromising the integrity of analyses and degrading the performance of downstream tasks. Consequently, research has focused on multivariate time series imputation, aiming to accurately impute the missing values based on available observations. A key research question is how to ensure imputation consistency, i.e., intra-consistency between observed and imputed values, and inter-consistency between adjacent windows after imputation. However, previous methods rely solely on the inductive bias of the imputation targets to guide the learning process, ignoring imputation consistency and ultimately resulting in poor performance. Diffusion models, known for their powerful generative abilities, prefer to generate consistent results based on available observations. Therefore, we propose a conditional diffusion model for Multivariate Time Series Consistent Imputation (MTSCI). Specifically, MTSCI employs a contrastive complementary mask to generate dual views during the forward noising process. Then, the intra contrastive loss is calculated to ensure intra-consistency between the imputed and observed values. Meanwhile, MTSCI utilizes a mixup mechanism to incorporate conditional information from adjacent windows during the denoising process, facilitating the inter-consistency between imputed samples. Extensive experiments on multiple real-world datasets demonstrate that our method achieves the state-of-the-art performance on multivariate time series imputation task under different missing scenarios. Code is available at this https URL.</li>
</ul>

<h3>Title: Neural Architecture Search based Global-local Vision Mamba for Palm-Vein Recognition</h3>
<ul>
<li><strong>Authors: </strong>Huafeng Qin, Yuming Fu, Jing Chen, Mounim A. El-Yacoubi, Xinbo Gao, Jun Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05743">https://arxiv.org/abs/2408.05743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05743">https://arxiv.org/pdf/2408.05743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05743]] Neural Architecture Search based Global-local Vision Mamba for Palm-Vein Recognition(https://arxiv.org/abs/2408.05743)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust</a></li>
<li><strong>Abstract: </strong>Due to the advantages such as high security, high privacy, and liveness recognition, vein recognition has been received more and more attention in past years. Recently, deep learning models, e.g., Mamba has shown robust feature representation with linear computational complexity and successfully applied for visual tasks. However, vision Manba can capture long-distance feature dependencies but unfortunately deteriorate local feature details. Besides, manually designing a Mamba architecture based on human priori knowledge is very time-consuming and error-prone. In this paper, first, we propose a hybrid network structure named Global-local Vision Mamba (GLVM), to learn the local correlations in images explicitly and global dependencies among tokens for vein feature representation. Secondly, we design a Multi-head Mamba to learn the dependencies along different directions, so as to improve the feature representation ability of vision Mamba. Thirdly, to learn the complementary features, we propose a ConvMamba block consisting of three branches, named Multi-head Mamba branch (MHMamba), Feature Iteration Unit branch (FIU), and Convolutional Neural Network (CNN) branch, where the Feature Iteration Unit branch aims to fuse convolutional local features with Mamba-based global representations. Finally, a Globallocal Alternate Neural Architecture Search (GLNAS) method is proposed to search the optimal architecture of GLVM alternately with the evolutionary algorithm, thereby improving the recognition performance for vein recognition tasks. We conduct rigorous experiments on three public palm-vein databases to estimate the performance. The experimental results demonstrate that the proposed method outperforms the representative approaches and achieves state-of-the-art recognition accuracy.</li>
</ul>

<h3>Title: Improving Adversarial Transferability with Neighbourhood Gradient Information</h3>
<ul>
<li><strong>Authors: </strong>Haijing Guo, Jiafeng Wang, Zhaoyu Chen, Kaixun Jiang, Lingyi Hong, Pinxue Guo, Jinglun Li, Wenqiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05745">https://arxiv.org/abs/2408.05745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05745">https://arxiv.org/pdf/2408.05745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05745]] Improving Adversarial Transferability with Neighbourhood Gradient Information(https://arxiv.org/abs/2408.05745)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) are known to be susceptible to adversarial examples, leading to significant performance degradation. In black-box attack scenarios, a considerable attack performance gap between the surrogate model and the target model persists. This work focuses on enhancing the transferability of adversarial examples to narrow this performance gap. We observe that the gradient information around the clean image, i.e. Neighbourhood Gradient Information, can offer high transferability. Leveraging this, we propose the NGI-Attack, which incorporates Example Backtracking and Multiplex Mask strategies, to use this gradient information and enhance transferability fully. Specifically, we first adopt Example Backtracking to accumulate Neighbourhood Gradient Information as the initial momentum term. Multiplex Mask, which forms a multi-way attack strategy, aims to force the network to focus on non-discriminative regions, which can obtain richer gradient information during only a few iterations. Extensive experiments demonstrate that our approach significantly enhances adversarial transferability. Especially, when attacking numerous defense models, we achieve an average attack success rate of 95.8%. Notably, our method can plugin with any off-the-shelf algorithm to improve their attack performance without additional time cost.</li>
</ul>

<h3>Title: Efficient and Versatile Robust Fine-Tuning of Zero-shot Models</h3>
<ul>
<li><strong>Authors: </strong>Sungyeon Kim, Boseung Jeong, Donghyun Kim, Suha Kwak</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05749">https://arxiv.org/abs/2408.05749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05749">https://arxiv.org/pdf/2408.05749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05749]] Efficient and Versatile Robust Fine-Tuning of Zero-shot Models(https://arxiv.org/abs/2408.05749)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Large-scale image-text pre-trained models enable zero-shot classification and provide consistent accuracy across various data distributions. Nonetheless, optimizing these models in downstream tasks typically requires fine-tuning, which reduces generalization to out-of-distribution (OOD) data and demands extensive computational resources. We introduce Robust Adapter (R-Adapter), a novel method for fine-tuning zero-shot models to downstream tasks while simultaneously addressing both these issues. Our method integrates lightweight modules into the pre-trained model and employs novel self-ensemble techniques to boost OOD robustness and reduce storage expenses substantially. Furthermore, we propose MPM-NCE loss designed for fine-tuning on vision-language downstream tasks. It ensures precise alignment of multiple image-text pairs and discriminative feature learning. By extending the benchmark for robust fine-tuning beyond classification to include diverse tasks such as cross-modal retrieval and open vocabulary segmentation, we demonstrate the broad applicability of R-Adapter. Our extensive experiments demonstrate that R-Adapter achieves state-of-the-art performance across a diverse set of tasks, tuning only 13% of the parameters of the CLIP encoders.</li>
</ul>

<h3>Title: Personalized Federated Learning for improving radar based precipitation nowcasting on heterogeneous areas</h3>
<ul>
<li><strong>Authors: </strong>Judith Sáinz-Pardo Díaz, María Castrillo, Juraj Bartok, Ignacio Heredia Cachá, Irina Malkin Ondík, Ivan Martynovskyi, Khadijeh Alibabaei, Lisana Berberi, Valentin Kozlov, Álvaro López García</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05761">https://arxiv.org/abs/2408.05761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05761">https://arxiv.org/pdf/2408.05761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05761]] Personalized Federated Learning for improving radar based precipitation nowcasting on heterogeneous areas(https://arxiv.org/abs/2408.05761)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>The increasing generation of data in different areas of life, such as the environment, highlights the need to explore new techniques for processing and exploiting data for useful purposes. In this context, artificial intelligence techniques, especially through deep learning models, are key tools to be used on the large amount of data that can be obtained, for example, from weather radars. In many cases, the information collected by these radars is not open, or belongs to different institutions, thus needing to deal with the distributed nature of this data. In this work, the applicability of a personalized federated learning architecture, which has been called adapFL, on distributed weather radar images is addressed. To this end, given a single available radar covering 400 km in diameter, the captured images are divided in such a way that they are disjointly distributed into four different federated clients. The results obtained with adapFL are analyzed in each zone, as well as in a central area covering part of the surface of each of the previously distributed areas. The ultimate goal of this work is to study the generalization capability of this type of learning technique for its extrapolation to use cases in which a representative number of radars is available, whose data can not be centralized due to technical, legal or administrative concerns. The results of this preliminary study indicate that the performance obtained in each zone with the adapFL approach allows improving the results of the federated learning approach, the individual deep learning models and the classical Continuity Tracking Radar Echoes by Correlation approach.</li>
</ul>

<h3>Title: An analysis of HOI: using a training-free method with multimodal visual foundation models when only the test set is available, without the training set</h3>
<ul>
<li><strong>Authors: </strong>Chaoyi Ai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05772">https://arxiv.org/abs/2408.05772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05772">https://arxiv.org/pdf/2408.05772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05772]] An analysis of HOI: using a training-free method with multimodal visual foundation models when only the test set is available, without the training set(https://arxiv.org/abs/2408.05772)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Human-Object Interaction (HOI) aims to identify the pairs of humans and objects in images and to recognize their relationships, ultimately forming $\langle human, object, verb \rangle$ triplets. Under default settings, HOI performance is nearly saturated, with many studies focusing on long-tail distribution and zero-shot/few-shot scenarios. Let us consider an intriguing problem:``What if there is only test dataset without training dataset, using multimodal visual foundation model in a training-free manner? '' This study uses two experimental settings: grounding truth and random arbitrary combinations. We get some interesting conclusion and find that the open vocabulary capabilities of the multimodal visual foundation model are not yet fully realized. Additionally, replacing the feature extraction with grounding DINO further confirms these findings.</li>
</ul>

<h3>Title: Seg-CycleGAN : SAR-to-optical image translation guided by a downstream task</h3>
<ul>
<li><strong>Authors: </strong>Hannuo Zhang, Huihui Li, Jiarui Lin, Yujie Zhang, Jianghua Fan, Hang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05777">https://arxiv.org/abs/2408.05777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05777">https://arxiv.org/pdf/2408.05777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05777]] Seg-CycleGAN : SAR-to-optical image translation guided by a downstream task(https://arxiv.org/abs/2408.05777)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Optical remote sensing and Synthetic Aperture Radar(SAR) remote sensing are crucial for earth observation, offering complementary capabilities. While optical sensors provide high-quality images, they are limited by weather and lighting conditions. In contrast, SAR sensors can operate effectively under adverse conditions. This letter proposes a GAN-based SAR-to-optical image translation method named Seg-CycleGAN, designed to enhance the accuracy of ship target translation by leveraging semantic information from a pre-trained semantic segmentation model. Our method utilizes the downstream task of ship target semantic segmentation to guide the training of image translation network, improving the quality of output Optical-styled images. The potential of foundation-model-annotated datasets in SAR-to-optical translation tasks is revealed. This work suggests broader research and applications for downstream-task-guided frameworks. The code will be available at this https URL</li>
</ul>

<h3>Title: U-DECN: End-to-End Underwater Object Detection ConvNet with Improved DeNoising Training</h3>
<ul>
<li><strong>Authors: </strong>Zhuoyan Liu, Bo Wang, Ye Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05780">https://arxiv.org/abs/2408.05780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05780">https://arxiv.org/pdf/2408.05780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05780]] U-DECN: End-to-End Underwater Object Detection ConvNet with Improved DeNoising Training(https://arxiv.org/abs/2408.05780)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Underwater object detection has higher requirements of running speed and deployment efficiency for the detector due to its specific environmental challenges. NMS of two- or one-stage object detectors and transformer architecture of query-based end-to-end object detectors are not conducive to deployment on underwater embedded devices with limited processing power. As for the detrimental effect of underwater color cast noise, recent underwater object detectors make network architecture or training complex, which also hinders their application and deployment on underwater vehicle platforms. In this paper, we propose the Underwater DECO with improved deNoising training (U-DECN), the query-based end-to-end object detector (with ConvNet encoder-decoder architecture) for underwater color cast noise that addresses the above problems. We integrate advanced technologies from DETR variants into DECO and design optimization methods specifically for the ConvNet architecture, including Separate Contrastive DeNoising Forward and Deformable Convolution in SIM. To address the underwater color cast noise issue, we propose an underwater color denoising query to improve the generalization of the model for the biased object feature information by different color cast noise. Our U-DECN, with ResNet-50 backbone, achieves 61.4 AP (50 epochs), 63.3 AP (72 epochs), 64.0 AP (100 epochs) on DUO, and 21 FPS (5 times faster than Deformable DETR and DINO 4 FPS) on NVIDIA AGX Orin by TensorRT FP16, outperforming the other state-of-the-art query-based end-to-end object detectors. The code is available at this https URL.</li>
</ul>

<h3>Title: CURLing the Dream: Contrastive Representations for World Modeling in Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Victor Augusto Kich, Jair Augusto Bottega, Raul Steinmetz, Ricardo Bedin Grando, Ayano Yorozu, Akihisa Ohya</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05781">https://arxiv.org/abs/2408.05781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05781">https://arxiv.org/pdf/2408.05781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05781]] CURLing the Dream: Contrastive Representations for World Modeling in Reinforcement Learning(https://arxiv.org/abs/2408.05781)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this work, we present Curled-Dreamer, a novel reinforcement learning algorithm that integrates contrastive learning into the DreamerV3 framework to enhance performance in visual reinforcement learning tasks. By incorporating the contrastive loss from the CURL algorithm and a reconstruction loss from autoencoder, Curled-Dreamer achieves significant improvements in various DeepMind Control Suite tasks. Our extensive experiments demonstrate that Curled-Dreamer consistently outperforms state-of-the-art algorithms, achieving higher mean and median scores across a diverse set of tasks. The results indicate that the proposed approach not only accelerates learning but also enhances the robustness of the learned policies. This work highlights the potential of combining different learning paradigms to achieve superior performance in reinforcement learning applications.</li>
</ul>

<h3>Title: SAGA: A Participant-specific Examination of Story Alternatives and Goal Applicability for a Deeper Understanding of Complex Events</h3>
<ul>
<li><strong>Authors: </strong>Sai Vallurupalli, Katrin Erk, Francis Ferraro</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05793">https://arxiv.org/abs/2408.05793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05793">https://arxiv.org/pdf/2408.05793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05793]] SAGA: A Participant-specific Examination of Story Alternatives and Goal Applicability for a Deeper Understanding of Complex Events(https://arxiv.org/abs/2408.05793)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Interpreting and assessing goal driven actions is vital to understanding and reasoning over complex events. It is important to be able to acquire the knowledge needed for this understanding, though doing so is challenging. We argue that such knowledge can be elicited through a participant achievement lens. We analyze a complex event in a narrative according to the intended achievements of the participants in that narrative, the likely future actions of the participants, and the likelihood of goal success. We collect 6.3K high quality goal and action annotations reflecting our proposed participant achievement lens, with an average weighted Fleiss-Kappa IAA of 80%. Our collection contains annotated alternate versions of each narrative. These alternate versions vary minimally from the "original" story, but can license drastically different inferences. Our findings suggest that while modern large language models can reflect some of the goal-based knowledge we study, they find it challenging to fully capture the design and intent behind concerted actions, even when the model pretraining included the data from which we extracted the goal knowledge. We show that smaller models fine-tuned on our dataset can achieve performance surpassing larger models.</li>
</ul>

<h3>Title: A Comparative Study of Convolutional and Recurrent Neural Networks for Storm Surge Prediction in Tampa Bay</h3>
<ul>
<li><strong>Authors: </strong>Mandana Farhang Ghahfarokhi, Seyed Hossein Sonbolestan, Mahta Zamanizadeh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05797">https://arxiv.org/abs/2408.05797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05797">https://arxiv.org/pdf/2408.05797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05797]] A Comparative Study of Convolutional and Recurrent Neural Networks for Storm Surge Prediction in Tampa Bay(https://arxiv.org/abs/2408.05797)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we compare the performance of three common deep learning architectures, CNN-LSTM, LSTM, and 3D-CNN, in the context of surrogate storm surge modeling. The study site for this paper is the Tampa Bay area in Florida. Using high-resolution atmospheric data from the reanalysis models and historical water level data from NOAA tide stations, we trained and tested these models to evaluate their performance. Our findings indicate that the CNN-LSTM model outperforms the other architectures, achieving a test loss of 0.010 and an R-squared (R2) score of 0.84. The LSTM model, although it achieved the lowest training loss of 0.007 and the highest training R2 of 0.88, exhibited poorer generalization with a test loss of 0.014 and an R2 of 0.77. The 3D-CNN model showed reasonable performance with a test loss of 0.011 and an R2 of 0.82 but displayed instability under extreme conditions. A case study on Hurricane Ian, which caused a significant negative surge of -1.5 meters in Tampa Bay indicates the CNN-LSTM model's robustness and accuracy in extreme scenarios.</li>
</ul>

<h3>Title: Egocentric Vision Language Planning</h3>
<ul>
<li><strong>Authors: </strong>Zhirui Fang, Ming Yang, Weishuai Zeng, Boyu Li, Junpeng Yue, Ziluo Ding, Xiu Li, Zongqing Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05802">https://arxiv.org/abs/2408.05802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05802">https://arxiv.org/pdf/2408.05802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05802]] Egocentric Vision Language Planning(https://arxiv.org/abs/2408.05802)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We explore leveraging large multi-modal models (LMMs) and text2image models to build a more general embodied agent. LMMs excel in planning long-horizon tasks over symbolic abstractions but struggle with grounding in the physical world, often failing to accurately identify object positions in images. A bridge is needed to connect LMMs to the physical world. The paper proposes a novel approach, egocentric vision language planning (EgoPlan), to handle long-horizon tasks from an egocentric perspective in varying household scenarios. This model leverages a diffusion model to simulate the fundamental dynamics between states and actions, integrating techniques like style transfer and optical flow to enhance generalization across different environmental dynamics. The LMM serves as a planner, breaking down instructions into sub-goals and selecting actions based on their alignment with these sub-goals, thus enabling more generalized and effective decision-making. Experiments show that EgoPlan improves long-horizon task success rates from the egocentric view compared to baselines across household scenarios.</li>
</ul>

<h3>Title: HySparK: Hybrid Sparse Masking for Large Scale Medical Image Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Fenghe Tang, Ronghao Xu, Qingsong Yao, Xueming Fu, Quan Quan, Heqin Zhu, Zaiyi Liu, S. Kevin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05815">https://arxiv.org/abs/2408.05815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05815">https://arxiv.org/pdf/2408.05815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05815]] HySparK: Hybrid Sparse Masking for Large Scale Medical Image Pre-Training(https://arxiv.org/abs/2408.05815)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>The generative self-supervised learning strategy exhibits remarkable learning representational capabilities. However, there is limited attention to end-to-end pre-training methods based on a hybrid architecture of CNN and Transformer, which can learn strong local and global representations simultaneously. To address this issue, we propose a generative pre-training strategy called Hybrid Sparse masKing (HySparK) based on masked image modeling and apply it to large-scale pre-training on medical images. First, we perform a bottom-up 3D hybrid masking strategy on the encoder to keep consistency masking. Then we utilize sparse convolution for the top CNNs and encode unmasked patches for the bottom vision Transformers. Second, we employ a simple hierarchical decoder with skip-connections to achieve dense multi-scale feature reconstruction. Third, we implement our pre-training method on a collection of multiple large-scale 3D medical imaging datasets. Extensive experiments indicate that our proposed pre-training strategy demonstrates robust transfer-ability in supervised downstream tasks and sheds light on HySparK's promising prospects. The code is available at this https URL</li>
</ul>

<h3>Title: Sampling Foundational Transformer: A Theoretical Perspective</h3>
<ul>
<li><strong>Authors: </strong>Viet Anh Nguyen, Minh Lenhat, Khoa Nguyen, Duong Duc Hieu, Dao Huu Hung, Truong Son Hy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05822">https://arxiv.org/abs/2408.05822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05822">https://arxiv.org/pdf/2408.05822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05822]] Sampling Foundational Transformer: A Theoretical Perspective(https://arxiv.org/abs/2408.05822)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The versatility of self-attention mechanism earned transformers great success in almost all data modalities, with limitations on the quadratic complexity and difficulty of training. To apply transformers across different data modalities, practitioners have to make specific clever data-modality-dependent constructions. In this paper, we propose Sampling Foundational Transformer (SFT) that can work on multiple data modalities (e.g., point cloud, graph, and sequence) and constraints (e.g., rotational-invariant). The existence of such model is important as contemporary foundational modeling requires operability on multiple data sources. For efficiency on large number of tokens, our model relies on our context aware sampling-without-replacement mechanism for both linear asymptotic computational complexity and real inference time gain. For efficiency, we rely on our newly discovered pseudoconvex formulation of transformer layer to increase model's convergence rate. As a model working on multiple data modalities, SFT has achieved competitive results on many benchmarks, while being faster in inference, compared to other very specialized models.</li>
</ul>

<h3>Title: Robust Domain Generalization for Multi-modal Object Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yuxin Qiao, Keqin Li, Junhong Lin, Rong Wei, Chufeng Jiang, Yang Luo, Haoyu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05831">https://arxiv.org/abs/2408.05831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05831">https://arxiv.org/pdf/2408.05831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05831]] Robust Domain Generalization for Multi-modal Object Recognition(https://arxiv.org/abs/2408.05831)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In multi-label classification, machine learning encounters the challenge of domain generalization when handling tasks with distributions differing from the training data. Existing approaches primarily focus on vision object recognition and neglect the integration of natural language. Recent advancements in vision-language pre-training leverage supervision from extensive visual-language pairs, enabling learning across diverse domains and enhancing recognition in multi-modal scenarios. However, these approaches face limitations in loss function utilization, generality across backbones, and class-aware visual fusion. This paper proposes solutions to these limitations by inferring the actual loss, broadening evaluations to larger vision-language backbones, and introducing Mixup-CLIPood, which incorporates a novel mix-up loss for enhanced class-aware visual fusion. Our method demonstrates superior performance in domain generalization across multiple datasets.</li>
</ul>

<h3>Title: Devlore: Extending Arm CCA to Integrated Devices A Journey Beyond Memory to Interrupt Isolation</h3>
<ul>
<li><strong>Authors: </strong>Andrin Bertschi, Supraja Sridhara, Friederike Groschupp, Mark Kuhne, Benedict Schlüter, Clément Thorens, Nicolas Dutly, Srdjan Capkun, Shweta Shinde</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05835">https://arxiv.org/abs/2408.05835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05835">https://arxiv.org/pdf/2408.05835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05835]] Devlore: Extending Arm CCA to Integrated Devices A Journey Beyond Memory to Interrupt Isolation(https://arxiv.org/abs/2408.05835)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect</a></li>
<li><strong>Abstract: </strong>Arm Confidential Computing Architecture (CCA) executes sensitive computation in an abstraction called realm VMs and protects it from the hypervisor, host OS, and other co-resident VMs. However, CCA does not allow integrated devices on the platform to access realm VMs and doing so requires intrusive changes to software and is simply not possible to achieve securely for some devices. In this paper, we present Devlore which allows realm VMs to directly access integrated peripherals. Devlore memory isolation re-purposes CCA hardware primitives (granule protection and stage-two page tables), while our interrupt isolation adapts a delegate-but-check strategy. Our choice of offloading interrupt management to the hypervisor but adding correctness checks in the trusted software allows Devlore to preserve compatibility and performance. We evaluate Devlore on Arm FVP to demonstrate 5 diverse peripherals attached to realm VMs.</li>
</ul>

<h3>Title: Using Retriever Augmented Large Language Models for Attack Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Renascence Tarafder Prapty, Ashish Kundu, Arun Iyengar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05855">https://arxiv.org/abs/2408.05855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05855">https://arxiv.org/pdf/2408.05855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05855]] Using Retriever Augmented Large Language Models for Attack Graph Generation(https://arxiv.org/abs/2408.05855)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>As the complexity of modern systems increases, so does the importance of assessing their security posture through effective vulnerability management and threat modeling techniques. One powerful tool in the arsenal of cybersecurity professionals is the attack graph, a representation of all potential attack paths within a system that an adversary might exploit to achieve a certain objective. Traditional methods of generating attack graphs involve expert knowledge, manual curation, and computational algorithms that might not cover the entire threat landscape due to the ever-evolving nature of vulnerabilities and exploits. This paper explores the approach of leveraging large language models (LLMs), such as ChatGPT, to automate the generation of attack graphs by intelligently chaining Common Vulnerabilities and Exposures (CVEs) based on their preconditions and effects. It also shows how to utilize LLMs to create attack graphs from threat reports.</li>
</ul>

<h3>Title: LaWa: Using Latent Space for In-Generation Image Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Ahmad Rezaei, Mohammad Akbari, Saeed Ranjbar Alvar, Arezou Fatemi, Yong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05868">https://arxiv.org/abs/2408.05868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05868">https://arxiv.org/pdf/2408.05868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05868]] LaWa: Using Latent Space for In-Generation Image Watermarking(https://arxiv.org/abs/2408.05868)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark, diffusion, generative</a></li>
<li><strong>Abstract: </strong>With generative models producing high quality images that are indistinguishable from real ones, there is growing concern regarding the malicious usage of AI-generated images. Imperceptible image watermarking is one viable solution towards such concerns. Prior watermarking methods map the image to a latent space for adding the watermark. Moreover, Latent Diffusion Models (LDM) generate the image in the latent space of a pre-trained autoencoder. We argue that this latent space can be used to integrate watermarking into the generation process. To this end, we present LaWa, an in-generation image watermarking method designed for LDMs. By using coarse-to-fine watermark embedding modules, LaWa modifies the latent space of pre-trained autoencoders and achieves high robustness against a wide range of image transformations while preserving perceptual quality of the image. We show that LaWa can also be used as a general image watermarking method. Through extensive experiments, we demonstrate that LaWa outperforms previous works in perceptual quality, robustness against attacks, and computational complexity, while having very low false positive rate. Code is available here.</li>
</ul>

<h3>Title: Defining Boundaries: A Spectrum of Task Feasibility for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wenbo Zhang, Zihang Xu, Hengrui Cai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05873">https://arxiv.org/abs/2408.05873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05873">https://arxiv.org/pdf/2408.05873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05873]] Defining Boundaries: A Spectrum of Task Feasibility for Large Language Models(https://arxiv.org/abs/2408.05873)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable performance in various tasks but often fail to handle queries that exceed their knowledge and capabilities, leading to incorrect or fabricated responses. This paper addresses the need for LLMs to recognize and refuse infeasible tasks due to the required skills surpassing their capabilities. We first systematically conceptualize infeasible tasks for LLMs, providing formal definitions and categorizations that cover a spectrum of related hallucinations. We develop and benchmark a new dataset comprising diverse infeasible and feasible tasks to test multiple LLMs' abilities on task feasibility. Furthermore, we explore the potential of training enhancements to increase LLMs' refusal capabilities with fine-tuning. Experiments validate the effectiveness of our methods, offering promising directions for refining the operational boundaries of LLMs in real applications.</li>
</ul>

<h3>Title: LLM-Based Robust Product Classification in Commerce and Compliance</h3>
<ul>
<li><strong>Authors: </strong>Sina Gholamian, Gianfranco Romani, Bartosz Rudnikowicz, Laura Skylaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05874">https://arxiv.org/abs/2408.05874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05874">https://arxiv.org/pdf/2408.05874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05874]] LLM-Based Robust Product Classification in Commerce and Compliance(https://arxiv.org/abs/2408.05874)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Product classification is a crucial task in international trade, as compliance regulations are verified and taxes and duties are applied based on product categories. Manual classification of products is time-consuming and error-prone, and the sheer volume of products imported and exported renders the manual process infeasible. Consequently, e-commerce platforms and enterprises involved in international trade have turned to automatic product classification using machine learning. However, current approaches do not consider the real-world challenges associated with product classification, such as very abbreviated and incomplete product descriptions. In addition, recent advancements in generative Large Language Models (LLMs) and their reasoning capabilities are mainly untapped in product classification and e-commerce. In this research, we explore the real-life challenges of industrial classification and we propose data perturbations that allow for realistic data simulation. Furthermore, we employ LLM-based product classification to improve the robustness of the prediction in presence of incomplete data. Our research shows that LLMs with in-context learning outperform the supervised approaches in the clean-data scenario. Additionally, we illustrate that LLMs are significantly more robust than the supervised approaches when data attacks are present.</li>
</ul>

<h3>Title: Creating Arabic LLM Prompts at Scale</h3>
<ul>
<li><strong>Authors: </strong>Abdelrahman El-Sheikh, Ahmed Elmogtaba, Kareem Darwish, Muhammad Elmallah, Ashraf Elneima, Hassan Sawaf</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05882">https://arxiv.org/abs/2408.05882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05882">https://arxiv.org/pdf/2408.05882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05882]] Creating Arabic LLM Prompts at Scale(https://arxiv.org/abs/2408.05882)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The debut of chatGPT and BARD has popularized instruction following text generation using LLMs, where a user can interrogate an LLM using natural language requests and obtain natural language answers that matches their requests. Training LLMs to respond in this manner requires a large number of worked out examples of user requests (aka prompts) with corresponding gold responses. In this paper, we introduce two methods for creating such prompts for Arabic cheaply and quickly. The first methods entails automatically translating existing prompt datasets from English, such as PromptSource and Super-NaturalInstructions, and then using machine translation quality estimation to retain high quality translations only. The second method involves creating natural language prompts on top of existing Arabic NLP datasets. Using these two methods we were able to create more than 67.4 million Arabic prompts that cover a variety of tasks including summarization, headline generation, grammar checking, open/closed question answering, creative writing, etc. We show that fine tuning an open 7 billion parameter large language model, namely base Qwen2 7B, enables it to outperform a state-of-the-art 70 billion parameter instruction tuned model, namely Llama3 70B, in handling Arabic prompts.</li>
</ul>

<h3>Title: GFlowNet Training by Policy Gradients</h3>
<ul>
<li><strong>Authors: </strong>Puhua Niu, Shili Wu, Mingzhou Fan, Xiaoning Qian</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05885">https://arxiv.org/abs/2408.05885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05885">https://arxiv.org/pdf/2408.05885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05885]] GFlowNet Training by Policy Gradients(https://arxiv.org/abs/2408.05885)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Generative Flow Networks (GFlowNets) have been shown effective to generate combinatorial objects with desired properties. We here propose a new GFlowNet training framework, with policy-dependent rewards, that bridges keeping flow balance of GFlowNets to optimizing the expected accumulated reward in traditional Reinforcement-Learning (RL). This enables the derivation of new policy-based GFlowNet training methods, in contrast to existing ones resembling value-based RL. It is known that the design of backward policies in GFlowNet training affects efficiency. We further develop a coupled training strategy that jointly solves GFlowNet forward policy training and backward policy design. Performance analysis is provided with a theoretical guarantee of our policy-based GFlowNet training. Experiments on both simulated and real-world datasets verify that our policy-based strategies provide advanced RL perspectives for robust gradient estimation to improve GFlowNet performance.</li>
</ul>

<h3>Title: Online-Score-Aided Federated Learning: Taming the Resource Constraints in Wireless Networks</h3>
<ul>
<li><strong>Authors: </strong>Md Ferdous Pervej, Minseok Choi, Andreas F. Molisch</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05886">https://arxiv.org/abs/2408.05886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05886">https://arxiv.org/pdf/2408.05886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05886]] Online-Score-Aided Federated Learning: Taming the Resource Constraints in Wireless Networks(https://arxiv.org/abs/2408.05886)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>While FL is a widely popular distributed ML strategy that protects data privacy, time-varying wireless network parameters and heterogeneous system configurations of the wireless device pose significant challenges. Although the limited radio and computational resources of the network and the clients, respectively, are widely acknowledged, two critical yet often ignored aspects are (a) wireless devices can only dedicate a small chunk of their limited storage for the FL task and (b) new training samples may arrive in an online manner in many practical wireless applications. Therefore, we propose a new FL algorithm called OSAFL, specifically designed to learn tasks relevant to wireless applications under these practical considerations. Since it has long been proven that under extreme resource constraints, clients may perform an arbitrary number of local training steps, which may lead to client drift under statistically heterogeneous data distributions, we leverage normalized gradient similarities and exploit weighting clients' updates based on optimized scores that facilitate the convergence rate of the proposed OSAFL algorithm. Our extensive simulation results on two different tasks -- each with three different datasets -- with four popular ML models validate the effectiveness of OSAFL compared to six existing state-of-the-art FL baselines.</li>
</ul>

<h3>Title: Integrative Approaches in Cybersecurity and AI</h3>
<ul>
<li><strong>Authors: </strong>Marwan Omar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05888">https://arxiv.org/abs/2408.05888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05888">https://arxiv.org/pdf/2408.05888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05888]] Integrative Approaches in Cybersecurity and AI(https://arxiv.org/abs/2408.05888)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>In recent years, the convergence of cybersecurity, artificial intelligence (AI), and data management has emerged as a critical area of research, driven by the increasing complexity and interdependence of modern technological ecosystems. This paper provides a comprehensive review and analysis of integrative approaches that harness AI techniques to enhance cybersecurity frameworks and optimize data management practices. By exploring the synergies between these domains, we identify key trends, challenges, and future directions that hold the potential to revolutionize the way organizations protect, analyze, and leverage their data. Our findings highlight the necessity of cross-disciplinary strategies that incorporate AI-driven automation, real-time threat detection, and advanced data analytics to build more resilient and adaptive security architectures.</li>
</ul>

<h3>Title: Enhancing 3D Transformer Segmentation Model for Medical Image with Token-level Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Xinrong Hu, Dewen Zeng, Yawen Wu, Xueyang Li, Yiyu Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05889">https://arxiv.org/abs/2408.05889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05889">https://arxiv.org/pdf/2408.05889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05889]] Enhancing 3D Transformer Segmentation Model for Medical Image with Token-level Representation Learning(https://arxiv.org/abs/2408.05889)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In the field of medical images, although various works find Swin Transformer has promising effectiveness on pixelwise dense prediction, whether pre-training these models without using extra dataset can further boost the performance for the downstream semantic segmentation remains unexplored.Applications of previous representation learning methods are hindered by the limited number of 3D volumes and high computational cost. In addition, most of pretext tasks designed specifically for Transformer are not applicable to hierarchical structure of Swin Transformer. Thus, this work proposes a token-level representation learning loss that maximizes agreement between token embeddings from different augmented views individually instead of volume-level global features. Moreover, we identify a potential representation collapse exclusively caused by this new loss. To prevent collapse, we invent a simple "rotate-and-restore" mechanism, which rotates and flips one augmented view of input volume, and later restores the order of tokens in the feature maps. We also modify the contrastive loss to address the discrimination between tokens at the same position but from different volumes. We test our pre-training scheme on two public medical segmentation datasets, and the results on the downstream segmentation task show more improvement of our methods than other state-of-the-art pre-trainig methods.</li>
</ul>

<h3>Title: CMAB: A First National-Scale Multi-Attribute Building Dataset Derived from Open Source Data and GeoAI</h3>
<ul>
<li><strong>Authors: </strong>Yecheng Zhang, Huimin Zhao, Ying Long</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05891">https://arxiv.org/abs/2408.05891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05891">https://arxiv.org/pdf/2408.05891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05891]] CMAB: A First National-Scale Multi-Attribute Building Dataset Derived from Open Source Data and GeoAI(https://arxiv.org/abs/2408.05891)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Rapidly acquiring three-dimensional (3D) building data, including geometric attributes like rooftop, height, and structure, as well as indicative attributes like function, quality, and age, is essential for accurate urban analysis, simulations, and policy updates. Existing large-scale building datasets lack accuracy, extensibility and indicative attributes. This paper presents a geospatial artificial intelligence (GeoAI) framework for large-scale building modeling, introducing the first Multi-Attribute Building dataset (CMAB) in China at a national scale. The dataset covers 3,667 natural cities with a total rooftop area of 21.3 billion square meters with an F1-Score of 89.93% in rooftop extraction through the OCRNet. We trained bootstrap aggregated XGBoost models with city administrative classifications, incorporating building features such as morphology, location, and function. Using multi-source data, including billions of high-resolution Google Earth imagery and 60 million street view images (SVI), we generated rooftop, height, function, age, and quality attributes for each building. Accuracy was validated through model benchmarks, existing similar products, and manual SVI validation. The results support urban planning and sustainable development.</li>
</ul>

<h3>Title: Polyp SAM 2: Advancing Zero shot Polyp Segmentation in Colorectal Cancer Detection</h3>
<ul>
<li><strong>Authors: </strong>Mobina Mansoori, Sajjad Shahabodini, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05892">https://arxiv.org/abs/2408.05892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05892">https://arxiv.org/pdf/2408.05892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05892]] Polyp SAM 2: Advancing Zero shot Polyp Segmentation in Colorectal Cancer Detection(https://arxiv.org/abs/2408.05892)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Polyp segmentation plays a crucial role in the early detection and diagnosis of colorectal cancer. However, obtaining accurate segmentations often requires labor-intensive annotations and specialized models. Recently, Meta AI Research released a general Segment Anything Model 2 (SAM 2), which has demonstrated promising performance in several segmentation tasks. In this work, we evaluate the performance of SAM 2 in segmenting polyps under various prompted settings. We hope this report will provide insights to advance the field of polyp segmentation and promote more interesting work in the future. This project is publicly available at this https URL sajjad-sh33/Polyp-SAM-2.</li>
</ul>

<h3>Title: GlyphPattern: An Abstract Pattern Recognition for Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zixuan Wu, Yoolim Kim, Carolyn Jane Anderson</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05894">https://arxiv.org/abs/2408.05894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05894">https://arxiv.org/pdf/2408.05894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05894]] GlyphPattern: An Abstract Pattern Recognition for Vision-Language Models(https://arxiv.org/abs/2408.05894)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) building upon the foundation of powerful large language models have made rapid progress in reasoning across visual and textual data. While VLMs perform well on vision tasks that they are trained on, our results highlight key challenges in abstract pattern recognition. We present GlyphPattern, a 954 item dataset that pairs 318 human-written descriptions of visual patterns from 40 writing systems with three visual presentation styles. GlyphPattern evaluates abstract pattern recognition in VLMs, requiring models to understand and judge natural language descriptions of visual patterns. GlyphPattern patterns are drawn from a large-scale cognitive science investigation of human writing systems; as a result, they are rich in spatial reference and compositionality. Our experiments show that GlyphPattern is challenging for state-of-the-art VLMs (GPT-4o achieves only 55% accuracy), with marginal gains from few-shot prompting. Our detailed error analysis reveals challenges at multiple levels, including visual processing, natural language understanding, and pattern generalization.</li>
</ul>

<h3>Title: Classifier Guidance Enhances Diffusion-based Adversarial Purification by Preserving Predictive Information</h3>
<ul>
<li><strong>Authors: </strong>Mingkun Zhang, Jianing Li, Wei Chen, Jiafeng Guo, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05900">https://arxiv.org/abs/2408.05900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05900">https://arxiv.org/pdf/2408.05900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05900]] Classifier Guidance Enhances Diffusion-based Adversarial Purification by Preserving Predictive Information(https://arxiv.org/abs/2408.05900)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Adversarial purification is one of the promising approaches to defend neural networks against adversarial attacks. Recently, methods utilizing diffusion probabilistic models have achieved great success for adversarial purification in image classification tasks. However, such methods fall into the dilemma of balancing the needs for noise removal and information preservation. This paper points out that existing adversarial purification methods based on diffusion models gradually lose sample information during the core denoising process, causing occasional label shift in subsequent classification tasks. As a remedy, we suggest to suppress such information loss by introducing guidance from the classifier confidence. Specifically, we propose Classifier-cOnfidence gUided Purification (COUP) algorithm, which purifies adversarial examples while keeping away from the classifier decision boundary. Experimental results show that COUP can achieve better adversarial robustness under strong attack methods.</li>
</ul>

<h3>Title: HcNet: Image Modeling with Heat Conduction Equation</h3>
<ul>
<li><strong>Authors: </strong>Zhemin Zhang, Xun Gong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05901">https://arxiv.org/abs/2408.05901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05901">https://arxiv.org/pdf/2408.05901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05901]] HcNet: Image Modeling with Heat Conduction Equation(https://arxiv.org/abs/2408.05901)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Foundation models, such as CNNs and ViTs, have powered the development of image modeling. However, general guidance to model architecture design is still missing. The design of many modern model architectures, such as residual structures, multiplicative gating signal, and feed-forward networks, can be interpreted in terms of the heat conduction equation. This finding inspired us to model images by the heat conduction equation, where the essential idea is to conceptualize image features as temperatures and model their information interaction as the diffusion of thermal energy. We can take advantage of the rich knowledge in the heat conduction equation to guide us in designing new and more interpretable models. As an example, we propose Heat Conduction Layer and Refine Approximation Layer inspired by solving the heat conduction equation using Finite Difference Method and Fourier series, respectively. This paper does not aim to present a state-of-the-art model; instead, it seeks to integrate the overall architectural design of the model into the heat conduction theory framework. Nevertheless, our Heat Conduction Network (HcNet) still shows competitive performance. Code available at \url{this https URL}.</li>
</ul>

<h3>Title: A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Chih-Wei Song, Yu-Kai Lee, Yin-Te Tsai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05911">https://arxiv.org/abs/2408.05911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05911">https://arxiv.org/pdf/2408.05911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05911]] A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning(https://arxiv.org/abs/2408.05911)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid development of large language models in recent years, there has been an increasing demand for domain-specific Agents that can cater to the unique needs of enterprises and organizations. Unlike general models, which strive for broad coverage, these specialized Agents rely on focused datasets tailored to their intended applications. This research proposes a pipeline that leverages the power of LLMs and the Retrieval-Augmented Generation related framework to construct high-quality instruction datasets for fine-tuning on specific domains using custom document collections. By ingesting domain-specific documents, the pipeline generates relevant and contextually appropriate instructions, thus effectively creating a comprehensive dataset for fine-tuning LLMs on the target domain. This approach overcomes the limitations of traditional dataset creation methods, which often rely on manual curation or web-scraping techniques that may introduce noise and irrelevant data. Notably, our pipeline offers a dynamic solution that can quickly adapt to updates or modifications in the domain-specific document collection, eliminating the need for complete retraining. Additionally, it addresses the challenge of data scarcity by enabling the generation of instruction datasets from a limited set of initial documents, rendering it suitable for unpopular or specialized domains where comprehensive datasets are scarce. As a case study, we apply this approach to the domain of psychiatry, a field requiring specialized knowledge and sensitive handling of patient information. The resulting fine-tuned LLM demonstrates showcases the viability of the proposed approach and underscores its potential for widespread adoption across various industries and domains where tailored, accurate, and contextually relevant language models are indispensable.</li>
</ul>

<h3>Title: Cluster-Segregate-Perturb (CSP): A Model-agnostic Explainability Pipeline for Spatiotemporal Land Surface Forecasting Models</h3>
<ul>
<li><strong>Authors: </strong>Tushar Verma, Sudipan Saha</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05916">https://arxiv.org/abs/2408.05916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05916">https://arxiv.org/pdf/2408.05916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05916]] Cluster-Segregate-Perturb (CSP): A Model-agnostic Explainability Pipeline for Spatiotemporal Land Surface Forecasting Models(https://arxiv.org/abs/2408.05916)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Satellite images have become increasingly valuable for modelling regional climate change effects. Earth surface forecasting represents one such task that integrates satellite images with meteorological data to capture the joint evolution of regional climate change effects. However, understanding the complex relationship between specific meteorological variables and land surface evolution poses a significant challenge. In light of this challenge, our paper introduces a pipeline that integrates principles from both perturbation-based explainability techniques like LIME and global marginal explainability techniques like PDP, besides addressing the constraints of using such techniques when applying them to high-dimensional spatiotemporal deep models. The proposed pipeline simplifies the undertaking of diverse investigative analyses, such as marginal sensitivity analysis, marginal correlation analysis, lag analysis, etc., on complex land surface forecasting models In this study we utilised Convolutional Long Short-Term Memory (ConvLSTM) as the surface forecasting model and did analyses on the Normalized Difference Vegetation Index (NDVI) of the surface forecasts, since meteorological variables like temperature, pressure, and precipitation significantly influence it. The study area encompasses various regions in Europe. Our analyses show that precipitation exhibits the highest sensitivity in the study area, followed by temperature and pressure. Pressure has little to no direct effect on NDVI. Additionally, interesting nonlinear correlations between meteorological variables and NDVI have been uncovered.</li>
</ul>

<h3>Title: PAFormer: Part Aware Transformer for Person Re-identification</h3>
<ul>
<li><strong>Authors: </strong>Hyeono Jung, Jangwon Lee, Jiwon Yoo, Dami Ko, Gyeonghwan Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05918">https://arxiv.org/abs/2408.05918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05918">https://arxiv.org/pdf/2408.05918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05918]] PAFormer: Part Aware Transformer for Person Re-identification(https://arxiv.org/abs/2408.05918)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Within the domain of person re-identification (ReID), partial ReID methods are considered mainstream, aiming to measure feature distances through comparisons of body parts between samples. However, in practice, previous methods often lack sufficient awareness of anatomical aspect of body parts, resulting in the failure to capture features of the same body parts across different samples. To address this issue, we introduce \textbf{Part Aware Transformer (PAFormer)}, a pose estimation based ReID model which can perform precise part-to-part comparison. In order to inject part awareness to pose tokens, we introduce learnable parameters called `pose token' which estimate the correlation between each body part and partial regions of the image. Notably, at inference phase, PAFormer operates without additional modules related to body part localization, which is commonly used in previous ReID methodologies leveraging pose estimation models. Additionally, leveraging the enhanced awareness of body parts, PAFormer suggests the use of a learning-based visibility predictor to estimate the degree of occlusion for each body part. Also, we introduce a teacher forcing technique using ground truth visibility scores which enables PAFormer to be trained only with visible parts. A set of extensive experiments show that our method outperforms existing approaches on well-known ReID benchmark datasets.</li>
</ul>

<h3>Title: A Simple Early Exiting Framework for Accelerated Sampling in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Taehong Moon, Moonseok Choi, EungGu Yun, Jongmin Yoon, Gayoung Lee, Jaewoong Cho, Juho Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05927">https://arxiv.org/abs/2408.05927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05927">https://arxiv.org/pdf/2408.05927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05927]] A Simple Early Exiting Framework for Accelerated Sampling in Diffusion Models(https://arxiv.org/abs/2408.05927)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have shown remarkable performance in generation problems over various domains including images, videos, text, and audio. A practical bottleneck of diffusion models is their sampling speed, due to the repeated evaluation of score estimation networks during the inference. In this work, we propose a novel framework capable of adaptively allocating compute required for the score estimation, thereby reducing the overall sampling time of diffusion models. We observe that the amount of computation required for the score estimation may vary along the time step for which the score is estimated. Based on this observation, we propose an early-exiting scheme, where we skip the subset of parameters in the score estimation network during the inference, based on a time-dependent exit schedule. Using the diffusion models for image synthesis, we show that our method could significantly improve the sampling throughput of the diffusion models without compromising image quality. Furthermore, we also demonstrate that our method seamlessly integrates with various types of solvers for faster sampling, capitalizing on their compatibility to enhance overall efficiency. The source code and our experiments are available at \url{this https URL}</li>
</ul>

<h3>Title: Multi-scale Contrastive Adaptor Learning for Segmenting Anything in Underperformed Scenes</h3>
<ul>
<li><strong>Authors: </strong>Ke Zhou, Zhongwei Qiu, Dongmei Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05936">https://arxiv.org/abs/2408.05936</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05936">https://arxiv.org/pdf/2408.05936</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05936]] Multi-scale Contrastive Adaptor Learning for Segmenting Anything in Underperformed Scenes(https://arxiv.org/abs/2408.05936)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Foundational vision models, such as the Segment Anything Model (SAM), have achieved significant breakthroughs through extensive pre-training on large-scale visual datasets. Despite their general success, these models may fall short in specialized tasks with limited data, and fine-tuning such large-scale models is often not feasible. Current strategies involve incorporating adaptors into the pre-trained SAM to facilitate downstream task performance with minimal model adjustment. However, these strategies can be hampered by suboptimal learning approaches for the adaptors. In this paper, we introduce a novel Multi-scale Contrastive Adaptor learning method named MCA-SAM, which enhances adaptor performance through a meticulously designed contrastive learning framework at both token and sample levels. Our Token-level Contrastive adaptor (TC-adaptor) focuses on refining local representations by improving the discriminability of patch tokens, while the Sample-level Contrastive adaptor (SC-adaptor) amplifies global understanding across different samples. Together, these adaptors synergistically enhance feature comparison within and across samples, bolstering the model's representational strength and its ability to adapt to new tasks. Empirical results demonstrate that MCA-SAM sets new benchmarks, outperforming existing methods in three challenging domains: camouflage object detection, shadow segmentation, and polyp segmentation. Specifically, MCA-SAM exhibits substantial relative performance enhancements, achieving a 20.0% improvement in MAE on the COD10K dataset, a 6.0% improvement in MAE on the CAMO dataset, a 15.4% improvement in BER on the ISTD dataset, and a 7.9% improvement in mDice on the Kvasir-SEG dataset.</li>
</ul>

<h3>Title: Deep Geometric Moments Promote Shape Consistency in Text-to-3D Generation</h3>
<ul>
<li><strong>Authors: </strong>Utkarsh Nath, Rajeev Goel, Eun Som Jeon, Changhoon Kim, Kyle Min, Yezhou Yang, Yingzhen Yang, Pavan Turaga</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05938">https://arxiv.org/abs/2408.05938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05938">https://arxiv.org/pdf/2408.05938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05938]] Deep Geometric Moments Promote Shape Consistency in Text-to-3D Generation(https://arxiv.org/abs/2408.05938)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>To address the data scarcity associated with 3D assets, 2D-lifting techniques such as Score Distillation Sampling (SDS) have become a widely adopted practice in text-to-3D generation pipelines. However, the diffusion models used in these techniques are prone to viewpoint bias and thus lead to geometric inconsistencies such as the Janus problem. To counter this, we introduce MT3D, a text-to-3D generative model that leverages a high-fidelity 3D object to overcome viewpoint bias and explicitly infuse geometric understanding into the generation pipeline. Firstly, we employ depth maps derived from a high-quality 3D model as control signals to guarantee that the generated 2D images preserve the fundamental shape and structure, thereby reducing the inherent viewpoint bias. Next, we utilize deep geometric moments to ensure geometric consistency in the 3D representation explicitly. By incorporating geometric details from a 3D asset, MT3D enables the creation of diverse and geometrically consistent objects, thereby improving the quality and usability of our 3D representations.</li>
</ul>

<h3>Title: UniPortrait: A Unified Framework for Identity-Preserving Single- and Multi-Human Image Personalization</h3>
<ul>
<li><strong>Authors: </strong>Junjie He, Yifeng Geng, Liefeng Bo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05939">https://arxiv.org/abs/2408.05939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05939">https://arxiv.org/pdf/2408.05939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05939]] UniPortrait: A Unified Framework for Identity-Preserving Single- and Multi-Human Image Personalization(https://arxiv.org/abs/2408.05939)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper presents UniPortrait, an innovative human image personalization framework that unifies single- and multi-ID customization with high face fidelity, extensive facial editability, free-form input description, and diverse layout generation. UniPortrait consists of only two plug-and-play modules: an ID embedding module and an ID routing module. The ID embedding module extracts versatile editable facial features with a decoupling strategy for each ID and embeds them into the context space of diffusion models. The ID routing module then combines and distributes these embeddings adaptively to their respective regions within the synthesized image, achieving the customization of single and multiple IDs. With a carefully designed two-stage training scheme, UniPortrait achieves superior performance in both single- and multi-ID customization. Quantitative and qualitative experiments demonstrate the advantages of our method over existing approaches as well as its good scalability, e.g., the universal compatibility with existing generative control tools. The project page is at this https URL .</li>
</ul>

<h3>Title: Spb3DTracker: A Robust LiDAR-Based Person Tracker for Noisy Environmen</h3>
<ul>
<li><strong>Authors: </strong>Eunsoo Im, Changhyun Jee, Jung Kwon Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05940">https://arxiv.org/abs/2408.05940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05940">https://arxiv.org/pdf/2408.05940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05940]] Spb3DTracker: A Robust LiDAR-Based Person Tracker for Noisy Environmen(https://arxiv.org/abs/2408.05940)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Person detection and tracking (PDT) has seen significant advancements with 2D camera-based systems in the autonomous vehicle field, leading to widespread adoption of these algorithms. However, growing privacy concerns have recently emerged as a major issue, prompting a shift towards LiDAR-based PDT as a viable alternative. Within this domain, "Tracking-by-Detection" (TBD) has become a prominent methodology. Despite its effectiveness, LiDAR-based PDT has not yet achieved the same level of performance as camera-based PDT. This paper examines key components of the LiDAR-based PDT framework, including detection post-processing, data association, motion modeling, and lifecycle management. Building upon these insights, we introduce SpbTrack, a robust person tracker designed for diverse environments. Our method achieves superior performance on noisy datasets and state-of-the-art results on KITTI Dataset benchmarks and custom office indoor dataset among LiDAR-based trackers. Project page at anonymous.</li>
</ul>

<h3>Title: Multimodal Large Language Models for Phishing Webpage Detection and Identification</h3>
<ul>
<li><strong>Authors: </strong>Jehyun Lee, Peiyuan Lim, Bryan Hooi, Dinil Mon Divakaran</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05941">https://arxiv.org/abs/2408.05941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05941">https://arxiv.org/pdf/2408.05941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05941]] Multimodal Large Language Models for Phishing Webpage Detection and Identification(https://arxiv.org/abs/2408.05941)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>To address the challenging problem of detecting phishing webpages, researchers have developed numerous solutions, in particular those based on machine learning (ML) algorithms. Among these, brand-based phishing detection that uses models from Computer Vision to detect if a given webpage is imitating a well-known brand has received widespread attention. However, such models are costly and difficult to maintain, as they need to be retrained with labeled dataset that has to be regularly and continuously collected. Besides, they also need to maintain a good reference list of well-known websites and related meta-data for effective performance. In this work, we take steps to study the efficacy of large language models (LLMs), in particular the multimodal LLMs, in detecting phishing webpages. Given that the LLMs are pretrained on a large corpus of data, we aim to make use of their understanding of different aspects of a webpage (logo, theme, favicon, etc.) to identify the brand of a given webpage and compare the identified brand with the domain name in the URL to detect a phishing attack. We propose a two-phase system employing LLMs in both phases: the first phase focuses on brand identification, while the second verifies the domain. We carry out comprehensive evaluations on a newly collected dataset. Our experiments show that the LLM-based system achieves a high detection rate at high precision; importantly, it also provides interpretable evidence for the decisions. Our system also performs significantly better than a state-of-the-art brand-based phishing detection system while demonstrating robustness against two known adversarial attacks.</li>
</ul>

<h3>Title: MV2DFusion: Leveraging Modality-Specific Object Semantics for Multi-Modal 3D Detection</h3>
<ul>
<li><strong>Authors: </strong>Zitian Wang, Zehao Huang, Yulu Gao, Naiyan Wang, Si Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05945">https://arxiv.org/abs/2408.05945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05945">https://arxiv.org/pdf/2408.05945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05945]] MV2DFusion: Leveraging Modality-Specific Object Semantics for Multi-Modal 3D Detection(https://arxiv.org/abs/2408.05945)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rise of autonomous vehicles has significantly increased the demand for robust 3D object detection systems. While cameras and LiDAR sensors each offer unique advantages--cameras provide rich texture information and LiDAR offers precise 3D spatial data--relying on a single modality often leads to performance limitations. This paper introduces MV2DFusion, a multi-modal detection framework that integrates the strengths of both worlds through an advanced query-based fusion mechanism. By introducing an image query generator to align with image-specific attributes and a point cloud query generator, MV2DFusion effectively combines modality-specific object semantics without biasing toward one single modality. Then the sparse fusion process can be accomplished based on the valuable object semantics, ensuring efficient and accurate object detection across various scenarios. Our framework's flexibility allows it to integrate with any image and point cloud-based detectors, showcasing its adaptability and potential for future advancements. Extensive evaluations on the nuScenes and Argoverse2 datasets demonstrate that MV2DFusion achieves state-of-the-art performance, particularly excelling in long-range detection scenarios.</li>
</ul>

<h3>Title: ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ronak Pradeep, Daniel Lee, Ali Mousavi, Jeff Pound, Yisi Sang, Jimmy Lin, Ihab Ilyas, Saloni Potdar, Mostafa Arefiyan, Yunyao Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05948">https://arxiv.org/abs/2408.05948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05948">https://arxiv.org/pdf/2408.05948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05948]] ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models(https://arxiv.org/abs/2408.05948)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Large Language Models (LLMs) and conversational assistants necessitates dynamic, scalable, and configurable conversational datasets for training and evaluation. These datasets must accommodate diverse user interaction modes, including text and voice, each presenting unique modeling challenges. Knowledge Graphs (KGs), with their structured and evolving nature, offer an ideal foundation for current and precise knowledge. Although human-curated KG-based conversational datasets exist, they struggle to keep pace with the rapidly changing user information needs. We present ConvKGYarn, a scalable method for generating up-to-date and configurable conversational KGQA datasets. Qualitative psychometric analyses confirm our method can generate high-quality datasets rivaling a popular conversational KGQA dataset while offering it at scale and covering a wide range of human-interaction configurations. We showcase its utility by testing LLMs on diverse conversations - exploring model behavior on conversational KGQA sets with different configurations grounded in the same KG fact set. Our results highlight the ability of ConvKGYarn to improve KGQA foundations and evaluate parametric knowledge of LLMs, thus offering a robust solution to the constantly evolving landscape of conversational assistants.</li>
</ul>

<h3>Title: Optimizing Vision Transformers with Data-Free Knowledge Transfer</h3>
<ul>
<li><strong>Authors: </strong>Gousia Habib, Damandeep Singh, Ishfaq Ahmad Malik, Brejesh Lall</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05952">https://arxiv.org/abs/2408.05952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05952">https://arxiv.org/pdf/2408.05952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05952]] Optimizing Vision Transformers with Data-Free Knowledge Transfer(https://arxiv.org/abs/2408.05952)</code><input type="text"></li>
<li><strong>Keywords: </strong>data-free, transformer</a></li>
<li><strong>Abstract: </strong>The groundbreaking performance of transformers in Natural Language Processing (NLP) tasks has led to their replacement of traditional Convolutional Neural Networks (CNNs), owing to the efficiency and accuracy achieved through the self-attention mechanism. This success has inspired researchers to explore the use of transformers in computer vision tasks to attain enhanced long-term semantic awareness. Vision transformers (ViTs) have excelled in various computer vision tasks due to their superior ability to capture long-distance dependencies using the self-attention mechanism. Contemporary ViTs like Data Efficient Transformers (DeiT) can effectively learn both global semantic information and local texture information from images, achieving performance comparable to traditional CNNs. However, their impressive performance comes with a high computational cost due to very large number of parameters, hindering their deployment on devices with limited resources like smartphones, cameras, drones etc. Additionally, ViTs require a large amount of data for training to achieve performance comparable to benchmark CNN models. Therefore, we identified two key challenges in deploying ViTs on smaller form factor devices: the high computational requirements of large models and the need for extensive training data. As a solution to these challenges, we propose compressing large ViT models using Knowledge Distillation (KD), which is implemented data-free to circumvent limitations related to data availability. Additionally, we conducted experiments on object detection within the same environment in addition to classification tasks. Based on our analysis, we found that datafree knowledge distillation is an effective method to overcome both issues, enabling the deployment of ViTs on less resourceconstrained devices.</li>
</ul>

<h3>Title: Boosting Adverse Weather Crowd Counting via Multi-queue Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Tianhang Pan, Zhuoran Zheng, Xiuyi Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05956">https://arxiv.org/abs/2408.05956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05956">https://arxiv.org/pdf/2408.05956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05956]] Boosting Adverse Weather Crowd Counting via Multi-queue Contrastive Learning(https://arxiv.org/abs/2408.05956)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Currently, most crowd counting methods have outstanding performance under normal weather conditions. However, they often struggle to maintain their performance in extreme and adverse weather conditions due to significant differences in the domain and a lack of adverse weather images for training. To address this issue and enhance the model's robustness in adverse weather, we propose a two-stage crowd counting method. Specifically, in the first stage, we introduce a multi-queue MoCo contrastive learning strategy to tackle the problem of weather class imbalance. This strategy facilitates the learning of weather-aware representations by the model. In the second stage, we propose to refine the representations under the guidance of contrastive learning, enabling the conversion of the weather-aware representations to the normal weather domain. While significantly improving the robustness, our method only marginally increases the weight of the model. In addition, we also create a new synthetic adverse weather dataset. Extensive experimental results show that our method achieves competitive performance.</li>
</ul>

<h3>Title: Target Detection of Safety Protective Gear Using the Improved YOLOv5</h3>
<ul>
<li><strong>Authors: </strong>Hao Liu, Xue Qin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05964">https://arxiv.org/abs/2408.05964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05964">https://arxiv.org/pdf/2408.05964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05964]] Target Detection of Safety Protective Gear Using the Improved YOLOv5(https://arxiv.org/abs/2408.05964)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>In high-risk railway construction, personal protective equipment monitoring is critical but challenging due to small and frequently obstructed targets. We propose YOLO-EA, an innovative model that enhances safety measure detection by integrating ECA into its backbone's convolutional layers, improving discernment of minuscule objects like hardhats. YOLO-EA further refines target recognition under occlusion by replacing GIoU with EIoU loss. YOLO-EA's effectiveness was empirically substantiated using a dataset derived from real-world railway construction site surveillance footage. It outperforms YOLOv5, achieving 98.9% precision and 94.7% recall, up 2.5% and 0.5% respectively, while maintaining real-time performance at 70.774 fps. This highly efficient and precise YOLO-EA holds great promise for practical application in intricate construction scenarios, enforcing stringent safety compliance during complex railway construction projects.</li>
</ul>

<h3>Title: Freehand Sketch Generation from Mechanical Components</h3>
<ul>
<li><strong>Authors: </strong>Zhichao Liao, Di Huang, Heming Fang, Yue Ma, Fengyuan Piao, Xinghui Li, Long Zeng, Pingfa Feng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05966">https://arxiv.org/abs/2408.05966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05966">https://arxiv.org/pdf/2408.05966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05966]] Freehand Sketch Generation from Mechanical Components(https://arxiv.org/abs/2408.05966)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>Drawing freehand sketches of mechanical components on multimedia devices for AI-based engineering modeling has become a new trend. However, its development is being impeded because existing works cannot produce suitable sketches for data-driven research. These works either generate sketches lacking a freehand style or utilize generative models not originally designed for this task resulting in poor effectiveness. To address this issue, we design a two-stage generative framework mimicking the human sketching behavior pattern, called MSFormer, which is the first time to produce humanoid freehand sketches tailored for mechanical components. The first stage employs Open CASCADE technology to obtain multi-view contour sketches from mechanical components, filtering perturbing signals for the ensuing generation process. Meanwhile, we design a view selector to simulate viewpoint selection tasks during human sketching for picking out information-rich sketches. The second stage translates contour sketches into freehand sketches by a transformer-based generator. To retain essential modeling features as much as possible and rationalize stroke distribution, we introduce a novel edge-constraint stroke initialization. Furthermore, we utilize a CLIP vision encoder and a new loss function incorporating the Hausdorff distance to enhance the generalizability and robustness of the model. Extensive experiments demonstrate that our approach achieves state-of-the-art performance for generating freehand sketches in the mechanical domain. Project page: this https URL .</li>
</ul>

<h3>Title: Nob-MIAs: Non-biased Membership Inference Attacks Assessment on Large Language Models with Ex-Post Dataset Construction</h3>
<ul>
<li><strong>Authors: </strong>Cédric Eichler, Nathan Champeil, Nicolas Anciaux, Alexandra Bensamoun, Heber Hwang Arcolezi, José Maria De Fuentes</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05968">https://arxiv.org/abs/2408.05968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05968">https://arxiv.org/pdf/2408.05968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05968]] Nob-MIAs: Non-biased Membership Inference Attacks Assessment on Large Language Models with Ex-Post Dataset Construction(https://arxiv.org/abs/2408.05968)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, membership infer, fair, large language model</a></li>
<li><strong>Abstract: </strong>The rise of Large Language Models (LLMs) has triggered legal and ethical concerns, especially regarding the unauthorized use of copyrighted materials in their training datasets. This has led to lawsuits against tech companies accused of using protected content without permission. Membership Inference Attacks (MIAs) aim to detect whether specific documents were used in a given LLM pretraining, but their effectiveness is undermined by biases such as time-shifts and n-gram overlaps. This paper addresses the evaluation of MIAs on LLMs with partially inferable training sets, under the ex-post hypothesis, which acknowledges inherent distributional biases between members and non-members datasets. We propose and validate algorithms to create ``non-biased'' and ``non-classifiable'' datasets for fairer MIA assessment. Experiments using the Gutenberg dataset on OpenLamma and Pythia show that neutralizing known biases alone is insufficient. Our methods produce non-biased ex-post datasets with AUC-ROC scores comparable to those previously obtained on genuinely random datasets, validating our approach. Globally, MIAs yield results close to random, with only one being effective on both random and our datasets, but its performance decreases when bias is removed.</li>
</ul>

<h3>Title: Unseen No More: Unlocking the Potential of CLIP for Generative Zero-shot HOI Detection</h3>
<ul>
<li><strong>Authors: </strong>Yixin Guo, Yu Liu, Jianghao Li, Weimin Wang, Qi Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05974">https://arxiv.org/abs/2408.05974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05974">https://arxiv.org/pdf/2408.05974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05974]] Unseen No More: Unlocking the Potential of CLIP for Generative Zero-shot HOI Detection(https://arxiv.org/abs/2408.05974)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Zero-shot human-object interaction (HOI) detector is capable of generalizing to HOI categories even not encountered during training. Inspired by the impressive zero-shot capabilities offered by CLIP, latest methods strive to leverage CLIP embeddings for improving zero-shot HOI detection. However, these embedding-based methods train the classifier on seen classes only, inevitably resulting in seen-unseen confusion for the model during inference. Besides, we find that using prompt-tuning and adapters further increases the gap between seen and unseen accuracy. To tackle this challenge, we present the first generation-based model using CLIP for zero-shot HOI detection, coined HOIGen. It allows to unlock the potential of CLIP for feature generation instead of feature extraction only. To achieve it, we develop a CLIP-injected feature generator in accordance with the generation of human, object and union features. Then, we extract realistic features of seen samples and mix them with synthetic features together, allowing the model to train seen and unseen classes jointly. To enrich the HOI scores, we construct a generative prototype bank in a pairwise HOI recognition branch, and a multi-knowledge prototype bank in an image-wise HOI recognition branch, respectively. Extensive experiments on HICO-DET benchmark demonstrate our HOIGen achieves superior performance for both seen and unseen classes under various zero-shot settings, compared with other top-performing methods. Code is available at: this https URL</li>
</ul>

<h3>Title: Global-to-Local Support Spectrums for Language Model Explainability</h3>
<ul>
<li><strong>Authors: </strong>Lucas Agussurja, Xinyang Lu, Bryan Kian Hsiang Low</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05976">https://arxiv.org/abs/2408.05976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05976">https://arxiv.org/pdf/2408.05976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05976]] Global-to-Local Support Spectrums for Language Model Explainability(https://arxiv.org/abs/2408.05976)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Existing sample-based methods, like influence functions and representer points, measure the importance of a training point by approximating the effect of its removal from training. As such, they are skewed towards outliers and points that are very close to the decision boundaries. The explanations provided by these methods are often static and not specific enough for different test points. In this paper, we propose a method to generate an explanation in the form of support spectrums which are based on two main ideas: the support sets and a global-to-local importance measure. The support set is the set of training points, in the predicted class, that ``lie in between'' the test point and training points in the other classes. They indicate how well the test point can be distinguished from the points not in the predicted class. The global-to-local importance measure is obtained by decoupling existing methods into the global and local components which are then used to select the points in the support set. Using this method, we are able to generate explanations that are tailored to specific test points. In the experiments, we show the effectiveness of the method in image classification and text generation tasks.</li>
</ul>

<h3>Title: The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI</h3>
<ul>
<li><strong>Authors: </strong>Miriam Schirmer, Tobias Leemann, Gjergji Kasneci, Jürgen Pfeffer, David Jurgens</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05977">https://arxiv.org/abs/2408.05977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05977">https://arxiv.org/pdf/2408.05977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05977]] The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI(https://arxiv.org/abs/2408.05977)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Psychological trauma can manifest following various distressing events and is captured in diverse online contexts. However, studies traditionally focus on a single aspect of trauma, often neglecting the transferability of findings across different scenarios. We address this gap by training language models with progressing complexity on trauma-related datasets, including genocide-related court data, a Reddit dataset on post-traumatic stress disorder (PTSD), counseling conversations, and Incel forum posts. Our results show that the fine-tuned RoBERTa model excels in predicting traumatic events across domains, slightly outperforming large language models like GPT-4. Additionally, SLALOM-feature scores and conceptual explanations effectively differentiate and cluster trauma-related language, highlighting different trauma aspects and identifying sexual abuse and experiences related to death as a common traumatic event across all datasets. This transferability is crucial as it allows for the development of tools to enhance trauma detection and intervention in diverse populations and settings.</li>
</ul>

<h3>Title: Diffuse-UDA: Addressing Unsupervised Domain Adaptation in Medical Image Segmentation with Appearance and Structure Aligned Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Haifan Gong, Yitao Wang, Yihan Wang, Jiashun Xiao, Xiang Wan, Haofeng Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05985">https://arxiv.org/abs/2408.05985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05985">https://arxiv.org/pdf/2408.05985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05985]] Diffuse-UDA: Addressing Unsupervised Domain Adaptation in Medical Image Segmentation with Appearance and Structure Aligned Diffusion Models(https://arxiv.org/abs/2408.05985)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>The scarcity and complexity of voxel-level annotations in 3D medical imaging present significant challenges, particularly due to the domain gap between labeled datasets from well-resourced centers and unlabeled datasets from less-resourced centers. This disparity affects the fairness of artificial intelligence algorithms in healthcare. We introduce Diffuse-UDA, a novel method leveraging diffusion models to tackle Unsupervised Domain Adaptation (UDA) in medical image segmentation. Diffuse-UDA generates high-quality image-mask pairs with target domain characteristics and various structures, thereby enhancing UDA tasks. Initially, pseudo labels for target domain samples are generated. Subsequently, a specially tailored diffusion model, incorporating deformable augmentations, is trained on image-label or image-pseudo-label pairs from both domains. Finally, source domain labels guide the diffusion model to generate image-label pairs for the target domain. Comprehensive evaluations on several benchmarks demonstrate that Diffuse-UDA outperforms leading UDA and semi-supervised strategies, achieving performance close to or even surpassing the theoretical upper bound of models trained directly on target domain data. Diffuse-UDA offers a pathway to advance the development and deployment of AI systems in medical imaging, addressing disparities between healthcare environments. This approach enables the exploration of innovative AI-driven diagnostic tools, improves outcomes, saves time, and reduces human error.</li>
</ul>

<h3>Title: Formalizing the Cryptographic Migration Problem</h3>
<ul>
<li><strong>Authors: </strong>Daniel Loebenberger, Stefan-Lukas Gazdag, Daniel Herzinger, Eduard Hirsch, Christian Näther</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05997">https://arxiv.org/abs/2408.05997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05997">https://arxiv.org/pdf/2408.05997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05997]] Formalizing the Cryptographic Migration Problem(https://arxiv.org/abs/2408.05997)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>With the advancements in quantum computing, transitioning to post-quantum cryptography is becoming increasingly critical to maintain the security of modern systems. This paper introduces a formal definition of the cryptographic migration problem and explores its complexities using a suitable directed graph model. Characteristics of the resulting migration graphs are analyzed and trade-offs discussed. By using classical mathematical results from combinatorics, probability theory and combinatorial analysis, we assess the challenges of migrating ``random'' large cryptographic IT-infrastructures. We show that any sufficiently large migration project that follows our model has an intrinsic complexity, either due to many dependent (comparatively easy) migration steps or due to at least one complicated migration step. This proves that in a suitable sense cryptographic migration is hard in general.</li>
</ul>

<h3>Title: An Analysis for Image-to-Image Translation and Style Transfer</h3>
<ul>
<li><strong>Authors: </strong>Xiaoming Yu, Jie Tian, Zhenhua Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06000">https://arxiv.org/abs/2408.06000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06000">https://arxiv.org/pdf/2408.06000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06000]] An Analysis for Image-to-Image Translation and Style Transfer(https://arxiv.org/abs/2408.06000)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>With the development of generative technologies in deep learning, a large number of image-to-image translation and style transfer models have emerged at an explosive rate in recent years. These two technologies have made significant progress and can generate realistic images. However, many communities tend to confuse the two, because both generate the desired image based on the input image and both cover the two definitions of content and style. In fact, there are indeed significant differences between the two, and there is currently a lack of clear explanations to distinguish the two technologies, which is not conducive to the advancement of technology. We hope to serve the entire community by introducing the differences and connections between image-to-image translation and style transfer. The entire discussion process involves the concepts, forms, training modes, evaluation processes, and visualization results of the two technologies. Finally, we conclude that image-to-image translation divides images by domain, and the types of images in the domain are limited, and the scope involved is small, but the conversion ability is strong and can achieve strong semantic changes. Style transfer divides image types by single image, and the scope involved is large, but the transfer ability is limited, and it transfers more texture and color of the image.</li>
</ul>

<h3>Title: DEEPTalk: Dynamic Emotion Embedding for Probabilistic Speech-Driven 3D Face Animation</h3>
<ul>
<li><strong>Authors: </strong>Jisoo Kim, Jungbin Cho, Joonho Park, Soonmin Hwang, Da Eun Kim, Geon Kim, Youngjae Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06010">https://arxiv.org/abs/2408.06010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06010">https://arxiv.org/pdf/2408.06010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06010]] DEEPTalk: Dynamic Emotion Embedding for Probabilistic Speech-Driven 3D Face Animation(https://arxiv.org/abs/2408.06010)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Speech-driven 3D facial animation has garnered lots of attention thanks to its broad range of applications. Despite recent advancements in achieving realistic lip motion, current methods fail to capture the nuanced emotional undertones conveyed through speech and produce monotonous facial motion. These limitations result in blunt and repetitive facial animations, reducing user engagement and hindering their applicability. To address these challenges, we introduce DEEPTalk, a novel approach that generates diverse and emotionally rich 3D facial expressions directly from speech inputs. To achieve this, we first train DEE (Dynamic Emotion Embedding), which employs probabilistic contrastive learning to forge a joint emotion embedding space for both speech and facial motion. This probabilistic framework captures the uncertainty in interpreting emotions from speech and facial motion, enabling the derivation of emotion vectors from its multifaceted space. Moreover, to generate dynamic facial motion, we design TH-VQVAE (Temporally Hierarchical VQ-VAE) as an expressive and robust motion prior overcoming limitations of VAEs and VQ-VAEs. Utilizing these strong priors, we develop DEEPTalk, A talking head generator that non-autoregressively predicts codebook indices to create dynamic facial motion, incorporating a novel emotion consistency loss. Extensive experiments on various datasets demonstrate the effectiveness of our approach in creating diverse, emotionally expressive talking faces that maintain accurate lip-sync. Source code will be made publicly available soon.</li>
</ul>

<h3>Title: HeadGAP: Few-shot 3D Head Avatar via Generalizable Gaussian Priors</h3>
<ul>
<li><strong>Authors: </strong>Xiaozheng Zheng, Chao Wen, Zhaohu Li, Weiyi Zhang, Zhuo Su, Xu Chang, Yang Zhao, Zheng Lv, Xiaoyuan Zhang, Yongjie Zhang, Guidong Wang, Lan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06019">https://arxiv.org/abs/2408.06019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06019">https://arxiv.org/pdf/2408.06019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06019]] HeadGAP: Few-shot 3D Head Avatar via Generalizable Gaussian Priors(https://arxiv.org/abs/2408.06019)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present a novel 3D head avatar creation approach capable of generalizing from few-shot in-the-wild data with high-fidelity and animatable robustness. Given the underconstrained nature of this problem, incorporating prior knowledge is essential. Therefore, we propose a framework comprising prior learning and avatar creation phases. The prior learning phase leverages 3D head priors derived from a large-scale multi-view dynamic dataset, and the avatar creation phase applies these priors for few-shot personalization. Our approach effectively captures these priors by utilizing a Gaussian Splatting-based auto-decoder network with part-based dynamic modeling. Our method employs identity-shared encoding with personalized latent codes for individual identities to learn the attributes of Gaussian primitives. During the avatar creation phase, we achieve fast head avatar personalization by leveraging inversion and fine-tuning strategies. Extensive experiments demonstrate that our model effectively exploits head priors and successfully generalizes them to few-shot personalization, achieving photo-realistic rendering quality, multi-view consistency, and stable animation.</li>
</ul>

<h3>Title: ClickAttention: Click Region Similarity Guided Interactive Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Long Xu, Shanghong Li, Yongquan Chen, Junkang Chen, Rui Huang, Feng Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06021">https://arxiv.org/abs/2408.06021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06021">https://arxiv.org/pdf/2408.06021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06021]] ClickAttention: Click Region Similarity Guided Interactive Segmentation(https://arxiv.org/abs/2408.06021)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Interactive segmentation algorithms based on click points have garnered significant attention from researchers in recent years.However, existing studies typically use sparse click maps as model inputs to segment specific target objects, which primarily affect local regions and have limited abilities to focus on the whole target object, leading to increased times of this http URL addition, most existing algorithms can not balance well between high performance and this http URL address this issue, we propose a click attention algorithm that expands the influence range of positive clicks based on the similarity between positively-clicked regions and the whole input.We also propose a discriminative affinity loss to reduce the attention coupling between positive and negative click regions to avoid an accuracy decrease caused by mutual interference between positive and negative clicks.Extensive experiments demonstrate that our approach is superior to existing methods and achieves cutting-edge performance in fewer this http URL interactive demo and all reproducible codes will be released at this https URL.</li>
</ul>

<h3>Title: Spacetime $E(n)$-Transformer: Equivariant Attention for Spatio-temporal Graphs</h3>
<ul>
<li><strong>Authors: </strong>Sergio G. Charles</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06039">https://arxiv.org/abs/2408.06039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06039">https://arxiv.org/pdf/2408.06039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06039]] Spacetime $E(n)$-Transformer: Equivariant Attention for Spatio-temporal Graphs(https://arxiv.org/abs/2408.06039)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce an $E(n)$-equivariant Transformer architecture for spatio-temporal graph data. By imposing rotation, translation, and permutation equivariance inductive biases in both space and time, we show that the Spacetime $E(n)$-Transformer (SET) outperforms purely spatial and temporal models without symmetry-preserving properties. We benchmark SET against said models on the charged $N$-body problem, a simple physical system with complex dynamics. While existing spatio-temporal graph neural networks focus on sequential modeling, we empirically demonstrate that leveraging underlying domain symmetries yields considerable improvements for modeling dynamical systems on graphs.</li>
</ul>

<h3>Title: ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers</h3>
<ul>
<li><strong>Authors: </strong>Aristi Papastavrou, Maria Lymperaiou, Giorgos Stamou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06040">https://arxiv.org/abs/2408.06040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06040">https://arxiv.org/pdf/2408.06040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06040]] ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers(https://arxiv.org/abs/2408.06040)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer, large language model</a></li>
<li><strong>Abstract: </strong>In the rapidly evolving fields of natural language processing and computer vision, Visual Word Sense Disambiguation (VWSD) stands as a critical, yet challenging task. The quest for models that can seamlessly integrate and interpret multimodal data is more pressing than ever. Imagine a system that can understand language with the depth and nuance of human cognition, while simultaneously interpreting the rich visual context of the world around it. We present ARPA, an architecture that fuses the unparalleled contextual understanding of large language models with the advanced feature extraction capabilities of transformers, which then pass through a custom Graph Neural Network (GNN) layer to learn intricate relationships and subtle nuances within the data. This innovative architecture not only sets a new benchmark in visual word disambiguation but also introduces a versatile framework poised to transform how linguistic and visual data interact by harnessing the synergistic strengths of its components, ensuring robust performance even in the most complex disambiguation scenarios. Through a series of experiments and comparative analysis, we reveal the substantial advantages of our model, underscoring its potential to redefine standards in the field. Beyond its architectural prowess, our architecture excels through experimental enrichments, including sophisticated data augmentation and multi-modal training techniques. ARPA's introduction marks a significant milestone in visual word disambiguation, offering a compelling solution that bridges the gap between linguistic and visual modalities. We invite researchers and practitioners to explore the capabilities of our model, envisioning a future where such hybrid models drive unprecedented advancements in artificial intelligence.</li>
</ul>

<h3>Title: Understanding Byzantine Robustness in Federated Learning with A Black-box Server</h3>
<ul>
<li><strong>Authors: </strong>Fangyuan Zhao, Yuexiang Xie, Xuebin Ren, Bolin Ding, Shusen Yang, Yaliang Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06042">https://arxiv.org/abs/2408.06042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06042">https://arxiv.org/pdf/2408.06042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06042]] Understanding Byzantine Robustness in Federated Learning with A Black-box Server(https://arxiv.org/abs/2408.06042)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) becomes vulnerable to Byzantine attacks where some of participators tend to damage the utility or discourage the convergence of the learned model via sending their malicious model updates. Previous works propose to apply robust rules to aggregate updates from participators against different types of Byzantine attacks, while at the same time, attackers can further design advanced Byzantine attack algorithms targeting specific aggregation rule when it is known. In practice, FL systems can involve a black-box server that makes the adopted aggregation rule inaccessible to participants, which can naturally defend or weaken some Byzantine attacks. In this paper, we provide an in-depth understanding on the Byzantine robustness of the FL system with a black-box server. Our investigation demonstrates the improved Byzantine robustness of a black-box server employing a dynamic defense strategy. We provide both empirical evidence and theoretical analysis to reveal that the black-box server can mitigate the worst-case attack impact from a maximum level to an expectation level, which is attributed to the inherent inaccessibility and randomness offered by a black-box server.The source code is available at this https URL to promote further research in the community.</li>
</ul>

<h3>Title: Enhancing Dialogue Speech Recognition with Robust Contextual Awareness via Noise Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Wonjun Lee, San Kim, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06043">https://arxiv.org/abs/2408.06043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06043">https://arxiv.org/pdf/2408.06043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06043]] Enhancing Dialogue Speech Recognition with Robust Contextual Awareness via Noise Representation Learning(https://arxiv.org/abs/2408.06043)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent dialogue systems rely on turn-based spoken interactions, requiring accurate Automatic Speech Recognition (ASR). Errors in ASR can significantly impact downstream dialogue tasks. To address this, using dialogue context from user and agent interactions for transcribing subsequent utterances has been proposed. This method incorporates the transcription of the user's speech and the agent's response as model input, using the accumulated context generated by each turn. However, this context is susceptible to ASR errors because it is generated by the ASR model in an auto-regressive fashion. Such noisy context can further degrade the benefits of context input, resulting in suboptimal ASR performance. In this paper, we introduce Context Noise Representation Learning (CNRL) to enhance robustness against noisy context, ultimately improving dialogue speech recognition accuracy. To maximize the advantage of context awareness, our approach includes decoder pre-training using text-based dialogue data and noise representation learning for a context encoder. Based on the evaluation of speech dialogues, our method shows superior results compared to baselines. Furthermore, the strength of our approach is highlighted in noisy environments where user speech is barely audible due to real-world noise, relying on contextual information to transcribe the input accurately.</li>
</ul>

<h3>Title: BooW-VTON: Boosting In-the-Wild Virtual Try-On via Mask-Free Pseudo Data Training</h3>
<ul>
<li><strong>Authors: </strong>Xuanpu Zhang, Dan Song, Pengxin Zhan, Qingguo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Anan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06047">https://arxiv.org/abs/2408.06047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06047">https://arxiv.org/pdf/2408.06047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06047]] BooW-VTON: Boosting In-the-Wild Virtual Try-On via Mask-Free Pseudo Data Training(https://arxiv.org/abs/2408.06047)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Image-based virtual try-on is an increasingly popular and important task to generate realistic try-on images of specific person. Existing methods always employ an accurate mask to remove the original garment in the source image, thus achieving realistic synthesized images in simple and conventional try-on scenarios based on powerful diffusion model. Therefore, acquiring suitable mask is vital to the try-on performance of these methods. However, obtaining precise inpainting masks, especially for complex wild try-on data containing diverse foreground occlusions and person poses, is not easy as Figure 1-Top shows. This difficulty often results in poor performance in more practical and challenging real-life scenarios, such as the selfie scene shown in Figure 1-Bottom. To this end, we propose a novel training paradigm combined with an efficient data augmentation method to acquire large-scale unpaired training data from wild scenarios, thereby significantly facilitating the try-on performance of our model without the need for additional inpainting masks. Besides, a try-on localization loss is designed to localize a more accurate try-on area to obtain more reasonable try-on results. It is noted that our method only needs the reference cloth image, source pose image and source person image as input, which is more cost-effective and user-friendly compared to existing methods. Extensive qualitative and quantitative experiments have demonstrated superior performance in wild scenarios with such a low-demand input.</li>
</ul>

<h3>Title: What Ails Generative Structure-based Drug Design: Too Little or Too Much Expressivity?</h3>
<ul>
<li><strong>Authors: </strong>Rafał Karczewski, Samuel Kaski, Markus Heinonen, Vikas Garg</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06050">https://arxiv.org/abs/2408.06050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06050">https://arxiv.org/pdf/2408.06050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06050]] What Ails Generative Structure-based Drug Design: Too Little or Too Much Expressivity?(https://arxiv.org/abs/2408.06050)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Several generative models with elaborate training and sampling procedures have been proposed recently to accelerate structure-based drug design (SBDD); however, perplexingly, their empirical performance turns out to be suboptimal. We seek to better understand this phenomenon from both theoretical and empirical perspectives. Since most of these models apply graph neural networks (GNNs), one may suspect that they inherit the representational limitations of GNNs. We analyze this aspect, establishing the first such results for protein-ligand complexes. A plausible counterview may attribute the underperformance of these models to their excessive parameterizations, inducing expressivity at the expense of generalization. We also investigate this possibility with a simple metric-aware approach that learns an economical surrogate for affinity to infer an unlabelled molecular graph and optimizes for labels conditioned on this graph and molecular properties. The resulting model achieves state-of-the-art results using 100x fewer trainable parameters and affords up to 1000x speedup. Collectively, our findings underscore the need to reassess and redirect the existing paradigm and efforts for SBDD.</li>
</ul>

<h3>Title: TruVRF: Towards Triple-Granularity Verification on Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Chunyi Zhou, Anmin Fu, Zhiyang Dai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06063">https://arxiv.org/abs/2408.06063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06063">https://arxiv.org/pdf/2408.06063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06063]] TruVRF: Towards Triple-Granularity Verification on Machine Unlearning(https://arxiv.org/abs/2408.06063)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The concept of the right to be forgotten has led to growing interest in machine unlearning, but reliable validation methods are lacking, creating opportunities for dishonest model providers to mislead data contributors. Traditional invasive methods like backdoor injection are not feasible for legacy data. To address this, we introduce TruVRF, a non-invasive unlearning verification framework operating at class-, volume-, and sample-level granularities. TruVRF includes three Unlearning-Metrics designed to detect different types of dishonest servers: Neglecting, Lazy, and Deceiving. Unlearning-Metric-I checks class alignment, Unlearning-Metric-II verifies sample count, and Unlearning-Metric-III confirms specific sample deletion. Evaluations on three datasets show TruVRF's robust performance, with over 90% accuracy for Metrics I and III, and a 4.8% to 8.2% inference deviation for Metric II. TruVRF also demonstrates generalizability and practicality across various conditions and with state-of-the-art unlearning frameworks like SISA and Amnesiac Unlearning.</li>
</ul>

<h3>Title: An Investigation Into Explainable Audio Hate Speech Detection</h3>
<ul>
<li><strong>Authors: </strong>Jinmyeong An, Wonjun Lee, Yejin Jeon, Jungseul Ok, Yunsu Kim, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06065">https://arxiv.org/abs/2408.06065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06065">https://arxiv.org/pdf/2408.06065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06065]] An Investigation Into Explainable Audio Hate Speech Detection(https://arxiv.org/abs/2408.06065)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Research on hate speech has predominantly revolved around detection and interpretation from textual inputs, leaving verbal content largely unexplored. While there has been limited exploration into hate speech detection within verbal acoustic speech inputs, the aspect of interpretability has been overlooked. Therefore, we introduce a new task of explainable audio hate speech detection. Specifically, we aim to identify the precise time intervals, referred to as audio frame-level rationales, which serve as evidence for hate speech classification. Towards this end, we propose two different approaches: cascading and End-to-End (E2E). The cascading approach initially converts audio to transcripts, identifies hate speech within these transcripts, and subsequently locates the corresponding audio time frames. Conversely, the E2E approach processes audio utterances directly, which allows it to pinpoint hate speech within specific time frames. Additionally, due to the lack of explainable audio hate speech datasets that include audio frame-level rationales, we curated a synthetic audio dataset to train our models. We further validated these models on actual human speech utterances and found that the E2E approach outperforms the cascading method in terms of the audio frame Intersection over Union (IoU) metric. Furthermore, we observed that including frame-level rationales significantly enhances hate speech detection accuracy for the E2E approach. \textbf{Disclaimer} The reader may encounter content of an offensive or hateful nature. However, given the nature of the work, this cannot be avoided.</li>
</ul>

<h3>Title: ControlNeXt: Powerful and Efficient Control for Image and Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Bohao Peng, Jian Wang, Yuechen Zhang, Wenbo Li, Ming-Chang Yang, Jiaya Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06070">https://arxiv.org/abs/2408.06070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06070">https://arxiv.org/pdf/2408.06070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06070]] ControlNeXt: Powerful and Efficient Control for Image and Video Generation(https://arxiv.org/abs/2408.06070)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated remarkable and robust abilities in both image and video generation. To achieve greater control over generated results, researchers introduce additional architectures, such as ControlNet, Adapters and ReferenceNet, to integrate conditioning controls. However, current controllable generation methods often require substantial additional computational resources, especially for video generation, and face challenges in training or exhibit weak control. In this paper, we propose ControlNeXt: a powerful and efficient method for controllable image and video generation. We first design a more straightforward and efficient architecture, replacing heavy additional branches with minimal additional cost compared to the base model. Such a concise structure also allows our method to seamlessly integrate with other LoRA weights, enabling style alteration without the need for additional training. As for training, we reduce up to 90% of learnable parameters compared to the alternatives. Furthermore, we propose another method called Cross Normalization (CN) as a replacement for Zero-Convolution' to achieve fast and stable training convergence. We have conducted various experiments with different base models across images and videos, demonstrating the robustness of our method.</li>
</ul>

<h3>Title: A-BDD: Leveraging Data Augmentations for Safe Autonomous Driving in Adverse Weather and Lighting</h3>
<ul>
<li><strong>Authors: </strong>Felix Assion, Florens Gressner, Nitin Augustine, Jona Klemenc, Ahmed Hammam, Alexandre Krattinger, Holger Trittenbach, Sascha Riemer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06071">https://arxiv.org/abs/2408.06071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06071">https://arxiv.org/pdf/2408.06071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06071]] A-BDD: Leveraging Data Augmentations for Safe Autonomous Driving in Adverse Weather and Lighting(https://arxiv.org/abs/2408.06071)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, segmentation</a></li>
<li><strong>Abstract: </strong>High-autonomy vehicle functions rely on machine learning (ML) algorithms to understand the environment. Despite displaying remarkable performance in fair weather scenarios, perception algorithms are heavily affected by adverse weather and lighting conditions. To overcome these difficulties, ML engineers mainly rely on comprehensive real-world datasets. However, the difficulties in real-world data collection for critical areas of the operational design domain (ODD) often means synthetic data is required for perception training and safety validation. Thus, we present A-BDD, a large set of over 60,000 synthetically augmented images based on BDD100K that are equipped with semantic segmentation and bounding box annotations (inherited from the BDD100K dataset). The dataset contains augmented data for rain, fog, overcast and sunglare/shadow with varying intensity levels. We further introduce novel strategies utilizing feature-based image quality metrics like FID and CMMD, which help identify useful augmented and real-world data for ML training and testing. By conducting experiments on A-BDD, we provide evidence that data augmentations can play a pivotal role in closing performance gaps in adverse weather and lighting conditions.</li>
</ul>

<h3>Title: CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, Da Yin, Xiaotao Gu, Yuxuan Zhang, Weihan Wang, Yean Cheng, Ting Liu, Bin Xu, Yuxiao Dong, Jie Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06072">https://arxiv.org/abs/2408.06072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06072">https://arxiv.org/pdf/2408.06072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06072]] CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer(https://arxiv.org/abs/2408.06072)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We introduce CogVideoX, a large-scale diffusion transformer model designed for generating videos based on text prompts. To efficently model video data, we propose to levearge a 3D Variational Autoencoder (VAE) to compress videos along both spatial and temporal dimensions. To improve the text-video alignment, we propose an expert transformer with the expert adaptive LayerNorm to facilitate the deep fusion between the two modalities. By employing a progressive training technique, CogVideoX is adept at producing coherent, long-duration videos characterized by significant motions. In addition, we develop an effective text-video data processing pipeline that includes various data preprocessing strategies and a video captioning method. It significantly helps enhance the performance of CogVideoX, improving both generation quality and semantic alignment. Results show that CogVideoX demonstrates state-of-the-art performance across both multiple machine metrics and human evaluations. The model weights of both the 3D Causal VAE and CogVideoX are publicly available at this https URL.</li>
</ul>

<h3>Title: Towards Adversarial Robustness via Debiased High-Confidence Logit Alignment</h3>
<ul>
<li><strong>Authors: </strong>Kejia Zhang, Juanjuan Weng, Zhiming Luo, Shaozi Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06079">https://arxiv.org/abs/2408.06079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06079">https://arxiv.org/pdf/2408.06079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06079]] Towards Adversarial Robustness via Debiased High-Confidence Logit Alignment(https://arxiv.org/abs/2408.06079)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Despite the significant advances that deep neural networks (DNNs) have achieved in various visual tasks, they still exhibit vulnerability to adversarial examples, leading to serious security concerns. Recent adversarial training techniques have utilized inverse adversarial attacks to generate high-confidence examples, aiming to align the distributions of adversarial examples with the high-confidence regions of their corresponding classes. However, in this paper, our investigation reveals that high-confidence outputs under inverse adversarial attacks are correlated with biased feature activation. Specifically, training with inverse adversarial examples causes the model's attention to shift towards background features, introducing a spurious correlation bias. To address this bias, we propose Debiased High-Confidence Adversarial Training (DHAT), a novel approach that not only aligns the logits of adversarial examples with debiased high-confidence logits obtained from inverse adversarial examples, but also restores the model's attention to its normal state by enhancing foreground logit orthogonality. Extensive experiments demonstrate that DHAT achieves state-of-the-art performance and exhibits robust generalization capabilities across various vision datasets. Additionally, DHAT can seamlessly integrate with existing advanced adversarial training techniques for improving the performance.</li>
</ul>

<h3>Title: Towards Robust Monocular Depth Estimation in Non-Lambertian Surfaces</h3>
<ul>
<li><strong>Authors: </strong>Junrui Zhang, Jiaqi Li, Yachuan Huang, Yiran Wang, Jinghong Zheng, Liao Shen, Zhiguo Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06083">https://arxiv.org/abs/2408.06083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06083">https://arxiv.org/pdf/2408.06083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06083]] Towards Robust Monocular Depth Estimation in Non-Lambertian Surfaces(https://arxiv.org/abs/2408.06083)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the field of monocular depth estimation (MDE), many models with excellent zero-shot performance in general scenes emerge recently. However, these methods often fail in predicting non-Lambertian surfaces, such as transparent or mirror (ToM) surfaces, due to the unique reflective properties of these regions. Previous methods utilize externally provided ToM masks and aim to obtain correct depth maps through direct in-painting of RGB images. These methods highly depend on the accuracy of additional input masks, and the use of random colors during in-painting makes them insufficiently robust. We are committed to incrementally enabling the baseline model to directly learn the uniqueness of non-Lambertian surface regions for depth estimation through a well-designed training framework. Therefore, we propose non-Lambertian surface regional guidance, which constrains the predictions of MDE model from the gradient domain to enhance its robustness. Noting the significant impact of lighting on this task, we employ the random tone-mapping augmentation during training to ensure the network can predict correct results for varying lighting inputs. Additionally, we propose an optional novel lighting fusion module, which uses Variational Autoencoders to fuse multiple images and obtain the most advantageous input RGB image for depth estimation when multi-exposure images are available. Our method achieves accuracy improvements of 33.39% and 5.21% in zero-shot testing on the Booster and Mirror3D dataset for non-Lambertian surfaces, respectively, compared to the Depth Anything V2. The state-of-the-art performance of 90.75 in delta1.05 within the ToM regions on the TRICKY2024 competition test set demonstrates the effectiveness of our approach.</li>
</ul>

<h3>Title: Building Decision Making Models Through Language Model Regime</h3>
<ul>
<li><strong>Authors: </strong>Yu Zhang, Haoxiang Liu, Feijun Jiang, Weihua Luo, Kaifu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06087">https://arxiv.org/abs/2408.06087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06087">https://arxiv.org/pdf/2408.06087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06087]] Building Decision Making Models Through Language Model Regime(https://arxiv.org/abs/2408.06087)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We propose a novel approach for decision making problems leveraging the generalization capabilities of large language models (LLMs). Traditional methods such as expert systems, planning algorithms, and reinforcement learning often exhibit limited generalization, typically requiring the training of new models for each unique task. In contrast, LLMs demonstrate remarkable success in generalizing across varied language tasks, inspiring a new strategy for training decision making models. Our approach, referred to as "Learning then Using" (LTU), entails a two-stage process. Initially, the \textit{learning} phase develops a robust foundational decision making model by integrating diverse knowledge from various domains and decision making contexts. The subsequent \textit{using} phase refines this foundation model for specific decision making scenarios. Distinct from other studies that employ LLMs for decision making through supervised learning, our LTU method embraces a versatile training methodology that combines broad pre-training with targeted fine-tuning. Experiments in e-commerce domains such as advertising and search optimization have shown that LTU approach outperforms traditional supervised learning regimes in decision making capabilities and generalization. The LTU approach is the first practical training architecture for both single-step and multi-step decision making tasks combined with LLMs, which can be applied beyond game and robot domains. It provides a robust and adaptable framework for decision making, enhances the effectiveness and flexibility of various systems in tackling various challenges.</li>
</ul>

<h3>Title: Approximating Discrimination Within Models When Faced With Several Non-Binary Sensitive Attributes</h3>
<ul>
<li><strong>Authors: </strong>Yijun Bian, Yujie Luo, Ping Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06099">https://arxiv.org/abs/2408.06099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06099">https://arxiv.org/pdf/2408.06099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06099]] Approximating Discrimination Within Models When Faced With Several Non-Binary Sensitive Attributes(https://arxiv.org/abs/2408.06099)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Discrimination mitigation with machine learning (ML) models could be complicated because multiple factors may interweave with each other including hierarchically and historically. Yet few existing fairness measures are able to capture the discrimination level within ML models in the face of multiple sensitive attributes. To bridge this gap, we propose a fairness measure based on distances between sets from a manifold perspective, named as 'harmonic fairness measure via manifolds (HFM)' with two optional versions, which can deal with a fine-grained discrimination evaluation for several sensitive attributes of multiple values. To accelerate the computation of distances of sets, we further propose two approximation algorithms named 'Approximation of distance between sets for one sensitive attribute with multiple values (ApproxDist)' and 'Approximation of extended distance between sets for several sensitive attributes with multiple values (ExtendDist)' to respectively resolve bias evaluation of one single sensitive attribute with multiple values and that of several sensitive attributes with multiple values. Moreover, we provide an algorithmic effectiveness analysis for ApproxDist under certain assumptions to explain how well it could work. The empirical results demonstrate that our proposed fairness measure HFM is valid and approximation algorithms (i.e., ApproxDist and ExtendDist) are effective and efficient.</li>
</ul>

<h3>Title: RISurConv: Rotation Invariant Surface Attention-Augmented Convolutions for 3D Point Cloud Classification and Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Zhang, Licheng Yang, Zhiyu Xiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06110">https://arxiv.org/abs/2408.06110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06110">https://arxiv.org/pdf/2408.06110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06110]] RISurConv: Rotation Invariant Surface Attention-Augmented Convolutions for 3D Point Cloud Classification and Segmentation(https://arxiv.org/abs/2408.06110)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Despite the progress on 3D point cloud deep learning, most prior works focus on learning features that are invariant to translation and point permutation, and very limited efforts have been devoted for rotation invariant property. Several recent studies achieve rotation invariance at the cost of lower accuracies. In this work, we close this gap by proposing a novel yet effective rotation invariant architecture for 3D point cloud classification and segmentation. Instead of traditional pointwise operations, we construct local triangle surfaces to capture more detailed surface structure, based on which we can extract highly expressive rotation invariant surface properties which are then integrated into an attention-augmented convolution operator named RISurConv to generate refined attention features via self-attention layers. Based on RISurConv we build an effective neural network for 3D point cloud analysis that is invariant to arbitrary rotations while maintaining high accuracy. We verify the performance on various benchmarks with supreme results obtained surpassing the previous state-of-the-art by a large margin. We achieve an overall accuracy of 96.0% (+4.7%) on ModelNet40, 93.1% (+12.8%) on ScanObjectNN, and class accuracies of 91.5% (+3.6%), 82.7% (+5.1%), and 78.5% (+9.2%) on the three categories of the FG3D dataset for the fine-grained classification task. Additionally, we achieve 81.5% (+1.0%) mIoU on ShapeNet for the segmentation task. Code is available here: this https URL</li>
</ul>

<h3>Title: A Methodological Report on Anomaly Detection on Dynamic Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Xiaohua Lu, Leshanshui Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06121">https://arxiv.org/abs/2408.06121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06121">https://arxiv.org/pdf/2408.06121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06121]] A Methodological Report on Anomaly Detection on Dynamic Knowledge Graphs(https://arxiv.org/abs/2408.06121)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we explore different approaches to anomaly detection on dynamic knowledge graphs, specifically in a microservices environment for Kubernetes applications. Our approach explores three dynamic knowledge graph representations: sequential data, one-hop graph structure, and two-hop graph structure, with each representation incorporating increasingly complex structural information. Each phase includes different machine learning and deep learning models. We empirically analyse their performance and propose an approach based on ensemble learning of these models. Our approach significantly outperforms the baseline on the ISWC 2024 Dynamic Knowledge Graph Anomaly Detection dataset, providing a robust solution for anomaly detection in dynamic complex data.</li>
</ul>

<h3>Title: DPDETR: Decoupled Position Detection Transformer for Infrared-Visible Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Junjie Guo, Chenqiang Gao, Fangcen Liu, Deyu Meng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06123">https://arxiv.org/abs/2408.06123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06123">https://arxiv.org/pdf/2408.06123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06123]] DPDETR: Decoupled Position Detection Transformer for Infrared-Visible Object Detection(https://arxiv.org/abs/2408.06123)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Infrared-visible object detection aims to achieve robust object detection by leveraging the complementary information of infrared and visible image pairs. However, the commonly existing modality misalignment problem presents two challenges: fusing misalignment complementary features is difficult, and current methods cannot accurately locate objects in both modalities under misalignment conditions. In this paper, we propose a Decoupled Position Detection Transformer (DPDETR) to address these problems. Specifically, we explicitly formulate the object category, visible modality position, and infrared modality position to enable the network to learn the intrinsic relationships and output accurate positions of objects in both modalities. To fuse misaligned object features accurately, we propose a Decoupled Position Multispectral Cross-attention module that adaptively samples and aggregates multispectral complementary features with the constraint of infrared and visible reference positions. Additionally, we design a query-decoupled Multispectral Decoder structure to address the optimization gap among the three kinds of object information in our task and propose a Decoupled Position Contrastive DeNosing Training strategy to enhance the DPDETR's ability to learn decoupled positions. Experiments on DroneVehicle and KAIST datasets demonstrate significant improvements compared to other state-of-the-art methods. The code will be released at this https URL.</li>
</ul>

<h3>Title: Utilize Transformers for translating Wikipedia category names</h3>
<ul>
<li><strong>Authors: </strong>Hoang-Thang Ta, Quoc Thang La</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06124">https://arxiv.org/abs/2408.06124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06124">https://arxiv.org/pdf/2408.06124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06124]] Utilize Transformers for translating Wikipedia category names(https://arxiv.org/abs/2408.06124)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>On Wikipedia, articles are categorized to aid readers in navigating content efficiently. The manual creation of new categories can be laborious and time-intensive. To tackle this issue, we built language models to translate Wikipedia categories from English to Vietnamese with a dataset containing 15,000 English-Vietnamese category pairs. Subsequently, small to medium-scale Transformer pre-trained models with a sequence-to-sequence architecture were fine-tuned for category translation. The experiments revealed that OPUS-MT-en-vi surpassed other models, attaining the highest performance with a BLEU score of 0.73, despite its smaller model storage. We expect our paper to be an alternative solution for translation tasks with limited computer resources.</li>
</ul>

<h3>Title: Uncovering the Role of Support Infrastructure in Clickbait PDF Campaigns</h3>
<ul>
<li><strong>Authors: </strong>Giada Stivala, Gianluca De Stefano, Andrea Mengascini, Mariano Graziano, Giancarlo Pellegrino</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06133">https://arxiv.org/abs/2408.06133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06133">https://arxiv.org/pdf/2408.06133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06133]] Uncovering the Role of Support Infrastructure in Clickbait PDF Campaigns(https://arxiv.org/abs/2408.06133)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Clickbait PDFs, an entry point for multiple Web attacks, are distributed via SEO poisoning and rank high in search results due to being massively uploaded on abused or compromised websites. The central role of these hosts in the distribution of clickbait PDFs remains understudied, and it is unclear whether attackers differentiate the types of hosting for PDF uploads, how long they rely on hosts, and how affected parties respond to abuse. To address this, we conducted real-time analyses on hosts, collecting data on 4,648,939 clickbait PDFs served by 177,835 hosts over 17 months. Our results revealed a diverse infrastructure, with hosts falling into three main hosting types. We also identified at scale the presence of eight software components which facilitate file uploads and which are likely exploited for clickbait PDF distribution. We contact affected parties to report the misuse of their resources via a large-scale vulnerability notification. While we observed some effectiveness in terms of number of cleaned-up PDFs following the notification, long-term improvement in this infrastructure remained insignificant. This finding raises questions about the hosting providers' role in combating abuse and the actual impact of vulnerability notifications.</li>
</ul>

<h3>Title: Med42-v2: A Suite of Clinical LLMs</h3>
<ul>
<li><strong>Authors: </strong>Clément Christophe, Praveen K Kanithi, Tathagata Raha, Shadab Khan, Marco AF Pimentel</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06142">https://arxiv.org/abs/2408.06142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06142">https://arxiv.org/pdf/2408.06142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06142]] Med42-v2: A Suite of Clinical LLMs(https://arxiv.org/abs/2408.06142)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Med42-v2 introduces a suite of clinical large language models (LLMs) designed to address the limitations of generic models in healthcare settings. These models are built on Llama3 architecture and fine-tuned using specialized clinical data. They underwent multi-stage preference alignment to effectively respond to natural prompts. While generic models are often preference-aligned to avoid answering clinical queries as a precaution, Med42-v2 is specifically trained to overcome this limitation, enabling its use in clinical settings. Med42-v2 models demonstrate superior performance compared to the original Llama3 models in both 8B and 70B parameter configurations and GPT-4 across various medical benchmarks. These LLMs are developed to understand clinical queries, perform reasoning tasks, and provide valuable assistance in clinical environments. The models are now publicly available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Efficient and Scalable Point Cloud Generation with Sparse Point-Voxel Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Ioannis Romanelis, Vlassios Fotis, Athanasios Kalogeras, Christos Alexakos, Konstantinos Moustakas, Adrian Munteanu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06145">https://arxiv.org/abs/2408.06145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06145">https://arxiv.org/pdf/2408.06145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06145]] Efficient and Scalable Point Cloud Generation with Sparse Point-Voxel Diffusion Models(https://arxiv.org/abs/2408.06145)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We propose a novel point cloud U-Net diffusion architecture for 3D generative modeling capable of generating high-quality and diverse 3D shapes while maintaining fast generation times. Our network employs a dual-branch architecture, combining the high-resolution representations of points with the computational efficiency of sparse voxels. Our fastest variant outperforms all non-diffusion generative approaches on unconditional shape generation, the most popular benchmark for evaluating point cloud generative models, while our largest model achieves state-of-the-art results among diffusion methods, with a runtime approximately 70% of the previously state-of-the-art PVD. Beyond unconditional generation, we perform extensive evaluations, including conditional generation on all categories of ShapeNet, demonstrating the scalability of our model to larger datasets, and implicit generation which allows our network to produce high quality point clouds on fewer timesteps, further decreasing the generation time. Finally, we evaluate the architecture's performance in point cloud completion and super-resolution. Our model excels in all tasks, establishing it as a state-of-the-art diffusion U-Net for point cloud generative modeling. The code is publicly available at this https URL.</li>
</ul>

<h3>Title: Novel View Synthesis from a Single Image with Pretrained Diffusion Guidance</h3>
<ul>
<li><strong>Authors: </strong>Taewon Kang, Divya Kothandaraman, Dinesh Manocha, Ming C. Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06157">https://arxiv.org/abs/2408.06157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06157">https://arxiv.org/pdf/2408.06157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06157]] Novel View Synthesis from a Single Image with Pretrained Diffusion Guidance(https://arxiv.org/abs/2408.06157)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent 3D novel view synthesis (NVS) methods are limited to single-object-centric scenes generated from new viewpoints and struggle with complex environments. They often require extensive 3D data for training, lacking generalization beyond training distribution. Conversely, 3D-free methods can generate text-controlled views of complex, in-the-wild scenes using a pretrained stable diffusion model without tedious fine-tuning, but lack camera control. In this paper, we introduce HawkI++, a method capable of generating camera-controlled viewpoints from a single input image. HawkI++ excels in handling complex and diverse scenes without additional 3D data or extensive training. It leverages widely available pretrained NVS models for weak guidance, integrating this knowledge into a 3D-free view synthesis approach to achieve the desired results efficiently. Our experimental results demonstrate that HawkI++ outperforms existing models in both qualitative and quantitative evaluations, providing high-fidelity and consistent novel view synthesis at desired camera angles across a wide variety of scenes.</li>
</ul>

<h3>Title: Blind-Match: Efficient Homomorphic Encryption-Based 1:N Matching for Privacy-Preserving Biometric Identification</h3>
<ul>
<li><strong>Authors: </strong>Hyunmin Choi, Jiwon Kim, Chiyoung Song, Simon S. Woo, Hyoungshick Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06167">https://arxiv.org/abs/2408.06167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06167">https://arxiv.org/pdf/2408.06167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06167]] Blind-Match: Efficient Homomorphic Encryption-Based 1:N Matching for Privacy-Preserving Biometric Identification(https://arxiv.org/abs/2408.06167)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, biometric</a></li>
<li><strong>Abstract: </strong>We present Blind-Match, a novel biometric identification system that leverages homomorphic encryption (HE) for efficient and privacy-preserving 1:N matching. Blind-Match introduces a HE-optimized cosine similarity computation method, where the key idea is to divide the feature vector into smaller parts for processing rather than computing the entire vector at once. By optimizing the number of these parts, Blind-Match minimizes execution time while ensuring data privacy through HE. Blind-Match achieves superior performance compared to state-of-the-art methods across various biometric datasets. On the LFW face dataset, Blind-Match attains a 99.63% Rank-1 accuracy with a 128-dimensional feature vector, demonstrating its robustness in face recognition tasks. For fingerprint identification, Blind-Match achieves a remarkable 99.55% Rank-1 accuracy on the PolyU dataset, even with a compact 16-dimensional feature vector, significantly outperforming the state-of-the-art method, Blind-Touch, which achieves only 59.17%. Furthermore, Blind-Match showcases practical efficiency in large-scale biometric identification scenarios, such as Naver Cloud's FaceSign, by processing 6,144 biometric samples in 0.74 seconds using a 128-dimensional feature vector.</li>
</ul>

<h3>Title: Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Mario Padilla Rodriguez, Mohamed Nafea</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06183">https://arxiv.org/abs/2408.06183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06183">https://arxiv.org/pdf/2408.06183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06183]] Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability(https://arxiv.org/abs/2408.06183)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, interpretability</a></li>
<li><strong>Abstract: </strong>Cardiovascular diseases are a leading cause of mortality worldwide, highlighting the need for accurate diagnostic methods. This study benchmarks centralized and federated machine learning algorithms for heart disease classification using the UCI dataset which includes 920 patient records from four hospitals in the USA, Hungary and Switzerland. Our benchmark is supported by Shapley-value interpretability analysis to quantify features' importance for classification. In the centralized setup, various binary classification algorithms are trained on pooled data, with a support vector machine (SVM) achieving the highest testing accuracy of 83.3\%, surpassing the established benchmark of 78.7\% with logistic regression. Additionally, federated learning algorithms with four clients (hospitals) are explored, leveraging the dataset's natural partition to enhance privacy without sacrificing accuracy. Federated SVM, an uncommon approach in the literature, achieves a top testing accuracy of 73.8\%. Our interpretability analysis aligns with existing medical knowledge of heart disease indicators. Overall, this study establishes a benchmark for efficient and interpretable pre-screening tools for heart disease while maintaining patients' privacy.</li>
</ul>

<h3>Title: Improving Structural Diversity of Blackbox LLMs via Chain-of-Specification Prompting</h3>
<ul>
<li><strong>Authors: </strong>Halley Young, Yimeng Zeng, Jacob Gardner, Osbert Bastani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06186">https://arxiv.org/abs/2408.06186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06186">https://arxiv.org/pdf/2408.06186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06186]] Improving Structural Diversity of Blackbox LLMs via Chain-of-Specification Prompting(https://arxiv.org/abs/2408.06186)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The capability to generate diverse text is a key challenge facing large language models (LLMs). Thus far, diversity has been studied via metrics such as $n$-gram diversity or diversity of BERT embeddings. However, for these kinds of diversity, the user has little control over the dimensions along which diversity is considered. For example, in the poetry domain, one might desire diversity in terms of rhyme and meter, whereas in the code domain, one might desire diversity in terms of the kinds of expressions used to solve a problem. We propose a diversity metric called structural diversity, where the user provides a mapping from generated text to features capturing the kinds of diversity that they care about. In addition, we propose a novel strategy called chain-of-specification (CoS) prompting for improving diversity by first having the LLM generate a specification encoding one instance of structural features, and then prompting the LLM to generate text that satisfies these features; notably, our strategy works with blackbox LLMs. In our experiments, we show that for structural diversity in the poetry and code domains, CoS significantly improves diversity compared to several baselines.</li>
</ul>

<h3>Title: FruitNeRF: A Unified Neural Radiance Field based Fruit Counting Framework</h3>
<ul>
<li><strong>Authors: </strong>Lukas Meyer, Andreas Gilson, Ute Schmidt, Marc Stamminger</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06190">https://arxiv.org/abs/2408.06190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06190">https://arxiv.org/pdf/2408.06190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06190]] FruitNeRF: A Unified Neural Radiance Field based Fruit Counting Framework(https://arxiv.org/abs/2408.06190)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We introduce FruitNeRF, a unified novel fruit counting framework that leverages state-of-the-art view synthesis methods to count any fruit type directly in 3D. Our framework takes an unordered set of posed images captured by a monocular camera and segments fruit in each image. To make our system independent of the fruit type, we employ a foundation model that generates binary segmentation masks for any fruit. Utilizing both modalities, RGB and semantic, we train a semantic neural radiance field. Through uniform volume sampling of the implicit Fruit Field, we obtain fruit-only point clouds. By applying cascaded clustering on the extracted point cloud, our approach achieves precise fruit count.The use of neural radiance fields provides significant advantages over conventional methods such as object tracking or optical flow, as the counting itself is lifted into 3D. Our method prevents double counting fruit and avoids counting irrelevant fruit.We evaluate our methodology using both real-world and synthetic datasets. The real-world dataset consists of three apple trees with manually counted ground truths, a benchmark apple dataset with one row and ground truth fruit location, while the synthetic dataset comprises various fruit types including apple, plum, lemon, pear, peach, and mango.Additionally, we assess the performance of fruit counting using the foundation model compared to a U-Net.</li>
</ul>

<h3>Title: Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption</h3>
<ul>
<li><strong>Authors: </strong>Siyang Jiang, Hao Yang, Qipeng Xie, Chuan Ma, Sen Wang, Guoliang Xing</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06197">https://arxiv.org/abs/2408.06197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06197">https://arxiv.org/pdf/2408.06197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06197]] Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption(https://arxiv.org/abs/2408.06197)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>In sectors such as finance and healthcare, where data governance is subject to rigorous regulatory requirements, the exchange and utilization of data are particularly challenging. Federated Learning (FL) has risen as a pioneering distributed machine learning paradigm that enables collaborative model training across multiple institutions while maintaining data decentralization. Despite its advantages, FL is vulnerable to adversarial threats, particularly poisoning attacks during model aggregation, a process typically managed by a central server. However, in these systems, neural network models still possess the capacity to inadvertently memorize and potentially expose individual training instances. This presents a significant privacy risk, as attackers could reconstruct private data by leveraging the information contained in the model itself. Existing solutions fall short of providing a viable, privacy-preserving BRFL system that is both completely secure against information leakage and computationally efficient. To address these concerns, we propose Lancelot, an innovative and computationally efficient BRFL framework that employs fully homomorphic encryption (FHE) to safeguard against malicious client activities while preserving data privacy. Our extensive testing, which includes medical imaging diagnostics and widely-used public image datasets, demonstrates that Lancelot significantly outperforms existing methods, offering more than a twenty-fold increase in processing speed, all while maintaining data privacy.</li>
</ul>

<h3>Title: 120 Domain-Specific Languages for Security</h3>
<ul>
<li><strong>Authors: </strong>Markus Krausz, Sven Peldszus, Francesco Regazzoni, Thorsten Berger, Tim Tim Güneysu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06219">https://arxiv.org/abs/2408.06219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06219">https://arxiv.org/pdf/2408.06219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06219]] 120 Domain-Specific Languages for Security(https://arxiv.org/abs/2408.06219)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Security engineering, from security requirements engineering to the implementation of cryptographic protocols, is often supported by domain-specific languages (DSLs). Unfortunately, a lack of knowledge about these DSLs, such as which security aspects are addressed and when, hinders their effective use and further research. This systematic literature review examines 120 security-oriented DSLs based on six research questions concerning security aspects and goals, language-specific characteristics, integration into the software development lifecycle (SDLC), and effectiveness of the DSLs. We observe a high degree of fragmentation, which leads to opportunities for integration. We also need to improve the usability and evaluation of security DSLs.</li>
</ul>

<h3>Title: A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Vispi Karkaria, Jie Chen, Christopher Luey, Chase Siuta, Damien Lim, Robert Radulescu, Wei Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06220">https://arxiv.org/abs/2408.06220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06220">https://arxiv.org/pdf/2408.06220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06220]] A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring(https://arxiv.org/abs/2408.06220)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We introduce a novel digital twin framework for predictive maintenance of long-term physical systems. Using monitoring tire health as an application, we show how the digital twin framework can be used to enhance automotive safety and efficiency, and how the technical challenges can be overcome using a three-step approach. Firstly, for managing the data complexity over a long operation span, we employ data reduction techniques to concisely represent physical tires using historical performance and usage data. Relying on these data, for fast real-time prediction, we train a transformer-based model offline on our concise dataset to predict future tire health over time, represented as Remaining Casing Potential (RCP). Based on our architecture, our model quantifies both epistemic and aleatoric uncertainty, providing reliable confidence intervals around predicted RCP. Secondly, to incorporate real-time data, we update the predictive model in the digital twin framework, ensuring its accuracy throughout its life span with the aid of hybrid modeling and the use of discrepancy function. Thirdly, to assist decision making in predictive maintenance, we implement a Tire State Decision Algorithm, which strategically determines the optimal timing for tire replacement based on RCP forecasted by our transformer model. This approach ensures our digital twin accurately predicts system health, continually refines its digital representation, and supports predictive maintenance decisions. Our framework effectively embodies a physical system, leveraging big data and machine learning for predictive maintenance, model updates, and decision-making.</li>
</ul>

<h3>Title: On Effects of Steering Latent Representation for Large Language Model Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Dang Huu-Tien, Trung-Tin Pham, Hoang Thanh-Tung, Naoya Inoue</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06223">https://arxiv.org/abs/2408.06223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06223">https://arxiv.org/pdf/2408.06223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06223]] On Effects of Steering Latent Representation for Large Language Model Unlearning(https://arxiv.org/abs/2408.06223)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Representation Misdirection for Unlearning (RMU), which steers model representation in the intermediate layer to a target random representation, is an effective method for large language model (LLM) unlearning. Despite its high performance, the underlying cause and explanation remain underexplored. In this paper, we first theoretically demonstrate that steering forget representations in the intermediate layer reduces token confidence, causing LLMs to generate wrong or nonsense responses. Second, we investigate how the coefficient influences the alignment of forget-sample representations with the random direction and hint at the optimal coefficient values for effective unlearning across different network layers. Third, we show that RMU unlearned models are robust against adversarial jailbreak attacks. Last, our empirical analysis shows that RMU is less effective when applied to the middle and later layers in LLMs. To resolve this drawback, we propose Adaptive RMU -- a simple yet effective alternative method that makes unlearning effective with most layers. Extensive experiments demonstrate that Adaptive RMU significantly improves the unlearning performance compared to prior art while incurring no additional computational cost.</li>
</ul>

<h3>Title: Correlation Weighted Prototype-based Self-Supervised One-Shot Segmentation of Medical Images</h3>
<ul>
<li><strong>Authors: </strong>Siladittya Manna, Saumik Bhattacharya, Umapada Pal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06235">https://arxiv.org/abs/2408.06235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06235">https://arxiv.org/pdf/2408.06235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06235]] Correlation Weighted Prototype-based Self-Supervised One-Shot Segmentation of Medical Images(https://arxiv.org/abs/2408.06235)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation is one of the domains where sufficient annotated data is not available. This necessitates the application of low-data frameworks like few-shot learning. Contemporary prototype-based frameworks often do not account for the variation in features within the support and query images, giving rise to a large variance in prototype alignment. In this work, we adopt a prototype-based self-supervised one-way one-shot learning framework using pseudo-labels generated from superpixels to learn the semantic segmentation task itself. We use a correlation-based probability score to generate a dynamic prototype for each query pixel from the bag of prototypes obtained from the support feature map. This weighting scheme helps to give a higher weightage to contextually related prototypes. We also propose a quadrant masking strategy in the downstream segmentation task by utilizing prior domain information to discard unwanted false positives. We present extensive experimentations and evaluations on abdominal CT and MR datasets to show that the proposed simple but potent framework performs at par with the state-of-the-art methods.</li>
</ul>

<h3>Title: Decentralized Intelligence Health Network (DIHN)</h3>
<ul>
<li><strong>Authors: </strong>Abraham Nash</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY, cs.DC, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06240">https://arxiv.org/abs/2408.06240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06240">https://arxiv.org/pdf/2408.06240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06240]] Decentralized Intelligence Health Network (DIHN)(https://arxiv.org/abs/2408.06240)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, fair</a></li>
<li><strong>Abstract: </strong>Decentralized Intelligence Health Network (DIHN) is a theoretical framework addressing significant challenges of health data sovereignty and AI utilization in healthcare caused by data fragmentation across providers and institutions. It establishes a sovereign architecture for healthcare provision as a prerequisite to a sovereign health network, then facilitates effective AI utilization by overcoming barriers to accessing diverse medical data sources. This comprehensive framework leverages: 1) self-sovereign identity architecture coupled with a personal health record (PHR) as a prerequisite for health data sovereignty; 2) a scalable federated learning (FL) protocol implemented on a public blockchain for decentralized AI training in healthcare, where health data remains with participants and only model parameter updates are shared; and 3) a scalable, trustless rewards mechanism to incentivize participation and ensure fair reward distribution. This framework ensures that no entity can prevent or control access to training on health data offered by participants or determine financial benefits, as these processes operate on a public blockchain with an immutable record and without a third party. It supports effective AI training in healthcare, allowing patients to maintain control over their health data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial healthcare algorithms. Patients receive rewards into their digital wallets as an incentive to opt-in to the FL protocol, with a long-term roadmap to funding decentralized insurance solutions. This approach introduces a novel, self-financed healthcare model that adapts to individual needs, complements existing systems, and redefines universal coverage. It highlights the potential to transform healthcare data management and AI utilization while empowering patients.</li>
</ul>

<h3>Title: 3D Reconstruction of Protein Structures from Multi-view AFM Images using Neural Radiance Fields (NeRFs)</h3>
<ul>
<li><strong>Authors: </strong>Jaydeep Rade, Ethan Herron, Soumik Sarkar, Anwesha Sarkar, Adarsh Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06244">https://arxiv.org/abs/2408.06244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06244">https://arxiv.org/pdf/2408.06244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06244]] 3D Reconstruction of Protein Structures from Multi-view AFM Images using Neural Radiance Fields (NeRFs)(https://arxiv.org/abs/2408.06244)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in deep learning for predicting 3D protein structures have shown promise, particularly when leveraging inputs like protein sequences and Cryo-Electron microscopy (Cryo-EM) images. However, these techniques often fall short when predicting the structures of protein complexes (PCs), which involve multiple proteins. In our study, we investigate using atomic force microscopy (AFM) combined with deep learning to predict the 3D structures of PCs. AFM generates height maps that depict the PCs in various random orientations, providing a rich information for training a neural network to predict the 3D structures. We then employ the pre-trained UpFusion model (which utilizes a conditional diffusion model for synthesizing novel views) to train an instance-specific NeRF model for 3D reconstruction. The performance of UpFusion is evaluated through zero-shot predictions of 3D protein structures using AFM images. The challenge, however, lies in the time-intensive and impractical nature of collecting actual AFM images. To address this, we use a virtual AFM imaging process that transforms a `PDB' protein file into multi-view 2D virtual AFM images via volume rendering techniques. We extensively validate the UpFusion architecture using both virtual and actual multi-view AFM images. Our results include a comparison of structures predicted with varying numbers of views and different sets of views. This novel approach holds significant potential for enhancing the accuracy of protein complex structure predictions with further fine-tuning of the UpFusion network.</li>
</ul>

<h3>Title: Open-Source Molecular Processing Pipeline for Generating Molecules</h3>
<ul>
<li><strong>Authors: </strong>Shreyas V, Jose Siguenza, Karan Bania, Bharath Ramsundar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06261">https://arxiv.org/abs/2408.06261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06261">https://arxiv.org/pdf/2408.06261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06261]] Open-Source Molecular Processing Pipeline for Generating Molecules(https://arxiv.org/abs/2408.06261)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Generative models for molecules have shown considerable promise for use in computational chemistry, but remain difficult to use for non-experts. For this reason, we introduce open-source infrastructure for easily building generative molecular models into the widely used DeepChem [Ramsundar et al., 2019] library with the aim of creating a robust and reusable molecular generation pipeline. In particular, we add high quality PyTorch [Paszke et al., 2019] implementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao and Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our implementations show strong performance comparable with past work [Kuznetsov and Polykovskiy, 2021, Cao and Kipf, 2022].</li>
</ul>

<h3>Title: Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment</h3>
<ul>
<li><strong>Authors: </strong>Karel D'Oosterlinck, Winnie Xu, Chris Develder, Thomas Demeester, Amanpreet Singh, Christopher Potts, Douwe Kiela, Shikib Mehri</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06266">https://arxiv.org/abs/2408.06266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06266">https://arxiv.org/pdf/2408.06266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06266]] Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment(https://arxiv.org/abs/2408.06266)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are often aligned using contrastive alignment objectives and preference pair datasets. The interaction between model, paired data, and objective makes alignment a complicated procedure, sometimes producing subpar results. We study this and find that (i) preference data gives a better learning signal when the underlying responses are contrastive, and (ii) alignment objectives lead to better performance when they specify more control over the model during training. Based on these insights, we introduce Contrastive Learning from AI Revisions (CLAIR), a data-creation method which leads to more contrastive preference pairs, and Anchored Preference Optimization (APO), a controllable and more stable alignment objective. We align Llama-3-8B-Instruct using various comparable datasets and alignment objectives and measure MixEval-Hard scores, which correlate highly with human judgments. The CLAIR preferences lead to the strongest performance out of all datasets, and APO consistently outperforms less controllable objectives. Our best model, trained on 32K CLAIR preferences with APO, improves Llama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our code is available at this https URL.</li>
</ul>

<h3>Title: A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution</h3>
<ul>
<li><strong>Authors: </strong>Sampath Rajapaksha, Ruby Rani, Erisa Karafili</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06272">https://arxiv.org/abs/2408.06272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06272">https://arxiv.org/pdf/2408.06272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06272]] A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution(https://arxiv.org/abs/2408.06272)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>In the constantly evolving field of cybersecurity, it is imperative for analysts to stay abreast of the latest attack trends and pertinent information that aids in the investigation and attribution of cyber-attacks. In this work, we introduce the first question-answering (QA) model and its application that provides information to the cybersecurity experts about cyber-attacks investigations and attribution. Our QA model is based on Retrieval Augmented Generation (RAG) techniques together with a Large Language Model (LLM) and provides answers to the users' queries based on either our knowledge base (KB) that contains curated information about cyber-attacks investigations and attribution or on outside resources provided by the users. We have tested and evaluated our QA model with various types of questions, including KB-based, metadata-based, specific documents from the KB, and external sources-based questions. We compared the answers for KB-based questions with those from OpenAI's GPT-3.5 and the latest GPT-4o LLMs. Our proposed QA model outperforms OpenAI's GPT models by providing the source of the answers and overcoming the hallucination limitations of the GPT models, which is critical for cyber-attack investigation and attribution. Additionally, our analysis showed that when the RAG QA model is given few-shot examples rather than zero-shot instructions, it generates better answers compared to cases where no examples are supplied in addition to the query.</li>
</ul>

<h3>Title: FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data</h3>
<ul>
<li><strong>Authors: </strong>Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Dui, Yikun Lei, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06273">https://arxiv.org/abs/2408.06273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06273">https://arxiv.org/pdf/2408.06273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06273]] FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data(https://arxiv.org/abs/2408.06273)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated prowess in a wide range of tasks. However, many LLMs exhibit significant performance discrepancies between high- and low-resource languages. To mitigate this challenge, we present FuxiTranyu, an open-source multilingual LLM, which is designed to satisfy the need of the research community for balanced and high-performing multilingual capabilities. FuxiTranyu-8B, the base model with 8 billion parameters, is trained from scratch on a meticulously balanced multilingual data repository that contains 600 billion tokens covering 43 natural languages and 16 programming languages. In addition to the base model, we also develop two instruction-tuned models: FuxiTranyu-8B-SFT that is fine-tuned on a diverse multilingual instruction dataset, and FuxiTranyu-8B-DPO that is further refined with DPO on a preference dataset for enhanced alignment ability. Extensive experiments on a wide range of multilingual benchmarks demonstrate the competitive performance of FuxiTranyu against existing multilingual LLMs, e.g., BLOOM-7B, PolyLM-13B, Llama-2-Chat-7B and Mistral-7B-Instruct. Interpretability analyses at both the neuron and representation level suggest that FuxiTranyu is able to learn consistent multilingual representations across different languages. To promote further research into multilingual LLMs and their working mechanisms, we release both the base and instruction-tuned FuxiTranyu models together with 58 pretraining checkpoints at HuggingFace and Github.</li>
</ul>

<h3>Title: Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Jieyong Kim, Hyunseo Kim, Hyunjin Cho, SeongKu Kang, Buru Chang, Jinyoung Yeo, Dongha Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06276">https://arxiv.org/abs/2408.06276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06276">https://arxiv.org/pdf/2408.06276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06276]] Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation(https://arxiv.org/abs/2408.06276)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks, generating significant interest in their application to recommendation systems. However, existing methods have not fully capitalized on the potential of LLMs, often constrained by limited input information or failing to fully utilize their advanced reasoning capabilities. To address these limitations, we introduce EXP3RT, a novel LLM-based recommender designed to leverage rich preference information contained in user and item reviews. EXP3RT is basically fine-tuned through distillation from a teacher LLM to perform three key tasks in order: EXP3RT first extracts and encapsulates essential subjective preferences from raw reviews, aggregates and summarizes them according to specific criteria to create user and item profiles. It then generates detailed step-by-step reasoning followed by predicted rating, i.e., reasoning-enhanced rating prediction, by considering both subjective and objective information from user/item profiles and item descriptions. This personalized preference reasoning from EXP3RT enhances rating prediction accuracy and also provides faithful and reasonable explanations for recommendation. Extensive experiments show that EXP3RT outperforms existing methods on both rating prediction and candidate item reranking for top-k recommendation, while significantly enhancing the explainability of recommendation systems.</li>
</ul>

<h3>Title: MovieSum: An Abstractive Summarization Dataset for Movie Screenplays</h3>
<ul>
<li><strong>Authors: </strong>Rohit Saxena, Frank Keller</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06281">https://arxiv.org/abs/2408.06281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06281">https://arxiv.org/pdf/2408.06281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06281]] MovieSum: An Abstractive Summarization Dataset for Movie Screenplays(https://arxiv.org/abs/2408.06281)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Movie screenplay summarization is challenging, as it requires an understanding of long input contexts and various elements unique to movies. Large language models have shown significant advancements in document summarization, but they often struggle with processing long input contexts. Furthermore, while television transcripts have received attention in recent studies, movie screenplay summarization remains underexplored. To stimulate research in this area, we present a new dataset, MovieSum, for abstractive summarization of movie screenplays. This dataset comprises 2200 movie screenplays accompanied by their Wikipedia plot summaries. We manually formatted the movie screenplays to represent their structural elements. Compared to existing datasets, MovieSum possesses several distinctive features: (1) It includes movie screenplays, which are longer than scripts of TV episodes. (2) It is twice the size of previous movie screenplay datasets. (3) It provides metadata with IMDb IDs to facilitate access to additional external knowledge. We also show the results of recently released large language models applied to summarization on our dataset to provide a detailed baseline.</li>
</ul>

<h3>Title: Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM</h3>
<ul>
<li><strong>Authors: </strong>Trisha Das, Dina Albassam, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06285">https://arxiv.org/abs/2408.06285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06285">https://arxiv.org/pdf/2408.06285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06285]] Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM(https://arxiv.org/abs/2408.06285)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Medical dialogue systems (MDS) enhance patient-physician communication, improve healthcare accessibility, and reduce costs. However, acquiring suitable data to train these systems poses significant challenges. Privacy concerns prevent the use of real conversations, necessitating synthetic alternatives. Synthetic dialogue generation from publicly available clinical notes offers a promising solution to this issue, providing realistic data while safeguarding privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot prompting and a feedback loop to generate and refine high-quality synthetic dialogues. The feedback consists of weighted evaluation scores for similarity and extractiveness. The iterative process ensures dialogues meet predefined thresholds, achieving superior extractiveness as a result of the feedback loop. Additionally, evaluation shows that the generated dialogues excel in factuality metric compared to the baselines and has comparable diversity scores with GPT4.</li>
</ul>

<h3>Title: Hound: Locating Cryptographic Primitives in Desynchronized Side-Channel Traces Using Deep-Learning</h3>
<ul>
<li><strong>Authors: </strong>Davide Galli, Giuseppe Chiari, Davide Zoni</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06296">https://arxiv.org/abs/2408.06296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06296">https://arxiv.org/pdf/2408.06296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06296]] Hound: Locating Cryptographic Primitives in Desynchronized Side-Channel Traces Using Deep-Learning(https://arxiv.org/abs/2408.06296)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Side-channel attacks allow to extract sensitive information from cryptographic primitives by correlating the partially known computed data and the measured side-channel signal. Starting from the raw side-channel trace, the preprocessing of the side-channel trace to pinpoint the time at which each cryptographic primitive is executed, and, then, to re-align all the collected data to this specific time represent a critical step to setup a successful side-channel attack. The use of hiding techniques has been widely adopted as a low-cost solution to hinder the preprocessing of side-channel traces thus limiting side-channel attacks in real scenarios. This work introduces Hound, a novel deep learning-based pipeline to locate the execution of cryptographic primitives within the side-channel trace even in the presence of trace deformations introduced by the use of dynamic frequency scaling actuators. Hound has been validated through successful attacks on various cryptographic primitives executed on an FPGA-based system-on-chip incorporating a RISC-V CPU, while dynamic frequency scaling is active. Experimental results demonstrate the possibility of identifying the cryptographic primitives in DFS-deformed side-channel traces.</li>
</ul>

<h3>Title: LEARN: An Invex Loss for Outlier Oblivious Robust Online Optimization</h3>
<ul>
<li><strong>Authors: </strong>Adarsh Barik, Anand Krishna, Vincent Y. F. Tan</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06297">https://arxiv.org/abs/2408.06297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06297">https://arxiv.org/pdf/2408.06297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06297]] LEARN: An Invex Loss for Outlier Oblivious Robust Online Optimization(https://arxiv.org/abs/2408.06297)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study a robust online convex optimization framework, where an adversary can introduce outliers by corrupting loss functions in an arbitrary number of rounds k, unknown to the learner. Our focus is on a novel setting allowing unbounded domains and large gradients for the losses without relying on a Lipschitz assumption. We introduce the Log Exponential Adjusted Robust and iNvex (LEARN) loss, a non-convex (invex) robust loss function to mitigate the effects of outliers and develop a robust variant of the online gradient descent algorithm by leveraging the LEARN loss. We establish tight regret guarantees (up to constants), in a dynamic setting, with respect to the uncorrupted rounds and conduct experiments to validate our theory. Furthermore, we present a unified analysis framework for developing online optimization algorithms for non-convex (invex) losses, utilizing it to provide regret bounds with respect to the LEARN loss, which may be of independent interest.</li>
</ul>

<h3>Title: Finding Patterns in Ambiguity: Interpretable Stress Testing in the Decision~Boundary</h3>
<ul>
<li><strong>Authors: </strong>Inês Gomes, Luís F. Teixeira, Jan N. van Rijn, Carlos Soares, André Restivo, Luís Cunha, Moisés Santos</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06302">https://arxiv.org/abs/2408.06302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06302">https://arxiv.org/pdf/2408.06302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06302]] Finding Patterns in Ambiguity: Interpretable Stress Testing in the Decision~Boundary(https://arxiv.org/abs/2408.06302)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The increasing use of deep learning across various domains highlights the importance of understanding the decision-making processes of these black-box models. Recent research focusing on the decision boundaries of deep classifiers, relies on generated synthetic instances in areas of low confidence, uncovering samples that challenge both models and humans. We propose a novel approach to enhance the interpretability of deep binary classifiers by selecting representative samples from the decision boundary - prototypes - and applying post-model explanation algorithms. We evaluate the effectiveness of our approach through 2D visualizations and GradientSHAP analysis. Our experiments demonstrate the potential of the proposed method, revealing distinct and compact clusters and diverse prototypes that capture essential features that lead to low-confidence decisions. By offering a more aggregated view of deep classifiers' decision boundaries, our work contributes to the responsible development and deployment of reliable machine learning systems.</li>
</ul>

<h3>Title: From SAM to SAM 2: Exploring Improvements in Meta's Segment Anything Model</h3>
<ul>
<li><strong>Authors: </strong>Athulya Sundaresan Geetha, Muhammad Hussain</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06305">https://arxiv.org/abs/2408.06305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06305">https://arxiv.org/pdf/2408.06305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06305]] From SAM to SAM 2: Exploring Improvements in Meta's Segment Anything Model(https://arxiv.org/abs/2408.06305)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model (SAM), introduced to the computer vision community by Meta in April 2023, is a groundbreaking tool that allows automated segmentation of objects in images based on prompts such as text, clicks, or bounding boxes. SAM excels in zero-shot performance, segmenting unseen objects without additional training, stimulated by a large dataset of over one billion image masks. SAM 2 expands this functionality to video, leveraging memory from preceding and subsequent frames to generate accurate segmentation across entire videos, enabling near real-time performance. This comparison shows how SAM has evolved to meet the growing need for precise and efficient segmentation in various applications. The study suggests that future advancements in models like SAM will be crucial for improving computer vision technology.</li>
</ul>

<h3>Title: HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From Heterogeneous LiDAR Sensors</h3>
<ul>
<li><strong>Authors: </strong>Hyungtae Lim, Seoyeon Jang, Benedikt Mersch, Jens Behley, Hyun Myung, Cyrill Stachniss</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06328">https://arxiv.org/abs/2408.06328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06328">https://arxiv.org/pdf/2408.06328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06328]] HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From Heterogeneous LiDAR Sensors(https://arxiv.org/abs/2408.06328)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Moving object segmentation (MOS) using a 3D light detection and ranging (LiDAR) sensor is crucial for scene understanding and identification of moving objects. Despite the availability of various types of 3D LiDAR sensors in the market, MOS research still predominantly focuses on 3D point clouds from mechanically spinning omnidirectional LiDAR sensors. Thus, we are, for example, lacking a dataset with MOS labels for point clouds from solid-state LiDAR sensors which have irregular scanning patterns. In this paper, we present a labeled dataset, called \textit{HeLiMOS}, that enables to test MOS approaches on four heterogeneous LiDAR sensors, including two solid-state LiDAR sensors. Furthermore, we introduce a novel automatic labeling method to substantially reduce the labeling effort required from human annotators. To this end, our framework exploits an instance-aware static map building approach and tracking-based false label filtering. Finally, we provide experimental results regarding the performance of commonly used state-of-the-art MOS approaches on HeLiMOS that suggest a new direction for a sensor-agnostic MOS, which generally works regardless of the type of LiDAR sensors used to capture 3D point clouds. Our dataset is available at this https URL.</li>
</ul>

<h3>Title: Animate, or Inanimate, That is the Question for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Leonardo Ranaldi, Giulia Pucci, Fabio Massimo Zanzotto</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.06332">https://arxiv.org/abs/2408.06332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.06332">https://arxiv.org/pdf/2408.06332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.06332]] Animate, or Inanimate, That is the Question for Large Language Models(https://arxiv.org/abs/2408.06332)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The cognitive essence of humans is deeply intertwined with the concept of animacy, which plays an essential role in shaping their memory, vision, and multi-layered language understanding. Although animacy appears in language via nuanced constraints on verbs and adjectives, it is also learned and refined through extralinguistic information. Similarly, we assume that the LLMs' limited abilities to understand natural language when processing animacy are motivated by the fact that these models are trained exclusively on text. Hence, the question this paper aims to answer arises: can LLMs, in their digital wisdom, process animacy in a similar way to what humans would do? We then propose a systematic analysis via prompting approaches. In particular, we probe different LLMs by prompting them using animate, inanimate, usual, and stranger contexts. Results reveal that, although LLMs have been trained predominantly on textual data, they exhibit human-like behavior when faced with typical animate and inanimate entities in alignment with earlier studies. Hence, LLMs can adapt to understand unconventional situations by recognizing oddities as animated without needing to interface with unspoken cognitive triggers humans rely on to break down animations.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
