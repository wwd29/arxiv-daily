<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-03-01</h1>
<h3>Title: Motion Guided Token Compression for Efficient Masked Video Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yukun Feng, Yangming Shi, Fengze Liu, Tan Yan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18577">https://arxiv.org/abs/2402.18577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18577">https://arxiv.org/pdf/2402.18577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18577]] Motion Guided Token Compression for Efficient Masked Video Modeling(https://arxiv.org/abs/2402.18577)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent developments in Transformers have achieved notable strides in enhancing video comprehension. Nonetheless, the O($N^2$) computation complexity associated with attention mechanisms presents substantial computational hurdles when dealing with the high dimensionality of videos. This challenge becomes particularly pronounced when striving to increase the frames per second (FPS) to enhance the motion capturing capabilities. Such a pursuit is likely to introduce redundancy and exacerbate the existing computational limitations. In this paper, we initiate by showcasing the enhanced performance achieved through an escalation in the FPS rate. Additionally, we present a novel approach, Motion Guided Token Compression (MGTC), to empower Transformer models to utilize a smaller yet more representative set of tokens for comprehensive video representation. Consequently, this yields substantial reductions in computational burden and remains seamlessly adaptable to increased FPS rates. Specifically, we draw inspiration from video compression algorithms and scrutinize the variance between patches in consecutive video frames across the temporal dimension. The tokens exhibiting a disparity below a predetermined threshold are then masked. Notably, this masking strategy effectively addresses video redundancy while conserving essential information. Our experiments, conducted on widely examined video recognition datasets, Kinetics-400, UCF101 and HMDB51, demonstrate that elevating the FPS rate results in a significant top-1 accuracy score improvement of over 1.6, 1.6 and 4.0. By implementing MGTC with the masking ratio of 25\%, we further augment accuracy by 0.1 and simultaneously reduce computational costs by over 31\% on Kinetics-400. Even within a fixed computational budget, higher FPS rates paired with MGTC sustain performance gains when compared to lower FPS settings.</li>
</ul>

<h3>Title: Wilcoxon Nonparametric CFAR Scheme for Ship Detection in SAR Image</h3>
<ul>
<li><strong>Authors: </strong>Xiangwei Meng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.SP, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18579">https://arxiv.org/abs/2402.18579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18579">https://arxiv.org/pdf/2402.18579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18579]] Wilcoxon Nonparametric CFAR Scheme for Ship Detection in SAR Image(https://arxiv.org/abs/2402.18579)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The parametric constant false alarm rate (CFAR) detection algorithms which are based on various statistical distributions, such as Gaussian, Gamma, Weibull, log-normal, G0 distribution, alpha-stable distribution, etc, are most widely used to detect the ship targets in SAR image at present. However, the clutter background in SAR images is complicated and variable. When the actual clutter background deviates from the assumed statistical distribution, the performance of the parametric CFAR detector will deteriorate. In addition to the parametric CFAR schemes, there is another class of nonparametric CFAR detectors which can maintain a constant false alarm rate for the target detection without the assumption of a known clutter distribution. In this work, the Wilcoxon nonparametric CFAR scheme for ship detection in SAR image is proposed and analyzed, and a closed form of the false alarm rate for the Wilcoxon nonparametric detector to determine the decision threshold is presented. By comparison with several typical parametric CFAR schemes on Radarsat-2, ICEYE-X6 and Gaofen-3 SAR images, the robustness of the Wilcoxon nonparametric detector to maintain a good false alarm performance in different detection backgrounds is revealed, and its detection performance for the weak ship in rough sea surface is improved to some extent. Moreover, the Wilcoxon nonparametric detector can suppress the false alarms resulting from the sidelobes at some degree and its detection speed is fast.</li>
</ul>

<h3>Title: MMSR: Symbolic Regression is a Multimodal Task</h3>
<ul>
<li><strong>Authors: </strong>Yanjie Li, Jingyi Liu, Weijun Li, Lina Yu, Min Wu, Wenqiang Li, Meilan Hao, Su Wei, Yusong Deng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18603">https://arxiv.org/abs/2402.18603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18603">https://arxiv.org/pdf/2402.18603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18603]] MMSR: Symbolic Regression is a Multimodal Task(https://arxiv.org/abs/2402.18603)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Mathematical formulas are the crystallization of human wisdom in exploring the laws of nature for thousands of years. Describing the complex laws of nature with a concise mathematical formula is a constant pursuit of scientists and a great challenge for artificial intelligence. This field is called symbolic regression. Symbolic regression was originally formulated as a combinatorial optimization problem, and GP and reinforcement learning algorithms were used to solve it. However, GP is sensitive to hyperparameters, and these two types of algorithms are inefficient. To solve this problem, researchers treat the mapping from data to expressions as a translation problem. And the corresponding large-scale pre-trained model is introduced. However, the data and expression skeletons do not have very clear word correspondences as the two languages do. Instead, they are more like two modalities (e.g., image and text). Therefore, in this paper, we proposed MMSR. The SR problem is solved as a pure multimodal problem, and contrastive learning is also introduced in the training process for modal alignment to facilitate later modal feature fusion. It is worth noting that in order to better promote the modal feature fusion, we adopt the strategy of training contrastive learning loss and other losses at the same time, which only needs one-step training, instead of training contrastive learning loss first and then training other losses. Because our experiments prove training together can make the feature extraction module and feature fusion module running-in better. Experimental results show that compared with multiple large-scale pre-training baselines, MMSR achieves the most advanced results on multiple mainstream datasets including SRBench.</li>
</ul>

<h3>Title: Impact of network topology on the performance of Decentralized Federated  Learning</h3>
<ul>
<li><strong>Authors: </strong>Luigi Palmieri, Chiara Boldrini, Lorenzo Valerio, Andrea Passarella, Marco Conti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18606">https://arxiv.org/abs/2402.18606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18606">https://arxiv.org/pdf/2402.18606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18606]] Impact of network topology on the performance of Decentralized Federated  Learning(https://arxiv.org/abs/2402.18606)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Fully decentralized learning is gaining momentum for training AI models at the Internet's edge, addressing infrastructure challenges and privacy concerns. In a decentralized machine learning system, data is distributed across multiple nodes, with each node training a local model based on its respective dataset. The local models are then shared and combined to form a global model capable of making accurate predictions on new data. Our exploration focuses on how different types of network structures influence the spreading of knowledge - the process by which nodes incorporate insights gained from learning patterns in data available on other nodes across the network. Specifically, this study investigates the intricate interplay between network structure and learning performance using three network topologies and six data distribution methods. These methods consider different vertex properties, including degree centrality, betweenness centrality, and clustering coefficient, along with whether nodes exhibit high or low values of these metrics. Our findings underscore the significance of global centrality metrics (degree, betweenness) in correlating with learning performance, while local clustering proves less predictive. We highlight the challenges in transferring knowledge from peripheral to central nodes, attributed to a dilution effect during model aggregation. Additionally, we observe that central nodes exert a pull effect, facilitating the spread of knowledge. In examining degree distribution, hubs in Barabasi-Albert networks positively impact learning for central nodes but exacerbate dilution when knowledge originates from peripheral nodes. Finally, we demonstrate the formidable challenge of knowledge circulation outside of segregated communities.</li>
</ul>

<h3>Title: Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An  Adversarial Perspective</h3>
<ul>
<li><strong>Authors: </strong>Xinjian Luo, Yangfan Jiang, Fei Wei, Yuncheng Wu, Xiaokui Xiao, Beng Chin Ooi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18607">https://arxiv.org/abs/2402.18607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18607">https://arxiv.org/pdf/2402.18607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18607]] Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An  Adversarial Perspective(https://arxiv.org/abs/2402.18607)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust, fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined. In this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execute fairness poisoning attacks to undermine the receiver's downstream models by manipulating the training data distribution of the diffusion model. Meanwhile, the receiver can perform property inference attacks to reveal the distribution of sensitive features in the sharer's dataset. Our experiments conducted on real-world datasets demonstrate remarkable attack performance on different types of diffusion models, which highlights the critical importance of robust data auditing and privacy protection protocols in pertinent applications.</li>
</ul>

<h3>Title: ICE-SEARCH: A Language Model-Driven Feature Selection Approach</h3>
<ul>
<li><strong>Authors: </strong>Tianze (Tom)Yang, Tianyi (Tim)Yang, Shaoshan Liu, Fuyuan Lvu, Xue Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18609">https://arxiv.org/abs/2402.18609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18609">https://arxiv.org/pdf/2402.18609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18609]] ICE-SEARCH: A Language Model-Driven Feature Selection Approach(https://arxiv.org/abs/2402.18609)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and mutation capabilities inherent in LMs within an evolutionary framework, significantly improving FS through the model's comprehensive world knowledge and its adaptability to a variety of roles. Our evaluation of this methodology spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular disease prediction. Our results not only demonstrate the efficacy of ICE-SEARCH in medical FS but also underscore the versatility, efficiency, and scalability of integrating LMs in FS tasks. The study emphasizes the critical role of incorporating domain-specific insights, illustrating ICE-SEARCH's robustness, generalizability, and swift convergence. This opens avenues for further research into comprehensive and intricate FS landscapes, marking a significant stride in the application of artificial intelligence in medical predictive analytics.</li>
</ul>

<h3>Title: A New Era in LLM Security: Exploring Security Concerns in Real-World  LLM-based Systems</h3>
<ul>
<li><strong>Authors: </strong>Fangzhou Wu, Ning Zhang, Somesh Jha, Patrick McDaniel, Chaowei Xiao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18649">https://arxiv.org/abs/2402.18649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18649">https://arxiv.org/pdf/2402.18649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18649]] A New Era in LLM Security: Exploring Security Concerns in Real-World  LLM-based Systems(https://arxiv.org/abs/2402.18649)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) systems are inherently compositional, with individual LLM serving as the core foundation with additional layers of objects such as plugins, sandbox, and so on. Along with the great potential, there are also increasing concerns over the security of such probabilistic intelligent systems. However, existing studies on LLM security often focus on individual LLM, but without examining the ecosystem through the lens of LLM systems with other objects (e.g., Frontend, Webtool, Sandbox, and so on). In this paper, we systematically analyze the security of LLM systems, instead of focusing on the individual LLMs. To do so, we build on top of the information flow and formulate the security of LLM systems as constraints on the alignment of the information flow within LLM and between LLM and other objects. Based on this construction and the unique probabilistic nature of LLM, the attack surface of the LLM system can be decomposed into three key components: (1) multi-layer security analysis, (2) analysis of the existence of constraints, and (3) analysis of the robustness of these constraints. To ground this new attack surface, we propose a multi-layer and multi-step approach and apply it to the state-of-art LLM system, OpenAI GPT4. Our investigation exposes several security issues, not just within the LLM model itself but also in its integration with other components. We found that although the OpenAI GPT4 has designed numerous safety constraints to improve its safety features, these safety constraints are still vulnerable to attackers. To further demonstrate the real-world threats of our discovered vulnerabilities, we construct an end-to-end attack where an adversary can illicitly acquire the user's chat history, all without the need to manipulate the user's input or gain direct access to OpenAI GPT4. Our demo is in the link: https://fzwark.github.io/LLM-System-Attack-Demo/</li>
</ul>

<h3>Title: Spatial Variation-Aware Read Disturbance Defenses: Experimental Analysis  of Real DRAM Chips and Implications on Future Solutions</h3>
<ul>
<li><strong>Authors: </strong>Abdullah Giray Yağlıkçı, Yahya Can Tuğrul, Geraldo F. Oliveira, İsmail Emir Yüksel, Ataberk Olgun, Haocong Luo, Onur Mutlu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18652">https://arxiv.org/abs/2402.18652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18652">https://arxiv.org/pdf/2402.18652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18652]] Spatial Variation-Aware Read Disturbance Defenses: Experimental Analysis  of Real DRAM Chips and Implications on Future Solutions(https://arxiv.org/abs/2402.18652)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust</a></li>
<li><strong>Abstract: </strong>Read disturbance in modern DRAM chips is a widespread phenomenon and is reliably used for breaking memory isolation, a fundamental building block for building robust systems. RowHammer and RowPress are two examples of read disturbance in DRAM where repeatedly accessing (hammering) or keeping active (pressing) a memory location induces bitflips in other memory locations. Unfortunately, shrinking technology node size exacerbates read disturbance in DRAM chips over generations. As a result, existing defense mechanisms suffer from significant performance and energy overheads, limited effectiveness, or prohibitively high hardware complexity. In this paper, we tackle these shortcomings by leveraging the spatial variation in read disturbance across different memory locations in real DRAM chips. To do so, we 1) present the first rigorous real DRAM chip characterization study of spatial variation of read disturbance and 2) propose Sv\"ard, a new mechanism that dynamically adapts the aggressiveness of existing solutions based on the row-level read disturbance profile. Our experimental characterization on 144 real DDR4 DRAM chips representing 10 chip designs demonstrates a large variation in read disturbance vulnerability across different memory locations: in the part of memory with the worst read disturbance vulnerability, 1) up to 2x the number of bitflips can occur and 2) bitflips can occur at an order of magnitude fewer accesses, compared to the memory locations with the least vulnerability to read disturbance. Sv\"ard leverages this variation to reduce the overheads of five state-of-the-art read disturbance solutions, and thus significantly increases system performance.</li>
</ul>

<h3>Title: Large Language Models and Games: A Survey and Roadmap</h3>
<ul>
<li><strong>Authors: </strong>Roberto Gallotta, Graham Todd, Marvin Zammit, Sam Earle, Antonios Liapis, Julian Togelius, Georgios N. Yannakakis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18659">https://arxiv.org/abs/2402.18659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18659">https://arxiv.org/pdf/2402.18659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18659]] Large Language Models and Games: A Survey and Roadmap(https://arxiv.org/abs/2402.18659)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.</li>
</ul>

<h3>Title: FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability</h3>
<ul>
<li><strong>Authors: </strong>Congying Xia, Chen Xing, Jiangshu Du, Xinyi Yang, Yihao Feng, Ran Xu, Wenpeng Yin, Caiming Xiong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18667">https://arxiv.org/abs/2402.18667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18667">https://arxiv.org/pdf/2402.18667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18667]] FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability(https://arxiv.org/abs/2402.18667)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents FoFo, a pioneering benchmark for evaluating large language models' (LLMs) ability to follow complex, domain-specific formats, a crucial yet underexamined capability for their application as AI agents. Despite LLMs' advancements, existing benchmarks fail to assess their format-following proficiency adequately. FoFo fills this gap with a diverse range of real-world formats and instructions, developed through an AI-Human collaborative method. Our evaluation across both open-source (e.g., Llama 2, WizardLM) and closed-source (e.g., GPT-4, PALM2, Gemini) LLMs highlights three key findings: open-source models significantly lag behind closed-source ones in format adherence; LLMs' format-following performance is independent of their content generation quality; and LLMs' format proficiency varies across different domains. These insights suggest the need for specialized tuning for format-following skills and highlight FoFo's role in guiding the selection of domain-specific AI agents. FoFo is released here at https://github.com/SalesforceAIResearch/FoFo.</li>
</ul>

<h3>Title: RORA: Robust Free-Text Rationale Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Zhengping Jiang, Yining Lu, Hanjie Chen, Daniel Khashabi, Benjamin Van Durme, Anqi Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18678">https://arxiv.org/abs/2402.18678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18678">https://arxiv.org/pdf/2402.18678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18678]] RORA: Robust Free-Text Rationale Evaluation(https://arxiv.org/abs/2402.18678)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Free-text rationales play a pivotal role in explainable NLP, bridging the knowledge and reasoning gaps behind a model's decision-making. However, due to the diversity of potential reasoning paths and a corresponding lack of definitive ground truth, their evaluation remains a challenge. Existing evaluation metrics rely on the degree to which a rationale supports a target label, but we find these fall short in evaluating rationales that inadvertently leak the labels. To address this problem, we propose RORA, a Robust free-text Rationale evaluation against label leakage. RORA quantifies the new information supplied by a rationale to justify the label. This is achieved by assessing the conditional V-information \citep{hewitt-etal-2021-conditional} with a predictive family robust against leaky features that can be exploited by a small model. RORA consistently outperforms existing approaches in evaluating human-written, synthetic, or model-generated rationales, particularly demonstrating robustness against label leakage. We also show that RORA aligns well with human judgment, providing a more reliable and accurate measurement across diverse free-text rationales.</li>
</ul>

<h3>Title: Grounding Language Models for Visual Entity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Zilin Xiao, Ming Gong, Paola Cascante-Bonilla, Xingyao Zhang, Jie Wu, Vicente Ordonez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18695">https://arxiv.org/abs/2402.18695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18695">https://arxiv.org/pdf/2402.18695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18695]] Grounding Language Models for Visual Entity Recognition(https://arxiv.org/abs/2402.18695)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce AutoVER, an Autoregressive model for Visual Entity Recognition. Our model extends an autoregressive Multi-modal Large Language Model by employing retrieval augmented constrained generation. It mitigates low performance on out-of-domain entities while excelling in queries that require visually-situated reasoning. Our method learns to distinguish similar entities within a vast label space by contrastively training on hard negative pairs in parallel with a sequence-to-sequence objective without an external retriever. During inference, a list of retrieved candidate answers explicitly guides language generation by removing invalid decoding paths. The proposed method achieves significant improvements across different dataset splits in the recently proposed Oven-Wiki benchmark. Accuracy on the Entity seen split rises from 32.7% to 61.5%. It also demonstrates superior performance on the unseen and query splits by a substantial double-digit margin.</li>
</ul>

<h3>Title: Spatial Coherence Loss for Salient and Camouflaged Object Detection and  Beyond</h3>
<ul>
<li><strong>Authors: </strong>Ziyun Yang, Kevin Choy, Sina Farsiu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18698">https://arxiv.org/abs/2402.18698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18698">https://arxiv.org/pdf/2402.18698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18698]] Spatial Coherence Loss for Salient and Camouflaged Object Detection and  Beyond(https://arxiv.org/abs/2402.18698)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Generic object detection is a category-independent task that relies on accurate modeling of objectness. Most relevant CNN-based models of objectness utilize loss functions (e.g., binary cross entropy) that focus on the single-response, i.e., the loss response of a single pixel. Inspired by the human visual system, which first discerns the boundaries of ambiguous regions (i.e., hard regions) before delving into the semantic meaning, we propose a novel loss function, Spatial Coherence Loss (SCLoss), that uses the mutual response between adjacent pixels to suppress or emphasize the single-response of pixels. We demonstrate that the proposed SCLoss can gradually learn the hard regions by detecting and emphasizing their boundaries. Through comprehensive experiments, we demonstrate that replacing popular loss functions with SCLoss can improve the performance of current state-of-the-art (SOTA) salient or camouflaged object detection (SOD or COD) models. We also demonstrate that combining SCLoss with other loss functions can further improve performance and result in the SOTA outcomes for different applications. Finally, as a demonstrative example of the potential uses for other related tasks, we show an application of SCLoss for semantic segmentation.</li>
</ul>

<h3>Title: Learning to Compress Prompt in Natural Language Formats</h3>
<ul>
<li><strong>Authors: </strong>Yu-Neng Chuang, Tianwei Xing, Chia-Yuan Chang, Zirui Liu, Xun Chen, Xia Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18700">https://arxiv.org/abs/2402.18700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18700">https://arxiv.org/pdf/2402.18700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18700]] Learning to Compress Prompt in Natural Language Formats(https://arxiv.org/abs/2402.18700)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are great at processing multiple natural language processing tasks, but their abilities are constrained by inferior performance with long context, slow inference speed, and the high cost of computing the results. Deploying LLMs with precise and informative context helps users process large-scale datasets more effectively and cost-efficiently. Existing works rely on compressing long prompt contexts into soft prompts. However, soft prompt compression encounters limitations in transferability across different LLMs, especially API-based LLMs. To this end, this work aims to compress lengthy prompts in the form of natural language with LLM transferability. This poses two challenges: (i) Natural Language (NL) prompts are incompatible with back-propagation, and (ii) NL prompts lack flexibility in imposing length constraints. In this work, we propose a Natural Language Prompt Encapsulation (Nano-Capsulator) framework compressing original prompts into NL formatted Capsule Prompt while maintaining the prompt utility and transferability. Specifically, to tackle the first challenge, the Nano-Capsulator is optimized by a reward function that interacts with the proposed semantics preserving loss. To address the second question, the Nano-Capsulator is optimized by a reward function featuring length constraints. Experimental results demonstrate that the Capsule Prompt can reduce 81.4% of the original length, decrease inference latency up to 4.5x, and save 80.1% of budget overheads while providing transferability across diverse LLMs and different datasets.</li>
</ul>

<h3>Title: Model Pairing Using Embedding Translation for Backdoor Attack Detection  on Open-Set Classification Tasks</h3>
<ul>
<li><strong>Authors: </strong>Alexander Unnervik, Hatef Otroshi Shahreza, Anjith George, Sébastien Marcel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18718">https://arxiv.org/abs/2402.18718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18718">https://arxiv.org/pdf/2402.18718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18718]] Model Pairing Using Embedding Translation for Backdoor Attack Detection  on Open-Set Classification Tasks(https://arxiv.org/abs/2402.18718)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, biometric</a></li>
<li><strong>Abstract: </strong>Backdoor attacks allow an attacker to embed a specific vulnerability in a machine learning algorithm, activated when an attacker-chosen pattern is presented, causing a specific misprediction. The need to identify backdoors in biometric scenarios has led us to propose a novel technique with different trade-offs. In this paper we propose to use model pairs on open-set classification tasks for detecting backdoors. Using a simple linear operation to project embeddings from a probe model's embedding space to a reference model's embedding space, we can compare both embeddings and compute a similarity score. We show that this score, can be an indicator for the presence of a backdoor despite models being of different architectures, having been trained independently and on different datasets. Additionally, we show that backdoors can be detected even when both models are backdoored. The source code is made available for reproducibility purposes.</li>
</ul>

<h3>Title: Learning Associative Memories with Gradient Descent</h3>
<ul>
<li><strong>Authors: </strong>Vivien Cabannes, Berfin Simsek, Alberto Bietti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18724">https://arxiv.org/abs/2402.18724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18724">https://arxiv.org/pdf/2402.18724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18724]] Learning Associative Memories with Gradient Descent(https://arxiv.org/abs/2402.18724)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This work focuses on the training dynamics of one associative memory module storing outer products of token embeddings. We reduce this problem to the study of a system of particles, which interact according to properties of the data distribution and correlations between embeddings. Through theory and experiments, we provide several insights. In overparameterized regimes, we obtain logarithmic growth of the ``classification margins.'' Yet, we show that imbalance in token frequencies and memory interferences due to correlated embeddings lead to oscillatory transitory regimes. The oscillations are more pronounced with large step sizes, which can create benign loss spikes, although these learning rates speed up the dynamics and accelerate the asymptotic convergence. In underparameterized regimes, we illustrate how the cross-entropy loss can lead to suboptimal memorization schemes. Finally, we assess the validity of our findings on small Transformer models.</li>
</ul>

<h3>Title: Unveiling Privacy, Memorization, and Input Curvature Links</h3>
<ul>
<li><strong>Authors: </strong>Deepak Ravikumar, Efstathia Soufleri, Abolfazl Hashemi, Kaushik Roy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18726">https://arxiv.org/abs/2402.18726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18726">https://arxiv.org/pdf/2402.18726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18726]] Unveiling Privacy, Memorization, and Input Curvature Links(https://arxiv.org/abs/2402.18726)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Deep Neural Nets (DNNs) have become a pervasive tool for solving many emerging problems. However, they tend to overfit to and memorize the training set. Memorization is of keen interest since it is closely related to several concepts such as generalization, noisy learning, and privacy. To study memorization, Feldman (2019) proposed a formal score, however its computational requirements limit its practical use. Recent research has shown empirical evidence linking input loss curvature (measured by the trace of the loss Hessian w.r.t inputs) and memorization. It was shown to be ~3 orders of magnitude more efficient than calculating the memorization score. However, there is a lack of theoretical understanding linking memorization with input loss curvature. In this paper, we not only investigate this connection but also extend our analysis to establish theoretical links between differential privacy, memorization, and input loss curvature. First, we derive an upper bound on memorization characterized by both differential privacy and input loss curvature. Second, we present a novel insight showing that input loss curvature is upper-bounded by the differential privacy parameter. Our theoretical findings are further empirically validated using deep models on CIFAR and ImageNet datasets, showing a strong correlation between our theoretical predictions and results observed in practice.</li>
</ul>

<h3>Title: Priority Sampling of Large Language Models for Compilers</h3>
<ul>
<li><strong>Authors: </strong>Dejan Grubisic, Chris Cummins, Volker Seeker, Hugh Leather</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18734">https://arxiv.org/abs/2402.18734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18734">https://arxiv.org/pdf/2402.18734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18734]] Priority Sampling of Large Language Models for Compilers(https://arxiv.org/abs/2402.18734)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models show great potential in generating and optimizing code. Widely used sampling methods such as Nucleus Sampling increase the diversity of generation but often produce repeated samples for low temperatures and incoherent samples for high temperatures. Furthermore, the temperature coefficient has to be tuned for each task, limiting its usability. We present Priority Sampling, a simple and deterministic sampling technique that produces unique samples ordered by the model's confidence. Each new sample expands the unexpanded token with the highest probability in the augmented search tree. Additionally, Priority Sampling supports generation based on regular expression that provides a controllable and structured exploration process. Priority Sampling outperforms Nucleus Sampling for any number of samples, boosting the performance of the original model from 2.87% to 5% improvement over -Oz. Moreover, it outperforms the autotuner used for the generation of labels for the training of the original model in just 30 samples.</li>
</ul>

<h3>Title: Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains</h3>
<ul>
<li><strong>Authors: </strong>Vilém Zouhar, Shuoyang Ding, Anna Currey, Tatyana Badeka, Jenyuan Wang, Brian Thompson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18747">https://arxiv.org/abs/2402.18747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18747">https://arxiv.org/pdf/2402.18747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18747]] Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains(https://arxiv.org/abs/2402.18747)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this dataset to investigate whether machine translation (MT) metrics which are fine-tuned on human-generated MT quality judgements are robust to domain shifts between training and inference. We find that fine-tuned metrics exhibit a substantial performance drop in the unseen domain scenario relative to metrics that rely on the surface form, as well as pre-trained metrics which are not fine-tuned on MT quality judgments.</li>
</ul>

<h3>Title: Pre-training Differentially Private Models with Limited Public Data</h3>
<ul>
<li><strong>Authors: </strong>Zhiqi Bu, Xinwei Zhang, Mingyi Hong, Sheng Zha, George Karypis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18752">https://arxiv.org/abs/2402.18752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18752">https://arxiv.org/pdf/2402.18752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18752]] Pre-training Differentially Private Models with Limited Public Data(https://arxiv.org/abs/2402.18752)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect</a></li>
<li><strong>Abstract: </strong>The superior performance of large foundation models relies on the use of massive amounts of high-quality data, which often contain sensitive, private and copyrighted material that requires formal protection. While differential privacy (DP) is a prominent method to gauge the degree of security provided to the models, its application is commonly limited to the model fine-tuning stage, due to the performance degradation when applying DP during the pre-training stage. Consequently, DP is yet not capable of protecting a substantial portion of the data used during the initial pre-training process. In this work, we first provide a theoretical understanding of the efficacy of DP training by analyzing the per-iteration loss improvement. We make a key observation that DP optimizers' performance degradation can be significantly mitigated by the use of limited public data, which leads to a novel DP continual pre-training strategy. Empirically, using only 10\% of public data, our strategy can achieve DP accuracy of 41.5\% on ImageNet-21k (with $\epsilon=8$), as well as non-DP accuracy of 55.7\% and and 60.0\% on downstream tasks Places365 and iNaturalist-2021, respectively, on par with state-of-the-art standard pre-training and substantially outperforming existing DP pre-trained models.</li>
</ul>

<h3>Title: On Defeating Graph Analysis of Anonymous Transactions</h3>
<ul>
<li><strong>Authors: </strong>Christoph Egger, Russell W. F. Lai, Viktoria Ronge, Ivy K. Y. Woo, Hoover H. F. Yin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18755">https://arxiv.org/abs/2402.18755</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18755">https://arxiv.org/pdf/2402.18755</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18755]] On Defeating Graph Analysis of Anonymous Transactions(https://arxiv.org/abs/2402.18755)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In a ring-signature-based anonymous cryptocurrency, signers of a transaction are hidden among a set of potential signers, called a ring, whose size is much smaller than the number of all users. The ring-membership relations specified by the sets of transactions thus induce bipartite transaction graphs, whose distribution is in turn induced by the ring sampler underlying the cryptocurrency. Since efficient graph analysis could be performed on transaction graphs to potentially deanonymise signers, it is crucial to understand the resistance of (the transaction graphs induced by) a ring sampler against graph analysis. Of particular interest is the class of partitioning ring samplers. Although previous works showed that they provide almost optimal local anonymity, their resistance against global, e.g. graph-based, attacks were unclear. In this work, we analyse transaction graphs induced by partitioning ring samplers. Specifically, we show (partly analytically and partly empirically) that, somewhat surprisingly, by setting the ring size to be at least logarithmic in the number of users, a graph-analysing adversary is no better than the one that performs random guessing in deanonymisation up to constant factor of 2.</li>
</ul>

<h3>Title: Disentangling the Causes of Plasticity Loss in Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Clare Lyle, Zeyu Zheng, Khimya Khetarpal, Hado van Hasselt, Razvan Pascanu, James Martens, Will Dabney</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18762">https://arxiv.org/abs/2402.18762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18762">https://arxiv.org/pdf/2402.18762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18762]] Disentangling the Causes of Plasticity Loss in Neural Networks(https://arxiv.org/abs/2402.18762)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Underpinning the past decades of work on the design, initialization, and optimization of neural networks is a seemingly innocuous assumption: that the network is trained on a \textit{stationary} data distribution. In settings where this assumption is violated, e.g.\ deep reinforcement learning, learning algorithms become unstable and brittle with respect to hyperparameters and even random seeds. One factor driving this instability is the loss of plasticity, meaning that updating the network's predictions in response to new information becomes more difficult as training progresses. While many recent works provide analyses and partial solutions to this phenomenon, a fundamental question remains unanswered: to what extent do known mechanisms of plasticity loss overlap, and how can mitigation strategies be combined to best maintain the trainability of a network? This paper addresses these questions, showing that loss of plasticity can be decomposed into multiple independent mechanisms and that, while intervening on any single mechanism is insufficient to avoid the loss of plasticity in all cases, intervening on multiple mechanisms in conjunction results in highly robust learning algorithms. We show that a combination of layer normalization and weight decay is highly effective at maintaining plasticity in a variety of synthetic nonstationary learning tasks, and further demonstrate its effectiveness on naturally arising nonstationarities, including reinforcement learning in the Arcade Learning Environment.</li>
</ul>

<h3>Title: Advancing Generative AI for Portuguese with Open Decoder Gervásio PT*</h3>
<ul>
<li><strong>Authors: </strong>Rodrigo Santos, João Silva, Luís Gomes, João Rodrigues, António Branco</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18766">https://arxiv.org/abs/2402.18766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18766">https://arxiv.org/pdf/2402.18766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18766]] Advancing Generative AI for Portuguese with Open Decoder Gervásio PT*(https://arxiv.org/abs/2402.18766)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>To advance the neural decoding of Portuguese, in this paper we present a fully open Transformer-based, instruction-tuned decoder model that sets a new state of the art in this respect. To develop this decoder, which we named Gerv\'asio PT*, a strong LLaMA~2 7B model was used as a starting point, and its further improvement through additional training was done over language resources that include new instruction data sets of Portuguese prepared for this purpose, which are also contributed in this paper. All versions of Gerv\'asio are open source and distributed for free under an open license, including for either research or commercial usage, and can be run on consumer-grade hardware, thus seeking to contribute to the advancement of research and innovation in language technology for Portuguese.</li>
</ul>

<h3>Title: CoMeT: Count-Min-Sketch-based Row Tracking to Mitigate RowHammer at Low  Cost</h3>
<ul>
<li><strong>Authors: </strong>F. Nisa Bostanci, Ismail Emir Yuksel, Ataberk Olgun, Konstantinos Kanellopoulos, Yahya Can Tugrul, A. Giray Yaglikci, Mohammad Sadrosadati, Onur Mutlu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18769">https://arxiv.org/abs/2402.18769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18769">https://arxiv.org/pdf/2402.18769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18769]] CoMeT: Count-Min-Sketch-based Row Tracking to Mitigate RowHammer at Low  Cost(https://arxiv.org/abs/2402.18769)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>We propose a new RowHammer mitigation mechanism, CoMeT, that prevents RowHammer bitflips with low area, performance, and energy costs in DRAM-based systems at very low RowHammer thresholds. The key idea of CoMeT is to use low-cost and scalable hash-based counters to track DRAM row activations. CoMeT uses the Count-Min Sketch technique that maps each DRAM row to a group of counters, as uniquely as possible, using multiple hash functions. When a DRAM row is activated, CoMeT increments the counters mapped to that DRAM row. Because the mapping from DRAM rows to counters is not completely unique, activating one row can increment one or more counters mapped to another row. Thus, CoMeT may overestimate, but never underestimates, a DRAM row's activation count. This property of CoMeT allows it to securely prevent RowHammer bitflips while properly configuring its hash functions reduces overestimations. As a result, CoMeT 1) implements substantially fewer counters than the number of DRAM rows in a DRAM bank and 2) does not significantly overestimate a DRAM row's activation count. Our comprehensive evaluations show that CoMeT prevents RowHammer bitflips with an average performance overhead of only 4.01% across 61 benign single-core workloads for a very low RowHammer threshold of 125, normalized to a system with no RowHammer mitigation. CoMeT achieves a good trade-off between performance, energy, and area overheads. Compared to the best-performing state-of-the-art mitigation, CoMeT requires 74.2x less area overhead at the RowHammer threshold 125 and incurs a small performance overhead on average for all RowHammer thresholds. Compared to the best-performing low-area-cost mechanism, at a very low RowHammer threshold of 125, CoMeT improves performance by up to 39.1% while incurring a similar area overhead. CoMeT is openly and freely available at https://github.com/CMU-SAFARI/CoMeT.</li>
</ul>

<h3>Title: A Quantitative Evaluation of Score Distillation Sampling Based  Text-to-3D</h3>
<ul>
<li><strong>Authors: </strong>Xiaohan Fei, Chethan Parameshwara, Jiawei Mo, Xiaolong Li, Ashwin Swaminathan, CJ Taylor, Paolo Favaro, Stefano Soatto</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18780">https://arxiv.org/abs/2402.18780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18780">https://arxiv.org/pdf/2402.18780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18780]] A Quantitative Evaluation of Score Distillation Sampling Based  Text-to-3D(https://arxiv.org/abs/2402.18780)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The development of generative models that create 3D content from a text prompt has made considerable strides thanks to the use of the score distillation sampling (SDS) method on pre-trained diffusion models for image generation. However, the SDS method is also the source of several artifacts, such as the Janus problem, the misalignment between the text prompt and the generated 3D model, and 3D model inaccuracies. While existing methods heavily rely on the qualitative assessment of these artifacts through visual inspection of a limited set of samples, in this work we propose more objective quantitative evaluation metrics, which we cross-validate via human ratings, and show analysis of the failure cases of the SDS technique. We demonstrate the effectiveness of this analysis by designing a novel computationally efficient baseline model that achieves state-of-the-art performance on the proposed metrics while addressing all the above-mentioned artifacts.</li>
</ul>

<h3>Title: OpticalDR: A Deep Optical Imaging Model for Privacy-Protective  Depression Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Pan, Junjun Jiang, Kui Jiang, Zhihao Wu, Keyuan Yu, Xianming Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18786">https://arxiv.org/abs/2402.18786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18786">https://arxiv.org/pdf/2402.18786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18786]] OpticalDR: A Deep Optical Imaging Model for Privacy-Protective  Depression Recognition(https://arxiv.org/abs/2402.18786)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Depression Recognition (DR) poses a considerable challenge, especially in the context of the growing concerns surrounding privacy. Traditional automatic diagnosis of DR technology necessitates the use of facial images, undoubtedly expose the patient identity features and poses privacy risks. In order to mitigate the potential risks associated with the inappropriate disclosure of patient facial images, we design a new imaging system to erase the identity information of captured facial images while retain disease-relevant features. It is irreversible for identity information recovery while preserving essential disease-related characteristics necessary for accurate DR. More specifically, we try to record a de-identified facial image (erasing the identifiable features as much as possible) by a learnable lens, which is optimized in conjunction with the following DR task as well as a range of face analysis related auxiliary tasks in an end-to-end manner. These aforementioned strategies form our final Optical deep Depression Recognition network (OpticalDR). Experiments on CelebA, AVEC 2013, and AVEC 2014 datasets demonstrate that our OpticalDR has achieved state-of-the-art privacy protection performance with an average AUC of 0.51 on popular facial recognition models, and competitive results for DR with MAE/RMSE of 7.53/8.48 on AVEC 2013 and 7.89/8.82 on AVEC 2014, respectively.</li>
</ul>

<h3>Title: Enhancing the "Immunity" of Mixture-of-Experts Networks for Adversarial  Defense</h3>
<ul>
<li><strong>Authors: </strong>Qiao Han, yong huang, xinling Guo, Yiteng Zhai, Yu Qin, Yao Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18787">https://arxiv.org/abs/2402.18787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18787">https://arxiv.org/pdf/2402.18787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18787]] Enhancing the "Immunity" of Mixture-of-Experts Networks for Adversarial  Defense(https://arxiv.org/abs/2402.18787)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Recent studies have revealed the vulnerability of Deep Neural Networks (DNNs) to adversarial examples, which can easily fool DNNs into making incorrect predictions. To mitigate this deficiency, we propose a novel adversarial defense method called "Immunity" (Innovative MoE with MUtual information \& positioN stabilITY) based on a modified Mixture-of-Experts (MoE) architecture in this work. The key enhancements to the standard MoE are two-fold: 1) integrating of Random Switch Gates (RSGs) to obtain diverse network structures via random permutation of RSG parameters at evaluation time, despite of RSGs being determined after one-time training; 2) devising innovative Mutual Information (MI)-based and Position Stability-based loss functions by capitalizing on Grad-CAM's explanatory power to increase the diversity and the causality of expert networks. Notably, our MI-based loss operates directly on the heatmaps, thereby inducing subtler negative impacts on the classification performance when compared to other losses of the same type, theoretically. Extensive evaluation validates the efficacy of the proposed approach in improving adversarial robustness against a wide range of attacks.</li>
</ul>

<h3>Title: MPAT: Building Robust Deep Neural Networks against Textual Adversarial  Attacks</h3>
<ul>
<li><strong>Authors: </strong>Fangyuan Zhang, Huichi Zhou, Shuangjiao Li, Hongtao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18792">https://arxiv.org/abs/2402.18792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18792">https://arxiv.org/pdf/2402.18792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18792]] MPAT: Building Robust Deep Neural Networks against Textual Adversarial  Attacks(https://arxiv.org/abs/2402.18792)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks have been proven to be vulnerable to adversarial examples and various methods have been proposed to defend against adversarial attacks for natural language processing tasks. However, previous defense methods have limitations in maintaining effective defense while ensuring the performance of the original task. In this paper, we propose a malicious perturbation based adversarial training method (MPAT) for building robust deep neural networks against textual adversarial attacks. Specifically, we construct a multi-level malicious example generation strategy to generate adversarial examples with malicious perturbations, which are used instead of original inputs for model training. Additionally, we employ a novel training objective function to ensure achieving the defense goal without compromising the performance on the original task. We conduct comprehensive experiments to evaluate our defense method by attacking five victim models on three benchmark datasets. The result demonstrates that our method is more effective against malicious adversarial attacks compared with previous defense methods while maintaining or further improving the performance on the original task.</li>
</ul>

<h3>Title: BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise  Missing Data</h3>
<ul>
<li><strong>Authors: </strong>Qiao Han, Mingqian Li, Yao Yang, Yiteng Zhai</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18800">https://arxiv.org/abs/2402.18800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18800">https://arxiv.org/pdf/2402.18800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18800]] BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise  Missing Data(https://arxiv.org/abs/2402.18800)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Block-wise missing data poses significant challenges in real-world data imputation tasks. Compared to scattered missing data, block-wise gaps exacerbate adverse effects on subsequent analytic and machine learning tasks, as the lack of local neighboring elements significantly reduces the interpolation capability and predictive power. However, this issue has not received adequate attention. Most SOTA matrix completion methods appeared less effective, primarily due to overreliance on neighboring elements for predictions. We systematically analyze the issue and propose a novel matrix completion method ``BlockEcho" for a more comprehensive solution. This method creatively integrates Matrix Factorization (MF) within Generative Adversarial Networks (GAN) to explicitly retain long-distance inter-element relationships in the original matrix. Besides, we incorporate an additional discriminator for GAN, comparing the generator's intermediate progress with pre-trained MF results to constrain high-order feature distributions. Subsequently, we evaluate BlockEcho on public datasets across three domains. Results demonstrate superior performance over both traditional and SOTA methods when imputing block-wise missing data, especially at higher missing rates. The advantage also holds for scattered missing data at high missing rates. We also contribute on the analyses in providing theoretical justification on the optimality and convergence of fusing MF and GAN for missing block data.</li>
</ul>

<h3>Title: To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair  Training on Shared Models</h3>
<ul>
<li><strong>Authors: </strong>Cyrus Cousins, I. Elizabeth Kumar, Suresh Venkatasubramanian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18803">https://arxiv.org/abs/2402.18803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18803">https://arxiv.org/pdf/2402.18803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18803]] To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair  Training on Shared Models(https://arxiv.org/abs/2402.18803)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>In fair machine learning, one source of performance disparities between groups is over-fitting to groups with relatively few training samples. We derive group-specific bounds on the generalization error of welfare-centric fair machine learning that benefit from the larger sample size of the majority group. We do this by considering group-specific Rademacher averages over a restricted hypothesis class, which contains the family of models likely to perform well with respect to a fair learning objective (e.g., a power-mean). Our simulations demonstrate these bounds improve over a naive method, as expected by theory, with particularly significant improvement for smaller group sizes.</li>
</ul>

<h3>Title: On the Decision-Making Abilities in Role-Playing using Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Chenglei Shen, Guofu Xie, Xiao Zhang, Jun Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18807">https://arxiv.org/abs/2402.18807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18807">https://arxiv.org/pdf/2402.18807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18807]] On the Decision-Making Abilities in Role-Playing using Large Language  Models(https://arxiv.org/abs/2402.18807)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are now increasingly utilized for role-playing tasks, especially in impersonating domain-specific experts, primarily through role-playing prompts. When interacting in real-world scenarios, the decision-making abilities of a role significantly shape its behavioral patterns. In this paper, we concentrate on evaluating the decision-making abilities of LLMs post role-playing thereby validating the efficacy of role-playing. Our goal is to provide metrics and guidance for enhancing the decision-making abilities of LLMs in role-playing tasks. Specifically, we first use LLMs to generate virtual role descriptions corresponding to the 16 personality types of Myers-Briggs Type Indicator (abbreviated as MBTI) representing a segmentation of the population. Then we design specific quantitative operations to evaluate the decision-making abilities of LLMs post role-playing from four aspects: adaptability, exploration$\&$exploitation trade-off ability, reasoning ability, and safety. Finally, we analyze the association between the performance of decision-making and the corresponding MBTI types through GPT-4. Extensive experiments demonstrate stable differences in the four aspects of decision-making abilities across distinct roles, signifying a robust correlation between decision-making abilities and the roles emulated by LLMs. These results underscore that LLMs can effectively impersonate varied roles while embodying their genuine sociological characteristics.</li>
</ul>

<h3>Title: BFRFormer: Transformer-based generator for Real-World Blind Face  Restoration</h3>
<ul>
<li><strong>Authors: </strong>Guojing Ge, Qi Song, Guibo Zhu, Yuting Zhang, Jinglu Chen, Miao Xin, Ming Tang, Jinqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18811">https://arxiv.org/abs/2402.18811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18811">https://arxiv.org/pdf/2402.18811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18811]] BFRFormer: Transformer-based generator for Real-World Blind Face  Restoration(https://arxiv.org/abs/2402.18811)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Blind face restoration is a challenging task due to the unknown and complex degradation. Although face prior-based methods and reference-based methods have recently demonstrated high-quality results, the restored images tend to contain over-smoothed results and lose identity-preserved details when the degradation is severe. It is observed that this is attributed to short-range dependencies, the intrinsic limitation of convolutional neural networks. To model long-range dependencies, we propose a Transformer-based blind face restoration method, named BFRFormer, to reconstruct images with more identity-preserved details in an end-to-end manner. In BFRFormer, to remove blocking artifacts, the wavelet discriminator and aggregated attention module are developed, and spectral normalization and balanced consistency regulation are adaptively applied to address the training instability and over-fitting problem, respectively. Extensive experiments show that our method outperforms state-of-the-art methods on a synthetic dataset and four real-world datasets. The source code, Casia-Test dataset, and pre-trained models are released at https://github.com/s8Znk/BFRFormer.</li>
</ul>

<h3>Title: How do Large Language Models Handle Multilingualism?</h3>
<ul>
<li><strong>Authors: </strong>Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, Lidong Bing</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18815">https://arxiv.org/abs/2402.18815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18815">https://arxiv.org/pdf/2402.18815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18815]] How do Large Language Models Handle Multilingualism?(https://arxiv.org/abs/2402.18815)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) demonstrate remarkable performance across a spectrum of languages. In this work, we delve into the question: How do LLMs handle multilingualism? We introduce a framework that depicts LLMs' processing of multilingual inputs: In the first several layers, LLMs understand the question, converting multilingual inputs into English to facilitate the task-solving phase. In the intermediate layers, LLMs engage in problem-solving by thinking in English and incorporating multilingual knowledge to obtain factual content, leveraging the self-attention and feed-forward structures, respectively. In the last several layers, LLMs generate responses that align with the original language of the query. In addition, we investigate the existence of language-specific neurons when processing a certain language. To detect neurons activated by the input language, even without labels, we innovatively design a Parallel Language specific Neuron Detection ($\texttt{PLND}$) method that effectively measures the significance of neurons when handling multilingual inputs. By comprehensive ablation analysis through deactivating neurons of different layers and structures, we verify the framework that we propose. Additionally, we demonstrate that we can utilize such a framework to effectively enhance the multilingual ability with much less training effort.</li>
</ul>

<h3>Title: Gradient Alignment for Cross-Domain Face Anti-Spoofing</h3>
<ul>
<li><strong>Authors: </strong>Binh M. Le, Simon S. Woo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18817">https://arxiv.org/abs/2402.18817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18817">https://arxiv.org/pdf/2402.18817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18817]] Gradient Alignment for Cross-Domain Face Anti-Spoofing(https://arxiv.org/abs/2402.18817)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in domain generalization (DG) for face anti-spoofing (FAS) have garnered considerable attention. Traditional methods have focused on designing learning objectives and additional modules to isolate domain-specific features while retaining domain-invariant characteristics in their representations. However, such approaches often lack guarantees of consistent maintenance of domain-invariant features or the complete removal of domain-specific features. Furthermore, most prior works of DG for FAS do not ensure convergence to a local flat minimum, which has been shown to be advantageous for DG. In this paper, we introduce GAC-FAS, a novel learning objective that encourages the model to converge towards an optimal flat minimum without necessitating additional learning modules. Unlike conventional sharpness-aware minimizers, GAC-FAS identifies ascending points for each domain and regulates the generalization gradient updates at these points to align coherently with empirical risk minimization (ERM) gradient updates. This unique approach specifically guides the model to be robust against domain shifts. We demonstrate the efficacy of GAC-FAS through rigorous testing on challenging cross-domain FAS datasets, where it establishes state-of-the-art performance. The code is available at https://github.com/leminhbinh0209/CVPR24-FAS.</li>
</ul>

<h3>Title: Dual Operating Modes of In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Ziqian Lin, Kangwook Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18819">https://arxiv.org/abs/2402.18819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18819">https://arxiv.org/pdf/2402.18819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18819]] Dual Operating Modes of In-Context Learning(https://arxiv.org/abs/2402.18819)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>In-context learning (ICL) exhibits dual operating modes: task learning, i.e., acquiring a new skill from in-context samples, and task retrieval, i.e., locating and activating a relevant pretrained skill. Recent theoretical work investigates various mathematical models to analyze ICL, but existing models explain only one operating mode at a time. We introduce a probabilistic model, with which one can explain the dual operating modes of ICL simultaneously. Focusing on in-context learning of linear functions, we extend existing models for pretraining data by introducing multiple task groups and task-dependent input distributions. We then analyze the behavior of the optimally pretrained model under the squared loss, i.e., the MMSE estimator of the label given in-context examples. Regarding pretraining task distribution as prior and in-context examples as the observation, we derive the closed-form expression of the task posterior distribution. With the closed-form expression, we obtain a quantitative understanding of the two operating modes of ICL. Furthermore, we shed light on an unexplained phenomenon observed in practice: under certain settings, the ICL risk initially increases and then decreases with more in-context examples. Our model offers a plausible explanation for this "early ascent" phenomenon: a limited number of in-context samples may lead to the retrieval of an incorrect skill, thereby increasing the risk, which will eventually diminish as task learning takes effect with more in-context samples. We also theoretically analyze ICL with biased labels, e.g., zero-shot ICL, where in-context examples are assigned random labels. Lastly, we validate our findings and predictions via experiments involving Transformers and large language models.</li>
</ul>

<h3>Title: Extended Flow Matching: a Method of Conditional Generation with  Generalized Continuity Equation</h3>
<ul>
<li><strong>Authors: </strong>Noboru Isobe, Masanori Koyama, Kohei Hayashi, Kenji Fukumizu</a></li>
<li><strong>Subjects: </strong>cs.LG, math.AP, math.FA, math.OC, math.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18839">https://arxiv.org/abs/2402.18839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18839">https://arxiv.org/pdf/2402.18839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18839]] Extended Flow Matching: a Method of Conditional Generation with  Generalized Continuity Equation(https://arxiv.org/abs/2402.18839)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated diffusion models, with the guidance-based classifier-free method taking the lead. However, the theory of the guidance-based method not only requires the user to fine-tune the "guidance strength," but its target vector field does not necessarily correspond to the conditional distribution used in training. In this paper, we develop the theory of conditional generation based on Flow Matching, a current strong contender of diffusion methods. Motivated by the interpretation of a probability path as a distribution on path space, we establish a novel theory of flow-based generation of conditional distribution by employing the mathematical framework of generalized continuity equation instead of the continuity equation in flow matching. This theory naturally derives a method that aims to match the matrix field as opposed to the vector field. Our framework ensures the continuity of the generated conditional distribution through the existence of flow between conditional distributions. We will present our theory through experiments and mathematical results.</li>
</ul>

<h3>Title: ViewFusion: Towards Multi-View Consistency via Interpolated Denoising</h3>
<ul>
<li><strong>Authors: </strong>Xianghui Yang, Yan Zuo, Sameera Ramasinghe, Loris Bazzani, Gil Avraham, Anton van den Hengel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18842">https://arxiv.org/abs/2402.18842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18842">https://arxiv.org/pdf/2402.18842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18842]] ViewFusion: Towards Multi-View Consistency via Interpolated Denoising(https://arxiv.org/abs/2402.18842)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Novel-view synthesis through diffusion models has demonstrated remarkable potential for generating diverse and high-quality images. Yet, the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this, we introduce ViewFusion, a novel, training-free algorithm that can be seamlessly integrated into existing pre-trained diffusion models. Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation, ensuring robust multi-view consistency during the novel-view generation process. Through a diffusion process that fuses known-view information via interpolated denoising, our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional fine-tuning. Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views.</li>
</ul>

<h3>Title: Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP  Models on Accuracy and Semantic Coherence</h3>
<ul>
<li><strong>Authors: </strong>Mingyang Li, Maoqin Yuan, Luyao Li, Han Pengsihua</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18849">https://arxiv.org/abs/2402.18849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18849">https://arxiv.org/pdf/2402.18849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18849]] Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP  Models on Accuracy and Semantic Coherence(https://arxiv.org/abs/2402.18849)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>This study discusses a new method combining image steganography technology with Natural Language Processing (NLP) large models, aimed at improving the accuracy and robustness of extracting steganographic text. Traditional Least Significant Bit (LSB) steganography techniques face challenges in accuracy and robustness of information extraction when dealing with complex character encoding, such as Chinese characters. To address this issue, this study proposes an innovative LSB-NLP hybrid framework. This framework integrates the advanced capabilities of NLP large models, such as error detection, correction, and semantic consistency analysis, as well as information reconstruction techniques, thereby significantly enhancing the robustness of steganographic text extraction. Experimental results show that the LSB-NLP hybrid framework excels in improving the extraction accuracy of steganographic text, especially in handling Chinese characters. The findings of this study not only confirm the effectiveness of combining image steganography technology and NLP large models but also propose new ideas for research and application in the field of information hiding. The successful implementation of this interdisciplinary approach demonstrates the great potential of integrating image steganography technology with natural language processing technology in solving complex information processing problems.</li>
</ul>

<h3>Title: Applications of 0-1 Neural Networks in Prescription and Prediction</h3>
<ul>
<li><strong>Authors: </strong>Vrishabh Patil, Kara Hoppe, Yonatan Mintz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18851">https://arxiv.org/abs/2402.18851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18851">https://arxiv.org/pdf/2402.18851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18851]] Applications of 0-1 Neural Networks in Prescription and Prediction(https://arxiv.org/abs/2402.18851)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>A key challenge in medical decision making is learning treatment policies for patients with limited observational data. This challenge is particularly evident in personalized healthcare decision-making, where models need to take into account the intricate relationships between patient characteristics, treatment options, and health outcomes. To address this, we introduce prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed integer programming that can be used with counterfactual estimation to optimize policies in medium data settings. These models offer greater interpretability than deep neural networks and can encode more complex policies than common models such as decision trees. We show that PNNs can outperform existing methods in both synthetic data experiments and in a case study of assigning treatments for postpartum hypertension. In particular, PNNs are shown to produce policies that could reduce peak blood pressure by 5.47 mm Hg (p=0.02) over existing clinical practice, and by 2 mm Hg (p=0.01) over the next best prescriptive modeling technique. Moreover PNNs were more likely than all other models to correctly identify clinically significant features while existing models relied on potentially dangerous features such as patient insurance information and race that could lead to bias in treatment.</li>
</ul>

<h3>Title: Rethinking Multi-domain Generalization with A General Learning Objective</h3>
<ul>
<li><strong>Authors: </strong>Zhaorui Tan, Xi Yang, Kaizhu Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18853">https://arxiv.org/abs/2402.18853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18853">https://arxiv.org/pdf/2402.18853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18853]] Rethinking Multi-domain Generalization with A General Learning Objective(https://arxiv.org/abs/2402.18853)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Multi-domain generalization (mDG) is universally aimed to minimize the discrepancy between training and testing distributions to enhance marginal-to-label distribution mapping. However, existing mDG literature lacks a general learning objective paradigm and often imposes constraints on static target marginal distributions. In this paper, we propose to leverage a $Y$-mapping to relax the constraint. We rethink the learning objective for mDG and design a new \textbf{general learning objective} to interpret and analyze most existing mDG wisdom. This general objective is bifurcated into two synergistic amis: learning domain-independent conditional features and maximizing a posterior. Explorations also extend to two effective regularization terms that incorporate prior information and suppress invalid causality, alleviating the issues that come with relaxed constraints. We theoretically contribute an upper bound for the domain alignment of domain-independent conditional features, disclosing that many previous mDG endeavors actually \textbf{optimize partially the objective} and thus lead to limited performance. As such, our study distills a general learning objective into four practical components, providing a general, robust, and flexible mechanism to handle complex domain shifts. Extensive empirical results indicate that the proposed objective with $Y$-mapping leads to substantially better mDG performance in various downstream tasks, including regression, segmentation, and classification.</li>
</ul>

<h3>Title: Probabilistic Lipschitzness and the Stable Rank for Comparing  Explanation Models</h3>
<ul>
<li><strong>Authors: </strong>Lachlan Simpson, Kyle Millar, Adriel Cheng, Cheng-Chew Lim, Hong Gunn Chew</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18863">https://arxiv.org/abs/2402.18863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18863">https://arxiv.org/pdf/2402.18863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18863]] Probabilistic Lipschitzness and the Stable Rank for Comparing  Explanation Models(https://arxiv.org/abs/2402.18863)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Explainability models are now prevalent within machine learning to address the black-box nature of neural networks. The question now is which explainability model is most effective. Probabilistic Lipschitzness has demonstrated that the smoothness of a neural network is fundamentally linked to the quality of post hoc explanations. In this work, we prove theoretical lower bounds on the probabilistic Lipschitzness of Integrated Gradients, LIME and SmoothGrad. We propose a novel metric using probabilistic Lipschitzness, normalised astuteness, to compare the robustness of explainability models. Further, we prove a link between the local Lipschitz constant of a neural network and its stable rank. We then demonstrate that the stable rank of a neural network provides a heuristic for the robustness of explainability models.</li>
</ul>

<h3>Title: Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient  Tuning</h3>
<ul>
<li><strong>Authors: </strong>Weijieying Ren, Xinlong Li, Lei Wang, Tianxiang Zhao, Wei Qin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18865">https://arxiv.org/abs/2402.18865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18865">https://arxiv.org/pdf/2402.18865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18865]] Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient  Tuning(https://arxiv.org/abs/2402.18865)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing research has shown that large language models (LLMs) exhibit remarkable performance in language understanding and generation. However, when LLMs are continuously fine-tuned on complex and diverse domain-specific downstream tasks, the inference performance on historical tasks decreases dramatically, which is known as a catastrophic forgetting problem. A trade-off needs to be kept between learning plasticity and memory stability. Plenty of existing works have explored strategies like memory replay, regularization and parameter isolation, but little is known about the geometric connection of various adjacent minima in the continual LLMs fine-tuning scenarios. In this work, we investigate the geometric connections of different minima through the lens of mode connectivity, which means different minima can be connected by a low-loss valley. Through extensive experiments, we uncover the mode connectivity phenomenon in the LLMs continual learning scenario and find that it can strike a balance between plasticity and stability. Building upon these findings, we propose a simple yet effective method called Interpolation-based LoRA (I-LoRA), which constructs a dual-memory experience replay framework based on LoRA parameter interpolations. Extensive experiments and analysis on eight domain-specific CL benchmarks demonstrate that I-LoRA consistently show significant improvement over the previous state-of-the-art approaches with up to $11\%$ performance gains, providing a strong baseline and insights for future research on the large language model continual learning problem. Our code is available at \url{https://github.com/which47/LLMCL}.</li>
</ul>

<h3>Title: Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Zhen Hao Wong, Hansi Yang, Xiaoyi Fu, Quanming Yao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18875">https://arxiv.org/abs/2402.18875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18875">https://arxiv.org/pdf/2402.18875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18875]] Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks(https://arxiv.org/abs/2402.18875)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Heterogeneous Graph Neural Networks (HGNNs) are a class of deep learning models designed specifically for heterogeneous graphs, which are graphs that contain different types of nodes and edges. This paper investigates the application of curriculum learning techniques to improve the performance and robustness of Heterogeneous Graph Neural Networks (GNNs). To better classify the quality of the data, we design a loss-aware training schedule, named LTS that measures the quality of every nodes of the data and incorporate the training dataset into the model in a progressive manner that increases difficulty step by step. LTS can be seamlessly integrated into various frameworks, effectively reducing bias and variance, mitigating the impact of noisy data, and enhancing overall accuracy. Our findings demonstrate the efficacy of curriculum learning in enhancing HGNNs capabilities for analyzing complex graph-structured data. The code is public at https: //github.com/LARS-research/CLGNN/.</li>
</ul>

<h3>Title: Dose Prediction Driven Radiotherapy Paramters Regression via Intra- and  Inter-Relation Modeling</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Cui, Yuanyuan Xu, Jianghong Xiao, Yuchen Fei, Jiliu Zhou, Xingcheng Peng, Yan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18879">https://arxiv.org/abs/2402.18879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18879">https://arxiv.org/pdf/2402.18879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18879]] Dose Prediction Driven Radiotherapy Paramters Regression via Intra- and  Inter-Relation Modeling(https://arxiv.org/abs/2402.18879)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep learning has facilitated the automation of radiotherapy by predicting accurate dose distribution maps. However, existing methods fail to derive the desirable radiotherapy parameters that can be directly input into the treatment planning system (TPS), impeding the full automation of radiotherapy. To enable more thorough automatic radiotherapy, in this paper, we propose a novel two-stage framework to directly regress the radiotherapy parameters, including a dose map prediction stage and a radiotherapy parameters regression stage. In stage one, we combine transformer and convolutional neural network (CNN) to predict realistic dose maps with rich global and local information, providing accurate dosimetric knowledge for the subsequent parameters regression. In stage two, two elaborate modules, i.e., an intra-relation modeling (Intra-RM) module and an inter-relation modeling (Inter-RM) module, are designed to exploit the organ-specific and organ-shared features for precise parameters regression. Experimental results on a rectal cancer dataset demonstrate the effectiveness of our method.</li>
</ul>

<h3>Title: Uncertainty-Based Extensible Codebook for Discrete Federated Learning in  Heterogeneous Data Silos</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Zhang, Yu Cao, Dianbo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18888">https://arxiv.org/abs/2402.18888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18888">https://arxiv.org/pdf/2402.18888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18888]] Uncertainty-Based Extensible Codebook for Discrete Federated Learning in  Heterogeneous Data Silos(https://arxiv.org/abs/2402.18888)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL), aimed at leveraging vast distributed datasets, confronts a crucial challenge: the heterogeneity of data across different silos. While previous studies have explored discrete representations to enhance model generalization across minor distributional shifts, these approaches often struggle to adapt to new data silos with significantly divergent distributions. In response, we have identified that models derived from FL exhibit markedly increased uncertainty when applied to data silos with unfamiliar distributions. Consequently, we propose an innovative yet straightforward iterative framework, termed Uncertainty-Based Extensible-Codebook Federated Learning (UEFL). This framework dynamically maps latent features to trainable discrete vectors, assesses the uncertainty, and specifically extends the discretization dictionary or codebook for silos exhibiting high uncertainty. Our approach aims to simultaneously enhance accuracy and reduce uncertainty by explicitly addressing the diversity of data distributions, all while maintaining minimal computational overhead in environments characterized by heterogeneous data silos. Through experiments conducted on five datasets, our method has demonstrated its superiority, achieving significant improvements in accuracy (by 3%--22.1%) and uncertainty reduction (by 38.83%--96.24%), thereby outperforming contemporary state-of-the-art methods. The source code is available at https://github.com/destiny301/uefl.</li>
</ul>

<h3>Title: On the Convergence of Differentially-Private Fine-tuning: To Linearly  Probe or to Fully Fine-tune?</h3>
<ul>
<li><strong>Authors: </strong>Shuqi Ke, Charlie Hou, Giulia Fanti, Sewoong Oh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18905">https://arxiv.org/abs/2402.18905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18905">https://arxiv.org/pdf/2402.18905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18905]] On the Convergence of Differentially-Private Fine-tuning: To Linearly  Probe or to Fully Fine-tune?(https://arxiv.org/abs/2402.18905)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by fine-tuning on private data using DP optimization techniques. In the DP setting, it has been observed that full fine-tuning may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2) explores the phenomenon of sequential fine-tuning, starting with linear probing and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP fine-tuning within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full fine-tuning. The theoretical results are supported by empirical evaluations on various benchmarks and models. The findings reveal the complex nature of DP fine-tuning methods. These results contribute to a deeper understanding of DP machine learning and highlight the importance of considering the allocation of privacy budget in the fine-tuning process.</li>
</ul>

<h3>Title: DIGIC: Domain Generalizable Imitation Learning by Causal Discovery</h3>
<ul>
<li><strong>Authors: </strong>Yang Chen, Yitao Liang, Zhouchen Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18910">https://arxiv.org/abs/2402.18910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18910">https://arxiv.org/pdf/2402.18910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18910]] DIGIC: Domain Generalizable Imitation Learning by Causal Discovery(https://arxiv.org/abs/2402.18910)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Causality has been combined with machine learning to produce robust representations for domain generalization. Most existing methods of this type require massive data from multiple domains to identify causal features by cross-domain variations, which can be expensive or even infeasible and may lead to misidentification in some cases. In this work, we make a different attempt by leveraging the demonstration data distribution to discover the causal features for a domain generalizable policy. We design a novel framework, called DIGIC, to identify the causal features by finding the direct cause of the expert action from the demonstration data distribution via causal discovery. Our framework can achieve domain generalizable imitation learning with only single-domain data and serve as a complement for cross-domain variation-based methods under non-structural assumptions on the underlying causal models. Our empirical study in various control tasks shows that the proposed framework evidently improves the domain generalization performance and has comparable performance to the expert in the original domain simultaneously.</li>
</ul>

<h3>Title: AdaMergeX: Cross-Lingual Transfer with Large Language Models via  Adaptive Adapter Merging</h3>
<ul>
<li><strong>Authors: </strong>Yiran Zhao, Wenxuan Zhang, Huiming Wang, Kenji Kawaguchi, Lidong Bing</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18913">https://arxiv.org/abs/2402.18913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18913">https://arxiv.org/pdf/2402.18913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18913]] AdaMergeX: Cross-Lingual Transfer with Large Language Models via  Adaptive Adapter Merging(https://arxiv.org/abs/2402.18913)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As an effective alternative to the direct fine-tuning on target tasks in specific languages, cross-lingual transfer addresses the challenges of limited training data by decoupling ''task ability'' and ''language ability'' by fine-tuning on the target task in the source language and another selected task in the target language, respectively. However, they fail to fully separate the task ability from the source language or the language ability from the chosen task. In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks. As the gap removes the impact of tasks, we assume that it remains consistent across tasks. Based on this assumption, we propose a new cross-lingual transfer method called $\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a reference task, we can determine that the divergence of adapters fine-tuned on the reference task in both languages follows the same distribution as the divergence of adapters fine-tuned on the target task in both languages. Hence, we can obtain target adapters by combining the other three adapters. Furthermore, we propose a structure-adaptive adapter merging method. Our empirical results demonstrate that our approach yields new and effective cross-lingual transfer, outperforming existing methods across all settings.</li>
</ul>

<h3>Title: Decompose-and-Compose: A Compositional Approach to Mitigating Spurious  Correlation</h3>
<ul>
<li><strong>Authors: </strong>Fahimeh Hosseini Noohdani, Parsa Hosseini, Arian Yazdan Parast, Hamidreza Yaghoubi Araghi, Mahdieh Soleymani Baghshah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18919">https://arxiv.org/abs/2402.18919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18919">https://arxiv.org/pdf/2402.18919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18919]] Decompose-and-Compose: A Compositional Approach to Mitigating Spurious  Correlation(https://arxiv.org/abs/2402.18919)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>While standard Empirical Risk Minimization (ERM) training is proven effective for image classification on in-distribution data, it fails to perform well on out-of-distribution samples. One of the main sources of distribution shift for image classification is the compositional nature of images. Specifically, in addition to the main object or component(s) determining the label, some other image components usually exist, which may lead to the shift of input distribution between train and test environments. More importantly, these components may have spurious correlations with the label. To address this issue, we propose Decompose-and-Compose (DaC), which improves robustness to correlation shift by a compositional approach based on combining elements of images. Based on our observations, models trained with ERM usually highly attend to either the causal components or the components having a high spurious correlation with the label (especially in datapoints on which models have a high confidence). In fact, according to the amount of spurious correlation and the easiness of classification based on the causal or non-causal components, the model usually attends to one of these more (on samples with high confidence). Following this, we first try to identify the causal components of images using class activation maps of models trained with ERM. Afterward, we intervene on images by combining them and retraining the model on the augmented data, including the counterfactual ones. Along with its high interpretability, this work proposes a group-balancing method by intervening on images without requiring group labels or information regarding the spurious features during training. The method has an overall better worst group accuracy compared to previous methods with the same amount of supervision on the group labels in correlation shift.</li>
</ul>

<h3>Title: A Simple yet Effective Network based on Vision Transformer for  Camouflaged Object and Salient Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Chao Hao, Zitong Yu, Xin Liu, Jun Xu, Huanjing Yue, Jingyu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18922">https://arxiv.org/abs/2402.18922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18922">https://arxiv.org/pdf/2402.18922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18922]] A Simple yet Effective Network based on Vision Transformer for  Camouflaged Object and Salient Object Detection(https://arxiv.org/abs/2402.18922)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Camouflaged object detection (COD) and salient object detection (SOD) are two distinct yet closely-related computer vision tasks widely studied during the past decades. Though sharing the same purpose of segmenting an image into binary foreground and background regions, their distinction lies in the fact that COD focuses on concealed objects hidden in the image, while SOD concentrates on the most prominent objects in the image. Previous works achieved good performance by stacking various hand-designed modules and multi-scale features. However, these carefully-designed complex networks often performed well on one task but not on another. In this work, we propose a simple yet effective network (SENet) based on vision Transformer (ViT), by employing a simple design of an asymmetric ViT-based encoder-decoder structure, we yield competitive results on both tasks, exhibiting greater versatility than meticulously crafted ones. Furthermore, to enhance the Transformer's ability to model local information, which is important for pixel-level binary segmentation tasks, we propose a local information capture module (LICM). We also propose a dynamic weighted loss (DW loss) based on Binary Cross-Entropy (BCE) and Intersection over Union (IoU) loss, which guides the network to pay more attention to those smaller and more difficult-to-find target objects according to their size. Moreover, we explore the issue of joint training of SOD and COD, and propose a preliminary solution to the conflict in joint training, further improving the performance of SOD. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of our method. The code is available at https://github.com/linuxsino/SENet.</li>
</ul>

<h3>Title: Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on  Pre-trained Language Models</h3>
<ul>
<li><strong>Authors: </strong>Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Gongshen Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18945">https://arxiv.org/abs/2402.18945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18945">https://arxiv.org/pdf/2402.18945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18945]] Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on  Pre-trained Language Models(https://arxiv.org/abs/2402.18945)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Pre-trained language models (PLMs) have been found susceptible to backdoor attacks, which can transfer vulnerabilities to various downstream tasks. However, existing PLM backdoors are conducted with explicit triggers under the manually aligned, thus failing to satisfy expectation goals simultaneously in terms of effectiveness, stealthiness, and universality. In this paper, we propose a novel approach to achieve invisible and general backdoor implantation, called \textbf{Syntactic Ghost} (synGhost for short). Specifically, the method hostilely manipulates poisoned samples with different predefined syntactic structures as stealth triggers and then implants the backdoor to pre-trained representation space without disturbing the primitive knowledge. The output representations of poisoned samples are distributed as uniformly as possible in the feature space via contrastive learning, forming a wide range of backdoors. Additionally, in light of the unique properties of syntactic triggers, we introduce an auxiliary module to drive the PLMs to learn this knowledge in priority, which can alleviate the interference between different syntactic structures. Experiments show that our method outperforms the previous methods and achieves the predefined objectives. Not only do severe threats to various natural language understanding (NLU) tasks on two tuning paradigms but also to multiple PLMs. Meanwhile, the synGhost is imperceptible against three countermeasures based on perplexity, fine-pruning, and the proposed maxEntropy.</li>
</ul>

<h3>Title: Improving Group Connectivity for Generalization of Federated Deep  Learning</h3>
<ul>
<li><strong>Authors: </strong>Zexi Li, Jie Lin, Zhiqi Li, Didi Zhu, Chao Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18949">https://arxiv.org/abs/2402.18949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18949">https://arxiv.org/pdf/2402.18949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18949]] Improving Group Connectivity for Generalization of Federated Deep  Learning(https://arxiv.org/abs/2402.18949)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, transformer</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) involves multiple heterogeneous clients collaboratively training a global model via iterative local updates and model fusion. The generalization of FL's global model has a large gap compared with centralized training, which is its bottleneck for broader applications. In this paper, we study and improve FL's generalization through a fundamental ``connectivity'' perspective, which means how the local models are connected in the parameter region and fused into a generalized global model. The term ``connectivity'' is derived from linear mode connectivity (LMC), studying the interpolated loss landscape of two different solutions (e.g., modes) of neural networks. Bridging the gap between LMC and FL, in this paper, we leverage fixed anchor models to empirically and theoretically study the transitivity property of connectivity from two models (LMC) to a group of models (model fusion in FL). Based on the findings, we propose FedGuCci and FedGuCci+, improving group connectivity for better generalization. It is shown that our methods can boost the generalization of FL under client heterogeneity across various tasks (4 CV datasets and 6 NLP datasets), models (both convolutional and transformer-based), and training paradigms (both from-scratch and pretrain-finetune).</li>
</ul>

<h3>Title: WWW: A Unified Framework for Explaining What, Where and Why of Neural  Networks by Interpretation of Neuron Concepts</h3>
<ul>
<li><strong>Authors: </strong>Yong Hyun Ahn, Hyeon Bae Kim, Seong Tae Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18956">https://arxiv.org/abs/2402.18956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18956">https://arxiv.org/pdf/2402.18956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18956]] WWW: A Unified Framework for Explaining What, Where and Why of Neural  Networks by Interpretation of Neuron Concepts(https://arxiv.org/abs/2402.18956)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Recent advancements in neural networks have showcased their remarkable capabilities across various domains. Despite these successes, the "black box" problem still remains. Addressing this, we propose a novel framework, WWW, that offers the 'what', 'where', and 'why' of the neural network decisions in human-understandable terms. Specifically, WWW utilizes adaptive selection for concept discovery, employing adaptive cosine similarity and thresholding techniques to effectively explain 'what'. To address the 'where' and 'why', we proposed a novel combination of neuron activation maps (NAMs) with Shapley values, generating localized concept maps and heatmaps for individual inputs. Furthermore, WWW introduces a method for predicting uncertainty, leveraging heatmap similarities to estimate 'how' reliable the prediction is. Experimental evaluations of WWW demonstrate superior performance in both quantitative and qualitative metrics, outperforming existing methods in interpretability. WWW provides a unified solution for explaining 'what', 'where', and 'why', introducing a method for localized explanations from global interpretations and offering a plug-and-play solution adaptable to various architectures.</li>
</ul>

<h3>Title: Towards Out-of-Distribution Detection for breast cancer classification  in Point-of-Care Ultrasound Imaging</h3>
<ul>
<li><strong>Authors: </strong>Jennie Karlsson, Marisa Wodrich, Niels Christian Overgaard, Freja Sahlin, Kristina Lång, Anders Heyden, Ida Arvidsson</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18960">https://arxiv.org/abs/2402.18960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18960">https://arxiv.org/pdf/2402.18960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18960]] Towards Out-of-Distribution Detection for breast cancer classification  in Point-of-Care Ultrasound Imaging(https://arxiv.org/abs/2402.18960)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning has shown to have great potential in medical applications. In critical domains as such, it is of high interest to have trustworthy algorithms which are able to tell when reliable assessments cannot be guaranteed. Detecting out-of-distribution (OOD) samples is a crucial step towards building a safe classifier. Following a previous study, showing that it is possible to classify breast cancer in point-of-care ultrasound images, this study investigates OOD detection using three different methods: softmax, energy score and deep ensembles. All methods are tested on three different OOD data sets. The results show that the energy score method outperforms the softmax method, performing well on two of the data sets. The ensemble method is the most robust, performing the best at detecting OOD samples for all three OOD data sets.</li>
</ul>

<h3>Title: PrivatEyes: Appearance-based Gaze Estimation Using Federated Secure  Multi-Party Computation</h3>
<ul>
<li><strong>Authors: </strong>Mayar Elfares, Pascal Reisert, Zhiming Hu, Wenwu Tang, Ralf Küsters, Andreas Bulling</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18970">https://arxiv.org/abs/2402.18970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18970">https://arxiv.org/pdf/2402.18970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18970]] PrivatEyes: Appearance-based Gaze Estimation Using Federated Secure  Multi-Party Computation(https://arxiv.org/abs/2402.18970)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Latest gaze estimation methods require large-scale training data but their collection and exchange pose significant privacy risks. We propose PrivatEyes - the first privacy-enhancing training approach for appearance-based gaze estimation based on federated learning (FL) and secure multi-party computation (MPC). PrivatEyes enables training gaze estimators on multiple local datasets across different users and server-based secure aggregation of the individual estimators' updates. PrivatEyes guarantees that individual gaze data remains private even if a majority of the aggregating servers is malicious. We also introduce a new data leakage attack DualView that shows that PrivatEyes limits the leakage of private training data more effectively than previous approaches. Evaluations on the MPIIGaze, MPIIFaceGaze, GazeCapture, and NVGaze datasets further show that the improved privacy does not lead to a lower gaze estimation accuracy or substantially higher computational costs - both of which are on par with its non-secure counterparts.</li>
</ul>

<h3>Title: Privacy Management and Interface Design for a Smart House</h3>
<ul>
<li><strong>Authors: </strong>Ana-Maria Comeaga, Iuliana Marin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18973">https://arxiv.org/abs/2402.18973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18973">https://arxiv.org/pdf/2402.18973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18973]] Privacy Management and Interface Design for a Smart House(https://arxiv.org/abs/2402.18973)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>In today's life, more and more people tend to opt for a smart house. In this way, the idea of including technology has become popular worldwide. Despite this concept's many benefits, managing security remains an essential problem due to the shared activities. The Internet of Things system behind a smart house is based on several sensors to measure temperature, humidity, air quality, and movement. Because of being supervised every day through sensors and controlling their house only with a simple click, many people can be afraid of this new approach in terms of their privacy, and this fact can constrain them from following their habits. The security aspects should be constantly analyzed to keep the data's confidentiality and make people feel safe in their own houses. In this context, the current paper puts light on an alternative design of a platform in which the safety of homeowners is the primary purpose, and they maintain complete control over the data generated by smart devices. The current research highlights the role of security and interface design in controlling a smart house. The study underscores the importance of providing an interface that can be used easily by any person to manage data and live activities in a modern residence in an era dominated by continuously developing technology.</li>
</ul>

<h3>Title: Graph Generation via Spectral Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Giorgia Minello, Alessandro Bicciato, Luca Rossi, Andrea Torsello, Luca Cosmo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18974">https://arxiv.org/abs/2402.18974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18974">https://arxiv.org/pdf/2402.18974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18974]] Graph Generation via Spectral Diffusion(https://arxiv.org/abs/2402.18974)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we present GRASP, a novel graph generative model based on 1) the spectral decomposition of the graph Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian and adjacency matrix. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the graph and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other methods. This is achieved by truncating the spectrum, which as we show in our experiments results in a faster yet accurate generative process. An extensive set of experiments on both synthetic and real world graphs demonstrates the strengths of our model against state-of-the-art alternatives.</li>
</ul>

<h3>Title: Theoretically Achieving Continuous Representation of Oriented Bounding  Boxes</h3>
<ul>
<li><strong>Authors: </strong>Zikai Xiao, Guo-Ye Yang, Xue Yang, Tai-Jiang Mu, Junchi Yan, Shi-min Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.18975">https://arxiv.org/abs/2402.18975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.18975">https://arxiv.org/pdf/2402.18975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.18975]] Theoretically Achieving Continuous Representation of Oriented Bounding  Boxes(https://arxiv.org/abs/2402.18975)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Considerable efforts have been devoted to Oriented Object Detection (OOD). However, one lasting issue regarding the discontinuity in Oriented Bounding Box (OBB) representation remains unresolved, which is an inherent bottleneck for extant OOD methods. This paper endeavors to completely solve this issue in a theoretically guaranteed manner and puts an end to the ad-hoc efforts in this direction. Prior studies typically can only address one of the two cases of discontinuity: rotation and aspect ratio, and often inadvertently introduce decoding discontinuity, e.g. Decoding Incompleteness (DI) and Decoding Ambiguity (DA) as discussed in literature. Specifically, we propose a novel representation method called Continuous OBB (COBB), which can be readily integrated into existing detectors e.g. Faster-RCNN as a plugin. It can theoretically ensure continuity in bounding box regression which to our best knowledge, has not been achieved in literature for rectangle-based object representation. For fairness and transparency of experiments, we have developed a modularized benchmark based on the open-source deep learning framework Jittor's detection toolbox JDet for OOD evaluation. On the popular DOTA dataset, by integrating Faster-RCNN as the same baseline model, our new method outperforms the peer method Gliding Vertex by 1.13% mAP50 (relative improvement 1.54%), and 2.46% mAP75 (relative improvement 5.91%), without any tricks.</li>
</ul>

<h3>Title: RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for  Remote Sensing Image Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhang, Xubing Yang, Rui Jiang, Wei Shao, Li Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19004">https://arxiv.org/abs/2402.19004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19004">https://arxiv.org/pdf/2402.19004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19004]] RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for  Remote Sensing Image Semantic Segmentation(https://arxiv.org/abs/2402.19004)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The development of high-resolution remote sensing satellites has provided great convenience for research work related to remote sensing. Segmentation and extraction of specific targets are essential tasks when facing the vast and complex remote sensing images. Recently, the introduction of Segment Anything Model (SAM) provides a universal pre-training model for image segmentation tasks. While the direct application of SAM to remote sensing image segmentation tasks does not yield satisfactory results, we propose RSAM-Seg, which stands for Remote Sensing SAM with Semantic Segmentation, as a tailored modification of SAM for the remote sensing field and eliminates the need for manual intervention to provide prompts. Adapter-Scale, a set of supplementary scaling modules, are proposed in the multi-head attention blocks of the encoder part of SAM. Furthermore, Adapter-Feature are inserted between the Vision Transformer (ViT) blocks. These modules aim to incorporate high-frequency image information and image embedding features to generate image-informed prompts. Experiments are conducted on four distinct remote sensing scenarios, encompassing cloud detection, field monitoring, building detection and road mapping tasks . The experimental results not only showcase the improvement over the original SAM and U-Net across cloud, buildings, fields and roads scenarios, but also highlight the capacity of RSAM-Seg to discern absent areas within the ground truth of certain datasets, affirming its potential as an auxiliary annotation method. In addition, the performance in few-shot scenarios is commendable, underscores its potential in dealing with limited datasets.</li>
</ul>

<h3>Title: Generating, Reconstructing, and Representing Discrete and Continuous  Data: Generalized Diffusion with Learnable Encoding-Decoding</h3>
<ul>
<li><strong>Authors: </strong>Guangyi Liu, Yu Wang, Zeyu Feng, Qiyu Wu, Liping Tang, Yuan Gao, Zhen Li, Shuguang Cui, Julian McAuley, Eric P. Xing, Zichao Yang, Zhiting Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19009">https://arxiv.org/abs/2402.19009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19009">https://arxiv.org/pdf/2402.19009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19009]] Generating, Reconstructing, and Representing Discrete and Continuous  Data: Generalized Diffusion with Learnable Encoding-Decoding(https://arxiv.org/abs/2402.19009)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), autoregressive models, and diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce generalized diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder parameters jointly with diffusion. By choosing appropriate encoder/decoder (e.g., large language models), DiLED naturally applies to different data types. Extensive experiments on text, proteins, and images demonstrate DiLED's flexibility to handle diverse data and tasks and its strong improvement over various existing models.</li>
</ul>

<h3>Title: SPriFed-OMP: A Differentially Private Federated Learning Algorithm for  Sparse Basis Recovery</h3>
<ul>
<li><strong>Authors: </strong>Ajinkya Kiran Mulay, Xiaojun Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19016">https://arxiv.org/abs/2402.19016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19016">https://arxiv.org/pdf/2402.19016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19016]] SPriFed-OMP: A Differentially Private Federated Learning Algorithm for  Sparse Basis Recovery(https://arxiv.org/abs/2402.19016)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Sparse basis recovery is a classical and important statistical learning problem when the number of model dimensions $p$ is much larger than the number of samples $n$. However, there has been little work that studies sparse basis recovery in the Federated Learning (FL) setting, where the client data's differential privacy (DP) must also be simultaneously protected. In particular, the performance guarantees of existing DP-FL algorithms (such as DP-SGD) will degrade significantly when $p \gg n$, and thus, they will fail to learn the true underlying sparse model accurately. In this work, we develop a new differentially private sparse basis recovery algorithm for the FL setting, called SPriFed-OMP. SPriFed-OMP converts OMP (Orthogonal Matching Pursuit) to the FL setting. Further, it combines SMPC (secure multi-party computation) and DP to ensure that only a small amount of noise needs to be added in order to achieve differential privacy. As a result, SPriFed-OMP can efficiently recover the true sparse basis for a linear model with only $n = O(\sqrt{p})$ samples. We further present an enhanced version of our approach, SPriFed-OMP-GRAD based on gradient privatization, that improves the performance of SPriFed-OMP. Our theoretical analysis and empirical results demonstrate that both SPriFed-OMP and SPriFed-OMP-GRAD terminate in a small number of steps, and they significantly outperform the previous state-of-the-art DP-FL solutions in terms of the accuracy-privacy trade-off.</li>
</ul>

<h3>Title: Combination of Weak Learners eXplanations to Improve Random Forest  eXplicability Robustness</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Pala, Esteban García-Cuesta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19025">https://arxiv.org/abs/2402.19025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19025">https://arxiv.org/pdf/2402.19025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19025]] Combination of Weak Learners eXplanations to Improve Random Forest  eXplicability Robustness(https://arxiv.org/abs/2402.19025)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The notion of robustness in XAI refers to the observed variations in the explanation of the prediction of a learned model with respect to changes in the input leading to that prediction. Intuitively, if the input being explained is modified slightly subtly enough so as to not change the prediction of the model too much, then we would expect that the explanation provided for that new input does not change much either. We argue that a combination through discriminative averaging of ensembles weak learners explanations can improve the robustness of explanations in ensemble methods.This approach has been implemented and tested with post-hoc SHAP method and Random Forest ensemble with successful results. The improvements obtained have been measured quantitatively and some insights into the explicability robustness in ensemble methods are presented.</li>
</ul>

<h3>Title: How to Train your Antivirus: RL-based Hardening through the  Problem-Space</h3>
<ul>
<li><strong>Authors: </strong>Jacopo Cortellazzi, Ilias Tsingenopoulos, Branislav Bošanský, Simone Aonzo, Davy Preuveneers, Wouter Joosen, Fabio Pierazzi, Lorenzo Cavallaro</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19027">https://arxiv.org/abs/2402.19027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19027">https://arxiv.org/pdf/2402.19027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19027]] How to Train your Antivirus: RL-based Hardening through the  Problem-Space(https://arxiv.org/abs/2402.19027)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>ML-based malware detection on dynamic analysis reports is vulnerable to both evasion and spurious correlations. In this work, we investigate a specific ML architecture employed in the pipeline of a widely-known commercial antivirus company, with the goal to harden it against adversarial malware. Adversarial training, the sole defensive technique that can confer empirical robustness, is not applicable out of the box in this domain, for the principal reason that gradient-based perturbations rarely map back to feasible problem-space programs. We introduce a novel Reinforcement Learning approach for constructing adversarial examples, a constituent part of adversarially training a model against evasion. Our approach comes with multiple advantages. It performs modifications that are feasible in the problem-space, and only those; thus it circumvents the inverse mapping problem. It also makes possible to provide theoretical guarantees on the robustness of the model against a particular set of adversarial capabilities. Our empirical exploration validates our theoretical insights, where we can consistently reach 0\% Attack Success Rate after a few adversarial retraining iterations.</li>
</ul>

<h3>Title: A Deep-Learning Technique to Locate Cryptographic Operations in  Side-Channel Traces</h3>
<ul>
<li><strong>Authors: </strong>Giuseppe Chiari, Davide Galli, Francesco Lattari, Matteo Matteucci, Davide Zoni</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19037">https://arxiv.org/abs/2402.19037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19037">https://arxiv.org/pdf/2402.19037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19037]] A Deep-Learning Technique to Locate Cryptographic Operations in  Side-Channel Traces(https://arxiv.org/abs/2402.19037)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>Side-channel attacks allow extracting secret information from the execution of cryptographic primitives by correlating the partially known computed data and the measured side-channel signal. However, to set up a successful side-channel attack, the attacker has to perform i) the challenging task of locating the time instant in which the target cryptographic primitive is executed inside a side-channel trace and then ii)the time-alignment of the measured data on that time instant. This paper presents a novel deep-learning technique to locate the time instant in which the target computed cryptographic operations are executed in the side-channel trace. In contrast to state-of-the-art solutions, the proposed methodology works even in the presence of trace deformations obtained through random delay insertion techniques. We validated our proposal through a successful attack against a variety of unprotected and protected cryptographic primitives that have been executed on an FPGA-implemented system-on-chip featuring a RISC-V CPU.</li>
</ul>

<h3>Title: Theoretical Foundations of Deep Selective State-Space Models</h3>
<ul>
<li><strong>Authors: </strong>Nicola Muca Cirone, Antonio Orvieto, Benjamin Walker, Cristopher Salvi, Terry Lyons</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19047">https://arxiv.org/abs/2402.19047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19047">https://arxiv.org/pdf/2402.19047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19047]] Theoretical Foundations of Deep Selective State-Space Models(https://arxiv.org/abs/2402.19047)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Structured state-space models (SSMs) such as S4, stemming from the seminal work of Gu et al., are gaining popularity as effective approaches for modeling sequential data. Deep SSMs demonstrate outstanding performance across a diverse set of domains, at a reduced training and inference cost compared to attention-based transformers. Recent developments show that if the linear recurrence powering SSMs allows for multiplicative interactions between inputs and hidden states (e.g. GateLoop, Mamba, GLA), then the resulting architecture can surpass in both in accuracy and efficiency attention-powered foundation models trained on text, at scales of billion parameters. In this paper, we give theoretical grounding to this recent finding using tools from Rough Path Theory: we show that when random linear recurrences are equipped with simple input-controlled transitions (selectivity mechanism), then the hidden state is provably a low-dimensional projection of a powerful mathematical object called the signature of the input -- capturing non-linear interactions between tokens at distinct timescales. Our theory not only motivates the success of modern selective state-space models such as Mamba but also provides a solid framework to understand the expressive power of future SSM variants.</li>
</ul>

<h3>Title: Exploring the Efficacy of Large Language Models in Summarizing Mental  Health Counseling Sessions: A Benchmark Study</h3>
<ul>
<li><strong>Authors: </strong>Prottay Kumar Adhikary, Aseem Srivastava, Shivani Kumar, Salam Michael Singh, Puneet Manuja, Jini K Gopinath, Vijay Krishnan, Swati Kedia, Koushik Sinha Deb, Tanmoy Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19052">https://arxiv.org/abs/2402.19052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19052">https://arxiv.org/pdf/2402.19052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19052]] Exploring the Efficacy of Large Language Models in Summarizing Mental  Health Counseling Sessions: A Benchmark Study(https://arxiv.org/abs/2402.19052)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Comprehensive summaries of sessions enable an effective continuity in mental health counseling, facilitating informed therapy planning. Yet, manual summarization presents a significant challenge, diverting experts' attention from the core counseling process. This study evaluates the effectiveness of state-of-the-art Large Language Models (LLMs) in selectively summarizing various components of therapy sessions through aspect-based summarization, aiming to benchmark their performance. We introduce MentalCLOUDS, a counseling-component guided summarization dataset consisting of 191 counseling sessions with summaries focused on three distinct counseling components (aka counseling aspects). Additionally, we assess the capabilities of 11 state-of-the-art LLMs in addressing the task of component-guided summarization in counseling. The generated summaries are evaluated quantitatively using standard summarization metrics and verified qualitatively by mental health professionals. Our findings demonstrate the superior performance of task-specific LLMs such as MentalLlama, Mistral, and MentalBART in terms of standard quantitative metrics such as Rouge-1, Rouge-2, Rouge-L, and BERTScore across all aspects of counseling components. Further, expert evaluation reveals that Mistral supersedes both MentalLlama and MentalBART based on six parameters -- affective attitude, burden, ethicality, coherence, opportunity costs, and perceived effectiveness. However, these models share the same weakness by demonstrating a potential for improvement in the opportunity costs and perceived effectiveness metrics.</li>
</ul>

<h3>Title: RobWE: Robust Watermark Embedding for Personalized Federated Learning  Model Ownership Protection</h3>
<ul>
<li><strong>Authors: </strong>Yang Xu, Yunlin Tan, Cheng Zhang, Kai Chi, Peng Sun, Wenyuan Yang, Ju Ren, Hongbo Jiang, Yaoxue Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19054">https://arxiv.org/abs/2402.19054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19054">https://arxiv.org/pdf/2402.19054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19054]] RobWE: Robust Watermark Embedding for Personalized Federated Learning  Model Ownership Protection(https://arxiv.org/abs/2402.19054)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, federate, watermark</a></li>
<li><strong>Abstract: </strong>Embedding watermarks into models has been widely used to protect model ownership in federated learning (FL). However, existing methods are inadequate for protecting the ownership of personalized models acquired by clients in personalized FL (PFL). This is due to the aggregation of the global model in PFL, resulting in conflicts over clients' private watermarks. Moreover, malicious clients may tamper with embedded watermarks to facilitate model leakage and evade accountability. This paper presents a robust watermark embedding scheme, named RobWE, to protect the ownership of personalized models in PFL. We first decouple the watermark embedding of personalized models into two parts: head layer embedding and representation layer embedding. The head layer belongs to clients' private part without participating in model aggregation, while the representation layer is the shared part for aggregation. For representation layer embedding, we employ a watermark slice embedding operation, which avoids watermark embedding conflicts. Furthermore, we design a malicious watermark detection scheme enabling the server to verify the correctness of watermarks before aggregating local models. We conduct an exhaustive experimental evaluation of RobWE. The results demonstrate that RobWE significantly outperforms the state-of-the-art watermark embedding schemes in FL in terms of fidelity, reliability, and robustness.</li>
</ul>

<h3>Title: VEnvision3D: A Synthetic Perception Dataset for 3D Multi-Task Model  Research</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Zhou, Chen Long, Yue Xie, Jialiang Wang, Boheng Li, Haiping Wang, Zhe Chen, Zhen Dong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19059">https://arxiv.org/abs/2402.19059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19059">https://arxiv.org/pdf/2402.19059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19059]] VEnvision3D: A Synthetic Perception Dataset for 3D Multi-Task Model  Research(https://arxiv.org/abs/2402.19059)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Developing a unified multi-task foundation model has become a critical challenge in computer vision research. In the current field of 3D computer vision, most datasets solely focus on a relatively limited set of tasks, which complicates the concurrent training requirements of various downstream tasks. This makes the training of multi-objective networks difficult to proceed with, which further hinders the development of foundation models in the 3D vision field. In this paper, we introduce VEnvision3D, a large 3D synthetic perception dataset for multi-task learning, including depth completion, segmentation, upsampling, place recognition, and 3D reconstruction. Since the data for each task was collected in the same scenarios, tasks are inherently aligned in terms of the utilized data. Therefore, such a unique attribute can assist in exploring the potential for the multi-task model and even the foundation model without separate training methods. Several new benchmarks based on the characteristics of the proposed dataset were presented. Extensive studies were performed on end-to-end models, revealing new observations, challenges, and opportunities for future research. In addition, we designed a straightfoward multi-task network to uncover the ability that VEnvision3D can offer for the foundation model. Our dataset and code will be open-sourced upon acceptance.</li>
</ul>

<h3>Title: TimeXer: Empowering Transformers for Time Series Forecasting with  Exogenous Variables</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Wang, Haixu Wu, Jiaxiang Dong, Yong Liu, Yunzhong Qiu, Haoran Zhang, Jianmin Wang, Mingsheng Long</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19072">https://arxiv.org/abs/2402.19072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19072">https://arxiv.org/pdf/2402.19072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19072]] TimeXer: Empowering Transformers for Time Series Forecasting with  Exogenous Variables(https://arxiv.org/abs/2402.19072)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, TimeXer, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, TimeXer empowers the canonical Transformer architecture with the ability to reconcile endogenous and exogenous information, where patch-wise self-attention and variate-wise cross-attention are employed. Moreover, a global endogenous variate token is adopted to effectively bridge the exogenous series into endogenous temporal patches. Experimentally, TimeXer significantly improves time series forecasting with exogenous variables and achieves consistent state-of-the-art performance in twelve real-world forecasting benchmarks.</li>
</ul>

<h3>Title: Pointing out the Shortcomings of Relation Extraction Models with  Semantically Motivated Adversarials</h3>
<ul>
<li><strong>Authors: </strong>Gennaro Nolano, Moritz Blum, Basil Ell, Philipp Cimiano</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19076">https://arxiv.org/abs/2402.19076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19076">https://arxiv.org/pdf/2402.19076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19076]] Pointing out the Shortcomings of Relation Extraction Models with  Semantically Motivated Adversarials(https://arxiv.org/abs/2402.19076)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>In recent years, large language models have achieved state-of-the-art performance across various NLP tasks. However, investigations have shown that these models tend to rely on shortcut features, leading to inaccurate predictions and causing the models to be unreliable at generalization to out-of-distribution (OOD) samples. For instance, in the context of relation extraction (RE), we would expect a model to identify the same relation independently of the entities involved in it. For example, consider the sentence "Leonardo da Vinci painted the Mona Lisa" expressing the created(Leonardo_da_Vinci, Mona_Lisa) relation. If we substiute "Leonardo da Vinci" with "Barack Obama", then the sentence still expresses the created relation. A robust model is supposed to detect the same relation in both cases. In this work, we describe several semantically-motivated strategies to generate adversarial examples by replacing entity mentions and investigate how state-of-the-art RE models perform under pressure. Our analyses show that the performance of these models significantly deteriorates on the modified datasets (avg. of -48.5% in F1), which indicates that these models rely to a great extent on shortcuts, such as surface forms (or patterns therein) of entities, without making full use of the information present in the sentences.</li>
</ul>

<h3>Title: VideoMAC: Video Masked Autoencoders Meet ConvNets</h3>
<ul>
<li><strong>Authors: </strong>Gensheng Pei, Tao Chen, Xiruo Jiang, Huafeng Liu, Zeren Sun, Yazhou Yao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19082">https://arxiv.org/abs/2402.19082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19082">https://arxiv.org/pdf/2402.19082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19082]] VideoMAC: Video Masked Autoencoders Meet ConvNets(https://arxiv.org/abs/2402.19082)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Recently, the advancement of self-supervised learning techniques, like masked autoencoders (MAE), has greatly influenced visual representation learning for images and videos. Nevertheless, it is worth noting that the predominant approaches in existing masked image / video modeling rely excessively on resource-intensive vision transformers (ViTs) as the feature encoder. In this paper, we propose a new approach termed as \textbf{VideoMAC}, which combines video masked autoencoders with resource-friendly ConvNets. Specifically, VideoMAC employs symmetric masking on randomly sampled pairs of video frames. To prevent the issue of mask pattern dissipation, we utilize ConvNets which are implemented with sparse convolutional operators as encoders. Simultaneously, we present a simple yet effective masked video modeling (MVM) approach, a dual encoder architecture comprising an online encoder and an exponential moving average target encoder, aimed to facilitate inter-frame reconstruction consistency in videos. Additionally, we demonstrate that VideoMAC, empowering classical (ResNet) / modern (ConvNeXt) convolutional encoders to harness the benefits of MVM, outperforms ViT-based approaches on downstream tasks, including video object segmentation (+\textbf{5.2\%} / \textbf{6.4\%} $\mathcal{J}\&\mathcal{F}$), body part propagation (+\textbf{6.3\%} / \textbf{3.1\%} mIoU), and human pose tracking (+\textbf{10.2\%} / \textbf{11.1\%} PCK@0.1).</li>
</ul>

<h3>Title: Leveraging Representations from Intermediate Encoder-blocks for  Synthetic Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Christos Koutlis, Symeon Papadopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19091">https://arxiv.org/abs/2402.19091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19091">https://arxiv.org/pdf/2402.19091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19091]] Leveraging Representations from Intermediate Encoder-blocks for  Synthetic Image Detection(https://arxiv.org/abs/2402.19091)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>The recently developed and publicly available synthetic image generation methods and services make it possible to create extremely realistic imagery on demand, raising great risks for the integrity and safety of online information. State-of-the-art Synthetic Image Detection (SID) research has led to strong evidence on the advantages of feature extraction from foundation models. However, such extracted features mostly encapsulate high-level visual semantics instead of fine-grained details, which are more important for the SID task. On the contrary, shallow layers encode low-level visual information. In this work, we leverage the image representations extracted by intermediate Transformer blocks of CLIP's image-encoder via a lightweight network that maps them to a learnable forgery-aware vector space capable of generalizing exceptionally well. We also employ a trainable module to incorporate the importance of each Transformer block to the final prediction. Our method is compared against the state-of-the-art by evaluating it on 20 test datasets and exhibits an average +10.6% absolute performance improvement. Notably, the best performing models require just a single epoch for training (~8 minutes). Code available at https://github.com/mever-team/rine.</li>
</ul>

<h3>Title: TEncDM: Understanding the Properties of Diffusion Model in the Space of  Language Model Encodings</h3>
<ul>
<li><strong>Authors: </strong>Alexander Shabalin, Viacheslav Meshchaninov, Tingir Badmaev, Dmitry Molchanov, Grigory Bartosh, Sergey Markov, Dmitry Vetrov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19097">https://arxiv.org/abs/2402.19097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19097">https://arxiv.org/pdf/2402.19097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19097]] TEncDM: Understanding the Properties of Diffusion Model in the Space of  Language Model Encodings(https://arxiv.org/abs/2402.19097)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Drawing inspiration from the success of diffusion models in various domains, numerous research papers proposed methods for adapting them to text data. Despite these efforts, none of them has managed to achieve the quality of the large language models. In this paper, we conduct a comprehensive analysis of key components of the text diffusion models and introduce a novel approach named Text Encoding Diffusion Model (TEncDM). Instead of the commonly used token embedding space, we train our model in the space of the language model encodings. Additionally, we propose to use a Transformer-based decoder that utilizes contextual information for text reconstruction. We also analyse self-conditioning and find that it increases the magnitude of the model outputs, allowing the reduction of the number of denoising steps at the inference stage. Evaluation of TEncDM on two downstream text generation tasks, QQP and XSum, demonstrates its superiority over existing non-autoregressive models.</li>
</ul>

<h3>Title: FlatNAS: optimizing Flatness in Neural Architecture Search for  Out-of-Distribution Robustness</h3>
<ul>
<li><strong>Authors: </strong>Matteo Gambella, Fabrizio Pittorino, Manuel Roveri</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19102">https://arxiv.org/abs/2402.19102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19102">https://arxiv.org/pdf/2402.19102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19102]] FlatNAS: optimizing Flatness in Neural Architecture Search for  Out-of-Distribution Robustness(https://arxiv.org/abs/2402.19102)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural Architecture Search (NAS) paves the way for the automatic definition of Neural Network (NN) architectures, attracting increasing research attention and offering solutions in various scenarios. This study introduces a novel NAS solution, called Flat Neural Architecture Search (FlatNAS), which explores the interplay between a novel figure of merit based on robustness to weight perturbations and single NN optimization with Sharpness-Aware Minimization (SAM). FlatNAS is the first work in the literature to systematically explore flat regions in the loss landscape of NNs in a NAS procedure, while jointly optimizing their performance on in-distribution data, their out-of-distribution (OOD) robustness, and constraining the number of parameters in their architecture. Differently from current studies primarily concentrating on OOD algorithms, FlatNAS successfully evaluates the impact of NN architectures on OOD robustness, a crucial aspect in real-world applications of machine and deep learning. FlatNAS achieves a good trade-off between performance, OOD generalization, and the number of parameters, by using only in-distribution data in the NAS exploration. The OOD robustness of the NAS-designed models is evaluated by focusing on robustness to input data corruptions, using popular benchmark datasets in the literature.</li>
</ul>

<h3>Title: Whispers that Shake Foundations: Analyzing and Mitigating False Premise  Hallucinations in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hongbang Yuan, Pengfei Cao, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19103">https://arxiv.org/abs/2402.19103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19103">https://arxiv.org/pdf/2402.19103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19103]] Whispers that Shake Foundations: Analyzing and Mitigating False Premise  Hallucinations in Large Language Models(https://arxiv.org/abs/2402.19103)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown impressive capabilities but still suffer from the issue of hallucinations. A significant type of this issue is the false premise hallucination, which we define as the phenomenon when LLMs generate hallucinated text when confronted with false premise questions. In this paper, we perform a comprehensive analysis of the false premise hallucination and elucidate its internal working mechanism: a small subset of attention heads (which we designate as false premise heads) disturb the knowledge extraction process, leading to the occurrence of false premise hallucination. Based on our analysis, we propose \textbf{FAITH} (\textbf{F}alse premise \textbf{A}ttention head constra\textbf{I}ining for mi\textbf{T}igating \textbf{H}allucinations), a novel and effective method to mitigate false premise hallucinations. It constrains the false premise attention heads during the model inference process. Impressively, extensive experiments demonstrate that constraining only approximately $1\%$ of the attention heads in the model yields a notable increase of nearly $20\%$ of model performance.</li>
</ul>

<h3>Title: CollaFuse: Navigating Limited Resources and Privacy in Collaborative  Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Domenique Zipperling, Simeon Allmendinger, Lukas Struppek, Niklas Kühl</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19105">https://arxiv.org/abs/2402.19105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19105">https://arxiv.org/pdf/2402.19105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19105]] CollaFuse: Navigating Limited Resources and Privacy in Collaborative  Generative AI(https://arxiv.org/abs/2402.19105)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, diffusion, generative</a></li>
<li><strong>Abstract: </strong>In the landscape of generative artificial intelligence, diffusion-based models present challenges for socio-technical systems in data requirements and privacy. Traditional approaches like federated learning distribute the learning process but strain individual clients, especially with constrained resources (e.g., edge devices). In response to these challenges, we introduce CollaFuse, a novel framework inspired by split learning. Tailored for efficient and collaborative use of denoising diffusion probabilistic models, CollaFuse enables shared server training and inference, alleviating client computational burdens. This is achieved by retaining data and computationally inexpensive GPU processes locally at each client while outsourcing the computationally expensive processes to the shared server. Demonstrated in a healthcare context, CollaFuse enhances privacy by highly reducing the need for sensitive information sharing. These capabilities hold the potential to impact various application areas, such as the design of edge computing solutions, healthcare research, or autonomous driving. In essence, our work advances distributed machine learning, shaping the future of collaborative GenAI networks.</li>
</ul>

<h3>Title: Continuous Sign Language Recognition Based on Motor attention mechanism  and frame-level Self-distillation</h3>
<ul>
<li><strong>Authors: </strong>Qidan Zhu, Jing Li, Fei Yuan, Quan Gan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19118">https://arxiv.org/abs/2402.19118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19118">https://arxiv.org/pdf/2402.19118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19118]] Continuous Sign Language Recognition Based on Motor attention mechanism  and frame-level Self-distillation(https://arxiv.org/abs/2402.19118)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Changes in facial expression, head movement, body movement and gesture movement are remarkable cues in sign language recognition, and most of the current continuous sign language recognition(CSLR) research methods mainly focus on static images in video sequences at the frame-level feature extraction stage, while ignoring the dynamic changes in the images. In this paper, we propose a novel motor attention mechanism to capture the distorted changes in local motion regions during sign language expression, and obtain a dynamic representation of image changes. And for the first time, we apply the self-distillation method to frame-level feature extraction for continuous sign language, which improves the feature expression without increasing the computational resources by self-distilling the features of adjacent stages and using the higher-order features as teachers to guide the lower-order features. The combination of the two constitutes our proposed holistic model of CSLR Based on motor attention mechanism and frame-level Self-Distillation (MAM-FSD), which improves the inference ability and robustness of the model. We conduct experiments on three publicly available datasets, and the experimental results show that our proposed method can effectively extract the sign language motion information in videos, improve the accuracy of CSLR and reach the state-of-the-art level.</li>
</ul>

<h3>Title: VIXEN: Visual Text Comparison Network for Image Difference Captioning</h3>
<ul>
<li><strong>Authors: </strong>Alexander Black, Jing Shi, Yifei Fai, Tu Bui, John Collomosse</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19119">https://arxiv.org/abs/2402.19119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19119">https://arxiv.org/pdf/2402.19119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19119]] VIXEN: Visual Text Comparison Network for Image Difference Captioning(https://arxiv.org/abs/2402.19119)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present VIXEN - a technique that succinctly summarizes in text the visual differences between a pair of images in order to highlight any content manipulation present. Our proposed network linearly maps image features in a pairwise manner, constructing a soft prompt for a pretrained large language model. We address the challenge of low volume of training data and lack of manipulation variety in existing image difference captioning (IDC) datasets by training on synthetically manipulated images from the recent InstructPix2Pix dataset generated via prompt-to-prompt editing framework. We augment this dataset with change summaries produced via GPT-3. We show that VIXEN produces state-of-the-art, comprehensible difference captions for diverse image contents and edit types, offering a potential mitigation against misinformation disseminated via manipulated image content. Code and data are available at this http URL</li>
</ul>

<h3>Title: Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale  Annotations</h3>
<ul>
<li><strong>Authors: </strong>Stephanie Brandl, Oliver Eberle, Tiago Ribeiro, Anders Søgaard, Nora Hollenstein</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19133">https://arxiv.org/abs/2402.19133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19133">https://arxiv.org/pdf/2402.19133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19133]] Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale  Annotations(https://arxiv.org/abs/2402.19133)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer</a></li>
<li><strong>Abstract: </strong>Rationales in the form of manually annotated input spans usually serve as ground truth when evaluating explainability methods in NLP. They are, however, time-consuming and often biased by the annotation process. In this paper, we debate whether human gaze, in the form of webcam-based eye-tracking recordings, poses a valid alternative when evaluating importance scores. We evaluate the additional information provided by gaze data, such as total reading times, gaze entropy, and decoding accuracy with respect to human rationale annotations. We compare WebQAmGaze, a multilingual dataset for information-seeking QA, with attention and explainability-based importance scores for 4 different multilingual Transformer-based language models (mBERT, distil-mBERT, XLMR, and XLMR-L) and 3 languages (English, Spanish, and German). Our pipeline can easily be applied to other tasks and languages. Our findings suggest that gaze data offers valuable linguistic insights that could be leveraged to infer task difficulty and further show a comparable ranking of explainability methods to that of human rationales.</li>
</ul>

<h3>Title: ProtoP-OD: Explainable Object Detection with Prototypical Parts</h3>
<ul>
<li><strong>Authors: </strong>Pavlos Rath-Manakidis, Frederik Strothmann, Tobias Glasmachers, Laurenz Wiskott</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19142">https://arxiv.org/abs/2402.19142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19142">https://arxiv.org/pdf/2402.19142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19142]] ProtoP-OD: Explainable Object Detection with Prototypical Parts(https://arxiv.org/abs/2402.19142)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Interpretation and visualization of the behavior of detection transformers tends to highlight the locations in the image that the model attends to, but it provides limited insight into the \emph{semantics} that the model is focusing on. This paper introduces an extension to detection transformers that constructs prototypical local features and uses them in object detection. These custom features, which we call prototypical parts, are designed to be mutually exclusive and align with the classifications of the model. The proposed extension consists of a bottleneck module, the prototype neck, that computes a discretized representation of prototype activations and a new loss term that matches prototypes to object classes. This setup leads to interpretable representations in the prototype neck, allowing visual inspection of the image content perceived by the model and a better understanding of the model's reliability. We show experimentally that our method incurs only a limited performance penalty, and we provide examples that demonstrate the quality of the explanations provided by our method, which we argue outweighs the performance penalty.</li>
</ul>

<h3>Title: A SAM-guided Two-stream Lightweight Model for Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Chenghao Li, Lei Qi, Xin Geng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19145">https://arxiv.org/abs/2402.19145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19145">https://arxiv.org/pdf/2402.19145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19145]] A SAM-guided Two-stream Lightweight Model for Anomaly Detection(https://arxiv.org/abs/2402.19145)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In industrial anomaly detection, model efficiency and mobile-friendliness become the primary concerns in real-world applications. Simultaneously, the impressive generalization capabilities of Segment Anything (SAM) have garnered broad academic attention, making it an ideal choice for localizing unseen anomalies and diverse real-world patterns. In this paper, considering these two critical factors, we propose a SAM-guided Two-stream Lightweight Model for unsupervised anomaly detection (STLM) that not only aligns with the two practical application requirements but also harnesses the robust generalization capabilities of SAM. We employ two lightweight image encoders, i.e., our two-stream lightweight module, guided by SAM's knowledge. To be specific, one stream is trained to generate discriminative and general feature representations in both normal and anomalous regions, while the other stream reconstructs the same images without anomalies, which effectively enhances the differentiation of two-stream representations when facing anomalous regions. Furthermore, we employ a shared mask decoder and a feature aggregation module to generate anomaly maps. Our experiments conducted on MVTec AD benchmark show that STLM, with about 16M parameters and achieving an inference time in 20ms, competes effectively with state-of-the-art methods in terms of performance, 98.26% on pixel-level AUC and 94.92% on PRO. We further experiment on more difficult datasets, e.g., VisA and DAGM, to demonstrate the effectiveness and generalizability of STLM.</li>
</ul>

<h3>Title: Typographic Attacks in Large Multimodal Models Can be Alleviated by More  Informative Prompts</h3>
<ul>
<li><strong>Authors: </strong>Hao Cheng, Erjia Xiao, Renjing Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19150">https://arxiv.org/abs/2402.19150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19150">https://arxiv.org/pdf/2402.19150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19150]] Typographic Attacks in Large Multimodal Models Can be Alleviated by More  Informative Prompts(https://arxiv.org/abs/2402.19150)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Multimodal Models (LMMs) rely on pre-trained Vision Language Models (VLMs) and Large Language Models (LLMs) to perform amazing emergent abilities on various multimodal tasks in the joint space of vision and language. However, the Typographic Attack, which shows disruption to VLMs, has also been certified as a security vulnerability to LMMs. In this work, we first comprehensively investigate the distractibility of LMMs by typography. In particular, we introduce the Typographic Dataset designed to evaluate distractibility across various multi-modal subtasks, such as object recognition, visual attributes detection, enumeration, arithmetic computation, and commonsense reasoning. To further study the effect of typographic patterns on performance, we also scrutinize the effect of tuning various typographic factors, encompassing font size, color, opacity, and spatial positioning of typos. We discover that LMMs can partially distinguish visual contents and typos when confronting typographic attacks, which suggests that embeddings from vision encoders contain enough information to distinguish visual contents and typos in images. Inspired by such phenomena, we demonstrate that CLIP's performance of zero-shot classification on typo-ridden images can be significantly improved by providing more informative texts to match images. Furthermore, we also prove that LMMs can utilize more informative prompts to leverage information in embeddings to differentiate between visual content and typos. Finally, we propose a prompt information enhancement method that can effectively mitigate the effects of typography.</li>
</ul>

<h3>Title: FedStruct: Federated Decoupled Learning over Interconnected Graphs</h3>
<ul>
<li><strong>Authors: </strong>Javad Aliakbari, Johan Östman, Alexandre Graell i Amat</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19163">https://arxiv.org/abs/2402.19163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19163">https://arxiv.org/pdf/2402.19163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19163]] FedStruct: Federated Decoupled Learning over Interconnected Graphs(https://arxiv.org/abs/2402.19163)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.</li>
</ul>

<h3>Title: Teaching Large Language Models an Unseen Language on the Fly</h3>
<ul>
<li><strong>Authors: </strong>Chen Zhang, Xiao Liu, Jiuheng Lin, Yansong Feng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19167">https://arxiv.org/abs/2402.19167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19167">https://arxiv.org/pdf/2402.19167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19167]] Teaching Large Language Models an Unseen Language on the Fly(https://arxiv.org/abs/2402.19167)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing large language models struggle to support numerous low-resource languages, particularly the extremely low-resource ones where there is minimal training data available for effective parameter updating. We thus investigate whether LLMs can learn a new language on the fly solely through prompting. To study this question, we collect a research suite for Zhuang, a language supported by no LLMs currently. We introduce \textsc{DiPMT++}, a framework for adapting LLMs to unseen languages by in-context learning. Using a dictionary and only 5K parallel sentences, \textsc{DiPMT++} significantly enhances the performance of GPT-4 from 0 to 16 BLEU for Chinese-to-Zhuang translation and achieves 32 BLEU for Zhuang-to-Chinese translation. Furthermore, we demonstrate the practical utility of this framework in aiding humans to translate completely unseen languages, which could contribute to the preservation of linguistic diversity.</li>
</ul>

<h3>Title: Improving Legal Judgement Prediction in Romanian with Long Text Encoders</h3>
<ul>
<li><strong>Authors: </strong>Mihai Masala, Traian Rebedea, Horia Velicu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19170">https://arxiv.org/abs/2402.19170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19170">https://arxiv.org/pdf/2402.19170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19170]] Improving Legal Judgement Prediction in Romanian with Long Text Encoders(https://arxiv.org/abs/2402.19170)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years,the entire field of Natural Language Processing (NLP) has enjoyed amazing novel results achieving almost human-like performance on a variety of tasks. Legal NLP domain has also been part of this process, as it has seen an impressive growth. However, general-purpose models are not readily applicable for legal domain. Due to the nature of the domain (e.g. specialized vocabulary, long documents) specific models and methods are often needed for Legal NLP. In this work we investigate both specialized and general models for predicting the final ruling of a legal case, task known as Legal Judgment Prediction (LJP). We particularly focus on methods to extend to sequence length of Transformer-based models to better understand the long documents present in legal corpora. Extensive experiments on 4 LJP datasets in Romanian, originating from 2 sources with significantly different sizes and document lengths, show that specialized models and handling long texts are critical for a good performance.</li>
</ul>

<h3>Title: Disentangling representations of retinal images with generative models</h3>
<ul>
<li><strong>Authors: </strong>Sarah Müller, Lisa M. Koch, Hendrik P. A. Lensch, Philipp Berens</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19186">https://arxiv.org/abs/2402.19186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19186">https://arxiv.org/pdf/2402.19186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19186]] Disentangling representations of retinal images with generative models(https://arxiv.org/abs/2402.19186)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Retinal fundus images play a crucial role in the early detection of eye diseases and, using deep learning approaches, recent studies have even demonstrated their potential for detecting cardiovascular risk factors and neurological disorders. However, the impact of technical factors on these images can pose challenges for reliable AI applications in ophthalmology. For example, large fundus cohorts are often confounded by factors like camera type, image quality or illumination level, bearing the risk of learning shortcuts rather than the causal relationships behind the image generation process. Here, we introduce a novel population model for retinal fundus images that effectively disentangles patient attributes from camera effects, thus enabling controllable and highly realistic image generation. To achieve this, we propose a novel disentanglement loss based on distance correlation. Through qualitative and quantitative analyses, we demonstrate the effectiveness of this novel loss function in disentangling the learned subspaces. Our results show that our model provides a new perspective on the complex relationship between patient attributes and technical confounders in retinal fundus image generation.</li>
</ul>

<h3>Title: PRSA: Prompt Reverse Stealing Attacks against Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yong Yang, Xuhong Zhang, Yi Jiang, Xi Chen, Haoyu Wang, Shouling Ji, Zonghui Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19200">https://arxiv.org/abs/2402.19200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19200">https://arxiv.org/pdf/2402.19200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19200]] PRSA: Prompt Reverse Stealing Attacks against Large Language Models(https://arxiv.org/abs/2402.19200)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Prompt, recognized as crucial intellectual property, enables large language models (LLMs) to perform specific tasks without the need of fine-tuning, underscoring their escalating importance. With the rise of prompt-based services, such as prompt marketplaces and LLM applications, providers often display prompts' capabilities through input-output examples to attract users. However, this paradigm raises a pivotal security concern: does the exposure of input-output pairs pose the risk of potential prompt leakage, infringing on the intellectual property rights of the developers? To our knowledge, this problem still has not been comprehensively explored yet. To remedy this gap, in this paper, we perform the first in depth exploration and propose a novel attack framework for reverse-stealing prompts against commercial LLMs, namely PRSA. The main idea of PRSA is that by analyzing the critical features of the input-output pairs, we mimic and gradually infer (steal) the target prompts. In detail, PRSA mainly consists of two key phases: prompt mutation and prompt pruning. In the mutation phase, we propose a prompt attention algorithm based on differential feedback to capture these critical features for effectively inferring the target prompts. In the prompt pruning phase, we identify and mask the words dependent on specific inputs, enabling the prompts to accommodate diverse inputs for generalization. Through extensive evaluation, we verify that PRSA poses a severe threat in real world scenarios. We have reported these findings to prompt service providers and actively collaborate with them to take protective measures for prompt copyright.</li>
</ul>

<h3>Title: PeLLE: Encoder-based language models for Brazilian Portuguese based on  open data</h3>
<ul>
<li><strong>Authors: </strong>Guilherme Lamartine de Mello, Marcelo Finger, and Felipe Serras, Miguel de Mello Carpi, Marcos Menon Jose, Pedro Henrique Domingues, Paulo Cavalim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19204">https://arxiv.org/abs/2402.19204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19204">https://arxiv.org/pdf/2402.19204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19204]] PeLLE: Encoder-based language models for Brazilian Portuguese based on  open data(https://arxiv.org/abs/2402.19204)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>In this paper we present PeLLE, a family of large language models based on the RoBERTa architecture, for Brazilian Portuguese, trained on curated, open data from the Carolina corpus. Aiming at reproducible results, we describe details of the pretraining of the models. We also evaluate PeLLE models against a set of existing multilingual and PT-BR refined pretrained Transformer-based LLM encoders, contrasting performance of large versus smaller-but-curated pretrained models in several downstream tasks. We conclude that several tasks perform better with larger models, but some tasks benefit from smaller-but-curated data in its pretraining.</li>
</ul>

<h3>Title: Memory-Augmented Generative Adversarial Transformers</h3>
<ul>
<li><strong>Authors: </strong>Stephan Raaijmakers, Roos Bakker, Anita Cremers, Roy de Kleijn, Tom Kouwenhoven, Tessa Verhoef</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19218">https://arxiv.org/abs/2402.19218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19218">https://arxiv.org/pdf/2402.19218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19218]] Memory-Augmented Generative Adversarial Transformers(https://arxiv.org/abs/2402.19218)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Conversational AI systems that rely on Large Language Models, like Transformers, have difficulty interweaving external data (like facts) with the language they generate. Vanilla Transformer architectures are not designed for answering factual questions with high accuracy. This paper investigates a possible route for addressing this problem. We propose to extend the standard Transformer architecture with an additional memory bank holding extra information (such as facts drawn from a knowledge base), and an extra attention layer for addressing this memory. We add this augmented memory to a Generative Adversarial Network-inspired Transformer architecture. This setup allows for implementing arbitrary felicity conditions on the generated language of the Transformer. We first demonstrate how this machinery can be deployed for handling factual questions in goal-oriented dialogues. Secondly, we demonstrate that our approach can be useful for applications like {\it style adaptation} as well: the adaptation of utterances according to certain stylistic (external) constraints, like social properties of human interlocutors in dialogues.</li>
</ul>

<h3>Title: Investigating Gender Fairness in Machine Learning-driven Personalized  Care for Chronic Pain</h3>
<ul>
<li><strong>Authors: </strong>Pratik Gajane, Sean Newman, John D. Piette</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19226">https://arxiv.org/abs/2402.19226</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19226">https://arxiv.org/pdf/2402.19226</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19226]] Investigating Gender Fairness in Machine Learning-driven Personalized  Care for Chronic Pain(https://arxiv.org/abs/2402.19226)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This study investigates gender fairness in personalized pain care recommendations using machine learning algorithms. Leveraging a contextual bandits framework, personalized recommendations are formulated and evaluated using LinUCB algorithm on a dataset comprising interactions with $164$ patients across $10$ sessions each. Results indicate that while adjustments to algorithm parameters influence the quality of pain care recommendations, this impact remains consistent across genders. However, when certain patient information, such as self-reported pain measurements, is absent, the quality of pain care recommendations for women is notably inferior to that for men.</li>
</ul>

<h3>Title: CricaVPR: Cross-image Correlation-aware Representation Learning for  Visual Place Recognition</h3>
<ul>
<li><strong>Authors: </strong>Feng Lu, Xiangyuan Lan, Lijun Zhang, Dongmei Jiang, Yaowei Wang, Chun Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19231">https://arxiv.org/abs/2402.19231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19231">https://arxiv.org/pdf/2402.19231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19231]] CricaVPR: Cross-image Correlation-aware Representation Learning for  Visual Place Recognition(https://arxiv.org/abs/2402.19231)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Over the past decade, most methods in visual place recognition (VPR) have used neural networks to produce feature representations. These networks typically produce a global representation of a place image using only this image itself and neglect the cross-image variations (e.g. viewpoint and illumination), which limits their robustness in challenging scenes. In this paper, we propose a robust global representation method with cross-image correlation awareness for VPR, named CricaVPR. Our method uses the self-attention mechanism to correlate multiple images within a batch. These images can be taken in the same place with different conditions or viewpoints, or even captured from different places. Therefore, our method can utilize the cross-image variations as a cue to guide the representation learning, which ensures more robust features are produced. To further facilitate the robustness, we propose a multi-scale convolution-enhanced adaptation method to adapt pre-trained visual foundation models to the VPR task, which introduces the multi-scale local information to further enhance the cross-image correlation-aware representation. Experimental results show that our method outperforms state-of-the-art methods by a large margin with significantly less training time. Our method achieves 94.5% R@1 on Pitts30k using 512-dim global features. The code is released at https://github.com/Lu-Feng/CricaVPR.</li>
</ul>

<h3>Title: Trained Random Forests Completely Reveal your Dataset</h3>
<ul>
<li><strong>Authors: </strong>Julien Ferry, Ricardo Fukasawa, Timothée Pascal, Thibaut Vidal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19232">https://arxiv.org/abs/2402.19232</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19232">https://arxiv.org/pdf/2402.19232</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19232]] Trained Random Forests Completely Reveal your Dataset(https://arxiv.org/abs/2402.19232)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>We introduce an optimization-based reconstruction attack capable of completely or near-completely reconstructing a dataset utilized for training a random forest. Notably, our approach relies solely on information readily available in commonly used libraries such as scikit-learn. To achieve this, we formulate the reconstruction problem as a combinatorial problem under a maximum likelihood objective. We demonstrate that this problem is NP-hard, though solvable at scale using constraint programming -- an approach rooted in constraint propagation and solution-domain reduction. Through an extensive computational investigation, we demonstrate that random forests trained without bootstrap aggregation but with feature randomization are susceptible to a complete reconstruction. This holds true even with a small number of trees. Even with bootstrap aggregation, the majority of the data can also be reconstructed. These findings underscore a critical vulnerability inherent in widely adopted ensemble methods, warranting attention and mitigation. Although the potential for such reconstruction attacks has been discussed in privacy research, our study provides clear empirical evidence of their practicability.</li>
</ul>

<h3>Title: Context-based Interpretable Spatio-Temporal Graph Convolutional Network  for Human Motion Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Edgar Medina, Leyong Loh, Namrata Gurung, Kyung Hun Oh, Niels Heller</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19237">https://arxiv.org/abs/2402.19237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19237">https://arxiv.org/pdf/2402.19237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19237]] Context-based Interpretable Spatio-Temporal Graph Convolutional Network  for Human Motion Forecasting(https://arxiv.org/abs/2402.19237)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Human motion prediction is still an open problem extremely important for autonomous driving and safety applications. Due to the complex spatiotemporal relation of motion sequences, this remains a challenging problem not only for movement prediction but also to perform a preliminary interpretation of the joint connections. In this work, we present a Context-based Interpretable Spatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D human pose forecasting model based on GCNs that encompasses specific layers, aiding model interpretability and providing information that might be useful when analyzing motion distribution and body behavior. Our architecture extracts meaningful information from pose sequences, aggregates displacements and accelerations into the input model, and finally predicts the output displacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI datasets demonstrate that CIST-GCN outperforms previous methods in human motion prediction and robustness. Since the idea of enhancing interpretability for motion prediction has its merits, we showcase experiments towards it and provide preliminary evaluations of such insights here. available code: https://github.com/QualityMinds/cistgcn</li>
</ul>

<h3>Title: Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question  Answering Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Zhikun Xu, Yinghui Li, Ruixue Ding, Xinyu Wang, Boli Chen, Yong Jiang, Xiaodong Deng, Jianxin Ma, Hai-Tao Zheng, Wenlian Lu, Pengjun Xie, Chang Zhou, Fei Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19248">https://arxiv.org/abs/2402.19248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19248">https://arxiv.org/pdf/2402.19248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19248]] Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question  Answering Benchmark(https://arxiv.org/abs/2402.19248)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>How to better evaluate the capabilities of Large Language Models (LLMs) is the focal point and hot topic in current LLMs research. Previous work has noted that due to the extremely high cost of iterative updates of LLMs, they are often unable to answer the latest dynamic questions well. To promote the improvement of Chinese LLMs' ability to answer dynamic questions, in this paper, we introduce CDQA, a Chinese Dynamic QA benchmark containing question-answer pairs related to the latest news on the Chinese Internet. We obtain high-quality data through a pipeline that combines humans and models, and carefully classify the samples according to the frequency of answer changes to facilitate a more fine-grained observation of LLMs' capabilities. We have also evaluated and analyzed mainstream and advanced Chinese LLMs on CDQA. Extensive experiments and valuable insights suggest that our proposed CDQA is challenging and worthy of more further study. We believe that the benchmark we provide will become the key data resource for improving LLMs' Chinese question-answering ability in the future.</li>
</ul>

<h3>Title: Feature boosting with efficient attention for scene parsing</h3>
<ul>
<li><strong>Authors: </strong>Vivek Singh, Shailza Sharma, Fabio Cuzzolin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19250">https://arxiv.org/abs/2402.19250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19250">https://arxiv.org/pdf/2402.19250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19250]] Feature boosting with efficient attention for scene parsing(https://arxiv.org/abs/2402.19250)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The complexity of scene parsing grows with the number of object and scene classes, which is higher in unrestricted open scenes. The biggest challenge is to model the spatial relation between scene elements while succeeding in identifying objects at smaller scales. This paper presents a novel feature-boosting network that gathers spatial context from multiple levels of feature extraction and computes the attention weights for each level of representation to generate the final class labels. A novel `channel attention module' is designed to compute the attention weights, ensuring that features from the relevant extraction stages are boosted while the others are attenuated. The model also learns spatial context information at low resolution to preserve the abstract spatial relationships among scene elements and reduce computation cost. Spatial attention is subsequently concatenated into a final feature set before applying feature boosting. Low-resolution spatial attention features are trained using an auxiliary task that helps learning a coarse global scene structure. The proposed model outperforms all state-of-the-art models on both the ADE20K and the Cityscapes datasets.</li>
</ul>

<h3>Title: Machine learning for modular multiplication</h3>
<ul>
<li><strong>Authors: </strong>Kristin Lauter, Cathy Yuanchen Li, Krystal Maughan, Rachel Newton, Megha Srivastava</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19254">https://arxiv.org/abs/2402.19254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19254">https://arxiv.org/pdf/2402.19254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19254]] Machine learning for modular multiplication(https://arxiv.org/abs/2402.19254)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Motivated by cryptographic applications, we investigate two machine learning approaches to modular multiplication: namely circular regression and a sequence-to-sequence transformer model. The limited success of both methods demonstrated in our results gives evidence for the hardness of tasks involving modular multiplication upon which cryptosystems are based.</li>
</ul>

<h3>Title: GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of  LLMs as Mathematical Problem Solvers</h3>
<ul>
<li><strong>Authors: </strong>Qintong Li, Leyang Cui, Xueliang Zhao, Lingpeng Kong, Wei Bi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19255">https://arxiv.org/abs/2402.19255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19255">https://arxiv.org/pdf/2402.19255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19255]] GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of  LLMs as Mathematical Problem Solvers(https://arxiv.org/abs/2402.19255)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks. However, there are increasing debates regarding whether these models truly understand and apply mathematical knowledge or merely rely on shortcuts for mathematical reasoning. One essential and frequently occurring evidence is that when the math questions are slightly changed, LLMs can behave incorrectly. This motivates us to evaluate the robustness of LLMs' math reasoning capability by testing a wide range of question variations. We introduce the adversarial grade school math (\datasetname) dataset, an extension of GSM8K augmented with various mathematical perturbations. Our experiments on 25 LLMs and 4 prompting techniques show that while LLMs exhibit different levels of math reasoning abilities, their performances are far from robust. In particular, even for problems that have been solved in GSM8K, LLMs can make mistakes when new statements are added or the question targets are altered. We also explore whether more robust performance can be achieved by composing existing prompting methods, in which we try an iterative method that generates and verifies each intermediate thought based on its reasoning goal and calculation result. Code and data are available at \url{https://github.com/qtli/GSM-Plus}.</li>
</ul>

<h3>Title: MaskFi: Unsupervised Learning of WiFi and Vision Representations for  Multimodal Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Jianfei Yang, Shijie Tang, Yuecong Xu, Yunjiao Zhou, Lihua Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19258">https://arxiv.org/abs/2402.19258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19258">https://arxiv.org/pdf/2402.19258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19258]] MaskFi: Unsupervised Learning of WiFi and Vision Representations for  Multimodal Human Activity Recognition(https://arxiv.org/abs/2402.19258)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Human activity recognition (HAR) has been playing an increasingly important role in various domains such as healthcare, security monitoring, and metaverse gaming. Though numerous HAR methods based on computer vision have been developed to show prominent performance, they still suffer from poor robustness in adverse visual conditions in particular low illumination, which motivates WiFi-based HAR to serve as a good complementary modality. Existing solutions using WiFi and vision modalities rely on massive labeled data that are very cumbersome to collect. In this paper, we propose a novel unsupervised multimodal HAR solution, MaskFi, that leverages only unlabeled video and WiFi activity data for model training. We propose a new algorithm, masked WiFi-vision modeling (MI2M), that enables the model to learn cross-modal and single-modal features by predicting the masked sections in representation learning. Benefiting from our unsupervised learning procedure, the network requires only a small amount of annotated data for finetuning and can adapt to the new environment with better performance. We conduct extensive experiments on two WiFi-vision datasets collected in-house, and our method achieves human activity recognition and human identification in terms of both robustness and accuracy.</li>
</ul>

<h3>Title: Masks, Signs, And Learning Rate Rewinding</h3>
<ul>
<li><strong>Authors: </strong>Advait Gadhikar, Rebekka Burkholz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19262">https://arxiv.org/abs/2402.19262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19262">https://arxiv.org/pdf/2402.19262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19262]] Masks, Signs, And Learning Rate Rewinding(https://arxiv.org/abs/2402.19262)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning Rate Rewinding (LRR) has been established as a strong variant of Iterative Magnitude Pruning (IMP) to find lottery tickets in deep overparameterized neural networks. While both iterative pruning schemes couple structure and parameter learning, understanding how LRR excels in both aspects can bring us closer to the design of more flexible deep learning algorithms that can optimize diverse sets of sparse architectures. To this end, we conduct experiments that disentangle the effect of mask learning and parameter optimization and how both benefit from overparameterization. The ability of LRR to flip parameter signs early and stay robust to sign perturbations seems to make it not only more effective in mask identification but also in optimizing diverse sets of masks, including random ones. In support of this hypothesis, we prove in a simplified single hidden neuron setting that LRR succeeds in more cases than IMP, as it can escape initially problematic sign configurations.</li>
</ul>

<h3>Title: Spinal Osteophyte Detection via Robust Patch Extraction on minimally  annotated X-rays</h3>
<ul>
<li><strong>Authors: </strong>Soumya Snigdha Kundu, Yuanhan Mo, Nicharee Srikijkasemwat, Bartłomiej W. Papiez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19263">https://arxiv.org/abs/2402.19263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19263">https://arxiv.org/pdf/2402.19263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19263]] Spinal Osteophyte Detection via Robust Patch Extraction on minimally  annotated X-rays(https://arxiv.org/abs/2402.19263)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>The development and progression of arthritis is strongly associated with osteophytes, which are small and elusive bone growths. This paper presents one of the first efforts towards automated spinal osteophyte detection in spinal X-rays. A novel automated patch extraction process, called SegPatch, has been proposed based on deep learning-driven vertebrae segmentation and the enlargement of mask contours. A final patch classification accuracy of 84.5\% is secured, surpassing a baseline tiling-based patch generation technique by 9.5%. This demonstrates that even with limited annotations, SegPatch can deliver superior performance for detection of tiny structures such as osteophytes. The proposed approach has potential to assist clinicians in expediting the process of manually identifying osteophytes in spinal X-ray.</li>
</ul>

<h3>Title: Robust Guidance for Unsupervised Data Selection: Capturing Perplexing  Named Entities for Domain-Specific Machine Translation</h3>
<ul>
<li><strong>Authors: </strong>Seunghyun Ji, Hagai Raja Sinulingga, Darongsae Kwon</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19267">https://arxiv.org/abs/2402.19267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19267">https://arxiv.org/pdf/2402.19267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19267]] Robust Guidance for Unsupervised Data Selection: Capturing Perplexing  Named Entities for Domain-Specific Machine Translation(https://arxiv.org/abs/2402.19267)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Employing extensive datasets enables the training of multilingual machine translation models; however, these models often fail to accurately translate sentences within specialized domains. Although obtaining and translating domain-specific data incurs high costs, it is inevitable for high-quality translations. Hence, finding the most 'effective' data with an unsupervised setting becomes a practical strategy for reducing labeling costs. Recent research indicates that this effective data could be found by selecting 'properly difficult data' based on its volume. This means the data should not be excessively challenging or overly simplistic, especially if the amount of data is limited. However, we found that establishing a criterion for unsupervised data selection remains challenging, as the 'proper difficulty' might vary based on the data domain being trained on. We introduce a novel unsupervised data selection method, 'Capturing Perplexing Named Entities', which adopts the maximum inference entropy in translated named entities as a selection measure. The motivation was that named entities in domain-specific data are considered the most complex portion of the data and should be predicted with high confidence. When verified with the 'Korean-English Parallel Corpus of Specialized Domains,' our method served as a robust guidance for unsupervised data selection, in contrast to existing methods.</li>
</ul>

<h3>Title: PlanGPT: Enhancing Urban Planning with Tailored Language Model and  Efficient Retrieval</h3>
<ul>
<li><strong>Authors: </strong>He Zhu, Wenjia Zhang, Nuoxian Huang, Boyang Li, Luyao Niu, Zipei Fan, Tianle Lun, Yicheng Tao, Junyou Su, Zhaoya Gong, Chenyu Fang, Xing Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19273">https://arxiv.org/abs/2402.19273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19273">https://arxiv.org/pdf/2402.19273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19273]] PlanGPT: Enhancing Urban Planning with Tailored Language Model and  Efficient Retrieval(https://arxiv.org/abs/2402.19273)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the field of urban planning, general-purpose large language models often struggle to meet the specific needs of planners. Tasks like generating urban planning texts, retrieving related information, and evaluating planning documents pose unique challenges. To enhance the efficiency of urban professionals and overcome these obstacles, we introduce PlanGPT, the first specialized Large Language Model tailored for urban and spatial planning. Developed through collaborative efforts with institutions like the Chinese Academy of Urban Planning, PlanGPT leverages a customized local database retrieval framework, domain-specific fine-tuning of base models, and advanced tooling capabilities. Empirical tests demonstrate that PlanGPT has achieved advanced performance, delivering responses of superior quality precisely tailored to the intricacies of urban planning.</li>
</ul>

<h3>Title: WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset</h3>
<ul>
<li><strong>Authors: </strong>Jiantao Qiu, Haijun Lv, Zhenjiang Jin, Rui Wang, Wenchang Ning, Jia Yu, ChaoBin Zhang, Pei Chu, Yuan Qu, Runyu Peng, Zhiyuan Zeng, Huanze Tang, Ruiliang Xu, Wei Li, Hang Yan, Conghui He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19282">https://arxiv.org/abs/2402.19282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19282">https://arxiv.org/pdf/2402.19282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19282]] WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset(https://arxiv.org/abs/2402.19282)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper presents WanJuan-CC, a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data. The study addresses the challenges of constructing large-scale pre-training datasets for language models, which require vast amounts of high-quality data. A comprehensive process was designed to handle Common Crawl data, including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering. From approximately 68 billion original English documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of high-quality data as part of WanJuan-CC. We have open-sourced 300B Tokens from this dataset. The paper also provides statistical information related to data quality, enabling users to select appropriate data according to their needs. To evaluate the quality and utility of the dataset, we trained 1B-parameter and 3B-parameter models using WanJuan-CC and another dataset, RefinedWeb. Results show that WanJuan-CC performs better on validation datasets and downstream tasks.</li>
</ul>

<h3>Title: StiefelGen: A Simple, Model Agnostic Approach for Time Series Data  Augmentation over Riemannian Manifolds</h3>
<ul>
<li><strong>Authors: </strong>Prasad Cheema, Mahito Sugiyama</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19287">https://arxiv.org/abs/2402.19287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19287">https://arxiv.org/pdf/2402.19287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19287]] StiefelGen: A Simple, Model Agnostic Approach for Time Series Data  Augmentation over Riemannian Manifolds(https://arxiv.org/abs/2402.19287)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Data augmentation is an area of research which has seen active development in many machine learning fields, such as in image-based learning models, reinforcement learning for self driving vehicles, and general noise injection for point cloud data. However, convincing methods for general time series data augmentation still leaves much to be desired, especially since the methods developed for these models do not readily cross-over. Three common approaches for time series data augmentation include: (i) Constructing a physics-based model and then imbuing uncertainty over the coefficient space (for example), (ii) Adding noise to the observed data set(s), and, (iii) Having access to ample amounts of time series data sets from which a robust generative neural network model can be trained. However, for many practical problems that work with time series data in the industry: (i) One usually does not have access to a robust physical model, (ii) The addition of noise can in of itself require large or difficult assumptions (for example, what probability distribution should be used? Or, how large should the noise variance be?), and, (iii) In practice, it can be difficult to source a large representative time series data base with which to train the neural network model for the underlying problem. In this paper, we propose a methodology which attempts to simultaneously tackle all three of these previous limitations to a large extent. The method relies upon the well-studied matrix differential geometry of the Stiefel manifold, as it proposes a simple way in which time series signals can placed on, and then smoothly perturbed over the manifold. We attempt to clarify how this method works by showcasing several potential use cases which in particular work to take advantage of the unique properties of this underlying manifold.</li>
</ul>

<h3>Title: Suppress and Rebalance: Towards Generalized Multi-Modal Face  Anti-Spoofing</h3>
<ul>
<li><strong>Authors: </strong>Xun Lin, Shuai Wang, Rizhao Cai, Yizhong Liu, Ying Fu, Zitong Yu, Wenzhong Tang, Alex Kot</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19298">https://arxiv.org/abs/2402.19298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19298">https://arxiv.org/pdf/2402.19298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19298]] Suppress and Rebalance: Towards Generalized Multi-Modal Face  Anti-Spoofing(https://arxiv.org/abs/2402.19298)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Face Anti-Spoofing (FAS) is crucial for securing face recognition systems against presentation attacks. With advancements in sensor manufacture and multi-modal learning techniques, many multi-modal FAS approaches have emerged. However, they face challenges in generalizing to unseen attacks and deployment conditions. These challenges arise from (1) modality unreliability, where some modality sensors like depth and infrared undergo significant domain shifts in varying environments, leading to the spread of unreliable information during cross-modal feature fusion, and (2) modality imbalance, where training overly relies on a dominant modality hinders the convergence of others, reducing effectiveness against attack types that are indistinguishable sorely using the dominant modality. To address modality unreliability, we propose the Uncertainty-Guided Cross-Adapter (U-Adapter) to recognize unreliably detected regions within each modality and suppress the impact of unreliable regions on other modalities. For modality imbalance, we propose a Rebalanced Modality Gradient Modulation (ReGrad) strategy to rebalance the convergence speed of all modalities by adaptively adjusting their gradients. Besides, we provide the first large-scale benchmark for evaluating multi-modal FAS performance under domain generalization scenarios. Extensive experiments demonstrate that our method outperforms state-of-the-art methods. Source code and protocols will be released on https://github.com/OMGGGGG/mmdg.</li>
</ul>

<h3>Title: DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly</h3>
<ul>
<li><strong>Authors: </strong>Gianluca Scarpellini, Stefano Fiorini, Francesco Giuliari, Pietro Morerio, Alessio Del Bue</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19302">https://arxiv.org/abs/2402.19302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19302">https://arxiv.org/pdf/2402.19302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19302]] DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly(https://arxiv.org/abs/2402.19302)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph. Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at https://github.com/IIT-PAVIS/DiffAssemble</li>
</ul>

<h3>Title: Learnability Gaps of Strategic Classification</h3>
<ul>
<li><strong>Authors: </strong>Lee Cohen, Yishay Mansour, Shay Moran, Han Shao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19303">https://arxiv.org/abs/2402.19303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19303">https://arxiv.org/pdf/2402.19303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19303]] Learnability Gaps of Strategic Classification(https://arxiv.org/abs/2402.19303)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In contrast with standard classification tasks, strategic classification involves agents strategically modifying their features in an effort to receive favorable predictions. For instance, given a classifier determining loan approval based on credit scores, applicants may open or close their credit cards to fool the classifier. The learning goal is to find a classifier robust against strategic manipulations. Various settings, based on what and when information is known, have been explored in strategic classification. In this work, we focus on addressing a fundamental question: the learnability gaps between strategic classification and standard learning. We essentially show that any learnable class is also strategically learnable: we first consider a fully informative setting, where the manipulation structure (which is modeled by a manipulation graph $G^\star$) is known and during training time the learner has access to both the pre-manipulation data and post-manipulation data. We provide nearly tight sample complexity and regret bounds, offering significant improvements over prior results. Then, we relax the fully informative setting by introducing two natural types of uncertainty. First, following Ahmadi et al. (2023), we consider the setting in which the learner only has access to the post-manipulation data. We improve the results of Ahmadi et al. (2023) and close the gap between mistake upper bound and lower bound raised by them. Our second relaxation of the fully informative setting introduces uncertainty to the manipulation structure. That is, we assume that the manipulation graph is unknown but belongs to a known class of graphs. We provide nearly tight bounds on the learning complexity in various unknown manipulation graph settings. Notably, our algorithm in this setting is of independent interest and can be applied to other problems such as multi-label learning.</li>
</ul>

<h3>Title: Loss-Free Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Jack Foster, Stefan Schoepf, Alexandra Brintrup</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19308">https://arxiv.org/abs/2402.19308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19308">https://arxiv.org/pdf/2402.19308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19308]] Loss-Free Machine Unlearning(https://arxiv.org/abs/2402.19308)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a machine unlearning approach that is both retraining- and label-free. Most existing machine unlearning approaches require a model to be fine-tuned to remove information while preserving performance. This is computationally expensive and necessitates the storage of the whole dataset for the lifetime of the model. Retraining-free approaches often utilise Fisher information, which is derived from the loss and requires labelled data which may not be available. Thus, we present an extension to the Selective Synaptic Dampening algorithm, substituting the diagonal of the Fisher information matrix for the gradient of the l2 norm of the model output to approximate sensitivity. We evaluate our method in a range of experiments using ResNet18 and Vision Transformer. Results show our label-free method is competitive with existing state-of-the-art approaches.</li>
</ul>

<h3>Title: Attacks Against Mobility Prediction in 5G Networks</h3>
<ul>
<li><strong>Authors: </strong>Syafiq Al Atiiq, Yachao Yuan, Christian Gehrmann, Jakob Sternby, Luis Barriga</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19319">https://arxiv.org/abs/2402.19319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19319">https://arxiv.org/pdf/2402.19319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19319]] Attacks Against Mobility Prediction in 5G Networks(https://arxiv.org/abs/2402.19319)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>The $5^{th}$ generation of mobile networks introduces a new Network Function (NF) that was not present in previous generations, namely the Network Data Analytics Function (NWDAF). Its primary objective is to provide advanced analytics services to various entities within the network and also towards external application services in the 5G ecosystem. One of the key use cases of NWDAF is mobility trajectory prediction, which aims to accurately support efficient mobility management of User Equipment (UE) in the network by allocating ``just in time'' necessary network resources. In this paper, we show that there are potential mobility attacks that can compromise the accuracy of these predictions. In a semi-realistic scenario with 10,000 subscribers, we demonstrate that an adversary equipped with the ability to hijack cellular mobile devices and clone them can significantly reduce the prediction accuracy from 75\% to 40\% using just 100 adversarial UEs. While a defense mechanism largely depends on the attack and the mobility types in a particular area, we prove that a basic KMeans clustering is effective in distinguishing legitimate and adversarial UEs.</li>
</ul>

<h3>Title: Verification of Neural Networks' Global Robustness</h3>
<ul>
<li><strong>Authors: </strong>Anan Kabaha, Dana Drachsler-Cohen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19322">https://arxiv.org/abs/2402.19322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19322">https://arxiv.org/pdf/2402.19322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19322]] Verification of Neural Networks' Global Robustness(https://arxiv.org/abs/2402.19322)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Neural networks are successful in various applications but are also susceptible to adversarial attacks. To show the safety of network classifiers, many verifiers have been introduced to reason about the local robustness of a given input to a given perturbation. While successful, local robustness cannot generalize to unseen inputs. Several works analyze global robustness properties, however, neither can provide a precise guarantee about the cases where a network classifier does not change its classification. In this work, we propose a new global robustness property for classifiers aiming at finding the minimal globally robust bound, which naturally extends the popular local robustness property for classifiers. We introduce VHAGaR, an anytime verifier for computing this bound. VHAGaR relies on three main ideas: encoding the problem as a mixed-integer programming and pruning the search space by identifying dependencies stemming from the perturbation or network computation and generalizing adversarial attacks to unknown inputs. We evaluate VHAGaR on several datasets and classifiers and show that, given a three hour timeout, the average gap between the lower and upper bound on the minimal globally robust bound computed by VHAGaR is 1.9, while the gap of an existing global robustness verifier is 154.7. Moreover, VHAGaR is 130.6x faster than this verifier. Our results further indicate that leveraging dependencies and adversarial attacks makes VHAGaR 78.6x faster.</li>
</ul>

<h3>Title: Generalizable Whole Slide Image Classification with Fine-Grained  Visual-Semantic Interaction</h3>
<ul>
<li><strong>Authors: </strong>Hao Li, Ying Chen, Yifei Chen, Wenxian Yang, Bowen Ding, Yuchen Han, Liansheng Wang, Rongshan Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19326">https://arxiv.org/abs/2402.19326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19326">https://arxiv.org/pdf/2402.19326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19326]] Generalizable Whole Slide Image Classification with Fine-Grained  Visual-Semantic Interaction(https://arxiv.org/abs/2402.19326)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Whole Slide Image (WSI) classification is often formulated as a Multiple Instance Learning (MIL) problem. Recently, Vision-Language Models (VLMs) have demonstrated remarkable performance in WSI classification. However, existing methods leverage coarse-grained pathogenetic descriptions for visual representation supervision, which are insufficient to capture the complex visual appearance of pathogenetic images, hindering the generalizability of models on diverse downstream tasks. Additionally, processing high-resolution WSIs can be computationally expensive. In this paper, we propose a novel "Fine-grained Visual-Semantic Interaction" (FiVE) framework for WSI classification. It is designed to enhance the model's generalizability by leveraging the interplay between localized visual patterns and fine-grained pathological semantics. Specifically, with meticulously designed queries, we start by utilizing a large language model to extract fine-grained pathological descriptions from various non-standardized raw reports. The output descriptions are then reconstructed into fine-grained labels used for training. By introducing a Task-specific Fine-grained Semantics (TFS) module, we enable prompts to capture crucial visual information in WSIs, which enhances representation learning and augments generalization capabilities significantly. Furthermore, given that pathological visual patterns are redundantly distributed across tissue slices, we sample a subset of visual instances during training. Our method demonstrates robust generalizability and strong transferability, dominantly outperforming the counterparts on the TCGA Lung Cancer dataset with at least 9.19% higher accuracy in few-shot experiments.</li>
</ul>

<h3>Title: A Novel Approach to Industrial Defect Generation through Blended Latent  Diffusion Model with Online Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Hanxi Li, Zhengxun Zhang, Hao Chen, Lin Wu, Bo Li, Deyin Liu, Mingwen Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19330">https://arxiv.org/abs/2402.19330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19330">https://arxiv.org/pdf/2402.19330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19330]] A Novel Approach to Industrial Defect Generation through Blended Latent  Diffusion Model with Online Adaptation(https://arxiv.org/abs/2402.19330)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Effectively addressing the challenge of industrial Anomaly Detection (AD) necessitates an ample supply of defective samples, a constraint often hindered by their scarcity in industrial contexts. This paper introduces a novel algorithm designed to augment defective samples, thereby enhancing AD performance. The proposed method tailors the blended latent diffusion model for defect sample generation, employing a diffusion model to generate defective samples in the latent space. A feature editing process, controlled by a "trimap" mask and text prompts, refines the generated samples. The image generation inference process is structured into three stages: a free diffusion stage, an editing diffusion stage, and an online decoder adaptation stage. This sophisticated inference strategy yields high-quality synthetic defective samples with diverse pattern variations, leading to significantly improved AD accuracies based on the augmented training set. Specifically, on the widely recognized MVTec AD dataset, the proposed method elevates the state-of-the-art (SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD metrics AP, IAP, and IAP90, respectively. The implementation code of this work can be found at the GitHub repository https://github.com/GrandpaXun242/AdaBLDM.git</li>
</ul>

<h3>Title: Compact Speech Translation Models via Discrete Speech Units Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Tsz Kin Lam, Alexandra Birch, Barry Haddow</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19333">https://arxiv.org/abs/2402.19333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19333">https://arxiv.org/pdf/2402.19333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19333]] Compact Speech Translation Models via Discrete Speech Units Pretraining(https://arxiv.org/abs/2402.19333)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Using Self-Supervised Learning (SSL) as model initialization is now common to obtain strong results in Speech Translation (ST). However, they also impose a large memory footprint, hindering on-device deployment. In this paper, we leverage the SSL models by pretraining smaller models on their Discrete Speech Units (DSU). We pretrain encoder-decoder models on 1) Filterbank-to-DSU and 2) DSU-to-Translation data, and take the encoder from 1) and the decoder from 2) to initialise a new model, finetuning this on limited speech-translation data. The final model becomes compact by using the DSU pretraining to distil the knowledge of the SSL model. Our method has several benefits over using DSU as model inputs, such as shorter inference pipeline and robustness over (DSU) tokenization. In contrast to ASR pretraining, it does not require transcripts, making it applicable to low-resource settings. Evaluation on CoVoST-2 X-En shows that our method is >$0.5$ BLEU better than a ST model that directly finetune the SSL model, given only half the model size, and on a par with ASR pretraining.</li>
</ul>

<h3>Title: Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge</h3>
<ul>
<li><strong>Authors: </strong>Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19334">https://arxiv.org/abs/2402.19334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19334">https://arxiv.org/pdf/2402.19334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19334]] Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge(https://arxiv.org/abs/2402.19334)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack</a></li>
<li><strong>Abstract: </strong>The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure. In our experiments, we explore various models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge. Our approach consistently outperforms the other advanced baselines, leading to an average of 75% reduction in the attack success rate. Since model merging has been an established approach for improving model performance, the extra advantage it provides regarding defense can be seen as a cost-free bonus.</li>
</ul>

<h3>Title: Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision  Transformers for High-Level Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Delfina Sol Martinez Pandiani, Nicolas Lazzari, Valentina Presutti</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19339">https://arxiv.org/abs/2402.19339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19339">https://arxiv.org/pdf/2402.19339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19339]] Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision  Transformers for High-Level Image Classification(https://arxiv.org/abs/2402.19339)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>The increasing demand for automatic high-level image understanding, particularly in detecting abstract concepts (AC) within images, underscores the necessity for innovative and more interpretable approaches. These approaches need to harmonize traditional deep vision methods with the nuanced, context-dependent knowledge humans employ to interpret images at intricate semantic levels. In this work, we leverage situated perceptual knowledge of cultural images to enhance performance and interpretability in AC image classification. We automatically extract perceptual semantic units from images, which we then model and integrate into the ARTstract Knowledge Graph (AKG). This resource captures situated perceptual semantics gleaned from over 14,000 cultural images labeled with ACs. Additionally, we enhance the AKG with high-level linguistic frames. We compute KG embeddings and experiment with relative representations and hybrid approaches that fuse these embeddings with visual transformer embeddings. Finally, for interpretability, we conduct posthoc qualitative analyses by examining model similarities with training instances. Our results show that our hybrid KGE-ViT methods outperform existing techniques in AC image classification. The posthoc interpretability analyses reveal the visual transformer's proficiency in capturing pixel-level visual attributes, contrasting with our method's efficacy in representing more abstract and semantic scene elements. We demonstrate the synergy and complementarity between KGE embeddings' situated perceptual knowledge and deep visual model's sensory-perceptual understanding for AC image classification. This work suggests a strong potential of neuro-symbolic methods for knowledge integration and robust image representation for use in downstream intricate visual comprehension tasks. All the materials and code are available online.</li>
</ul>

<h3>Title: One model to use them all: Training a segmentation model with  complementary datasets</h3>
<ul>
<li><strong>Authors: </strong>Alexander C. Jenke, Sebastian Bodenstedt, Fiona R. Kolbinger, Marius Distler, Jürgen Weitz, Stefanie Speidel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19340">https://arxiv.org/abs/2402.19340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19340">https://arxiv.org/pdf/2402.19340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19340]] One model to use them all: Training a segmentation model with  complementary datasets(https://arxiv.org/abs/2402.19340)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Understanding a surgical scene is crucial for computer-assisted surgery systems to provide any intelligent assistance functionality. One way of achieving this scene understanding is via scene segmentation, where every pixel of a frame is classified and therefore identifies the visible structures and tissues. Progress on fully segmenting surgical scenes has been made using machine learning. However, such models require large amounts of annotated training data, containing examples of all relevant object classes. Such fully annotated datasets are hard to create, as every pixel in a frame needs to be annotated by medical experts and, therefore, are rarely available. In this work, we propose a method to combine multiple partially annotated datasets, which provide complementary annotations, into one model, enabling better scene segmentation and the use of multiple readily available datasets. Our method aims to combine available data with complementary labels by leveraging mutual exclusive properties to maximize information. Specifically, we propose to use positive annotations of other classes as negative samples and to exclude background pixels of binary annotations, as we cannot tell if they contain a class not annotated but predicted by the model. We evaluate our method by training a DeepLabV3 on the publicly available Dresden Surgical Anatomy Dataset, which provides multiple subsets of binary segmented anatomical structures. Our approach successfully combines 6 classes into one model, increasing the overall Dice Score by 4.4% compared to an ensemble of models trained on the classes individually. By including information on multiple classes, we were able to reduce confusion between stomach and colon by 24%. Our results demonstrate the feasibility of training a model on multiple datasets. This paves the way for future work further alleviating the need for one large, fully segmented datasets.</li>
</ul>

<h3>Title: Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy,  Advances, and Outlook</h3>
<ul>
<li><strong>Authors: </strong>Xingchen Zou, Yibo Yan, Xixuan Hao, Yuehong Hu, Haomin Wen, Erdong Liu, Junbo Zhang, Yong Li, Tianrui Li, Yu Zheng, Yuxuan Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19348">https://arxiv.org/abs/2402.19348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19348">https://arxiv.org/pdf/2402.19348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19348]] Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy,  Advances, and Outlook(https://arxiv.org/abs/2402.19348)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.</li>
</ul>

<h3>Title: Watermark Stealing in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nikola Jovanović, Robin Staab, Martin Vechev</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19361">https://arxiv.org/abs/2402.19361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19361">https://arxiv.org/pdf/2402.19361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19361]] Watermark Stealing in Large Language Models(https://arxiv.org/abs/2402.19361)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal, watermark, large language model</a></li>
<li><strong>Abstract: </strong>LLM watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment. In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes. We show that querying the API of the watermarked LLM to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed. We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings. We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%. Our findings challenge common beliefs about LLM watermarking, stressing the need for more robust schemes. We make all our code and additional examples available at https://watermark-stealing.org.</li>
</ul>

<h3>Title: SoK: Exploring the Potential of Large Language Models for Improving  Digital Forensic Investigation Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Akila Wickramasekara, Frank Breitinger, Mark Scanlon</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19366">https://arxiv.org/abs/2402.19366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19366">https://arxiv.org/pdf/2402.19366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19366]] SoK: Exploring the Potential of Large Language Models for Improving  Digital Forensic Investigation Efficiency(https://arxiv.org/abs/2402.19366)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs. In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement entities.</li>
</ul>

<h3>Title: Structure Preserving Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Haoye Lu, Spencer Szabados, Yaoliang Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19369">https://arxiv.org/abs/2402.19369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19369">https://arxiv.org/pdf/2402.19369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19369]] Structure Preserving Diffusion Models(https://arxiv.org/abs/2402.19369)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have become the leading distribution-learning method in recent years. Herein, we introduce structure-preserving diffusion processes, a family of diffusion processes for learning distributions that possess additional structure, such as group symmetries, by developing theoretical conditions under which the diffusion transition steps preserve said symmetry. While also enabling equivariant data sampling trajectories, we exemplify these results by developing a collection of different symmetry equivariant diffusion models capable of learning distributions that are inherently symmetric. Empirical studies, over both synthetic and real-world datasets, are used to validate the developed models adhere to the proposed theory and are capable of achieving improved performance over existing methods in terms of sample equality. We also show how the proposed models can be used to achieve theoretically guaranteed equivariant image noise reduction without prior knowledge of the image orientation.</li>
</ul>

<h3>Title: OpenMedLM: Prompt engineering can out-perform fine-tuning in medical  question-answering with open-source large language models</h3>
<ul>
<li><strong>Authors: </strong>Jenish Maharjan, Anurag Garikipati, Navan Preet Singh, Leo Cyrus, Mayank Sharma, Madalina Ciobanu, Gina Barnes, Rahul Thapa, Qingqing Mao, Ritankar Das</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19371">https://arxiv.org/abs/2402.19371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19371">https://arxiv.org/pdf/2402.19371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19371]] OpenMedLM: Prompt engineering can out-perform fine-tuning in medical  question-answering with open-source large language models(https://arxiv.org/abs/2402.19371)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LLMs have become increasingly capable at accomplishing a range of specialized-tasks and can be utilized to expand equitable access to medical knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging specialized medical data and significant, thus costly, amounts of computational power. Many of the top performing LLMs are proprietary and their access is limited to very few research groups. However, open-source (OS) models represent a key area of growth for medical LLMs due to significant improvements in performance and an inherent ability to provide the transparency and compliance required in healthcare. We present OpenMedLM, a prompting platform which delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks. We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks (MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of prompting strategies, including zero-shot, few-shot, chain-of-thought (random selection and kNN selection), and ensemble/self-consistency voting. We found that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks, surpassing the previous best performing OS models that leveraged computationally costly extensive fine-tuning. The model delivers a 72.6% accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the first OS LLM to surpass 80% accuracy on this benchmark. Our results highlight medical-specific emergent properties in OS LLMs which have not yet been documented to date elsewhere, and showcase the benefits of further leveraging prompt engineering to improve the performance of accessible LLMs for medical applications.</li>
</ul>

<h3>Title: Assessing Visually-Continuous Corruption Robustness of Neural Networks  Relative to Human Performance</h3>
<ul>
<li><strong>Authors: </strong>Huakun Shen, Boyue Caroline Hu, Krzysztof Czarnecki, Lina Marsso, Marsha Chechik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19401">https://arxiv.org/abs/2402.19401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19401">https://arxiv.org/pdf/2402.19401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19401]] Assessing Visually-Continuous Corruption Robustness of Neural Networks  Relative to Human Performance(https://arxiv.org/abs/2402.19401)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>While Neural Networks (NNs) have surpassed human accuracy in image classification on ImageNet, they often lack robustness against image corruption, i.e., corruption robustness. Yet such robustness is seemingly effortless for human perception. In this paper, we propose visually-continuous corruption robustness (VCR) -- an extension of corruption robustness to allow assessing it over the wide and continuous range of changes that correspond to the human perceptive quality (i.e., from the original image to the full distortion of all perceived visual information), along with two novel human-aware metrics for NN evaluation. To compare VCR of NNs with human perception, we conducted extensive experiments on 14 commonly used image corruptions with 7,718 human participants and state-of-the-art robust NN models with different training objectives (e.g., standard, adversarial, corruption robustness), different architectures (e.g., convolution NNs, vision transformers), and different amounts of training data augmentation. Our study showed that: 1) assessing robustness against continuous corruption can reveal insufficient robustness undetected by existing benchmarks; as a result, 2) the gap between NN and human robustness is larger than previously known; and finally, 3) some image corruptions have a similar impact on human perception, offering opportunities for more cost-effective robustness assessments. Our validation set with 14 image corruptions, human robustness data, and the evaluation code is provided as a toolbox and a benchmark.</li>
</ul>

<h3>Title: Entity-Aware Multimodal Alignment Framework for News Image Captioning</h3>
<ul>
<li><strong>Authors: </strong>Junzhe Zhang, Huixuan Zhang, Xiaojun Wan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19404">https://arxiv.org/abs/2402.19404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19404">https://arxiv.org/pdf/2402.19404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19404]] Entity-Aware Multimodal Alignment Framework for News Image Captioning(https://arxiv.org/abs/2402.19404)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>News image captioning task is a variant of image captioning task which requires model to generate a more informative caption with news image and the associated news article. Multimodal Large Language models have developed rapidly in recent years and is promising in news image captioning task. However, according to our experiments, common MLLMs are not good at generating the entities in zero-shot setting. Their abilities to deal with the entities information are still limited after simply fine-tuned on news image captioning dataset. To obtain a more powerful model to handle the multimodal entity information, we design two multimodal entity-aware alignment tasks and an alignment framework to align the model and generate the news image captions. Our method achieves better results than previous state-of-the-art models in CIDEr score (72.33 -> 86.29) on GoodNews dataset and (70.83 -> 85.61) on NYTimes800k dataset.</li>
</ul>

<h3>Title: On the Scaling Laws of Geographical Representation in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nathan Godey, Éric de la Clergerie, Benoît Sagot</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19406">https://arxiv.org/abs/2402.19406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19406">https://arxiv.org/pdf/2402.19406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19406]] On the Scaling Laws of Geographical Representation in Language Models(https://arxiv.org/abs/2402.19406)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.</li>
</ul>

<h3>Title: PEM: Prototype-based Efficient MaskFormer for Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Niccolò Cavagnero, Gabriele Rosi, Claudia Ruttano, Francesca Pistilli, Marco Ciccone, Giuseppe Averta, Fabio Cermelli</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19422">https://arxiv.org/abs/2402.19422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19422">https://arxiv.org/pdf/2402.19422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19422]] PEM: Prototype-based Efficient MaskFormer for Image Segmentation(https://arxiv.org/abs/2402.19422)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Recent transformer-based architectures have shown impressive results in the field of image segmentation. Thanks to their flexibility, they obtain outstanding performance in multiple segmentation tasks, such as semantic and panoptic, under a single unified framework. To achieve such impressive performance, these architectures employ intensive operations and require substantial computational resources, which are often not available, especially on edge devices. To fill this gap, we propose Prototype-based Efficient MaskFormer (PEM), an efficient transformer-based architecture that can operate in multiple segmentation tasks. PEM proposes a novel prototype-based cross-attention which leverages the redundancy of visual features to restrict the computation and improve the efficiency without harming the performance. In addition, PEM introduces an efficient multi-scale feature pyramid network, capable of extracting features that have high semantic content in an efficient way, thanks to the combination of deformable convolutions and context-based self-modulation. We benchmark the proposed PEM architecture on two tasks, semantic and panoptic segmentation, evaluated on two different datasets, Cityscapes and ADE20K. PEM demonstrates outstanding performance on every task and dataset, outperforming task-specific architectures while being comparable and even better than computationally-expensive baselines.</li>
</ul>

<h3>Title: Leveraging AI Predicted and Expert Revised Annotations in Interactive  Segmentation: Continual Tuning or Full Training?</h3>
<ul>
<li><strong>Authors: </strong>Tiezheng Zhang, Xiaoxi Chen, Chongyu Qu, Alan Yuille, Zongwei Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19423">https://arxiv.org/abs/2402.19423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19423">https://arxiv.org/pdf/2402.19423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19423]] Leveraging AI Predicted and Expert Revised Annotations in Interactive  Segmentation: Continual Tuning or Full Training?(https://arxiv.org/abs/2402.19423)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Interactive segmentation, an integration of AI algorithms and human expertise, premises to improve the accuracy and efficiency of curating large-scale, detailed-annotated datasets in healthcare. Human experts revise the annotations predicted by AI, and in turn, AI improves its predictions by learning from these revised annotations. This interactive process continues to enhance the quality of annotations until no major revision is needed from experts. The key challenge is how to leverage AI predicted and expert revised annotations to iteratively improve the AI. Two problems arise: (1) The risk of catastrophic forgetting--the AI tends to forget the previously learned classes if it is only retrained using the expert revised classes. (2) Computational inefficiency when retraining the AI using both AI predicted and expert revised annotations; moreover, given the dominant AI predicted annotations in the dataset, the contribution of newly revised annotations--often account for a very small fraction--to the AI training remains marginal. This paper proposes Continual Tuning to address the problems from two perspectives: network design and data reuse. Firstly, we design a shared network for all classes followed by class-specific networks dedicated to individual classes. To mitigate forgetting, we freeze the shared network for previously learned classes and only update the class-specific network for revised classes. Secondly, we reuse a small fraction of data with previous annotations to avoid over-computing. The selection of such data relies on the importance estimate of each data. The importance score is computed by combining the uncertainty and consistency of AI predictions. Our experiments demonstrate that Continual Tuning achieves a speed 16x greater than repeatedly training AI from scratch without compromising the performance.</li>
</ul>

<h3>Title: Griffin: Mixing Gated Linear Recurrences with Local Attention for  Efficient Language Models</h3>
<ul>
<li><strong>Authors: </strong>Soham De, Samuel L. Smith, Anushan Fernando, Aleksandar Botev, George Cristian-Muraru, Albert Gu, Ruba Haroun, Leonard Berrada, Yutian Chen, Srivatsan Srinivasan, Guillaume Desjardins, Arnaud Doucet, David Budden, Yee Whye Teh, Razvan Pascanu, Nando De Freitas, Caglar Gulcehre</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19427">https://arxiv.org/abs/2402.19427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19427">https://arxiv.org/pdf/2402.19427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19427]] Griffin: Mixing Gated Linear Recurrences with Local Attention for  Efficient Language Models(https://arxiv.org/abs/2402.19427)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated linear recurrences with local attention. Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of Llama-2 despite being trained on over 6 times fewer tokens. We also show that Griffin can extrapolate on sequences significantly longer than those seen during training. Our models match the hardware efficiency of Transformers during training, and during inference they have lower latency and significantly higher throughput. We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training.</li>
</ul>

<h3>Title: Differentially Private Worst-group Risk Minimization</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Zhou, Raef Bassily</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19437">https://arxiv.org/abs/2402.19437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19437">https://arxiv.org/pdf/2402.19437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19437]] Differentially Private Worst-group Risk Minimization(https://arxiv.org/abs/2402.19437)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We initiate a systematic study of worst-group risk minimization under $(\epsilon, \delta)$-differential privacy (DP). The goal is to privately find a model that approximately minimizes the maximal risk across $p$ sub-populations (groups) with different distributions, where each group distribution is accessed via a sample oracle. We first present a new algorithm that achieves excess worst-group population risk of $\tilde{O}(\frac{p\sqrt{d}}{K\epsilon} + \sqrt{\frac{p}{K}})$, where $K$ is the total number of samples drawn from all groups and $d$ is the problem dimension. Our rate is nearly optimal when each distribution is observed via a fixed-size dataset of size $K/p$. Our result is based on a new stability-based analysis for the generalization error. In particular, we show that $\Delta$-uniform argument stability implies $\tilde{O}(\Delta + \frac{1}{\sqrt{n}})$ generalization error w.r.t. the worst-group risk, where $n$ is the number of samples drawn from each sample oracle. Next, we propose an algorithmic framework for worst-group population risk minimization using any DP online convex optimization algorithm as a subroutine. Hence, we give another excess risk bound of $\tilde{O}\left( \sqrt{\frac{d^{1/2}}{\epsilon K}} +\sqrt{\frac{p}{K\epsilon^2}} \right)$. Assuming the typical setting of $\epsilon=\Theta(1)$, this bound is more favorable than our first bound in a certain range of $p$ as a function of $K$ and $d$. Finally, we study differentially private worst-group empirical risk minimization in the offline setting, where each group distribution is observed by a fixed-size dataset. We present a new algorithm with nearly optimal excess risk of $\tilde{O}(\frac{p\sqrt{d}}{K\epsilon})$.</li>
</ul>

<h3>Title: ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL</h3>
<ul>
<li><strong>Authors: </strong>Yifei Zhou, Andrea Zanette, Jiayi Pan, Sergey Levine, Aviral Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19446">https://arxiv.org/abs/2402.19446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19446">https://arxiv.org/pdf/2402.19446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19446]] ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL(https://arxiv.org/abs/2402.19446)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or "agent" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively. To do this, our framework adopts a hierarchical RL approach and runs two RL algorithms in parallel: a high-level off-policy value-based RL algorithm to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level value function to train a token policy within each utterance or turn. Our hierarchical framework, Actor-Critic Framework with a Hierarchical Structure (ArCHer), can also give rise to other RL methods. Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).</li>
</ul>

<h3>Title: Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent  on Language Models</h3>
<ul>
<li><strong>Authors: </strong>Frederik Kunstner, Robin Yadav, Alan Milligan, Mark Schmidt, Alberto Bietti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19449">https://arxiv.org/abs/2402.19449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19449">https://arxiv.org/pdf/2402.19449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19449]] Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent  on Language Models(https://arxiv.org/abs/2402.19449)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models. We further study this phenomenon on a linear classification with cross-entropy loss, showing that heavy-tailed class imbalance leads to ill-conditioning, and that the normalization used by Adam can counteract it.</li>
</ul>

<h3>Title: Curiosity-driven Red-teaming for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhang-Wei Hong, Idan Shenfeld, Tsun-Hsuan Wang, Yung-Sung Chuang, Aldo Pareja, James Glass, Akash Srivastava, Pulkit Agrawal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19464">https://arxiv.org/abs/2402.19464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19464">https://arxiv.org/pdf/2402.19464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19464]] Curiosity-driven Red-teaming for Large Language Models(https://arxiv.org/abs/2402.19464)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an LLM generates unwanted content, the current paradigm is to recruit a \textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs. However, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM. However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM. To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty. Our method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods. Our method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily fine-tuned using human preferences to avoid toxic outputs. Code is available at \url{https://github.com/Improbable-AI/curiosity_redteam}</li>
</ul>

<h3>Title: Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period  of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chen Qian, Jie Zhang, Wei Yao, Dongrui Liu, Zhenfei Yin, Yu Qiao, Yong Liu, Jing Shao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19465">https://arxiv.org/abs/2402.19465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19465">https://arxiv.org/pdf/2402.19465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19465]] Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period  of Large Language Models(https://arxiv.org/abs/2402.19465)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to investigate the dynamics of trustworthiness during pre-training. We are the first to observe a similar two-phase phenomenon: fitting and compression~\citep{shwartz2017opening}. This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field. We will make our code publicly accessible at \url{https://github.com/ChnQ/TracingLLM}.</li>
</ul>

<h3>Title: Loose LIPS Sink Ships: Asking Questions in Battleship with  Language-Informed Program Sampling</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Grand, Valerio Pepe, Jacob Andreas, Joshua B. Tenenbaum</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19471">https://arxiv.org/abs/2402.19471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19471">https://arxiv.org/pdf/2402.19471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19471]] Loose LIPS Sink Ships: Asking Questions in Battleship with  Language-Informed Program Sampling(https://arxiv.org/abs/2402.19471)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Questions combine our mastery of language with our remarkable facility for reasoning about uncertainty. How do people navigate vast hypothesis spaces to pose informative questions given limited cognitive resources? We study these tradeoffs in a classic grounded question-asking task based on the board game Battleship. Our language-informed program sampling (LIPS) model uses large language models (LLMs) to generate natural language questions, translate them into symbolic programs, and evaluate their expected information gain. We find that with a surprisingly modest resource budget, this simple Monte Carlo optimization strategy yields informative questions that mirror human performance across varied Battleship board scenarios. In contrast, LLM-only baselines struggle to ground questions in the board state; notably, GPT-4V provides no improvement over non-visual baselines. Our results illustrate how Bayesian models of question-asking can leverage the statistics of language to capture human priors, while highlighting some shortcomings of pure LLMs as grounded reasoners.</li>
</ul>

<h3>Title: Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid  Progress</h3>
<ul>
<li><strong>Authors: </strong>Ameya Prabhu, Vishaal Udandarao, Philip Torr, Matthias Bethge, Adel Bibi, Samuel Albanie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19472">https://arxiv.org/abs/2402.19472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19472">https://arxiv.org/pdf/2402.19472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19472]] Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid  Progress(https://arxiv.org/abs/2402.19472)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Standardized benchmarks drive progress in machine learning. However, with repeated testing, the risk of overfitting grows as algorithms over-exploit benchmark idiosyncrasies. In our work, we seek to mitigate this challenge by compiling ever-expanding large-scale benchmarks called Lifelong Benchmarks. As exemplars of our approach, we create Lifelong-CIFAR10 and Lifelong-ImageNet, containing (for now) 1.69M and 1.98M test samples, respectively. While reducing overfitting, lifelong benchmarks introduce a key challenge: the high cost of evaluating a growing number of models across an ever-expanding sample set. To address this challenge, we also introduce an efficient evaluation framework: Sort \& Search (S&S), which reuses previously evaluated models by leveraging dynamic programming algorithms to selectively rank and sub-select test samples, enabling cost-effective lifelong benchmarking. Extensive empirical evaluations across 31,000 models demonstrate that S&S achieves highly-efficient approximate accuracy measurement, reducing compute cost from 180 GPU days to 5 GPU hours (1000x reduction) on a single A100 GPU, with low approximation error. As such, lifelong benchmarks offer a robust, practical solution to the "benchmark exhaustion" problem.</li>
</ul>

<h3>Title: Retrieval-Augmented Generation for AI-Generated Content: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Bin Cui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19473">https://arxiv.org/abs/2402.19473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19473">https://arxiv.org/pdf/2402.19473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19473]] Retrieval-Augmented Generation for AI-Generated Content: A Survey(https://arxiv.org/abs/2402.19473)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The development of Artificial Intelligence Generated Content (AIGC) has been facilitated by advancements in model algorithms, scalable foundation model architectures, and the availability of ample high-quality datasets. While AIGC has achieved remarkable performance, it still faces challenges, such as the difficulty of maintaining up-to-date and long-tail knowledge, the risk of data leakage, and the high costs associated with training and inference. Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to address such challenges. In particular, RAG introduces the information retrieval process, which enhances AIGC results by retrieving relevant objects from available data stores, leading to greater accuracy and robustness. In this paper, we comprehensively review existing efforts that integrate RAG technique into AIGC scenarios. We first classify RAG foundations according to how the retriever augments the generator. We distill the fundamental abstractions of the augmentation methodologies for various retrievers and generators. This unified perspective encompasses all RAG scenarios, illuminating advancements and pivotal technologies that help with potential future progress. We also summarize additional enhancements methods for RAG, facilitating effective engineering and implementation of RAG systems. Then from another view, we survey on practical applications of RAG across different modalities and tasks, offering valuable references for researchers and practitioners. Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research. Project: https://github.com/hymie122/RAG-Survey</li>
</ul>

<h3>Title: The All-Seeing Project V2: Towards General Relation Comprehension of the  Open World</h3>
<ul>
<li><strong>Authors: </strong>Weiyun Wang, Yiming Ren, Haowen Luo, Tiantong Li, Chenxiang Yan, Zhe Chen, Wenhai Wang, Qingyun Li, Lewei Lu, Xizhou Zhu, Yu Qiao, Jifeng Dai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19474">https://arxiv.org/abs/2402.19474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19474">https://arxiv.org/pdf/2402.19474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19474]] The All-Seeing Project V2: Towards General Relation Comprehension of the  Open World(https://arxiv.org/abs/2402.19474)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present the All-Seeing Project V2: a new model and dataset designed for understanding object relations in images. Specifically, we propose the All-Seeing Model V2 (ASMv2) that integrates the formulation of text generation, object localization, and relation comprehension into a relation conversation (ReC) task. Leveraging this unified task, our model excels not only in perceiving and recognizing all objects within the image but also in grasping the intricate relation graph between them, diminishing the relation hallucination often encountered by Multi-modal Large Language Models (MLLMs). To facilitate training and evaluation of MLLMs in relation understanding, we created the first high-quality ReC dataset ({AS-V2) which is aligned with the format of standard instruction tuning data. In addition, we design a new benchmark, termed Circular-based Relation Probing Evaluation (CRPE) for comprehensively evaluating the relation comprehension capabilities of MLLMs. Notably, our ASMv2 achieves an overall accuracy of 52.04 on this relation-aware benchmark, surpassing the 43.14 of LLaVA-1.5 by a large margin. We hope that our work can inspire more future research and contribute to the evolution towards artificial general intelligence. Our project is released at https://github.com/OpenGVLab/all-seeing.</li>
</ul>

<h3>Title: DistriFusion: Distributed Parallel Inference for High-Resolution  Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu, Kai Li, Song Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.19481">https://arxiv.org/abs/2402.19481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.19481">https://arxiv.org/pdf/2402.19481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.19481]] DistriFusion: Distributed Parallel Inference for High-Resolution  Diffusion Models(https://arxiv.org/abs/2402.19481)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved great success in synthesizing high-quality images. However, generating high-resolution images with diffusion models is still challenging due to the enormous computational costs, resulting in a prohibitive latency for interactive applications. In this paper, we propose DistriFusion to tackle this problem by leveraging parallelism across multiple GPUs. Our method splits the model input into multiple patches and assigns each patch to a GPU. However, na\"{\i}vely implementing such an algorithm breaks the interaction between patches and loses fidelity, while incorporating such an interaction will incur tremendous communication overhead. To overcome this dilemma, we observe the high similarity between the input from adjacent diffusion steps and propose displaced patch parallelism, which takes advantage of the sequential nature of the diffusion process by reusing the pre-computed feature maps from the previous timestep to provide context for the current step. Therefore, our method supports asynchronous communication, which can be pipelined by computation. Extensive experiments show that our method can be applied to recent Stable Diffusion XL with no quality degradation and achieve up to a 6.1$\times$ speedup on eight NVIDIA A100s compared to one. Our code is publicly available at https://github.com/mit-han-lab/distrifuser.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
