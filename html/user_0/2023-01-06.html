<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: MetaSecure: A Passwordless Authentication for the Metaverse. (arXiv:2301.01770v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01770">http://arxiv.org/abs/2301.01770</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01770] MetaSecure: A Passwordless Authentication for the Metaverse](http://arxiv.org/abs/2301.01770) #secure</code></li>
<li>Summary: <p>Metaverse in general holds a potential future for cyberspace. At the
beginning of Web 2.0, it was witnessed that people were signing in with various
pseudonyms or 'nyms', risking their online identities by increasing presence of
fake accounts leading to difficulty in unique identification for different
roles. However, in Web 3.0, the metaverse, a user's identity is tied to their
original identity, where risking one poses a significant risk to the other.
Therefore, this paper proposes a novel authentication system for securing
digital assets, online identity, avatars, and accounts called Metasecure where
a unique id for every entity or user to develop a human establishment is
essential on a digital platform. The proposed passwordless system provides
three layers of security using device attestation, facial recognition and use
of physical security keys, security keys, or smartcards in accordance to Fast
IDentity Online (FIDO2) specifications. It provides SDKs for authentication on
any system including VR/XR glasses, thus ensuring seamlessness in accessing
services in the Metaverse.
</p></li>
</ul>

<h3>Title: FPGA Implementation of SIMON-128 Cryptographic Algorithm Using Artix-7. (arXiv:2301.01889v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01889">http://arxiv.org/abs/2301.01889</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01889] FPGA Implementation of SIMON-128 Cryptographic Algorithm Using Artix-7](http://arxiv.org/abs/2301.01889) #secure</code></li>
<li>Summary: <p>FPGA is a hardware architecture based on a matrix of programmable and
configurable logic circuits thanks to which a large number of functionalities
inside the device can be modified using a hardware description language. These
functionalities must often be secured especially when the context is sensitive
(military, banking, medical, legal, etc.). In this paper, we put forward an
efficient implementation of SIMON's block cipher algorithm using Xilinx Vivado
2018.2. The proposed design is analyzed through simulation on Xilinx Artix-7. A
prototype of our design is implemented using the xc7a35tcsg324-1 FPGA chip.
Performance and results are discussed.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Unsupervised High Impedance Fault Detection Using Autoencoder and Principal Component Analysis. (arXiv:2301.01867v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01867">http://arxiv.org/abs/2301.01867</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01867] Unsupervised High Impedance Fault Detection Using Autoencoder and Principal Component Analysis](http://arxiv.org/abs/2301.01867) #security</code></li>
<li>Summary: <p>Detection of high impedance faults (HIF) has been one of the biggest
challenges in the power distribution network. The low current magnitude and
diverse characteristics of HIFs make them difficult to be detected by
over-current relays. Recently, data-driven methods based on machine learning
models are gaining popularity in HIF detection due to their capability to learn
complex patterns from data. Most machine learning-based detection methods adopt
supervised learning techniques to distinguish HIFs from normal load conditions
by performing classifications, which rely on a large amount of data collected
during HIF. However, measurements of HIF are difficult to acquire in the real
world. As a result, the reliability and generalization of the classification
methods are limited when the load profiles and faults are not present in the
training data. Consequently, this paper proposes an unsupervised HIF detection
framework using the autoencoder and principal component analysis-based
monitoring techniques. The proposed fault detection method detects the HIF by
monitoring the changes in correlation structure within the current waveforms
that are different from the normal loads. The performance of the proposed HIF
detection method is tested using real data collected from a 4.16 kV
distribution system and compared with results from a commercially available
solution for HIF detection. The numerical results demonstrate that the proposed
method outperforms the commercially available HIF detection technique while
maintaining high security by not falsely detecting during load conditions.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: MS-DINO: Efficient Distributed Training of Vision Transformer Foundation Model in Medical Domain through Masked Sampling. (arXiv:2301.02064v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.02064">http://arxiv.org/abs/2301.02064</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.02064] MS-DINO: Efficient Distributed Training of Vision Transformer Foundation Model in Medical Domain through Masked Sampling](http://arxiv.org/abs/2301.02064) #privacy</code></li>
<li>Summary: <p>In spite of the recent success of deep learning in the medical domain, the
problem of data scarcity in the medical domain gets aggravated due to privacy
and data ownership issues. Distributed learning approaches including federated
learning have been studied to alleviate the problems, but they suffer from
cumbersome communication overheads and weakness in privacy protection. To
address this, here we propose a self-supervised masked sampling distillation
method for vision transformer that can be performed without continuous
communication but still enhance privacy using a vision transformer-specific
encryption method. The effectiveness of our method is demonstrated with
extensive experiments on two medical domain data and two different downstream
tasks, showing superior performances than those obtained with the existing
distributed learning strategy as well as the fine-tuning only baseline. As the
self-supervised model built with the proposed method is capable of having a
general semantic understanding of the modality, we demonstrate its potential as
a task-agnostic foundation model for various medical tasks, widening the
applicability in the medical domain.
</p></li>
</ul>

<h3>Title: Privacy and Efficiency of Communications in Federated Split Learning. (arXiv:2301.01824v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01824">http://arxiv.org/abs/2301.01824</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01824] Privacy and Efficiency of Communications in Federated Split Learning](http://arxiv.org/abs/2301.01824) #privacy</code></li>
<li>Summary: <p>Everyday, large amounts of sensitive data \sai{is} distributed across mobile
phones, wearable devices, and other sensors. Traditionally, these enormous
datasets have been processed on a single system, with complex models being
trained to make valuable predictions. Distributed machine learning techniques
such as Federated and Split Learning have recently been developed to protect
user \sai{data and} privacy better while ensuring high performance. Both of
these distributed learning architectures have advantages and disadvantages. In
this paper, we examine these tradeoffs and suggest a new hybrid Federated Split
Learning architecture that combines the efficiency and privacy benefits of
both. Our evaluation demonstrates how our hybrid Federated Split Learning
approach can lower the amount of processing power required by each client
running a distributed learning system, reduce training and inference time while
keeping a similar accuracy. We also discuss the resiliency of our approach to
deep learning privacy inference attacks and compare our solution to other
recently proposed benchmarks.
</p></li>
</ul>

<h3>Title: PMP: Privacy-Aware Matrix Profile against Sensitive Pattern Inference for Time Series. (arXiv:2301.01838v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01838">http://arxiv.org/abs/2301.01838</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01838] PMP: Privacy-Aware Matrix Profile against Sensitive Pattern Inference for Time Series](http://arxiv.org/abs/2301.01838) #privacy</code></li>
<li>Summary: <p>Recent rapid development of sensor technology has allowed massive
fine-grained time series (TS) data to be collected and set the foundation for
the development of data-driven services and applications. During the process,
data sharing is often involved to allow the third-party modelers to perform
specific time series data mining (TSDM) tasks based on the need of data owner.
The high resolution of TS brings new challenges in protecting privacy. While
meaningful information in high-resolution TS shifts from concrete point values
to local shape-based segments, numerous research have found that long
shape-based patterns could contain more sensitive information and may
potentially be extracted and misused by a malicious third party. However, the
privacy issue for TS patterns is surprisingly seldom explored in
privacy-preserving literature. In this work, we consider a new
privacy-preserving problem: preventing malicious inference on long shape-based
patterns while preserving short segment information for the utility task
performance. To mitigate the challenge, we investigate an alternative approach
by sharing Matrix Profile (MP), which is a non-linear transformation of
original data and a versatile data structure that supports many data mining
tasks. We found that while MP can prevent concrete shape leakage, the canonical
correlation in MP index can still reveal the location of sensitive long
pattern. Based on this observation, we design two attacks named Location Attack
and Entropy Attack to extract the pattern location from MP. To further protect
MP from these two attacks, we propose a Privacy-Aware Matrix Profile (PMP) via
perturbing the local correlation and breaking the canonical correlation in MP
index vector. We evaluate our proposed PMP against baseline noise-adding
methods through quantitative analysis and real-world case studies to show the
effectiveness of the proposed method.
</p></li>
</ul>

<h3>Title: DP-SIPS: A simpler, more scalable mechanism for differentially private partition selection. (arXiv:2301.01998v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01998">http://arxiv.org/abs/2301.01998</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01998] DP-SIPS: A simpler, more scalable mechanism for differentially private partition selection](http://arxiv.org/abs/2301.01998) #privacy</code></li>
<li>Summary: <p>Partition selection, or set union, is an important primitive in
differentially private mechanism design: in a database where each user
contributes a list of items, the goal is to publish as many of these items as
possible under differential privacy.
</p></li>
</ul>

<p>In this work, we present a novel mechanism for differentially private
partition selection. This mechanism, which we call DP-SIPS, is very simple: it
consists of iterating the naive algorithm over the data set multiple times,
removing the released partitions from the data set while increasing the privacy
budget at each step. This approach preserves the scalability benefits of the
naive mechanism, yet its utility compares favorably to more complex approaches
developed in prior work.
</p>
<p>Along the way, this work also gives an alternate definition of approximate
zero-concentrated DP, and reports some empirical observations on the utility of
other partition selection mechanisms.
</p>

<h3>Title: Linking Souls to Humans with ZKBID: Accountable Anonymous Blockchain Accounts for Web 3.0 Decentralized Identity. (arXiv:2301.02102v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.02102">http://arxiv.org/abs/2301.02102</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.02102] Linking Souls to Humans with ZKBID: Accountable Anonymous Blockchain Accounts for Web 3](http://arxiv.org/abs/2301.02102) #privacy</code></li>
<li>Summary: <p>A decentralized identity system that can provide users with self-sovereign
digital identities to facilitate complete control over their own data is
paramount to Web 3.0. The accounting system on blockchain is an ideal archetype
for realizing Web 3.0 decentralized identity: users can create their accounts
without registering with a central agent. Such an identity system is endowed
with anonymity property: nobody knows the account's owner because the
relationship between an account and the owner is invisible. Thus, user privacy
is well protected even though the account's data is public. However, a
disadvantage of such complete anonymity is that users can create multiple
accounts without authentication to obfuscate their activities on the
blockchain. In particular, the current anonymous blockchain account system
cannot accurately register the social relationships and interactions between
real human users, given the amorphous mappings between users and blockchain
identities. Mistrust can be a major hurdle to the large-scale deployment of Web
3.0. This work proposes ZKBID, a zero-knowledge blockchain-account-based Web
3.0 decentralized identity scheme, to overcome endemic mistrust in blockchain
account systems. ZKBID links souls (blockchain accounts) to humans (users) in a
one-to-one manner to truly reflect the societal relationships and interactions
between humans on the blockchain. With ZKBID, the users are accountable for
their accounts anonymously, preserving privacy. ZKBID authenticates users using
face match and then maps authenticated users to accounts. Zero-knowledge proofs
encode the face match results, and user-account mappings employ linkable ring
signatures to preserve anonymity. We implemented ZKBID and built a blockchain
test network for evaluation purposes. Our tests demonstrate the effectiveness
of ZKBID and suggest proper ways to configure ZKBID system parameters.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Multi-Task Learning for Budbreak Prediction. (arXiv:2301.01815v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01815">http://arxiv.org/abs/2301.01815</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01815] Multi-Task Learning for Budbreak Prediction](http://arxiv.org/abs/2301.01815) #protect</code></li>
<li>Summary: <p>Grapevine budbreak is a key phenological stage of seasonal development, which
serves as a signal for the onset of active growth. This is also when grape
plants are most vulnerable to damage from freezing temperatures. Hence, it is
important for winegrowers to anticipate the day of budbreak occurrence to
protect their vineyards from late spring frost events. This work investigates
deep learning for budbreak prediction using data collected for multiple grape
cultivars. While some cultivars have over 30 seasons of data others have as
little as 4 seasons, which can adversely impact prediction accuracy. To address
this issue, we investigate multi-task learning, which combines data across all
cultivars to make predictions for individual cultivars. Our main result shows
that several variants of multi-task learning are all able to significantly
improve prediction accuracy compared to learning for each cultivar
independently.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Domain Generalization via Ensemble Stacking for Face Presentation Attack Detection. (arXiv:2301.02145v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.02145">http://arxiv.org/abs/2301.02145</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.02145] Domain Generalization via Ensemble Stacking for Face Presentation Attack Detection](http://arxiv.org/abs/2301.02145) #attack</code></li>
<li>Summary: <p>Face presentation attack detection (PAD) plays a pivotal role in securing
face recognition systems against spoofing attacks. Although great progress has
been made in designing face PAD methods, developing a model that can generalize
well to an unseen test domain remains a significant challenge. Moreover, due to
different types of spoofing attacks, creating a dataset with a sufficient
number of samples for training deep neural networks is a laborious task. This
work addresses these challenges by creating synthetic data and introducing a
deep learning-based unified framework for improving the generalization ability
of the face PAD. In particular, synthetic data is generated by proposing a
video distillation technique that blends a spatiotemporal warped image with a
still image based on alpha compositing. Since the proposed synthetic samples
can be generated by increasing different alpha weights, we train multiple
classifiers by taking the advantage of a specific type of ensemble learning
known as a stacked ensemble, where each such classifier becomes an expert in
its own domain but a non-expert to others. Motivated by this, a meta-classifier
is employed to learn from these experts collaboratively so that when developing
an ensemble, they can leverage complementary information from each other to
better tackle or be more useful for an unseen target domain. Experimental
results using half total error rates (HTERs) on four PAD databases CASIA-MFSD
(6.97 %), Replay-Attack (33.49%), MSU-MFSD (4.02%), and OULU-NPU (10.91%))
demonstrate the robustness of the method and open up new possibilities for
advancing presentation attack detection using ensemble learning with
large-scale synthetic data.
</p></li>
</ul>

<h3>Title: Availability Adversarial Attack and Countermeasures for Deep Learning-based Load Forecasting. (arXiv:2301.01832v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01832">http://arxiv.org/abs/2301.01832</a></li>
<li>Code URL: <a href="https://github.com/xuwkk/aaa_load_forecast">https://github.com/xuwkk/aaa_load_forecast</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01832] Availability Adversarial Attack and Countermeasures for Deep Learning-based Load Forecasting](http://arxiv.org/abs/2301.01832) #attack</code></li>
<li>Summary: <p>The forecast of electrical loads is essential for the planning and operation
of the power system. Recently, advances in deep learning have enabled more
accurate forecasts. However, deep neural networks are prone to adversarial
attacks. Although most of the literature focuses on integrity-based attacks,
this paper proposes availability-based adversarial attacks, which can be more
easily implemented by attackers. For each forecast instance, the availability
attack position is optimally solved by mixed-integer reformulation of the
artificial neural network. To tackle this attack, an adversarial training
algorithm is proposed. In simulation, a realistic load forecasting dataset is
considered and the attack performance is compared to the integrity-based
attack. Meanwhile, the adversarial training algorithm is shown to significantly
improve robustness against availability attacks. All codes are available at
https://github.com/xuwkk/AAA_Load_Forecast.
</p></li>
</ul>

<h3>Title: Randomized Message-Interception Smoothing: Gray-box Certificates for Graph Neural Networks. (arXiv:2301.02039v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.02039">http://arxiv.org/abs/2301.02039</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.02039] Randomized Message-Interception Smoothing: Gray-box Certificates for Graph Neural Networks](http://arxiv.org/abs/2301.02039) #attack</code></li>
<li>Summary: <p>Randomized smoothing is one of the most promising frameworks for certifying
the adversarial robustness of machine learning models, including Graph Neural
Networks (GNNs). Yet, existing randomized smoothing certificates for GNNs are
overly pessimistic since they treat the model as a black box, ignoring the
underlying architecture. To remedy this, we propose novel gray-box certificates
that exploit the message-passing principle of GNNs: We randomly intercept
messages and carefully analyze the probability that messages from adversarially
controlled nodes reach their target nodes. Compared to existing certificates,
we certify robustness to much stronger adversaries that control entire nodes in
the graph and can arbitrarily manipulate node features. Our certificates
provide stronger guarantees for attacks at larger distances, as messages from
farther-away nodes are more likely to get intercepted. We demonstrate the
effectiveness of our method on various models and datasets. Since our gray-box
certificates consider the underlying graph structure, we can significantly
improve certifiable robustness by applying graph sparsification.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Learning Trajectory-Word Alignments for Video-Language Tasks. (arXiv:2301.01953v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01953">http://arxiv.org/abs/2301.01953</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01953] Learning Trajectory-Word Alignments for Video-Language Tasks](http://arxiv.org/abs/2301.01953) #robust</code></li>
<li>Summary: <p>Aligning objects with words plays a critical role in Image-Language BERT
(IL-BERT) and Video-Language BERT (VDL-BERT). Different from the image case
where an object covers some spatial patches, an object in a video usually
appears as an object trajectory, i.e., it spans over a few spatial but longer
temporal patches and thus contains abundant spatiotemporal contexts. However,
modern VDL-BERTs neglect this trajectory characteristic that they usually
follow IL-BERTs to deploy the patch-to-word (P2W) attention while such
attention may over-exploit trivial spatial contexts and neglect significant
temporal contexts. To amend this, we propose a novel TW-BERT to learn
Trajectory-Word alignment for solving video-language tasks. Such alignment is
learned by a newly designed trajectory-to-word (T2W) attention. Besides T2W
attention, we also follow previous VDL-BERTs to set a word-to-patch (W2P)
attention in the cross-modal encoder. Since T2W and W2P attentions have diverse
structures, our cross-modal encoder is asymmetric. To further help this
asymmetric cross-modal encoder build robust vision-language associations, we
propose a fine-grained ``align-before-fuse'' strategy to pull close the
embedding spaces calculated by the video and text encoders. By the proposed
strategy and T2W attention, our TW-BERT achieves SOTA performances on
text-to-video retrieval tasks, and comparable performances on video question
answering tasks with some VDL-BERTs trained on much more data. The code will be
available in the supplementary material.
</p></li>
</ul>

<h3>Title: CAT: LoCalization and IdentificAtion Cascade Detection Transformer for Open-World Object Detection. (arXiv:2301.01970v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01970">http://arxiv.org/abs/2301.01970</a></li>
<li>Code URL: <a href="https://github.com/xiaomabufei/CAT">https://github.com/xiaomabufei/CAT</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01970] CAT: LoCalization and IdentificAtion Cascade Detection Transformer for Open-World Object Detection](http://arxiv.org/abs/2301.01970) #robust</code></li>
<li>Summary: <p>Open-world object detection (OWOD), as a more general and challenging goal,
requires the model trained from data on known objects to detect both known and
unknown objects and incrementally learn to identify these unknown objects. The
existing works which employ standard detection framework and fixed
pseudo-labelling mechanism (PLM) have the following problems: (i) The inclusion
of detecting unknown objects substantially reduces the model's ability to
detect known ones. (ii) The PLM does not adequately utilize the priori
knowledge of inputs. (iii) The fixed selection manner of PLM cannot guarantee
that the model is trained in the right direction. We observe that humans
subconsciously prefer to focus on all foreground objects and then identify each
one in detail, rather than localize and identify a single object
simultaneously, for alleviating the confusion. This motivates us to propose a
novel solution called CAT: LoCalization and IdentificAtion Cascade Detection
Transformer which decouples the detection process via the shared decoder in the
cascade decoding way. In the meanwhile, we propose the self-adaptive
pseudo-labelling mechanism which combines the model-driven with input-driven
PLM and self-adaptively generates robust pseudo-labels for unknown objects,
significantly improving the ability of CAT to retrieve unknown objects.
Comprehensive experiments on two benchmark datasets, i.e., MS-COCO and PASCAL
VOC, show that our model outperforms the state-of-the-art in terms of all
metrics in the task of OWOD, incremental object detection (IOD) and open-set
detection.
</p></li>
</ul>

<h3>Title: Robust Dynamic Radiance Fields. (arXiv:2301.02239v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.02239">http://arxiv.org/abs/2301.02239</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.02239] Robust Dynamic Radiance Fields](http://arxiv.org/abs/2301.02239) #robust</code></li>
<li>Summary: <p>Dynamic radiance field reconstruction methods aim to model the time-varying
structure and appearance of a dynamic scene. Existing methods, however, assume
that accurate camera poses can be reliably estimated by Structure from Motion
(SfM) algorithms. These methods, thus, are unreliable as SfM algorithms often
fail or produce erroneous poses on challenging videos with highly dynamic
objects, poorly textured surfaces, and rotating camera motion. We address this
robustness issue by jointly estimating the static and dynamic radiance fields
along with the camera parameters (poses and focal length). We demonstrate the
robustness of our approach via extensive quantitative and qualitative
experiments. Our results show favorable performance over the state-of-the-art
dynamic view synthesis methods.
</p></li>
</ul>

<h3>Title: The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation. (arXiv:2301.01768v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01768">http://arxiv.org/abs/2301.01768</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01768] The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation](http://arxiv.org/abs/2301.01768) #robust</code></li>
<li>Summary: <p>Conversational artificial intelligence (AI) disrupts how humans interact with
technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue
model that can converse with its human counterparts with unprecedented
capabilities. ChatGPT has witnessed tremendous attention from the media,
academia, industry, and the general public, attracting more than a million
users within days of its release. However, its explosive adoption for
information search and as an automated decision aid underscores the importance
to understand its limitations and biases. This paper focuses on one of
democratic society's most important decision-making processes: political
elections. Prompting ChatGPT with 630 political statements from two leading
voting advice applications and the nation-agnostic political compass test in
three pre-registered experiments, we uncover ChatGPT's pro-environmental,
left-libertarian ideology. For example, ChatGPT would impose taxes on flights,
restrict rent increases, and legalize abortion. In the 2021 elections, it would
have voted most likely for the Greens both in Germany (B\"undnis 90/Die
Gr\"unen) and in the Netherlands (GroenLinks). Our findings are robust when
negating the prompts, reversing the order of the statements, varying prompt
formality, and across languages (English, German, Dutch, and Spanish). We
conclude by discussing the implications of politically biased conversational AI
on society.
</p></li>
</ul>

<h3>Title: A Survey of Code-switching: Linguistic and Social Perspectives for Language Technologies. (arXiv:2301.01967v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01967">http://arxiv.org/abs/2301.01967</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01967] A Survey of Code-switching: Linguistic and Social Perspectives for Language Technologies](http://arxiv.org/abs/2301.01967) #robust</code></li>
<li>Summary: <p>The analysis of data in which multiple languages are represented has gained
popularity among computational linguists in recent years. So far, much of this
research focuses mainly on the improvement of computational methods and largely
ignores linguistic and social aspects of C-S discussed across a wide range of
languages within the long-established literature in linguistics. To fill this
gap, we offer a survey of code-switching (C-S) covering the literature in
linguistics with a reflection on the key issues in language technologies. From
the linguistic perspective, we provide an overview of structural and functional
patterns of C-S focusing on the literature from European and Indian contexts as
highly multilingual areas. From the language technologies perspective, we
discuss how massive language models fail to represent diverse C-S types due to
lack of appropriate training data, lack of robust evaluation benchmarks for C-S
(across multilingual situations and types of C-S) and lack of end-to-end
systems that cover sociolinguistic aspects of C-S as well. Our survey will be a
step towards an outcome of mutual benefit for computational scientists and
linguists with a shared interest in multilingualism and C-S.
</p></li>
</ul>

<h3>Title: Deep Statistical Solver for Distribution System State Estimation. (arXiv:2301.01835v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01835">http://arxiv.org/abs/2301.01835</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01835] Deep Statistical Solver for Distribution System State Estimation](http://arxiv.org/abs/2301.01835) #robust</code></li>
<li>Summary: <p>Implementing accurate Distribution System State Estimation (DSSE) faces
several challenges, among which the lack of observability and the high density
of the distribution system. While data-driven alternatives based on Machine
Learning models could be a choice, they suffer in DSSE because of the lack of
labeled data. In fact, measurements in the distribution system are often noisy,
corrupted, and unavailable. To address these issues, we propose the Deep
Statistical Solver for Distribution System State Estimation (DSS$^2$), a deep
learning model based on graph neural networks (GNNs) that accounts for the
network structure of the distribution system and for the physical governing
power flow equations. DSS$^2$ leverages hypergraphs to represent the
heterogeneous components of the distribution systems and updates their latent
representations via a node-centric message-passing scheme. A weakly supervised
learning approach is put forth to train the DSS$^2$ in a learning-to-optimize
fashion w.r.t. the Weighted Least Squares loss with noisy measurements and
pseudomeasurements. By enforcing the GNN output into the power flow equations
and the latter into the loss function, we force the DSS$^2$ to respect the
physics of the distribution system. This strategy enables learning from noisy
measurements, acting as an implicit denoiser, and alleviating the need for
ideal labeled data. Extensive experiments with case studies on the IEEE 14-bus,
70-bus, and 179-bus networks showed the DSS$^2$ outperforms by a margin the
conventional Weighted Least Squares algorithm in accuracy, convergence, and
computational time, while being more robust to noisy, erroneous, and missing
measurements. The DSS$^2$ achieves a competing, yet lower, performance compared
with the supervised models that rely on the unrealistic assumption of having
all the true labels.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Emotion-Cause Pair Extraction as Question Answering. (arXiv:2301.01982v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01982">http://arxiv.org/abs/2301.01982</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01982] Emotion-Cause Pair Extraction as Question Answering](http://arxiv.org/abs/2301.01982) #extraction</code></li>
<li>Summary: <p>The task of Emotion-Cause Pair Extraction (ECPE) aims to extract all
potential emotion-cause pairs of a document without any annotation of emotion
or cause clauses. Previous approaches on ECPE have tried to improve
conventional two-step processing schemes by using complex architectures for
modeling emotion-cause interaction. In this paper, we cast the ECPE task to the
question answering (QA) problem and propose simple yet effective BERT-based
solutions to tackle it. Given a document, our Guided-QA model first predicts
the best emotion clause using a fixed question. Then the predicted emotion is
used as a question to predict the most potential cause for the emotion. We
evaluate our model on a standard ECPE corpus. The experimental results show
that despite its simplicity, our Guided-QA achieves promising results and is
easy to reproduce. The code of Guided-QA is also provided.
</p></li>
</ul>

<h3>Title: Plant species richness prediction from DESIS hyperspectral data: A comparison study on feature extraction procedures and regression models. (arXiv:2301.01918v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01918">http://arxiv.org/abs/2301.01918</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01918] Plant species richness prediction from DESIS hyperspectral data: A comparison study on feature extraction procedures and regression models](http://arxiv.org/abs/2301.01918) #extraction</code></li>
<li>Summary: <p>The diversity of terrestrial vascular plants plays a key role in maintaining
the stability and productivity of ecosystems. Monitoring species compositional
diversity across large spatial scales is challenging and time consuming. The
advanced spectral and spatial specification of the recently launched DESIS (the
DLR Earth Sensing Imaging Spectrometer) instrument provides a unique
opportunity to test the potential for monitoring plant species diversity with
spaceborne hyperspectral data. This study provides a quantitative assessment on
the ability of DESIS hyperspectral data for predicting plant species richness
in two different habitat types in southeast Australia. Spectral features were
first extracted from the DESIS spectra, then regressed against on-ground
estimates of plant species richness, with a two-fold cross validation scheme to
assess the predictive performance. We tested and compared the effectiveness of
Principal Component Analysis (PCA), Canonical Correlation Analysis (CCA), and
Partial Least Squares analysis (PLS) for feature extraction, and Kernel Ridge
Regression (KRR), Gaussian Process Regression (GPR), Random Forest Regression
(RFR) for species richness prediction. The best prediction results were r=0.76
and RMSE=5.89 for the Southern Tablelands region, and r=0.68 and RMSE=5.95 for
the Snowy Mountains region. Relative importance analysis for the DESIS spectral
bands showed that the red-edge, red, and blue spectral regions were more
important for predicting plant species richness than the green bands and the
near-infrared bands beyond red-edge. We also found that the DESIS hyperspectral
data performed better than Sentinel-2 multispectral data in the prediction of
plant species richness. Our results provide a quantitative reference for future
studies exploring the potential of spaceborne hyperspectral data for plant
biodiversity mapping.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h2>fair</h2>
<h3>Title: Network Utility Maximization with Unknown Utility Functions: A Distributed, Data-Driven Bilevel Optimization Approach. (arXiv:2301.01801v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01801">http://arxiv.org/abs/2301.01801</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01801] Network Utility Maximization with Unknown Utility Functions: A Distributed, Data-Driven Bilevel Optimization Approach](http://arxiv.org/abs/2301.01801) #fair</code></li>
<li>Summary: <p>Fair resource allocation is one of the most important topics in communication
networks. Existing solutions almost exclusively assume each user utility
function is known and concave. This paper seeks to answer the following
question: how to allocate resources when utility functions are unknown, even to
the users? This answer has become increasingly important in the next-generation
AI-aware communication networks where the user utilities are complex and their
closed-forms are hard to obtain. In this paper, we provide a new solution using
a distributed and data-driven bilevel optimization approach, where the lower
level is a distributed network utility maximization (NUM) algorithm with
concave surrogate utility functions, and the upper level is a data-driven
learning algorithm to find the best surrogate utility functions that maximize
the sum of true network utility. The proposed algorithm learns from data
samples (utility values or gradient values) to autotune the surrogate utility
functions to maximize the true network utility, so works for unknown utility
functions. For the general network, we establish the nonasymptotic convergence
rate of the proposed algorithm with nonconcave utility functions. The
simulations validate our theoretical results and demonstrate the great
effectiveness of the proposed method in a real-world network.
</p></li>
</ul>

<h3>Title: Trace Encoding in Process Mining: a survey and benchmarking. (arXiv:2301.02167v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.02167">http://arxiv.org/abs/2301.02167</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.02167] Trace Encoding in Process Mining: a survey and benchmarking](http://arxiv.org/abs/2301.02167) #fair</code></li>
<li>Summary: <p>Encoding methods are employed across several process mining tasks, including
predictive process monitoring, anomalous case detection, trace clustering, etc.
These methods are usually performed as preprocessing steps and are responsible
for transforming complex information into a numerical feature space. Most
papers choose existing encoding methods arbitrarily or employ a strategy based
on a specific expert knowledge domain. Moreover, existing methods are employed
by using their default hyperparameters without evaluating other options. This
practice can lead to several drawbacks, such as suboptimal performance and
unfair comparisons with the state-of-the-art. Therefore, this work aims at
providing a comprehensive survey on event log encoding by comparing 27 methods,
from different natures, in terms of expressivity, scalability, correlation, and
domain agnosticism. To the best of our knowledge, this is the most
comprehensive study so far focusing on trace encoding in process mining. It
contributes to maturing awareness about the role of trace encoding in process
mining pipelines and sheds light on issues, concerns, and future research
directions regarding the use of encoding methods to bridge the gap between
machine learning models and process mining.
</p></li>
</ul>

<h2>interpretability</h2>
<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Accuracy and Fidelity Comparison of Luna and DALL-E 2 Diffusion-Based Image Generation Systems. (arXiv:2301.01914v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2301.01914">http://arxiv.org/abs/2301.01914</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2301.01914] Accuracy and Fidelity Comparison of Luna and DALL-E 2 Diffusion-Based Image Generation Systems](http://arxiv.org/abs/2301.01914) #diffusion</code></li>
<li>Summary: <p>We qualitatively examine the accuracy and fideltiy between two
diffusion-based image generation systems, namely DALL-E 2 and Luna, which have
massive differences in training datasets, algorithmic approaches, prompt
resolvement, and output upscaling. In our research we conclude that DALL-E 2
significantly edges Luna in both alignment and fidelity comparisons
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
